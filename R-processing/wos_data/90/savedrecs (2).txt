FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Liu, XY
   Wang, XC
   Wu, ZK
AF Liu, Xinyue
   Wang, Xingce
   Wu, Zhongke
TI Extending B-spline by piecewise polynomial
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE G(2)continuity; B-spline; curve extension; matrix representation of
   B-spline; minimal strain energy
ID NURBS CURVES; MATRIX
AB Curve extension is a useful tool in the computer-aided design (CAD) community. A given B-spline curve usually needs to be extended by another curve to reach one or more target points. In this work, we aim to enlarge the representation domain of the extending part to achieve the optimal extending result in the global solution space. Inspired by this, we have made three contributions. First, we use piecewise polynomial, that is, a nonuniform B-spline, instead of one polynomial segment to extend the original curve. Compared to one polynomial segment, curves consisting of piecewise polynomial have stronger modeling ability and therefore expand the solution space of the problem. For extension to multiple target points, we are the first to directly give extension results based on all target points rather than extending to every target step by step. Third, we exploit the matrix representation of B-splines to obtain an explicit solution for this extension problem. The detailed formula derivations and experimental results are provided to show the validity and effectiveness of our method.
C1 [Liu, Xinyue; Wang, Xingce; Wu, Zhongke] Beijing Normal Univ, Beijing, Peoples R China.
C3 Beijing Normal University
RP Wang, XC (corresponding author), Beijing Normal Univ, Beijing, Peoples R China.
EM wangxingce@bnu.edu.cn
FU National Key Cooperation from the BRICS Program of China
   [2017YFE0100500]; National Key R&D Program of China [2017YFB1002604,
   2017YFB1402105]; National Nature Science Foundation of China [61972041]
FX National Key Cooperation from the BRICS Program of China, Grant/Award
   Number: No. 2017YFE0100500; National Key R&D Program of China,
   Grant/Award Numbers: No. 2017YFB1002604, No. 2017YFB1402105; National
   Nature Science Foundation of China, Grant/Award Number: No.61972041
CR BARSKY BA, 1990, IEEE COMPUT GRAPH, V10, P60, DOI 10.1109/38.45811
   CHANG G, 1982, COMPUT AIDED DESIGN, V14, P345, DOI 10.1016/0010-4485(82)90059-8
   Chen XD, 2012, COMPUT AIDED DESIGN, V44, P1217, DOI 10.1016/j.cad.2012.07.002
   Cohen E., 1982, Computers in Industry, V3, P9, DOI 10.1016/0166-3615(82)90027-6
   Garin G., 1987, Computer-Aided Geometric Design, V4, P91, DOI 10.1016/0167-8396(87)90027-6
   GRABOWSKI H, 1992, COMPUT AIDED DESIGN, V24, P637, DOI 10.1016/0010-4485(92)90018-6
   Hu SM, 2002, COMPUT AIDED DESIGN, V34, P415, DOI 10.1016/S0010-4485(01)00108-7
   Liu LG, 2002, COMPUT AIDED GEOM D, V19, P409, DOI 10.1016/S0167-8396(02)00124-3
   Liu LH, 2008, International Conference on Intelligent Computation Technology and Automation, Vol 1, Proceedings, P1096, DOI 10.1109/ICICTA.2008.452
   Liu YJ, 2009, J ZHEJIANG UNIV-SC A, V10, P570, DOI 10.1631/jzus.A0820819
   Lu Y, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-5322-x
   Mo Guo-liang, 2006, Journal of Zhejiang University (Science), V7, P2043, DOI 10.1631/jzus.2006.A2043
   Piegl L, 1995, NURBS BOOK
   Qin KH, 2000, VISUAL COMPUT, V16, P177, DOI 10.1007/s003710050206
   Rosales E, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322970
   SHETTY S, 1991, COMPUT AIDED DESIGN, V23, P484, DOI 10.1016/0010-4485(91)90046-Y
   TILLER W, 1992, COMPUT AIDED DESIGN, V24, P445, DOI 10.1016/0010-4485(92)90012-Y
   Wang XF, 1997, COMPUT AIDED DESIGN, V29, P485, DOI 10.1016/S0010-4485(96)00087-5
NR 18
TC 0
Z9 0
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1942
DI 10.1002/cav.1942
EA SEP 2020
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000566432600001
DA 2024-07-18
ER

PT J
AU Sun, MH
   Yang, SW
   Liu, HZ
AF Sun, Manhui
   Yang, Shaowu
   Liu, Henzhu
TI Scale-aware camera localization in 3D LiDAR maps with a monocular visual
   odometry
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE multimodal data matching; point cloud registration; visual localization
ID REGISTRATION
AB Localization information is essential for mobile robot systems in navigation tasks. Many visual-based approaches focus on localizing a robot within prior maps acquired with cameras. It is critical where the Global Positioning System signal is unreliable. In contrast to conventional methods that localize a camera in an image-based map, we propose a novel approach that localizes a monocular camera within a given three-dimensional (3D) light detection and ranging (LiDAR) map. We employ visual odometry to reconstruct a semidense set of 3D points from the monocular camera images. These points are continuously matched against the 3D prior LiDAR map by a modified feature-based point cloud registration method to track a full six-degree-of-freedom camera pose. Since the monocular camera suffers from the scale-drift problem due to the lack of depth information, the proposed method solves it by adopting updatable scale estimation. Experiments carried out on a publicly large-scale data set demonstrate that the camera and LiDAR multimodal data matching problem is solved, and the localization accuracy of our method is comparable to state-of-the-art approaches.
C1 [Sun, Manhui; Yang, Shaowu; Liu, Henzhu] Natl Univ Def Technol, Coll Comp, State Key Lab High Performance Comp, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Yang, SW (corresponding author), Natl Univ Def Technol, Coll Comp, State Key Lab High Performance Comp, Changsha 410073, Hunan, Peoples R China.
EM shaowu.yang@nudt.edu.cn
OI Sun, Manhui/0000-0002-6850-8789
FU National Natural Science Foundation of China [61803375, 91648204];
   National Key Research and Development Program of China [2017YFB1001900,
   2017YFB1301104]; National Science and Technology Major Project
FX National Natural Science Foundation of China, Grant/Award Number:
   61803375 and 91648204; National Key Research and Development Program of
   China, Grant/Award Number: 2017YFB1001900 and 2017YFB1301104; National
   Science and Technology Major Project
CR Al-Durgham K., 2014, P ASPRS 2014 ANN C L
   [Anonymous], P IEEE INT C ROB AUT
   [Anonymous], P IEEE RSJ INT C INT
   Bellekens B, 2014, AMBIENT 2014, P8
   Bosse M, 2012, IEEE T ROBOT, V28, P1104, DOI 10.1109/TRO.2012.2200990
   Concha A, 2015, 2015 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR)
   Eade E, 2006, P IEEE C COMP VIS PA
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004
   Gao X, 2018, IEEE INT C INT ROBOT, P2198, DOI 10.1109/IROS.2018.8593376
   Geiger A., 2012, CVPR
   Holz D, 2015, IEEE ROBOT AUTOM MAG, V22, P110, DOI 10.1109/MRA.2015.2432331
   문희창, 2008, [Journal of Institute of Control, Robotics and Systems, 제어.로봇.시스템학회 논문지], V14, P27
   Kim YC, 2018, PRION, V12, P197, DOI 10.1080/19336896.2018.1471922
   KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377
   Mellado N, 2014, COMPUT GRAPH FORUM, V33, P205, DOI 10.1111/cgf.12446
   Nüchter A, 2007, J FIELD ROBOT, V24, P699, DOI 10.1002/rob.20209
   Nützi G, 2011, J INTELL ROBOT SYST, V61, P287, DOI 10.1007/s10846-010-9490-z
   Pomerleau Francois, 2015, Found. Trends Robot., V4, P1
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Rusinkiewicz S, 2002, P INT C 3 D DIG IM M
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Rusu RB, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P643, DOI 10.1109/ICARCV.2008.4795593
   Taketomi T, 2017, IPSJ Trans. Comput. Vis. Appl, V9, P1, DOI [10.1186/s41074-017-0027-2, DOI 10.1186/S41074-017-0027-2]
   Wolcott RW, 2014, IEEE INT C INT ROBOT, P176, DOI 10.1109/IROS.2014.6942558
   Xiao JH, 2013, J FIELD ROBOT, V30, P552, DOI 10.1002/rob.21457
   Yang BS, 2014, ISPRS J PHOTOGRAMM, V95, P109, DOI 10.1016/j.isprsjprs.2014.05.012
   Yang SW, 2017, ROBOT AUTON SYST, V93, P116, DOI 10.1016/j.robot.2017.03.018
   Yang SN, 2018, IEEE ACCESS, V6, P41539, DOI 10.1109/ACCESS.2018.2858809
   Zhang J., 2014, ROBOTICS SCI SYSTEMS, P9, DOI 10.15607/RSS.2014.X.007
NR 32
TC 1
Z9 2
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1879
DI 10.1002/cav.1879
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400007
DA 2024-07-18
ER

PT J
AU Kim, JH
   Kim, W
   Kim, YB
   Im, J
   Lee, J
   Kim, SJ
AF Kim, Jong-Hyun
   Kim, Wook
   Kim, Young Bin
   Im, Jaeho
   Lee, Jung
   Kim, Sun-Jeong
TI Robust handling of clumping and stiffness in wet hair animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE clumping; coupling of water and hair; stiffness; wet hair animation
AB Simulating the clumping and stiffness of wet hair or fur is a challenging problem. The dynamics of wet hair or fur are characterized by clumping and stiffness at the tip, which can be seen clearly in running animals or headbanging scenes. Existing animation methods address these phenomena within preset scenarios. However, there is no consensus on a method for depicting the details of wet hair. This paper therefore proposes a new method for modeling the clumping and stiffness of wet hair or fur. Previous studies have focused on modeling the absorption of water into hair or fur, whereas this paper considers a realistic simulation of wet hair. Unlike dry hair strands, wet hair strands adjacent to one another are subject to a clumping force, gathering together and becoming more stiff as the saturation level of water increases. The proposed method builds on a surface-tension model based on smoothed particle hydrodynamics to simulate the clumping force and to adjust the hair elasticity via stiffness constraints. The method gives realistic simulations of wet hair by maintaining the clumping force of the wet hair during movement and by simulating the stiffness of the hair in line with its water-saturation level.
C1 [Kim, Jong-Hyun; Kim, Wook; Kim, Young Bin; Im, Jaeho; Lee, Jung] Kangnam Univ, Gangnamno 40, Yongin 136713, Gyeonggi Do, South Korea.
   [Kim, Sun-Jeong] Hallym Univ, 1215 Engn Bldg,1 Hallymdaehak Gil, Chunchon 24252, Gangwondo, South Korea.
C3 Kangnam University; Hallym University
RP Kim, SJ (corresponding author), Hallym Univ, 1215 Engn Bldg,1 Hallymdaehak Gil, Chunchon 24252, Gangwondo, South Korea.
EM sunkim@hallym.ac.kr
OI Kim, Jong-Hyun/0000-0003-1603-2675
CR Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   [Anonymous], 2014, WORKSH VIRT REAL INT
   [Anonymous], 2003, P ACM SIGGRAPH EUR S
   Baek S, 2015, COMPUT ANIMAT VIRT W, V26, P347, DOI 10.1002/cav.1646
   Brown J, 2004, VISUAL COMPUT, V20, P165, DOI 10.1007/s00371-003-0226-y
   Chen YJ, 2012, VISUAL COMPUT, V28, P765, DOI 10.1007/s00371-012-0687-y
   Choe B., 2005, SCA 05, P153, DOI DOI 10.1145/1073368.1073389
   Fei Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073630
   LENAERTS T, 2009, MIXING FLUIDS AND GR, V28, P213, DOI DOI 10.1111/J.1467-8659.2009.01360.X
   Lenaerts T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360648
   M_uller M., 2012, P VRIPHYS, P39
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   RUNGJIRATANANON. W, 2008, REAL TIME ANIMATION, V27, P1887
   RUNGJIRATANANON. W, 2012, WETTING EFFECTS IN H, V31, P1993, DOI DOI 10.1111/J.1467-8659.2012.03191.X
   Selle A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360663
   Tampubolon AP, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073651
   Um K, 2013, COMPUT ANIMAT VIRT W, V24, P247, DOI 10.1002/cav.1497
   YUKSEL C., 2009, ACM SIGGRAPH ASIA 20
NR 19
TC 0
Z9 0
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2017
VL 28
IS 6
AR e1796
DI 10.1002/cav.1796
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9YH
UT WOS:000417254100007
DA 2024-07-18
ER

PT J
AU Polceanu, M
   Buche, C
AF Polceanu, Mihai
   Buche, Cedric
TI Computational mental simulation: A review
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Review
DE agent controller; analogical representations; decision-making; inner
   virtual world; mental simulation; robot cognition
ID IMAGERY; MIND; PERCEPTION; IMITATION; COGNITION; FUTURE; MODEL; TIME; ME
AB This paper is dedicated to the study of existing approaches that explicitly use mental simulation. Current implementations of the mental simulation paradigm, taken together, computationally address many aspects suggested by cognitive science research. Agents are able to find solutions to nontrivial scenarios in virtual or physical environments. Existing systems also learn new behavior by imitation of others similar to them and model the behavior of different others with the help of specialized models, culminating with the collaboration between agents and humans. Approaches that use self models are able to mentally simulate interaction and to learn about their own physical properties. Multiple mental simulations are used to find solutions to tasks, for truth maintenance, and contradiction detection. However, individual approaches do not cover all of the contexts of mental simulation and most rely on techniques which are only suitable for subsets of obtainable functionality. This review spans through four perspectives on the functionality of state-of-the-art artificial intelligence applications, while linking them to cognitive science research results. Finally, an overview identifies the main gaps in existing literature on computational mental simulation and provides our suggestions for future development.
C1 [Polceanu, Mihai] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
   [Polceanu, Mihai; Buche, Cedric] Ecole Natl Ingn Brest, Lab STICC, Plouzane, France.
C3 State University System of Florida; Florida International University;
   Ecole Nationale d'Ingenieurs de Brest (ENIB)
RP Polceanu, M (corresponding author), Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
EM mpolcean@cs.fiu.edu
CR Abou Risk N., 2010, P INT C AUTONOMOUS A, P159
   Alissandrakis A, 2002, IEEE T SYST MAN CY A, V32, P482, DOI 10.1109/TSMCA.2002.804820
   Anderson J. R., 1993, Rules of the mind
   [Anonymous], 1986, Mental Images and Their Transformations
   [Anonymous], 2011, The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 1
   [Anonymous], 1983, The architecture of cognition
   ap Cenydd L, 2013, COMPUT ANIMAT VIRT W, V24, P65, DOI 10.1002/cav.1436
   Atkeson CG, 1997, IEEE INT CONF ROBOT, P3557, DOI 10.1109/ROBOT.1997.606886
   Balla RK, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P40
   Barsalou LW, 2009, PHILOS T R SOC B, V364, P1281, DOI 10.1098/rstb.2008.0319
   Bergen B., 2005, Proceedings of the Twenty-Seventh Annual Conference of the Cognitive Science Society, P232
   Berthoz A., 1997, SENS MOUVEMENT O JAC
   Bongard J, 2006, SCIENCE, V314, P1118, DOI 10.1126/science.1133687
   Breazeal C, 2009, INT J ROBOT RES, V28, P656, DOI 10.1177/0278364909102796
   Brooks R. A., 1990, Robotics and Autonomous Systems, V6, P3, DOI 10.1016/S0921-8890(05)80025-9
   Browne CB, 2012, IEEE T COMP INTEL AI, V4, P1, DOI 10.1109/TCIAIG.2012.2186810
   Buche C, 2013, COMPUT ANIMAT VIRT W, V24, P111, DOI 10.1002/cav.1486
   Buche C, 2010, COMPUT ANIMAT VIRT W, V21, P573, DOI 10.1002/cav.363
   Buche C, 2002, 3 INT C INT GAM SIM, P89
   Buchsbaum D, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P85
   Buckner RL, 2007, TRENDS COGN SCI, V11, P49, DOI 10.1016/j.tics.2006.11.004
   Byrne P, 2007, PSYCHOL REV, V114, P340, DOI 10.1037/0033-295X.114.2.340
   Cardin Y, 2016, THESIS
   Carruthers P., 1996, Theories of theories of mind
   Cassimatis NL, 2004, ROBOT AUTON SYST, V49, P13, DOI 10.1016/j.robot.2004.07.014
   Castillo E., 1997, Expert Systems and Probabilistic Network Models, V493, P543
   Chersi F, 2013, ADAPT BEHAV, V21, P251, DOI 10.1177/1059712313488789
   Churchill D., 2013, 2013 IEEE Conference on Computational Inteligence in Games (CIG), P1
   Costa P, 2013, J ARTIF INTELL RES, V47, P313, DOI 10.1613/jair.3989
   Dautenhahn K, 2002, FROM ANIM ANIMAT, P1
   Decety Jean, 1995, Behavioural Brain Research, V72, P127, DOI 10.1016/0166-4328(96)00141-6
   Di Nuovo A, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P91, DOI 10.1109/SSCI.2015.23
   Doya K, 2000, NEURAL COMPUT, V12, P219, DOI 10.1162/089976600300015961
   DUFOSSE M, 1985, EXP BRAIN RES, V60, P330
   Eslami SM Ali, 2016, NeurIPS, P3225
   Frith U, 1999, MIND LANG, V14, P1
   Fürnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794
   Goldman A., 2005, PERSPECTIVES IMITATI, P79
   Gray J, 2005, P AAAI 2005 WORKSH M, P79
   Grèzes J, 2001, HUM BRAIN MAPP, V12, P1, DOI 10.1002/1097-0193(200101)12:1<1::AID-HBM10>3.0.CO;2-V
   Gross J, 2004, P NATL ACAD SCI USA, V101, P13050, DOI 10.1073/pnas.0404944101
   Grush R, 2004, BEHAV BRAIN SCI, V27, P377, DOI 10.1017/S0140525X04000093
   Hanratty T, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY (IAT 2007), P116, DOI 10.1109/IAT.2007.43
   Happé F, 2003, ANN NY ACAD SCI, V1001, P134, DOI 10.1196/annals.1279.008
   Hegarty M, 2004, TRENDS COGN SCI, V8, P280, DOI 10.1016/j.tics.2004.04.001
   Hsu F-H., 2002, Behind Deep Blue: building the computer that defeated the world chess champion
   Kahneman D., 1981, The simulation heuristic (TR-5)
   Kavsek B, 2006, APPL ARTIF INTELL, V20, P543, DOI 10.1080/08839510600779688
   Kennedy WG, 2009, INT J SOC ROBOT, V1, P181, DOI 10.1007/s12369-009-0014-6
   Kennedy WilliamG., 2008, AAAI, P1300
   Kocsis L, 2006, LECT NOTES COMPUT SC, V4212, P282, DOI 10.1007/11871842_29
   Kormushev P, 2013, ROBOTICS, V2, P122, DOI 10.3390/robotics2030122
   Kosslyn S. M., 1980, Image and mind
   KOSSLYN SM, 1988, SCIENCE, V240, P1621, DOI 10.1126/science.3289115
   Kunze L, 2011, IEEE INT C INT ROBOT, P3172, DOI 10.1109/IROS.2011.6048350
   Laird J. E., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, P385, DOI 10.1145/375735.376343
   Laird JE, 2012, SOAR COGNITIVE ARCHITECTURE, P1
   LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6
   MARKMAN KD, 1993, J EXP SOC PSYCHOL, V29, P87, DOI 10.1006/jesp.1993.1005
   Masterjohn JG, 2015, LECT NOTES ARTIF INT, V9513, P177, DOI 10.1007/978-3-319-29339-4_15
   Meltzoff A.N., 2002, Blackwell Handbook of Childhood Cognitive Development, P6
   MELTZOFF AN, 1995, DEV PSYCHOL, V31, P838, DOI 10.1037/0012-1649.31.5.838
   Meltzoff AN, 2002, ELEMENTS DEV THEORY
   Meltzoff AN, 2007, DEVELOPMENTAL SCI, V10, P126, DOI 10.1111/j.1467-7687.2007.00574.x
   Miwa K, 2014, LECT NOTES COMPUT SC, V8474, P398, DOI 10.1007/978-3-319-07221-0_49
   Moulton ST, 2009, PHILOS T R SOC B, V364, P1273, DOI 10.1098/rstb.2008.0314
   Negnevitsky M., 2005, RULE BASED EXPERT SY, P25
   Pearl J., 2009, Causality, DOI DOI 10.1017/CBO9780511803161
   Pezzulo G, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00092
   Polceanu M, 2015, 28 INT FLOR ART INT, P73
   Polceanu M., IJCAI 2013 S ANGRY B
   Poli R, 2010, FORESIGHT, V12, P7, DOI 10.1108/14636681011049839
   PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512
   Rabbani AH, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1726
   Rao RPN, 2004, BAYESIAN MODEL IMITA
   Rizzolatti G, 2005, KODALY ENVOY, V66, P557
   Rochat Philippe, 2009, P191, DOI 10.1007/978-1-59745-479-7_9
   Roese NealJ., 1995, What Might Have Been: The Social Psychology of Counterfactual Thinking
   Roese NJ, 1997, PSYCHOL BULL, V121, P133, DOI 10.1037/0033-2909.121.1.133
   Roy D, 2004, IEEE T SYST MAN CY B, V34, P1374, DOI 10.1109/TSMCB.2004.823327
   Rumelhart D.E., 1983, Representation in memory
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Svensson H., 2009, P 31 ANN C COGN SCI, P2890
   Svensson H, 2016, COGN SYST RES, V40, P161, DOI 10.1016/j.cogsys.2016.06.003
   Taylor SE, 1998, AM PSYCHOL, V53, P429, DOI 10.1037/0003-066X.53.4.429
   Ustun V, 2008, 2008 WINTER SIMULATION CONFERENCE, VOLS 1-5, P879, DOI 10.1109/WSC.2008.4736152
   Van Hoeck N, 2013, SOC COGN AFFECT NEUR, V8, P556, DOI 10.1093/scan/nss031
   Vernon D, 2007, IEEE T EVOLUT COMPUT, V11, P151, DOI 10.1109/TEVC.2006.890274
   Visser U, 2007, AI MAG, V28, P115
   Wilkins D. E., 2014, Practical Planning: Extending the Classical AI Planning Paradigm
   Williams D, 2010, AUTISM, V14, P474, DOI 10.1177/1362361310366314
   Wilson JR, 2016, AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1015
   Wu J., 2015, ADV NEURAL INFORM PR, DOI DOI 10.1007/978-3-319-26532-2_15
   Ziemke T, 2005, NEUROCOMPUTING, V68, P85, DOI 10.1016/j.neucom.2004.12.005
NR 94
TC 1
Z9 1
U1 2
U2 25
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2017
VL 28
IS 5
AR e1732
DI 10.1002/cav.1732
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA FO9XG
UT WOS:000417251100005
DA 2024-07-18
ER

PT J
AU Oshita, M
   Oshima, H
   Senju, Y
   Morishige, S
AF Oshita, Masaki
   Oshima, Hayato
   Senju, Yuta
   Morishige, Syun
TI Character motion synthesis by principal component analysis and motion
   control interface by hands
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion control; hand; principal component analysis; computer animation;
   user interface
ID REAL-TIME
AB In this paper, we propose an interactive character motion control interface that uses hands. Using their hands and fingers, the user can control a large number of degrees of freedom at the same time. We applied principal component analysis to a set of sample poses and assigned the extracted principal components to each degree of freedom of the hands (such as the hand positions and finger bending/extending angles). The user can control the blending weights of the principal components and deform the character's pose by moving their hands and bending/extending their fingers. We introduced pose and action controls, so that we can alter the standing pose and perform various actions with deformations. So that various types of actions were possible, we constructed a number of action models in advance. We introduced action model selection and action execution mechanisms. We developed methods for computing the feature vector, for applying principal component analysis, and for pose and action synthesis. In addition, we introduced a pose transition method for performing a step motion when necessary to prevent foot sliding. We present our experimental results and demonstrate the effectiveness of our interface. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Oshita, Masaki; Oshima, Hayato; Senju, Yuta; Morishige, Syun] Kyushu Inst Technol, Iizuka, Fukuoka, Japan.
C3 Kyushu Institute of Technology
RP Oshita, M (corresponding author), Kyushu Inst Technol, Iizuka, Fukuoka, Japan.
EM oshita@ces.kyutech.ac.jp
FU Japan Society for the Promotion of Science (JSPS) [24500238, 15H02704];
   Grants-in-Aid for Scientific Research [15H02704, 24500238] Funding
   Source: KAKEN
FX This work was supported in part by Grant-in-Aid for Scientific Research
   (no. 24500238 and 15H02704) from the Japan Society for the Promotion of
   Science (JSPS).
CR Carvalho SR, 2007, COMPUT ANIMAT VIRT W, V18, P493, DOI 10.1002/cav.210
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Igarashi Takeo, 2005, ACM SIGGRAPH EUR S C, P253
   Ishigaki S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531367
   Jain S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477936
   Komura T, 2006, COMPUT ANIMAT VIRT W, V17, P513, DOI 10.1002/cav.114
   Laszlo J, 2005, COMPUT GRAPH FORUM, V24, P257, DOI 10.1111/j.1467-8659.2005.00850.x
   Liang H, 2014, IEEE T MULTIMEDIA, V16, P1241, DOI 10.1109/TMM.2014.2306177
   Liang H, 2013, VISUAL COMPUT, V29, P837, DOI 10.1007/s00371-013-0822-4
   Liang XB, 2009, COMPUT ANIMAT VIRT W, V20, P89, DOI 10.1002/cav.311
   Ma ZY, 2014, VISUAL COMPUT, V30, P1133, DOI 10.1007/s00371-013-0894-1
   Macchietto A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531386
   Min JY, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640452
   Nik INI, 2012, IIEEJ IM EL VIS COMP, P1
   Numaguchi Naoki, 2011, P 2011 ACM SIGGRAPH, P157
   Okada Y., 2003, P 3 IASTED INT C VIS, P13
   Oshita M, 2005, COMPUT ANIMAT VIRT W, V16, P237, DOI 10.1002/cav.97
   Oshita M., 2006, ACM SIGCHI INT C ADV
   Oshita M., 2013, Proceedings of the 12th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry - VRCAI, V13, P131
   Oshita M, 2012, WSCG'2012, CONFERENCE PROCEEDINGS, PTS I & II, P213
   Oshita M, 2008, COMPUT GRAPH FORUM, V27, P1909, DOI 10.1111/j.1467-8659.2008.01339.x
   Park SI., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. SCA2, P105, DOI DOI 10.1145/545261.545279
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Shin HJ, 2006, COMPUT ANIMAT VIRT W, V17, P219, DOI 10.1002/cav.125
   Shiratori T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409076
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   Wu CC, 2008, LECT NOTES COMPUT SC, V5358, P97
   Wu Chun-Chih, 2010, P 2010 ACM SIGGRAPH, P113
NR 31
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2016
VL 27
IS 6
BP 532
EP 545
DI 10.1002/cav.1673
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EE1HQ
UT WOS:000389332200003
DA 2024-07-18
ER

PT J
AU Yang, X
   Liu, Q
   Zhang, PF
   Xin, LT
   Zhou, DS
   Wang, YX
   Zhang, Q
   Wei, XP
AF Yang, Xin
   Liu, Qi
   Zhang, Pengfei
   Xin, Lutong
   Zhou, Dongsheng
   Wang, Yuxin
   Zhang, Qiang
   Wei, Xiaopeng
TI DKD: a fast <i>k</i>-d tree update design for dynamic scenes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE acceleration structure; dynamic scene; rendering
ID CONSTRUCTION; PARALLEL
AB We design dynamic k-d (DKD) tree based on classical k-d tree for animated scene rendering. Our method can inherit the benefit of efficient traversal of k-d tree and minimize time cost to update DKD tree, making it well suited for animated geometry. DKD employs primitive reset, redistribution to reflect the updated positions of geometry, and leaf node incremental growing to avoid the deterioration of hierarchy quality due to refitting. Our experiments show that DKD has a significant rendering performance improvement than selected existing methods. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Yang, Xin; Liu, Qi; Zhang, Pengfei] Dalian Univ Technol, Dept Comp Sci, Dalian, Peoples R China.
   [Xin, Lutong] Dalian Univ Technol, Comp Sci, Dalian, Peoples R China.
   [Wang, Yuxin] Dalian Univ Technol, Sch Comp Sci, Dalian, Peoples R China.
   [Wei, Xiaopeng] Dalian Univ Technol, Dalian, Peoples R China.
   [Zhou, Dongsheng] Dalian Univ, Minist Educ, Key Lab Adv Design & Intelligent Comp, Dalian, Peoples R China.
   [Zhang, Qiang] Dalian Univ, Ctr Adv Design Technol, Dalian, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology; Dalian
   University of Technology; Dalian University of Technology; Dalian
   University; Dalian University
RP Wang, YX (corresponding author), Dalian Univ Technol, Dalian, Peoples R China.; Zhou, DS (corresponding author), Dalian Univ, Dalian, Peoples R China.
EM donyson@126.com; wyx@dlut.edu.cn
RI Zhang, Qiang/A-3698-2010; zhang, qiang/HZJ-9551-2023; wei,
   xiao/ISB-6027-2023; Zhang, Pengfei/GPC-5146-2022; Wang,
   Yuxin/ABF-2724-2020; jiang, lei/IWE-1124-2023
OI Zhang, Pengfei/0000-0002-7090-0325; Zhang, Qiang/0000-0003-3776-9799; ,
   Xin/0000-0002-8046-722X
CR Bittner J, 2015, COMPUT GRAPH-UK, V47, P135, DOI 10.1016/j.cag.2014.12.001
   Bocchino Robert L., 2010, P HIGH PERF GRAPH, P77
   Domingues Leonardo., 2015, Proceedings of High-Performance Graphics, P13
   Fatahalian G., 2013, P 5 HIGH PERF GRAPH, P81, DOI 10.1145/2492045.2492054
   Garanzha K., 2011, P ACM SIGGRAPH S HIG, P59, DOI DOI 10.1145/2018323.2018333
   Garanzha K, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P123, DOI 10.1109/RT.2008.4634632
   Günther J, 2006, COMPUT GRAPH FORUM, V25, P517, DOI 10.1111/j.1467-8659.2006.00971.x
   Ize T., 2007, P EUR S PAR GRAPH VI, P101
   Karras Tero., 2013, Proceedings of the 5th High-Performance Graphics Conference, P89, DOI DOI 10.1145/2492045.2492055
   Kopta D., 2012, P ACM SIGGRAPH S INT, P197, DOI DOI 10.1145/2159616.2159649
   Pantaleoni J., 2010, P C HIGH PERFORMANCE, P87
   Pharr M, 2010, PHYS BASED RENDERING
   Shevtsov M, 2007, COMPUT GRAPH FORUM, V26, P395, DOI 10.1111/j.1467-8659.2007.01062.x
   Wald I, 2008, COMPUT GRAPH-UK, V32, P3, DOI 10.1016/j.cag.2007.11.004
   Wald I, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P33, DOI 10.1109/RT.2007.4342588
   Wald I, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P61
   Wald I, 2009, COMPUT GRAPH FORUM, V28, P1691, DOI 10.1111/j.1467-8659.2008.01313.x
   Wu Zhefeng, 2011, P ACM SIGGRAPH S HIG, P71, DOI DOI 10.1145/2018323.2018335
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 19
TC 2
Z9 2
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 340
EP 350
DI 10.1002/cav.1717
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300018
DA 2024-07-18
ER

PT J
AU Kim, YJ
   Woo, JH
   Kim, MS
   Elber, G
AF Kim, Yong-Joon
   Woo, Jong-Hwa
   Kim, Myung-Soo
   Elber, Gershon
TI Interactive tree modeling and deformation with collision detection and
   avoidance
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE interactive tree modeling and deformation; collision detection and
   avoidance; sweep surfaces; bounding volume hierarchy (BVH); convex
   combination; growth simulation; aging; withering
AB We present an interactive tree modeling and deformation system that supports an efficient collision detection and avoidance using a bounding volume hierarchy of sweep surfaces. Starting with conventional tree models (given as meshes), we convert them into sweep surfaces and deform their branches interactively while detecting and avoiding collisions with many other branches. Multiple tree models (sharing the same topology) can be generated with great ease using this sweep-based approach, and they can serve as a basis for the generation of a multiparameter family of trees. We demonstrate the effectiveness of our approach in an automatic generation of similar trees, the colonization of trees to form a forest, and the tree growth, aging, and withering simulations. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Kim, Yong-Joon; Elber, Gershon] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
   [Woo, Jong-Hwa; Kim, Myung-Soo] Seoul Natl Univ, Sch Comp Sci & Engn, Coll Engn, Seoul 151744, South Korea.
C3 Technion Israel Institute of Technology; Seoul National University (SNU)
RP Kim, MS (corresponding author), Seoul Natl Univ, Sch Comp Sci & Engn, Coll Engn, Seoul 151744, South Korea.
EM mskim@snu.ac.kr
FU European Union under REA [PIAP-GA-2011-286426]; Israel Science
   Foundation [278/13]; Korean MCST; KOCCA in the CT RD Program
   [R2014060001]; NRF [2013R1A1A2010085]
FX This work was supported in part by the People Programme (Marie Curie
   Actions) of the European Union's Seventh Framework Programme
   FP7/2007-2013/ under REA grant agreement PIAP-GA-2011-286426, in part by
   the Israel Science Foundation (Grant No. 278/13), and also in part by
   the Korean MCST and KOCCA in the CT R&D Program 2014 (No. R2014060001),
   and in part by NRF Research Grants (No. 2013R1A1A2010085).
CR Akenine-Mollers T, 2008, REAL TIME RENDERING
   Chiba N, 1996, J VISUAL COMP ANIMAT, V7, P79, DOI 10.1002/(SICI)1099-1778(199604)7:2<79::AID-VIS139>3.0.CO;2-W
   Chis X, 2007, ACM SIGGRAPH POST
   Farins G, 2002, CURVES SURFACES CAGD
   Filip D., 1986, Computer-Aided Geometric Design, V3, P295, DOI 10.1016/0167-8396(86)90005-1
   FOWLER DR, 1992, COMP GRAPH, V26, P361, DOI 10.1145/142920.134093
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Hyun DE, 2005, VISUAL COMPUT, V21, P542, DOI 10.1007/s00371-005-0343-x
   Krishnamurthy A, 2011, COMPUT AIDED DESIGN, V43, P1370, DOI 10.1016/j.cad.2011.08.022
   Larsens E, 1999, TR99018 UNC DEP COMP
   Lee J, 2006, COMPUT ANIMAT VIRT W, V17, P479, DOI 10.1002/cav.150
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Mechs R, 1996, COMP GRAPH SIGGRAPH, P397
   Palubicki W, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531364
   Park J, 2013, COMPUT ANIMAT VIRT W, V24, P317, DOI 10.1002/cav.1510
   Pirk S., 2012, ACM T GRAPHIC, V31, DOI DOI 10.1145/2185520.2185546
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366188
   Prusinkiewicz P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P351, DOI 10.1145/192161.192254
   Prusinkiewiczs P, 1990, ALGORITHMIC BEAUTY P
   RUNIONS A, 2007, EUR WORKSH NAT PHEN, P63
   Stava O, 2014, COMPUT GRAPH FORUM, V33, P118, DOI 10.1111/cgf.12282
   Tan P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239538
   Tans P, 2008, ACM T GRAPHIC, V27
   Wang WP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330513
   Weber J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P119, DOI 10.1145/218380.218427
   Yoon SH, 2006, COMPUT GRAPH FORUM, V25, P487, DOI 10.1111/j.1467-8659.2006.00968.x
   Zhu XQ, 2015, VISUAL COMPUT, V31, P69, DOI 10.1007/s00371-013-0905-2
NR 27
TC 6
Z9 8
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 423
EP 432
DI 10.1002/cav.1661
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700024
DA 2024-07-18
ER

PT J
AU Wang, YZ
   Xiong, YS
   Xu, K
   Liu, D
AF Wang, Yanzhen
   Xiong, Yueshan
   Xu, Kai
   Liu, Dong
TI vKASS: a surgical procedure simulation system for arthroscopic anterior
   cruciate ligament reconstruction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE virtual surgery; arthroscopy; ACL reconstruction; procedure simulation;
   haptic feedback
AB Arthroscopic surgeries, which are widely used for anterior cruciate ligament (ACL) reconstruction, not only require advanced handeye coordination but also involve complicated surgical procedure, necessitating simulation-based training for surgeons. This paper describes a surgical procedure simulation system for the training of arthroscopic ACL reconstruction. Different from existing simulation-based training systems for basic surgical skills, this system provides a complete simulation for the entire procedure of arthroscopic ACL reconstruction, involving operations such as puncturing, probing, incision, and drilling. In this system, we employ a linear elastic finite element method and position-based dynamics for deformable modeling. Simplified vertex duplicating method and an implementation of real-time Boolean operations are proposed for the topological change of tissue models involved in the incision simulation and tunnel construction. Two specially designed force feedback models are introduced for the haptic rendering of probing and drilling operations. By using these fast and stable simulation methods, this system is able to provide real-time realistic graphical and haptic feedback to the user, making it efficient and practical for training purpose. Feedback from the surgeon trainees shows that this system is very effective in training not only for basic surgical skills but also for the complex surgical procedure. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Wang, Yanzhen] Natl Univ Def Technol, Coll Informat Syst & Management, Changsha 410073, Hunan, Peoples R China.
   [Xiong, Yueshan; Xu, Kai; Liu, Dong] Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China
RP Wang, YZ (corresponding author), Natl Univ Def Technol, Coll Informat Syst & Management, 137 Yanwachi St, Changsha 410073, Hunan, Peoples R China.
EM yanzhen.wang@gmail.com
FU Research Fund for the Doctoral Program of Higher Education
   [20104307110003]; National Science Foundation of China [60773022]
FX The research work in this paper was partially sponsored by the Research
   Fund for the Doctoral Program of Higher Education with grant number
   20104307110003 and the National Science Foundation of China with grant
   number 60773022.
CR Ackerman MJ, 1998, P IEEE, V86, P504, DOI 10.1109/5.662875
   Adams B, 2003, ACM T GRAPHIC, V22, P651, DOI 10.1145/882262.882320
   [Anonymous], 1994, P ASME WINT ANN M S, DOI DOI 10.1145/1029632.1029682
   [Anonymous], 1998, GHOST SDK VERSION 3
   [Anonymous], P 1 JOINT C COMP VIS
   Bayona S, 2009, COMPUT ANIMAT VIRT W, V20, P39, DOI 10.1002/cav.268
   Bro-Nielsen M, 1998, P IEEE, V86, P490, DOI 10.1109/5.662874
   Funk L, 2007, TAMESIDE MED J, V1, P5
   GEIGER B, 1996, NUAGES PACKAGE 3D RE
   GMV, 2009, VIRT REAL ARTHR TRAI
   Heng PA, 2004, IEEE T INF TECHNOL B, V8, P217, DOI 10.1109/TITB.2004.826720
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Mabrey Jay D, 2002, Arthroscopy, V18, pE28, DOI 10.1053/jars.2002.33790
   McCarthy AD, 1998, ST HEAL T, V50, P302
   Megali G, 2002, P 5 INT C MED IM C 2
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muller W, 1998, ST HEAL T, V50, P13
   Müller W, 2000, RADIOLOGE, V40, P290, DOI 10.1007/s001170050671
   Nevatia R., 1973, IJCAI, P641
   Taubin G., 1995, P 22 ANN C COMP GRAP
   Xu K, 2009, COMPUT GRAPH-UK, V33, P250, DOI 10.1016/j.cag.2009.03.020
NR 21
TC 7
Z9 8
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2013
VL 24
IS 1
BP 25
EP 41
DI 10.1002/cav.1434
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 089PU
UT WOS:000314923300005
DA 2024-07-18
ER

PT J
AU van Toll, WG
   Cook, AF
   Geraerts, R
AF van Toll, Wouter G.
   Cook, Atlas F.
   Geraerts, Roland
TI A navigation mesh for dynamic environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE navigation mesh; dynamic environments; medial axis; Voronoi diagram
AB Games and simulations frequently model scenarios where obstacles move, appear, and disappear in an environment. A city environment changes as new buildings and roads are constructed, and routes can become partially blocked by small obstacles many times in a typical day. This paper studies the effect of using local updates to repair only the affected regions of a navigation mesh in response to a change in the environment. The techniques are inspired by incremental methods for Voronoi diagrams. The main novelty of this paper is that we show how to maintain a 2D or 2.5D navigation mesh in an environment that contains dynamic polygonal obstacles. Experiments show that local updates are fast enough to permit real-time updates of the navigation mesh. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [van Toll, Wouter G.; Cook, Atlas F.; Geraerts, Roland] Univ Utrecht, Dept Informat & Comp Sci, NL-3584 CC Utrecht, Netherlands.
C3 Utrecht University
RP Geraerts, R (corresponding author), Univ Utrecht, Dept Informat & Comp Sci, NL-3584 CC Utrecht, Netherlands.
EM R.J.Geraerts@uu.nl
RI Geraerts, Roland/B-3859-2016
OI Geraerts, Roland/0000-0002-8161-579X
FU GATE project; Netherlands Organization for Scientific Research (NWO)
FX This research has been supported by the GATE project funded by the
   Netherlands Organization for Scientific Research (NWO).
CR [Anonymous], 1975, P 16 ANN IEEE S FDN
   De Berg M., 2008, Computational Geometry: Algorithms and Applications, V17
   de Moura Pinto F, 2011, VISUAL COMPUTER INT, V27, P463
   Devillers O., 1999, Proceedings of the Fifteenth Annual Symposium on Computational Geometry, P181, DOI 10.1145/304893.304969
   Fortune S., 1986, P 2 ANN S COMP GEOM, P313, DOI DOI 10.1145/10515.10549
   Gayle R, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3783
   Geraerts R, 2010, IEEE INT CONF ROBOT, P1997, DOI 10.1109/ROBOT.2010.5509263
   GOWDA IG, 1983, IEEE T INFORM THEORY, V29, P724, DOI 10.1109/TIT.1983.1056738
   GREEN PJ, 1978, COMPUT J, V21, P168, DOI 10.1093/comjnl/21.2.168
   Hale D.H., 2008, Proceedings of the 4th AAAI Artificial Intelligence and Interactive Digital Entertainment Conference, P173
   Held M, 2009, COMPUT AIDED DESIGN, V41, P327, DOI 10.1016/j.cad.2008.08.004
   Hoff KE, 1999, COMP GRAPH, P277, DOI 10.1145/311535.311567
   Kallmann M, 2004, IEEE INT CONF ROBOT, P4399, DOI 10.1109/ROBOT.2004.1302410
   Kallmann M., 2003, GEOMETRIC MODELLING
   Kallmann M., 2010, EUR SIGGRAPH S COMP
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Kuffner J. J.  Jr., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P995, DOI 10.1109/ROBOT.2000.844730
   Mononen Mikko, 2012, RECAST NAVIGATION
   Mostafavi MA, 2003, COMPUT GEOSCI-UK, V29, P523, DOI 10.1016/S0098-3004(03)00017-7
   Okabe A., 2000, Spatial tessellations: concepts and applications of Voronoi diagrams, V43
   Olivia R., 2011, LNCS, V7060
   Pettre J, 2005, 1 INT WORKSH CROWD S, P1
   Preparata F., 1977, MATH FDN COMPUTER SC, V53
   Rabin S., 2004, AI GAME PROGRAMMING
   ROOS T, 1992, LECT NOTES CONTR INF, V180, P102
   Snook G., 2000, Game Programming Gems
   Sud A, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P99
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van Toll W, 2011, IEEE INT C INT ROBOT, P3526, DOI 10.1109/IROS.2011.6048397
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   Wein R, 2007, COMP GEOM-THEOR APPL, V36, P66, DOI 10.1016/j.comgeo.2005.11.007
NR 32
TC 27
Z9 32
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2012
VL 23
IS 6
BP 535
EP 546
DI 10.1002/cav.1468
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 051NL
UT WOS:000312134000003
DA 2024-07-18
ER

PT J
AU Zhu, MY
   Sun, HJ
   Lan, RY
   Li, B
AF Zhu, Mingyang
   Sun, Huaijiang
   Lan, Rongyi
   Li, Bin
TI Human motion retrieval using topic model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human motion retrieval; latent Dirichlet allocation; topic motion;
   geometric features
ID CAPTURE DATA
AB Content-based human motion retrieval is important for animators with the development of motion editing and synthesis, which need to search similar motions in large databases. Obtaining text-based representation from quantization of mocap data turned out to be efficient. It becomes a fundamental step of many researches in human motion analysis. Geometric features are one of these techniques, which involve much prior knowledge and reduce data redundancy of numerical data. We describe geometric features as basic unit to define human motions (also called mo-words) and view a human motion as a generative process. Therefore, we obtain topic motions, which possess more semantic information using latent Dirichlet allocation by learning from massive training examples in order to understand motions better. We combine probabilistic model with human motion retrieval and come up with a new representation of human motions and a new retrieval framework. Our experiments demonstrate its advantages, both for understanding motions and retrieval. Copyright (c) 2011 John Wiley & Sons, Ltd.
C1 [Zhu, Mingyang; Sun, Huaijiang; Lan, Rongyi; Li, Bin] Nanjing Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Zhu, MY (corresponding author), Nanjing Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
EM zmy8475@gmail.com
CR [Anonymous], 2009, P 2009 ACM SIGGRAPH
   [Anonymous], 2009, Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games, I3D'09, DOI DOI 10.1145/1507149.1507181
   [Anonymous], 2007, DOCUMENTATION MOCAP
   Barbic J, 2004, PROC GRAPH INTERF, P185
   BEAUDOIN P, 2008, P 2008 ACM SIGGRAPH, P117
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Hu DJ, 2009, INT C MUS INF RETR I
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Russell B.C., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P1605, DOI DOI 10.1109/CVPR.2006.326
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Wu SY, 2009, VISUAL COMPUT, V25, P499, DOI 10.1007/s00371-009-0345-1
   Yu T, 2005, COMPUT ANIMAT VIRT W, V16, P273, DOI 10.1002/cav.89
   Zhang Z, 2008, THESIS MIT
NR 15
TC 3
Z9 4
U1 0
U2 7
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2012
VL 23
IS 5
BP 469
EP 476
DI 10.1002/cav.432
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 021ZW
UT WOS:000309925700003
DA 2024-07-18
ER

PT J
AU Olivier, AH
   Kulpa, R
   Pettré, J
   Crétual, A
AF Olivier, Anne-Helene
   Kulpa, Richard
   Pettre, Julien
   Cretual, Armel
TI A step-by-step modeling, analysis and annotation of locomotion
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion analysis; turn detection; velocity-curvature space; motion
   segmentation
ID TURNING STRATEGIES; MOTION
AB Annotating unlabeled motion captures plays an important role in Computer Animation for motion analysis and motion edition purposes. Locomotion is a difficult case study as all the limbs of the human body are involved whereas a low-dimensional global motion is performed. The oscillatory nature of the locomotion makes difficult the distinction between straight steps and turning ones, especially for subtle orientation changes. In this paper we propose to geometrically model the center of mass trajectory during locomotion as a C-1-continuous circular arcs sequence. Our model accurately analyzes the global motion into the velocity-curvature space. An experimental study demonstrates that an invariant law links curvature and velocity during straight walk. We finally illustrate how the resulting law can be used for annotation purposes: any unlabeled motion captured walk can be transformed into an annotated sequence of straight and turning steps. Several examples demonstrate the robustness of our approach and give comparison with classical threshold-based techniques. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Olivier, Anne-Helene] Univ Rennes 2, UFRAPS, Lab M2S, F-35044 Rennes, France.
   [Olivier, Anne-Helene; Kulpa, Richard] IRISA INRIA, Bunraku Team, Rennes, France.
C3 Universite Rennes 2; Universite de Rennes; Universite de Rennes;
   Universite Paris Saclay
RP Olivier, AH (corresponding author), Univ Rennes 2, UFRAPS, Lab M2S, Campus La Harpe,Ave Charles Tillon,CS 24414, F-35044 Rennes, France.
EM anne-helene.olivier@irisa.fr
RI Pettré, Julien/AAB-2590-2022; Olivier, Anne-Hélène/AAH-7378-2020;
   Cretual, Armel/AFM-5749-2022
OI Olivier, Anne-Hélène/0000-0002-2833-020X; Cretual,
   Armel/0000-0002-3838-1051
FU ANR
FX This research was founded by the ANR-PsiRob Locanthrope Project.
CR [Anonymous], SCA 06 P 2006 ACM SI
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Boulic R., 2004, J. Game Develop., V1, P29
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Fusco N, 2008, GAIT POSTURE, V28, P663, DOI 10.1016/j.gaitpost.2008.04.016
   Glaister BC, 2007, GAIT POSTURE, V25, P289, DOI 10.1016/j.gaitpost.2006.04.003
   Glardon P, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P292, DOI 10.1109/CGI.2004.1309224
   Hase K, 1999, J NEUROPHYSIOL, V81, P2914, DOI 10.1152/jn.1999.81.6.2914
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   KWON T., 2005, SCA 05, P29
   Kwon TS, 2007, COMPUT ANIMAT VIRT W, V18, P463, DOI 10.1002/cav.185
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   MULLER M, 2009, SCA
   Olivier AH, 2007, NEUROSCI LETT, V412, P148, DOI 10.1016/j.neulet.2006.11.005
   Park SI, 2004, COMPUT ANIMAT VIRT W, V15, P125, DOI 10.1002/cav.15
   Park SI., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. SCA2, P105, DOI DOI 10.1145/545261.545279
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   SEDGEMAN R, 1994, ADV REHABILITATION
   SHIRATORI T, 2003, MULTISENSOR FUSION I, P89
   Taylor MJD, 2005, HUM MOVEMENT SCI, V24, P558, DOI 10.1016/j.humov.2005.07.005
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
NR 22
TC 9
Z9 9
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2011
VL 22
IS 5
BP 421
EP 433
DI 10.1002/cav.377
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856HY
UT WOS:000297631000003
DA 2024-07-18
ER

PT J
AU Liu, GD
   Xu, ML
   Pan, ZG
   El Rhalibi, A
AF Liu, Gengdai
   Xu, Mingliang
   Pan, Zhigeng
   El Rhalibi, Abdennour
TI Human motion generation with multifactor models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion; multifactor; multilinear independent components analysis; tensor
AB To generate human motions with various specific attributes is a difficult task because of high dimensionality and complexity of human motions. This paper presents a novel human motion model for generating and editing motions with multiple factors. A set of motions performed by several actors with various styles was captured for constructing a well-structured motion database. Subsequently, MICA (multilinear independent component analysis) model that combines ICA and conventional multilinear framework was adopted for the construction of a multifactor model. With this model, new motions can be synthesized by interpolation and through solving optimization problems for the specific factors. Our method offers a practical solution to edit stylistic human motions in a parametric space learnt with MICA model. We demonstrated the power of our method by generating and editing sideways stepping, reaching, and striding over obstructions using different actors with various styles. The experimental results show that our method can be used for interactive stylistic motion synthesis and editing. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Liu, Gengdai] Xidian Univ, Sch Comp Sci, Xian, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Peoples R China.
   [Pan, Zhigeng] Hangzhou Normal Univ, Digital Media & HCI Res Ctr, Hangzhou, Zhejiang, Peoples R China.
   [El Rhalibi, Abdennour] Liverpool John Moores Univ, Sch Comp & Maths, Liverpool L3 5UX, Merseyside, England.
C3 Xidian University; Zhengzhou University; Hangzhou Normal University;
   Liverpool John Moores University
RP Liu, GD (corresponding author), Xidian Univ, Sch Comp Sci, Xian, Peoples R China.
EM gdliu@xidian.edu.cn; programming.game@gmail.com
OI Pan, Zhi-geng/0000-0003-0717-5850
FU NSFC [61003197]
FX This work is supported by NSFC project (grant no. 61003197). The authors
   would like to acknowledge Pengyu Zhu, Pei Lv, and Huansen Li for helping
   us with motion capture and the volunteers for being the actors. We thank
   the anonymous reviewers for their suggestions and comments, which help
   us greatly to improve this paper. We show special thanks to Jinxiang
   Chai for his useful comments and works on the final version of this
   paper.
CR [Anonymous], 2007, P 24 INT C MACHINE L, DOI DOI 10.1145/1273496.1273619
   Chuang E, 2005, ACM T GRAPHIC, V24, P331, DOI 10.1145/1061347.1061355
   De Lasa M, 2010, ACM T GRAPHICS, V29
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Ikemoto L, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477927
   Lathauwer LD, 1995, HIGHER ORDER POWER M, P10
   Lee J, 1999, COMP GRAPH, P39
   Ma W., 2010, P ACM SIGGRAPH EUR S, P21
   Min J., 2010, P 2010 ACM SIGGRAPH, DOI [10.1145/1730804.1730811, DOI 10.1145/1730804.1730811]
   Min JY, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640452
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   Mukai T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P9, DOI 10.1109/PG.2007.36
   Park SW, 2007, IEEE T SYST MAN CY B, V37, P1156, DOI 10.1109/TSMCB.2007.904575
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Shapiro A, 2006, PROC GRAPH INTERF, P33
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Tournier M, 2009, COMPUT GRAPH FORUM, V28, P355, DOI 10.1111/j.1467-8659.2009.01375.x
   Urtasun R, 2004, COMPUT GRAPH FORUM, V23, P799, DOI 10.1111/j.1467-8659.2004.00809.x
   Vasilescu MAO, 2005, PROC CVPR IEEE, P547
   Vasilescu MAO, 2002, INT C PATT RECOG, P456, DOI 10.1109/ICPR.2002.1047975
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
NR 23
TC 2
Z9 5
U1 0
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL-AUG
PY 2011
VL 22
IS 4
BP 351
EP 359
DI 10.1002/cav.424
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 825OW
UT WOS:000295290400004
DA 2024-07-18
ER

PT J
AU Van Laerhoven, T
   Di Fiore, F
   Van Haevre, W
   Van Reeth, F
AF Van Laerhoven, Tom
   Di Fiore, Fabian
   Van Haevre, William
   Van Reeth, Frank
TI Paint-on-glass animation: the fellowship of digital paint and artisanal
   control
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE animation; 2D animation; painterly animation; paint system;
   paint-on-glass
AB In this paper we deal with paint-on-glass animation, which is a technique for making animated films by pushing slow-drying paints from frame to frame directly under the camera. As artwork is continuously destroyed upon creating new frames, the animator is not able to rehearse or refine the animation afterwards. Furthermore, due to impracticable issues like how to stack up layers containing wet paint or how to overlay masks on the wet medium, one has to take both creative as technical decisions for each shot. Our approach consists of an interactive paint setup that physically simulates paint media. Together with a set of digital tools the artist is relieved from the difficult task of sustaining a constant frame-to-frame coherence while animating and is given the possibility to modify or undo earlier paint modifications. Regarding the interaction part, the artist stays in full control by employing a tangible interface. This allows artists to push pigment with their fingers, use special-purpose digital brushes, or even to employ real life tools like paper tissue. Feedback from artists confirms the real-life behaviour of stretching and smudging the paint as well as interacting with the setup, resulting in a natural and reality-based methodology. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Van Laerhoven, Tom; Di Fiore, Fabian; Van Haevre, William; Van Reeth, Frank] Hasselt Univ tUL IBBT, Expertise Ctr Digital Media, BE-3590 Diepenbeek, Belgium.
C3 Hasselt University
RP Di Fiore, F (corresponding author), Hasselt Univ tUL IBBT, Expertise Ctr Digital Media, Wetenschapspk 2, BE-3590 Diepenbeek, Belgium.
EM fabian.difiore@uhasselt.be
OI Di Fiore, Fabian/0000-0003-4908-0673; VAN REETH,
   Frank/0000-0002-3705-7807
CR Baxter B, 2001, COMP GRAPH, P461, DOI 10.1145/383259.383313
   Cao X, 2008, THIRD ANNUAL IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, PROCEEDINGS, P139
   Chu NSH, 2004, IEEE COMPUT GRAPH, V24, P76, DOI 10.1109/MCG.2004.37
   *MICR, MICR SURF
   OKAICHI N, 2008, VISUAL COMPUTER COMP, P753
   SAITO S, 1999, P 26 SIGGR, P226
   Van Laerhoven T, 2005, COMPUT ANIMAT VIRT W, V16, P429, DOI 10.1002/cav.95
   Van Laerhoven T, 2007, VISUAL COMPUT, V23, P763, DOI 10.1007/s0037l-007-0158-z
   Vandoren P, 2008, THIRD ANNUAL IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, PROCEEDINGS, P71
   Vandoren Peter., 2009, Proceedings of the ACM Conference on Interactive Tabletops and Surfaces, P53
   VANLAERHOVEN T, 2008, COMPUTER ANIMATION V, P365
NR 11
TC 1
Z9 1
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 325
EP 332
DI 10.1002/cav.406
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700029
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xiao, ZD
   Nait-Charif, H
   Zhang, JJ
AF Xiao, Zhidong
   Nait-Charif, Hammadi
   Zhang, Jian J.
TI Real time automatic skeleton and motion estimation for character
   animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion capture; motion tracking; character mapping; character animation
AB Motion capture is prevalent in the pipeline of realistic articulated character animation. To define accurate joint positions and joint orientations for the movement of a hierarchical human-like character without using a pre-defined skeleton remains a challenge for motion capture studios. In this paper, we present a method for automatically estimating and determining the topology of a hierarchical human skeleton from optical motion capture data based on the human biomechanical information. Through the use of a novel per-frame based recursive method with joint angle minimization, human skeleton mapping from optical markers and joint angle estimation are achieved in real time. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Xiao, Zhidong; Nait-Charif, Hammadi; Zhang, Jian J.] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
   [Zhang, Jian J.] Bournemouth Univ, Bournemouth Media Sch, Comp Animat Res Ctr, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University; Bournemouth University
RP Zhang, JJ (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
EM jzhang@bournemouth.ac.uk
RI Charif, Hammadi Nait/AAG-6142-2020
OI Zhang, Jian/0000-0002-7069-5771; Xiao, Zhidong/0000-0003-1977-4674
CR Abe Y., 2004, P 2004 ACM SIGGRAPHE, P173
   [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   *AUT, 2007, AUT MOT
   Bodenheimer Bobby., 1997, COMPUTER ANIMATION S, P3
   Glardon P, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P292, DOI 10.1109/CGI.2004.1309224
   Kirk AG, 2005, PROC CVPR IEEE, P782
   KOVAR L, 2003, SCA 03, P214
   LeVeau B.F., 1992, Williams and Lissner's Biomechanics of Human Motion, V3rd
   MONZANI JS, 2000, COMPUT GRAPH FORUM, V19, P11, DOI DOI 10.1111/1467-8659.00393
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   O'Brien JF, 2000, PROC GRAPH INTERF, P53
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   ROSE C, 1996, SIGGRAPH 96, P147
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Safonova A., 2005, Dans SCA '05, P171
   SILAGHI MC, 1998, CAPTECH 98 P INT WOR, P26
   Winter D., 1990, BIOMECHANICS HUMAN M
   ZHAO JM, 1994, ACM T GRAPHIC, V13, P313, DOI 10.1145/195826.195827
   ZORDAN VB, 2003, SCA 2003, P245
NR 19
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2009
VL 20
IS 5-6
SI SI
BP 523
EP 531
DI 10.1002/cav.276
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 516RI
UT WOS:000271559700005
DA 2024-07-18
ER

PT J
AU Oh, S
   Kim, Y
   Roh, BS
AF Oh, Seungtaik
   Kim, Younghee
   Roh, Byung-Seok
TI Impulse-based rigid body interaction in SPH
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE SPH; fluid; rigid body; boundary force; impulse
ID ANIMATION
AB A new boundary force is proposed to solve rigid body interaction in SPH (Smoothed Particle Hydrodynamics). The new boundary force is impulse-based rather than potential-based. The impulse is converted to a boundary force with a fundamental observation that the impulse is a momentum change which is a result of a force acting on an object during a time interval. Our new impulse-based boundary force gives more stable and accurate results in all kinds of rigid body interactions, especially in rigid-rigid interaction since our boundary force faithfully reflects the dynamic features of rigid body. With our impulse-based boundary force, SPH fluid solver is capable of full two way interaction of fluid and rigid body and it turns to be a particle-based rigid body solver if only rigid bodies are simulated without fluid. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Oh, Seungtaik] ETRI, Digital Content Res Div, Taejon 305700, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Oh, S (corresponding author), ETRI, Digital Content Res Div, Taejon 305700, South Korea.
EM stoh@etri.re.kr
RI Roh, Byungseok/AAF-6824-2019
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   [Anonymous], SIGGRAPH 2005 ACM SI
   Baraff D., 1989, Computer Graphics, V23, P223, DOI 10.1145/74334.74356
   BARAFF D, 1993, ALGORITHMICA, V10, P292, DOI 10.1007/BF01891843
   Baraff D, 2001, ACM SIGGRAPH 2001 CO
   Batty C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276502
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   BELL N, 2005, SCA 05, P77
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Carlson M., 2004, SIGGRAPH '04, P377
   Cleary PW, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239548, 10.1145/1276377.1276499]
   Desbrun M., 1996, P EUROGRAPHICS WORKS, P61
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   GIANG T, 2003, EUR IR WORKSH, P1
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Guendelman E, 2003, ACM T GRAPHIC, V22, P871, DOI 10.1145/882262.882358
   Hahn J. K., 1988, Computer Graphics, V22, P299, DOI 10.1145/378456.378530
   Hong JM, 2005, ACM T GRAPHIC, V24, P915, DOI 10.1145/1073204.1073283
   HONG JM, 2008, SIGGRAPH 08, V27, P1
   Keiser R., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P125, DOI 10.1109/PBG.2005.194073
   Klingner BM, 2006, ACM T GRAPHIC, V25, P820, DOI 10.1145/1141911.1141961
   Landau L., FLUID MECH
   Lenaerts T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360648
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   Mirtich B., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P181, DOI 10.1145/199404.199436
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   Monaghan JJ, 2003, J WATERW PORT COAST, V129, P250, DOI 10.1061/(ASCE)0733-950X(2003)129:6(250)
   MONAGHAN JJ, 1994, J COMPUT PHYS, V110, P399, DOI 10.1006/jcph.1994.1034
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Muller M., 2003, SCA, P154
   PREMOZE S, EUROGRAPHICS 2003, V22
   Robinson A, 2008, ALIMENT PHARM THER, V27, P9, DOI 10.1111/j.1365-2036.2008.03604.x
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
NR 37
TC 21
Z9 23
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 215
EP 224
DI 10.1002/cav.290
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700015
DA 2024-07-18
ER

PT J
AU Pan, JJ
   Yang, XS
   Xie, X
   Willis, P
   Zhang, JJ
AF Pan, Junjun
   Yang, Xiaosong
   Xie, Xin
   Willis, Philip
   Zhang, Jian J.
TI Automatic rigging for animation characters with 3D silhouette
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE rigging; curve skeleton; animation skeleton; medial axis; 3D silhouette
AB Animating an articulated 3D character requires the specification of its interior skeleton structure which defines how the skin surface is deformed during animation. Currently this task is to a large extent accomplished manually, which consumes a large amount of animators' time. This paper presents an automatic rigging method making use of a new geometry entity called the 3D silhouette. The first step is to extract a coarse 3D curve skeleton and some skeletal joints of a character. This curve skeleton is then refilled with a perpendicular silhouette. According to the connectivity of the skeletal joints, the hierarchical animation skeleton is finally constructed. By avoiding complicated computation such as voxelization and pruning, this method is simple and efficient, much faster than existing methods. It proves very useful for quick animation production, with applications including games design and prototype graphical systems. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Pan, Junjun; Yang, Xiaosong; Zhang, Jian J.] Bournemouth Univ, Media Sch, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
   [Willis, Philip] Univ Bath, Media Technol Res Ctr, Bath BA2 7AY, Avon, England.
   [Willis, Philip] Univ Bath, Dept Comp Sci, Bath BA2 7AY, Avon, England.
C3 Bournemouth University; University of Bath; University of Bath
RP Zhang, JJ (corresponding author), Bournemouth Univ, Media Sch, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
EM jzhang@bournemouth.ac.uk
RI chen, jia/A-3560-2011; Pan, Junjun/A-1316-2013
OI Yang, Xiaosong/0000-0003-3815-0584
CR AU K, 2008, P ACM SIGGRAPH, P124
   AUJAY G, 2007, ACM SIGGRAPH EG S CO, P144
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   CORNEA D, 2006, IEEE T VISUALIZATION, V6, P81
   DEY K, 2006, P EUR S GEOM, P143
   GRAFT L, 2002, ALIAS WAVEFRONT
   Grigorishin T, 1998, PATTERN ANAL APPL, V1, P163, DOI 10.1007/BF01259366
   IGARASHI T, P ACM SIGGRAPH 99, P212
   JAMES DL, P ACM SIGGRAPH 05, P312
   Jarvis R. A., 1973, Information Processing Letters, V2, P18, DOI 10.1016/0020-0190(73)90020-3
   KATZ S, 2005, VISUAL COMPUT, V10, P37
   Liu PC, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P409
   SABRY M, 2005, P CVPR, P458
   SHILANE P, 2004, SHAPE MODELLING INT, P191
   TIERNY J, 2006, VISUAL COMPUT, V10, P120
   Wade L, 2002, VISUAL COMPUT, V18, P97, DOI 10.1007/s003710100139
   WANG Y, 2008, IEEE T VISUALIZATION, V5, P196
   Wu FC, 2006, VISUAL COMPUT, V22, P117, DOI 10.1007/s00371-005-0357-4
   Yuksel Can, 2007, Symposium on Geometry Processing, P153, DOI DOI 10.2312/SGP/SGP07/153-162
NR 19
TC 19
Z9 22
U1 2
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 121
EP 131
DI 10.1002/cav.284
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700006
DA 2024-07-18
ER

PT J
AU Yang, WW
   Feng, JQ
AF Yang, Wenwu
   Feng, Jieqing
TI 2D shape manipulation via topology-aware rigid grid
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE shape manipulation; topology-aware; tunable stiffness; nonlinear
   optimization
ID DEFORMATION
AB This paper presents a new method which allows user to manipulate a two-dimensional shape in an intutive and flexible way. The shape is discretized as a regular grid. User places handles on the grid and manipulates the shape by moving the handles to the desired positions. To meet the constraints of the users manipulation, the grid is then deformed in an as-rigid-as-possible way. However, this straight forward approach tends to produce unnatural deformations when the grid resolution is not high enough to capture the topological structure of the shape. In the proposed method, the regular grid is trimmed and only the cells that are inside the fatty regions of the shape tire preserved, namely "interior grid." When user manipulates the shape, the interior grid and the shape boundary curve tire deformed With minimum distortions. To make the deformations of the interior grid and the boundary curve consistent, a junction energy is introduced. In this Way, the unnatural deformation effects could be effectively removed and the physically plausible results can be obtained. Meanwhile, the proposed approach provides user an intuitive and simple way to adjust the shape global and local stiffnesses. The deformation is formulated as an energy minimization problem. The energy function is ion-quadratic and could be efficiently solved using an iterative solver with the fast summation technique that exploits the interior grid and boundary curve regularities. In addition, the method could be easily extended to manipulate curves and stick figures. Experimental results demonstrate the capability and flexibility of the new method. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Yang, Wenwu; Feng, Jieqing] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Feng, JQ (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM wwyang@cad.zju.edu.cn; jqfeng@cad.zju.edu.cn
CR [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Botsch M, 2005, COMPUT GRAPH FORUM, V24, P611, DOI 10.1111/j.1467-8659.2005.00886.x
   Botsch M, 2007, COMPUT GRAPH FORUM, V26, P339, DOI 10.1111/j.1467-8659.2007.01056.x
   Davis TA, 2004, ACM T MATH SOFTWARE, V30, P196, DOI 10.1145/992200.992206
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   JAMES DL, 2004, SIGGRAPH 04, P38
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Rivers AR, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239533
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Schiwietz T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P27, DOI 10.1109/PG.2007.44
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   SORKINE O, 2007, SGP 07, P109
   Steinemann D., 2008, P 2008 ACM SIGGRAPHE, P87
   Weng YL, 2006, VISUAL COMPUT, V22, P653, DOI 10.1007/s00371-006-0054-y
   Yang WW, 2008, VISUAL COMPUT, V24, P495, DOI 10.1007/s00371-008-0230-3
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
NR 17
TC 4
Z9 4
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 175
EP 184
DI 10.1002/cav.285
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700011
DA 2024-07-18
ER

PT J
AU Arellano, D
   Varona, J
   Perales, FJ
AF Arellano, Diana
   Varona, Javier
   Perales, Francisco J.
TI Generation and visualization of emotional states in virtual characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE emotion and personality; virtual humans; facial animation
ID PERSONALITY; MODEL
AB This paper presents art affective model that determines the emotional state of a character according to the personality traits and the experienced emotions. We consider an emotional state as tire layer between personality and emotion. The proposed affective model offers a mapping between emotions and emotional states. To evidence emotional states of a virtual character; We can attribute them facial expressions based oil their associated emotions. Facial expressions for intermediate emotions are generated automatically from expressions for universal emotions. The experiments show coherent emotional states produced by a simulated story. They also present how tire corresponding emotions were represented through dynamic and static facial expressions. Finally, the obtained results demonstrate tire satisfactory recognition by a group of people unfamiliar with tire work described. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Arellano, Diana] Univ Illes Balears, Dept Ciencies Matemat & Informat, Unitat Graf & Visio Ordinador & Intel Ligencia Ar, Palma de Mallorca 07122, Spain.
   Univ Illes Balears, Dept Math & Comp Sci, Area Comp Graph & Comp Vis, Palma de Mallorca 07122, Spain.
   [Perales, Francisco J.] Univ Illes Balears, HU MODAN European Project 2001 32202, Palma de Mallorca 07122, Spain.
C3 Universitat de les Illes Balears; Universitat de les Illes Balears;
   Universitat de les Illes Balears
RP Arellano, D (corresponding author), Univ Illes Balears, Dept Ciencies Matemat & Informat, Unitat Graf & Visio Ordinador & Intel Ligencia Ar, Carretera Valldemossa Km 7-5, Palma de Mallorca 07122, Spain.
EM diana.arellano@uib.es
RI perales, francisco/G-3084-2015; Varona, Javier/X-5831-2018
OI perales, francisco/0000-0002-9872-3172; Varona,
   Javier/0000-0002-0287-0486
CR Abrantes GA, 1999, IEEE T CIRC SYST VID, V9, P290, DOI 10.1109/76.752096
   [Anonymous], 2005, INT JOINT C AUTONOMO, DOI DOI 10.1145/1082473.1082478
   Cerezo E, 2007, LECT NOTES COMPUT SC, V4478, P40
   Egges A, 2004, COMPUT ANIMAT VIRT W, V15, P1, DOI 10.1002/cav.3
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P., 1982, EMOTION HUMAN FACE
   El-Nasr MS, 2000, AUTON AGENT MULTI-AG, V3, P219, DOI 10.1023/A:1010030809960
   Gebhard P, 2006, LECT NOTES ARTIF INT, V4133, P343
   KSHIRSAGAR S, 2002, SMARTGRAPH 02, P107
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Raouzaiou A, 2002, EURASIP J APPL SIG P, V2002, P1021, DOI 10.1155/S1110865702206149
   Russell J.A., 1989, Emotion: Theory, Research, and Experience, V4, P83, DOI DOI 10.1016/B978-0-12-558704-4.50010-4
   Su WP, 2007, IEEE T VIS COMPUT GR, V13, P281, DOI 10.1109/TVCG.2007.44
   VINAYAGAMOORTHY V, 2006, EUROGRAPHICS STATE A
   Whissell C. M., 1989, MEASUREMENT EMOTIONS
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
NR 17
TC 13
Z9 16
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 259
EP 270
DI 10.1002/cav.234
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200010
DA 2024-07-18
ER

PT J
AU Xiao, CX
   Liu, S
   Fu, HB
   Lin, CC
   Song, CF
   Huang, ZY
   He, FZ
   Peng, QS
AF Xiao, Chunxia
   Liu, Shu
   Fu, Hongbo
   Lin, Chengchun
   Song, Chengfang
   Huang, Zhiyong
   He, Fazhi
   Peng, Qunsheng
TI Video completion and synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE belief propagation; video completion; patches similarity
ID IMAGE COMPLETION; MOTION
AB This paper presents a new exemplar-based framework for video completion, allowing aesthetically pleasing completion of large space-time holes. We regard video completion as a discrete global optimization on a 3D graph embedded in the space-time video volume. We introduce a new objective function which enforces global spatio-temporal consistency among patches that fill the hole and surrounding it, in terms of both color similarity and motion similarity. The optimization is solved by a novel algorithm, called weighted priority belief propagation (BP), which alleviates the problems of slow convergence and intolerable storage size when using the standard BP. This objective function can also handle video text-tire synthesis by extending an input video texture to a laser texture region. Experiments on a wide variety of video examples With complex dynamic scenes demonstrate the advantages of our method over existing techniques: salient structures and motion information are much better restored. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Xiao, Chunxia; He, Fazhi] Wuhan Univ, Comp Sch, Wuhan, Peoples R China.
C3 Wuhan University
RP Xiao, CX (corresponding author), Wuhan Univ, Comp Sch, Wuhan, Peoples R China.
EM cxxiao@whu.edu.cn
RI He, Fazhi/Q-3691-2018
OI FU, Hongbo/0000-0002-0284-726X
CR [Anonymous], 1999, ICCV
   [Anonymous], INT C COMP VIS
   [Anonymous], 1999, INTEL CORPORATION MI
   Bar-Joseph Z, 2001, IEEE T VIS COMPUT GR, V7, P120, DOI 10.1109/2945.928165
   BERTALMIO M, 2001, CVPR01, P355
   Cheung V, 2005, PROC CVPR IEEE, P42
   CRIMINISI A, 2003, CVPR 2003
   Drori I, 2003, ACM T GRAPHIC, V22, P303, DOI 10.1145/882262.882267
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   FROLOVA D, 2006, ADV TOPICS COMPUTER
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Jia JY, 2006, IEEE T PATTERN ANAL, V28, P832, DOI 10.1109/TPAMI.2006.108
   Jia YT, 2005, VISUAL COMPUT, V21, P601, DOI 10.1007/s00371-005-0313-3
   Kokaram A, 2004, J MATH IMAGING VIS, V20, P163, DOI 10.1023/B:JMIV.0000011325.36760.1e
   Kokaram AC, 2005, IEE P-VIS IMAGE SIGN, V152, P407, DOI 10.1049/ip-vis:20045152
   KOMODAKIS N, 2006, CVPR 06, P442
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Patwardhan K., 2005, P IEEE INT C IMAGE P, V2, P69
   Patwardhan KA, 2007, IEEE T IMAGE PROCESS, V16, P545, DOI 10.1109/TIP.2006.888343
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Shiratori T., 2006, Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P411
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
NR 27
TC 5
Z9 6
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 341
EP 353
DI 10.1002/cav.249
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200017
DA 2024-07-18
ER

PT J
AU Hong, SM
   Simpson, B
   Baranoski, GVG
AF Hong, SM
   Simpson, B
   Baranoski, GVG
TI Interactive venation-based leaf shape modeling
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE venation; leaf; skeleton; interpolation
AB We describe a representation for tree leaves and an interactive modeling system for creating realistic close-up images of leaf clusters. The planar outline of the leaf and the larger members of its venation system are strong factors in the recognition of plant species and as such are essential to realistic imaging. The larger veins also play a major biological role in determining the leaf surface shape and it is this role that we mimic in the shape modeling discussed in this paper. The proposed representation uses a model of a leaf consisting of a three-dimensional skeleton formed by its larger veins and a surface membrane representing the leaf lamina that spans the void between the veins. The veins play two roles. They can be interactively modified to create the 3-D shape of the leaf model. They also provide for realistic light and shadow effects when rendered as generalized cylinders using measured width parameters. The representation consists of two coupled data structures, a tree data structure of veins for the leaf skeleton and an unstructured triangular mesh for the leaf membrane. The skeleton is modified by the user of the modeling system, and the membrane mesh is a surface mesh that follows the skeleton shape computed using harmonic interpolation. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Univ Waterloo, Comp Sci Lab, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Univ Waterloo, Comp Sci Lab, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
EM smhong@cs.uwaterloo.ca
RI Baranoski, Gladimir/A-1944-2008
CR Baranoski G., 2004, LIGHT INTERACTION PL
   BLANCHETTE J, 2004, CPLUSPLUS GUI PROGRA
   Bloomenthal J., 1985, Computer Graphics, V19, P305, DOI 10.1145/325165.325249
   Bohn S, 2002, PHYS REV E, V65, DOI 10.1103/PhysRevE.65.061914
   FORD BJ, 1986, J BIOL EDUC, V20, P251, DOI 10.1080/00219266.1986.9654834
   George P., 1998, DELAUNAY TRIANGULATI
   Gold C., 1999, Proceedings of the Fifteenth Annual Symposium on Computational Geometry, P189, DOI 10.1145/304893.304971
   HICKEY LJ, 1979, ANAT DICOTYLEDONS, V1
   Jaquemoud S., 2001, PROC 8 INT S PHYS ME, P223
   LETNIOWSKI FW, 1992, SIAM J SCI STAT COMP, V13, P765, DOI 10.1137/0913045
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Mündermann L, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P60, DOI 10.1109/CGI.2003.1214448
   *PERS VIS PTY LTD, 2004, PERS VIS TM RAYTR CO
   Prusinkiewicz P, 2001, COMP GRAPH, P289, DOI 10.1145/383259.383291
   Roth-Nebelsick A, 2001, ANN BOT-LONDON, V87, P553, DOI 10.1006/anbo.2001.1391
   RUPPERT J, 1995, J ALGORITHM, V18, P548, DOI 10.1006/jagm.1995.1021
   Shewchuk J., 1996, First Workshop on Applied Computational Geometry, P124
NR 17
TC 15
Z9 25
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 415
EP 427
DI 10.1002/cav.88
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000025
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jin, XG
   Liu, SJ
   Wang, CCL
   Feng, JQ
   Sun, HQ
AF Jin, XG
   Liu, SJ
   Wang, CCL
   Feng, JQ
   Sun, HQ
TI Blob-based liquid morphing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE 3D morphing; blobby object; medial axis sphere-tree; cellular matching;
   hierarchical matching
ID IMPLICIT SURFACES
AB In this paper, we propose a novel practical method for blob-based liquid 3D morphing. Firstly, blobby objects are employed to approximate a given polygonal surface. The primitives in the medial axis sphere-tree of a polygonal model are utilized as initial blobs - this greatly improves the robustness and efficiency of the blob-based approximation. Secondly, we establish the blob correspondences between two models by sphere cellular matching and hierarchical matching. Finally, we interpolate the parameters of the implicit representation to get the intermediate shapes. Experiments show our method can produce visually pleasing liquid morphing effects. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM jin@cad.zju.edu.cn
RI Liu, Shengjun/AAI-8456-2020; Wang, Charlie C. L./B-3730-2010
OI Wang, Charlie C. L./0000-0003-4406-8480
CR [Anonymous], 1997, Introduction to Implicit Surfaces
   BITTAR E, 1995, COMPUT GRAPH FORUM, V14, pC457, DOI 10.1111/j.1467-8659.1995.cgf143_0457.x
   Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290
   Bloomenthal J, 1999, SHAPE MODELING INTERNATIONAL '99 - INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P44, DOI 10.1109/SMA.1999.749322
   Bradshaw G, 2004, ACM T GRAPHIC, V23, P1, DOI 10.1145/966131.966132
   Cohen-Or D, 1998, ACM T GRAPHIC, V17, P116, DOI 10.1145/274363.274366
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Frisken SF, 2000, COMP GRAPH, P249, DOI 10.1145/344779.344899
   Galin E, 1996, COMPUT GRAPH FORUM, V15, pC143, DOI 10.1111/1467-8659.1530143
   MURAKI S, 1991, COMP GRAPH, V25, P227, DOI 10.1145/127719.122743
   Nishimura H., 1985, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ68D, P718
   Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293
   Pasko Alexander., 1995, Implicit Surfaces, volume 95, P97
   PAYNE BA, 1992, IEEE COMPUT GRAPH, V12, P65, DOI 10.1109/38.135885
   Press W. H., 1988, Numerical Recipes
   RANJAN V, 1995, TR9530 U BRIT COL DE
   Shen C, 2004, ACM T GRAPHIC, V23, P896, DOI 10.1145/1015706.1015816
   Sramek M, 1999, IEEE T VIS COMPUT GR, V5, P251, DOI 10.1109/2945.795216
   Treece G, 2001, VISUAL COMPUT, V17, P397, DOI 10.1007/s003710100113
   Tsingos N., 1995, COMPUTER GRAPHICS IN, V5, P3
   Turk G, 2002, ACM T GRAPHIC, V21, P855, DOI 10.1145/571647.571650
   TURK G, 1995, P SIGGRAPH 99 LOS AN, P335
   Wyvill B., 1986, Visual Computer, V2, P235, DOI 10.1007/BF01900347
   Wyvill B., 1993, MODELING VISUALIZING
   WYVILL B, 1990, MODELING ANIMATING I
   Wyvill G., 1986, Visual Computer, V2, P227, DOI 10.1007/BF01900346
   Yngve G, 2002, IEEE T VIS COMPUT GR, V8, P346, DOI 10.1109/TVCG.2002.1044520
NR 28
TC 6
Z9 10
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 391
EP 403
DI 10.1002/cav.84
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000023
DA 2024-07-18
ER

PT J
AU Kang, BK
   Ihm, I
   Bajaj, C
AF Kang, BK
   Ihm, I
   Bajaj, C
TI Extending the photon mapping method for realistic rendering of hot
   gaseous fluids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE rendering; gaseous fluids; incandescence; blackbody radiation; photon
   mapping; physically based fluid animation
AB With the increased sophistication and use of heated gas, fire, and explosion simulations in computer graphics applications, there is a corresponding impetus to improve the visual realism in the rendering of such simulated phenomena. In visualizing these turbulent fluids, an appropriate incorporation of their incandescent properties into the rendering significantly enhances the realism of visual effects. In this paper, we effectively synthesize the light emission phenomena of hot gaseous fluids by extending the photon mapping global illumination method. In particular, we add two new photon maps to capture the thermal radiation effects. First, we define an emission photon map to store the photons emitted within hot gaseous fluids. Second, we utilize additional flash and flash reflection photon maps, which are effective in creating a visual effect of light that intensively and instantly propagates outside hot gaseous fluids, visually capturing shock waves. Our current technique, while based on the theory of blackbody radiation, is parameterized to enable an animator to generate a wide range of visual effects with fairly intuitive user control. We demonstrate the effectiveness of our new rendering technique and user-controlled generation of visual effects with several example pictures and animations. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Sogang Univ, Dept Comp Sci, Seoul, South Korea.
   Univ Texas, Austin, TX 78712 USA.
C3 Sogang University; University of Texas System; University of Texas
   Austin
RP Ihm, I (corresponding author), Sogang Univ, Dept Comp Sci, 1 Shinsu Dong, Seoul, South Korea.
EM ihm@sogang.ac.kr
CR [Anonymous], 2001, THERMAL RAD HEAT TRA
   Beaudoin P., 2001, P GRAPH INT, P159, DOI [10.5555/780986.781006., DOI 10.5555/780986.781006]
   Chandrasekhar Subrahmanyan., RAD TRANSFER
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Foster Nick., 1997, P 24 ANN C COMP GRAP, P181
   Hasinoff SW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1184
   Henyey LG, 1941, ASTROPHYS J, V93, P70, DOI 10.1086/144246
   Ihm Insung., 2004, Proceedings of the 2004 ACM SIGGRAPH/ Eurographics symposium on Computer animation, SCA '04, P203
   Jensen HW., 2001, REALISTIC IMAGE SYNT, DOI [10.1201/9780429294907, DOI 10.1201/9780429294907]
   JENSEN HW, 1998, P SIGGRAPH 98, P311, DOI DOI 10.1145/280814.280925
   Lamorlette A, 2002, ACM T GRAPHIC, V21, P729, DOI 10.1145/566570.566644
   Mazarak O, 1999, PROC GRAPH INTERF, P211
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   MOSHIER SL, 1999, UNPUB EXPRESSIONS IN
   *NASA, 2005, DEEP IMP SMASH SUCC
   Neff M, 1999, PROC GRAPH INTERF, P193
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   PAVICIC MJ, 1990, GRAPHICS GEMS, V1, P144
   PEREZ F, 1997, P 8 EUR WORKSH REND, P309
   Pharr M, 2000, COMP GRAPH, P75, DOI 10.1145/344779.344824
   Pighin Frederic., 2004, SCA'04: Proceedings ofthe 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P223, DOI 10.1145/1028523.1028552
   Premo*e S., 2004, P EUR S REND
   Rasmussen N, 2003, ACM T GRAPHIC, V22, P703, DOI 10.1145/882262.882335
   Serway R. A., MODERN PHYS
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam Jos., 1995, Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, SIGGRAPH '95, P129
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Wei XM, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P227, DOI 10.1109/VISUAL.2002.1183779
   Yngve GD, 2000, COMP GRAPH, P29, DOI 10.1145/344779.344801
NR 31
TC 3
Z9 3
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 353
EP 363
DI 10.1002/cav.94
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000020
DA 2024-07-18
ER

PT J
AU Komura, T
   Ho, ESL
   Lau, RWH
AF Komura, T
   Ho, ESL
   Lau, RWH
TI Animating reactive motion using momentum-based inverse kinematics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE computer animation; inverse kinematics; real-time animation
AB Interactive generation of reactive motions for virtual humans as they are hit, pushed and pulled are very important to many applications, such as computer games. In this paper, we propose a new method to simulate reactive motions during arbitrary bipedal activities, such as standing, walking or running. It is based on momentum based inverse kinematics and motion blending. When generating the animation, the user first imports the primary motion to which the perturbation is to be applied to. According to the condition of the impact, the system selects a reactive motion from the database of pre-captured stepping and reactive motions. It then blends the selected motion into the primary motion using momentum-based inverse kinematics. Since the reactive motions can be edited in real-time, the criteria for motion search can be much relaxed than previous methods, and therefore, the computational cost for motion search can be reduced. Using our method, it is possible to generate reactive motions by applying external perturbations to the characters at arbitrary moment while they are performing some actions. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 City Univ Hong Kong, Dept Comp Engn & Informat Technol, Kowloon, Hong Kong, Peoples R China.
   City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong; City University of Hong Kong
RP City Univ Hong Kong, Dept Comp Sci, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
EM taku@ieee.org
RI Ho, Edmond S. L./JDW-1835-2023
OI Ho, Edmond S. L./0000-0001-5862-106X; LAU, Rynson W
   H/0000-0002-8957-8129
CR Ahokas H., 2004, On the evolution, spread and names of rutabaga, DOI 10.1145/1077534.1077542
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   KAJITA S, 2002, P IEEE INT C ROB AUT
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   MANDEL M, 2004, THESIS CMU
   Oshita M, 2001, COMPUT GRAPH FORUM, V20, pC192, DOI 10.1111/1467-8659.00512
   RAIBERT MH, 1986, COMMUN ACM, V29, P499, DOI 10.1145/5948.5950
   ZORDAN V, 2002, P ACM COMP AN
   Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249
NR 10
TC 21
Z9 43
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 213
EP 223
DI 10.1002/cav.101
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000008
DA 2024-07-18
ER

PT J
AU Müller, M
   Schirm, S
   Teschner, M
   Heidelberger, B
   Gross, M
AF Müller, M
   Schirm, S
   Teschner, M
   Heidelberger, B
   Gross, M
TI Interaction of fluids with deformable solids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE smoothed particle hydrodynamics (SPH); finite element method (FEM);
   solid-fluid interaction
AB In this paper, we present a method for simulating the interaction of fluids with deformable solids. The method is designed for the use in interactive systems such as virtual surgery simulators where the real-time interplay of liquids and surrounding tissue is important. In computer graphics, a variety of techniques have been proposed to model liquids and deformable objects at interactive rates. As important as the plausible animation of these substances is the fast and stable modeling of their interaction. The method we describe in this paper models the exchange of momentum between Lagrangian particle-based fluid models and solids represented by polygonal meshes. To model the solid-fluid interaction we use virtual boundary particles. They are placed on the surface of the solid objects according to Gaussian quadrature rules allowing the computation of smooth interaction potentials that yield stable simulations. We demonstrate our approach in an interactive simulation environment for fluids and deformable solids. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Swiss Fed Inst Technol, Comp Graph Lab, CH-8092 Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Swiss Fed Inst Technol, Comp Graph Lab, Haldeneggsteig 4, CH-8092 Zurich, Switzerland.
EM muellerm@inf.ethz.ch
OI Gross, Markus/0009-0003-9324-779X
CR Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290
   BLOOMENTHAL J, 1995, THESIS U CALGARY CAN
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Chung T.J., 1996, APPL CONTINUUM MECH
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   Desbrun M., 1999, Space-Time Adaptive Simulation of Highly Deformable Substances
   DESBRUN M, 1996, 6 EUR WORKSH COMP AN, P61
   DESBRUN M., 1999, GRAPHICS INTERFACE 9
   Desbrun M., 1999, 3829 INRIA
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Génevaux O, 2003, PROC GRAPH INTERF, P31
   GENEVAUX O, 2003, GRAPHICS INTERFACE
   Grinspun E, 2002, ACM T GRAPHIC, V21, P281, DOI 10.1145/566570.566578
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   Monaghan J.J., 1994, ASME S COMPUTATIONAL
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   MONAGHAN JJ, 1994, ASME S COMP METH FLU
   Muller M., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, P154
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   OBRIEN JF, 1999, P SIGGRAPH 1999, P287
   Pozrikidis C., 1998, NUMERICAL COMPUTATIO
   PREMOZE S, 2003, EUROGRAPHICS, V22, P401
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   SHERSTYUK A, 1998, IMPLICIT SURFACES 97, P145
   Stam J., 1999, The Proceedings of SIGGRAPH, P121, DOI DOI 10.1145/311535.311548
   Stora D, 1999, PROC GRAPH INTERF, P203
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47
NR 30
TC 129
Z9 163
U1 2
U2 35
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 159
EP 171
DI 10.1002/cav.18
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700005
DA 2024-07-18
ER

PT J
AU Li, H
   Dai, J
   Zeng, R
   Bai, JX
   Chen, ZM
   Pan, JJ
AF Li, Hao
   Dai, Ju
   Zeng, Rui
   Bai, Junxuan
   Chen, Zhangmeng
   Pan, Junjun
TI Foot-constrained spatial-temporal transformer for keyframe-based complex
   motion synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE constraint embedding; foot constraint; foot sliding; motion transition;
   transformer
AB Keyframe-based motion synthesis holds significant effects in games and movies. Existing methods for complex motion synthesis often require secondary post-processing to eliminate foot sliding to yield satisfied motions. In this paper, we analyze the cause of the sliding issue attributed to the mismatch between root trajectory and motion postures. To address the problem, we propose a novel end-to-end Spatial-Temporal transformer network conditioned on foot contact information for high-quality keyframe-based motion synthesis. Specifically, our model mainly compromises a spatial-temporal transformer encoder and two decoders to learn motion sequence features and predict motion postures and foot contact states. A novel constrained embedding, which consists of keyframes and foot contact constraints, is incorporated into the model to facilitate network learning from diversified control knowledge. To generate matched root trajectory with motion postures, we design a differentiable root trajectory reconstruction algorithm to construct root trajectory based on the decoder outputs. Qualitative and quantitative experiments on the public LaFAN1, Dance, and Martial Arts datasets demonstrate the superiority of our method in generating high-quality complex motions compared with state-of-the-arts.
   Pipeline of complex motion generation based onkeyframes and foot constraints. The postures marked in pink are the keyframes, and the postures marked in grey are the synthesized frames.image
C1 [Li, Hao; Zeng, Rui; Chen, Zhangmeng; Pan, Junjun] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Li, Hao; Dai, Ju; Zeng, Rui; Chen, Zhangmeng; Pan, Junjun] Peng Cheng Lab, Dept Math & Theories, Shenzhen, Peoples R China.
   [Bai, Junxuan] Capital Univ Phys Educ & Sports, Inst Artificial Intelligence Sports, Beijing, Peoples R China.
   [Dai, Ju] Peng Cheng Lab, Shenzhen, Peoples R China.
   [Pan, Junjun] Beihang Univ, Beijing, Peoples R China.
C3 Beihang University; Peng Cheng Laboratory; CAPITAL UNIVERSITY OF
   PHYSICAL EDUCATION AND SPORTS; Peng Cheng Laboratory; Beihang University
RP Dai, J (corresponding author), Peng Cheng Lab, Shenzhen, Peoples R China.; Pan, JJ (corresponding author), Beihang Univ, Beijing, Peoples R China.
EM daij@pcl.ac.cn; pan_junjun@buaa.edu.cn
RI Pan, Junjun/A-1316-2013; Bai, Junxuan/P-7282-2018
OI Bai, Junxuan/0000-0002-7941-0584; Dai, Ju/0000-0002-9397-8539
FU This research is supported by National Key Ramp;D Program of China (No.
   2022ZD0115902) and National Natural Science Foundation of China (Nos.
   62102208, 62272017, U20A20195, 62172437). Young Elite Scientists
   Sponsorship Program by BAST (No. BYESS2023382). [2022ZD0115902];
   National Key Ramp;D Program of China [62102208, 62272017, U20A20195,
   62172437]; National Natural Science Foundation of China [BYESS2023382];
   Young Elite Scientists Sponsorship Program by BAST
FX This research is supported by National Key R&D Program of China (No.
   2022ZD0115902) and National Natural Science Foundation of China (Nos.
   62102208, 62272017, U20A20195, 62172437). Young Elite Scientists
   Sponsorship Program by BAST (No. BYESS2023382).
CR Aristidou A., ACM SIGGRAPH EUR S C
   Beaudoin P., 2008, ACM SIGGRAPH EUR S C
   Bergamin K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356536
   Chen K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459932
   Duan Y., AAAI C ART INT ASS A, P4459
   Gopalakrishnan A, 2019, PROC CVPR IEEE, P12108, DOI 10.1109/CVPR.2019.01239
   Harvey FG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392480
   Harvey FG, 2018, SA'18: SIGGRAPH ASIA 2018 TECHNICAL BRIEFS, DOI 10.1145/3283254.3283277
   Henter GE, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417836
   Holden D., 2015, SIGGRAPH AS TECHN BR
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Kaufmann M, 2020, INT CONF 3D VISION, P918, DOI 10.1109/3DV50981.2020.00102
   Kenwright B., 2012, J GRAPHICS TOOLS, V16, P177, DOI DOI 10.1080/2165347X.2013.823362
   Kovar L., 2002, ACM SIGGRAPH EUR S C
   Lee K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275071
   Lee M, 2013, MULTIMED TOOLS APPL, V62, P895, DOI 10.1007/s11042-012-1288-5
   Leeney M, 2009, INT J COMPUT MATH, V86, P79, DOI 10.1080/00207160801923064
   Lehrmann AM, 2014, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2014.171
   Li PZ, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530157
   Lyard E, 2007, VISUAL COMPUT, V23, P689, DOI 10.1007/s00371-007-0135-6
   Meng PF, 2018, INT CONF LIGHTN PROT
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Pan JJ, 2021, COMPUT GRAPH FORUM, V40, P71, DOI 10.1111/cgf.14402
   Prazak M., 2011, ACM SIGGRAPH EUR S C
   Qin J, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555454
   Tang X., 2022, ACM T GRAPHIC, V41, p137:1
   Wang H, 2021, IEEE T VIS COMPUT GR, V27, P216, DOI 10.1109/TVCG.2019.2936810
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Wang Jack M., 2005, Gaussian process dynamical models for human motion
   Wang ZY, 2021, IEEE T VIS COMPUT GR, V27, P14, DOI 10.1109/TVCG.2019.2938520
   Wei PC, 2020, NEURAL COMPUT APPL, V32, P1813, DOI 10.1007/s00521-020-04739-4
   Xiao YP, 2020, COMPUT VIS MEDIA, V6, P113, DOI 10.1007/s41095-020-0174-8
   Xu YF, 2022, COMPUT VIS MEDIA, V8, P33, DOI 10.1007/s41095-021-0247-3
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
   Zheng Y, 2021, IEEE IC COMP COM NET, DOI 10.1109/ICCCN52240.2021.9522282
NR 36
TC 0
Z9 0
U1 2
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2217
EA SEP 2023
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NX4V2
UT WOS:001077510600001
DA 2024-07-18
ER

PT J
AU Han, B
   Yao, C
   Wang, XK
   Chang, J
   Ban, XJ
AF Han, Bing
   Yao, Chao
   Wang, Xiaokun
   Chang, Jian
   Ban, Xiaojuan
TI HandDGCL: Two-hand 3D reconstruction based disturbing graph contrastive
   learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE graph contrastive learning; hand pose estimation; hand shape
   reconstruction
AB Virtual reality (VR) and augmented reality (AR) applications are becoming increasingly prevalent. However, constructing realistic 3D hands, especially when two hands are interacting, from a single RGB image remains a major challenge due to severe mutual occlusion and the enormous diversity of hand poses. In this article, we propose a disturbing graph contrastive learning strategy for two-hand 3D reconstruction. This involves a graph disturbance network designed to generate graph feature pairs to enhance the consistency of the two-hand pose features. A contrastive learning module leverages high-quality generative features for a strong feature expression. We further propose a similarity distinguish method to divide positive and negative features for accelerating the model convergence. Additionally, a multi-term loss is designed to balance the relation among the hand pose, the visual scale and the viewpoint position. Our model has achieved state-of-the-art results in the InterHand2.6M benchmark. Ablation studies show the model's great ability to correct unreasonable hand movements. In subjective assessments, our graph disturbance learning method significantly improves the construction of realistic 3D hands, especially when two hands are interacting.
C1 [Han, Bing; Ban, Xiaojuan] Univ Sci & Technol Beijing, Inst Artificial Intelligence, Beijing Adv Innovat Ctr Mat Genome Engn, Beijing, Peoples R China.
   [Han, Bing] Univ Sci & Technol Beijing, Shunde Innovat Sch, Foshan, Peoples R China.
   [Yao, Chao; Wang, Xiaokun] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing, Peoples R China.
   [Wang, Xiaokun] Univ Sci & Technol Beijing, Sch Intelligence Sci & Technol, Beijing, Peoples R China.
   [Chang, Jian] Bournemouth Univ, Poole, Dorset, England.
   [Ban, Xiaojuan] Univ Sci & Technol Beijing, Key Lab Intelligent Bionic Unmanned Syst, Minist Educ, Beijing, Peoples R China.
   [Ban, Xiaojuan] Univ Sci & Technol Beijing, Inst Artificial Intelligence, Beijing Adv Innovat Ctr Mat Genome Engn, Beijing 100083, Peoples R China.
   [Yao, Chao] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing; University of Science &
   Technology Beijing; University of Science & Technology Beijing;
   University of Science & Technology Beijing; Bournemouth University;
   University of Science & Technology Beijing; University of Science &
   Technology Beijing; University of Science & Technology Beijing
RP Ban, XJ (corresponding author), Univ Sci & Technol Beijing, Inst Artificial Intelligence, Beijing Adv Innovat Ctr Mat Genome Engn, Beijing 100083, Peoples R China.; Yao, C (corresponding author), Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
EM yaochao@ustb.edu.cn; banxj@ustb.edu.cn
RI Wang, Xiaokun/AAH-6815-2021
OI Wang, Xiaokun/0000-0003-4148-5561; Wang, Xiaokun/0000-0002-4449-591X
FU National Key R&D Program of China [2022ZD0118001]; National Natural
   Science Foundation of China [U22A2022, 61972028]; Guangdong Basic and
   Applied Basic Research Foundation [2023A1515030177]; Scientific and
   Technological Innovation Foundation of Shunde Graduate School, USTB
   [BK21BF002]
FX ACKNOWLEDGMENTS This article is sponsored by National Key R&D Program of
   China (2022ZD0118001), National Natural Science Foundation of China
   under Grant U22A2022 and 61972028, Guangdong Basic and Applied Basic
   Research Foundation (2023A1515030177), and Scientific and Technological
   Innovation Foundation of Shunde Graduate School, USTB under Grant
   BK21BF002.
CR Baek S, 2020, PROC CVPR IEEE, P6120, DOI 10.1109/CVPR42600.2020.00616
   Baek S, 2018, PROC CVPR IEEE, P8330, DOI 10.1109/CVPR.2018.00869
   Boukhayma A, 2019, PROC CVPR IEEE, P10835, DOI 10.1109/CVPR.2019.01110
   Chen T., P 37 INT C MACH LEAR
   Chen Ting, 2020, ADV NEURAL INFORM PR, V33, P22243
   Chen X., P 2021 IEEE CVF C CO
   Chengde Wan, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P442, DOI 10.1007/978-3-030-58577-8_27
   Chu G., P 30 INT JOINT C ART
   Defferrard M., Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering
   Gao H., P INT C MACH LEARN
   Ge LH, 2019, PROC CVPR IEEE, P10825, DOI 10.1109/CVPR.2019.01109
   Ge L, 2016, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2016.391
   Grill Jean-Bastien, 2020, ADV NEURAL INFORM PR
   Hampali S., P IEEE COMP VIS PATT
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   He Yiming, 2021, Artificial Intelligence, P540
   Iqbal U, 2018, LECT NOTES COMPUT SC, V11215, P125, DOI 10.1007/978-3-030-01252-6_8
   Joo H, 2019, IEEE T PATTERN ANAL, V41, P190, DOI 10.1109/TPAMI.2017.2782743
   Karunratanakul K, 2021, INT CONF 3D VISION, P11, DOI 10.1109/3DV53792.2021.00012
   Kim DU., P 2021 IEEE CVF INT
   Kulon D., P BRIT MACH VIS C BM
   Lee N, 2022, AAAI CONF ARTIF INTE, P7372
   Li M., P IEEE CVF C COMP VI
   Malik J, 2018, INT CONF 3D VISION, P110, DOI 10.1109/3DV.2018.00023
   Meng H, 2022, LECT NOTES COMPUT SC, V13666, P380, DOI 10.1007/978-3-031-20068-7_22
   Moon G., P EUR C COMP VIS ECC
   Mueller F, 2017, IEEE I CONF COMP VIS, P1163, DOI 10.1109/ICCV.2017.131
   Park JK., P IEEE CVF C COMP VI
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Rong Y, 2021, INT CONF 3D VISION, P432, DOI 10.1109/3DV53792.2021.00053
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Sinha A, 2016, PROC CVPR IEEE, P4150, DOI 10.1109/CVPR.2016.450
   Spurr A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11210, DOI 10.1109/ICCV48922.2021.01104
   Spurr A, 2018, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2018.00017
   Sridhar S, 2016, LECT NOTES COMPUT SC, V9906, P294, DOI 10.1007/978-3-319-46475-6_19
   Thakoor S., P INT C LEARN REPR
   Tong Zekun, 2021, Advances in neural information processing systems, V34, P19580
   Wang J., 2020, RGB2HANDS REAL TIME, V39
   You Y, 2020, ADV NEURAL INFORM PR, V33, P5812, DOI [10.48550/arXiv.2010.13902, DOI 10.48550/ARXIV.2010.13902]
   Zhang B., P 2021 IEEE CVF INT
   Zhang JW, 2017, IEEE IMAGE PROC, P982, DOI 10.1109/ICIP.2017.8296428
   Zhou Y., P 2020 IEEE CVF C CO
   Zimmermann C, 2021, Pattern Recognition, P250
   Zimmermann C, 2019, IEEE I CONF COMP VIS, P813, DOI 10.1109/ICCV.2019.00090
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 45
TC 0
Z9 0
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2186
EA JUN 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000998837400001
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Lee, J
   Kim, SW
   Um, K
   Kee, MH
   Han, J
AF Lee, JaeHyun
   Kim, Seung-wook
   Um, Kiwon
   Kee, Min Hyung
   Han, JungHyun
TI Inversion alleviation for stable elastic body simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE elasticity; inversion; optimization; physically-based simulation
AB In general, it is not easy to simulate an elastic body that undergoes large deformations. Especially when its elements are inverted or tangled, that is, when its vertices penetrate its polygons, simulation often fails. In this paper, we propose a simple yet highly effective method for alleviating the inversion problems of elastic bodies. Our experiments made with typical optimization-based solvers demonstrate that the proposed method successfully stabilizes the solvers and produces visually plausible motions. We believe that our method can be widely adopted by a variety of state-of-the-art elastic-body simulators thanks to its simplicity.
C1 [Lee, JaeHyun; Kim, Seung-wook; Kee, Min Hyung; Han, JungHyun] Korea Univ, Dept Comp Sci, Seoul, South Korea.
   [Um, Kiwon] IP Paris, Telecom Paris, LTCI, Paris, France.
C3 Korea University; IMT - Institut Mines-Telecom; Institut Polytechnique
   de Paris; Telecom Paris
RP Han, J (corresponding author), Korea Univ, Dept Comp Sci, Seoul, South Korea.
EM dlwogus1223@korea.ac.kr; wook0249@korea.ac.kr;
   kiwon.um@telecom-paris.fr; minh702@korea.ac.kr; jhan@korea.ac.kr
OI Kim, Seung-wook/0000-0003-4178-772X
FU Ministry of Science and ICT, Korea [IITP-2023-2020-0-01819]; Information
   Technology Research Center [IITP-2023-2020-0-01460, 2020-0-00861]
FX Ministry of Science and ICT, South Korea, Grant/Award Number:
   IITP-2023-2020-0-01819; Information Technology Research Center,
   Grant/Award Numbers: IITP-2023-2020-0-01460, 2020-0-00861
CR [Anonymous], 2004, P 2004 ACM SIGGRAPH, DOI DOI 10.1145/1028523.1028541
   Baraff D., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P23, DOI 10.1145/192161.192168
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Blender Online Community, 2018, BLEND 3D MOD REND PA
   Bonet J, 2008, NONLINEAR CONTINUUM MECHANICS FOR FINITE ELEMENT ANALYSIS, 2ND EDITION, P1, DOI 10.1017/CBO9780511755446
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Escobar JM, 2003, COMPUT METHOD APPL M, V192, P2775, DOI 10.1016/S0045-7825(03)00299-8
   Golub GH., 1961, NUMER MATH, V3, P157, DOI DOI 10.1007/BF01386013
   Huang QX, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766890
   Kim Theodore, 2020, ACM SIGGRAPH 2020 CO, DOI DOI 10.1145/3388769.3407490
   LIU T, 2017, ACM T GRAPHIC, V36, P1, DOI DOI 10.1145/3072959.2990496
   Macklin Miles, 2021, MIG '21: Motion, Interaction and Games, DOI 10.1145/3487983.3488289
   Macklin M, 2016, P 9 INT C MOT GAM, P49, DOI [10.1145/2994258.2994272, DOI 10.1145/2994258.2994272]
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muller M, 2020, COMPUT GRAPH FORUM, V39, P101, DOI 10.1111/cgf.14105
   Narain R., 2016, P ACM SIGGRAPH EUR S, P21
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Overby M, 2017, IEEE T VIS COMPUT GR, V23, P2222, DOI 10.1109/TVCG.2017.2730875
   Schmedding R, 2008, VISUAL COMPUT, V24, P625, DOI 10.1007/s00371-008-0243-y
   Sifakis E, 2012, ACM SIGGRAPH 2012 CO, DOI [10.1145/2343483.2343501, DOI 10.1145/2343483.2343501]
   Smith B, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3180491
NR 24
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2183
EA MAY 2023
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000991736700001
DA 2024-07-18
ER

PT J
AU Zou, XJ
   Ye, YQ
   Zhu, ZM
   Chen, Q
AF Zou, Xunjin
   Ye, Yunqing
   Zhu, Zhenmin
   Chen, Qiang
TI Crowd evacuation simulation in flowing fluids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE continuum dynamics; crowd fluid interaction; crowd simulation; path
   planning
AB In this article, we propose an integrated model for simulating the interaction between crowds and fluid particles. Our focus is on simulating evacuation motion for crowds in the face of sudden floods. Our model treats both the crowd and the water as fluid particles, which allows us to incorporate various forces such as pressure, shear, buoyancy, and active forces to drive the agents. Additionally, we have designed a minimum rotational path-planning algorithm for agents to search for safe destinations during evacuations. To develop practical crowd evacuation strategies, we observed and studied survival techniques from whirlpools and sudden changes in water levels during floods. Our simulated evacuation results provide plausible strategies for crowds to survive dangerous floods.
C1 [Zou, Xunjin; Zhu, Zhenmin] East China Jiaotong Univ, Sch Elect & Automat Engn, Nanchang, Peoples R China.
   [Zou, Xunjin] Jiangxi Prov Nat Resources Dev Ctr, Nanchang, Peoples R China.
   [Ye, Yunqing] East China Jiaotong Univ, Sch Software, Nanchang, Peoples R China.
   [Chen, Qiang] Jiangxi Univ Finance & Econ, Sch Informat Management, Nanchang, Peoples R China.
   [Chen, Qiang] Jiangxi Vocat Coll Sci & Technol, Nanchang, Peoples R China.
   [Chen, Qiang] Jiangxi Univ Finance & Econ, Sch Informat Technol, Mailu Campus,665 West Yuping Rd, Nanchang, Jiangxi, Peoples R China.
   [Ye, Yunqing] East China Jiaotong Univ, Sch Software, 808 East Shuanggang St, Nanchang, Peoples R China.
C3 East China Jiaotong University; East China Jiaotong University; Jiangxi
   University of Finance & Economics; Jiangxi University of Finance &
   Economics; East China Jiaotong University
RP Chen, Q (corresponding author), Jiangxi Univ Finance & Econ, Sch Informat Technol, Mailu Campus,665 West Yuping Rd, Nanchang, Jiangxi, Peoples R China.; Ye, YQ (corresponding author), East China Jiaotong Univ, Sch Software, 808 East Shuanggang St, Nanchang, Peoples R China.
EM yeyunqingecjtu@163.com; qiangchen@jxufe.edu.cn
RI Chen, Xupeng/KFA-5959-2024; Li, Hongbo/KHV-4191-2024
OI Li, Hongbo/0000-0003-4495-0756; Chen, Qiang/0000-0002-3642-8119; Zou,
   Xun Jin/0009-0006-8279-7325
FU NSFC [52065024]; Jiangxi Province Key RD Program [20202BBE53022,
   20223BBE51010]; Jiangxi Province 03 Special Project [20212ABC03A20];
   China NSFC [62262024]; Scientific Research Project of Education
   Department of Jiangxi Province [GJJ210511, GJJ207109]
FX ACKNOWLEDGMENTS Zhenmin Zhu was supported by the NSFC (Grant No.
   52065024), Jiangxi Province Key R&D Program (Grant Nos. 20202BBE53022,
   20223BBE51010), Jiangxi Province 03 Special Project (Grant No.
   20212ABC03A20). Qiang Chen was supported in part by the China NSFC
   (Grant No. 62262024), Scientific Research Project of Education
   Department of Jiangxi Province (Grant Nos. GJJ210511, GJJ207109).
CR Bayazit OB., P 8 INT C ART LIF
   Best A., P EUR ACM SIGGRAPH S
   Chen Q, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1977
   Clements RR, 2004, MATH COMPUT SIMULAT, V64, P259, DOI 10.1016/j.matcom.2003.09.019
   Demyen D., P 21 NAT C ART INT
   Funge J., P 26 ANN C COMP GRAP
   Golas A., P ACM SIGGRAPH S INT
   Heigeas L., P GRAPH 2003 13 INT
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hu KD, 2023, IEEE T VIS COMPUT GR, V29, P2036, DOI 10.1109/TVCG.2021.3139031
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Muller M., P EUR SIGGRAPH S COM
   Narain R., P ACM SIGGRAPH AS 20
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Patil S, 2011, IEEE T VIS COMPUT GR, V17, P244, DOI 10.1109/TVCG.2010.33
   Reynolds CW., P GAM DEV C
   Shao W., P 2005 ACM SIGGRAPH
   Shirvani M., AGENT BASED SIMULATO
   Shirvani M, 2021, J FLOOD RISK MANAG, V14, DOI 10.1111/jfr3.12695
   THALMANN D., 2012, Crowd Simulation, V2nd
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van Toll W, 2021, COMPUT GRAPH-UK, V98, P306, DOI 10.1016/j.cag.2021.06.005
   Yang SW, 2020, GRAPH MODELS, V111, DOI 10.1016/j.gmod.2020.101081
NR 24
TC 0
Z9 0
U1 10
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2161
EA MAY 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000990201000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Akhunov, R
   Winchenbach, R
   Kolb, A
AF Akhunov, Rustam
   Winchenbach, Rene
   Kolb, Andreas
TI Evaluation of particle-based smoothed particle hydrodynamics boundary
   handling approaches in computer animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE comparison; fluid simulation; method evaluation; smoothed particles
   hydrodynamics (SPH)
ID DIVERGENCE-FREE; SPH METHODS; FLOWS
AB Boundary handling is an important aspect of fluid simulation, and several boundary handling approaches exist in smoothed particle hydrodynamics (SPH), which have individual strengths and weaknesses. However, comparing different boundary handling approaches is challenging as there is no common basis for evaluations, that is, no universal set of experiments with quantitative evaluation across different methods, especially within computer animation where many evaluations rely mainly on visual perception. This article proposes a set of experiments to aid the evaluation of the main categories of fluid-boundary interactions that are important in computer animation, that is, no motion (resting) fluid, tangential and normal motion of a fluid with respect to the boundary, and a fluid impacting a corner. We propose ten experiments, comprising experimental setup and quantitative evaluation with optional visual inspections, that are arranged in four groups which focus on one of the main category of fluid-boundary interactions. We use these experiments to evaluate three particle-based boundary handling methods, that is, pressure mirroring, pressure boundaries, and moving least squares pressure extrapolation, in combination with two incompressible SPH fluid simulation methods, namely IISPH and DFSPH, to establish a quantifiable relation between different combinations of boundary handling with simulation approaches and the main categories of fluid-boundary interactions. Finally, we summarize all results in a rating table and show how our experiments can be used to determine the promising method for specific requirements regarding a given constellation of fluid-boundary interaction.
C1 [Akhunov, Rustam; Kolb, Andreas] Siegen Univ, Comp Grap, Siegen, Germany.
   [Winchenbach, Rene] Tech Univ Munich, Phys based Simulat, Munich, Germany.
C3 Universitat Siegen; Technical University of Munich
RP Akhunov, R (corresponding author), Siegen Univ, Comp Grap, Siegen, Germany.
EM rustam.akhunov@uni-siegen.de
OI Akhunov, Rustam/0000-0002-4545-6672
CR Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Band S., 2017, MOVING LEAST SQUARES
   Band S, 2018, COMPUT GRAPH-UK, V76, P37, DOI 10.1016/j.cag.2018.08.001
   Band S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3180486
   Becker M, 2009, IEEE T VIS COMPUT GR, V15, P493, DOI 10.1109/TVCG.2008.107
   Bell N., 2005, P 2005 ACM SIGGRAPH, P77, DOI DOI 10.1145/1073368.1073379
   Bender J, 2017, IEEE T VIS COMPUT GR, V23, P1193, DOI 10.1109/TVCG.2016.2578335
   Bender Jan, 2019, Motion, Interaction and Games, DOI [DOI 10.1145/3359566.3360077, 10.1145/3359566.3360077]
   Boxer G., 1988, FLUID MECH-SOV RES, P8
   Crespo AJC, 2007, CMC-COMPUT MATER CON, V5, P173
   Crespo AC, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020685
   Delorme L, 2009, OCEAN ENG, V36, P168, DOI 10.1016/j.oceaneng.2008.09.014
   English A, 2022, COMPUT PART MECH, V9, P911, DOI 10.1007/s40571-021-00403-3
   Farzin S, 2019, COMPUT FLUIDS, V179, P52, DOI 10.1016/j.compfluid.2018.10.010
   Ferrand M, 2013, INT J NUMER METH FL, V71, P446, DOI 10.1002/fld.3666
   Fujisawa M, 2015, COMPUT GRAPH FORUM, V34, P155, DOI 10.1111/cgf.12754
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Gissler C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3284980
   Harada T., 2007, P 23 SPRING C COMPUT, P191
   Huber M., 2015, VRIPHYS, P41, DOI DOI 10.2312/VRIPHYS.20151333
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Issa R., 2006, TEST CASE 2 3D DAMBR
   Koschier D, 2022, COMPUT GRAPH FORUM, V41, P737, DOI 10.1111/cgf.14508
   Koschier D, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099565
   Koschier Dan., 2019, Eurographics 2019-Tutorials, DOI DOI 10.2312/EGT.20191035
   Lee E., 2010, APPL WEAKLY COMPRESS
   Liu S., 2018, INT J OCEAN COASTAL, V1, P1840002, DOI 10.1142/S252980701840002X
   Long T, 2017, J COMPUT PHYS, V350, P166, DOI 10.1016/j.jcp.2017.08.044
   Mayrhofer A, 2015, NUMER ALGORITHMS, V68, P15, DOI 10.1007/s11075-014-9835-y
   Mayrhofer A, 2013, COMPUT PHYS COMMUN, V184, P2515, DOI 10.1016/j.cpc.2013.07.004
   Minor H.-E, 2009, VAW MITTEILUNG, V211
   Monaghan JJ, 2009, COMPUT PHYS COMMUN, V180, P1811, DOI 10.1016/j.cpc.2009.05.008
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   MONAGHAN JJ, 1994, J COMPUT PHYS, V110, P399, DOI 10.1006/jcph.1994.1034
   Monaghan JJ, 1999, J WATERW PORT C-ASCE, V125, P145, DOI 10.1061/(ASCE)0733-950X(1999)125:3(145)
   Morris JP, 1997, J COMPUT PHYS, V136, P214, DOI 10.1006/jcph.1997.5776
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Nomeritae, 2016, ADV WATER RESOUR, V97, P156, DOI 10.1016/j.advwatres.2016.09.008
   Pu JH, 2013, ENG APPL COMP FLUID, V7, P544
   Rakhsha M., 2019, APS DIVISION FLUID D, pH07
   Schlicker S., 2018, ACTIVE CALCULUS MULT
   Shadloo MS, 2012, INT J NUMER METH ENG, V89, P939, DOI 10.1002/nme.3267
   Sheikh B, 2021, ACTA GEOTECH, V16, P2389, DOI 10.1007/s11440-020-01063-y
   spheric-sph, SPHERIC VAL TESTS
   Vaserstein L. N, 1969, Problemy Peredachi Informatsii, V5, P64
   Winchenbach R., 2018, THESIS U SIEGEN
   Winchenbach R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417829
NR 48
TC 2
Z9 2
U1 2
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2138
EA JAN 2023
PG 26
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HE6E0
UT WOS:000909531200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Jain, R
   Karsh, RK
   Barbhuiya, A
AF Jain, Rahul
   Karsh, Ram Kumar
   Barbhuiya, Abul Abbas
TI Linked motion image-based dynamic hand gesture recognition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE classifier; convolutional neural network; dynamic images; hand gesture
   recognition
ID HUMAN-COMPUTER INTERACTION
AB The researchers have paid significant attention to dynamic images for hand gesture recognition. Dynamic images are gesture representation patterns that simultaneously capture spatial, temporal, and structural information from the video. Existing techniques to generate dynamic images provide low discriminability for the gestures, which follow the same trajectory, but in opposite directions, such as "swiping hand right" versus "swiping hand left." Also, limited to similar gestures such as "Snap fingers" versus "Dual fingers heart." To address these issues, we have proposed an algorithm to convert a depth video into a single dynamic image known as a linked motion image (LMI). We give the LMI to a classifier consisting of an ensemble of three modified pretrained convolutional neural networks. We conduct the experiments using a multimodal large-scale EgoGesture dataset and The MSR Gesture 3D dataset. For the EgoGesture dataset, the proposed method achieved an accuracy of 92.91%, which is better than the state-of-the-art methods. For the MSR Gesture 3D dataset, the proposed method accuracy is 100%, which outperforms the state-of-the-art methods. This work also highlights the recognition accuracy and precision of each gesture. The experiments demonstrate the work's economic efficiency using a web-based data science environment called Kaggle rather than high-end systems like GPU.
C1 [Jain, Rahul; Karsh, Ram Kumar; Barbhuiya, Abul Abbas] Natl Inst Technol, Elect & Commun Engn Dept, Silchar, Assam, India.
   [Jain, Rahul] Natl Inst Technol, Elect & Commun Engn Dept, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; National Institute of Technology (NIT System);
   National Institute of Technology Silchar
RP Jain, R (corresponding author), Natl Inst Technol, Elect & Commun Engn Dept, Silchar 788010, Assam, India.
EM rahul_jain_rs@ece.nits.ac.in
OI Jain, Rahul/0000-0003-4894-3721; Karsh, Ram/0000-0002-2341-341X
CR Abavisani M, 2019, PROC CVPR IEEE, P1165, DOI 10.1109/CVPR.2019.00126
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF AUTOMA, P476, DOI 10.1109/FG.2017.150
   Azad R, 2019, IEEE T CIRC SYST VID, V29, P1729, DOI 10.1109/TCSVT.2018.2855416
   Barbhuiya AA, 2021, MULTIMED TOOLS APPL, V80, P3051, DOI 10.1007/s11042-020-09829-y
   Cao CQ, 2017, IEEE I CONF COMP VIS, P3783, DOI 10.1109/ICCV.2017.406
   Chang CC, 2006, J INF SCI ENG, V22, P1047
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2021, IEEE T IND INFORM, V17, P2261, DOI 10.1109/TII.2020.2991208
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Hasan H, 2014, NEURAL COMPUT APPL, V25, P251, DOI 10.1007/s00521-013-1481-0
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Ju C, 2018, J APPL STAT, V45, P2800, DOI 10.1080/02664763.2018.1441383
   Kopuklu Okan, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P85, DOI 10.1109/TBIOM.2020.2968216
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Li ZF, 2019, MULTIMED TOOLS APPL, V78, P19587, DOI 10.1007/s11042-019-7356-3
   Lin M., NETWORK NETWORK P 2
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Simonyan K., PREPRINT
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang PC, 2016, INT C PATT RECOG, P13, DOI 10.1109/ICPR.2016.7899600
   Wang PC, 2016, INT C PATT RECOG, P7, DOI 10.1109/ICPR.2016.7899599
   Yang R, 2015, LECT NOTES COMPUT SC, V9007, P37, DOI 10.1007/978-3-319-16814-2_3
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Zhang YF, 2018, IEEE T MULTIMEDIA, V20, P1038, DOI 10.1109/TMM.2018.2808769
   Zhang Z, 2017, IEEE INT CONF AUTOMA, P238, DOI 10.1109/FG.2017.38
NR 33
TC 0
Z9 0
U1 4
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2137
EA JAN 2023
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HA0K0
UT WOS:000908050500001
DA 2024-07-18
ER

PT J
AU Yan, YL
   Zhang, LJ
   Chen, MY
AF Yan, Yuling
   Zhang, Lijun
   Chen, Minye
TI AGRMTS: A virtual aircraft maintenance training system using gesture
   recognition based on PSO-BPNN model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE BPNN; gesture recognition; Laplace kernel; virtual maintenance
AB The quality and efficiency of aircraft maintenance are the key to ensure flight safety and on-time rate, which mainly depend on the techniques and experience of maintenance engineer. Generally, exercises on physical prototypes are used to improve the maintenance capability of engineers, but this will waste a lot of consumables and easily cause safety accidents. With the development of computer technology, maintenance training in a virtual environment has become an advanced and reliable solution. In this paper, a virtual training system of aircraft maintenance based on gesture recognition interaction is established. Leap Motion is used as a sensor to construct a hybrid machine learning gesture recognition model, so as to obtain natural human-computer interaction experience. In the recognition model, the initial weight matrix and the number of hidden layer nodes in the back propagation neural network are jointly optimized by the Particle Swarm Optimization algorithm with self-adaption inertial weight. This optimization algorithm achieved a recognition rate of 81.26% in the dynamic gesture database constructed in this paper, which is higher than other available algorithms. A preliminary usability evaluation in university classrooms shows that the teaching system in this paper can achieve a better interactive experience.
C1 [Yan, Yuling; Zhang, Lijun] Soochow Univ, Sch Rail Transportat, Suzhou, Peoples R China.
   [Chen, Minye] Shanghai Univ Engn Sci, Shanghai, Peoples R China.
C3 Soochow University - China; Shanghai University of Engineering Science
RP Zhang, LJ (corresponding author), Soochow Univ, Sch Rail Transportat, Shanghai, Peoples R China.
EM zhanglijun@suda.edu.cn
RI Zhang, Lijun/H-8200-2019
OI Zhang, Lijun/0000-0002-5273-6867; yan, rainling/0000-0001-7119-172X
CR Belhocine M., 2016, P INT C EL ENG IEEE
   Boting Chen, 2020, 2020 International Conference on Computer Engineering and Application (ICCEA), P529, DOI 10.1109/ICCEA50009.2020.00117
   Bouhlel, 2020, P 17 INT MULT SYST S
   Cao, 2018, P 4 INT C COMM INF P
   CAVAZZA M, 1995, ADV HUM FACT ERGON, V20, P597, DOI 10.1016/S0921-2647(06)80095-X
   Chakraborty BK, 2018, IET COMPUT VIS, V12, P3, DOI 10.1049/iet-cvi.2017.0052
   Deng, 2018, FUZZY SYSTEMS KNOWLE
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Egger J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173972
   Hongchao, 1738, J PHYS C SER, V1
   Joshi S, 2016, 2016 INTERNATIONAL CONFERENCE ON MICRO-ELECTRONICS AND TELECOMMUNICATION ENGINEERING (ICMETE), P110, DOI 10.1109/ICMETE.2016.11
   Kiliboz NÇ, 2015, J VIS COMMUN IMAGE R, V28, P97, DOI 10.1016/j.jvcir.2015.01.015
   Li CX, 2019, IEEE ACCESS, V7, P136914, DOI 10.1109/ACCESS.2019.2942648
   Linares-Barranco A., 2019, IEEE ACCESS, V99, P1
   Liu L., 2013, 23 INT JOINT C ART I
   Liu S., 2019, P 2019 IEEE 1 INT C
   Merriaux P, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071591
   Munden, 2015, IEEE
   Numfu M, 2019, PROC CIRP, V84, P1069, DOI 10.1016/j.procir.2019.04.268
   Oguri K., 2015, P 2015 IEEE INT C CO
   Pysander, 2017, P SWECOG C
   Rehman Akif, 2020, PMAM '20: Proceedings of the Eleventh International Workshop on Programming Models and Applications for Multicores and Manycores, DOI 10.1145/3380536.3380540
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Sabzevari R, 2016, IEEE T ROBOT, V32, P638, DOI 10.1109/TRO.2016.2552548
   Sharma JK, 2015, INT CONF COMPUT INTE, P411, DOI 10.1109/CICN.2015.86
   Shuang Zhang, 2020, 2020 IEEE International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA), P132, DOI 10.1109/ICIBA50161.2020.9277201
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Weldon WT., 2021, INT J AEROSP PSYCHOL, P1
   Yoon HS, 2001, PATTERN RECOGN, V34, P1491, DOI 10.1016/S0031-3203(00)00096-0
   Zhang L., 2017, P 2017 IEEE INT C CO
   Zhang XX, 2019, 2019 2ND WORLD CONFERENCE ON MECHANICAL ENGINEERING AND INTELLIGENT MANUFACTURING (WCMEIM 2019), P474, DOI 10.1109/WCMEIM48965.2019.00100
NR 31
TC 0
Z9 0
U1 1
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2022
VL 33
IS 1
AR e2031
DI 10.1002/cav.2031
EA SEP 2021
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH4XD
UT WOS:000694999800001
DA 2024-07-18
ER

PT J
AU Wu, HS
   Li, YF
   Chen, L
   Liu, XT
   Li, P
AF Wu, Huisi
   Li, Yifan
   Chen, Le
   Liu, Xueting
   Li, Ping
TI Deep boundary-aware semantic image segmentation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE boundary-aware mechanism; semantic segmentation; two-branch CNN
AB While extensive research efforts have been made in semantic image segmentation, the state-of-the-art methods still suffer from blurry boundaries and mismatched objects due to the insufficient multiscale adaptability. In this paper, we propose a two-branch convolutional neural network (CNN) approach to capture the multiscale context and the boundary information with the two branches, respectively. To capture the multiscale context, we propose to embed self-attention mechanism to the atrous spatial pyramid pooling network. To capture the boundary information, we propose to fuse the low-level features in boundary feature extraction for refining the extracted boundaries via a feature fusion layer (FFL). With FFL, our method can improve the segmentation result with clearer boundaries. A new loss function is proposed which contains a segmentation loss and a boundary loss. Experiments show that our method can predict the boundaries of objects more clearly and have better performance for small-scale objects.
C1 [Wu, Huisi; Li, Yifan; Chen, Le; Liu, Xueting] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
C3 Shenzhen University; Hong Kong Polytechnic University
RP Wu, HS (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
EM hswu@szu.edu.cn
RI Li, Ping/AAO-2019-2020; Liu, Xueting/AAG-9648-2019
OI Li, Ping/0000-0002-1503-0240; Liu, Xueting/0000-0002-0868-5353; Wu,
   Huisi/0000-0002-0399-9089
FU National Natural Science Foundation of China [61973221, 62002232];
   Natural Science Foundation of Guangdong Province of China
   [2018A030313381, 2019A1515011165]
FX This work was supported in part by grants from the National Natural
   Science Foundation of China under Grant 61973221 and 62002232, the
   Natural Science Foundation of Guangdong Province of China under Grant
   2018A030313381 and 2019A1515011165.
CR Acuna D, 2019, PROC CVPR IEEE, P11067, DOI 10.1109/CVPR.2019.01133
   [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.492
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bertasius G, 2016, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2016.392
   Chen L.-C., 2018, Pertanika J. Trop. Agric. Sci., P801, DOI [10.1007/978-3-030-01234-2_49, DOI 10.1007/978-3-030-01234-249, DOI 10.1007/978-3-030-01234-2_49]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu Y, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P782
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Liu S., 2017, P ADV NEUR INF PROC, V30, P1519
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu, 2018, P AS C MACH LEARN ST, P81
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Yu ZD, 2017, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2017.191
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhang XF, 2016, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2016.126
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 26
TC 2
Z9 2
U1 1
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2023
DI 10.1002/cav.2023
EA MAY 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000653153400001
DA 2024-07-18
ER

PT J
AU Wu, ML
   Liu, SG
   Xu, Q
AF Wu, Maolin
   Liu, Shiguang
   Xu, Qing
TI Improved divergence-free smoothed particle hydrodynamics via priority of
   divergence-free solver and SOR
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; fluid simulation; smoothed particle hydrodynamics;
   divergence&#8208; free; SOR
ID SPH
AB Fluid simulation plays an important role in movie special effects, computer games, etc. In recent years, the Smoothed Particle Hydrodynamics (SPH) has become a popular fluid simulation method due to its simpler implementation and better processing capabilities for various complex scenes. Although the computational efficiency of the current SPH method has been significantly improved, there is still much room for improvement in pressure solving. This paper proposes an improved pressure solution method based on DFSPH. Firstly, we eliminate the velocity divergence of the fluid by changing the solution order of the nonpressure force and divergence solvers, thereby reducing the number of iterations required by the density solver. Secondly, the SOR method is applied to the pressure solver, furthering reducing the number of iterations of the density solver. Various experiments demonstrated that our method improves the efficiency of the solver with little decrease in stability compared to state-of-the-art methods. The speedup factor reaches between 1.35 and 1.4 at a time step of 5ms, and the more the number of particles, the faster the performance increases.
C1 [Wu, Maolin; Liu, Shiguang; Xu, Qing] Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
   [Liu, Shiguang] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn
RI Xu, Qing/E-8857-2016
OI Xu, Qing/0000-0002-8243-6670
FU National Natural Science Foundation of China [62072328, 61672375]
FX National Natural Science Foundation of China, Grant/Award Number:
   62072328, 61672375
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   [Anonymous], 2008, Fluid Simulation for Computer Graphics
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J, 2017, IEEE T VIS COMPUT GR, V23, P1193, DOI 10.1109/TVCG.2016.2578335
   Feng XB, 2019, PROCEEDINGS OF THE 32ND INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2019), P41, DOI 10.1145/3328756.3328761
   Gissler C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3284980
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Ihmsen M, 2011, COMPUT GRAPH FORUM, V30, P99, DOI [10.1111/j.1467-8659.2010.01832.x, 10.1111/j.1467-8659.2010.01834.x]
   Koschier Dan., 2019, Eurographics 2019-Tutorials, DOI DOI 10.2312/EGT.20191035
   Liu SG, 2011, VISUAL COMPUT, V27, P241, DOI 10.1007/s00371-010-0531-1
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   MONAGHAN JJ, 1989, J COMPUT PHYS, V82, P1, DOI 10.1016/0021-9991(89)90032-6
   MONAGHAN JJ, 1994, J COMPUT PHYS, V110, P399, DOI 10.1006/jcph.1994.1034
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Sauer T., 2012, Numerical Analysis, V2nd ed.
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Weiler M, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13349
   Yang Z., 2019, COMPUT ANIMAT VIR WO, V30, P1
   Zhang XY, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1801
   Zhang XY, 2015, COMPUT ANIMAT VIRT W, V26, P357, DOI 10.1002/cav.1637
NR 24
TC 3
Z9 5
U1 2
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2006
DI 10.1002/cav.2006
EA MAY 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000653338300001
DA 2024-07-18
ER

PT J
AU Usman, M
   Haworth, B
   Faloutsos, P
   Kapadia, M
AF Usman, Muhammad
   Haworth, Brandon
   Faloutsos, Petros
   Kapadia, Mubbasir
TI Simulation-as-a-Service: Analyzing Crowd Movements in Virtual
   Environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE building information modeling; crowd simulation; human&#8208; centric
   design; simulation&#8208; as&#8208; a&#8208; service; spatial analytics
AB At present, environment designers mostly use their intuition and experience to predictively account for how environments might support dynamic activity. The majority of Computer-Aided Design tools only provide a static representation of space which potentially ignores the impact that an environment layout produces on its occupants and their movements. To address this, computational techniques such as crowd simulation have been developed. With few exceptions, crowd simulation frameworks are often decoupled from environment modeling tools. They usually require specific hardware/software infrastructures and expertise to be used, hindering the designers' abilities to seamlessly simulate, analyze, and incorporate movement-centric dynamics into their design workflows. To bridge this disconnect, we devise a cross-browser service-based simulation analytics platform to analyze environment layouts with respect to occupancy and activity. Our platform allows users to access simulation services by uploading three-dimensional environment models in numerous common formats, devise targeted simulation scenarios, run simulations, and instantly generate crowd-based analytics for their designs. We conducted a case study to showcase cross-domain applicability of our service-based platform, and a user study to evaluate the usability of this approach.
C1 [Usman, Muhammad; Faloutsos, Petros] York Univ, Elect Engn & Comp Sci, Toronto, ON, Canada.
   [Haworth, Brandon] Univ Victoria, Comp Sci, Victoria, BC, Canada.
   [Kapadia, Mubbasir] Rutgers State Univ, Rutgers State Univ New Jersey, New Brunswick, NJ USA.
C3 York University - Canada; University of Victoria; Rutgers University
   System; Rutgers University New Brunswick
RP Usman, M (corresponding author), York Univ, Elect Engn & Comp Sci, Toronto, ON, Canada.
EM usman@cse.yorku.ca
OI Usman, Muhammad/0000-0003-2059-7206; Haworth,
   Brandon/0000-0001-8134-0047
FU National Science Foundation (US) [IIS-1703883, SAS-1723869]; Ontario
   Graduate Scholarship (OGS); Intelligent Systems for Sustainable Urban
   Mobility (ISSUM)
FX Intelligent Systems for Sustainable Urban Mobility (ISSUM); National
   Science Foundation (US), Grant/Award Numbers: IIS-1703883, S &
   AS-1723869; Ontario Graduate Scholarship (OGS)
CR Bangor A, 2009, J USABILITY STUD, V4, P114
   Berseth G, 2015, COMPUT ANIMAT VIRT W, V26, P377, DOI 10.1002/cav.1652
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Cassol VJ, 2017, IEEE COMPUT GRAPH, V37, P60, DOI 10.1109/MCG.2017.3271454
   Cayirci Erdal, 2011, 2011 International Conference on High Performance Computing & Simulation, P397
   Cayirci E, 2013, WINT SIMUL C PROC, P389, DOI 10.1109/WSC.2013.6721436
   Faloutsos, 2015, COMPUT ANIMAT VIR WO
   Faloutsos, 2011, MODULAR FRAMEWORK AD
   FRUIN J.J., 1971, Designing for pedestrians: A level-of-service concept. Highway Research Record
   Haworth B, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1749
   Heess N., 2017, CoRR, abs/1707.02286.
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kapadia, 2019, JOINT EXPLORATION AN
   Kapadia M., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games, I3D '09, P215
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Laplante Phillip A., 2008, IT Professional, V10, P46, DOI 10.1109/MITP.2008.60
   MUBBASIR KAPADIA., 2015, SYNTHESIS LECT VISUA, V7, P1
   Musse, 2013, CROWD SIMULATION, P195
   Pax R., 2018, P IEEE ACM 22 INT S, P1
   Pelechano N., 2016, SIMULATING HETEROGEN
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Sauro J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2215, DOI 10.1145/1978942.1979266
   Singh S, 2011, COMPUT ANIMAT VIRT W, V22, P151, DOI 10.1002/cav.403
   Singh S, 2009, LECT NOTES COMPUT SC, V5884, P158, DOI 10.1007/978-3-642-10347-6_15
   Turner M, 2003, COMPUTER, V36, P38, DOI 10.1109/MC.2003.1236470
   Usman M, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1990
   Usman M, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI 10.1145/3274247.3274503
   Usman M, 2019, COMM COM INF SC, V1028, P279, DOI 10.1007/978-981-13-8410-3_20
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Wang SX, 2015, SIMUL-T SOC MOD SIM, V91, P71, DOI 10.1177/0037549714562994
   Zehe D, 2015, WINT SIMUL C PROC, P103, DOI 10.1109/WSC.2015.7408156
NR 32
TC 3
Z9 3
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2021
VL 32
IS 6
AR e1990
DI 10.1002/cav.1990
EA FEB 2021
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XW9UC
UT WOS:000618688800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, Q
   Luo, GL
   Tong, Y
   Jin, XG
   Deng, ZG
AF Chen, Qiang
   Luo, Guoliang
   Tong, Yang
   Jin, Xiaogang
   Deng, Zhigang
TI A linear wave propagation-based simulation model for dense and polarized
   crowds
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE boundary constraints; dense and polarized crowd; fluid&#8208; based
   model; linear waves; smoothed particle hydrodynamics
ID HYDRODYNAMICS; MOTION; FLOW
AB Fluid-like motion and linear wave propagation behavior will emerge when we impose boundary constraints and polarized conditions on crowds. To this end, we present a Lagrangian hydrodynamics method to simulate the fluid-like motion of crowd and a triggering approach to generate the linear stop-and-go wave behavior. Specifically, we impose a self-propulsion force on the leading agents of the crowd to push the crowd to move forward and introduce a Smoothed Particle Hydrodynamics-based model to simulate the dynamics of dense crowds. Besides, we present a motion signal propagation approach to trigger the rest of the crowd so that they respond to the immediate leaders linearly, which can lead to the linear stop-and-go wave effect of the fluid-like motion for the crowd. Our experiments demonstrate that our model can simulate large-scale dense crowds with linear wave propagation.
C1 [Chen, Qiang; Luo, Guoliang; Tong, Yang] East China Jiaotong Univ, VR & Interact Tech Inst, Nanchang, Jiangxi, Peoples R China.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Jin, Xiaogang] ZJU Tencent Game & Intelligent Graph Innovat Tech, Hangzhou, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77004 USA.
C3 East China Jiaotong University; Zhejiang University; University of
   Houston System; University of Houston
RP Luo, GL (corresponding author), East China Jiaotong Univ, VR & Interact Tech Inst, Nanchang, Jiangxi, Peoples R China.; Deng, ZG (corresponding author), Univ Houston, Dept Comp Sci, Houston, TX 77004 USA.
EM luoguoliang@ecjtu.edu.cn; zdeng4@uh.edu
RI li, yao/IYJ-1364-2023; Liu, Gui/JHU-8707-2023; Zhao, Xuan/JMR-2135-2023;
   Yang, Ying/ABD-2481-2022
OI Jin, Xiaogang/0000-0001-7339-2920; Chen, Qiang/0000-0002-3642-8119;
   Deng, Zhigang/0000-0003-2571-5865; Deng, Zhigang/0000-0002-0452-8676
FU National Natural Science Foundation of China [61962021, 62036010]; Key
   Research Program of Jiangxi Province [20202ACBL202008]; Key Research and
   Development Program of Jiangxi Province [20192BBE50079, 2018BBE50024];
   Key Research and Development Program of Zhejiang Province [2020C03096,
   2018C01090]; NSF [IIS-2005430]
FX This work has been in part supported by the National Natural Science
   Foundation of China under Grant 61962021, the Key Research Program of
   Jiangxi Province under Grant 20202ACBL202008, the Key Research and
   Development Program of Jiangxi Province under Grant 20192BBE50079 and
   2018BBE50024. Xiaogang Jin was supported by the Key Research and
   Development Program of Zhejiang Province (Grant nos. 2020C03096,
   2018C01090), and the National Natural Science Foundation of China (Grant
   No. 62036010). Zhigang Deng is in part supported by NSF IIS-2005430.
CR Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   [Anonymous], 2003, P ACM SIGGRAPH EUR S
   [Anonymous], 2001, CONDMAT0112117 ARXIV
   Appert-Rolland C., 2014, PEDESTR EVACUATION D, P305
   Appert-Rolland C, 2012, PEDESTRIAN EVACUATIO, P305
   Aw A, 2002, SIAM J APPL MATH, V63, P259, DOI 10.1137/S0036139900380955
   Bain N, 2019, SCIENCE, V363, P46, DOI 10.1126/science.aat9891
   Bandala AA, 2016, J ADV COMPUT INTELL, V20, P84
   Burchan Bayazit O., 2003, Proceedings of International conference on Artificial life, P362
   Cao SC, 2016, PHYS REV E, V94, DOI 10.1103/PhysRevE.94.012312
   Chang G.L., 1985, TRANSPORT RES REC, V1005, P107
   Chen Q, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1902
   Chraibi M, 2015, PHYS REV E, V92, DOI 10.1103/PhysRevE.92.042809
   Farkas I, 2002, NATURE, V419, P131, DOI 10.1038/419131a
   Fiorini P, 1998, INT J ROBOT RES, V17, P760, DOI 10.1177/027836499801700706
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Helbing D, 2007, ARXIV07083339
   Hughes RL, 2002, TRANSPORT RES B-METH, V36, P507, DOI 10.1016/S0191-2615(01)00015-7
   Hughes Rowan., 2015, Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, P79, DOI DOI 10.1145/2822013.2822030
   Kang SJ, 2012, APPL MATH INFORM SCI, V6, P167
   Lemercier S, 2012, COMPUT GRAPH FORUM, V31, P489, DOI 10.1111/j.1467-8659.2012.03028.x
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Marchetti MC, 2013, REV MOD PHYS, V85, DOI 10.1103/RevModPhys.85.1143
   MUBBASIR KAPADIA., 2015, SYNTHESIS LECT VISUA, V7, P1
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pelechano N., 2008, Synthesis Lectures on Computer Graphics and Animation, V3, P1, DOI DOI 10.2200/S00123ED1V01Y200808CGR008
   Pelechano N., 2006, Modeling realistic high density autonomous agent crowd movement: social forces, communication, roles and psychological influences
   Schadschneider A, 2011, NETW HETEROG MEDIA, V6, P545, DOI 10.3934/nhm.2011.6.545
   Singh S, 2009, COMPUT ANIMAT VIRT W, V20, P533, DOI 10.1002/cav.277
   Thalmann D., 2013, Crowd Simulation, P111, DOI DOI 10.1007/978-1-4471-4450-2_5
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van Wageningen-Kessels F, 2018, TRANSPORT SCI, V52, P547, DOI 10.1287/trsc.2017.0793
   van Wageningen-Kessels F, 2016, PHYSICA A, V443, P272, DOI 10.1016/j.physa.2015.09.048
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Yuan YF, 2020, TRANSPORT RES C-EMER, V111, P334, DOI 10.1016/j.trc.2019.12.017
NR 38
TC 3
Z9 3
U1 2
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2021
VL 32
IS 1
AR e1977
DI 10.1002/cav.1977
EA NOV 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QP5QT
UT WOS:000587236200001
DA 2024-07-18
ER

PT J
AU Liu, N
   Wang, XC
   Liu, SL
   Wu, ZK
   He, J
   Cheng, P
   Miao, CY
   Thalmann, NM
AF Liu, Na
   Wang, Xingce
   Liu, Shaolong
   Wu, Zhongke
   He, Jiale
   Cheng, Peng
   Miao, Chunyan
   Thalmann, Nadia Magnenat
TI Hierarchical planning-based crowd formation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fuzzy logic control; gaze-movement angle; team formation; three-layered
   architecture; time-space table
ID SIMULATION; MODEL
AB Team formation with realistic crowd simulation behavior is a challenge in computer graphics, multiagent control, and social simulation. In this study, we propose a framework of crowd formation via hierarchical planning, which includes cooperative-task, coordinated-behavior, and action-control planning. In cooperative-task planning, we improve the grid potential field to achieve global path planning for a team. In coordinated-behavior planning, we propose a time-space table to arrange behavior scheduling for a movement. In action-control planning, we combine the gaze-movement angle model and fuzzy logic control to achieve agent action. Our method has several advantages. (1) The hierarchical architecture is guaranteed to match the human decision process from high to low intelligence. (2) The agent plans his behavior only with the local information of his neighbor; the global intelligence of the group emerges from these local interactions. (3) The time-space table fully utilizes three-dimensional information. Our method is verified using crowds of various densities, from sparse to dense, employing quantitative performance measures. The approach is independent of the simulation model and can be extended to other crowd simulation tasks.
C1 [Liu, Na; Wang, Xingce; Liu, Shaolong; Wu, Zhongke; He, Jiale] Beijing Normal Univ, Coll Comp Sci & Technol, Beijing 100875, Peoples R China.
   [Cheng, Peng; Miao, Chunyan; Thalmann, Nadia Magnenat] Nanyang Technol Univ, Sch Comp Engn, MIRALab, Singapore, Singapore.
C3 Beijing Normal University; Nanyang Technological University
RP Wang, XC; Wu, ZK (corresponding author), Beijing Normal Univ, Coll Comp Sci & Technol, Beijing 100875, Peoples R China.
EM wangxingce@bnu.edu.cn; zwu@bnu.edu.cn
RI Thalmann, Nadia/AAK-5195-2021; Miao, Chunyan/A-3730-2011
OI Thalmann, Nadia/0000-0002-1459-5960; Miao, Chunyan/0000-0002-0300-3448;
   CHENG, Peng/0000-0003-3516-7196; liu, daisy/0000-0002-4572-4155
FU National Key Research and Development Program of China [2017YFB1002604,
   2017YFB100-2600, 2017YFB1402100]; BRICS of China [2017YFE0100500];
   Beijing Municipal Natural Science Foundation of China [4172033]
FX National Key Research and Development Program of China, Grant/Award
   Number: 2017YFB1002604, 2017YFB100-2600, and 2017YFB1402100; National
   Key Cooperation between the BRICS of China, Grant/Award Number:
   2017YFE0100500; Beijing Municipal Natural Science Foundation of China,
   Grant/Award Number: 4172033
CR Alizadeh R, 2011, SAFETY SCI, V49, P315, DOI 10.1016/j.ssci.2010.09.006
   Barnett A, 2016, COMPUT GRAPH FORUM, V35, P120, DOI 10.1111/cgf.12735
   Bridson R, 2010, SCIENCE, V330, P1756, DOI 10.1126/science.1198769
   Cai PP, 2016, AUTOMAT CONSTR, V62, P133, DOI 10.1016/j.autcon.2015.09.007
   Casareale C, 2017, BUILD SIMUL-CHINA, V10, P989, DOI 10.1007/s12273-017-0381-0
   Chen MQ, 2012, PROCEEDINGS OF THE XI'AN 2012 INTERNATIONAL CONFERENCE OF SPORT SCIENCE & PHYSICAL EDUCATION, VOL II: PHYSICAL EDUCATION AND INNOVATION, P230
   Chen Y, 2017, IEEE T ROBOT, V33, P1242, DOI 10.1109/TRO.2017.2699670
   CUTTING JE, 1995, PSYCHOL REV, V102, P627, DOI 10.1037/0033-295X.102.4.627
   Dubois D, 1996, FUZZY SET SYST, V84, P169, DOI 10.1016/0165-0114(96)00066-8
   Dutra TB, 2017, COMPUT GRAPH FORUM, V36, P337, DOI 10.1111/cgf.13130
   Flagg M, 2013, IEEE T VIS COMPUT GR, V19, P1935, DOI 10.1109/TVCG.2012.317
   Goswami D, 2014, COMPUT SCI
   Gu Q, 2013, IEEE COMPUT GRAPH, V33, P20, DOI 10.1109/MCG.2011.87
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Henry Joseph., 2012, Proceedings of the 11th ACM SIGGRAPH / Eurographics conference on Computer Animation, EUROSCA'12, P193
   Hughes RL, 2003, ANNU REV FLUID MECH, V35, P169, DOI 10.1146/annurev.fluid.35.101101.161136
   Hughes Rowan., 2015, Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, P79, DOI DOI 10.1145/2822013.2822030
   Ioannidis K, 2011, ROBOT AUTON SYST, V59, P113, DOI 10.1016/j.robot.2010.10.004
   Kapadia M., 2013, P 12 ACM SIG GRAPHEU, P115, DOI DOI 10.1145/2485895.2485909
   Karamouzas I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073705
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Lemercier S, 2016, COMPUT ANIMAT VIRT W, V27, P24, DOI 10.1002/cav.1629
   Levine S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966402
   Li Jian, 2010, Journal of Computer Aided Design & Computer Graphics, V22, P1158, DOI 10.3724/SP.J.1089.2010.10928
   Liu Haiying, 2015, P 14 ACM SIGGRAPH EU, P193, DOI DOI 10.1145/2786784.2795135
   Liu HB, 2007, J MICROMECH MICROENG, V17, P2055, DOI 10.1088/0960-1317/17/10/018
   Malinowski A, 2017, PROCEDIA COMPUT SCI, V108, P917, DOI 10.1016/j.procs.2017.05.036
   Morrison JE, 2003, DTIC DOCUMENT
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Nasir FM, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P289, DOI 10.1145/3013971.3014017
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Park JH, 2013, COMPUT ANIMAT VIRT W, V24, P173, DOI 10.1002/cav.1504
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   Stüvel SA, 2017, IEEE T VIS COMPUT GR, V23, P1823, DOI 10.1109/TVCG.2016.2545670
   van den Berg JP, 2008, IEEE INT C ROB AUT M
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   van Goethem A, 2015, TECHNICAL REPORT SER
   Wang WY, 2017, IEEE T CYBERNETICS, V47, P4208, DOI 10.1109/TCYB.2016.2602498
   Wang XC, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P251, DOI 10.1145/3013971.3013978
   Wu Q., 2013, Proceedings of the 3rd ACM SIGCOMM workshop on Information-centric networking, ICN '13, P41
   Xu JY, 2008, COMPUT ANIMAT VIRT W, V19, P319, DOI 10.1002/cav.231
   Xu M., 2012, Proc. of the 20th ACM Int. Conf. on Multimedia, P1189, DOI [10.1145/2393347.2396415, DOI 10.1145/2393347.2396415]
   Xu ML, 2014, J COMPUT SCI TECH-CH, V29, P799, DOI 10.1007/s11390-014-1469-y
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Zesch T, 2010, NAT LANG ENG, V16, P25, DOI 10.1017/S1351324909990167
   Zhang P, 2015, VISUAL COMPUT, V31, P5, DOI 10.1007/s00371-013-0900-7
   Zheng LP, 2014, COMPUT GRAPH-UK, V38, P268, DOI 10.1016/j.cag.2013.10.035
NR 47
TC 0
Z9 0
U1 2
U2 20
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2019
VL 30
IS 6
AR e1875
DI 10.1002/cav.1875
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KD5NX
UT WOS:000507913800003
DA 2024-07-18
ER

PT J
AU Jin, YX
   Li, P
   Sheng, B
   Nie, YW
   Kim, JM
   Wu, EH
AF Jin, Yuxi
   Li, Ping
   Sheng, Bin
   Nie, Yongwei
   Kim, Jinman
   Wu, Enhua
TI SRNPD: Spatial rendering network for pencil drawing stylization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE geometry information constraint; single-shot bottom-up; spatial
   rendering network; stroke shading fusion
ID GENERATION
AB Pencil drawing is a simple yet effective way to depict what people see by clearly presenting details of the scene. Existing methods usually extract strokes of the input image and adjust the result image tone to make it look like a pencil drawing. However, they do not consider the quality of the stroke image and the geometry information of lines in the stroke image, which unavoidably results in the violation of original essential structures and in a flatten pencil drawing with unrealistic appearance. We put forward a spatial rendering network for pencil drawing stylization. Spatial stroke images are extracted from the image pyramid by a single-shot bottom-up neural network to improve the quality of these stroke images. Unlike the former tone adjustment-based methods, we analyze perceptual cues of strokes at different stroke image levels and use the obtained geometry information to constrain the stroke shading procedure. The final pencil drawing result is achieved by the stroke shading fusion of different levels' shading results. The effectiveness of our spatial rendering network for pencil drawing stylization is demonstrated by an ablation study, comparison to the state of the art, and a user study.
C1 [Jin, Yuxi; Li, Ping] Macau Univ Sci & Technol, Fac Informat Technol, Taipa, Macao, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Nie, Yongwei] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
   [Kim, Jinman] Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Wu, Enhua] Univ Macau, Fac Sci & Technol, Taipa, Macao, Peoples R China.
C3 Macau University of Science & Technology; Hong Kong Polytechnic
   University; Shanghai Jiao Tong University; South China University of
   Technology; University of Sydney; Chinese Academy of Sciences; Institute
   of Software, CAS; University of Macau
RP Li, P (corresponding author), Macau Univ Sci & Technol, Fac Informat Technol, Taipa, Macao, Peoples R China.; Li, P (corresponding author), Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
EM lipingfire@ieee.org
RI Yuxi, Jin/HPD-0563-2023; Li, Ping/AAO-2019-2020; Kim, Jin
   Man/HJO-8987-2023; Kim, Jin/AAS-5810-2021
OI Li, Ping/0000-0002-1503-0240; Kim, Jin/0000-0002-7667-9588; kim,
   jinman/0000-0001-5960-1060
FU Macau Science and Technology Development Fund [0027/2018/A1]; National
   Natural Science Foundation of China [61872241, 61632003, 61672502,
   61602183, 61572316]; Science and Technology Project of Guangzhou City
FX Macau Science and Technology Development Fund, Grant/Award Number:
   0027/2018/A1; National Natural Science Foundation of China, Grant/Award
   Number: 61872241, 61632003, 61672502, 61602183, and 61572316; Science
   and Technology Project of Guangzhou City,
CR CHEN Q., 2017, PROC INT CONF RECON, P2497
   Chen Z., 2018, P 31 INT C COMP AN S, P32
   Chen ZY, 2008, LECT NOTES COMPUT SC, V5353, P931, DOI 10.1007/978-3-540-89796-5_117
   Dang-en Xie, 2010, Proceedings 2010 International Conference on Computing, Control and Industrial Engineering (CCIE 2010), P166, DOI 10.1109/CCIE.2010.160
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Gao CY, 2018, COMPUT GRAPH FORUM, V37, P395, DOI 10.1111/cgf.13334
   Hata M., 2013, P ACM S APPL PERC, P119
   Hata M, 2012, VISUAL COMPUT, V28, P657, DOI 10.1007/s00371-012-0689-9
   Jayaraman PK, 2018, IEEE T VIS COMPUT GR, V24, P2103, DOI 10.1109/TVCG.2017.2705182
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Lee H., 2006, NPAR 2006, P37, DOI [10. 1145/1124728. 1124735, DOI 10.1145/1124728.1124735]
   Liu YM, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE IN SPORT (IACSS2011), P189
   Lu Cewu., 2012, Proc. NPAR, P65
   Mao XY, 2001, CAD/GRAPHICS '2001: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN AND COMPUTER GRAPHICS, VOLS 1 AND 2, P240
   Matsui H, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P148
   Ning Wang, 2011, 2011 12th International Conference on Computer-Aided Design and Computer Graphics, P367, DOI 10.1109/CAD/Graphics.2011.50
   Ohtake Y, 2004, ACM T GRAPHIC, V23, P609, DOI 10.1145/1015706.1015768
   Okawa R, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P282, DOI 10.23919/MVA.2017.7986856
   Spicker M, 2015, SIGGRAPH AS 2015 TEC
   Sun WT, 2019, CRIT REV BIOTECHNOL, V39, P618, DOI 10.1080/07388551.2019.1608503
   Way DL, 2014, INT J INNOV COMPUT I, V10, P233
   Yamamoto S, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P329
   Yang H, 2012, COMPUT GRAPH FORUM, V31, P1471, DOI 10.1111/j.1467-8659.2012.03143.x
   Yang TH, 2019, AUDIOL NEURO-OTOL, V24, P183, DOI 10.1159/000501540
   Yeh CK, 2015, IEEE T VIS COMPUT GR, V21, P304, DOI 10.1109/TVCG.2014.2360406
   Zhang J, 2017, 2017 IEEE INT C MULT, P261
NR 28
TC 3
Z9 4
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1890
DI 10.1002/cav.1890
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400015
DA 2024-07-18
ER

PT J
AU Peng, C
   Zhao, ZP
   Li, C
   Wang, CB
   Qin, H
   Quan, HY
AF Peng, Chen
   Zhao, Zipeng
   Li, Chen
   Wang, Changbo
   Qin, Hong
   Quan, Hongyan
TI Data-driven retrieval of spray details with random forest-based distance
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE machine learning; random forests; spray simulation
AB Generating realistic spray details in liquid simulations remains computationally expensive. This paper proposes a data-driven method to simulate high-resolution sprays on low-resolution grids by retrieving details with the most compatible details from a precomputed repository efficiently. We first employ a random forest-based distance (RFD) to measure the similarity of liquid regions. In consideration of spatiotemporal relationships between one liquid region and its neighbors, we define a multinary label for RFD instead of the original binary one. Our improved RFD enables us to retrieve details that fit ground truth the best. To ensure temporal continuity of our result and to generate new details from existing ones, we formulate a series of forests with a training set from different time steps. Then, we synthesize results of each forest according to their distances. Finally, we put the synthesis result in correct positions to generate desired sprays motion. In our method, a state-of-the-art cascade forest is employed for a higher accuracy. Several experiments with various grid resolutions validate our method both in visual effect and computational cost.
C1 [Peng, Chen; Zhao, Zipeng; Li, Chen; Wang, Changbo; Quan, Hongyan] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai 200062, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 East China Normal University; State University of New York (SUNY)
   System; State University of New York (SUNY) Stony Brook
RP Wang, CB (corresponding author), East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai 200062, Peoples R China.
EM cbwang@sei.ecnu.edu.cn
RI Li, Kexin/KAO-2519-2024
OI Zhao, Zipeng/0000-0002-3797-6483
FU National Natural Science Foundation of China [61532002, 61672237];
   National Science Foundation of USA [IIS-1715985, IIS-1812606]
FX National Natural Science Foundation of China, Grant/Award Number:
   61532002 and 61672237; National Science Foundation of USA, Grant/Award
   Number: IIS-1715985 and IIS-1812606
CR [Anonymous], 2006, P 20 ANN C NEUR INF
   [Anonymous], 2012, ACM SIGKDD
   [Anonymous], ABS160703597 CORR
   Bagar F, 2010, COMPUT GRAPH FORUM, V29, P1383, DOI 10.1111/j.1467-8659.2010.01734.x
   Batty C., 2008, S COMP AN, P219
   Batty C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276502
   Bonev B, 2017, ABS170407854 CORR
   Boyd L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159522
   Chu MY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073643
   Clausen P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451243
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P225, DOI 10.1111/cgf.12825
   Gerszewski D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508430
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Guo XX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P481, DOI 10.1145/2939672.2939738
   Harlow FH, 1962, LADC5288 US DEP EN O
   Ihmsen Markus, 2014, P 35 ANN C EUR ASS C, DOI [10.2312/egst.20141034, DOI 10.2312/EGST.20141034]
   Ladicky L, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818129
   Mihalef V, 2009, COMPUT GRAPH FORUM, V28, P229, DOI 10.1111/j.1467-8659.2009.01362.x
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Teng Y, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980229
   Um K, 2018, COMPUT GRAPH FORUM, V37, P171, DOI 10.1111/cgf.13522
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Yang C, 2016, COMPUT ANIMAT VIRT W, V27, P415, DOI 10.1002/cav.1695
   Yang LP, 2014, COMPUT GRAPH FORUM, V33, P199, DOI 10.1111/cgf.12488
   Zhou Zhi-Hua, 2017, ABS170208835 CORR
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 26
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1901
DI 10.1002/cav.1901
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400020
DA 2024-07-18
ER

PT J
AU Lu, Y
   Zhao, S
   Younes, N
   Lahn, JKI
AF Lu, Yao
   Zhao, Shang
   Younes, Naji
   Lahn, James K., I
TI Accurate nonrigid 3D human body surface reconstruction using commodity
   depth sensors
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE body composition inference; medical application; multimodality
   registration; nonrigid registration; skeletal joints inference;
   supervised learning; surface reconstruction system
ID REGISTRATION; ERROR; MODEL
AB In the last decade, 3D modeling techniques enjoyed a booming development in both hardware and software. High-end hardware generates high fidelity results, but the cost is prohibitive, whereas consumer-level devices generate plausible results for entertainment purposes but are not appropriate for medical uses. We present a cost-effective and easy-to-use 3D body reconstruction system using consumer-grade depth sensors, which provides reconstructed body shapes with a high degree of accuracy and reliability appropriate for medical applications. Our surface registration framework integrates the articulated motion assumption, global loop closure constraint, and a general as-rigid-as-possible deformation model. To enhance the reconstruction quality, we propose a novel approach to accurately infer skeletal joints from anatomical data using multimodality registration. We further propose a supervised predictive model to infer the skeletal joints for arbitrary subjects independent from anatomical data reference. A rigorous validation test has been conducted on real subjects to evaluate the reconstruction accuracy and repeatability. Our system has the potential to make accurate body surface scanning systems readily available for medical professionals and the general public. The system can be used to obtain additional health data derived from 3D body shapes, such as the percentage of body fat.
C1 [Lu, Yao; Zhao, Shang] George Washington Univ, Sch Engn & Appl Sci, Inst Comp Graph, Dept Comp Sci, 800 22nd St NW Suite 3400, Washington, DC 20052 USA.
   [Younes, Naji] George Washington Univ, Milken Inst Sch Publ Hlth, Dept Epidemiol & Biostat, 800 22nd St NW Suite 7680, Washington, DC 20052 USA.
   [Lahn, James K., I] George Washington Univ, Sch Engn & Appl Sci, Dept Comp Sci, 800 22nd St NW Suite 5830, Washington, DC 20052 USA.
   [Lahn, James K., I] George Washington Univ, Sch Med & Hlth Sci, Inst Comp Graph, Dept Pediat, 800 22nd St NW Suite 5830, Washington, DC 20052 USA.
C3 George Washington University; George Washington University; George
   Washington University; George Washington University
RP Lu, Y (corresponding author), George Washington Univ, Sch Engn & Appl Sci, Inst Comp Graph, Dept Comp Sci, 800 22nd St NW Suite 3400, Washington, DC 20052 USA.
EM luy161616@gwu.edu
RI zhao, shang/AAC-7399-2021
OI Hahn, James/0000-0001-6535-8175; Lu, Yao/0000-0001-7680-1531
FU NIH [1R21HL124443]; NSF [CNS-1337722]
FX NIH, Grant/Award Number: 1R21HL124443; NSF, Grant/Award Number:
   CNS-1337722
CR Alassaf MH, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P579
   Aldridge K, 2005, AM J MED GENET A, V138A, P247, DOI 10.1002/ajmg.a.30959
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Amberg B., 2007, 2007 IEEE C COMPUTER, P1
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], TC 2 3D BOD SCANN
   [Anonymous], OP SOURC DRIV KIN WI
   [Anonymous], J MED INTERNET RES
   [Anonymous], 6 INT C 3D BOD SCANN
   [Anonymous], STYK BOD SCANN TECH
   Ball SD, 2004, PHYSIOL MEAS, V25, P671, DOI 10.1088/0967-3334/25/3/007
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Chang W, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966405
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Cui Y., 2012, ACCV Workshops, P133
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Dou MS, 2015, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2015.7298647
   Dou MS, 2014, 2014 IEEE VIRTUAL REALITY (VR), P39, DOI 10.1109/VR.2014.6802048
   Dou MS, 2013, INT SYM MIX AUGMENT, P99, DOI 10.1109/ISMAR.2013.6671769
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kazhdan Michael, 2013, Acm Transactions on Graphics, DOI DOI 10.1145/2487228.2487237
   Knoop S, 2005, IEEE-RAS INT C HUMAN, P74
   Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508407
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Pons-Moll G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766993
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sharp GC, 2004, IEEE T PATTERN ANAL, V26, P1037, DOI 10.1109/TPAMI.2004.49
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Tsoli A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601225
   Tzou CHJ, 2014, J PLAST RECONSTR AES, V67, P489, DOI 10.1016/j.bjps.2014.01.003
   Wang RZ, 2016, LECT NOTES COMPUT SC, V9911, P271, DOI 10.1007/978-3-319-46478-7_17
   Wang RZ, 2014, PROC CVPR IEEE, P4018, DOI 10.1109/CVPR.2014.513
   Wang X, 2014, J NEUROSCI, V34, P6182, DOI 10.1523/JNEUROSCI.5093-13.2014
   Zeng M, 2013, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2013.26
   Zhang Q, 2014, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2014.92
NR 40
TC 13
Z9 17
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2018
VL 29
IS 5
AR e1807
DI 10.1002/cav.1807
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GW0KS
UT WOS:000446555300003
PM 31156352
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhong, SS
   Xie, Z
   Wang, WN
   Liu, Z
   Liu, LG
AF Zhong, Saishang
   Xie, Zhong
   Wang, Weina
   Liu, Zheng
   Liu, Ligang
TI Mesh denoising via total variation and weighted Laplacian
   regularizations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE feature preserving; Laplacian; mesh denoising; total variation
ID DIFFUSION
AB Mesh denoising is a fundamental problem in geometry processing. The main challenge is to preserve sharp features (such as edges and corners) and smooth regions (such as smoothly curved regions and fine details) while removing the noise. State-of-the-art denoising methods still struggle with this issue. In this paper, we first propose a new variational model combining total variation and anisotropic Laplacian regularization to filter the normal vector field of the mesh. This model can preserve sharp features and simultaneously handle smooth regions well. Then, a new vertex updating scheme is presented to reconstruct the mesh according to the filtered face normals. It prevents the orientation ambiguity problem introduced by existing schemes. Experiments show that our denoising method outperforms all compared methods visually and quantitatively, especially for meshes consisting of both sharp features and smooth regions.
C1 [Zhong, Saishang; Xie, Zhong; Liu, Zheng] China Univ Geosci, Fac Informat Engn, Wuhan 430074, Hubei, Peoples R China.
   [Zhong, Saishang; Xie, Zhong; Liu, Zheng] China Univ Geosci, Natl Engn Res Ctr Geog Informat Syst, Wuhan 430074, Hubei, Peoples R China.
   [Wang, Weina; Liu, Ligang] Univ Sci & Technol China, Sch Math Sci, Hefei, Anhui, Peoples R China.
C3 China University of Geosciences; China University of Geosciences;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Liu, Z (corresponding author), China Univ Geosci, Fac Informat Engn, Wuhan 430074, Hubei, Peoples R China.; Liu, Z (corresponding author), China Univ Geosci, Natl Engn Res Ctr Geog Informat Syst, Wuhan 430074, Hubei, Peoples R China.
EM saishang@cug.edu.cn; xiezhong@cug.edu.cn; wnwang@mail.ustc.edu.cn;
   liu.zheng.jojo@gmail.com; lgliu@ustc.edu.cn
OI Liu, Zheng/0000-0001-6713-6680
FU National Natural Science Foundation of China [61702467, 41671400]
FX National Natural Science Foundation of China, Grant/Award Number:
   61702467 and 41671400
CR Bajaj CL, 2003, ACM T GRAPHIC, V22, P4, DOI 10.1145/588272.588276
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   DENNIS JE, 1977, SIAM REV, V19, P46, DOI 10.1137/1019005
   Desbrun M, 2000, PROC GRAPH INTERF, P145
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Fan HQ, 2010, IEEE T VIS COMPUT GR, V16, P312, DOI 10.1109/TVCG.2009.70
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   He L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461965
   Hildebrandt K, 2004, COMPUT GRAPH FORUM, V23, P391, DOI 10.1111/j.1467-8659.2004.00770.x
   Hildebrandt K., 2007, SGP 07 P 5 EUROGRAPH, P203, DOI DOI 10.2312/SGP/SGP07/203-212
   Lu XQ, 2017, COMPUT AIDED GEOM D, V54, P49, DOI 10.1016/j.cagd.2017.02.011
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Sun XF, 2007, IEEE T VIS COMPUT GR, V13, P925, DOI 10.1109/TVCG.2007.1065
   Tasdizen T, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P125, DOI 10.1109/VISUAL.2002.1183766
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Taubin G., 2001, RC22213W0110051 IBM
   Wang CCL, 2006, IEEE T VIS COMPUT GR, V12, P629, DOI 10.1109/TVCG.2006.60
   Wang RM, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2557449
   Wei MQ, 2015, IEEE T VIS COMPUT GR, V21, P43, DOI 10.1109/TVCG.2014.2326872
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Zhang HY, 2015, IEEE T VIS COMPUT GR, V21, P873, DOI 10.1109/TVCG.2015.2398432
   Zhang WY, 2015, COMPUT GRAPH FORUM, V34, P23, DOI 10.1111/cgf.12742
   Zheng YY, 2011, IEEE T VIS COMPUT GR, V17, P1521, DOI 10.1109/TVCG.2010.264
NR 23
TC 13
Z9 13
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1827
DI 10.1002/cav.1827
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100018
DA 2024-07-18
ER

PT J
AU Baek, S
   Han, J
AF Baek, Seungho
   Han, JungHyun
TI Simulation of thin liquid jets with threads
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE fluid simulation; liquid jets; thin features
ID COLLISION
AB In a thin liquid jet from faucet, shower, fountain, etc., the initially smooth jet surface is gradually perturbed with time to eventually produce droplets. This paper proposes to model such a liquid jet with a thread. It is defined as a series of nodes and an edge connecting a pair of nodes is filled with volume particles. The jet's large-scale behavior is simulated by moving a relatively small number of nodes whereas the small-scale detail is described using the volume particles. The proposed method is capable of handling a large number of jets and describing the special effects, such as liquid chain and fishbone, produced by impinging jets. Furthermore, the proposed method can be neatly integrated into existing fluid simulation systems at a small cost.
C1 [Baek, Seungho] Korea Univ, 311 WooJung Informat & Commun Bldg, Seoul 02841, South Korea.
   [Han, JungHyun] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Korea University; Korea University
RP Han, J (corresponding author), Korea Univ, 311 WooJung Informat & Commun Bldg, Seoul 02841, South Korea.
EM jhan@korea.ac.kr
FU National Research Foundation of Korea (NRF) [NRF-2016R1A2B3014319]
FX National Research Foundation of Korea (NRF), Grant/Award Number:
   NRF-2016R1A2B3014319
CR Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Ashgriz N, 2011, HANDBOOK OF ATOMIZATION AND SPRAYS: THEORY AND APPLICATIONS, P685, DOI 10.1007/978-1-4419-7264-4_30
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bergou M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778853
   Bremond N, 2006, J FLUID MECH, V549, P273, DOI 10.1017/S0022112005007962
   Brochu T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778784
   Bush JWM, 2004, J FLUID MECH, V511, P285, DOI 10.1017/S002211200400967X
   Choo YJ, 2002, PHYS FLUIDS, V14, P622, DOI 10.1063/1.1429250
   Da F, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925899
   Eggers J, 2008, REP PROG PHYS, V71, DOI 10.1088/0034-4885/71/3/036601
   Hagedorn JG, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.056312
   He XW, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682630
   Hong JM, 2005, ACM T GRAPHIC, V24, P915, DOI 10.1145/1073204.1073283
   Hu XY, 2006, J COMPUT PHYS, V213, P844, DOI 10.1016/j.jcp.2005.09.001
   Jakob Wenzel, 2010, Mitsuba renderer
   Jung SJ, 2010, PHYS FLUIDS, V22, DOI 10.1063/1.3373513
   Li R, 2006, PHYS FLUIDS, V18, DOI 10.1063/1.2338064
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   MISZTAL M. K., 2010, P 7 WORKSH VIRT REAL
   Morris JP, 2000, INT J NUMER METH FL, V33, P333, DOI 10.1002/1097-0363(20000615)33:3<333::AID-FLD11>3.0.CO;2-7
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Panao MRO, 2014, EXP THERM FLUID SCI, V58, P170, DOI 10.1016/j.expthermflusci.2014.07.003
   Shen YB, 1998, J FLUID ENG-T ASME, V120, P482, DOI 10.1115/1.2820688
   Spillmann J, 2008, COMPUT GRAPH FORUM, V27, P497, DOI 10.1111/j.1467-8659.2008.01147.x
   Tartakovsky A, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.026301
   THUREY N., 2010, ACM T GRAPHIC, V29, P48
   Um K, 2014, COMPUT GRAPH FORUM, V33, P209, DOI 10.1111/cgf.12489
   Zhao F, 2015, J PROPUL POWER, V31, P1653, DOI 10.2514/1.B35751
   Zhu B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601201
NR 29
TC 1
Z9 1
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1768
DI 10.1002/cav.1768
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200014
DA 2024-07-18
ER

PT J
AU Haworth, B
   Usman, M
   Berseth, G
   Kapadia, M
   Faloutsos, P
AF Haworth, Brandon
   Usman, Muhammad
   Berseth, Glen
   Kapadia, Mubbasir
   Faloutsos, Petros
TI On density-flow relationships during crowd evacuation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE architectural optimization; crowd flow; crowd simulation
AB Traffic and pedestrian dynamics communities often use a standard qualitative classification, namely, level of service (LoS), to describe the relationship between the crowd flow and crowd density in an environment. However, this classification has not yet been rigorously studied in the application of synthetic crowds, which are derived using a variety of approaches and may model certain behaviors better than others. Although synthetic crowds can be simulated to extrapolate crowd flow for rigorous quantitative analysis, these may be at odds with the qualitative LoS. In order to successfully use computer-assisted design, it is important to have sound quantitative metrics as the basis for analysis and optimization. In this paper, we present a systematic empirical analysis of LoS for synthetic crowds. Using established crowd simulation techniques, we quantify the relation between crowd density and crowd flow for evacuation scenarios across different simulators to explore conformity to qualitative LoS classifications. Following this study, we perform environment optimization experiments under various LoS conditions. Finally, we test the generality of optimizing under these LoS conditions. Our results motivate the need for further study, using real and synthetic crowd datasets across representative environment benchmarks.
C1 [Haworth, Brandon; Usman, Muhammad; Faloutsos, Petros] York Univ, Dept Elect Engn & Comp Sci, Toronto, ON, Canada.
   [Berseth, Glen] Univ British Columbia, Dept Comp Sci, Vancouver, BC, Canada.
   [Kapadia, Mubbasir] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ USA.
C3 York University - Canada; University of British Columbia; Rutgers
   University System; Rutgers University New Brunswick
RP Haworth, B (corresponding author), York Univ, Dept Elect Engn & Comp Sci, Toronto, ON, Canada.
EM brandon@cse.yorku.ca
OI Berseth, Glen/0000-0001-7351-8028; Haworth, Brandon/0000-0001-8134-0047;
   Usman, Muhammad/0000-0003-2059-7206
CR Berseth G., 2014, P ACM SIGGRAPH EUR S, P1
   Berseth G, 2015, COMPUT ANIMAT VIRT W, V26, P377, DOI 10.1002/cav.1652
   Charalambous P, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12472
   Fruin John J., 1971, TECHNICAL REPORT
   Hansen M, 1996, IEEE C EVOL COMPUTAT, P312, DOI 10.1109/ICEC.1996.542381
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Helbing D, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.046109
   Jiang L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115463
   Johansson A, 2008, ADV COMPLEX SYST, V11, P497, DOI 10.1142/S0219525908001854
   Kapadia M., 2011, P 2011 ACM SIGGRAPH, P53, DOI DOI 10.1145/2019406.2019414
   Karamouzas I, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.238701
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Lerner A, 2010, COMPUT GRAPH FORUM, V29, P2197, DOI 10.1111/j.1467-8659.2010.01808.x
   Lerner A, 2009, LECT NOTES COMPUT SC, V5884, P75, DOI 10.1007/978-3-642-10347-6_7
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Narang S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117856
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rodriguez S, 2013, IEEE INT C INT ROBOT, P1327, DOI 10.1109/IROS.2013.6696521
   Seyfried A, 2010, PEDESTRIAN AND EVACUATION DYNAMICS 2008, P145, DOI 10.1007/978-3-642-04504-2_11
   Singh S, 2009, COMPUT ANIMAT VIRT W, V20, P533, DOI 10.1002/cav.277
   Singh Shawn., 2011, ACM SIGGRAPH I3D, P141
   Still GK, 2007, INT J CRIT INFRASTRU, V3, P376, DOI 10.1504/IJCIS.2007.014116
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Wolinski D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982442
   Wolinski D, 2014, TRANSP RES PROC, V2, P228, DOI 10.1016/j.trpro.2014.09.041
NR 27
TC 8
Z9 9
U1 4
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1783
DI 10.1002/cav.1783
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200028
DA 2024-07-18
ER

PT J
AU Tisserand, Y
   Cuel, L
   Magnenat-Thalmann, N
AF Tisserand, Yvain
   Cuel, Louis
   Magnenat-Thalmann, Nadia
TI Automatic 3D garment positioning based on surface metric
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE cloth simulation; garment positioning; surface metric minimisation;
   virtual try-on
AB Positioning virtual garments onto a 3D avatar is known to be a time-consuming process. This task is usually done manually if the proportion of the garment needs to be kept during the process for a fitting purpose. The positioning of the garment is currently the main limitation to propose a fully automatic virtual try-on application. This paper presents an automatic method based on surface energy minimisation that allows fully automatically positioning of a 3D virtual cloth without deformation of the patterns. The minimum of surface energy is reached by animating the humanoid avatar. Humanoid joints are manipulated to place a 3D avatar into the virtual garment. The proposed method, as well as its implementation, is described in this paper.
C1 [Tisserand, Yvain; Cuel, Louis; Magnenat-Thalmann, Nadia] Univ Geneva, MIRALab, Geneva, Switzerland.
   [Tisserand, Yvain; Magnenat-Thalmann, Nadia] Nanyang Technol Univ, Singapore, Singapore.
C3 University of Geneva; Nanyang Technological University
RP Tisserand, Y (corresponding author), Univ Geneva, MIRALab, Geneva, Switzerland.; Tisserand, Y (corresponding author), Nanyang Technol Univ, Singapore, Singapore.
EM yvain.tisserand@miralab.ch
RI Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Nadia/0000-0002-1459-5960; Tisserand,
   Yvain/0000-0001-9027-6497
FU European research project ViMM [CULT-COOP-8-2016 727107]
FX European research project ViMM Grant/Award Number: CULT-COOP-8-2016
   727107
CR [Anonymous], 2012, BAYESIAN APPROACH GL
   [Anonymous], 2009, THESIS U NICE SOPHIA
   [Anonymous], 2015, ACM COMPUT SURV, DOI DOI 10.1145/2668020
   Au OKC, 2010, COMPUT GRAPH FORUM, V29, P645, DOI 10.1111/j.1467-8659.2009.01634.x
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Boender C. G. E., 1995, HDB GLOBAL OPTIMIZAT, V2, P829, DOI 10.1007/978-1-4615-2025-2_15
   Bridson R., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P28
   Brouet R, 2012, SIGGRAPH 2012, V31
   Choi KJ, 2005, COMPUT AIDED DESIGN, V37, P585, DOI 10.1016/j.cad.2004.11.002
   Clegg A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766986
   Cordier F, 2002, COMPUT GRAPH FORUM, V21, P327, DOI 10.1111/1467-8659.t01-1-00592
   English E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360665
   Fuhrmann A, 2003, COMPUT GRAPH-UK, V27, P71, DOI 10.1016/S0097-8493(02)00245-5
   Giovanni Stevie, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P55, DOI 10.1007/978-3-642-34710-8_6
   GroB Clemens., 2003, P 18 SPRING C COMPUT, P99
   Gruen A, 2004, REMOTE SENSING SPATI, V5
   Guan P., 2013, THESIS BROWN U PROVI
   Hauswiesner S, 2011, P 10 INT C VIRT REAL, P23, DOI DOI 10.1145/2087756.2087759
   Horst R., 1996, Global Optimization Deterministic Approaches, V3rd
   Kasap M, 2011, VISUAL COMPUT, V27, P263, DOI 10.1007/s00371-011-0547-1
   Lee Y, 2013, COMPUT GRAPH-UK, V37, P911, DOI 10.1016/j.cag.2013.07.005
   Li Z, 2009, INT C COMP AID DES C, P74, DOI 10.1109/CADCG.2009.5246928
   Magnenat-Thalmann N, 2004, J COMPUT SCI TECH-CH, V19, P575, DOI 10.1007/BF02945583
   Magnenat-Thalmann N, 2010, MODELING AND SIMULATING BODIES AND GARMENTS, P161, DOI 10.1007/978-1-84996-263-6_5
   Pinter JD, 1991, SCI AM, V264, P54
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Volino P, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P265, DOI 10.1109/CGI.2001.934683
   Volino P, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P257, DOI 10.1109/CGI.2000.852341
   Wacker M., 2005, RES J TEXTILE APPARE, V9, P37
   Ye Mao, 2014, IEEE Trans Vis Comput Graph, V20, P550, DOI 10.1109/TVCG.2014.35
NR 31
TC 8
Z9 8
U1 1
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1770
DI 10.1002/cav.1770
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200016
DA 2024-07-18
ER

PT J
AU Nagendran, A
   Steed, A
   Kelly, B
   Pan, Y
AF Nagendran, Arjun
   Steed, Anthony
   Kelly, Brian
   Pan, Ye
TI Symmetric telepresence using robotic humanoid surrogates
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE 3D telepresence; telepresence robots; symmetric telepresence; robotic
   surrogates; remote robot control
AB Telepresence involves the use of virtual reality technology to facilitate apparent physical participation in distant events, including potentially performing tasks, while creating a sense of being in that location. Traditionally, such systems are asymmetric in nature where only one side (participant) is teleported to the remote location. In this manuscript, the authors explore the possibility of symmetric three-dimensional telepresence where both sides (participants) are teleported simultaneously to each other's location; the overarching concept of symmetric telepresence in virtual environments is extended to telepresence robots in physical environments. Two identical physical humanoid robots located in UK and the USA serve as surrogates while performing a transcontinental shared collaborative task. The actions of these surrogate robots are driven by capturing the intent of the participants controlling them in either location. Participants could communicate verbally but could not see the other person or the remote location while performing the task. The effectiveness of gesturing along with other observations during this preliminary experiment is presented. Results reveal that the symmetric robotic telepresence allowed participants to use and understand gestures in cases where they would otherwise have to describe their actions verbally. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Nagendran, Arjun] Univ Cent Florida, Inst Simulat & Training, Res, Orlando, FL 32816 USA.
   [Kelly, Brian] Univ Cent Florida, Inst Simulat & Training, Synthet Real Lab, Orlando, FL 32816 USA.
   [Steed, Anthony] UCL, Virtual Environm & Comp Graph VECG Grp, London, England.
   [Pan, Ye] UCL, Dept Comp Sci, Virtual Environm & Comp Graph Grp, London, England.
C3 State University System of Florida; University of Central Florida; State
   University System of Florida; University of Central Florida; University
   of London; University College London; University of London; University
   College London
RP Nagendran, A (corresponding author), Univ Cent Florida, Orlando, FL 32816 USA.
EM arjun@cs.ucf.edu
RI Nagendran, Arjun/F-1325-2014
OI Nagendran, Arjun/0000-0002-5318-2560; Steed, Anthony/0000-0001-9034-3020
FU Office of Naval Research (ONR) [N00014-12-1-0052, N00014-14-1-0248,
   N00014-12-1-1003]; BEAMING Project (EU FP7) [248629]; Engineering
   Doctorate Centre in Virtual Environments, Imaging and Visualisation
   (EPSRC) [EP/G037159/1]
FX The material presented in this publication is based on work supported in
   part by the Office of Naval Research (ONR) Code 30 (Program Manager-Dr.
   Peter Squire) (N00014-12-1-0052, N00014-14-1-0248, and
   N00014-12-1-1003), the BEAMING Project (EU FP7 grant number 248629), and
   the Engineering Doctorate Centre in Virtual Environments, Imaging and
   Visualisation (EPSRC grant number EP/G037159/1). Any opinions, findings,
   and conclusions or recommendations expressed in this material are those
   of the authors and do not necessarily reflect the views of the sponsors.
CR Adalgeirsson SO, 2010, ACMIEEE INT CONF HUM, P15, DOI 10.1109/HRI.2010.5453272
   Hancock PA, 2011, HUM FACTORS, V53, P517, DOI 10.1177/0018720811417254
   Lee MK, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P33
   Lincoln P, 2009, INT SYM MIX AUGMENT, P27, DOI 10.1109/ISMAR.2009.5336503
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Nagendran A., 2013, the Proceedings of the Virtual Reality Software Technology (VRST) Conference 2013, P143
   Nagendran A, 2014, PRESENCE-TELEOP VIRT, V23, P109, DOI 10.1162/PRES_a_00177
   Paulos E., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P296, DOI 10.1145/274644.274686
   Sakamoto D., 2007, Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction, P193, DOI [DOI 10.1145/1228716.1228743, 10.1145/1228716.1228743]
   Tachi S, 2003, ADV ROBOTICS, V17, P199, DOI 10.1163/156855303764018468
   Tsui KM, 2011, ACMIEEE INT CONF HUM, P11, DOI 10.1145/1957656.1957664
   Xiao Y, 2014, PRESENCE-VIRTUAL AUG, V23, P133, DOI 10.1162/PRES_a_00176
   Yim J., 2011, Ext. Abstracts CHI 2011, P781, DOI DOI 10.1145/1979742.197963
   Yumak Z, 2014, PRESENCE-TELEOP VIRT, V23, P172, DOI 10.1162/PRES_a_00179
NR 14
TC 11
Z9 11
U1 3
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 271
EP 280
DI 10.1002/cav.1638
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kim, Y
   Han, J
AF Kim, YoungBeom
   Han, JungHyun
TI Bulging-free dual quaternion skinning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE skinning animation; linear blend skinning; dual quaternion skinning
ID SPACE
AB The linear blend skinning has been the most popular skeletal animation algorithm and also notorious for the collapsing-joint and candy-wrapper artifacts. The dual quaternion skinning (DQS) successfully resolves the problems, but it reveals its own artifacts, which we name bulging joint and distorted normal. We propose to post-process the DQS algorithm; the bulging-joint artifact can be removed by correcting the vertex positions, and the distorted-normal artifact can be removed by correcting the vertex normals. The proposed method is simple yet quite effective. The experimental results show that the skinning animation quality is significantly improved. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Kim, YoungBeom; Han, JungHyun] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Korea University
RP Han, J (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM jhan@korea.ac.kr
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA) in the Culture Technology (CT) Research & Development
   Program; National Research Foundation of Korea (NRF) - Korean government
   (MEST) [NRF-2012R1A2A2A06047007]
FX This research is supported by the Ministry of Culture, Sports and
   Tourism (MCST) and Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) Research & Development Program 2013. It is also
   supported by the National Research Foundation of Korea (NRF) grant
   funded by the Korean government (MEST) (NRF-2012R1A2A2A06047007).
CR [Anonymous], 2005, P 2005 S INTERACTIVE, DOI [DOI 10.1145/1053427.10534294, DOI 10.1145/1053427.1053429]
   [Anonymous], 2001, P 2001 S INTERACTIVE
   [Anonymous], 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'02
   [Anonymous], 2002, P 2002 ACM SIGGRAPHE
   GREGORY A., 2008, ACM SIGGRAPH TALKS, P57
   Hejl J., 2004, Game Programming Gems, V4, P487
   Hyun DE, 2005, VISUAL COMPUT, V21, P542, DOI 10.1007/s00371-005-0343-x
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   KAVAN L., 2012, ACM T GRAPHIC, V31
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Merry B, 2006, ACM T GRAPHIC, V25, P1400, DOI 10.1145/1183287.1183294
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Vaillant R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461960
   Wang RY, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239524, 10.1145/1276377.1276468]
   Weber O, 2007, COMPUT GRAPH FORUM, V26, P265, DOI 10.1111/j.1467-8659.2007.01048.x
   Yang Xiaosong., 2006, Computer Graphics, Imaging and Visualisation, 2006 International Conference on, P323
NR 17
TC 18
Z9 18
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 323
EP 331
DI 10.1002/cav.1604
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300013
DA 2024-07-18
ER

PT J
AU Li, S
   Zhao, QP
   Wang, SF
   Hao, AM
   Qin, H
AF Li, Shuai
   Zhao, Qinping
   Wang, Shengfa
   Hao, Aimin
   Qin, Hong
TI Interactive deformation and cutting simulation directly using
   patient-specific volumetric images
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE volumetric image manipulation; patient-specific medical simulation;
   physics-based modeling; CUDA
ID SURGICAL SIMULATION; MODEL
AB This paper systematically advocates an interactive volumetric image manipulation framework, which can enable the rapid deployment and instant utility of patient-specific medical images in virtual surgery simulation while requiring little user involvement. We seamlessly integrate multiple technical elements to synchronously accommodate physics-plausible simulation and high-fidelity anatomical structures visualization. Given a volumetric image, in a user-transparent way, we build a proxy to represent the geometrical structure and encode its physical state without the need of explicit 3-D reconstruction. On the basis of the dynamic update of the proxy, we simulate large-scale deformation, arbitrary cutting, and accompanying collision response driven by a non-linear finite element method. By resorting to the upsampling of the sparse displacement field resulted from non-linear finite element simulation, the cut/deformed volumetric image can evolve naturally and serves as a time-varying 3-D texture to expedite direct volume rendering. Moreover, our entire framework is built upon CUDA (Beihang University, Beijing, China) and thus can achieve interactive performance even on a commodity laptop. The implementation details, timing statistics, and physical behavior measurements have shown its practicality, efficiency, and robustness. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Li, Shuai; Zhao, Qinping; Hao, Aimin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Wang, Shengfa] Dalian Univ Technol, Dalian, Liaoning, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 Beihang University; Dalian University of Technology; State University of
   New York (SUNY) System; State University of New York (SUNY) Stony Brook
RP Li, S (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM ls@vrlab.buaa.edu.cn
FU National Natural Science Foundation of China [61190120, 61190121,
   61190125]; National Science Foundation of USA [IIS-0949467, IIS-1047715,
   IIS-1049448]; Direct For Computer & Info Scie & Enginr; Div Of
   Information & Intelligent Systems [1047715] Funding Source: National
   Science Foundation
FX This research is supported in part by National Natural Science
   Foundation of China (No. 61190120, 61190121, and 61190125) and National
   Science Foundation of USA (No. IIS-0949467, IIS-1047715, and
   IIS-1049448). Thanks to the Chinese Visible Human Project for providing
   the volumetric images. We would like to thank the anonymous reviewers
   for their very constructive comments and suggestions that helped greatly
   improve this paper's quality.
CR Bao CB, 2008, INT CONF BIOMED, P575, DOI 10.1109/BMEI.2008.129
   Bruckner S, 2006, IEEE T VIS COMPUT GR, V12, P1077, DOI 10.1109/TVCG.2006.140
   Bürger K, 2008, IEEE T VIS COMPUT GR, V14, P1388, DOI 10.1109/TVCG.2008.120
   Chang J, 2004, COMPUT ANIMAT VIRT W, V15, P211, DOI 10.1002/cav.23
   Chao I, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778775
   Correa CD, 2006, IEEE T VIS COMPUT GR, V12, P1069, DOI 10.1109/TVCG.2006.144
   Correa CarlosD., 2007, Sixth Eurographics / IEEE VGTC Workshop on Volume Graphics, P91
   Correa CarlosD., 2006, Fifth Eurographics / IEEE VGTC Workshop on Volume Graphics, P9, DOI DOI 10.2312/VG/VG06/009-016
   Dick C, 2011, IEEE T VIS COMPUT GR, V17, P1663, DOI 10.1109/TVCG.2010.268
   Engel K, 2006, REAL TIME VOLUME GRA
   Fierz B, 2012, IEEE T VIS COMPUT GR, V18, P717, DOI 10.1109/TVCG.2011.105
   Fierz Basil, 2011, Proceedings of the 2011 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P257
   Fong P, 2009, INT J ROBOT RES, V28, P630, DOI 10.1177/0278364908100326
   Forest C., 2002, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2002. 5th International Conference. Proceedings, Part II (Lecture Notes in Computer Science Vol.2489), P235
   Fortmeier D., 2012, GERM C MED IMAG COMP, V2012, P117, DOI [10.1007/978-3-642-28502-8, DOI 10.1007/978-3-642-28502-8]
   Ganovelli F., 2002, J GRAPHICS TOOLS, V7, P17
   Hung KWC, 2011, INT J COMPUT ASS RAD, V6, P35, DOI 10.1007/s11548-010-0456-1
   Jerábková L, 2010, PROG BIOPHYS MOL BIO, V103, P217, DOI 10.1016/j.pbiomolbio.2010.09.012
   Jin X, 2012, COMPUTER METHODS BIO
   Masutani Y, 2004, PROC SPIE, V5367, P500, DOI 10.1117/12.535122
   McGuffin MJ, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P401, DOI 10.1109/VISUAL.2003.1250400
   Miller K, 2007, COMMUN NUMER METH EN, V23, P121, DOI 10.1002/cnm.887
   Miller K, 2005, J MECH MED BIOL, V5, P105, DOI 10.1142/S0219519405001254
   Mosegaard J, 2005, STUD HEALTH TECHNOL, V111, P342
   Nakao M, 2010, IEEE PAC VIS SYMP, P161, DOI 10.1109/PACIFICVIS.2010.5429597
   Noe KO, 2010, LECT NOTES COMPUT SC, V5958, P59, DOI 10.1007/978-3-642-11615-5_7
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Plass A, 2009, ANN THORAC SURG, V88, P1851, DOI 10.1016/j.athoracsur.2009.08.015
   Satava RM, 2008, WORLD J SURG, V32, P141, DOI 10.1007/s00268-007-9374-y
   Sifakis E, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P73
   Soler L, 2008, WORLD J SURG, V32, P208, DOI 10.1007/s00268-007-9329-3
   Sutherland LM, 2006, ANN SURG, V243, P291, DOI 10.1097/01.sla.0000200839.93965.26
   Takayama K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360652
   Taylor ZA, 2009, MED IMAGE ANAL, V13, P234, DOI 10.1016/j.media.2008.10.001
   Taylor ZA, 2008, IEEE T MED IMAGING, V27, P650, DOI 10.1109/TMI.2007.913112
   Wicke M, 2007, COMPUT GRAPH FORUM, V26, P355, DOI 10.1111/j.1467-8659.2007.01058.x
   Wittek A, 2007, J BIOMECH, V40, P919, DOI 10.1016/j.jbiomech.2006.02.021
NR 37
TC 9
Z9 12
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2014
VL 25
IS 2
BP 155
EP 169
DI 10.1002/cav.1543
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AE8SY
UT WOS:000334273500006
DA 2024-07-18
ER

PT J
AU Park, J
   Shim, M
   Park, SY
   Kang, Y
   Kim, MS
AF Park, Jaesung
   Shim, Minsub
   Park, Seon-Young
   Kang, Yunku
   Kim, Myung-Soo
TI Realistic deformation of 3D human blood vessels
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE blood vessel; deformation; collision detection and avoidance; sweep
   surface; BVH; sphere tree; LSS tree; B-splines
ID VIRTUAL HUMANS
AB We present a real-time algorithm for realistically deforming 3D human blood vessels, while automatically detecting and avoiding interference among a large number of blood vessels under deformation. Sweep surfaces are employed for this purpose. Using a dynamic bounding volume hierarchy, specially designed for sweep surfaces, we support collision detection and other related geometric computations in real time. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Park, Jaesung; Shim, Minsub; Kang, Yunku; Kim, Myung-Soo] Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151744, South Korea.
   [Park, Seon-Young] Seoul Natl Univ, Coll Med, Seoul 110799, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU)
RP Kim, MS (corresponding author), Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151744, South Korea.
EM mskim@snu.ac.kr
OI Park, Seon Young/0000-0002-1733-1987
FU College of Engineering of Seoul National University; College of Medicine
   of Seoul National University
FX This research was supported in part by the Collaborative Research
   Program between the College of Engineering and the College of Medicine
   of Seoul National University.
CR [Anonymous], 1999, TR99018 UNC DEP COMP
   Cao L., 2012, THESIS HONG KONG U
   Filip D., 1986, Computer-Aided Geometric Design, V3, P295, DOI 10.1016/0167-8396(86)90005-1
   Flannery B. P., 1992, NUMERICAL RECIPES C, DOI DOI 10.2277/052143064X
   Gabrys E, 2005, CHAOS SOLITON FRACT, V24, P707, DOI 10.1016/j.chaos.2004.09.087
   Hyun DE, 2005, VISUAL COMPUT, V21, P542, DOI 10.1007/s00371-005-0343-x
   Jayalalitha G, 2008, COMPUT BIOL MED, V38, P684, DOI 10.1016/j.compbiomed.2008.03.002
   Kim YJ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024203
   Kirbas C, 2004, ACM COMPUT SURV, V36, P81, DOI 10.1145/1031120.1031121
   Krishnamurthy A, 2011, COMPUT AIDED DESIGN, V43, P1370, DOI 10.1016/j.cad.2011.08.022
   Lee J, 2006, COMPUT ANIMAT VIRT W, V17, P479, DOI 10.1002/cav.150
   Magnenat-Thalmann N, 2005, VISUAL COMPUT, V21, P997, DOI 10.1007/s00371-005-0363-6
   Magnenat-Thalmann N, SIGGRAPH AS 2008 COU
   Magnenat-Thalmann Nadia., 2004, HDB VIRTUAL HUMANS
   Netter Frank., 2006, ATLAS HUMAN ANATOMY
   Park S, 2008, ACM TOG, V27
   Park SI, 2006, ACM T GRAPHIC, V25, P881, DOI 10.1145/1141911.1141970
   Prusinkiewicz P., 1990, ALGORITHMIC BEAUTY P
   Prusinkiewicz P., 1997, ADV COMPUTATIONAL LI, P1
   Rhodes G, 2001, GAME PROGRAMMING GEM, V2, P191
   Scheeppers F, 1997, COMPUTER GRAPHICS, P163
   van Welbergen H, 2010, COMPUT GRAPH FORUM, V29, P2530, DOI 10.1111/j.1467-8659.2010.01822.x
   Zhang Yongjie, 2007, Comput Methods Appl Mech Eng, V196, P2943
NR 23
TC 5
Z9 5
U1 2
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 317
EP 325
DI 10.1002/cav.1510
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500019
DA 2024-07-18
ER

PT J
AU Kokkinara, E
   Oyekoya, O
   Steed, A
AF Kokkinara, Elena
   Oyekoya, Oyewole
   Steed, Anthony
TI Modelling selective visual attention for autonomous virtual characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation; attention; autonomous virtual characters
ID EYE; BEHAVIORS
AB Autonomous virtual characters (AVCs) are becoming more prevalent both for real-time interaction and also as digital actors in film and TV production. AVCs require believable virtual human animations, accompanied by natural attention generation, and thus the software that controls the AVCs needs to model when and how to interact with the objects and other characters that exist in the virtual environment. This paper models automatic attention behaviour using a saliency model that generates plausible targets for combined gaze and head motions. The model was compared with the default behaviour of the Second Life (SL) system in an object observation scenario while it was compared with real actors' behaviour in a conversation scenario. Results from a study run within the SL system demonstrate a promising attention model that is not just believable and realistic but also adaptable to varying task, without any prior knowledge of the virtual scene. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Kokkinara, Elena; Oyekoya, Oyewole; Steed, Anthony] UCL, Virtual Environm & Comp Graph Grp, Dept Comp Sci, London WC1E 6BT, England.
C3 University of London; University College London
RP Kokkinara, E (corresponding author), Univ Pompeu Fabra, Synthet Percept Emot & Cognit Syst Mixed Real Lab, Roc Boronat 138, Barcelona 08018, Spain.
EM redarahel@gmail.com
OI Steed, Anthony/0000-0001-9034-3020
FU EPSRC; EU
FX We would like to thank the following sponsors: EPSRC Eyecatching, EU
   Presenccia and EU Beaming.
CR Bilvi M, 2003, INT C AUT AG MULT SY
   Cranefield S, 2010, LECT NOTES ARTIF INT, V6069, P133, DOI 10.1007/978-3-642-14962-7_9
   Friedman D, 2007, LECT NOTES ARTIF INT, V4722, P252
   Gillies MFP, 2002, J VISUAL COMP ANIMAT, V13, P287, DOI 10.1002/vis.296
   Grillon H, 2009, COMPUT ANIMAT VIRT W, V20, P111, DOI 10.1002/cav.293
   Gu E, 2006, LECT NOTES ARTIF INT, V4133, P193
   Istance H, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P221, DOI 10.1145/1344471.1344523
   Itti L, 2003, PROC SPIE, V5200, P64, DOI 10.1117/12.512618
   Itti L, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P521, DOI 10.1109/ICME.2006.262440
   Khullar SC, 2001, AUTON AGENT MULTI-AG, V4, P9, DOI 10.1023/A:1010010528443
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Ma XH, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P143, DOI 10.1109/VR.2009.4811014
   Masuko S, 2007, COMPUT GRAPH FORUM, V26, P303, DOI 10.1111/j.1467-8659.2007.01052.x
   Oyekoya Oyewole., 2009, Proceedings of the 16th acm symposium on virtual reality software and technology, P199, DOI [10.1145/1643928.1643973, DOI 10.1145/1643928.1643973]
   Pashler H, 1998, PSYCHOL ATTENTION
   Peters C, 2003, COMP ANIM CONF PROC, P111, DOI 10.1109/CASA.2003.1199311
   Poggi I, 2000, AI COMMUN, V13, P169
   Rikert TD, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P436, DOI 10.1109/AFGR.1998.670987
   Rymaszewski M., 2006, 2 LIFE OFFICIAL GUID
   Thalmann D, 2000, WORKSH ACH HUM LIK B
   Vinayagamoorthy V, 2004, COMPUT GRAPH FORUM, V23, P1, DOI 10.1111/j.1467-8659.2004.00001.x
NR 21
TC 7
Z9 10
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL-AUG
PY 2011
VL 22
IS 4
BP 361
EP 369
DI 10.1002/cav.425
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 825OW
UT WOS:000295290400005
DA 2024-07-18
ER

PT J
AU Hwang, H
   Kim, K
   Ribera, RBI
   Noh, J
AF Hwang, Huicheol
   Kim, Kyehyun
   Blanco i Ribera, Roger
   Noh, Junyong
TI Stereoscopic image generation of background terrain scenes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE terrain geometry; stereoscopic; compositing; 2D to 3D conversion
ID 3D
AB The reconstruction of 3D terrain geometry from images is essential for compositing CG objects into a live-action background or for 2D to 3D conversion of terrain scenes. We present a novel mesh refinement algorithm for the creation of stereoscopic images of terrain scenes. Previous approaches emphasise the smoothness of the resulting terrain mesh over accuracy [1]. Point cloud-based methods cannot effectively recover the entire surface, leading to visual discrepancies after monocular sequences are converted into 3D stereo. As misalignment or inaccurate 3D terrain data over corresponding 2D background images can result in visual fatigue when stereo sequences are generated, ensuring accuracy of the reconstructed geometry is very important. To achieve the necessary accuracy, our method evaluates mesh errors utilising a texture projection onto the geometry and refines the mesh using Laplacian-based editing. Our algorithm automatically generates stereoscopic images of terrain scenes. In addition, our method simplifies identification and compositing of foreground objects on the terrain geometry. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Hwang, Huicheol; Kim, Kyehyun; Blanco i Ribera, Roger] Korea Adv Inst Sci & Technol, GSCT, Visual Media Lab, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Hwang, H (corresponding author), Korea Adv Inst Sci & Technol, GSCT, Visual Media Lab, 335 Gwahak Ro, Taejon 305701, South Korea.
EM hc0728.hwang@kaist.ac.kr
RI Noh, Junyong/C-1663-2011
CR [Anonymous], CVPR
   [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Beardsley P., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P683
   DANIEL GA, 2009, ACM T GRAPHICS, V29
   Jiang Ze-tao, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P327, DOI 10.1109/CSIE.2009.144
   Knorr S, 2008, SIGNAL PROCESS-IMAGE, V23, P665, DOI 10.1016/j.image.2008.07.004
   KUNTER M, 2009, SPIES ELECT IMAGING
   Lang M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778812
   Lindstrom P, 2002, IEEE T VIS COMPUT GR, V8, P239, DOI 10.1109/TVCG.2002.1021577
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   McKenzie Alexander, 2008, Journal of Computing Science and Engineering, V2, P98, DOI 10.5626/JCSE.2008.2.1.098
   Nistér D, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P438, DOI 10.1109/TDPVT.2004.1335271
   POLLEFEYS M, 1998, 3D STRUCTURE MUTIPLE, P138
   SAMOZINO M., 2006, SGP 06, P51
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
NR 18
TC 1
Z9 1
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 317
EP 323
DI 10.1002/cav.415
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700028
DA 2024-07-18
ER

PT J
AU Liao, J
   Yu, JH
   Patterson, J
AF Liao, Jing
   Yu, Jinhui
   Patterson, John
TI Modeling ocean waves and interaction between objects and ocean water for
   cartoon animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE effects; model; ocean water; cartoon animation
AB We present a scheme for the animation of ocean waves in a recognizable drawn animation cartoon style. This consists principally of two parts: the first part is the ocean surface generated by a procedural model which governs the dynamics of the ocean surface and rendered with stylized whitewater forms over the ocean wave crests; the second part is water effects caused by interactions between the ocean water and obstacle objects, such as waves crashing against obstacles-like rocks or boats and forms surrounding objects, and those effects are simulated with different hierarchical models. The ocean surface can be used either alone or in conjunction with effects caused by the interactions according to the scene. With minimum user intervention, i.e., specification of a few parameters, our model is able to generate cartoon ocean wave animations using these procedural methods, as shown by examples given in the paper. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Liao, Jing; Yu, Jinhui] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Patterson, John] Univ Glasgow, Dept Comp Sci, Glasgow G12 8QQ, Lanark, Scotland.
C3 Zhejiang University; University of Glasgow
RP Yu, JH (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM jhyu@cad.zju.edu.cn
OI LIAO, Jing/0000-0001-7014-5377
CR Adabala N, 2002, COMPUT GRAPH FORUM, V21, P65, DOI 10.1111/1467-8659.00566
   DIFIORE F, 2004, P COMP AN SOC AG CAS, P171
   EDEN AM, 2007, P GRAPH INT 07, V31, P51
   Fournier A., 1986, Computer Graphics, V20, P75, DOI 10.1145/15886.15894
   Gonzato JC, 2000, J VISUAL COMP ANIMAT, V11, P27, DOI 10.1002/(SICI)1099-1778(200002)11:1<27::AID-VIS214>3.0.CO;2-5
   Iglesias A, 2004, FUTURE GENER COMP SY, V20, P1355, DOI 10.1016/j.future.2004.05.026
   MASTIN GA, 1987, IEEE COMPUT GRAPH, V7, P16, DOI 10.1109/MCG.1987.276961
   PEACHEY DR, 1986, P SIGGRAPH 86, V20, P65
   TESSENDORF J, 2001, SIGGR 2001 COURS 47
   Thon Sebastien., 2001, P 2001 INT EUROGRAPH, P53
   THORNTON JD, 2006, P SIGGRAPH 06 SKETCH
   TSO PY, 1987, ACM T GRAPHIC, V6, P191, DOI 10.1145/35068.35070
   Yu JH, 2008, COMPUT ANIMAT VIRT W, V19, P375, DOI 10.1002/cav.239
   Yu JH, 2007, COMPUT ANIMAT VIRT W, V18, P405, DOI 10.1002/cav.207
NR 14
TC 5
Z9 6
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 81
EP 89
DI 10.1002/cav.400
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700002
DA 2024-07-18
ER

PT J
AU Li, SQ
   Xu, C
AF Li, Shiqi
   Xu, Chi
TI Efficient lookup table based camera pose estimation for augmented
   reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; camera pose estimation; lookup table
ID TRACKING
AB Until now, exising camera pose estimation methods for the widely used square marker-based augmented reality (AR) are either highly sensitive to noise or much time consuming, and developers have to work hard to find the proper trade-off between computational speed and quality in mobile AR applications where computational resources are limited. The major difficulty is that only the four corner points of the square AR marker are available, and no redundant point correspondences can be used for a stable estimation. To solve this problem, an efficient lookup table (LUT)-based non-iterative solution is presented in this paper that achieves high stability in the presence of noise better than the most robust and accurate iterative solutions in the field, with the same level of accuracy and a much lower computational complexity. Our central idea consists of extracting a key parameter beta from the camera pose and creating a LUT for beta by taking the symmetrical structure of the square marker into account, thereby exploiting additional information. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Li, Shiqi; Xu, Chi] Huazhong Univ Sci & Technol, Sch Mech Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Xu, C (corresponding author), Huazhong Univ Sci & Technol, Sch Mech Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM xuchi.hust@yahoo.com.cn
CR ABIDI MA, 1995, IEEE T PATTERN ANAL, V17, P534, DOI 10.1109/34.391388
   [Anonymous], 2007, Proc. CVWW '07
   Ansar A, 2003, IEEE T PATTERN ANAL, V25, P578, DOI 10.1109/TPAMI.2003.1195992
   Araujo H, 1998, COMPUT VIS IMAGE UND, V70, P227, DOI 10.1006/cviu.1997.0632
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BOUTHEMY P, 1989, IEEE T PATTERN ANAL, V11, P499, DOI 10.1109/34.24782
   BUJNAK M, 2008, IEEE C COMP VIS PATT, P1
   Claus D, 2004, LECT NOTES COMPUT SC, V2034, P469
   FIALA M, 2005, IEEE COMP SOC C COMP, V2
   Fischer J, 2007, COMPUT GRAPH-UK, V31, P39, DOI 10.1016/j.cag.2006.09.007
   *GRAZ U, 2009, HANDH AUGM REAL PROJ
   JONIETZ E, 2007, MIT TECHNOLOGY REV
   Kalkofen D., 2007, P INT S MIXED AUGMEN, P191, DOI [10.1109/ISMAR.2007.4538846, DOI 10.1109/ISMAR.2007.4538846]
   Klein G, 2009, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2009.5336495
   Klein George, 2007, P1
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199
   MALIK S, 2002, P VIS INT
   Papagiannakis G, 2008, COMPUT ANIMAT VIRT W, V19, P3, DOI 10.1002/cav.221
   Rohs M., 2007, J VIRTUAL REALITY BR, V4
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Schall G, 2009, PERS UBIQUIT COMPUT, V13, P281, DOI 10.1007/s00779-008-0204-5
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252
   Taylor S., 2009, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR'09), P15
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Wang XY, 2006, AUTOMAT CONSTR, V15, P314, DOI 10.1016/j.autcon.2005.06.002
   Yuan ML, 2005, COMPUT GRAPH-UK, V29, P980, DOI 10.1016/j.cag.2005.09.014
   Zhang X, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P97, DOI 10.1109/ISMAR.2002.1115078
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhu JJ, 2010, COMPUT ANIMAT VIRT W, V21, P509, DOI 10.1002/cav.326
NR 30
TC 11
Z9 14
U1 1
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2011
VL 22
IS 1
BP 47
EP 58
DI 10.1002/cav.385
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 727SD
UT WOS:000287820600005
DA 2024-07-18
ER

PT J
AU Steptoe, W
   Oyekoya, O
   Steed, A
AF Steptoe, William
   Oyekoya, Oyewole
   Steed, Anthony
TI Eyelid kinematics for virtual characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE eyelid kinematics; facial animation; parametric modelling; virtual
   humans
ID MOVEMENTS
AB When compared to gaze, animation of the eyelids has been largely overlooked in the computer graphics literature. Eyelid movement plays an important part both in conveying accurate gaze direction and in improving the visual appearance of virtual characters. Eyelids have two major motion components: lid saccades that follow the vertical rotation the eyes, and blinking. Derived from literature in ophthalmology and psychology, this paper presents parametric models for both motion types, and emphasizes their dynamic temporal behaviour. Experimental validation classifies model-generated animation as similar to that encoded from expensive motion captured data, and significantly exceeding linearly interpolated animation. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Steptoe, William; Steed, Anthony] UCL, Dept Comp Sci, Virtual Environm & Comp Graph Grp, London WC1E 6BT, England.
C3 University of London; University College London
RP Steptoe, W (corresponding author), UCL, Dept Comp Sci, Virtual Environm & Comp Graph Grp, London WC1E 6BT, England.
EM W.Steptoe@cs.ucl.ac.uk
OI Steed, Anthony/0000-0001-9034-3020
CR Albrecht I, 2002, ADVANCES IN MODELLING, ANIMATION AND RENDERING, P283
   [Anonymous], 2008, Comput. Entertain., DOI [DOI 10.1145/1394021.1394034, 10.1145/1394021.1394034]
   Banf M, 2009, COMPUT GRAPH FORUM, V28, P659, DOI 10.1111/j.1467-8659.2009.01406.x
   BECKER W, 1988, J NEUROPHYSIOL, V60, P1227, DOI 10.1152/jn.1988.60.4.1227
   Bitouk D, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P107
   Breton G., 2001, P 6 INT C 3D WEB TEC, P15
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Deng ZG, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.35
   Engbert R, 2003, VISION RES, V43, P1035, DOI 10.1016/S0042-6989(03)00084-1
   EVINGER C, 1991, INVEST OPHTH VIS SCI, V32, P387
   Garau M, 2006, COMP SUPP COMP W SER, V34, P17
   GORDON G, 1951, BRIT J OPHTHALMOL, V35, P339, DOI 10.1136/bjo.35.6.339
   HALL A, 1945, BRIT J OPHTHALMOL, V29, P445, DOI 10.1136/bjo.29.9.445
   HALL ARTHUR J., 1936, BRIT JOUR OPHTHAL MOL, V20, P257, DOI 10.1136/bjo.20.5.257
   HAWES MJ, 1982, ARCH OPHTHALMOL-CHIC, V100, P1313
   ITTI L, 2004, P SOC PHOTO-OPT INS, V5200, P64
   KENNARD DW, 1964, J NERV MENT DIS, V139, P31, DOI 10.1097/00005053-196407000-00004
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Ma XH, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P143, DOI 10.1109/VR.2009.4811014
   Malbouisson JMC, 2005, INVEST OPHTH VIS SCI, V46, P857, DOI 10.1167/iovs.04-1086
   OYEKOYA O, 2009, P 16 ACM S VIRT REAL, P199
   Parke F., 1996, COMPUTER FACIAL ANIM
   PETERS C, 2003, INT C COMP GRAPH INT, P1
   STEPTOE W, 2010, P 28 INT C HUM FACT
   Steptoe W, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P111
   Steptoe W, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P83, DOI 10.1109/VR.2009.4811003
   STERN JA, 1994, HUM FACTORS, V36, P285, DOI 10.1177/001872089403600209
   TAKASHIMA K, 2008, P GRAPH INT, P169, DOI DOI 10.1145/1375714.1375744
   Tateno K, 2005, International Symposium on Mixed and Augmented Reality, Proceedings, P100
   VanderWerf F, 2003, J NEUROPHYSIOL, V89, P2784, DOI 10.1152/jn.00557.2002
   VANGISBERGEN JAM, 1981, J NEUROPHYSIOL, V45, P417, DOI 10.1152/jn.1981.45.3.417
   Vilhjalmsson H. H., 1998, Proceedings of the Second International Conference on Autonomous Agents, P269, DOI 10.1145/280765.280843
   Vinayagamoorthy V, 2004, COMPUT GRAPH FORUM, V23, P1, DOI 10.1111/j.1467-8659.2004.00001.x
   Weissenfeld A, 2010, VISUAL COMPUT, V26, P1201, DOI 10.1007/s00371-009-0401-x
   Williams L., 1990, Proceedings of SIGGRAPH, V24, P235
   WOUTERS RJ, 1995, INVEST OPHTH VIS SCI, V36, P2686
NR 36
TC 13
Z9 16
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 161
EP 171
DI 10.1002/cav.354
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400004
DA 2024-07-18
ER

PT J
AU Kim, Y
   Lee, K
   Kim, W
AF Kim, Youngjun
   Lee, Kunwoo
   Kim, Wontae
TI 3D virtual simulator for breast plastic surgery
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE 3D human modeling; image-based modeling; breast surgery; simulation
AB We have proposed novel 3D virtual simulation software for breast plastic surgery. Our software comprises two processes: a 3D torso modeling and a virtual simulation of the surgery result. First, image-based modeling is performed ill order to obtain a female subject's 3D torso data. Our image-based modeling method utilizes a template model, and this is deformed according to the patient's photographs. For the deformation, we applied procrustes analysis and radial basis functions (RBF). In order to enhance reality, the subject's photographs are snapped onto a mesh. Second, from the modeled subject data, we simulate the subject's virtual appearance after the plastic surgery by morphing the shape of the breasts. We solve the simulation problem by all example-based approach. The subject's virtual shape is obtained from the relations between the pair sets of feature points from previous patients' photographs obtained before and after the surgery. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Kim, Youngjun] Seoul Natl Univ, Human Ctr CAD Lab, Sch Mech & Aerosp Engn, Seoul, South Korea.
   [Kim, Wontae] Sogang Univ, Dept Comp Sci, Seoul, South Korea.
C3 Seoul National University (SNU); Sogang University
RP Kim, Y (corresponding author), Seoul Natl Univ, Human Ctr CAD Lab, Sch Mech & Aerosp Engn, Shilim 9 Dong, Seoul, South Korea.
EM yjkim@cad.snu.ac.kr
CR Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   *AM SOC PLAST SURG, 2007 REP 2006 STAT
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2001, P 2001 S INTERACTIVE
   ANSARI AN, 2003, P IEEE C ADV VID SIG
   Balaniuk Remis, 2006, ANN 8 S VIRTUAL REAL, P387
   *BEF, KAER SARL
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Carr JC, 1997, IEEE T MED IMAGING, V16, P96, DOI 10.1109/42.552059
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   GOWER J., 2004, Procrustes Problems
   HWANG B, 2000, INT C PATT REC ICPR, V2, P838
   Hwang BW, 2003, IEEE T PATTERN ANAL, V25, P365, DOI 10.1109/TPAMI.2003.1182099
   LEE HS, 2004, THESIS SEOUL NATL U
   Lee HY, 2004, APPL ERGON, V35, P353, DOI 10.1016/j.apergo.2004.03.004
   Lee W, 2000, COMPUT GRAPH FORUM, V19, pC1, DOI 10.1111/1467-8659.00392
   NOH J, 2000, ACM VIRTUAL REALITY
   Ohtake Y, 2001, COMPUT AIDED DESIGN, V33, P789, DOI 10.1016/S0010-4485(01)00095-1
   Park IK, 2005, EURASIP J APPL SIG P, V2005, P2072, DOI 10.1155/ASP.2005.2072
   *PLAST SURG GROUP, MIRR DIG IM
   Seo H, 2004, GRAPH MODELS, V66, P1, DOI 10.1016/j.gmod.2003.07.004
   SEO H, 2006, EDUTAINMENT 2006, P849
   Seo H, 2007, COMPUT ANIMAT VIRT W, V18, P141, DOI 10.1002/cav.169
   THALMANN NM, 2004, J COMPUTER SCI TECHN, V19, P575
   Zhang MD, 2004, I C COMP GRAPH IM VI, P165
   INAMODEL
NR 26
TC 13
Z9 18
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 515
EP 526
DI 10.1002/cav.237
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200032
DA 2024-07-18
ER

PT J
AU Han, S
   Lim, M
   Lee, D
   Hyun, SJ
AF Han, Seunghyun
   Lim, Mingyu
   Lee, Dongman
   Hyun, Soon J.
TI A scalable interest management scheme for distributed virtual
   environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE distributed virtual environment; interest management; multicast;
   scalability; sub-region; user interest group
AB With the expansion of the internet and its bandwidth, distributed virtual environment (DVE) applications have become more prevalent. In DVE applications, users frequently crowd in a specific place, and a key aspect to consider is how to provide interactive performance for users. However, existing approaches using multicast require users to receive uninteresting messages. Even though recent works have addressed fine-grained filtering, they still incur other drawbacks in terms Of assigning lots of multicast addresses or handling overhead of multicast groups. This makes the system less scalable as the number of users increases. In this paper, we propose a new scalable filtering scheme that reduces not only the number of messages during interaction in a region and among neighboring regions, but also the number of multicast addresses without significant computational overhead. Interest management in a region dynamically creates groups of users with the same interests. While members communicate with each other with high fidelity, a representative sends information to non-members with low frequency. For interaction among neighboring regions, we propose a sub-region concept to select only a subset of users from the neighboring regions based on proximity, the distribution of the users' locations, and the viewing direction of a user. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 [Lee, Dongman] Informat & Commun Univ, Taejon, South Korea.
RP Lee, D (corresponding author), Informat & Commun Univ, 119 Munjiro, Taejon, South Korea.
EM dennis@icu.ac.kr
RI Lim, Mingyu/D-3819-2011; Lee, Dongman/C-1728-2011; Hyun, Soon
   Joo/C-1748-2011
OI Lim, Mingyu/0000-0002-3749-1902; 
CR ABRAMS HA, 1999, THESIS NAV POSTGR SC
   [Anonymous], 1995, ACM Transactions on Computer-Human Interaction (TOCHI), DOI DOI 10.1145/210079.210088
   Barrus JW, 1996, IEEE COMPUT GRAPH, V16, P50, DOI 10.1109/38.544072
   Benford S, 1997, PROCEEDINGS OF THE FIFTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P189
   Capps M, 2000, IEEE COMPUT GRAPH, V20, P12, DOI 10.1109/38.865873
   CAREY R, 2001, 147722 ISO IEC
   Ding Dawei, 2003, P ACM S VIRTUAL REAL, P223
   Frécon E, 2001, PRESENCE-TELEOP VIRT, V10, P109, DOI 10.1162/105474601750182351
   Greenhalgh C., 2000, Proceedings of the third international conference on Collaborative virtual environments, P119, DOI DOI 10.1145/351006.351027
   Hagsand O, 1996, IEEE MULTIMEDIA, V3, P30, DOI 10.1109/93.486702
   HAN S, 2002, P INT C VIRT SYST MU
   *IEEE, 2001, 151612000 IEEE
   LEE D, 2002, P 4 INT C COLL VIRT, P47
   Léty E, 2004, IEEE ACM T NETWORK, V12, P247, DOI 10.1109/TNET.2004.826276
   LIM M, 2005, P COLLABTECH2005, P34
   LIU C, 2004, P 1 IEEE CONS COMM N, P477
   MACEDONIA MR, 1995, IEEE COMPUT GRAPH, V15, P38, DOI 10.1109/38.403826
   Macedonia MR, 1997, IEEE MULTIMEDIA, V4, P48, DOI 10.1109/93.580395
   Morse KL, 2000, PRESENCE-TELEOP VIRT, V9, P52, DOI 10.1162/105474600566619
   Ng B., 2002, VRST 02, P163
   Oliveira J.C., 2003, Presence, V12, P555
   PRYCE N, 1997, P 4 UK VR SIG C NOV
   *REAL TIM VIS CO, X3DBROWSER
   Singhal SK, 1996, INT CON DISTR COMP S, P196, DOI 10.1109/ICDCS.1996.507917
   SINGLIAL S, 1999, NETWORKED VIRTNAL EN
   Steed A., 2003, VRST '03: Proceedings of the ACM symposium on Virtual reality software and technology, P7
   Van Hook D. J., 1994, P 11 DIS WORKSH STAN, P367
NR 27
TC 3
Z9 3
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2008
VL 19
IS 2
BP 129
EP 149
DI 10.1002/cav.218
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 296PY
UT WOS:000255559500005
DA 2024-07-18
ER

PT J
AU Pei, Y
   Zha, HB
AF Pei, Yuru
   Zha, Hongbin
TI Stylized synthesis of facial speech motions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE speech animation; visyllable dynamic model; stylized synthesis;
   decomposable; generalized mapping
AB Stylized synthesis of facial speech motions is central to facial animation. Most synthesis algorithms put emphasis on the reasonable concatenation of captured motion segments. The dynamic modeling of speech units, e.g. visemes and visyllables (the visual appearance of a syllable), has not drawn much attention. In this paper, we address the fundamental issues regarding the stylized dynamic modeling of visyllables. The decomposable generalized model is learnt for the stylized motion synthesis. The visyllable modeling includes two parts: (1) A dynamic model for each kind of visyllable that is learnt based on a Gaussian Process Dynamical Model; (2) A multilinear model based unified mapping between the high dimensional observation space and low dimensional latent space. The dynamic visyllable model embeds the high dimensional motion data, and constructs the dynamic mapping in the latent space simultaneously. To generalize the visyllable model from several instances, the mapping coefficient matrices are assembled to a tensor, which is decomposed into independent modes, e.g. identity and uttering styles. Therefore, with the linear combination Of components in each mode, the novel stylized motions can be synthesized. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Peking Univ, State Key Lab Mach Percept, Beijing, Peoples R China.
C3 Peking University
RP Pei, Y (corresponding author), Peking Univ, State Key Lab Mach Percept, Sci Bldg 2,5 Yiheyuan Rd, Beijing, Peoples R China.
EM peiyuru@cis.pku.edu.cn
CR Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537
   Bregler C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P353, DOI 10.1145/258734.258880
   Cao Y, 2005, ACM T GRAPHIC, V24, P1283, DOI 10.1145/1095878.1095881
   Deng ZG, 2006, IEEE T VIS COMPUT GR, V12, P1523, DOI 10.1109/TVCG.2006.90
   ELGAMMAL A, 2004, CVPR 04, P478
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   King SA, 2005, IEEE T VIS COMPUT GR, V11, P341, DOI 10.1109/TVCG.2005.43
   Kshirsagar S, 2003, COMPUT GRAPH FORUM, V22, P631, DOI 10.1111/1467-8659.t01-2-00711
   Lawrence ND, 2004, ADV NEUR IN, V16, P329
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   Ma JY, 2006, IEEE T VIS COMPUT GR, V12, P266, DOI 10.1109/TVCG.2006.18
   Pei Y, 2007, IEEE T VIS COMPUT GR, V13, P58, DOI 10.1109/TVCG.2007.22
   Rahimi A, 2005, PROC CVPR IEEE, P868
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Urtasun R., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P238, DOI DOI 10.1109/CVPR.2006.15
   Vasilescu MAO, 2003, PROC CVPR IEEE, P93
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   WANG JM, 2005, NIPS, P1441
   WANG Q, 2003, CVPR, P227
   Wang Y, 2004, COMPUT GRAPH FORUM, V23, P677, DOI 10.1111/j.1467-8659.2004.00800.x
NR 21
TC 4
Z9 4
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 517
EP 526
DI 10.1002/cav.186
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000030
DA 2024-07-18
ER

PT J
AU Yang, X
   Zhang, JJ
AF Yang, Xiaosong
   Zhang, Jian J.
TI Automatic muscle generation for character skin deformation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character skin deformation; anatomy-based character animation
AB As skin shape depends oil the underlying anatomical structure, the anatomy-based techniques usually afford greater realism than the traditional skeleton-driven approach. Oil the downside, however, it is against the current animation workflow, as the animator has to model many individual muscles before the final skin layer arrives, resulting in an unintuitive modelling process. In this paper, we present a new anatomy-based technique that allows the animator to start from an already modelled character. Muscles having visible influence oil the skin shape at the rest pose are extracted automatically by studying the surface geometry of the skin. The extracted muscles are then used to deform the skin in areas Where there exist complex deformations. The remaining skin areas, unaffected or hardly affected by the muscles, are handled by the skeleton-driven technique, allowing both techniques to play their strengths. In order for the extracted muscles to produce realistic local skin deformation during animation, muscle bulging and special movements are both represented. Whereas the former ensues volume preservation, the latter allows a muscle not only to deform along a straight path, but also to slide and bend around joints and bones, resulting in the production of sophisticated muscle movements and deformations. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Bournemouth Univ, Bournemouth Media Sch, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University
RP Zhang, JJ (corresponding author), Bournemouth Univ, Bournemouth Media Sch, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
EM jzhang@bournemouth.ac.uk
OI Yang, Xiaosong/0000-0003-3815-0584
CR Albrecht Irene., 2003, P 2003 ACM SIGGRAPHE, P98
   Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626
   [Anonymous], 2002, P 2002 ACM SIGGRAPHE
   AUBEL A, 2000, TC5WG510 IFIP
   Chadwick J. E., 1989, Computer Graphics, V23, P243, DOI 10.1145/74334.74358
   CHEW LP, 1989, ALGORITHMICA, V4, P97, DOI 10.1007/BF01553881
   EKOULE AB, 1991, ACM T GRAPHIC, V10, P182, DOI 10.1145/108360.108363
   IGARASHI T, 1999, ACM SIGGRAPH 99
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   MAGNENATTHALMAN.N, P GRAPH INT 88 EDM A, P26
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   NEDEL L, 1998, P COMP AN IEEE COMP
   PRATSCHER M, P 2005 ACM SIGGR EUR, P329
   SCHEEPERS CF, 1996, THESIS OHIO STATE U
   SCHEEPERS F, 1997, P 24 ANN C COMP GRAP, P163, DOI DOI 10.1145/258734.258827
   SHEN J, P IMPL SURF 95 GREN, P187
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   SIMMONS M, 2002, P 2002 ACM SIGGRAPH, P139, DOI DOI 10.1145/545261.545284
   SINGH K, 1995, THESIS OHIO STATE U
   SLOAN PJ, P 2001 S INT 3D GRAP, P135
   WILHELMS J, 1995, UCSCCRL9501
   WILHELMS J, 1997, P SIGGRAPH 97, P173
   Yang Xu, 2005, Proceedings. 13th IEEE International Workshop on Software Technology and Engineering Practice
NR 24
TC 9
Z9 9
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 293
EP 303
DI 10.1002/cav.133
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400016
DA 2024-07-18
ER

PT J
AU Benes, B
   Tesinsky, V
   Hornys, J
   Bhatia, SK
AF Benes, B
   Tesinsky, V
   Hornys, J
   Bhatia, SK
TI Hydraulic erosion
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE hydraulic erosion; virtual world; visualization; terrain morphing
AB This paper presents a generalized solution to modelling hydraulic erosion using ideas from fluid mechanics. The model is based on the Navier-Stokes equations, which provide the dynamics of velocity and pressure. These equations form the basis for the model to balance erosion and deposition that determine changes in the layers between water and erosion material. The eroded material is captured and relocated by water according to a material transport equation. The resulting model is fully 3D and is able to simulate a variety of phenomena including river meanders, low hill sediment wash, natural water springs and receding waterfalls. The simulations show the terrain morphogenesis and can be used for animations as well as for static scene generation. Copyright (C) 2006 John Wiley & Sons, Ltd.
C1 Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Purdue Univ, Dept Comp Graph Technol, 1419 Knoy Hall,Room 363, W Lafayette, IN 47907 USA.
EM bbenes@purdue.edu
RI Benes, Bedrich/A-8150-2016
OI Benes, Bedrich/0000-0002-5293-2112
CR Benes B, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P79
   Chiba N, 1998, J VISUAL COMP ANIMAT, V9, P185, DOI 10.1002/(SICI)1099-1778(1998100)9:4<185::AID-VIS178>3.0.CO;2-2
   Dorsey J, 1999, COMP GRAPH, P225, DOI 10.1145/311535.311560
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Kelley A. D., 1988, Computer Graphics, V22, P263, DOI 10.1145/378456.378519
   Langendoen E.J., 2000, 16 USDA AGR RES SERV
   Li X., 1993, P 20 ANN C COMPUTER, P361
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Musgrave F. K., 1989, Computer Graphics, V23, P41, DOI 10.1145/74334.74337
   Onoue K, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P252, DOI 10.1109/PCCGA.2003.1238267
   Onoue K, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P427, DOI 10.1109/PCCGA.2000.883978
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Sumner RW, 1999, COMPUT GRAPH FORUM, V18, P17, DOI 10.1111/1467-8659.00299
NR 14
TC 54
Z9 62
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2006
VL 17
IS 2
BP 99
EP 108
DI 10.1002/cav.77
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040JO
UT WOS:000237375000003
DA 2024-07-18
ER

PT J
AU Chang, J
   Zhang, JJ
AF Chang, J
   Zhang, JJ
TI Mesh-free deformations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th Annual Conference on Computer Animation and Social Agents (CASA
   2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE physically based modelling; deformation; mesh-free; point-based;
   computer animation
AB Existing physically based deformation techniques, such as the finite element method (FEM) and the mass-spring systems (MSS), require the deformed object to be properly meshed. This is arguably the most expensive manual intervention process. In this paper, we propose a mesh-free deformation technique where only unconnected points are involved. The idea is to develop an approximate analytical solution using the Kelvin solution. Due to the fact that no mesh is involved, deforming a complex shape is as straightforward as deforming a simple one. Furthermore, the trade-off between efficiency and accuracy is easy to achieve by redistributing the points concerned. Experiments show that this method is fast and offers similar accuracy to the FEM. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Bournemouth Univ, Sch Med, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University
RP Chang, J (corresponding author), Bournemouth Univ, Sch Med, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
EM jchang@bournemouth.ac.uk
OI Zhang, Jian/0000-0002-7069-5771; Chang, Jian/0000-0003-4118-147X
CR [Anonymous], P SIGGRAPH 1988
   BARAFF D, 1992, P 19 ANN C COMP GRAP, P303
   CHEN DT, 1992, P SIGGRAPH 1992, P89
   Golub G. H., 1983, MATRIX COMPUTATIONS
   HIROTA G, 2002, THESIS U N CAROLINA
   Johnstone B., 1987, Text, V1, P205
   KOCH R.M., 1996, P SIGGRAPH, P421
   Liu G.R., 2003, Mesh Free Methods: Moving beyond The Finite Element Method
   Saada A.S., 1993, ELASTICITY THEORY AP
   TU X., 1994, P ACM SIGGRAPH 94, P43, DOI DOI 10.1145/192161.192170
   WIEDERMANN J, 2002, 500 3D OBJECTS
   You LH, 2000, COMPUT METHOD APPL M, V190, P853, DOI 10.1016/S0045-7825(99)00448-X
NR 12
TC 11
Z9 13
U1 0
U2 0
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 211
EP 218
DI 10.1002/cav.23
PG 8
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 839OZ
UT WOS:000222795700010
DA 2024-07-18
ER

PT J
AU Cunningham, DW
   Nusseck, M
   Wallraven, C
   Bülthoff, HH
AF Cunningham, DW
   Nusseck, M
   Wallraven, C
   Bülthoff, HH
TI The role of image size in the recognition of conversational facial
   expressions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th Annual Conference on Computer Animation and Social Agents (CASA
   2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE computer graphics; conversational agents; facial expressions; image size
AB Facial expressions can be used to direct the flow of a conversation as well as to improve the clarity of communication. The critical physical differences between expressions can, however, be small and subtle. Clear presentation of facial expressions in applied settings, then, would seem to require a large conversational agent. Given that visual displays are generally limited in size, the usage of a large conversational agent would reduce the amount of space available for the display of other information. Here, we examine the role of image size in the recognition of facial expressions. The results show that conversational facial expressions can be easily recognized at surprisingly small image sizes. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany.
C3 Max Planck Society
RP Cunningham, DW (corresponding author), Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany.
EM douglas.cunningham@tuebingen.mpg.de
RI Bülthoff, Heinrich/AAC-8818-2019; Bülthoff, Heinrich H/J-6579-2012
OI Bülthoff, Heinrich H/0000-0003-2568-0607; Cunningham, Douglas
   William/0000-0003-1419-2552; Wallraven, Christian/0000-0002-2604-9115
NR 0
TC 6
Z9 6
U1 0
U2 2
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 305
EP 310
DI 10.1002/cav.33
PG 6
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 839OZ
UT WOS:000222795700020
OA Bronze
DA 2024-07-18
ER

PT J
AU Perchet, D
   Fetita, CI
   Vial, L
   Preteux, F
   Caillibotte, G
   Sbirlea-Apiou, G
   Thiriet, M
AF Perchet, D
   Fetita, CI
   Vial, L
   Preteux, F
   Caillibotte, G
   Sbirlea-Apiou, G
   Thiriet, M
TI Virtual investigation of pulmonary airways in volumetric computed
   tomography
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE adaptive meshing; endoluminal navigation; fluid flow simulation; central
   axis; pulmonary airways; 3D reconstruction; virtual bronchoscopy
ID ALGORITHM; FLOW
AB This paper addresses the issue of non-invasive investigation and functional assessment of pulmonary airways reconstructed from multi detector computed tomography clinical acquisitions. Such an analysis combines accurate 3D meshing of the inner bronchial wall surface and navigation and interactivity tools based on a robust central axis representation. A reliable endoluminal investigation of airways via virtual bronchoscopy is possible regardless of their anatomical/pathological specificity (small caliber bronchi, severe stenoses,...). Computational fluid dynamics simulations on real airway geometries allow to assess functional modifications induced by physiopathological changes. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Inst Natl Telecommun, ARTEMIS Project Unit, GET, F-91011 Evry, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   SudParis
RP Inst Natl Telecommun, ARTEMIS Project Unit, GET, F-91011 Evry, France.
RI Caillibotte, Georges/JED-5639-2023
CR Eck M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P325, DOI 10.1145/237170.237271
   ELMASRY OA, 1982, RESP PHYSL 1, V49, P75
   FETITA CI, 2004, IEEE T MED IMAGING
   GRENIER P, 1996, MED RADIOLOGY SPIRAL, P185
   KIRKPATRICK DG, 1979, IEEE 20 ANN S FDN CO, P18
   Kwon GH, 2003, COMPUT STRUCT, V81, P765, DOI 10.1016/S0045-7949(02)00406-6
   Lachaud J O, 1999, Med Image Anal, V3, P187, DOI 10.1016/S1361-8415(99)80012-7
   LEE TY, COMPUTERIZED MED IMA, V25, P405
   Liu Y, 2002, J BIOMECH, V35, P465, DOI 10.1016/S0021-9290(01)00225-1
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Ma CM, 1996, COMPUT VIS IMAGE UND, V64, P420, DOI 10.1006/cviu.1996.0069
   MARTONEN TB, 1994, PARTICUL SCI TECHNOL, V12, P175, DOI 10.1080/02726359408906649
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   MENON AS, 1984, RESP PHYSIOL, V55, P255, DOI 10.1016/0034-5687(84)90026-4
   Sherbrooke EC, 1996, IEEE T VIS COMPUT GR, V2, P44, DOI 10.1109/2945.489386
   Summers RM, 2001, PROC SPIE, V4321, P22, DOI 10.1117/12.428154
   VIAL L, 2004, EUR SOC BIOM ESB C
   Wood ZJ, 2000, IEEE VISUAL, P275, DOI 10.1109/VISUAL.2000.885705
   Zhou Y, 1999, IEEE T VIS COMPUT GR, V5, P196, DOI 10.1109/2945.795212
NR 19
TC 11
Z9 11
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 361
EP 376
DI 10.1002/cav.40
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700027
DA 2024-07-18
ER

PT J
AU Egges, A
   Kshirsagar, S
   Magnenat-Thalmann, N
AF Egges, A
   Kshirsagar, S
   Magnenat-Thalmann, N
TI Generic personality and emotion simulation for conversational agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE personality; emotion simulation; facial animation; artificial
   intelligence
AB This paper describes a generic model for personality, mood and emotion simulation for conversational virtual humans. We present a generic model for updating the parameters related to emotional behaviour, as well as a linear implementation of the generic update mechanisms. We explore how existing theories for appraisal can be integrated into the framework. Then we describe a prototype system that uses the described models in combination with a dialogue system and a talking head with synchronized speech and facial expressions. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Geneva, MIRALab, CH-1211 Geneva, Switzerland.
   Univ Montreal, Montreal, PQ H3C 3J7, Canada.
C3 University of Geneva; Universite de Montreal
RP Univ Geneva, MIRALab, 24,Rue Gen Dufour, CH-1211 Geneva, Switzerland.
EM egges@miralab.unige.ch
RI Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Nadia/0000-0002-1459-5960
CR ANDRE E, 1999, P INT WORKSH AFF INT
   [Anonymous], P 1 INT JOINT C AUT
   [Anonymous], 1997, Proceedings of the 1997 National Conference on Artificial Intelligence (AAAI97)
   [Anonymous], 1990, Handbook of personality: Theory and research
   [Anonymous], 2002, Proceedings of the 2nd international symposium on Smart graphics, DOI [10.1145/569005.569021, DOI 10.1145/569005.569021]
   BALL G, 1998, P WORKSH EMB CONV CH, P83
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   Costa P. T., 1992, PSYCHOL ASSESSMENT, V4, P5, DOI DOI 10.1037/1040-3590.4.1.5
   EGGES A, 2003, 9 INT C MULT MOD
   Ekman P., 1982, EMOTION HUMAN FACE
   Elliott Clark, 1992, PhD thesis.
   ELNASR M, 1999, P AUT AG 99
   JOHNS M, 2001, 10 C COMP GEN FORC B
   Kshirsagar S, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P38, DOI 10.1109/CGI.2001.934656
   KSHIRSAGAR S, 2001, DEFORMABLE AVATARS, P33
   MOFFAT D, 1995, LECT NOTES ARTIFICIA
   Ortony A., 1988, COGNITIVE STRUCTURE
   PIWEK P, 2002, ANNOTATED BIBLIO AFF
NR 18
TC 89
Z9 107
U1 0
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2004
VL 15
IS 1
BP 1
EP 13
DI 10.1002/cav.3
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 832EF
UT WOS:000222249300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Guo, WC
   Li, SC
   Zhang, ZX
   Chen, ZR
   Chang, KH
   Wang, S
AF Guo, Wenchen
   Li, Shucheng
   Zhang, Zixun
   Chen, Zhirui
   Chang, KuoHsiang
   Wang, Su
TI A "magic world" for children: Design and development of a serious game
   to improve spatial ability
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE game user experience; game-based learning; serious game; spatial ability
ID REALITY
AB Research has shown that spatial perception is not only one of the essential abilities for success in science, technology, engineering, and mathematics (STEM), but is also closely related to the quality of human existence. However, for a variety of reasons, many students' spatial skills are less than ideal. In recent years, various video games are showing great potential as low-cost but effective training tools to improve the educational level and cognitive skills. This paper presented a novel serious strategy game named Magic World. The game was designed to enhance children's spatial perception and motivation by using narrative, virtual contexts, and game mechanics that incorporate educational content with entertainment as a powerful extra-curricular aid. A pilot study and evaluation experiment were conducted with primary school students (N = 68) and the results showed that the training had a measurable positive impact on students' spatial ability. In addition, user experience surveys of the game showed that Magic World was considered a fun, challenging, and popular game for children.
C1 [Guo, Wenchen; Li, Shucheng; Chang, KuoHsiang; Wang, Su] Peking Univ, Sch Software & Microelect, Beijing, Peoples R China.
   [Zhang, Zixun] Yanshan Univ, Sch Foreign Studies, Qinhuangdao, Peoples R China.
   [Chen, Zhirui] Univ Chinese Acad Social Sci, Sch Journalism & Commun, Beijing, Peoples R China.
C3 Peking University; Yanshan University; Chinese Academy of Social
   Sciences; University of Chinese Academy of Social Sciences
RP Guo, WC; Chang, KH; Wang, S (corresponding author), Peking Univ, Sch Software & Microelect, Beijing, Peoples R China.
EM beihuanfanchen@sina.com; simonkhc@vip.sina.com; samwang_2000@163.com
OI Guo, Wenchen/0000-0001-7757-1037; Chen, Zhirui/0000-0002-1550-8259
CR Andrade A., 2022, INT DES CHILDR IDC 2, DOI [10.1145/3501712.3535276, DOI 10.1145/3501712.3535276]
   [Anonymous], 2000, Sex differences in cognitive abilities
   Camingue J., P 15 INT C FDN DIG G
   Capecchi I, 2022, EDUC SCI, V12, DOI 10.3390/educsci12080536
   Clements D. H., 1992, Handbook of research on mathematics teaching and learning, P420
   Dillenbourg P., LESSONS LEARNING 199
   Do TV, 2009, LECT NOTES COMPUT SC, V5613, P296, DOI 10.1007/978-3-642-02583-9_33
   Feng J, 2007, PSYCHOL SCI, V18, P850, DOI 10.1111/j.1467-9280.2007.01990.x
   French J.W., 1951, The description of aptitude and achievement tests in terms of rotated factors
   Han J., 2021 CHI C HUM FACT
   Hookham G, 2019, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2019), DOI 10.1145/3290688.3290747
   Huang SY, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11010025
   Ibrahim R, 2009, 2009 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS, VOLS 1 AND 2, P282
   Karasavvidis I, 2015, INTED PROC, P7803
   Laine TH, 2020, IEEE T LEARN TECHNOL, V13, P804, DOI 10.1109/TLT.2020.3018503
   Leclet-Groux D, 2014, IEEE INT CONF ADV LE, P242, DOI 10.1109/ICALT.2014.77
   Levine SC, 2005, PSYCHOL SCI, V16, P841, DOI 10.1111/j.1467-9280.2005.01623.x
   Liang X., CHI C HUM FACT COMP
   LINN MC, 1985, CHILD DEV, V56, P1479, DOI 10.1111/j.1467-8624.1985.tb00213.x
   Martin-Dorta N, 2014, MULTIMED TOOLS APPL, V73, P1575, DOI 10.1007/s11042-013-1652-0
   MCGEE MG, 1979, PSYCHOL BULL, V86, P889, DOI 10.1037/0033-2909.86.5.889
   Merriman NA, 2018, BEHAV INFORM TECHNOL, V37, P538, DOI 10.1080/0144929X.2018.1462402
   Mix KS, 2012, ADV CHILD DEV BEHAV, V42, P197
   Newcombe N.S., 2013, AM EDUC, V37, P26
   PETERS M, 1995, BRAIN COGNITION, V28, P39, DOI 10.1006/brcg.1995.1032
   Piaget J., 1968, GENETIC EPISTEMOLOGY
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   Sorby S.A., 2007, Australian Journal of Engineering Education, V13, P1, DOI [DOI 10.1080/22054952.2007.11463998, https://doi.org/10.1080/22054952.2007.11463998]
   van Delden R, 2019, PROC EUR CONF GAME, P767, DOI 10.34190/GBL.19.069
   Wauck HC., P 2019 CHI C HUM FAC
   Wilson DW, 2016, P ANN HICSS, P638, DOI 10.1109/HICSS.2016.85
   Zeng J., 2021 INT S ED TECHN
NR 32
TC 1
Z9 1
U1 10
U2 32
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2181
EA MAY 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000990195700001
DA 2024-07-18
ER

PT J
AU Venugopal, JP
   Subramanian, AAV
   Peatchimuthu, J
AF Venugopal, Jothi Prakash
   Subramanian, Arul Antran Vijay
   Peatchimuthu, Jegathesh
TI The realm of metaverse: A survey
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; blockchain; extended reality; internet; metaverse;
   virtual reality
ID DIGITAL TWIN; BIG DATA; BLOCKCHAIN; INFORMATION; FRAMEWORK; CHALLENGES;
   LATENCY; FUTURE
AB The next step of digital development is the metaverse, which has the potential to drastically alter how people use technology and expand the range of services available beyond conventional systems that can be accessed online. As the efficiency, performance, and quality of service access reach their peak levels, the focus has shifted to the user experience. Due to this, there is an increasing demand for more involved and thorough customer service, and service providers are willing to increase their present standards. Consumers are genuinely asking for tactile and immersive elements in their digital interfaces, but these features can only be made possible by the metaverse's potentially futuristic subfields of virtual reality (VR), augmented reality (AR), mixed reality (MR), and extended reality (XR). However, the metaverse may not be widely used due to significant security and privacy issues either from underlying technology or produced by the new digital environment. A variety of fundamental problems, such as scalability and interoperability, can arise in terms of ensuring security for the metaverse because of the metaverse's inherent properties, such as immersive realism, sustainability, and heterogeneity. In this survey, we propose a hypothetical meta-stack framework to understand the various components in the realm of metaverse and then provide wide-ranging insights on the most recent development in metaverse realm in the context of cutting-edge technologies, security vulnerabilities and preventive measures specific to the metaverse and the research challenges pertaining to metaverse.
C1 [Venugopal, Jothi Prakash; Peatchimuthu, Jegathesh] Karpagam Coll Engn, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
   [Venugopal, Jothi Prakash; Subramanian, Arul Antran Vijay] Karpagam Coll Engn, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
C3 Karpagam College of Engineering; Karpagam College of Engineering
RP Venugopal, JP; Subramanian, AAV (corresponding author), Karpagam Coll Engn, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
EM jothiprakashv@gmail.com; arulantranvijay@gmail.com
RI Prakash, Jothi/AAP-1618-2021; S, Arul Antran Vijay/AAM-8297-2020
OI Prakash, Jothi/0000-0002-5427-9460; S, Arul Antran
   Vijay/0000-0002-5543-7547; P, jegathesh/0000-0002-9937-4592
CR Abiri R, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/aaf12e
   Agnusdei GP, 2021, COMPUT IND ENG, V154, DOI 10.1016/j.cie.2021.107137
   Al-Fuqaha A, 2015, IEEE COMMUN SURV TUT, V17, P2347, DOI 10.1109/COMST.2015.2444095
   [Anonymous], 2022, PRIVACY SAND
   [Anonymous], 2021, DEVELOPING OMNI
   [Anonymous], 2018, CURR CONTENTS
   Ante L, 2023, ECON INNOV NEW TECH, V32, P1216, DOI 10.1080/10438599.2022.2119564
   Arboleda SA, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445398
   ARVAS S., 2022, AJIT-e: Bilisim Teknolojileri Online Dergisi, V13, P53
   Attia MB., 2019, CURR CONTENTS, V7, p58 990
   Azaria A, 2016, PROCEEDINGS 2016 2ND INTERNATIONAL CONFERENCE ON OPEN AND BIG DATA - OBD 2016, P25, DOI 10.1109/OBD.2016.11
   Bajireanu R., 2019, Int. J. Comput., V4, P1
   Baktir AC, 2017, IEEE COMMUN SURV TUT, V19, P2359, DOI 10.1109/COMST.2017.2717482
   Becker Vincent, 2020, AUGMENTED HUMAN RES, V5, P1
   Bennis M, 2018, P IEEE, V106, P1834, DOI 10.1109/JPROC.2018.2867029
   Bermejo Fernandez Carlos, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P478, DOI 10.1145/3462244.3479885
   Bhaskar A, 2015, IEEE T INTELL TRANSP, V16, P113, DOI 10.1109/TITS.2014.2328373
   Bian YY, 2022, LECT NOTES COMPUT SC, V12988, P109, DOI 10.1007/978-3-030-96282-1_8
   Bistarelli S., 2017, Proceedings of the Symposium on Applied Computing - SAC, V17, P1836, DOI 10.1145/3019612.3019841
   Bogost I., 2008, UNIT OPERATIONS APPR
   Bono S, 2009, IEEE SECUR PRIV, V7, P13, DOI 10.1109/MSP.2009.75
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Braud T., 2022, IEEE MULTIMEDIA, V1, P1
   Braud T, 2020, INT CONF PERVAS COMP, DOI 10.1109/percom45495.2020.9127360
   Braud T, 2017, INT CON DISTR COMP S, P1796, DOI 10.1109/ICDCS.2017.48
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Cao YZ, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312797
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cha HS, 2022, VIRTUAL REAL-LONDON, V26, P385, DOI 10.1007/s10055-021-00575-6
   Chaturvedi I, 2019, PROCEEDINGS OF IUI 2019, P625, DOI 10.1145/3301275.3302263
   Chen L., 2019, CURR CONTENTS, p1:34
   Chen ZT, 2018, FUTURE GENER COMP SY, V84, P126, DOI 10.1016/j.future.2017.10.008
   Cheng RZ, 2022, IEEE NETWORK, V36, P197, DOI 10.1109/MNET.117.2200055
   Chia A, 2020, INTERNET POLICY REV, V9, DOI 10.14763/2020.4.1515
   Chun-Cheng Chang, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P2083, DOI 10.1177/1071181319631428
   Cloete R., 2020, P 26 ACM S VIRTUAL R, P1
   Dagang Li, 2019, IEEE Networking Letters, V1, P30, DOI 10.1109/LNET.2019.2891998
   Dahan NA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11101616
   Dang Q, 2019, TSINGHUA SCI TECHNOL, V24, P663, DOI 10.26599/TST.2018.9010100
   DAntonio E, 2020, IEEE INT INSTR MEAS, DOI [DOI 10.1109/I2MTC43012.2020.9128918, 10.1109/i2mtc43012.2020.9128918]
   Davis A, 2009, J ASSOC INF SYST, V10, P90, DOI 10.17705/1jais.00183
   Dear K, 2019, RUSI J, V164, P18, DOI 10.1080/03071847.2019.1693801
   Dehesa J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376714
   docs, 2022, ABOUT US
   Du H., GLOBECOM 2022 2022 I, V2, P4346
   Duan HH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P153, DOI 10.1145/3474085.3479238
   Fahimi F, 2021, IEEE T NEUR NET LEAR, V32, P4039, DOI 10.1109/TNNLS.2020.3016666
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Farhat MH, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/abd280
   Foxman M, 2019, SOC MEDIA SOC, V5, DOI 10.1177/2056305119880177
   Fromknecht C., 2014, CertCoin: A NameCoin Based Decentralized Authentication System, P1
   Fuller A, 2020, IEEE ACCESS, V8, P108952, DOI 10.1109/ACCESS.2020.2998358
   Gadekallu TR, 2022, IEEE INTERNET THINGS, V9, P964, DOI 10.1109/JIOT.2021.3119639
   Gehrmann C, 2020, IEEE T IND INFORM, V16, P669, DOI 10.1109/TII.2019.2938885
   Genay A. C. S., 2021, IEEE Transactions on Visualization and Computer Graphics, V26, DOI 10.1109/TVCG.2021.3099290
   Gharsallaoui R, 2017, INT WIREL COMMUN, P1072, DOI 10.1109/IWCMC.2017.7986434
   Grieves M., 2017, TRANSDISCIPLINARY PE, P85, DOI [DOI 10.1007/978-3-319-38756-7_4, 10.1007/978-3-319-38756-7_4]
   Gualda D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21061950
   Guan ZS, 2022, IEEE T DEPEND SECURE, V19, P1446, DOI 10.1109/TDSC.2020.3025129
   Guo JX, 2022, IEEE T RELIAB, V71, P1219, DOI 10.1109/TR.2020.3046556
   Gupta SD, 2019, INT RELIAB PHY SYM, DOI 10.1109/irps.2019.8720595
   Ha K, 2014, MOBISYS'14: PROCEEDINGS OF THE 12TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P68, DOI 10.1145/2594368.2594383
   Haffegee A, 2009, LECT NOTES COMPUT SC, V5545, P729, DOI 10.1007/978-3-642-01973-9_81
   Han Y, 2023, IEEE INTERNET THINGS, V10, P268, DOI 10.1109/JIOT.2022.3201082
   Hartmann Jeremy, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P445, DOI 10.1145/3379337.3415849
   Hofmann W, 2019, IFAC PAPERSONLINE, V52, P2104, DOI 10.1016/j.ifacol.2019.11.516
   Hong JW, 2020, INT J HUM-COMPUT INT, V36, P1768, DOI 10.1080/10447318.2020.1785693
   Hoque MA, 2020, NOSSDAV '20: PROCEEDINGS OF THE 2020 WORKSHOP ON NETWORK AND OPERATING SYSTEM SUPPORT FOR DIGITAL AUDIO AND VIDEO, P40, DOI 10.1145/3386290.3396935
   Hu F, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3397306
   Itoh N., 2022, CURR CONTENTS, V46, P261
   Ivkovic Z, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P135, DOI 10.1145/2702123.2702432
   Jan MA, 2021, IEEE T IND INFORM, V17, P5829, DOI [10.1109/tii.2020.3043802, 10.1109/TII.2020.3043802]
   Jensen J, 2013, IEEE SECUR PRIV, V11, P34, DOI 10.1109/MSP.2012.135
   Jeon Joo-Eon, 2021, [Journal of Distribution Science, 유통과학연구], V19, P81
   Jiang D, 2019, IEEE INT CONF MOB CL, P1, DOI 10.1109/MobileCloud.2019.00008
   Jo D, 2016, IEEE T CONSUM ELECTR, V62, P334, DOI 10.1109/TCE.2016.7613201
   Joshua J, 2017, INTERDISCIP LIT STUD, V19, P17
   Jovanovic A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030317
   Jung K., 2022, CHI C HUM FACT COMP, P1
   Jungherr A, 2022, SOC MEDIA SOC, V8, DOI 10.1177/20563051221107641
   Kai CH, 2021, IEEE T COGN COMMUN, V7, P624, DOI 10.1109/TCCN.2020.3018159
   Kamal M, 2018, IEEE ACCESS, V6, P34439, DOI 10.1109/ACCESS.2018.2850821
   Kapp S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062234
   Kelly JW, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P687, DOI 10.1109/VR50410.2021.00095
   Kim JC, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041738
   Kiong L.V., 2022, Metaverse Made Easy: A Beginner's Guide to the Metaverse: Everything you need to know about Metaverse, NFT and GameFi
   Kocur Martin, 2020, VRST '20: 26th ACM Symposium on Virtual Reality Software and Technology, DOI 10.1145/3385956.3418973
   Korsi MJL, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P91, DOI 10.1145/2967934.2968110
   Kostenko D., 2020, CURR CONTENTS, V1, P106
   Kostenko O. V., 2022, World Sci, V1, P1, DOI [10.31435/rsglobal_ws/30012022/7751, DOI 10.31435/RSGLOBAL_WS/30012022/7751]
   Koutsabasis P, 2012, DESIGN STUD, V33, P357, DOI 10.1016/j.destud.2011.11.004
   Kraus S., 2022, INT J ENTREP BEHAV R
   Kumar A, 2021, IEEE ACCESS, V9, P13761, DOI 10.1109/ACCESS.2021.3050929
   Kumar A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290607.3312928, 10.1109/imarc45935.2019.9118731]
   Kumar R, 2022, IEEE T INTELL TRANSP, V23, P16492, DOI 10.1109/TITS.2021.3098636
   Kwon YD., 2020, IEEE SYST J, P1
   Kye B., 2021, CURR CONTENTS, P18
   Laaki H, 2019, IEEE ACCESS, V7, P20325, DOI 10.1109/ACCESS.2019.2897018
   Lam KY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2447, DOI 10.1145/3474085.3475413
   LAM KY, 2019, INT CONF PERVAS COMP
   Langlotz T, 2012, PERS UBIQUIT COMPUT, V16, P623, DOI 10.1007/s00779-011-0430-0
   Lassagne A, 2018, IEEE T HAPTICS, V11, P119, DOI 10.1109/TOH.2017.2755653
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Le XH, 2022, ADV SCI, V9, DOI 10.1002/advs.202201056
   Lebeck K, 2018, P IEEE S SECUR PRIV, P392, DOI 10.1109/SP.2018.00051
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Lee J, 2020, IET COLL INTEL MANUF, V2, P34, DOI 10.1049/iet-cim.2020.0009
   Lee LH, 2019, INT CONF PERVAS COMP, DOI 10.1109/percom.2019.8767420
   Lee LH, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3467963
   Lee LH, 2018, IEEE ACCESS, V6, P28712, DOI 10.1109/ACCESS.2018.2831081
   Li RN, 2019, IEEE T SERV COMPUT, V12, P762, DOI 10.1109/TSC.2018.2853167
   Li Y., 2021, CURR CONTENTS, V7, P509
   Li Z, 2018, IEEE T INF FOREN SEC, V13, P802, DOI 10.1109/TIFS.2017.2768020
   Liang W, 2020, IEEE T IND INFORM, V16, P6543, DOI 10.1109/TII.2020.2966069
   Liang XP, 2017, IEEE ACM INT SYMP, P468, DOI 10.1109/CCGRID.2017.8
   Liao Xishun, 2020, 2020 IEEE 91 VEHICUL
   Lin P, 2021, IEEE T IND INFORM, V17, P7607, DOI 10.1109/TII.2021.3061579
   Lin X., 2019, IEEE Communications Standards Magazine, V3, P30, DOI [DOI 10.1109/MCOMSTD.001.1800036, 10.1109/MCOMSTD.001.1800036]
   Lincoln P, 2016, IEEE T VIS COMPUT GR, V22, P1367, DOI 10.1109/TVCG.2016.2518038
   Liotou E, 2018, IEEE J SEL AREA COMM, V36, P598, DOI 10.1109/JSAC.2018.2815421
   Liu H, 2019, IEEE INTERNET THINGS, V6, P1352, DOI 10.1109/JIOT.2018.2843561
   Liu HY, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333116
   Liu PTS, 2016, LECT NOTES COMPUT SC, V9977, P254, DOI 10.1007/978-3-319-50011-9_20
   Liu Y, 2019, IEEE ACCESS, V7, P49088, DOI 10.1109/ACCESS.2019.2909828
   Luo HW, 2021, PROC CVPR IEEE, P11657, DOI 10.1109/CVPR46437.2021.01149
   Luo Y, 2021, CANCER CELL INT, V21, DOI 10.1186/s12935-021-01793-3
   Lyu Q., 2020, CURR CONTENTS
   Ma CS, 2019, IEEE T MULTIMEDIA, V21, P173, DOI 10.1109/TMM.2018.2851446
   MacIntyre B, 2002, P IEEE VIRT REAL ANN, P73, DOI 10.1109/VR.2002.996507
   Malazita J., 2018, FEMINISM PLAY, P37
   Metasploitable, 2022, US
   Min QF, 2019, INT J INFORM MANAGE, V49, P502, DOI 10.1016/j.ijinfomgt.2019.05.020
   Moi T, 2020, ENG FAIL ANAL, V112, DOI 10.1016/j.engfailanal.2020.104517
   Moinnereau Marc-Antoine, 2022, Qual User Exp, V7, P5, DOI 10.1007/s41233-022-00052-1
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Murphy D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141217
   Murray JH, 2020, J VIS CULT, V19, P11, DOI 10.1177/1470412920906253
   Nagano K., 2018, ACM SIGGRAPH 2018 RE, P1
   Nakao M., 2014, P 5 AUGMENTED HUMAN, P1
   Narumi T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P93
   Nguyen T., 2022, JMIRx Med, V3, DOI [10.2196/33502, DOI 10.2196/33502]
   Nicoll Benjamin., 2019, UNITY GAME ENGINE CI
   Nieborg DB, 2021, GAMES CULT, V16, P305, DOI 10.1177/1555412020937826
   Nijholt A, 2017, 2017 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P190, DOI 10.1109/CW.2017.23
   Park Yongtae., 2019, PROC ACM MOBISYS, P117
   Pfeiffer T., 2014, P S EYE TRACK RES AP, P195, DOI DOI 10.1145/2578153.2578183
   Pike C., 2022, CURR CONTENTS
   Piltan F, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104602
   Qi QL, 2018, IEEE ACCESS, V6, P3585, DOI 10.1109/ACCESS.2018.2793265
   Ren YJ, 2019, MATH BIOSCI ENG, V16, P1874, DOI 10.3934/mbe.2019091
   Ren YJ, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/6874158
   Rhee H., 2021, J KOREA GAME SOC, V21, P79, DOI DOI 10.7583/JKGS.2021.21.3.79
   Rivu R, 2021, LECT NOTES COMPUT SC, V12936, P234, DOI 10.1007/978-3-030-85607-6_16
   Rome RJ., 2019, NARRATIVE VIRTUAL RE
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Roo JS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1459, DOI 10.1145/3025453.3025743
   Rospigliosi P, 2022, INTERACT LEARN ENVIR, V30, P1, DOI 10.1080/10494820.2022.2022899
   Ruohomäki T, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P155, DOI 10.1109/IS.2018.8710517
   Ruth K, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P141
   Rydell L., 2022, LINGUIST PHILOS INVE, V21, P25, DOI [10.22381/lpi2120222, DOI 10.22381/LPI2120222]
   Saberi-Karimian M, 2021, CRIT REV CL LAB SCI, V58, P275, DOI 10.1080/10408363.2020.1857681
   Salanitri D., 2016, P EUROPEAN C COGNITI, P1, DOI [10.1145/2970930.2970947, DOI 10.1145/2970930.2970947]
   Samir E, 2022, IEEE INTERNET THINGS, V9, P7972, DOI 10.1109/JIOT.2021.3112537
   Saragih Jason M, 2011, Proc Int Conf Autom Face Gesture Recognit, P117, DOI 10.1109/FG.2011.5771400
   Satchidanandan B, 2017, P IEEE, V105, P219, DOI 10.1109/JPROC.2016.2575064
   Schmalstieg D., 2016, AUGMENTED REALITY PR
   Sedlmeir J., 2021, ACM SIGENERGY ENERGY, V1, P20, DOI DOI 10.1145/3508467.3508470
   Sevcik L, 2014, INTERNATIONAL SYMPOSIUM ON PERFORMANCE EVALUATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS (SPECTS 2014), P593, DOI 10.1109/SPECTS.2014.6879998
   Shang JC, 2022, IEEE T MOBILE COMPUT, V21, P433, DOI 10.1109/TMC.2020.3007740
   Shatilov KA, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3457950
   Shen M, 2020, IEEE J SEL AREA COMM, V38, P942, DOI 10.1109/JSAC.2020.2980916
   Shi S, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P222, DOI 10.1145/3304109.3306217
   Shin Younji, 2021, [The journal of Convergence on Culture Technology, 문화기술의 융합], V7, P577
   Singh Karan, 2018, 2018 International Conference on Computing, Power and Communication Technologies (GUCON), P165, DOI 10.1109/GUCON.2018.8674919
   Siyaev A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062066
   Skalidis I, 2023, TRENDS CARDIOVAS MED, V33, P471, DOI 10.1016/j.tcm.2022.05.004
   Soni B, 2008, IEEE IJCNN, P363, DOI 10.1109/IJCNN.2008.4633818
   Spielberg S., 2018, Ready Player One
   Srinivas J, 2020, IEEE T DEPEND SECURE, V17, P1133, DOI 10.1109/TDSC.2018.2857811
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Suhail S, 2022, IEEE INTERNET COMPUT, V26, P58, DOI 10.1109/MIC.2021.3059320
   Sun FM, 2021, IEEE INTERNET THINGS, V8, P1636, DOI 10.1109/JIOT.2020.3014646
   Suzuki Sin-nosuke, 2020, Procedia Computer Science, V176, P2125, DOI 10.1016/j.procs.2020.09.249
   Takahashi D, 2021, ABOUT US
   Tanaka K, 2008, INT SYM MIX AUGMENT, P139, DOI 10.1109/ISMAR.2008.4637340
   Tang FX, 2023, IEEE WIREL COMMUN, V30, P72, DOI 10.1109/MWC.019.2100721
   Tassinari M, 2022, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.815497
   Tuegel E. J., 2011, International Journal of Aerospace Engineering, V2011, DOI [DOI 10.1155/2011/154798, 10.1155/2011/154798]
   Urom C, 2022, FINANC RES LETT, V50, DOI 10.1016/j.frl.2022.103188
   Vailshery L S., 2021, Internet of Things (IoT) and non-IoT active device connections worldwide from 2010 to 2025
   Venkatesan M, 2021, CELL REP MED, V2, DOI 10.1016/j.xcrm.2021.100348
   Vural S, 2013, IEEE COMMUN SURV TUT, V15, P223, DOI 10.1109/SURV.2012.021312.00018
   Wacker P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376848
   Wan L., 2019, International Conference on Smart Infrastructure and Construction 2019 (ICSIC) Driving Data-Informed Decision-Making, P187
   Wang D., 2021, 2021 2 INT C EL COMM, P983
   Wang FY, 2022, IEEE T COMPUT SOC SY, V9, P2, DOI 10.1109/TCSS.2022.3145165
   Wang FY, 2016, IEEE-CAA J AUTOMATIC, V3, P113, DOI 10.1109/JAS.2016.7471613
   Wang SP, 2018, IEEE ACCESS, V6, P38437, DOI 10.1109/ACCESS.2018.2851611
   Wang XD, 2021, IEEE COMMUN LETT, V25, P2333, DOI 10.1109/LCOMM.2021.3067898
   Wang XY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4533, DOI 10.1145/3394171.3414449
   Wang YT, 2023, IEEE COMMUN SURV TUT, V25, P319, DOI 10.1109/COMST.2022.3202047
   Wang YT, 2022, IEEE COMMUN SURV TUT, V24, P160, DOI 10.1109/COMST.2021.3131711
   Wei X., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P500, DOI [DOI 10.1145/1027527.1027648, 10.1145/1027527.1027648]
   Wellmann F, 2022, GEOSPHERE, V18, P732, DOI 10.1130/GES02455.1
   White G, 2021, CITIES, V110, DOI 10.1016/j.cities.2020.103064
   Wiederhold BK, 2022, CYBERPSYCH BEH SOC N, V25, P1, DOI 10.1089/cyber.2021.29234.editorial
   Wilson Lori A., 2021, Information Display, V37, P30, DOI 10.1002/msid.1214
   Won-Suk Kim，, 2021, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V24, P1090
   Wu EH.K., 2020 IEEE INT C CONS, P1
   Xia Q, 2017, IEEE ACCESS, V5, P14757, DOI 10.1109/ACCESS.2017.2730843
   Xie C, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P179, DOI 10.1145/2983310.2989183
   Xu KH, 2017, IEEE T DEPEND SECURE, V14, P199, DOI 10.1109/TDSC.2015.2443795
   Yang K, 2016, IEEE T MULTIMEDIA, V18, P940, DOI 10.1109/TMM.2016.2535728
   Yang Q., 2022, CURR CONTENTS
   Yilmaz H, 2022, NURS EDUC TODAY, V108, DOI 10.1016/j.nedt.2021.105179
   Yiping G., 2021, CURR CONTENTS, V21
   Yousaf FZ, 2017, IEEE INT CONF COMM, P1195, DOI 10.1109/ICCW.2017.7962821
   Yue Qin, 2019, 2019 2nd World Symposium on Communication Engineering (WSCE). Proceedings, P189, DOI 10.1109/WSCE49000.2019.9040920
   Zhang DW, 2022, INFORMS J COMPUT, V34, P1126, DOI 10.1287/ijoc.2021.1069
   Zhang LJ, 2022, IEEE SYST J, V16, P2822, DOI 10.1109/JSYST.2021.3057333
   Zhang LY, 2020, IEEE T DEPEND SECURE, V17, P1218, DOI 10.1109/TDSC.2018.2864748
   Zhang LY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (IEEE ICWS 2018), P139, DOI 10.1109/ICWS.2018.00025
   Zhang T., 2016, ACM T INTERACT INTEL, V7, P1
   Zhao JB, 2017, P IEEE VIRT REAL ANN, P313, DOI 10.1109/VR.2017.7892302
   Zhao TM, 2020, IEEE INFOCOM SER, P30, DOI [10.1109/infocom41043.2020.9155526, 10.1109/INFOCOM41043.2020.9155526]
   Zheng GL, 2019, IEEE SENS J, V19, P1186, DOI 10.1109/JSEN.2018.2879929
   Zimmermann R., 2008, PROCEEDING 16 ACM IN, P299
   Zyskind G, 2015, 2015 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW), P180, DOI 10.1109/SPW.2015.27
NR 228
TC 7
Z9 7
U1 22
U2 80
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2150
EA MAR 2023
PG 28
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000941930600001
DA 2024-07-18
ER

PT J
AU Wu, H
   Wang, CB
   He, GQ
AF Wu, Hui
   Wang, Changbo
   He, Gaoqi
TI Dynamic leader role modeling for self-organizing crowd evacuation
   simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; dynamic leader role model; leader-follower
   relationship; OCEAN; social force model
ID PERSONALITY; IDENTITY
AB The role of the leader in the self-organizing crowd has a significant influence on the crowd evacuation when an emergency occurs. However, current crowd evacuation models either ignore the leadership characteristics of pedestrians or predefine an invariable leader identity. This article clearly distinguishes leaders from followers in a crowd and evaluates the impact of the leader's role on crowd evacuation under dynamic situations. First, the leadership model of the pedestrian is built based on the classic OCEAN personality parameters. Social dominance tendency is measured for more credibility. Then, the dynamic leader role model (DLRM) is proposed to describe the relationship between leaders and followers, considering the interaction among pedestrians during the evacuation. Finally, a novel crowd simulation algorithm based on the above DLRM is presented using the extended social force model. Various experiments in several typical scenarios verified that our proposed simulation model has better realism.
C1 [Wu, Hui; Wang, Changbo; He, Gaoqi] East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
C3 East China Normal University
RP He, GQ (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
EM gqhe@cs.ecnu.edu.cn
OI He, Gaoqi/0000-0001-8365-0970; Wang, Changbo/0000-0001-8940-6418; Wu,
   Hui/0000-0003-3304-7692
FU Natural Science Foundation of China [62002121, 62072183]; Open Project
   Program of the State Key Lab of CADCG; Zhejiang University
FX Natural Science Foundation of China, Grant/Award Numbers: 62002121,
   62072183; Open Project Program of the State Key Lab of CAD & CG;
   Zhejiang University
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   [Anonymous], 2010, ACAD MANAGE REV
   Aouaidjia K, 2021, IEEE T SYST MAN CY-S, V51, P2774, DOI 10.1109/TSMC.2019.2916896
   Brewer MB, 1996, J PERS SOC PSYCHOL, V71, P83, DOI 10.1037/0022-3514.71.1.83
   Chen L, 2018, SIMUL MODEL PRACT TH, V82, P1, DOI 10.1016/j.simpat.2017.12.011
   DeRue DS, 2011, RES ORGAN BEHAV, V31, P125, DOI 10.1016/j.riob.2011.09.007
   Derue DS, 2011, SER ORGAN MANAGE, P217
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Fachri M, 2017, PROCEEDINGS OF 2017 4TH INTERNATIONAL CONFERENCE ON NEW MEDIA STUDIES (CONMEDIA 2017), P92, DOI 10.1109/CONMEDIA.2017.8266037
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Jiang JW, 2020, GRAPH MODELS, V111, DOI 10.1016/j.gmod.2020.101077
   Juniastuti S, 2016, 2016 INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND SMART DEVICES (ISESD), P148, DOI 10.1109/ISESD.2016.7886709
   Kalshoven K, 2011, J BUS ETHICS, V100, P349, DOI 10.1007/s10551-010-0685-9
   Kamel A, 2021, IEEE T MULTIMEDIA, V23, P1330, DOI 10.1109/TMM.2020.2999181
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Kark R, 2003, J APPL PSYCHOL, V88, P246, DOI 10.1037/0021-9010.88.2.246
   Lombardi M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75551-2
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Ortony, 1988, J INTELL DECIS TECHN, V4, P51
   Schreiber T, 2000, PHYS REV LETT, V85, P461, DOI 10.1103/PhysRevLett.85.461
   Sibley CG, 2008, PERS SOC PSYCHOL REV, V12, P248, DOI 10.1177/1088868308319226
   Song JN, 2019, IEEE ACCESS, V7, P100162, DOI 10.1109/ACCESS.2019.2930104
   Song XN, 2022, IEEE T CYBERNETICS, V52, P178, DOI 10.1109/TCYB.2020.2972634
   Sui ZZ, 2019, IEEE IJCNN
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   von Rueden C, 2014, HUM NATURE-INT BIOS, V25, P538, DOI 10.1007/s12110-014-9213-4
   Wang XL, 2015, SAFETY SCI, V74, P150, DOI 10.1016/j.ssci.2014.12.007
   Xie W, 2022, AUTOMAT CONSTR, V134, DOI 10.1016/j.autcon.2021.104100
   Xu ML, 2014, J COMPUT SCI TECH-CH, V29, P799, DOI 10.1007/s11390-014-1469-y
   Xu ML, 2021, IEEE T INTELL TRANSP, V22, P6977, DOI 10.1109/TITS.2020.3000607
   Yang XX, 2016, PHYSICA A, V442, P397, DOI 10.1016/j.physa.2015.08.020
   Yang XX, 2014, PHYSICA A, V411, P63, DOI 10.1016/j.physa.2014.05.068
   Zhang HT, 2014, SCI REP-UK, V4, DOI 10.1038/srep05805
   Zhang P, 2022, IEEE T PATTERN ANAL, V44, P2742, DOI 10.1109/TPAMI.2020.3038217
NR 36
TC 1
Z9 1
U1 1
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2023
VL 34
IS 1
SI SI
AR e2115
DI 10.1002/cav.2115
EA AUG 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Z2BA
UT WOS:000842170300001
DA 2024-07-18
ER

PT J
AU Du, X
   Sun, XJ
   Wang, KP
   Yang, JL
   Wang, CAJ
AF Du, Xue
   Sun, Xiujuan
   Wang, Kunpeng
   Yang, Junlong
   Wang, Chuanjiang
TI Underwater image enhancement method based on entropy weight fusion
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE color compensation; entropy weight method; image enhancement; retinex
   algorithm; underwater image
AB Due to the absorption and scattering of underwater light, underwater images often have some phenomena such as colorcast, low contrast, and blurred details. Therefore, an underwater image enhancement method based on entropy weight fusion is proposed. First, white balance processing can effectively correct the blue (green) color appearance of the image. Then the white-balanced images are converted from RGB space to LAB space, and L channel is processed with improved adaptive gamma correction, and then converted back to RGB space. CLAHE and bilateral filtering are performed in RGB space. The RGB space is converted to HSV space, the V channel is processed by single-scale retinex algorithm combined with guided filtering, stretching the R channel with s-cosine curve,and then converted back to RGB space. Finally, the three results are fused by entropy weight to obtain the final enhanced image. Experimental results show that the proposed algorithm can improve the contrast and clarity of underwater images, and effectively remove colorcast.
C1 [Du, Xue; Sun, Xiujuan; Wang, Kunpeng; Yang, Junlong; Wang, Chuanjiang] Shandong Univ Sci & Technol, Coll Elect Engn & Automat, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Sun, XJ (corresponding author), Shandong Univ Sci & Technol, Coll Elect Engn & Automat, Qingdao 266590, Peoples R China.
EM cxjsun@sdust.edu.cn
RI Wang, Kun-Peng/R-2727-2016
OI Wang, Kun-Peng/0000-0002-2847-5919; Du, Xue/0000-0002-1479-365X
FU Key Science and Technology Innovation Programs in Shandong Province
   [2017CXGC0919]; Shandong Province Key Research and Development Plan
   [2016GSF201197]
FX The authors very much appreciate the support to this research by: (1)
   The Key Science and Technology Innovation Programs in Shandong Province
   (NO.2017CXGC0919), and (2) the Shandong Province Key Research and
   Development Plan (No.2016GSF201197).
CR Akkaynak D, 2018, PROC CVPR IEEE, P6723, DOI 10.1109/CVPR.2018.00703
   Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Chen XL, 2017, IEEE I CONF COMP VIS, P4106, DOI 10.1109/ICCV.2017.440
   Dai CG, 2018, ACTA OPT SIN, V38, DOI 10.3788/AOS201838.1110003
   Emberton S., 2015, PROC BRIT MACH VIS C, V125, DOI 10.5244/C.29.125
   Fu XY, 2020, SIGNAL PROCESS-IMAGE, V86, DOI 10.1016/j.image.2020.115892
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao CC., 2020, RADIOENGINEERING, V50, P848
   Haofeng Hu, 2018, IEEE Photonics Journal, V10, DOI 10.1109/JPHOT.2018.2791517
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Honnutagi P, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT - 2018), P1654, DOI 10.1109/ICEECCOT43722.2018.9001568
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Lai ZQ, 2016, INT CONF SOFTW ENG, P481, DOI 10.1109/ICSESS.2016.7883113
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Li Y., 2014, MATH PROBL ENG, V2014, P1
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Sha Junming, 2012, Journal of Projectiles, Rockets, Missiles and Guidance, V32, P3
   Shen Y., 2017, ACTA OPT SINICA, V37, P82
   [石磊 Shi Lei], 2018, [量子电子学报, Chinese Journal of Quantum Electronics], V35, P7
   Song W, 2020, IEEE T BROADCAST, V66, P153, DOI 10.1109/TBC.2019.2960942
   Wen HC, 2013, IEEE INT SYMP CIRC S, P753, DOI 10.1109/ISCAS.2013.6571956
   Xiujuan S., 2018, J SHANDONG U SCI TEC, V37, P111, DOI DOI 10.16452/J.CNKI.SDKJZK.2018.04.014
   Yang M, 2020, IEEE J OCEANIC ENG, V45, P521, DOI 10.1109/JOE.2018.2886093
   Zotin Alexander, 2018, Procedia Computer Science, V131, P6, DOI 10.1016/j.procs.2018.04.179
NR 36
TC 0
Z9 0
U1 4
U2 32
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2023
VL 34
IS 2
AR e2098
DI 10.1002/cav.2098
EA AUG 2022
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D7UU4
UT WOS:000836206000001
DA 2024-07-18
ER

PT J
AU Yin, JF
   Zhu, DM
   Shi, M
   Li, ZX
   Duan, M
   Mi, XY
   Wang, ZQ
AF Yin, Jingfang
   Zhu, Dengming
   Shi, Min
   Li, Zhaoxin
   Duan, Ming
   Mi, Xiangyuan
   Wang, Zhaoqi
TI MoFiM: A morphable fish modeling method for underwater binocular vision
   system
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D reconstruction of fish; fish morphology landmarks; landmark
   estimation; underwater fish dataset
ID 3D; RECONSTRUCTION; SHAPE
AB Fish morphology is an essential basis for fishery management, as it can reflect the growth status of fishes. Noncontact 3D reconstruction of underwater fish is a new way to obtain fish morphology. While it is difficult to reconstruct fish on account of the inadequate information caused by fish swimming and poor underwater imaging. This article introduces a morphable fish modeling method for the underwater binocular vision system. First, we define a fish representation based on selected landmarks. Then, we propose a chirality-supervision incorporated hourglass network to estimate fish orientation and fish 2D landmarks simultaneously, and calculate fish 3D landmarks by triangulation. Next, we propose a fish modeling method which is based on 3D landmarks and introduce the optimization procedure of fish modeling. Finally, we obtain the complete 3D fish model corresponding to the input images. To train our network and build a parametric model, we constructed an underwater vision dataset and fish instance dataset respectively. We conducted experiments with grass carp as an example, and the experimental results show that our method can achieve effective fish modeling and is useful for noncontact measurement of underwater fish.
C1 [Yin, Jingfang; Zhu, Dengming; Li, Zhaoxin; Wang, Zhaoqi] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Shi, Min] North China Elect Power Univ, Sch Control & Comp Engn, Beijing, Peoples R China.
   [Duan, Ming; Mi, Xiangyuan] Chinese Acad Sci, Inst Hydrobiol, Wuhan, Hubei, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   North China Electric Power University; Chinese Academy of Sciences;
   Institute of Hydrobiology, CAS
RP Zhu, DM (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
EM mdzhu@ict.ac.cn
RI DUAN, Ming/D-7189-2012
OI Zhu, Dengming/0000-0001-5078-5780
FU National Key Research and Development Program of China [2020YFB1710400];
   Scientific Instrument Developing Project of the Chinese Academy of
   Sciences [YJKYYQ20190055]; National Natural Science Foundation of China
   [32172955]
FX National Key Research and Development Program of China, Grant/Award
   Number: 2020YFB1710400; Scientific Instrument Developing Project of the
   Chinese Academy of Sciences, Grant/Award Number: YJKYYQ20190055;
   National Natural Science Foundation of China, Grant/Award Number:
   32172955
CR Agudo Antonio, 2022, ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2495, DOI 10.1109/ICASSP43922.2022.9746343
   Agudo A, 2022, IEEE T PATTERN ANAL, V44, P519, DOI 10.1109/TPAMI.2020.3008276
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 1987, Visual Reconstruction
   [Anonymous], Florida Museum of Natural History 2021 Historical Archaeology Type Gallery: List of Types
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Dibra E, 2016, INT CONF 3D VISION, P108, DOI 10.1109/3DV.2016.19
   Fernandes AFA, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105274
   Guan P, 2009, IEEE I CONF COMP VIS, P1381, DOI 10.1109/iccv.2009.5459300
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hu haitao, 2022, Journal of Zhejiang University (Science Edition), V49, P19, DOI 10.3785/j.issn.1008-9497.2022.01.003
   Jiang L, 2018, IEEE T IMAGE PROCESS, V27, P4756, DOI 10.1109/TIP.2018.2845697
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Kingma D. P., 2014, arXiv
   Li Z., 2009, Research on Structured Light 3D Measurement Technology and System Based on Digital Grating Projection
   Liang J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133691
   Lin Zhiqiu, 2020, P IEEECVF C COMPUTER, P12295
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Skinner KA, 2019, IEEE INT CONF ROBOT, P7947, DOI [10.1109/ICRA.2019.8794272, 10.1109/icra.2019.8794272]
   Sorkine O, 2007, S GEOM PROC, V4, P109, DOI [10.1145/1073204.1073323, DOI 10.1145/1073204.1073323]
   STRAUSS RE, 1982, SYST ZOOL, V31, P113, DOI 10.2307/2413032
   Tachella J, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12943-7
   Terzopoulos D., 1994, Artificial Life, V1, P327
   Valle R, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102846
   Vatnehol S, 2018, ICES J MAR SCI, V75, P1803, DOI 10.1093/icesjms/fsy029
   Weidner Nick, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5709, DOI 10.1109/ICRA.2017.7989672
   Wu FZ, 2019, PROC CVPR IEEE, P959, DOI 10.1109/CVPR.2019.00105
   Xiaoyuan Tu, 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P43
   Xiong Ying, 2015, Hupo Kexue, V27, P466
   Yao Y, 2020, P IEEE CVF C COMP VI, P7600
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yin JF, 2019, IEEE ACCESS, V7, P112544, DOI 10.1109/ACCESS.2019.2934863
   Yu ZH, 2020, PROC CVPR IEEE, P1946, DOI 10.1109/CVPR42600.2020.00202
   Zelditch ML, 2012, GEOMETRIC MORPHOMETRICS FOR BIOLOGISTS: A PRIMER, 2ND EDITION, P1
   [张琮毅 Zhang Congyi], 2019, [计算机学报, Chinese Journal of Computers], V42, P1939
   Zhen WK, 2020, IEEE INT CONF ROBOT, P6773, DOI [10.1109/icra40945.2020.9197030, 10.1109/ICRA40945.2020.9197030]
   Zhou SZ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778863
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
NR 46
TC 0
Z9 0
U1 4
U2 38
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2022
VL 33
IS 5
AR e2104
DI 10.1002/cav.2104
EA JUL 2022
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5E9FV
UT WOS:000829769300001
DA 2024-07-18
ER

PT J
AU Zhou, LF
   Kong, MY
   Liu, ZW
   Li, L
AF Zhou, Lanfeng
   Kong, Mingyue
   Liu, Ziwei
   Li, Ling
TI Vision sensor-based SLAM problem for small UAVs in dynamic indoor
   environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dynamic environment; ORB-SLAM3; positioning; target detection; UAV;
   visual SLAM
AB In recent years, with the rapid development of artificial intelligence, machine vision and other related technologies, there has been a demand for higher levels of intelligence in UAVs. There are many excellent SLAM systems available, but most of them assume that their working environment is static. When there are dynamic objects in the environment the localization and mapping accuracy of the SLAM system is reduced, and it can even cause its tracking to fail. To solve this problem. In this paper, we propose a target detection-based SLAM algorithm for real-time operation in crowded dynamic environments. The algorithm removes feature points of dynamic objects from key frames and then constructs a point cloud map of based on the state-of-the-art SLAM system ORB-SLAM3. Finally, the proposed method is validated and evaluated on multiple dynamic datasets and real environments. The results show that the algorithm in this paper outperforms other visual SLAM algorithms in terms of localization and map building accuracy in more highly dynamic datasets, while guaranteeing performance.
C1 [Zhou, Lanfeng; Kong, Mingyue; Liu, Ziwei; Li, Ling] Shanghai Inst Technol, Shanghai, Peoples R China.
C3 Shanghai Institute of Technology
RP Zhou, LF; Kong, MY (corresponding author), Shanghai Inst Technol, Shanghai, Peoples R China.
EM lfzhou@sit.edu.cn; spartaqaq@163.com
CR Bau D, 2020, P NATL ACAD SCI USA, V117, P30071, DOI 10.1073/pnas.1907375117
   Bingzhen Li, 2021, Proceedings of the 2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA), P137, DOI 10.1109/ICPECA51329.2021.9362714
   Boudjit K, 2022, J EXP THEOR ARTIF IN, V34, P527, DOI 10.1080/0952813X.2021.1907793
   Campos Carlos, 2021, IEEE Transactions on Robotics, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Labbé M, 2019, J FIELD ROBOT, V36, P416, DOI 10.1002/rob.21831
   LaValley MP, 2008, CIRCULATION, V117, P2395, DOI 10.1161/CIRCULATIONAHA.106.682658
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   R┬u┬anz M., 2017, REAL TIME SEGMENTATI
   Soares JCV, 2019, 2019 19TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P135, DOI 10.1109/ICAR46387.2019.8981617
   Xiao LH, 2019, ROBOT AUTON SYST, V117, P1, DOI 10.1016/j.robot.2019.03.012
   Yao EL, 2018, ROBOT AUTON SYST, V107, P209, DOI 10.1016/j.robot.2018.06.009
   Zhong FW, 2018, IEEE WINT CONF APPL, P1001, DOI 10.1109/WACV.2018.00115
   Zhou K, 2016, DESTECH TRANS COMP
NR 20
TC 2
Z9 2
U1 4
U2 41
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2088
DI 10.1002/cav.2088
EA JUN 2022
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000806085100001
DA 2024-07-18
ER

PT J
AU Rativa, AS
   Postma, M
   Zaanen, M
AF Rativa, Alexandra Sierra
   Postma, Marie
   Zaanen, Menno
TI The uncanny valley of a virtual animal
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animal-likeness; animateness; attractiveness; commonality; familiarity;
   interestingness; naturalness; uncanny valley; virtual animals; virtual
   characters; virtual pandas
AB Virtual robots, including virtual animals, are expected to play a major role within affective and aesthetic interfaces, serious games, video instruction, and the personalization of educational instruction. Their actual impact, however, will very much depend on user perception of virtual characters as the uncanny valley hypothesis has shown that the design of virtual characters determines user experiences. In this article, we investigated whether the uncanny valley effect, which has already been found for the human-like appearance of virtual characters, can also be found for animal-like appearances. We conducted an online study (N = 163) in which six different animal designs were evaluated in terms of the following properties: familiarity, commonality, naturalness, attractiveness, interestingness, and animateness. The study participants differed in age (under 10-60 years) and origin (Europe, Asia, North America, and South America). For the evaluation of the results, we ranked the animal-likeness of the character using both expert opinion and participant judgments. Next to that, we investigated the effect of movement and morbidity. The results confirm the existence of the uncanny valley effect for virtual animals, especially with respect to familiarity and commonality, for both still and moving images. The effect was particularly pronounced for morbid images. For naturalness and attractiveness, the effect was only present in the expert-based ranking, but not in the participant-based ranking. No uncanny valley effect was detected for interestingness and animateness. This investigation revealed that the appearance of virtual animals directly affects user perception and thus, presumably, impacts user experience when used in applied settings.
C1 [Rativa, Alexandra Sierra; Postma, Marie] Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
   [Rativa, Alexandra Sierra] Breda Univ Appl Sci, Acad Games & Media, Breda, Netherlands.
   [Zaanen, Menno] North West Univ, South African Ctr Digital Language Resources SADi, Potchefstroom, South Africa.
C3 Tilburg University; Breda University of Applied Sciences; North West
   University - South Africa
RP Postma, M (corresponding author), Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands.
EM profealexandrasierra@gmail.com
OI Postma, Marie/0000-0002-5919-209X; Sierra Rativa,
   Alexandra/0000-0002-8645-8121
FU Departamento Administrativo de Ciencia, Tecnologia e Innovacion
   (Colciencias); Nederlandse Organisatie voor Wetenschappelijk Onderzoek
FX Departamento Administrativo de Ciencia, Tecnologia e Innovacion
   (Colciencias); Nederlandse Organisatie voor Wetenschappelijk Onderzoek
CR ap Cenydd L, 2013, COMPUT ANIMAT VIRT W, V24, P65, DOI 10.1002/cav.1436
   Bartneck Christoph, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P269, DOI 10.1109/ROMAN.2009.5326351
   Burleigh TJ, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01488
   Burleigh TJ, 2013, COMPUT HUM BEHAV, V29, P759, DOI 10.1016/j.chb.2012.11.021
   Ciechanowski L, 2019, FUTURE GENER COMP SY, V92, P539, DOI 10.1016/j.future.2018.01.055
   Criscuolo NM., 2019, THESIS U MASSACHUSET, P825, DOI [10.7275/14427281, DOI 10.7275/14427281]
   Dill Vanderson, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P511, DOI 10.1007/978-3-642-33197-8_62
   Ducarme Frederic., 2013, BIOSCIENCES MASTER R, V10, P1
   Ho CC, 2010, COMPUT HUM BEHAV, V26, P1508, DOI 10.1016/j.chb.2010.05.015
   INTONSPETERSON MJ, 1981, J EXP PSYCHOL-HUM L, V7, P133, DOI 10.1037/0278-7393.7.2.133
   Kandel K, 2015, BIOL CONSERV, V181, P150, DOI 10.1016/j.biocon.2014.10.007
   Kätsyri J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00390
   Kim SJ, 2012, J GLOB FASH MARK, V3, P81, DOI 10.1080/20932685.2012.10593110
   Lanier J., 1992, Interactive Learning International, V8, P275
   Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001
   Löffler D, 2020, ACMIEEE INT CONF HUM, P261, DOI 10.1145/3319502.3374788
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   MacDorman K, 2006, ICCS COGSCI 2006 LON, P26, DOI DOI 10.1093/SCAN/NSR025
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   MotionCow, PHOTOREALISTIC PAND
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Rativa AS, 2020, ADV INTELL SYST, V1023, P419, DOI 10.1007/978-3-030-26945-6_38
   Royse P, 2007, NEW MEDIA SOC, V9, P555, DOI 10.1177/1461444807080322
   Saveanimalsworld, OS PAND
   Schneider E., 2007, Schneider, E. , Wang, Y. (2007). Exploring the uncanny valley with Japanese video game characters. In Proceedings of DiGRA 2007: Situated play (pp. 546-549).
   Schwind V, 2018, INT J HUM-COMPUT ST, V111, P49, DOI 10.1016/j.ijhcs.2017.11.003
   Schwind V., 2018, Interactions, V25, P45, DOI [https://doi.org/10.1145/3236673, DOI 10.1145/3236673]
   Schwind Valentin, 2018, Implications of the uncanny valley of avatars and virtual characters for human-computer interaction, DOI [10.18419/opus-9936, DOI 10.18419/OPUS-9936]
   Rativa AS, 2020, SIMULAT GAMING, V51, P685, DOI 10.1177/1046878120926694
   Tinwell A, 2011, COMPUT HUM BEHAV, V27, P741, DOI 10.1016/j.chb.2010.10.018
   Zlotowski J.A., 2018, Geminoid Studies, P163, DOI DOI 10.1007/978-981-10-8702-8_10
NR 32
TC 2
Z9 2
U1 2
U2 25
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2022
VL 33
IS 2
AR e2043
DI 10.1002/cav.2043
EA MAR 2022
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 0T8YJ
UT WOS:000769913500001
OA Green Published
DA 2024-07-18
ER

PT J
AU Aman, A
   Demirci, S
   Güdükbay, U
   Wald, I
AF Aman, Aytek
   Demirci, Serkan
   Gudukbay, Ugur
   Wald, Ingo
TI Multi-level tetrahedralization-based accelerator for ray-tracing
   animated scenes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE acceleration structure; Bounding Volume Hierarchy; k-d tree; ray
   tracing; tetrahedralization
AB We describe a hybrid acceleration structure for ray tracing. The hybrid structure is a Bounding Volume Hierarchy (BVH) where the leaf nodes are tetrahedralized for a decent ray-surface intersection performance. We use the hybrid acceleration structure (BTH) in a two-level acceleration structure for rendering animated scenes. There is a BVH at the top level in this two-level structure and the proposed hybrid structure (BTH) at the bottom level. We test the proposed two-level structure (BVH-BTH) for various animated scenes and obtained promising results against other acceleration structures in terms of rendering times. The two-level BVH-BTH structure outperforms the two-level BVH structure for the tested dynamic scenes.
C1 [Aman, Aytek; Demirci, Serkan; Gudukbay, Ugur] Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
   [Wald, Ingo] NVIDIA, Salt Lake City, UT USA.
C3 Ihsan Dogramaci Bilkent University
RP Güdükbay, U (corresponding author), Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
EM gudukbay@cs.bilkent.edu.tr
RI Gudukbay, Ugur/F-1012-2011
OI Gudukbay, Ugur/0000-0003-2462-6959; Wald, Ingo/0000-0003-0046-713X;
   Demirci, Serkan/0000-0001-8805-5310
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [117E881]
FX The Scientific and Technological Research Council of Turkey (TUBITAK),
   Grant/Award Number: 117E881
CR Aman A., 2021, ARXIV210302309
   [Anonymous], 2016, PHYS BASED RENDERING
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Cleary J. G., 1988, Visual Computer, V4, P65, DOI 10.1007/BF01905559
   Ericson C., 2004, REAL TIME COLLISION
   GOLDSMITH J, 1987, IEEE COMPUT GRAPH, V7, P14, DOI 10.1109/MCG.1987.276983
   Hatfield, 1988, TUTORIAL COMPUTER GR, P148
   Hu YX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201353
   Kajiya J. T., 1986, SIGGRAPH, P143, DOI 10.1145/15886.15902
   Lagae A, 2008, COMPUT GRAPH FORUM, V27, P1303, DOI 10.1111/j.1467-8659.2008.01269.x
   Lext J., 2001, EUR 2001 SHORT PRES, P311
   Lubich M., 2012, BLENDER MINUTES
   M?ller G., 1998, P INT C COMP VIS GOA, P19
   MacDonald J. D., 1990, Visual Computer, V6, P153, DOI 10.1007/BF01911006
   Maria M, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 1, P236, DOI 10.5220/0006131002360243
   McGuire M., 2017, Computer Graphics Archive
   Popov S, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P89
   Si H, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2629697
   Wald I, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186650
   Wald I, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P33, DOI 10.1109/RT.2007.4342588
   Wald I, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P61
   Wang, 1996, P 5 INT MESH ROUNDT, P47
NR 22
TC 2
Z9 2
U1 2
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2024
DI 10.1002/cav.2024
EA JUN 2021
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000656544500001
DA 2024-07-18
ER

PT J
AU Ali, G
   Lee, M
   Hwang, JI
AF Ali, Ghazanfar
   Lee, Myungho
   Hwang, Jae-In
TI Automatic text-to-gesture rule generation for embodied conversational
   agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; gesture generation; rule-based mapping; social
   agents; virtual agents
AB Interactions with embodied conversational agents can be enhanced using human-like co-speech gestures. Traditionally, rule-based co-speech gesture mapping has been utilized for this purpose. However, the creation of this mapping is laborious and often requires human experts. Moreover, human-created mapping tends to be limited, therefore prone to generate repeated gestures. In this article, we present an approach to automate the generation of rule-based co-speech gesture mapping from publicly available large video data set without the intervention of human experts. At run-time, word embedding is utilized for rule searching to get the semantic-aware, meaningful, and accurate rule. The evaluation indicated that our method achieved comparable performance with the manual map generated by human experts, with a more variety of gestures activated. Moreover, synergy effects were observed in users' perception of generated co-speech gestures when combined with the manual map.
C1 [Ali, Ghazanfar] Univ Sci & Technol, Div NT IT, Daejeon, South Korea.
   [Lee, Myungho; Hwang, Jae-In] Korea Inst Sci & Technol, Imaging Media Res Ctr, Seoul, South Korea.
C3 University of Science & Technology (UST); Korea Institute of Science &
   Technology (KIST)
RP Hwang, JI (corresponding author), Korea Inst Sci & Technol, Imaging Media Res Ctr, Seoul, South Korea.
EM hji@kist.re.kr
OI Ali, Ghazanfar/0000-0002-7741-1938
FU Korea Creative Content Agency (KOCCA) in the Culture Technology (CT)
   Research and Development Program; KIST Flagship Project
FX This research is supported by the Korea Creative Content Agency (KOCCA)
   in the Culture Technology (CT) Research and Development Program and KIST
   Flagship Project.
CR Ali G, 2019, PROCEEDINGS OF THE 32ND INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2019), P47, DOI 10.1145/3328756.3328758
   Anabuki M, 2000, P C HUM FACT COMP SY
   Arroyo-Palacios J, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P121, DOI 10.1109/ISMAR-Adjunct.2017.45
   Avramova V, 2017, LECT NOTES COMPUTER
   Bogdanovych A, 2015, LECT NOTES ARTIF INT, V8955, P142, DOI 10.1007/978-3-319-14803-8_11
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Castano R, 2014, COMMUN COMPUT PHYS, V498, P34
   de Coninck F, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P41, DOI 10.1109/AIVR46125.2019.00016
   Ferstl Y, 2019, P MIG 2019 ACM C MOT, P1
   Ginosar S, 2019, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2019.00361
   Heylen D, 2008, LECT NOTES COMPUT SC, V5208, P270
   Kipp M, 2001, P EUROSPEECH 2001 SC
   Knapp M.L., 2013, Cengage Learning
   Kopp S., 2003, KI, V17, P11
   Kucherenko T, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P97, DOI 10.1145/3308532.3329472
   Lee Jina, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P161, DOI 10.1007/978-3-642-33197-8_17
   Lee J, 2006, LECT NOTES ARTIF INT, V4133, P243
   Levine S, 2010, P ACM SIGGRAPH 2010
   Machidon OM, 2018, J CULT HERIT, V33, P249, DOI 10.1016/j.culher.2018.01.007
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Richards D., 2012, P 8 AUSTR C INT ENT, P1
   STUDDERTKENNEDY M, 1994, LANG SPEECH, V37, P203, DOI 10.1177/002383099403700208
   Vosinakis S, 2018, LECT NOTES COMPUT SC, V10754, P197, DOI 10.1007/978-3-319-75789-6_14
   Yoon Y, 2019, IEEE INT CONF ROBOT, P4303, DOI [10.1109/icra.2019.8793720, 10.1109/ICRA.2019.8793720]
NR 26
TC 9
Z9 9
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1944
DI 10.1002/cav.1944
EA SEP 2020
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000566926000001
DA 2024-07-18
ER

PT J
AU Liu, WY
   Wong, SK
   Chen, CY
AF Liu, Wen-Yun
   Wong, Sai-Keung
   Chen, Chien-Yuan
TI A natural language interface with casual users for crowd animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd animation; interactive interface; natural language processing
ID SIMULATION; MODEL
AB We develop an interface that bridges crowd simulation and natural language processing techniques so that casual users can produce crowd animation by text input. The interface adopts a parser and a tagger to analyze simple English sentences to convert them into intermediate data structures that encapsulate the essential elements of crowds. There are five stages: preprocessing, parsing input sentences, crowd generation, animation adjustment, and crowd animation. Our system supports basic behaviors including standing, walking, running, escaping, being attracted, and queuing. We conducted a user experience study to evaluate the interface. The results show that the interface is user-friendly for casual users to produce crowd animation.
C1 [Liu, Wen-Yun; Wong, Sai-Keung; Chen, Chien-Yuan] Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Wong, SK (corresponding author), Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
EM cswingo@cs.nctu.edu.tw
FU Ministry of Science and Technology of the ROC [MOST 108-2221-E-009-080]
FX This research was supported by the Ministry of Science and Technology of
   the ROC under grant no. MOST 108-2221-E-009-080.
CR Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Chang A, 2014, P 2014 C EMP METH NA, P2028, DOI [DOI 10.3115/V1/D14-1217, 10.3115/v1/D14-1217.]
   Chen H, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1826
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Coyne B, 2001, COMP GRAPH, P487, DOI 10.1145/383259.383316
   De Marneffe M.-C., 2008, Stanford Typed Dependencies Manual
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Huang L, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7020079
   Huang Zhiheng., 2015, Bidirectional LSTM-CRF models for sequence tagging
   Irsoy O, 2014, P 2014 C EMPIRICAL M, P720, DOI DOI 10.3115/V1/D14-1080
   Johansson R, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1073
   Karamouzas I, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.238701
   Kim J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601170
   Krontiris A., 2016, P 29 INT C COMPUTER, P61
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   Lafferty J., 2001, CONDITIONAL RANDOM F, P1
   LI FS, 2016, ADV SOC SCI EDUC HUM, P101
   Ma M, 2006, THESIS
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   McCallum A., 2000, 17 INT C MACH LEARN, P591
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Schuster Sebastian, 2016, UNIVERSAL DEPENDENCI
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Ulicny Branislav, 2004, SCA'04'- Proc. of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P243, DOI [DOI 10.2312/SCA/SCA04/243-252, 10.1145/1028523.1028555, DOI 10.1145/1028523.1028555]
   Volonte M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P293, DOI [10.1109/VR46266.2020.1581610451331, 10.1109/VR46266.2020.00-55]
   Wolinski D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982442
   Wong SK, 2018, P ACM SIGGRAPH S INT
   Zhang L, 2017, CHIN CONTR CONF, P5629, DOI 10.23919/ChiCC.2017.8028251
NR 31
TC 5
Z9 5
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1965
DI 10.1002/cav.1965
EA SEP 2020
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000565674500001
DA 2024-07-18
ER

PT J
AU Yu, P
   Pan, JJ
   Qin, H
   Hao, AM
   Wang, HP
AF Yu, Peng
   Pan, Junjun
   Qin, Hong
   Hao, Aimin
   Wang, Haipeng
TI Real-time suturing simulation for virtual reality medical training
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE suturing simulation; position-based dynamics; virtual surgery simulator
AB At present, virtual reality (VR) -based medical simulators provide an efficient and cost-effective alternative without exposing risk to the traditional training approaches. As an essential and indispensable task in fundamental surgical skills training, the research of suturing simulation still remains insufficient in the field of virtual surgery. In this paper, we present a real-time suturing simulation framework which can handle the complex interactions between surgical instruments and soft tissue. The simulation consists of two stages: external interaction and internal coupling. External interaction involves the interplay between needle/suture and the soft tissue, which are both deformed by position-based dynamics (PBD) with different constraints. At the internal coupling stage, once the force exceeds a threshold, the needle tip will puncture and penetrate into the soft tissue and generate a path. To guarantee the needle/suture accurately following the path inside the soft tissue, we propose a novel coupling method by matching and generating the constraints among needle, suture, and penetration path. We have applied this suturing simulation into a VR laparoscopic surgery simulator with haptic force. Our experimental results demonstrate that our approach can achieve real-time performance with a high degree of visual realism and haptic fidelity.
C1 [Yu, Peng; Pan, Junjun; Hao, Aimin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Yu, Peng; Pan, Junjun; Hao, Aimin] Peng Cheng Lab, Shenzhen, Peoples R China.
   [Pan, Junjun] Bournemouth Univ, Fac Media & Commun, Poole, Dorset, England.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, New York, NY 11794 USA.
   [Wang, Haipeng] Beijing Aerosp Gen Hosp, Beijing, Peoples R China.
C3 Beihang University; Peng Cheng Laboratory; Bournemouth University; State
   University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Pan, JJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.; Qin, H (corresponding author), SUNY Stony Brook, Dept Comp Sci, New York, NY 11794 USA.
EM pan_junjun@buaa.edu.cn; qin@cs.sunysb.edu
RI Pan, Junjun/A-1316-2013
OI Yu, Peng/0000-0002-8652-2744
FU National Key R&D Program of China [2018YFC0115102]; National Natural
   Science Foundation of China [61872020, 61532002, 61672149]; Beijing
   Natural Science Foundation Haidian Primitive Innovation Joint Fund
   [L182016]; Beijing Advanced Innovation Center for Biomedical Engineering
   [ZF138G1714]; Research Unit of Virtual Human and Virtual Surgery,
   Chinese Academy of Medical Sciences' Shenzhen Research Institute of Big
   Data, Shenzhen
FX This research is supported in part by National Key R&D Program of China
   (No. 2018YFC0115102), National Natural Science Foundation of China (No.
   61872020, 61532002, 61672149), Beijing Natural Science Foundation
   Haidian Primitive Innovation Joint Fund (L182016), Beijing Advanced
   Innovation Center for Biomedical Engineering (ZF138G1714), Research Unit
   of Virtual Human and Virtual Surgery, Chinese Academy of Medical
   Sciences' Shenzhen Research Institute of Big Data, Shenzhen 518000.
CR Agha RA, 2015, INT SURG, V100, P350, DOI 10.9738/INTSURG-D-14-00004.1
   Bender J, 2014, COMPUT GRAPH-UK, V44, P1, DOI 10.1016/j.cag.2014.07.004
   Chentanez N, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531394
   Deul C, 2018, COMPUT GRAPH FORUM, V37, P313, DOI 10.1111/cgf.13326
   DiMaio SP, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P344, DOI 10.1109/HAPTIC.2002.998979
   Goksel Orcun, 2006, Comput Aided Surg, V11, P279, DOI 10.1080/10929080601089997
   Hu YX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201353
   Jackson RC, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P3659, DOI 10.1109/IROS.2016.7759539
   Khadem M, 2016, IEEE ROBOT AUTOM LET, V1, P800, DOI 10.1109/LRA.2016.2528301
   Kugelstadt T., 2016, Symposium on Computer Animation, P169, DOI [10.2312/sca.20161234, DOI 10.2312/SCA.20161234]
   Pai DK, 2002, COMPUT GRAPH FORUM, V21, P347, DOI 10.1111/1467-8659.00594
   Qi D, 2017, J BIOMED INFORM, V75, P48, DOI 10.1016/j.jbi.2017.09.010
   Sifakis E, 2012, ACM SIGGRAPH 2012 CO, DOI [10.1145/2343483.2343501, DOI 10.1145/2343483.2343501]
   Soler C, 2018, COMPUT GRAPH FORUM, V37, P137, DOI 10.1111/cgf.13519
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Xu L, 2018, INT J COMPUT ASS RAD, V13, P1019, DOI 10.1007/s11548-018-1739-1
NR 16
TC 5
Z9 5
U1 6
U2 38
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1940
DI 10.1002/cav.1940
EA SEP 2020
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000565701700001
DA 2024-07-18
ER

PT J
AU Zhang, X
   Schaumann, D
   Haworth, B
   Faloutsos, P
   Kapadia, M
AF Zhang, Xun
   Schaumann, Davide
   Haworth, Brandon
   Faloutsos, Petros
   Kapadia, Mubbasir
TI Coupling agent motivations and spatial behaviors for authoring
   multiagent narratives
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE agent-centric authoring; behavior-centric authoring; multiagent behavior
   authoring; multiagent behavior synthesis; multiagent narratives;
   space-centric authoring
ID NAVIGATION; MODEL
AB Authoring behavior narratives for heterogeneous multiagent virtual humans engaged in collaborative, localized, and task-based behaviors can be challenging. Traditional behavior authoring frameworks are either space-centric, where occupancy parameters are specified; behavior-centric, where multiagent behaviors are defined; or agent-centric, where desires and intentions drive agents' behavior. In this paper, we propose to integrate these approaches into a unique framework to author behavior narratives that progressively satisfy time-varying building-level occupancy specifications, room-level behavior distributions, and agent-level motivations using a prioritized resource allocation system. This approach can generate progressively more complex and plausible narratives that satisfy spatial, behavioral, and social constraints. Possible applications of this system involve computer gaming and decision-making in engineering and architectural design.
C1 [Zhang, Xun; Schaumann, Davide; Kapadia, Mubbasir] Rutgers State Univ, Comp Sci Dept, New Brunswick, NJ USA.
   [Haworth, Brandon; Faloutsos, Petros] York Univ, Elect Engn & Comp Sci Dept, Toronto, ON, Canada.
   [Faloutsos, Petros] UHN, Toronto Rehabil Inst, Toronto, ON, Canada.
C3 Rutgers University System; Rutgers University New Brunswick; York
   University - Canada; University of Toronto; University Health Network
   Toronto; Toronto Rehabilitation Institute
RP Zhang, X (corresponding author), Rutgers State Univ, New Brunswick, NJ 08854 USA.
EM xz348@cs.rutgers.edu
OI Schaumann, Davide/0000-0001-9899-2818; Haworth,
   Brandon/0000-0001-8134-0047; Zhang, Xun/0000-0002-7777-1052
FU NSERC; National Science Foundation (NSF) [IIS-1703883, SAS-1723869];
   DARPA SocialSim [W911NF-17-C-0098]; Murray Fellowship
FX NSERC Discovery and Create Programs; National Science Foundation (NSF),
   Grant/Award Number: IIS-1703883 and SAS-1723869 ; DARPA SocialSim,
   Grant/Award Number: W911NF-17-C-0098 ; Murray Fellowship
CR Abaci T, 2005, 13 INT C CENTR EUR C
   Chiandussi G, 2012, COMPUT MATH APPL, V63, P912, DOI 10.1016/j.camwa.2011.11.057
   Haldi F, 2011, J BUILD PERFORM SIMU, V4, P323, DOI 10.1080/19401493.2011.558213
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Iqbal MS, 2014, TRANSPORT RES C-EMER, V40, P63, DOI 10.1016/j.trc.2014.01.002
   Kapadia M, 2015, VIRTUAL CROWDS STEPS, V7
   Kapadia M, 2016, P 9 INT C MOT GAM 20
   Krontiris A, 2016, P 29 INT C COMP AN S
   Mahdavi A, 2015, ENERG BUILDINGS, V86, P349, DOI 10.1016/j.enbuild.2014.10.027
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Normoyle A, 2014, P 18 M ACM SIGGRAPH
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Rao A. S., 1995, ICMAS-95 Proceedings. First International Conference on Multi-Agent Systems, P312
   Reiss S, 1998, PSYCHOL ASSESSMENT, V10, P97, DOI 10.1037/1040-3590.10.2.97
   Reynolds CW, 1999, GAM DEV C 1999 SAN J
   Schaumann D, 2017, P S SIMULATION ARCHI
   Shoulson Alexander, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P144, DOI 10.1007/978-3-642-25090-3_13
   Singh S, 2011, COMPUT ANIMAT VIRT W, V22, P151, DOI 10.1002/cav.403
   Stocker C, 2010, INT C INT VIRT AG 20
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Yu Q, 2007, P 2007 ACM SIGGRAPH
   Zhang X., 2019, P S SIM ARCH URB DES, P1
NR 23
TC 6
Z9 7
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1898
DI 10.1002/cav.1898
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400011
DA 2024-07-18
ER

PT J
AU Chen, K
   Johan, H
AF Chen, Kan
   Johan, Henry
TI Interactive authoring of bending and twisting motions of short plants
   using hand gestures
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation authoring; hand gestures; short plants
ID ANIMATION; TREES
AB In this paper, we propose an approach to interactively author the bending and twisting motions of short plants using hand gestures, especially suitable for grass, flowers, and leaves. Our method is based on the observations that hand motions can represent the bending and twisting motions of short plants and using a hand to describe motions is natural and proficient for human. We therefore use a hand as a puppet to author the animation of one single short plant based on transferring the motions of a hand to the motions of a short plant. We first author the global motions of the short plant followed by the motions of its elements such as leaves and flowers. We also propose a framework to utilize the animation results to animate a field of short plants and further adjust the motion effects according to the properties of the short plants, such as rigidity. As a result, users can intuitively and rapidly author and generate their desired motions of short plants under the influence of external forces. Especially, our method is accessible to non-expert users and suitable for fast prototyping and authoring specific motions of short plants such as in cartoons.
C1 [Chen, Kan] Nanyang Technol Univ, 50 Nanyang Ave,NS1-1,Level 5, Singapore 639798, Singapore.
   [Chen, Kan] DigiPen Inst Technol Singapore, 510 Dover Rd,02-01 SIT SP Bldg, Singapore 139660, Singapore.
   [Johan, Henry] Fraunhofer IDM NTU, 50 Nanyang Ave,NS1-1, Singapore 639798, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Chen, K (corresponding author), Nanyang Technol Univ, 50 Nanyang Ave,NS1-1,Level 5, Singapore 639798, Singapore.
EM kchen1@e.ntu.edu.sg
FU National Research Foundation under its International Research Centres in
   Singapore Funding Initiative
FX This research is supported by the National Research Foundation, Prime
   Minister's Office, Singapore under its International Research Centres in
   Singapore Funding Initiative.
CR Akagi Y, 2006, COMPUT GRAPH-UK, V30, P529, DOI 10.1016/j.cag.2006.03.017
   [Anonymous], 2013, P 12 ACM SIGGRAPHEUR, DOI DOI 10.1145/2485895.2485903
   CHEN K, 2013, A SIMPLE METHOD TO A, P244, DOI DOI 10.1109/CADGRAPHICS.2013.39
   Chen K, 2015, I3D 15 P 19 S INT 3D, P69
   CHEN K, 2010, REAL TIME CONTINUUM, P227
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   Diener J, 2009, COMPUT GRAPH FORUM, V28, P533, DOI 10.1111/j.1467-8659.2009.01393.x
   Diener Julien., 2006, Proceedings of the Eurographics Symposium on Computer Animation, P187
   Dontcheva M, 2003, ACM T GRAPHIC, V22, P409, DOI 10.1145/882262.882285
   ElKoura G., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P110
   FAN ZZ, 2015, I3D 15 P 19 S INT 3D, P55, DOI DOI 10.1145/2699276.2699283
   Gkioulekas I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516972
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Gleicher M, 2000, SIGGRAPH 00 ACM SIGG
   Habel R, 2009, COMPUT GRAPH FORUM, V28, P523, DOI 10.1111/j.1467-8659.2009.01391.x
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Hu SJ, 2012, VISUAL COMPUT, V28, P859, DOI 10.1007/s00371-012-0694-z
   James DL, 2007, ACM T GRAPHIC, V26
   Jens Orthmann, 2009, Journal of WSCG, V17, P65
   K: PELZER., 2004, GPU GEMS PROGRAMMING, P107
   Kazi RH, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P351, DOI 10.1145/2556288.2556987
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Li C, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024161
   Lockwood Noah., 2012, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '12, P43, DOI [10.2312/SCA/SCA12/043-052, DOI 10.2312/SCA/SCA12/043-052]
   Long J, 2015, VISUAL COMPUT, V31, P325, DOI 10.1007/s00371-014-0927-4
   Ma CY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964957
   Oshita M, 2014, VRCAI 14 P 13 ACM SI, P171
   Ota S, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P52, DOI 10.1109/CGI.2003.1214447
   Rhodin H, 2014, COMPUT GRAPH FORUM, V33, P273, DOI 10.1111/cgf.12325
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Shinya M., 1992, Computer Graphics Forum, V11, pC119, DOI 10.1111/1467-8659.1130119
   SHIRATORI T, 2013, EXPRESSING ANIMATED, P59
   Sousa T., 2007, GPU GEMS, V3, P373
   Stam J, 1997, COMPUT GRAPH FORUM, V16, pC159, DOI 10.1111/1467-8659.00152
   Sturman DJ, 1998, IEEE COMPUT GRAPH, V18, P38, DOI 10.1109/38.637269
   Weber JP, 2008, IEEE COMPUT GRAPH, V28, P67, DOI 10.1109/MCG.2008.51
   Wheatland N, 2015, COMPUT GRAPH FORUM, V34, P735, DOI 10.1111/cgf.12595
   Zhang L, 2007, ACM T GRAPHIC, P735
   Zhang L, 2007, COMPUT ANIMAT VIRT W, V18, P371, DOI 10.1002/cav.205
   Zioma R., 2007, GPU GEMS, V3, P105
NR 41
TC 2
Z9 2
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2017
VL 28
IS 6
AR e1747
DI 10.1002/cav.1747
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9YH
UT WOS:000417254100004
DA 2024-07-18
ER

PT J
AU Laclé, F
   Pronost, N
AF Lacle, Francis
   Pronost, Nicolas
TI A scalable geometrical model for musculotendon units
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE multi-scale virtual human; musculotendon unit modeling; geometrical
   enhancement
AB Physics-based simulation of systems such as virtual humans has benefited from recent advances in muscle actuation. However, to be manageable for motion controllers, muscles are usually solely represented by their action line, a polyline that does not include data on the tridimensional geometry of the muscle. This paper focuses on combining, by a controllable enhancement process, a functional and biomechanical model of musculotendon units with its high resolution geometrical counterpart. The method was developed in order to be invariant to spatial and polygonal configurations and to be scalable in both longitudinal and latitudinal directions. Results with 48 musculotendon units for the lower body show a drop of 84% with respect to the number of vertices when compared with the high resolution model, while maintaining the functional information. A real-time simulation experiment resulted in a runtime of 135 Hz. Copyright (C) 2015 JohnWiley & Sons, Ltd.
C1 [Lacle, Francis; Pronost, Nicolas] Univ Utrecht, Dept Informat Comp Sci, Princetonpl 5, NL-3584 CC Utrecht, Netherlands.
   [Pronost, Nicolas] Univ Claude Bernard Lyon 1, CNRS, LIRIS 8 Blvd Niels Bohr, F-69622 Villeurbanne, France.
C3 Utrecht University; Institut National des Sciences Appliquees de Lyon -
   INSA Lyon; Centre National de la Recherche Scientifique (CNRS);
   Universite Claude Bernard Lyon 1
RP Pronost, N (corresponding author), Univ Claude Bernard Lyon 1, CNRS, LIRIS 8 Blvd Niels Bohr, F-69622 Villeurbanne, France.
EM nicolas.pronost@univ-lyon1.fr
OI PRONOST, NICOLAS/0000-0003-4499-509X; Lacle, Francis/0000-0002-7382-5711
CR Benjamin M, 2006, J ANAT, V208, P471, DOI 10.1111/j.1469-7580.2006.00540.x
   Berranen Y, 2012, IEEE ENG MED BIO, P4863, DOI 10.1109/EMBC.2012.6347083
   Blemker SS, 2005, ANN BIOMED ENG, V33, P661, DOI 10.1007/s10439-005-1433-7
   Chadwick J. E., 1989, Computer Graphics, V23, P243, DOI 10.1145/74334.74358
   Delp SL, 2007, IEEE T BIO-MED ENG, V54, P1940, DOI 10.1109/TBME.2007.901024
   DELP SL, 1990, IEEE T BIO-MED ENG, V37, P757, DOI 10.1109/10.102791
   Design S, ULT HUM MOD DAT SET
   Geijtenbeek T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508399
   Jacobson A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461916
   Kohout J, 2014, COMPUT GRAPH FORUM, V33, P1, DOI 10.1111/cgf.12354
   Lee D, 2011, FOUND TRENDS COMPUT, V7, P229, DOI 10.1561/0600000036
   Lee SH, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559756
   Lemos RR, 2005, COMPUT ANIMAT VIRT W, V16, P319, DOI 10.1002/cav.83
   Millard M, 2013, J BIOMECH ENG-T ASME, V135, DOI 10.1115/1.4023390
   Moller T., 1997, J GRAPHICS TOOLS, V2, P21, DOI [DOI 10.1080/10867651.1997.10487468, 10.1080/10867651.1997.10487468]
   Sánchez CA, 2014, COMP M BIO BIO E-IV, V2, P223, DOI 10.1080/21681163.2013.862861
   Si WG, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2626346
   Sueda S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360682
   Tan J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185522
   Teran J, 2005, IEEE T VIS COMPUT GR, V11, P317, DOI 10.1109/TVCG.2005.42
   Thalmann D, 1996, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P166, DOI 10.1109/CGI.1996.511798
   Wang JM, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185521
   Wilhelms J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P173, DOI 10.1145/258734.258833
   ZAJAC FE, 1989, CRIT REV BIOMED ENG, V17, P359
NR 24
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2017
VL 28
IS 1
AR e1684
DI 10.1002/cav.1684
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM0DZ
UT WOS:000394990300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Laraba, S
   Tilmanne, J
AF Laraba, Sohaib
   Tilmanne, Joelle
TI Dance performance evaluation using hidden Markov models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE gesture recognition; hidden Markov Models; interactive systems; maximum
   likelihood linear regression; performance evaluation
ID ACTION RECOGNITION
AB We present in this paper a hidden Markov model-based system for real-time gesture recognition and performance evaluation. The system decodes performed gestures and outputs at the end of a recognized gesture, a likelihood value that is transformed into a score. This score is used to evaluate a performance comparing to a reference one. For the learning procedure, a set of relational features has been extracted from high-precision motion capture system and used to train hidden Markov models. At runtime, a low-cost sensor (Microsoft Kinect) is used to capture a learner's movements. An intermediate step of model adaptation was hence requested to allow recognizing gestures captured by this low-cost sensor. We present one application of this gesture evaluation system in the context of traditional dance basics learning. The estimation of the log-likelihood allows giving a feedback to the learner as a score related to his performance. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Laraba, Sohaib; Tilmanne, Joelle] Univ Mons, Numediart Inst, TCTS Lab, Mons, Belgium.
C3 University of Mons
RP Laraba, S (corresponding author), Univ Mons, Numediart Inst, TCTS Lab, Mons, Belgium.
EM sohaib.laraba@umons.ac.be
RI Laraba, Sohaib/HHR-8810-2022
OI Laraba, Sohaib/0000-0002-7937-4149
CR [Anonymous], 2007, Information retrieval for music and motion
   Bevilacqua Frederic., 2009, Gesture Workshop, P73, DOI [10.1007/978-3-642-12553-9_7, DOI 10.1007/978-3-642-12553-9_7]
   Blackburn J, 2007, LECT NOTES COMPUT SC, V4814, P285
   Bloom V., 2012, 2012 IEEE COMP SOC C, P7, DOI [DOI 10.1109/CVPRW.2012.6239175, 10.1109/CVPRW.2012.6239175]
   Chan JCP, 2011, IEEE T LEARN TECHNOL, V4, P187, DOI 10.1109/TLT.2010.27
   de Bettio RW, 2013, J COMPUT SCI TECHNOL, V13, P69
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Kitsikidis Alexandros, 2014, Universal Access in Human-Computer Interaction. Design and Development Methods for Universal Access. 8th International Conference, UAHCI 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8513, P379, DOI 10.1007/978-3-319-07437-5_36
   Laraba S., 2015, P 8 ACM SIGGRAPH C M, P17
   Leggetter C.J., 1995, ARPA SPOKEN LANGUAGE, P110
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Pengyu Hong, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P410, DOI 10.1109/AFGR.2000.840667
   Ravet T., 2014, P 2014 INT WORKSH MO, P82
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98
   Young S., 2000, HTK BOOK VERSION 3 0
NR 19
TC 20
Z9 22
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 321
EP 329
DI 10.1002/cav.1715
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300016
DA 2024-07-18
ER

PT J
AU Xue, JJ
   Zhao, G
   Xiao, WL
AF Xue, Junjie
   Zhao, Gang
   Xiao, Wenlei
TI An efficient GPU out-of-core framework for interactive rendering of
   large-scale CAD models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE massive model rendering; GPU out-of-core; geometry compression; LOD
   processing; occlusion culling
ID TREE
AB Real-time rendering of large-scale engineering computer-aided design (CAD) models has been recognized as a challenging task. Because of the constraints of limited graphics processing unit (GPU) memory size and computation capacity, a massive model with hundreds of millions of triangles cannot be loaded and rendered in real-time using most of modern GPUs. In this paper, an efficient GPU out-of-core framework is proposed for interactively visualizing large-scale CAD models. To improve efficiency of data fetching from CPU host memory to GPU device memory, a parallel offline geometry compression scheme is introduced to minimize the storage cost of each primitive by compressing the levels of detail (LOD) geometries into a highly compact format. At the rendering stage, occlusion culling and LOD processing algorithms are integrated and implemented with an efficient GPU-based approach to determine a minimal scale of primitives to be transferred for each frame. A prototype software system is developed to preprocess and render massive CAD models with the proposed framework. Experimental results show that users can walkthrough massive CAD models with hundreds of millions of triangles at high frame rates using our framework. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Xue, Junjie; Zhao, Gang; Xiao, Wenlei] Beihang Univ, Sch Mech Engn & Automat, Beijing, Peoples R China.
   [Zhao, Gang; Xiao, Wenlei] Minist Ind & Informat Technol, Key Lab Aeronaut Smart Mfg, Beijing, Peoples R China.
   [Xue, Junjie; Zhao, Gang] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Zhao, G (corresponding author), Beihang Univ, Sch Mech Engn & Automat, Beijing, Peoples R China.
EM zhaog@buaa.edu.cn
RI Zhao, Gang/JMC-6248-2023
CR Afra AT, 2012, COMPUT GRAPH FORUM, V31, P75, DOI 10.1111/j.1467-8659.2011.02085.x
   Cigolle Zina H., 2014, Journal of Computer Graphics Techniques (JCGT), V3, P1
   DEERING M, 1995, P 22 ANN C COMP GRAP, P13
   Gobbetti E, 2005, ACM T GRAPHIC, V24, P878, DOI 10.1145/1073204.1073277
   Laine S, 2011, IEEE T VIS COMPUT GR, V17, P1048, DOI 10.1109/TVCG.2010.240
   MacDonald J. D., 1990, Visual Computer, V6, P153, DOI 10.1007/BF01911006
   Peng C., 2014, PACIFIC GRAPHIC SHOR
   Peng C, 2013, P ACM SIGGRAPH S INT, P187
   Peng C, 2012, 2012 SC COMPANION: HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SCC), P215, DOI 10.1109/SC.Companion.2012.37
   Peng C, 2012, COMPUT GRAPH FORUM, V31, P393, DOI 10.1111/j.1467-8659.2012.03018.x
   Peng Chao., 2016, COMPUTER AIDED DESIG, V13, P173, DOI DOI 10.1080/16864360.2015.1084184
   Shou LD, 2004, IEEE T KNOWL DATA EN, V16, P1357, DOI 10.1109/TKDE.2004.78
   Shou LD, 2003, PROC INT CONF DATA, P557, DOI 10.1109/ICDE.2003.1260821
   STEPHENS A, 2006, P EUR S PAR GRAPH VI, P19
   Villanueva AJ, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P7, DOI 10.1145/2856400.2856420
   Wald I., 2004, P EUR S REND, P81
   William V, 2002, P 13 EUR WORKSH REND, P203
   Yoon S.E., 2008, SYNTHESILECT COMPU, V2, P1
   Yoon SE, 2006, VISUAL COMPUT, V22, P772, DOI 10.1007/s00371-006-0062-y
NR 19
TC 1
Z9 1
U1 0
U2 10
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 231
EP 240
DI 10.1002/cav.1704
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300007
DA 2024-07-18
ER

PT J
AU Zank, M
   Nescher, T
   Kunz, A
AF Zank, Markus
   Nescher, Thomas
   Kunz, Andreas
TI Predicting audio step feedback for real walking in virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE step prediction; gait; human walking; virtual reality; auditory
   feedback; step sound
ID PHASE DETECTION; FOOTSTEPS
AB When navigating in virtual environments by using real walking, the correct auditory step feedback is usually ignored, although this could give more information to the user about the ground he is walking on. One reason for this is time constraints that hinder a replay of a walking sound synchronous to the haptic step feedback when walking. In order to add a matching step feedback to virtual environments, this paper introduces a calibration-free system, which can predict the occurrence time of a step-down event based on an analysis of the user's gait. For detecting reliable characteristics of the gait, accelerometers and gyroscopes are used, which are mounted on the user's foot. Because the proposed system is capable of detecting the characteristic events in the foot's swing phase, it allows a prediction that gives enough time to replay sound synchronous to the haptic sensation of walking. In order to find the best prediction regarding prediction time and accuracy, data gathered in an experiment is analyzed regarding reliably occurring characteristics in the human gait. Based on this, a suitable prediction algorithm is proposed. Copyright (C) 2014 John Wiley & Sons, Ltd.
C1 [Zank, Markus; Nescher, Thomas; Kunz, Andreas] ETH, ICVR, Inst Machine Tools & Mfg, Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Zank, M (corresponding author), ETH, ICVR, Inst Machine Tools & Mfg, Zurich, Switzerland.
EM zank@iwf.mavt.ethz.ch
RI Kunz, Andreas/B-9241-2008
OI Kunz, Andreas/0000-0002-6495-4327; Zank, Markus/0009-0008-5446-8289
FU Swiss National Science Foundation [127298]
FX The authors would like to thank the Swiss National Science Foundation
   (project number 127298) for funding this work.
CR [Anonymous], 1981, Human Walking
   Avanzini F, 2005, IEEE T SPEECH AUDI P, V13, P1073, DOI 10.1109/TSA.2005.852984
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Foxlin E, 2005, IEEE COMPUT GRAPH, V25, P38, DOI 10.1109/MCG.2005.140
   Giordano BL, 2012, J ACOUST SOC AM, V131, P4002, DOI 10.1121/1.3699205
   Law AW, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P126, DOI 10.1109/HAVE.2008.4685311
   Menzer F, 2010, COGN NEUROSCI-UK, V1, P184, DOI 10.1080/17588921003743581
   Nordahl R., 2005, 8 ANN INT WORKSH PRE, P353
   Nordahl R, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P73, DOI 10.1109/VR.2012.6180888
   Nordahl R, 2011, IEEE T VIS COMPUT GR, V17, P1234, DOI 10.1109/TVCG.2011.30
   Occelli V, 2011, PSYCHON B REV, V18, P429, DOI 10.3758/s13423-011-0070-4
   Pappas IPI, 2001, IEEE T NEUR SYS REH, V9, P113, DOI 10.1109/7333.928571
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Serafin S., 2010, Proceedings of Eurohaptics, P61
   Stirling R., 2003, proceedings of European navigation conference GNSS, P110
   Turchet Luca, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P269, DOI 10.1109/MMSP.2010.5662031
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vaughan C.L., 1992, DYNAMICS HUMAN GAIT
   Wang Y, 2010, AUDIO ENG SOC CONVEN, V128, P8081
   Wendt Jeremy D., 2010, 2010 IEEE Virtual Reality Conference (VR), P51, DOI 10.1109/VR.2010.5444812
   WILLEMSEN ATM, 1990, IEEE T BIO-MED ENG, V37, P1201, DOI 10.1109/10.64463
NR 21
TC 2
Z9 3
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2015
VL 26
IS 6
BP 537
EP 547
DI 10.1002/cav.1611
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DB2QO
UT WOS:000368354300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, WT
   Zhou, YF
   Zhang, CM
   Li, XM
AF Li, Weitao
   Zhou, Yuanfeng
   Zhang, Caiming
   Li, Xuemei
TI Robust multi-level partition of unity implicits from triangular meshes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE MPU; approximation; dual graph; polygon-implicit error metric
ID SURFACES; CURVES; RECONSTRUCTION
AB This paper presents a new robust multi-level partition of unity (MPU) method, which constructs an implicit surface from a triangular mesh via the new error metric between the mesh and the implicit surface. The new error metric employs a weighted function of inner points and vertices of a triangle to fit an implicit surface, which can control the approximation error between the surface and vertices of the triangle. Furthermore, it is applied to the MPU method by utilizing the dual graph of a triangular mesh, and the general quadric implicit surface is used for surface representation. Compared with the MPU method, the new method generates fewer subdivision cells with the same approximation error and performs more steadily especially when given triangular mesh with fewer vertices. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Li, Weitao; Zhou, Yuanfeng; Zhang, Caiming; Li, Xuemei] Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Peoples R China.
   [Zhang, Caiming] Shandong Univ Finance & Econ, Shandong Prov Key Lab Digital Media Technol, Jinan, Peoples R China.
C3 Shandong University; Shandong University of Finance & Economics
RP Zhou, YF (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Software Pk Campus,Shunhua Rd, Jinan 250101, Peoples R China.
EM yfzhou@sdu.edu.cn
RI liu, xinyi/KFB-4466-2024; Zhang, Caiming/AHD-6558-2022
OI Zhang, Caiming/0000-0002-6365-6221
FU National Nature Science Foundation of China [61020106001, 61202148,
   61103150]; Independent Innovation Foundation of Shandong University
   (IIFSDU) [2012TB013]; Graduate Independent Innovation Foundation of
   Shandong University (GIIFSDU) [11150070613227]
FX This work is supported by the National Nature Science Foundation of
   China (61020106001, 61202148, and 61103150), the Independent Innovation
   Foundation of Shandong University (IIFSDU; 2012TB013), and the Graduate
   Independent Innovation Foundation of Shandong University (GIIFSDU;
   11150070613227).
CR Allaire S., 2007, ICCV IEEE, P1, DOI 10.1109/ICCV.2007.4409163
   BAEG M, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P204, DOI 10.1109/IROS.1995.525885
   BAJAJ C, 1993, ACM T GRAPHIC, V12, P327, DOI 10.1145/159730.159734
   BAJAJ CL, 1992, ACM T GRAPHIC, V11, P61, DOI 10.1145/102377.120081
   BEARDSLEY PA, 1998, P IEEE C AUT FAC GES
   Benko P, 2002, COMPUT AIDED GEOM D, V19, P173, DOI 10.1016/S0167-8396(01)00085-1
   Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760
   BLOOMENTHAL J, 1994, GRAPHICS GEMS, V4, P324
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Dai M, 2007, PATTERN RECOGN, V40, P504, DOI 10.1016/j.patcog.2006.01.016
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Garland M., 2001, I3D 01, P49, DOI [DOI 10.1145/364338.364345, 10.1145/364338.364345]
   Helzer A, 2004, IEEE T PATTERN ANAL, V26, P1283, DOI 10.1109/TPAMI.2004.91
   Kanai T., 2006, P 4 EUR S GEOM PROC, P21
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602
   Li QD, 2004, GEOMETRIC MODELING AND PROCESSING 2004, PROCEEDINGS, P335
   Morse BS, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P89, DOI 10.1109/SMA.2001.923379
   MURAKI S, 1991, COMP GRAPH, V25, P227, DOI 10.1145/127719.122743
   Museth K, 2002, ACM T GRAPHIC, V21, P330, DOI 10.1145/566570.566585
   Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293
   Shen C, 2004, ACM T GRAPHIC, V23, P896, DOI 10.1145/1015706.1015816
   Tasdizen T, 2000, IEEE T IMAGE PROCESS, V9, P405, DOI 10.1109/83.826778
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
   Turk G, 2002, ACM T GRAPHIC, V21, P855, DOI 10.1145/571647.571650
   Turk G, 1999, COMP GRAPH, P335, DOI 10.1145/311535.311580
   Vanco M, 2008, COMPUT GRAPH FORUM, V27, P1593, DOI 10.1111/j.1467-8659.2007.01109.x
   Yan YLD, 2006, P 4 INT C GEOM MOD P, P26
   Yngve G, 2002, IEEE T VIS COMPUT GR, V8, P346, DOI 10.1109/TVCG.2002.1044520
   Zhao HK, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P194, DOI 10.1109/VLSM.2001.938900
NR 31
TC 2
Z9 3
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2014
VL 25
IS 2
BP 115
EP 127
DI 10.1002/cav.1536
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AE8SY
UT WOS:000334273500003
OA Bronze
DA 2024-07-18
ER

PT J
AU Lv, L
   Mao, TL
   Liu, XC
   Wang, ZQ
AF Lv, Lei
   Mao, Tianlu
   Liu, Xuecheng
   Wang, Zhaoqi
TI Optimization-based group performance deducing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE large-scale group; group motion bigraph; performance animation
ID MODEL; BEHAVIORS
AB Large-scale group performance animation has been an important research topic because of its diverse range of applications including virtual rehearsal and film production. Animating hundreds of virtual actors as what the director wishes is a tough task. In this paper, we address this challenge by introducing an optimization method that generates large-scale group performance by deducing a small-scale one with fewer actors. We introduced group motion bigraph technique and transformed the motion-deducing problem into a constrained optimization problem. A solving process is then presented to automatically obtain the motion of the large group with velocity constraints. Moreover, an interactive system of constructing the group motion bigraph has been implemented, which provides flexible edit and control on deducing group motion. The animation results show that our method is competent for deducing large-scale group performance from only several motion clips performed by small groups. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Lv, Lei; Mao, Tianlu; Wang, Zhaoqi] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Lv, Lei] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Liu, Xuecheng] China Film Post Prod Co, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Lv, L (corresponding author), Chinese Acad Sci, Adv Comp Res Lab, Inst Comp Technol, 6 Kexueyuan South Rd, Beijing, Peoples R China.
EM lvlei@ict.ac.cn
FU National Natural Science Foundation of China [U0935003, 61173053,
   61100086]; National High Technology Research and Development Program of
   China [2013AA013902]; National Key Technology RD Program [2012BAH39B01];
   Public Service Industrial Special Research [2013467058]
FX This work is supported and funded by the National Natural Science
   Foundation of China (Grant Nos. U0935003, 61173053, 61100086), the
   National High Technology Research and Development Program of China
   (Grant No. 2013AA013902), the National Key Technology R&D Program (Grant
   No. 2012BAH39B01), and the Public Service Industrial Special Research
   (Grant No. 2013467058). We would like to thank the reviewers for their
   constructive comments and suggestions.
CR Anderson M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P286
   [Anonymous], 1999, P GAM DEV C
   Braun A, 2003, COMP ANIM CONF PROC, P143, DOI 10.1109/CASA.2003.1199317
   Braun A., 2005, Proceedings of the ACM symposium on Virtual reality software and technology, P244
   Courty N, 2007, COMPUT ANIMAT VIRT W, V18, P361, DOI 10.1002/cav.199
   Gu Q., 2011, Graphics Interface 2011, P266, DOI DOI 10.5555/1992917.1992919
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hughes RL, 2003, ANNU REV FLUID MECH, V35, P169, DOI 10.1146/annurev.fluid.35.101101.161136
   Johansson A., 2007, Adv. Complex Syst, V10, P271, DOI [10.1142/S0219525907001355, DOI 10.1142/S0219525907001355]
   Ju E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866162
   Kapadia M., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games, I3D '09, P215
   Kapadia M, 2012, VISUAL COMPUT, V28, P1209, DOI 10.1007/s00371-011-0669-5
   Karamouzas I., 2010, Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology, VRST '10, P183, DOI DOI 10.1145/1889863
   Kwon TS, 2007, COMPUT ANIMAT VIRT W, V18, P463, DOI 10.1002/cav.185
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   Lee KC, 2007, 2007 MOBILE NETWORKING FOR VEHICULAR ENVIRONMENTS, P109, DOI 10.1109/MOVE.2007.4300814
   Lerner A., 2009, SCA, ACM, P199, DOI DOI 10.1145/1599470.1599496
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Li Y., 2012, Eurographics Symposium on Computer Animation, P201
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Park MJ, 2010, VISUAL COMPUT, V26, P1383, DOI 10.1007/s00371-009-0415-4
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rodrigues RA, 2010, APPL ARTIF INTELL, V24, P594, DOI 10.1080/08839514.2010.492167
   Schuerman M, 2010, COMPUT ANIMAT VIRT W, V21, P267, DOI 10.1002/cav.367
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   Singh Shawn., 2011, ACM SIGGRAPH I3D, P141
   Sung M, 2004, COMPUT GRAPH FORUM, V23, P239
   Takahashi S, 2009, COMPUT GRAPH FORUM, V28, P639, DOI 10.1111/j.1467-8659.2009.01404.x
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Wojtan C., 2006, P 2006 ACM SIGGRAPHE, P15
   Xiaoyuan Tu, 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P43
   Xu JY, 2008, COMPUT ANIMAT VIRT W, V19, P319, DOI 10.1002/cav.231
   YEH H., 2008, SCA 08 P 2005 ACM SI, P39
NR 38
TC 3
Z9 3
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2014
VL 25
IS 2
BP 171
EP 184
DI 10.1002/cav.1544
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AE8SY
UT WOS:000334273500007
DA 2024-07-18
ER

PT J
AU Qi, T
   Feng, YF
   Xiao, J
   Zhuang, YT
   Yang, XS
   Zhang, JJ
AF Qi, Tian
   Feng, Yinfu
   Xiao, Jun
   Zhuang, Yueting
   Yang, Xiaosong
   Zhang, Jianjun
TI A semantic feature for human motion retrieval
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion retrieval; motion annotation; semantic feature; key-frame
   extraction; key-pose model
AB With the explosive growth of motion capture data, it becomes very imperative in animation production to have an efficient search engine to retrieve motions from large motion repository. However, because of the high dimension of data space and complexity of matching methods, most of the existing approaches cannot return the result in real time. This paper proposes a high level semantic feature in a low dimensional space to represent the essential characteristic of different motion classes. On the basis of the statistic training of Gauss Mixture Model, this feature can effectively achieve motion matching on both global clip level and local frame level. Experiment results show that our approach can retrieve similar motions with rankings from large motion database in real-time and also can make motion annotation automatically on the fly. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Qi, Tian; Feng, Yinfu; Xiao, Jun; Zhuang, Yueting] Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310027, Peoples R China.
   [Yang, Xiaosong; Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
C3 Zhejiang University; Bournemouth University
RP Xiao, J (corresponding author), Zhejiang Univ, Inst Artificial Intelligence, 38 Zheda Rd, Hangzhou 310027, Peoples R China.
EM junx@cs.zju.edu.cn
OI FENG, yinfu/0000-0001-9136-0965; Yang, Xiaosong/0000-0003-3815-0584;
   Zhang, Jian/0000-0002-7069-5771
FU National Key Basic Research Program (973) of China [2012CB316400];
   National High Technology R&D Program (863) of China [2012AA011502];
   National Key Technology R&D Program of China [2013BAH59F02]; Sino-UK
   Higher Education Research Partnership for PhD Studies Project
FX This research is supported by the National Key Basic Research Program
   (973) of China (No. 2012CB316400), the National High Technology R&D
   Program (863) of China (No. 2012AA011502), the National Key Technology
   R&D Program of China (No. 2013BAH59F02), and the Sino-UK Higher
   Education Research Partnership for PhD Studies Project.
CR [Anonymous], 2009, Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games, I3D'09, DOI DOI 10.1145/1507149.1507181
   [Anonymous], 2010, SCA'10: proceedings of the 2010 ACM SIGGRAPH/Eurographics symposium on computer animation, DOI [10.2312/SCA/SCA10/001-010, DOI 10.2312/SCA/SCA10/001-010]
   [Anonymous], 2005, P ACM SIGGRAPH EUR S, DOI [10.1145/1073368.1073377, DOI 10.1145/1073368.1073377]
   Chao MW, 2012, IEEE T VIS COMPUT GR, V18, P729, DOI 10.1109/TVCG.2011.53
   Chiu CY, 2004, J VIS COMMUN IMAGE R, V15, P446, DOI 10.1016/j.jvcir.2004.04.004
   Choi MG, 2012, COMPUT GRAPH FORUM, V31, P2057, DOI 10.1111/j.1467-8659.2012.03198.x
   Eitz M, 2012, ACM T GRAPHICS TOG, P31
   Gleicher M., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P139, DOI 10.1145/253284.253321
   Gonen O, 2012, COMPUT GRAPH-UK, V36, P521, DOI 10.1016/j.cag.2012.03.019
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Huang TY, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P209
   Hyo Jong Shin, 2007, Proceedings Graphics Interface 2007, P63, DOI 10.1145/1268517.1268530
   Jain S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477936
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Le Naour Thibaut, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P362, DOI 10.1007/978-3-642-34710-8_33
   Lin Y., 2006, Proceedings of the 4th international Conference on Computer Graphics and interactive Techniques in Australasia and Southeast Asia (Kuala Lumpur, Malaysia, November 29 - December 02, 2006), P31
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   Liu G., 2005, P 2005 ACM SIGMOD IN, P924
   Liu TC, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1230812.1230813
   Lv F., 2007, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P1
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Meng J., 2008, Eurographics (Short Papers), P71
   Min J., 2010, P 2010 ACM SIGGRAPH, DOI [10.1145/1730804.1730811, DOI 10.1145/1730804.1730811]
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   Pradhan GN, 2009, IEEE T INF TECHNOL B, V13, P802, DOI 10.1109/TITB.2009.2021262
   Shao TJ, 2011, COMPUT GRAPH FORUM, V30, P2011, DOI 10.1111/j.1467-8659.2011.02050.x
   Songle Chen, 2012, 2012 4th International Conference on Digital Home (ICDH 2012), P298, DOI 10.1109/ICDH.2012.91
   Sun C, 2011, COMPUT GRAPH FORUM, V30, P1953, DOI 10.1111/j.1467-8659.2011.02048.x
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
   Yu T, 2005, COMPUT ANIMAT VIRT W, V16, P273, DOI 10.1002/cav.89
NR 33
TC 16
Z9 16
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 399
EP 407
DI 10.1002/cav.1505
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500027
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhang, YJ
   Pettré, J
   Ondrej, J
   Qin, XY
   Peng, QS
   Donikian, S
AF Zhang, Yijiang
   Pettre, Julien
   Ondrej, Jan
   Qin, Xueying
   Peng, Qunsheng
   Donikian, Stephane
TI Online inserting virtual characters into dynamic video?scenes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE mixed reality; steering method; collision avoidance
AB The seamless integration of virtual characters into dynamic scenes captured by video is a challenging problem. In order to achieve consistent composite results, both the virtual and real characters must share the same geometrical constraints and their interactions must follow some common sense. One essential question is how to detect the motion of real objectssuch as real characters moving in the videoand how to steer virtual characters accordingly to avoid unrealistic collisions. We propose an online solution. First, by analysis of the input video, the motion states of the real pedestrians are recovered into a common world 3D coordinate system. Meanwhile, a simplified accuracy measurement is defined to represent the confidence of the motion estimate. Then, under the constraints imposed by the real dynamic objects, the motion of virtual characters are accommodated by a uniform steering model. The final step is to merge virtual objects back to the real video scene by taking into account visibility and occlusion constraints between real foreground objects and virtual ones. Several examples demonstrate the efficiency of the proposed algorithm. Copyright (c) 2011 John Wiley & Sons, Ltd.
C1 [Zhang, Yijiang; Pettre, Julien; Ondrej, Jan; Donikian, Stephane] INRIA Rennes, Mimetic Team, Rennes, France.
   [Zhang, Yijiang; Qin, Xueying; Peng, Qunsheng] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310003, Zhejiang, Peoples R China.
   [Qin, Xueying] Shandong Univ, Sch Comp Sci & Technol, Jinan 250100, Peoples R China.
C3 Universite de Rennes; Zhejiang University; Shandong University
RP Zhang, YJ (corresponding author), INRIA Rennes, Mimetic Team, Rennes, France.
EM yijiang.zhang@irisa.fr
RI Pettré, Julien/AAB-2590-2022; Qin, Xueying/AAM-8775-2021; Ondrej,
   Jan/N-1947-2016
OI Qin, Xueying/0000-0003-0057-295X; Ondrej, Jan/0000-0002-5409-1521
FU National Basic Research Program of China (973 Program) [2009CB320802];
   National Natural Science Foundation of China [60833007]; French Eiffel
   Program; French Embassy scholarship program
FX This research is supported by the National Basic Research Program of
   China (973 Program grant No. 2009CB320802), the National Natural Science
   Foundation of China (Grant No. 60833007), the French Eiffel Program, and
   the French Embassy scholarship program.
CR BUGEAU A, 2008, J IMAGE VIDEO PROCES, V3, P1
   Gérin-Lajoie M, 2005, MOTOR CONTROL, V9, P242, DOI 10.1123/mcj.9.3.242
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Helbing D, 2005, TRANSPORT SCI, V39, P1, DOI 10.1287/trsc.1040.0108
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Khan S, 2000, AS C COMP VIS, P1132
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   Reynolds C. W., 1999, P GAM DEV C, P763
   ROSALES R, 1999, IEEE COMP SOC C COMP, V2, P123
   Somasundaram A, 2003, COMP ANIM CONF PROC, P137, DOI 10.1109/CASA.2003.1199315
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   WANG C, 2009, ICCV 09 IEEE INT C C
   Yang T, 2005, PROC CVPR IEEE, P970
   Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52
   Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73
NR 18
TC 6
Z9 7
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2011
VL 22
IS 6
BP 499
EP 510
DI 10.1002/cav.427
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856IA
UT WOS:000297631200003
DA 2024-07-18
ER

PT J
AU Dutreve, L
   Meyer, A
   Bouakaz, S
AF Dutreve, Ludovic
   Meyer, Alexandre
   Bouakaz, Sada
TI Easy acquisition and real-time animation of facial wrinkles
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE facial animation; wrinkle acquisition; fine-scale animation; RBF
   interpolation
AB Facial animation details like wrinkles or bulges are very useful for the analysis and the interpretation of facial emotions and expressions. However, outfitting a virtual face with expression details for real-time applications is a difficult task. In this paper, we propose a mono-camera acquisition technique of facial animation details and a technique which add a wrinkle map layer (fine-scale animation) to a skinning layer (large-scale animation) for real-time rendering of a virtual 3D face. The acquisition is based on ratio image computed from two pictures of a same face, with and without expression. The real-time dynamic wrinkles technique is based on a small set of reference poses. These two methods offer an easy and low-cost way to capture facial animation details and use it for real-time facial animation. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Dutreve, Ludovic; Meyer, Alexandre; Bouakaz, Sada] Univ Lyon, LIRIS, F-69622 Villeurbanne, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon
RP Meyer, A (corresponding author), Univ Lyon, LIRIS, Batiment Nautibus 710,43,Boulevard 11 Novembre 19, F-69622 Villeurbanne, France.
EM alexandre.meyer@liris.cnrs.fr
OI MEYER, Alexandre/0000-0002-0249-1048
CR Alexander Oleg, 2009, ACM SIGGRAPH COURSES
   Bando Y, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P166, DOI 10.1109/PCCGA.2002.1167852
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   Bickel B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239484
   Bradley D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778778
   COURGEON M, 2009, IVA 09
   DEMELO C, 2009, IVA 09
   Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003
   Ersotelos N, 2008, VISUAL COMPUT, V24, P13, DOI 10.1007/s00371-007-0175-y
   Gain J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409629
   Larboulette C, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P522, DOI 10.1109/CGI.2004.1309258
   Liu ZC, 2001, COMP GRAPH, P271
   LO YS, 2008, CGI 08 P COMP GRAPH, P118
   Na K, 2004, COMPUT GRAPH FORUM, V23, P687, DOI 10.1111/j.1467-8659.2004.00801.x
   OAT C., 2007, ACM SIGGRAPH 2007 CO
   PRADOS E, 2005, CVPR 05
   Robles-Kelly A, 2007, IEEE T IMAGE PROCESS, V16, P7, DOI 10.1109/TIP.2006.884945
   Siddiqui AM, 2009, PATTERN RECOGN LETT, V30, P377, DOI 10.1016/j.patrec.2008.11.004
   Smith WAP, 2008, INT J COMPUT VISION, V76, P71, DOI 10.1007/s11263-007-0074-8
   Vogel O, 2009, LECT NOTES COMPUT SC, V5748, P191, DOI 10.1007/978-3-642-03798-6_20
   Wang H, 2010, ACM T GRAPHICS, V29
   WEISE T, 2007, CVPR 07
   Wilson CA, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731055
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Wu TP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409072
NR 25
TC 6
Z9 9
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 169
EP 176
DI 10.1002/cav.395
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700012
OA Green Published
DA 2024-07-18
ER

PT J
AU Seo, H
   Bang, JW
   Park, JM
   Jeon, SH
AF Seo, Hyewon
   Bang, Joon-Won
   Park, Ji-Man
   Jeon, Soo-Hyun
TI 3D billiards game with haptic interface
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE billiards game; haptic interface; multibody dynamics; rigid objects
AB Intuitive human-computer interaction has been an active research area with the participation of both academic and industrial groups. It is an important technical and psychological element in computer games, digital product design, cybers ports, etc. In this paper, we present our work on a 3D billiards game featuring a haptic interface. Most of the existing games available today concentrate on the development of sophisticated physics engines to obtain realistic motion of billiards balls or of sound engines for realistic sound effect. Our focus in this work is on the improved realism on the hitting action of the game with the aid of haptic device. We do so by computing accurate feedback force on the haptic handle, considering the exact point of contact and physically faithful collision response. Also presented is the physically based modeling of the game environment, including the collision interaction among billiards balls, and between the table and billiards balls. As a result, the players can enjoy a more realistic and pleasurable game compared to other existing 3D billiards games. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Seo, Hyewon] Univ Strasbourg, LSIIT, CNRS, UMR 7005, F-67412 Illkirch Graffenstaden, France.
   [Bang, Joon-Won] Chungnam Natl Univ, Image Proc Lab, Taejon, South Korea.
   [Jeon, Soo-Hyun] Chungnam Natl Univ, Comp Graph Lab, Taejon, South Korea.
C3 Centre National de la Recherche Scientifique (CNRS); Universites de
   Strasbourg Etablissements Associes; Universite de Strasbourg; Chungnam
   National University; Chungnam National University
RP Seo, H (corresponding author), Chungnam Natl Univ, Dept Comp Sci & Engn, 220 Gung Dong, Taejon, South Korea.
EM seo@unistra.fr
FU Engineering Research Center [R11-2007-028-02002-0]; Korean National
   Research Foundation [20090083874]; CNRS (Centre National de la Recherche
   Scientifique)
FX This work was supported in part by the Engineering Research Center
   Program (No. R11-2007-028-02002-0) and in part by Specific & Fundamental
   Research Program (No. 20090083874) of Korean National Research
   Foundation. The first author has been partly supported by the CNRS
   (Centre National de la Recherche Scientifique).
CR BOURG D. M., 2002, PHYS GAME DEV
   Gourishankar V, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P494
   King SA, 2002, COMP ANIM CONF PROC, P233, DOI 10.1109/CA.2002.1017542
   Ruffaldi E., 2006, P ACM S VIRTUAL REAL, P320, DOI [10.1145/1180495.1180559, DOI 10.1145/1180495.1180559]
   4 BALL GAME
   HANGAME BILLIARD GAM
   HAJIMETENO WII GAMES
   BILLIARDS BAR
   CUE SPORTS SNOOKER V
   HAMARU STAR BILLIARD
   NETMARBLE BILLIARD G
NR 11
TC 1
Z9 2
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2010
VL 21
IS 5
BP 523
EP 530
DI 10.1002/cav.337
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 672VP
UT WOS:000283615300005
OA Bronze
DA 2024-07-18
ER

PT J
AU Courty, N
   Cuzol, A
AF Courty, N.
   Cuzol, A.
TI Conditional stochastic simulation for character animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE character animation; conditional stochastic simulation; motion synthesis
AB In a context of interactive applications, adapting motion capture data to new situations or producing variants of them are known as non trivial tasks. We propose an original method that produces motions that preserve the statistical properties of a reference motion while ensuring some constraints. This method uses principles of conditional stochastic simulation to achieve this goal. Notably, a new real time algorithm, performing sequentially and producing the desired motion is introduced. Possible applications of our method are numerous and several examples are given, along with results. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Courty, N.; Cuzol, A.] Univ Europeenne Bretagne, VALORIA, F-56000 Vannes, France.
C3 Universite de Bretagne Occidentale
RP Courty, N (corresponding author), Univ Europeenne Bretagne, VALORIA, Campus Tohann, F-56000 Vannes, France.
EM courty@univ-ubs.fr
CR Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Chai JX, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239459
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Ikemoto L, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477927
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lantuéjoul C, 2002, GEOSTATISTICAL SIMULATION, P1
   Lau M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618517
   LI Y, 2002, SIGGRAPH, P465
   McDonnell R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360625
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   Pullen K, 2000, COMP ANIM CONF PROC, P36, DOI 10.1109/CA.2000.889031
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Stein M.L., 1999, INTERPOLATION SPATIA
   TOURNIER M, 2009, COMPUTER GRAPHICS FO, V28
   Urtasun R., 2006, C COMP VIS PATT REC
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Wang LP, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.41
   YE Y, 2010, COMPUT GRAPH FORUM, V29, P1
NR 22
TC 3
Z9 3
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 443
EP 452
DI 10.1002/cav.374
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400030
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gao, YJ
   Zhao, QP
   Hao, AM
   Sezgin, TM
   Dodgson, NA
AF Gao, Yujian
   Zhao, Qinping
   Hao, Aimin
   Sezgin, T. M.
   Dodgson, N. A.
TI Automatic construction of 3D animatable facial avatars
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE facial animation; avatar; multi-layer model; landmark detection; rigging
ID ANIMATION
AB Rigging for facial animation is an important but time-consuming task, which generally requires experienced artists with knowledge of facial anatomy. In this paper, we investigate whether it is possible to produce a good animatable avatar automatically, given only a 3D static triangle mesh of the head. An automatic mechanism is devised for constructing multi-layer animatable facial avatars for unseen faces. We evaluate our technique with a variety of models, and give a quantitative analysis of the constructed results. We also designed and conducted a user study for evaluating the perceived quality of the generated expressive animations. The results demonstrate that our method is an appropriate tool for naive users to customize their personal 3D avatars. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Gao, Yujian; Zhao, Qinping; Hao, Aimin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Sezgin, T. M.] Koc Univ, Coll Engn, Istanbul, Turkey.
   [Sezgin, T. M.] Univ Cambridge, Rainbow Grp, Comp Lab, Cambridge CB2 1TN, England.
   [Dodgson, N. A.] Univ Cambridge, Graph & Interact Res Grp Rainbow, Comp Lab, Cambridge CB2 1TN, England.
C3 Beihang University; Koc University; University of Cambridge; University
   of Cambridge
RP Gao, YJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, 83 Xueyuan Rd, Beijing, Peoples R China.
EM gaoyj@vrlab.buaa.edu.cn
RI /AAL-4614-2020; Dodgson, Neil/A-4506-2009
OI Dodgson, Neil/0000-0001-7649-8528; Sezgin, Tevfik
   Metin/0000-0002-1524-1646
CR Aina OO, 2009, VISUAL COMPUT, V25, P617, DOI 10.1007/s00371-009-0320-x
   [Anonymous], P IEEE COMP SOC C CO
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Capell S., 2005, P 2005 ACM SIGGRAPH, P301, DOI DOI 10.1145/1073368.1073412
   Chai Jin-xiang., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. SCA'03, P193
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   Colombo A, 2006, PATTERN RECOGN, V39, P444, DOI 10.1016/j.patcog.2005.09.009
   Orvalho VC, 2008, COMPUT GRAPH FORUM, V27, P1997, DOI 10.1111/j.1467-8659.2008.01187.x
   D'Hose J., 2007, IEEE Conference on Biometrics: Theory, Applications and Systems, BTAS'07, P1
   Deng Zhigang., 2007, DATA DRIVEN 3D FACIA
   Ersotelos N, 2008, VISUAL COMPUT, V24, P13, DOI 10.1007/s00371-007-0175-y
   Feng WW, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360690
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gordon G. G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P808, DOI 10.1109/CVPR.1992.223253
   Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hassenzahl M, 2003, Berichte Des Ger Chapter Acm, V2003, P187
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Kahler K., 2001, PROC GRAPHICS INTERF, P37
   Lee Y., 1995, SIGGRAPH, P55, DOI [10.1145/218380.218407, DOI 10.1145/218380.218407]
   Li P, 2002, P SOC PHOTO-OPT INS, V4661, P169, DOI 10.1117/12.460170
   Liu ZC, 2001, COMP GRAPH, P271
   MOCCOZET L, 2004, P WORKSH MOD MOT CAP, P73
   Mortara M, 2004, ALGORITHMICA, V38, P227, DOI 10.1007/s00453-003-1051-4
   Parke F., 1996, COMPUTER FACIAL ANIM
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   PIGHIN F, 1998, P SIGGRAPH 98, P75
   Platt S. M., 1981, Computer Graphics, V15, P245, DOI 10.1145/965161.806812
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   SUMIT IE, 1996, P COMP AN C 96, P68
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Wang YJ, 2002, PATTERN RECOGN LETT, V23, P1191, DOI 10.1016/S0167-8655(02)00066-1
   WATERS K, 1987, P 14 ANN C COMP GRAP, P17
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
   Xu CH, 2006, PATTERN RECOGN LETT, V27, P1487, DOI 10.1016/j.patrec.2006.02.015
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang QS, 2006, IEEE T VIS COMPUT GR, V12, P48, DOI 10.1109/TVCG.2006.9
   Zhang Y, 2004, IEEE T VIS COMPUT GR, V10, P339, DOI 10.1109/TVCG.2004.1272733
   Zhang Y, 2001, COMP ANIM CONF PROC, P28, DOI 10.1109/CA.2001.982374
   Zhou Y, 2003, PROC CVPR IEEE, P109
NR 41
TC 5
Z9 7
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 343
EP 354
DI 10.1002/cav.340
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400021
DA 2024-07-18
ER

PT J
AU Seo, J
   Seol, Y
   Wi, D
   Kim, Y
   Noh, J
AF Seo, Jaewoo
   Seol, Yeongho
   Wi, Daehyeon
   Kim, Younghui
   Noh, Junyong
TI Rigging transfer
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE animation; deformation; rigging; anatomy
ID DEFORMATION
AB Realistic character animation requires elaborate rigging built on top of high quality 3D models. Sophisticated anatomically based rigs are often the choice of visual effect studios where life-like animation of CG characters is the primary objective. However, rigging a character with a muscular skeletal system is very involving and time-consuming process, even for professionals. Although, there have been recent research efforts to automate either all or some parts of the rigging process, the complexity of anatomically based rigging nonetheless opens up new research challenges. We propose a new method to automate anatomically based rigging that transfers an existing rig of one character to another. The method is based on a data interpolation in the surface and volume domain, where various rigging elements can be transferred between different models. As it only requires a small number of corresponding input feature points, users can produce highly detailed rigs for a variety of desired character with ease. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Seo, Jaewoo] Korea Adv Inst Sci & Technol, GSCT, Taejon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Seo, J (corresponding author), Korea Adv Inst Sci & Technol, GSCT, 335 Gwahak Ro, Taejon, South Korea.
EM goongsang@gmail.com
RI Noh, Junyong/C-1663-2011; Seol, Yeongho/KIE-6801-2024
CR ATTENE M, 2006, SMI 06
   BARAN I, 2007, ACM SIGGRAPH 2007 SA
   CAPELL S, 2005, SCA 05
   CHANG YT, 2006, P COMP GRAPH INT, P78
   Orvalho VC, 2008, COMPUT GRAPH FORUM, V27, P1997, DOI 10.1111/j.1467-8659.2008.01187.x
   DAVE J, 2006, ACM SIGGRAPH 2006 CO
   JOSHI P, 2007, ACM SIGGRAPH 2007
   JU T, 2008, ACM SIGGRAPH AS 2008
   JU T, 2005, ACM SIGGRAPH 2005
   KINCHUNG AO, 2008, ACM SIGGRAPH 2008
   Kraevoy V., 2004, ACM SIGGRAPH 2004
   LANDRENEAU E, 2009, COMPUTER GRAPHICS FO, V28
   LEWIS JP, 2000, SIGGRAPH 00
   Li X., 2007, P 2007 ACM S SOL PHY
   LI X, 2008, IEEE T VISUALIZATION, V14
   Lipman Y, 2007, P 5 EUR S GEOM PROC
   Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378
   MOHR A, 2003, ACM SIGGRAPH 2003
   Nedel LP, 1998, COMP ANIM CONF PROC, P34, DOI 10.1109/CA.1998.681905
   Piegl L., 1997, The Nurbs Book, Vsecond
   Pratscher M., 2005, P 2005 ACM SIGGRAPH
   Scheepers F., 1997, P 24 ANN C COMP GRAP
   SCHREINER J, 2004, ACM SIGGRAPH 2004
   Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011
   Smith Jason., 2006, ACM SIGGRAPH 2006 Sketches
   WANG RY, 2007, ACM SIGGRAPH 2007
   WESTENHOFER B, 2005, ANIMATION WORLD NETW
   WILHELMS J, 1997, ACM SIGGRAPH 97
NR 28
TC 8
Z9 10
U1 1
U2 6
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 375
EP 386
DI 10.1002/cav.358
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400024
DA 2024-07-18
ER

PT J
AU Lin, IC
   Chang, WH
   Lo, YS
   Peng, JY
   Lin, CY
AF Lin, I-Chen
   Chang, Wen-Hsing
   Lo, Yung-Sheng
   Peng, Jen-Yu
   Lin, Chan-Yu
TI Image-based detail reconstruction of non-Lambertian surfaces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE image-based 3D modeling; shape-from-shading; non-Lambertian reflection;
   motion capture; facial animation
ID MODEL; CAPTURE; SHAPE
AB This paper presents a novel optimization framework for estimating the static or dynamic surfaces with details. The proposed method uses dense depths from a structured-light system or sparse ones from motion capture as the initial positions, and exploits non-Lambertian reflectance models to approximate surface reflectance. Multi-stage shape-from-shading (SFS) is then applied to optimize both shape geometry and reflectance properties. Because this method uses non-Lambertian properties, it can compensate for triangulation reconstruction errors caused by view-dependent reflections. This approach can also estimate detailed undulations on text-tireless regions, and employs spatial-temporal constraints for reliably tracking time-varying surfaces. Experiment results demonstrate that accurate and detailed 3D surfaces can be reconstructed from images acquired by off-the-shelf devices. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Lin, I-Chen; Peng, Jen-Yu] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lin, IC (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM ichenlin@cs.nctu.edu.tw
RI liu, yi/GXE-9662-2022
OI Lin, I-Chen/0000-0001-9924-4723
FU National Science Council, Taiwan [95-2221-E-009-164-MY3]
FX The authors would like to thank CAIG lab members, especially Chao-Chih
   Lin and Zhi-Han Yen, for their assistance in experiment. This work was
   Supported in part by National Science Council, Taiwan with grant number
   95-2221-E-009-164-MY3.
CR AHMED A, 2007, P IEEE C COMP VIS PA, pX1
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P 23 ANN C COMP GRAP
   [Anonymous], EUR S REND
   Bickel B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239484
   Castellani U, 2008, COMPUT ANIMAT VIRT W, V19, P591, DOI 10.1002/cav.269
   Donner C, 2005, ACM T GRAPHIC, V24, P1032, DOI 10.1145/1073204.1073308
   Fang H, 2004, ACM T GRAPHIC, V23, P354, DOI 10.1145/1015706.1015728
   Golovinskiy A, 2006, ACM T GRAPHIC, V25, P1025, DOI 10.1145/1141911.1141988
   Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387
   Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158
   Huynh DQ, 1997, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.1997.609324
   Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319
   Lin IC, 2005, VISUAL COMPUT, V21, P355, DOI 10.1007/s00371-005-0291-5
   Lin IC, 2002, IEEE COMPUT GRAPH, V22, P72, DOI 10.1109/MCG.2002.1046631
   Magnenat-Thalmann N, 2002, IEEE T INF TECHNOL B, V6, P317, DOI 10.1109/TITB.2002.806097
   Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   Vogiatzis G, 2005, PROC CVPR IEEE, P391
   Wenger A, 2005, ACM T GRAPHIC, V24, P756, DOI 10.1145/1073204.1073258
   Weyrich T, 2006, ACM T GRAPHIC, V25, P1013, DOI 10.1145/1141911.1141987
   Yu TL, 2004, PROC CVPR IEEE, P226
   Zeng G, 2005, PROC CVPR IEEE, P343
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
NR 25
TC 1
Z9 1
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2010
VL 21
IS 1
BP 55
EP 68
DI 10.1002/cav.332
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 560XD
UT WOS:000274937200005
DA 2024-07-18
ER

PT J
AU Farouki, RT
   Giannelli, C
AF Farouki, Rida T.
   Giannelli, Carlotta
TI Spatial camera orientation control by rotation-minimizing directed
   frames
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE camera orientation; directed frames; angular velocity;
   rotation-minimizing frames; anti-hodograph; Pythagorean curves
ID HERMITE INTERPOLATION; BRONCHOSCOPY; CURVES
AB The use of rotation-minimizing directed frames (RMDFs) for defining smoothly varying camera orientations along given spatial paths, in real or virtual environments, is proposed. A directed frame on a space curve r(xi) is a varying orthonormal basis (o, p, q) for R-3 such that o(xi) = r(xi)/vertical bar r(xi)vertical bar coincides with the unit polar vector from the origin to each curve point, and such a frame is rotation-minimizing if its angular velocity vector omega maintains a vanishing component along o. To facilitate computation of rotation-minimizing directed frames, it is shown that the basic theory is equivalent to the established theory for rotation-minimizing adapted frames-for which one frame vector coincides with the tangent t(xi) = r'(xi)/vertical bar r'(xi)vertical bar at each curve point-if one replaces the given space curve by its anti-hodograph (i.e., indefinite integral). A family of polynomial curves on which RMDFs can be computed exactly by a rational function integration, the Pythagorean (P) curves, is also introduced, together with algorithms for their construction. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Farouki, Rida T.] Univ Calif Davis, Dept Mech & Aeronaut Engn, Davis, CA 95616 USA.
   [Giannelli, Carlotta] Univ Florence, Dept Comp Sci & Syst, I-50121 Florence, Italy.
C3 University of California System; University of California Davis;
   University of Florence
RP Farouki, RT (corresponding author), Univ Calif Davis, Dept Mech & Aeronaut Engn, Davis, CA 95616 USA.
EM farouki@ucdavis.edu
RI Farouki, Rida/HCG-8930-2022; Giannelli, Carlotta/G-2093-2014
OI Giannelli, Carlotta/0000-0002-5137-1405
CR Beltran JV, 2007, J COMPUT APPL MATH, V206, P116, DOI 10.1016/j.cam.2006.06.001
   BISHOP RL, 1975, AM MATH MON, V82, P246, DOI 10.2307/2319846
   Cao CGL, 2007, SURG ENDOSC, V21, P480, DOI 10.1007/s00464-006-9000-3
   Choi HI, 2002, ADV COMPUT MATH, V17, P5, DOI 10.1023/A:1015294029079
   Christie M, 2005, LECT NOTES COMPUT SC, V3638, P40
   Colt HG, 2001, CHEST, V120, P1333, DOI 10.1378/chest.120.4.1333
   Farouki R.T., 2008, Geometry and Computing, V1, P728, DOI DOI 10.1007/978-3-540-73398-0
   Farouki RT, 2008, COMPUT AIDED GEOM D, V25, P274, DOI 10.1016/j.cagd.2007.09.007
   Farouki RT, 2004, J COMPUT APPL MATH, V162, P365, DOI 10.1016/j.cam.2003.08.030
   Farouki RT, 2003, COMPUT AIDED GEOM D, V20, P435, DOI 10.1016/S0167-8396(03)00095-5
   Farouki RT, 2002, GRAPH MODELS, V64, P382, DOI 10.1016/S1524-0703(03)00002-X
   Farouki RT, 2002, ADV COMPUT MATH, V17, P369, DOI 10.1023/A:1016280811626
   Farouki RT, 2002, COMPUT AIDED GEOM D, V19, P395, DOI 10.1016/S0167-8396(02)00123-1
   FAROUKI RT, 2008, J SYMBOLIC IN PRESS
   Guggenheimer H., 1989, Computer-Aided Geometric Design, V6, P77, DOI 10.1016/0167-8396(89)90008-3
   Holden JG, 1999, SURG ENDOSC-ULTRAS, V13, P127, DOI 10.1007/s004649900920
   Jüttler B, 1999, COMPUT AIDED DESIGN, V31, P73, DOI 10.1016/S0010-4485(98)00081-5
   JUTTLER B, 1999, J GEOM GRAPHICS, V3, P141
   Juttler B., 1998, GEOMETRIC MODELING P, P83
   Klok F., 1986, Computer-Aided Geometric Design, V3, P217, DOI 10.1016/0167-8396(86)90039-7
   Kreyszig E., 1959, Differential geometry
   MATTSSONBOZE D, 2000, Patent No. 6097423
   MONTERDE J, 2008, ADV COMPUTATIONAL MA
   Nieuwenhuisen D, 2004, IEEE INT CONF ROBOT, P3870, DOI 10.1109/ROBOT.2004.1308871
   SCHARA JN, 2006, Patent No. 7134992
   Sir Z, 2007, MATH COMPUT, V76, P1373, DOI 10.1090/S0025-5718-07-01925-4
   Solomon SB, 2000, CHEST, V118, P1783, DOI 10.1378/chest.118.6.1783
   Wang WP, 1997, COMPUT AIDED DESIGN, V29, P379, DOI 10.1016/S0010-4485(96)00077-2
NR 28
TC 14
Z9 14
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL-AUG
PY 2009
VL 20
IS 4
BP 457
EP 472
DI 10.1002/cav.274
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 488QG
UT WOS:000269364200003
DA 2024-07-18
ER

PT J
AU Kim, S
   Redon, S
   Kim, YJ
AF Kim, Sujeong
   Redon, Stephane
   Kim, Young J.
TI View-dependent dynamics of articulated bodies
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE dynamics; kinematics; level-of-detail; simulation; articulated bodies
ID PARALLEL O(LOG(N)) CALCULATION; RIGID-BODY DYNAMICS; ALGORITHM; MOTION;
   EFFICIENT
AB We propose a method for view-dependent simplification of articulated-body dynamics, which enables an automatic trade-off between visual precision and computational efficiency. We begin by discussing the problem of simplifying the simulation based on visual criteria, and show that it raises a number of challenging questions. We then focus on articulated-body dynamics simulation, and propose a semi-predictive approach which relies on a combination of exact, a priori error metrics computations, and visibility estimations. We suggest several variants of semi-predictive metrics based on hierarchical data structures and the use of graphics hardware, and discuss their relative merits in terms of computational efficiency and precision. Finally, we present several benchmarks and demonstrate how our view-dependent articulated-body dynamics method allows an animator (or a physics engine) to finely tune the visual quality and obtain potentially significant speed-ups during interactive or off-line simulations. Copyright 2008 John Wiley & Sons, Ltd.
C1 [Kim, Young J.] Ewha Womans Univ, Seoul, South Korea.
   [Redon, Stephane] INRIA Rhone Alpes, Grenoble, France.
   [Redon, Stephane] Univ N Carolina, Dept Comp Sci, GAMMA Res Team, Chapel Hill, NC 27515 USA.
C3 Ewha Womans University; University of North Carolina; University of
   North Carolina Chapel Hill
RP Kim, YJ (corresponding author), Ewha Womans Univ, Seoul, South Korea.
EM kimy@ewha.ac.kr
OI Redon, Stephane/0000-0002-2618-8975; Kim, Young J./0000-0003-2159-4832
CR [Anonymous], 2003, Level of detail for 3D graphics
   BARZEL R, 1996, P EUR WORKSH COMP AN, P183
   BEAUDOIN J, 2004, P 2004 ACM SIGGRAPH
   BERTAILS F, 2003, P ACM SIGGRAPH EUR S
   CARLSON D, 1997, P GRAPH INT
   Chen HM, 2000, ENZYME MICROB TECH, V27, P219, DOI 10.1016/S0141-0229(00)00215-5
   Chenney S, 1999, IEEE COMPUT GRAPH, V19, P79, DOI 10.1109/38.749126
   CHENNEY S, 1997, P 1997 S INT 3D GRAP
   DEBUNNE G, 2001, P 28 ANN C COMP GRAP
   Featherstone R, 1999, INT J ROBOT RES, V18, P876, DOI 10.1177/02783649922066628
   Featherstone R, 1999, INT J ROBOT RES, V18, P867, DOI 10.1177/02783649922066619
   Gayle R, 2007, IEEE INT CONF ROBOT, P3319, DOI 10.1109/ROBOT.2007.363985
   GOTTSCHALK S, 1996, SIGGRAPH 96 C P, P171
   Grinspun E, 2002, ACM T GRAPHIC, V21, P281, DOI 10.1145/566570.566578
   Harrison J, 2004, ACM T GRAPHIC, V23, P569, DOI 10.1145/1015706.1015761
   HOPPE H, 1997, SIGGRAPH 97, P189
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   LI L, 2005, P 28 AUSTR C COMP SC
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   *NVIDA, 2004, SDK WHIT PAP OCC QUE
   O'Sullivan C, 2001, ACM T GRAPHIC, V20, P151, DOI 10.1145/501786.501788
   OBRIEN D, 2001, P COMP AN
   OSULLIVAN C, 2003, SIGGRAPH 03, P527
   OSullivan Carol., 2005, ACM T APPL PERCEPTIO, V2, P309
   PERBET F, 2001, P 2001 S INT 3D GRAP
   Redon S, 2006, COMPUT AIDED DESIGN, V38, P300, DOI 10.1016/j.cad.2006.01.009
   Redon S, 2005, ACM T GRAPHIC, V24, P936, DOI 10.1145/1073204.1073294
   Reitsma PSA, 2003, ACM T GRAPHIC, V22, P537, DOI 10.1145/882262.882304
   Twigg CD, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239465
   WARD K, 2003, P COMP AN SOC AG
NR 30
TC 1
Z9 1
U1 0
U2 1
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 223
EP 233
DI 10.1002/cav.245
PG 11
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 354GZ
UT WOS:000259628200007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Silveira, R
   Prestes, E
   Nedel, LP
AF Silveira, Renato
   Prestes, Edson
   Nedel, Luciana P.
TI Managing coherent groups
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE groups simulation; motion planning; formation-keeping; potential field
ID NAVIGATION
AB The animation of groups of characters involves the generation of some interesting steering behaviors like following a single path, moving toward a common objective, and moving while keeping a formation. This paper presents a new approach to manage the movement of groups in dynamic environments using a simple and robust algorithm that includes a strategy to keep formations during the displacement of the group. Our method is based oil a boundary value problem (BVP) involving Laplace's equation and has two layers. In the first one, a group map is built to allow for local control of each individual, while in the second one a path planning is performed for each group as a whole. Results show that our technique is robust to several situations and can be implemented on GPU, which results in real-time performance for large groups. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Silveira, Renato] Univ Fed Rio Grande do Sul, Inst Informat, BR-90046900 Porto Alegre, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP Silveira, R (corresponding author), Univ Fed Rio Grande do Sul, Inst Informat, BR-90046900 Porto Alegre, RS, Brazil.
EM rsilveira@inf.ufrgs.br
RI Prestes, Edson/C-4947-2013; Nedel, Luciana/G-3506-2012
OI Nedel, Luciana/0000-0002-2390-1392
CR [Anonymous], 2006, 900 SIGGRAPH S VID G, P113, DOI [DOI 10.1145/1183316.1183333, 10.1145/1183316.1183333]
   BALCH T, 2000, IEEE INT C ROB AUT I
   Berg J., 2008, SI3D 08, P139
   DAPPER F, 2007, P COMP GRAPH INT CGI, P105
   DIETRICH CA, 2008, GAME PROGRAMMING GEM, P59
   Fredslund J, 2002, IEEE T ROBOTIC AUTOM, V18, P837, DOI 10.1109/TRA.2002.803458
   KAMPHUIS A, 2004, SCA 04, P19
   LI T, 2003, INT C ROB AUT ICRA
   Miller Freeman Game Group, 1999, P GAM DEV C SAN JOS, P763
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   MUSSE SR, 2005, ACM SIGGRAPH 2005 CO, P2
   Nieuwenhuisen D, 2007, SCI COMPUT PROGRAM, V67, P91, DOI 10.1016/j.scico.2006.06.008
   Pottinger D., 1999, GAME DEV         JAN, P42
   Pottinger D., 1999, GAME DEV MAGAZINE, P48
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Song P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1217, DOI 10.1109/ROBOT.2002.1014709
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Trevisan M, 2006, J INTELL ROBOT SYST, V45, P101, DOI 10.1007/s10846-005-9008-2
NR 18
TC 7
Z9 9
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 295
EP 305
DI 10.1002/cav.261
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200013
DA 2024-07-18
ER

PT J
AU Avanzini, F
   Crosato, P
AF Avanzini, Federico
   Crosato, Paolo
TI Integrating physically based sound models in a multimodal rendering
   architecture
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE multimodal interaction; sound rendering; stiffness
ID PERCEPTION; HEAR; WORLD
AB This paper presents a multimodal rendering architectnre that integrates physically based sound models with haptic and visual rendering. The proposed sound modeling approach is compared to other existing techniques. An example of implementation of the architectnre is presented, that realizes bimodal (auditory and haptic) rendering of contact stiffness. It is shown that the proposed rendering scheme allows tight synchronization of the two modalities, as well as a high degree of interactivity and responsiveness of the sound models to gestures and actions of a user. Finally, an experiment on the relative contributions of haptic and auditory information to bimodal judgments of contact stiffness is presented. Experimental results support the effectiveness of auditory feedback in modulating haptic perception of stiffness. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Univ Padua, Dept Informat Engn, I-35131 Padua, Italy.
C3 University of Padua
RP Avanzini, F (corresponding author), Univ Padua, Dept Informat Engn, Via Gradenigo 6-A, I-35131 Padua, Italy.
EM avanzini@dei.unipd.it
RI Avanzini, Federico/HCI-9135-2022
OI Avanzini, Federico/0000-0002-1257-5878
CR Adrien J.-M., 1991, Representations on musical signals, P269
   Avanzini F, 2005, IEEE T SPEECH AUDI P, V13, P1073, DOI 10.1109/TSA.2005.852984
   Avanzini F., 2003, THE SOUNDING OBJECT, P137
   Avanzini F., 2004, P C SOUND MUSIC COMP, P287
   Bresciani JP, 2005, EXP BRAIN RES, V162, P172, DOI 10.1007/s00221-004-2128-2
   COLGATE JE, 1994, IEEE INT CONF ROBOT, P3205, DOI 10.1109/ROBOT.1994.351077
   Cook Perry R, 2002, Real Sound Synthesis for Interactive Applications
   DiFilippo D. E., 2000, P ACM S US INT SOFTW
   DiFranco D. E., 1997, P ASME DYN SYST CONT, V61
   DOBASHI Y, 2003, P ACM SIGGRAPH, P732
   Doel K, 2005, ACM Trans. Appl. Percept., V2, P534, DOI [10.1145/1101530.1101554, DOI 10.1145/1101530.1101554]
   FREED DJ, 1990, J ACOUST SOC AM, V87, P311, DOI 10.1121/1.399298
   GAVER WW, 1993, ECOL PSYCHOL, V5, P1, DOI 10.1207/s15326969eco0501_1
   GAVER WW, 1993, ECOL PSYCHOL, V5, P285, DOI 10.1207/s15326969eco0504_2
   GIORDANO B, 2006, THESIS U PADOVA ITAL
   Guest S, 2002, EXP BRAIN RES, V146, P161, DOI 10.1007/s00221-002-1164-z
   Hahn JK, 1998, PRESENCE-TELEOP VIRT, V7, P67, DOI 10.1162/105474698565532
   Hötting K, 2004, PSYCHOL SCI, V15, P60, DOI 10.1111/j.0963-7214.2004.01501010.x
   HUNT KH, 1975, J APPL MECH-T ASME, V42, P440, DOI 10.1115/1.3423596
   Klatzky RL, 2000, PRESENCE-TELEOP VIRT, V9, P399, DOI 10.1162/105474600566907
   Kuchenbecker KJ, 2006, IEEE T VIS COMPUT GR, V12, P219, DOI 10.1109/TVCG.2006.32
   Lederman SJ, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P97, DOI 10.1109/HAPTIC.2002.998946
   LEDERMAN SJ, 1979, PERCEPTION, V8, P93, DOI 10.1068/p080093
   McGee P., 2002, EUROHAPTICS, P47
   *NOV TECH, 2002, P 7 PHANT US GROUP W
   OBrien J.F., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics symposium on Computer animation, P175
   Salisbury K, 2004, IEEE COMPUT GRAPH, V24, P24, DOI 10.1109/MCG.2004.1274058
   van den Doel K, 1998, PRESENCE-TELEOP VIRT, V7, P382, DOI 10.1162/105474698565794
   Welch R.B., 1986, HDB PERCEPTION HUMAN
   WU W, 1999, P ASME DYN SYST CONT, V67
   Zolzer U., 2002, DAFX-Digital audio effects
NR 31
TC 18
Z9 20
U1 0
U2 0
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 411
EP 419
DI 10.1002/cav.144
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400027
DA 2024-07-18
ER

PT J
AU Jorissen, P
   De Boeck, J
   Lamotte, W
AF Jorissen, Pieter
   De Boeck, Joan
   Lamotte, Wim
TI Bringing haptics and physical simulation together: haptic travel through
   physical worlds
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE virtual environments; haptic interaction; physical simulation;
   navigation
ID VIRTUAL ENVIRONMENTS
AB This paper describes our efforts in bringing haptics closer to current dynamic virtual environments (VE). These interactive 3D worlds make more and more rise of physical simulations in order to increase realism. As a first step in closing the gap, we propose haptic travel that allows users to feel how their virtual representation navigates through the simulated world. In this Work, we show how we coupled stable haptic rendering to physical simulation in order to achieve this. By generating a force feedback field, based oil the user's input in combination with collision information provided by a rigid body simulator, we managed to provide the user with useful information Oil what is happening to its virtual representation. A humanoid animated character, which represents the riser, is coupled to tire rigid body object that represents the user in physical space. This character is animated according to the travel motions that the physical object makes, depending oil user input from the haptic device. Our approach is suitable for a whole set of applications and input devices and can reduce the number of devices necessary to interact in VEs. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Expertise Ctr Digital Media, B-3590 Diepenbeek, Belgium.
   Interdisciplinary Inst Broadband Technol, B-3590 Diepenbeek, Belgium.
RP Jorissen, P (corresponding author), Expertise Ctr Digital Media, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
EM pieter.jorissen@uhasselt.be
RI Lamotte, Wim/F-1796-2017
OI Lamotte, Wim/0000-0003-1888-6383
CR [Anonymous], 2005, P 7 INT C VIRT REAL
   BOWMAN D, 1998, HUM COMP INT CONS HC
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Jorissen P, 2005, IEEE T VIS COMPUT GR, V11, P649, DOI 10.1109/TVCG.2005.100
   MINE M, 1995, TR95018
   OORE S, 2000, P GRAPH INT GI02
   POUPREY I, 1998, COMPUT GRAPH FORUM, V17, P30
   STONE RJ, 2000, P 1 INT WORKSH HAPT, P1
NR 8
TC 2
Z9 2
U1 0
U2 4
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 179
EP 187
DI 10.1002/cav.121
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400005
DA 2024-07-18
ER

PT J
AU Pettré, J
   Ciechomski, PD
   Maïm, J
   Yersin, B
   Laumond, JP
   Thalmann, D
AF Pettre, Julien
   Ciechomski, Pablo de Heras
   Maim, Jonathan
   Yersin, Barbara
   Laumond, Jean-Paul
   Thalmann, Daniel
TI Real-time navigating crowds:: scalable simulation and rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE real-time crowds; crowd simulation; crowd rendering; navigation
ID VIRTUAL HUMANS; MOTION; MODEL; COMPLEX
AB This paper introduces a framework for real-time simulation and rendering of crowds navigating in a virtual environment. The solution first consists in a specific environment preprocessing technique giving rise to navigation graphs, Which are then used by the navigation and simulation tasks. Second, navigation planning interactively provides various solutions to the user queries, allowing to spread a crowd by individualizing trajectories. A scalable simulation model enables the management of large crowds, while saving computation time for rendering tasks. Pedestrian graphical models are divided into three rendering fidelities ranging from billboards to dynamic meshes, allowing close-up views of detailed digital actors with a large variety of locomotion animations. Examples illustrate our method in several environments with crowds of up to 35 000 pedestrians with real-time performance. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Swiss Fed Inst Technol, Virtual Real Lab, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Pettré, J (corresponding author), Swiss Fed Inst Technol, Virtual Real Lab, CH-1015 Lausanne, Switzerland.
EM julien.pettre@epfl.ch
RI Pettré, Julien/AAB-2590-2022; Thalmann, Daniel/A-4347-2008; Thalmann,
   Daniel/AAL-1097-2020
OI Thalmann, Daniel/0000-0002-0451-7491
CR [Anonymous], S COMP AN 05 P NEW Y
   [Anonymous], SCHRIFTENREIHE IVT
   [Anonymous], 2012, Robot Motion Planning
   [Anonymous], 2005, P ACM SIGGRAPH EUR S
   Aubel A, 2000, IEEE T CIRC SYST VID, V10, P207, DOI 10.1109/76.825720
   Bouvier E., 1996, proc: Eurographics Workshop on Virtual Environments and Scientific Visualization'96, P104
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   COIC JM, 2005, 3 LOD REALISTIC REAL
   DOBBYN S, 2005, I3D 05, P95
   GIPPS PG, 1985, MATH COMPUT SIMULAT, V27, P95, DOI 10.1016/0378-4754(85)90027-8
   Glardon P, 2006, VISUAL COMPUT, V22, P194, DOI 10.1007/s00371-006-0376-9
   Haït A, 2002, ADV ROBOTICS, V16, P673, DOI 10.1163/15685530260425693
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   HODGINS JK, 1995, SIGGRAPH 95, V29, P71
   Hoff KE, 1999, COMP GRAPH, P277, DOI 10.1145/311535.311567
   HOPPE H, 1996, SIGGRAPH 96, P99, DOI DOI 10.1145/237170.237216
   KAMPHUIS A, 2004, SCA 04, P19
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Klüpfel H, 2001, THEORETICAL AND PRACTICAL ISSUES ON CELLULAR AUTOMATA, P63
   KWON T., 2005, SCA 05, P29
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   MOLLER T, 2002, REAL TIME RENDERING
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   PEARCE D, 2004, SCA 04, P34
   PETTRE J, 2003, SCA 03, P258
   Pettre J., 2005, First Intl. Work- shop on Crowd Simulation, P81
   Pfister H, 2000, COMP GRAPH, P335, DOI 10.1145/344779.344936
   Reynolds C. W., 1999, P GAM DEV C, P763
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   SHAO W, 2005, SCA 05, P19
   Tecchia F, 2002, COMPUT GRAPH FORUM, V21, P753, DOI 10.1111/1467-8659.00633
   Terzopoulos D, 1999, COMMUN ACM, V42, P32, DOI 10.1145/310930.310966
   Ulicny Branislav, 2004, SCA'04'- Proc. of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P243, DOI [DOI 10.2312/SCA/SCA04/243-252, 10.1145/1028523.1028555, DOI 10.1145/1028523.1028555]
   Wand M, 2002, COMPUT GRAPH FORUM, V21, P483, DOI 10.1111/1467-8659.t01-1-00608
   Yersin B., 2005, P 1 INT WORKSHOP CRO, P169
NR 39
TC 73
Z9 82
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 445
EP 455
DI 10.1002/cav.147
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400030
DA 2024-07-18
ER

PT J
AU Hong, JK
   Kim, CH
AF Hong, JK
   Kim, CH
TI Animating smoke with dynamic balance
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE computer animation; fluid animation; gaseous phenomena; advection;
   numerical dissipation; vorticity confinement
AB We propose a numerical method for maintaining a dynamic rolling motion of animated gaseous phenomena, such as smoke, that avoids dissipation due to numerical error. We compensate for the errors induced by a semi-Lagrangian scheme using an error estimate for each time interval. We develop a new advection term and perform vortex advection based on a vorticity confinement force. Example simulations show that this method is able to keep smoke features alive, even near the center Of a vortex. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Korea Univ, Comp Graph Lab, Seoul 136701, South Korea.
C3 Korea University
RP Korea Univ, Comp Graph Lab, 5 Ga,Anam Dong, Seoul 136701, South Korea.
EM chkim@korea.ac.kr
CR Abbott M.B., 1989, COMPUTATIONAL FLUID
   ANGELIDIS A, 2005, EUR ACM SIGGRAPH S C
   [Anonymous], 1992, VORTEX DYNAMICS, DOI DOI 10.1017/CBO9780511624063
   BRUGER A, 2002, J COMPUT PHYS, V4, P197
   Dupont TF, 2003, J COMPUT PHYS, V190, P311, DOI 10.1016/S0021-9991(03)00276-6
   FATTAL R, 2004, P ACM SIGGRAPH 2004, V190, P441
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster Nick., 1997, P 24 ANN C COMP GRAP, P181
   Griebel M, 1988, NUMERICAL SIMULATION
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   HONG JM, 2005, ACM T GRAPHICS
   HONG JM, 2002, COMPUT GRAPH FORUM, V22, P253
   Johnston H, 2004, J COMPUT PHYS, V199, P221, DOI 10.1016/j.jcp.2004.02.009
   KIM B, 2005, EUR WORKSH NAT PHEN
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   PARK S, 2005, EUR GRAPH ACM SIGGRA
   Press W. H., 1988, Numerical Recipes
   SELLE A, 2005, ACM T GRAPHIC, V24, P1
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Song OY, 2005, ACM T GRAPHIC, V24, P81, DOI 10.1145/1037957.1037962
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Van Dyke M., 1982, ALBUM FLUID MOTION
NR 24
TC 3
Z9 3
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 405
EP 414
DI 10.1002/cav.87
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000024
DA 2024-07-18
ER

PT J
AU Park, SI
   Shin, HJ
   Kim, TH
   Shin, SY
AF Park, SI
   Shin, HJ
   Kim, TH
   Shin, SY
TI On-line motion blending for real-time locomotion generation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE computer animation; example-based motion synthesis; motion blending;
   locomotion generation
AB In this paper, we present an integrated framework of on-line motion blending for locomotion generation. We first provide a novel scheme for incremental timewarping, which always guarantees that the time goes forward. Combining the idea of motion blending with that of posture rearrangement, we introduce a motion transition graph to address on-line motion blending and transition simultaneously. Guided by a stream of motion specifications, our motion synthesis scheme moves from node to node in an on-line manner while blending a motion at a node and generating a transition motion at an edge. For smooth on-line motion transition, we also attach a set of example transition motions to an edge. To represent similar postures consistently, we exploit the inter-frame coherency embedded in the input motion specification. Finally, we provide a comprehensive solution to on-line motion retargeting by integrating existing techniques. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Korea Adv Inst Sci & Technol, Div Comp Sci, Taejon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Korea Adv Inst Sci & Technol, Div Comp Sci, Taejon, South Korea.
EM sipark@jupiter.kaist.ac.kr
RI Shin, Sung Yong/C-1955-2011
OI Shin, Hyun Joon/0000-0002-7786-6908
CR [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], 2001, P 2001 S INTERACTIVE
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Choi KJ, 2000, J VISUAL COMP ANIMAT, V11, P223, DOI 10.1002/1099-1778(200012)11:5<223::AID-VIS236>3.0.CO;2-5
   Gleicher M, 2001, GRAPH MODELS, V63, P107, DOI 10.1006/gmod.2001.0549
   GUO S, 1996, P EUR WORKSH COMP AN, V96, P95
   KIM MJ, 1995, P 22 ANN C COMP GRAP, P369, DOI DOI 10.1145/218380.218486
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee J, 1999, COMP GRAPH, P39
   Lee J, 2002, IEEE T VIS COMPUT GR, V8, P119, DOI 10.1109/2945.998665
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   Park S, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P105, DOI 10.1109/MOTION.2002.1182221
   Pullen K, 2002, ACM T GRAPHIC, V21, P501
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Shoemake Ken, 1985, P 12 ANN C COMP GRAP, P245, DOI [DOI 10.1145/325165.325242, DOI 10.1145/325334.325242]
   Sturman DJ, 1998, IEEE COMPUT GRAPH, V18, P38, DOI 10.1109/38.637269
   Wiley DJ, 1997, IEEE COMPUT GRAPH, V17, P39, DOI 10.1109/38.626968
NR 21
TC 42
Z9 63
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 125
EP 138
DI 10.1002/cav.15
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700002
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, IR
   Wan, JWL
   Baranoski, GVG
AF Wang, IR
   Wan, JWL
   Baranoski, GVG
TI Physically-based simulation of plant leaf growth
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE plant; leaf; growth model; physically-based simulation; natural
   phenomena
ID SCATTERING
AB A mathematical model is presented to simulate the growth of a plant leaf. The tissue in the leaf has been regarded as a viscous, incompressible fluid whose 2D expansion comes from the non-zero specific growth rate in area. The resulting system of equations are composed of the modified Navier-Stokes equations. The level set method is used to capture the expanding leaf front. Numerical simulations indicate that different portions of the leaf expand at different rates, which is consistent with the biological observations in the growth of a plant leaf. Numerical results for the case of the Xanthium leaf growth are also presented. A standard ray tracing technique is applied to produce an animation simulating the leaf growth process of three days. The key results with their physical and practical implications are discussed. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Waterloo, Sch Comp Sci, Waterloo, ON, Canada.
C3 University of Waterloo
RP Univ Waterloo, Sch Comp Sci, 200 Univ Ave W, Waterloo, ON, Canada.
EM r5wang@uwaterloo.ca
RI Baranoski, Gladimir/A-1944-2008
CR [Anonymous], P C GRAPH HARDW
   Avery GS Jr, 1933, AM J BOT, V20, P565, DOI 10.2307/2436259
   Baranoski GVG, 2001, VISUAL COMPUT, V17, P491, DOI 10.1007/s003710100126
   Batchelor G., 1967, INTRO FLUID DYNAMICS
   Bloomenthal J., 1985, Computer Graphics, V19, P305, DOI 10.1145/325165.325249
   BREECE HT, 1971, APPL OPTICS, V10, P119, DOI 10.1364/AO.10.000119
   CHORIN AJ, 1968, MATH COMPUT, V22, P745, DOI 10.2307/2004575
   Dillon R, 1999, J THEOR BIOL, V197, P295, DOI 10.1006/jtbi.1998.0876
   ERICKSON RO, 1966, J EXP BOT, V17, P390, DOI 10.1093/jxb/17.2.390
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Golub G.H., 1991, MATRIX COMPUTATIONS, Vsecond
   GOODWIN RH, 1956, AM J BOT, V43, P479, DOI 10.2307/2438887
   Griebel M, 1998, Numerical simulation in fluid dynamics: A practical introduction
   Hanrahan P., 1993, P ACM SIGGRAPH, P165
   Hosgood B., 1995, 16095 EUR EN
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Maksymowych R., 1973, ANAL LEAF DEV
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PRUSINKIEWICZ P, 1993, P SIGGRAPH 93, P351, DOI DOI 10.1145/166117.166161
   Richards OW, 1943, AM NAT, V77, P385, DOI 10.1086/281140
   SCHMUNDT D, 1996, P INT C SPECTR OPT T
   SILK WK, 1979, J THEOR BIOL, V76, P481, DOI 10.1016/0022-5193(79)90014-6
   SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155
   TOME MF, 1994, J COMPUT PHYS, V110, P171, DOI 10.1006/jcph.1994.1013
   Yavneh I, 1998, SIAM J SCI COMPUT, V19, P1682, DOI 10.1137/S1064827596310998
NR 28
TC 13
Z9 17
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 237
EP 244
DI 10.1002/cav.26
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700013
DA 2024-07-18
ER

PT J
AU Zang, CY
   Gai, W
   Li, HD
   Xing, CZ
   Wang, WF
   Li, DL
   Lv, GR
   Yang, CL
AF Zang, Chenyu
   Gai, Wei
   Li, Haodong
   Xing, Chenzhi
   Wang, Wenfei
   Li, Dongli
   Lv, Gaorong
   Yang, Chenglei
TI Supporting foot interaction of reaction time training system
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE foot interaction; human computer interaction; interactive playground;
   reaction time training
ID VIDEO GAME EXPERIENCE; ATTENTION; EXERCISE; TRIAL
AB Reaction time, the ability to detect, process and respond to stimuli, is one of the fundamental factors in human computer interaction, and is a key cognitive skill in clinical and healthy populations. Good reaction time allows us to respond to stimuli and situations with agility and efficiency. How to train and improve a person's reaction time has become an important research question. In this paper, we present a new training genre which combines the user-centered personalized training objects generation with precise tracking of foot interaction.Virtual objects are created with respect to the user's features and historical training effectiveness, and are in motion. A foot tracking algorithm based on three-Gaussian model is designed to support interaction with stepping on moving virtual objects. We present the design and implementation of the system, as well as user studies. Findings illustrate that the reaction time performances are significantly improved following of seven days of training based on foot interaction.
   A user-adaptive foot interaction-based reaction-time training system. Training with fusion movements can improve human reactions.image
C1 [Zang, Chenyu; Gai, Wei; Li, Haodong; Xing, Chenzhi; Wang, Wenfei; Lv, Gaorong; Yang, Chenglei] Shandong Univ, Sch Software, Jinan, Peoples R China.
   [Li, Dongli] Huaiyin Dist Educ & Sports Bur, Expt Kindergarten Jinan Huaiyin Dist 2, Jinan, Peoples R China.
C3 Shandong University
RP Gai, W; Lv, GR (corresponding author), Shandong Univ, Sch Software, Jinan, Peoples R China.
EM gw@sdu.edu.cn; 15953173765@163.com
OI Zang, Chenyu/0009-0008-5803-1455
FU We would like to thank all reviewers for their valuable comments. This
   work is supported by National Key Ramp;D Program of China
   (2022ZD0118002), and the National Natural Science Foundation of China
   under Grants (62007021, 61972233, 62277035). [2022ZD0118002]; National
   Key Ramp;D Program of China [62007021, 61972233, 62277035]; National
   Natural Science Foundation of China
FX We would like to thank all reviewers for their valuable comments. This
   work is supported by National Key R&D Program of China (2022ZD0118002),
   and the National Natural Science Foundation of China under Grants
   (62007021, 61972233, 62277035).
CR Adleman NE, 2016, DEV COGN NEUROS-NETH, V19, P248, DOI 10.1016/j.dcn.2016.05.001
   Ando S, 2002, PERCEPT MOTOR SKILL, V95, P747, DOI 10.2466/PMS.95.7.747-751
   Bi XJ, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P313, DOI 10.1145/2984511.2984546
   Bialystok E, 2006, CAN J EXP PSYCHOL, V60, P68, DOI 10.1037/cjep2006008
   Boisgontier MP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090457
   Castel AD, 2005, ACTA PSYCHOL, V119, P217, DOI 10.1016/j.actpsy.2005.02.004
   Chandra S, 2016, PROCEDIA COMPUT SCI, V84, P115, DOI 10.1016/j.procs.2016.04.074
   Cibrian FL, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P223, DOI 10.1145/2638728.2638773
   del Corral T, 2014, J CYST FIBROS, V13, P706, DOI 10.1016/j.jcf.2014.05.004
   Delden VR., 2017, INT TECHN INT ENT 8, P124
   Ebersbach G, 2014, ARCH PHYS MED REHAB, V95, P996, DOI 10.1016/j.apmr.2013.10.020
   Franceschini S, 2013, CURR BIOL, V23, P462, DOI 10.1016/j.cub.2013.01.044
   Glueck AC, 2020, VIRTUAL REAL-LONDON, V24, P223, DOI 10.1007/s10055-019-00392-y
   Green CS, 2015, CURR OPIN BEHAV SCI, V4, P103, DOI 10.1016/j.cobeha.2015.04.012
   Green CS, 2003, NATURE, V423, P534, DOI 10.1038/nature01647
   Greenhouse I, 2017, J NEUROSCI, V37, P2686, DOI 10.1523/JNEUROSCI.3129-16.2017
   HART S G, 1988, P139
   Huang J., 2018, UNDERSTANDING UNCERT, P1
   Huang J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1031, DOI 10.1145/3332165.3347880
   Jayaswal AA., 2016, The Journal of Medical Research, V4, P1228, DOI [10.17511/ijmrr.2016.i07.26, DOI 10.17511/IJMRR.2016.I07.26]
   Kasahara S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445147
   Keshavan MS, 2014, AM J PSYCHIAT, V171, P510, DOI 10.1176/appi.ajp.2013.13081075
   Kuang SB, 2017, COGN NEUROSCI-UK, V8, P126, DOI 10.1080/17588928.2016.1205575
   LORD SR, 1994, ARCH PHYS MED REHAB, V75, P648, DOI 10.1016/0003-9993(94)90187-2
   Marwan S, 2022, IEEE T LEARN TECHNOL, V15, P406, DOI 10.1109/TLT.2022.3180984
   Micarelli A, 2017, INT J REHABIL RES, V40, P325, DOI 10.1097/MRR.0000000000000244
   Mistridis P, 2017, SWISS MED WKLY, V147, DOI 10.4414/smw.2017.14407
   Moreno A, 2016, ENTERTAIN COMPUT, V16, P67, DOI 10.1016/j.entcom.2016.03.001
   Peng C, 2019, IEEE ACCESS, V7, P68878, DOI 10.1109/ACCESS.2019.2918846
   Rabiner DL, 2010, J ABNORM CHILD PSYCH, V38, P131, DOI 10.1007/s10802-009-9353-x
   Ree MJ, 2008, PERS PSYCHOL, V61, P215
   Reeves DL, 2007, ARCH CLIN NEUROPSYCH, V22, pS15, DOI 10.1016/j.acn.2006.10.013
   Reigal RE, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02278
   Seitz PF., 1996, J ACOUST SOC AM, V99, P2602
   [史珈铭 Shi Jiaming], 2022, [心理科学, Journal of Psychological Science], V45, P1182
   Spitzer US, 2013, TRENDS NEUROSCI EDUC, V2, P1, DOI 10.1016/j.tine.2013.03.002
   Sturm J., 2013, P C HUM FACT COMP SY, P1
   Syväoja HJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103559
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   van Delden R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2462, DOI 10.1145/3025453.3025816
   van Delden R, 2014, LECT NOTES COMPUT SC, V8850, P145, DOI 10.1007/978-3-319-14112-1_13
   Wass SV, 2012, DEV REV, V32, P360, DOI 10.1016/j.dr.2012.07.001
   Weech S, 2018, J NEUROPHYSIOL, V120, P2201, DOI 10.1152/jn.00477.2018
   Wilcoxon F., 1992, Individual comparisons by ranking methods
   Yohanna F., 2020, CYBERPSYCHOL BEHAV, V1, P23
   Zheng Y, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401135
   Ziagkas E, 2018, ADV INTELL SYST, V725, P644, DOI 10.1007/978-3-319-75175-7_63
NR 47
TC 0
Z9 0
U1 6
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2219
EA OCT 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001077553200001
DA 2024-07-18
ER

PT J
AU Li, CC
   Wu, Q
AF Li, Chaochao
   Wu, Qiong
TI Heterogeneous group path planning algorithm based on data and mechanism
   model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE collision avoidance; heterogeneous group; hybrid driven model; path
   planning
ID MOTION
AB It is a challenging task to find a feasible path from the start to the end for heterogeneous group and avoid collision between dynamic agents and static obstacles. The existing methods are usually applicable to static simple scenes or the type of scenes including a single kind of agents, and it is difficult to meet the high dynamic heterogeneous group movements. To address the above issues, we propose a hybrid driven heterogeneous group path planning method based on data and mechanism model. Data and mechanism model are combined to drive movements of heterogeneous groups. The experimental results show that our method can describe movements of heterogeneous groups more realistically and solve the collision avoidance of heterogeneous groups well. We quantitatively evaluate our method using metrics such as the number of inflection points and the average turning angle. Average turning angle has decreased by 59.50% on average over prior methods. Number of inflection points has decreased by 69.19% on average over prior methods.
   This article proposes a hybrid driven heterogeneous group path planning method based on data and mechanism model. Data and mechanism model are combined to drive movements of heterogeneous groups. The experimental results show that our method can describe movements of heterogeneous groups realistically and solve the collision avoidance of heterogeneous groups well.image
C1 [Li, Chaochao] Zhengzhou Univ, Sch Comp & Artificial Intelligence, Zhengzhou, Peoples R China.
   [Wu, Qiong] Zhengzhou Profess Tech Inst Elect & Informat, Sch Art, Zhengzhou, Peoples R China.
C3 Zhengzhou University
RP Wu, Q (corresponding author), Zhengzhou Profess Tech Inst Elect & Informat, Sch Art, Zhengzhou, Peoples R China.
EM 295766890@qq.com
FU Chaochao Li was supported by the National Natural Science Foundation of
   China (Grant No. 62102371). [62102371]; National Natural Science
   Foundation of China
FX Chaochao Li was supported by the National Natural Science Foundation of
   China (Grant No. 62102371).
CR Aremu D. R., 2020, 2020 INT C MATH COMP, P1, DOI [10.1109/ ICMCECS47690.2020.240873, DOI 10.1109/ICMCECS47690.2020.240873]
   ASiL U., 2020, P INN INT SYST APPL, P1
   Bruce J, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2383, DOI 10.1109/IRDS.2002.1041624
   Buyukkocak AT, 2021, IEEE ROBOT AUTOM LET, V6, P1375, DOI 10.1109/LRA.2021.3057049
   Cai PP, 2020, IEEE INT CONF ROBOT, P4023, DOI [10.1109/icra40945.2020.9197228, 10.1109/ICRA40945.2020.9197228]
   Du Jixiang, 2022, 2022 5th International Conference on Robotics, Control and Automation Engineering (RCAE), P236, DOI 10.1109/RCAE56054.2022.9995798
   Hu B, 2021, IEEE T IND ELECTRON, V68, P3292, DOI 10.1109/TIE.2020.2978701
   Hwang I., 2019, INT J PROD RES, V3, P1
   Jiang H., 2021, J PHYS C SER, V1871
   Jiang L, 2020, IEEE-CAA J AUTOMATIC, V7, P1179, DOI 10.1109/JAS.2019.1911732
   Li BH, 2022, IEEE-CAA J AUTOMATIC, V9, P283, DOI 10.1109/JAS.2021.1004252
   Li CC, 2022, IEEE T AFFECT COMPUT, V13, P729, DOI 10.1109/TAFFC.2019.2954394
   Li J., 2020, P INT JOINT C AUT AG, P726
   Li JY, 2019, AAAI CONF ARTIF INTE, P7627
   Li J, 2017, IEEE T SYST MAN CY-S, V47, P1039, DOI 10.1109/TSMC.2016.2531648
   Luo YF, 2022, IEEE ROBOT AUTOM LET, V7, P3499, DOI 10.1109/LRA.2022.3144501
   Ma Y., 2018, ACM COMP SCI CARS S
   Ma YX, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1044
   Mingliang Xu, 2021, IEEE Transactions on Intelligent Transportation Systems, V22, P6977, DOI 10.1109/TITS.2020.3000607
   Muhammad F, 2018, 2018 INTERNATIONAL SEMINAR ON INTELLIGENT TECHNOLOGY AND ITS APPLICATIONS (ISITIA 2018), P275, DOI 10.1109/ISITIA.2018.8711117
   Murakami K, 2020, COMPUT IND ENG, V141, DOI 10.1016/j.cie.2020.106270
   Orozco-Rosas U, 2022, IEEE ACCESS, V10, P84648, DOI 10.1109/ACCESS.2022.3197628
   Orozco-Rosas U, 2019, IEEE ACCESS, V7, P156787, DOI 10.1109/ACCESS.2019.2949835
   Orozco-Rosas U, 2019, APPL SOFT COMPUT, V77, P236, DOI 10.1016/j.asoc.2019.01.036
   Pan ZH, 2022, IEEE T CIRCUITS-II, V69, P1129, DOI 10.1109/TCSII.2021.3112787
   Predhumeau M., 2020, 2020 SPRING SIM C NE, P1
   Ren JP, 2021, IEEE T VIS COMPUT GR, V27, P1953, DOI 10.1109/TVCG.2019.2946769
   Saeed RA, 2022, INFORM SCIENCES, V583, P137, DOI 10.1016/j.ins.2021.11.028
   Saeid S., 2019, 2019 5 INT C CONTR A
   Solis I, 2021, IEEE ROBOT AUTOM LET, V6, P4608, DOI 10.1109/LRA.2021.3068910
   Song Chen, 2022, 2022 International Seminar on Computer Science and Engineering Technology (SCSET), P19, DOI 10.1109/SCSET55041.2022.00014
   STENTZ A, 1994, IEEE INT CONF ROBOT, P3310, DOI 10.1109/ROBOT.1994.351061
   Sundaran K., 2018, 2018 Fourth International Conference on Advances in Electrical, Electronics, Information, Communication and Bio-Informatics (AEEICB), P1
   Tingyu Ma, 2020, 2020 International Conference on Information Science, Parallel and Distributed Systems (ISPDS), P283, DOI 10.1109/ISPDS51347.2020.00065
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Zhang TY, 2022, IEEE-CAA J AUTOMATIC, V9, P64, DOI 10.1109/JAS.2021.1004275
   Zhao YH, 2022, VEH TECHNOL CONFE, DOI 10.1109/VTC2022-Spring54318.2022.9860976
   [郑渤龙 Zheng Bolong], 2022, [计算机研究与发展, Journal of Computer Research and Development], V59, P329
   Zhi-Wen W, 2016, INT SYM COMPUT INTEL, P211, DOI [10.1109/ISCID.2016.54, 10.1109/ISCID.2016.1055]
NR 39
TC 0
Z9 0
U1 2
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2220
EA SEP 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001076076000001
DA 2024-07-18
ER

PT J
AU Fang, JH
   You, LH
   Chaudhry, E
   Zhang, J
AF Fang, Junheng
   You, Lihua
   Chaudhry, Ehtzaz
   Zhang, Jian
TI State-of-the-art improvements and applications of position based
   dynamics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE basic concepts; new applications; position-based approaches; recent
   improvements
ID SIMULATION; CONSTRAINT; DEFORMATION; FRAMEWORK; MODELS; ORDER
AB The emergence of position-based simulation approaches has quickly developed a group of new topics in the computer graphics community. These approaches are popular due to their advantages, including computational efficiency, controllability, stability and robustness for different scenarios, whilst they also have some weaknesses. In this survey, we will introduce the concept of the baseline position based dynamics (PBD) method and review the improvements and applications of PBD since 2018, including extensions for different materials and integrations with other techniques.
C1 [Fang, Junheng; You, Lihua; Chaudhry, Ehtzaz; Zhang, Jian] Bournemouth Univ, Natl Ctr Comp Animat, Poole, England.
C3 Bournemouth University
RP Fang, JH (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole, England.
EM jfang@bournemouth.ac.uk
OI Fang, Junheng/0000-0002-2024-3304
CR Ali IR, 2020, BAGHDAD SCI J, V17, P1294, DOI 10.21123/bsj.2020.17.4.1294
   Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626
   Angles B, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340260
   [Anonymous], 2005, P 2005 S INTERACTIVE, DOI [DOI 10.1145/1053427.10534294, DOI 10.1145/1053427.1053429]
   Bender J., 2017, P EUR ASS COMP GRAPH, DOI DOI 10.2312/EGT.20171034
   Bender J, 2014, COMPUT GRAPH-UK, V44, P1, DOI 10.1016/j.cag.2014.07.004
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P246, DOI 10.1111/cgf.12272
   Berndt I, 2017, IEEE COMPUT GRAPH, V37, P24, DOI 10.1109/MCG.2017.45
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Cao S., 2021, P 26 CAADRIA C, P21
   Capell S., 2005, P 2005 ACM SIGGRAPH, P301, DOI DOI 10.1145/1073368.1073412
   Cetinaslan O., 2021, P 14 ACM SIGGRAPH C, P1
   Cetinaslan O, 2018, ENTERTAIN COMPUT, V26, P78, DOI 10.1016/j.entcom.2018.02.001
   Chadwick J. E., 1989, Computer Graphics, V23, P243, DOI 10.1145/74334.74358
   Dahl A., 2019, MOTION INTERACTION G, P1, DOI DOI 10.1145/3359566.3360078
   Deul C, 2018, COMPUT GRAPH FORUM, V37, P313, DOI 10.1111/cgf.13326
   Deul C, 2016, COMPUT ANIMAT VIRT W, V27, P103, DOI 10.1002/cav.1614
   Dinev D, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201277
   English E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360665
   Francu M., 2017, P WORKSHOP VIRTUAL R, DOI [10.2312/vriphys.20171083, DOI 10.2312/VRIPHYS.20171083]
   Geyer L., 2022, THESIS WIEN
   Gibson S.F. F., 1997, SURVEY DEFORMABLE MO
   Gu YF, 2017, AER ADV ENG RES, V86, P191
   Han Y, 2020, PREPRINT
   Holden D, 2019, PROCEEDINGS SCA 2019: ACM SIGGRAPH/EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION, DOI 10.1145/3309486.3340245
   Huang Tianqi, 2022, SID Symposium Digest of Technical Papers, V53, P91, DOI 10.1002/sdtp.15857
   Jakobsen T., 2001, P GAM DEV C 2001, P1
   Khan L, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11142139
   Kim JH, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0272433
   KIM T.-Y., 2012, P ACM SIGGRAPHEUROGR, P305, DOI DOI 10.5555/2422356.2422399
   Koster M., 2016, INT J COMPUT GRAPH A, V6, P1, DOI DOI 10.5121/IJCGA.2016.6301
   Lee DK, 2022, INTELL AUTOM SOFT CO, V32, P1541, DOI 10.32604/iasc.2022.020674
   Li J., 2019, Proc. 18th annu. ACM SIGGRAPH/Eurographics SCA, P1
   Liu F., PREPRINT
   Liu Y., 1621, J PHYS CONF SER, V2020
   Löschner F, 2020, COMPUT GRAPH FORUM, V39, P157, DOI 10.1111/cgf.14110
   Macklin M, 2016, P 9 INT C MOT GAM, P49, DOI [10.1145/2994258.2994272, DOI 10.1145/2994258.2994272]
   Macklin M., 2019, P 18 ANN ACM SIGGRAP, P1
   Macklin M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3338695
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Müller MH, 2008, PROGRESS AND CHALLENGES IN TRANSFUSION MEDICINE, HEMOSTASIS AND HEMOTHERAPY: STATE OF THE ART 2008, P1, DOI 10.1159/000176608
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muller M, 2020, COMPUT GRAPH FORUM, V39, P101, DOI 10.1111/cgf.14105
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Pan JJ, 2015, COMPUT ANIMAT VIRT W, V26, P321, DOI 10.1002/cav.1655
   Pan Z., 2018, P INT WORKSHOP ALGOR, P673
   Peng H., 2022, IEEE T CYBERNETICS, V38, P1
   Romeo M, 2020, COMPUT GRAPH FORUM, V39, P134, DOI 10.1111/cgf.13734
   Romeo M., 2018, P 28 SPAN COMP GRAPH, P1, DOI DOI 10.2312/CEIG.20181146
   Schenck C., 2018, C ROBOT LEARNING, P317
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Shao H., 2022, THESIS
   Shao H, 2021, Advances in Neural Information Processing Systems, V34
   Shao XQ, 2017, IEEE ACCESS, V5, P13901, DOI 10.1109/ACCESS.2017.2729601
   Sharma R, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P214, DOI 10.1109/AIVR50618.2020.00044
   Soler C, 2018, COMPUT GRAPH FORUM, V37, P137, DOI 10.1111/cgf.13519
   Tagliabue E, 2020, IEEE INT C INT ROBOT, P3261, DOI 10.1109/IROS45743.2020.9341710
   Tan S., 2021, IEEE T CIRC SYST VID, V2021
   Terzopoulos D., 1988, Visual Computer, V4, P306, DOI 10.1007/BF01908877
   Vincent MB., 1996, IMPULSE BASED DYNAMI
   Walczak L., 2020, CURR DIR BIOMED ENG, V6
   Walczak L., 2019, P EUROGRAPHICS WORKS, P165
   Walczak L, 2022, COMPUT GRAPH FORUM, V41, P270, DOI 10.1111/cgf.14434
   Weiss T, 2017, MIG'17: PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON MOTION IN GAMES, DOI 10.1145/3136457.3136462
   Wu Hongyu, 2022, Complex System Modeling and Simulation, V2, P186, DOI 10.23919/CSMS.2022.0009
   Wu J, 2015, COMPUT GRAPH FORUM, V34, P161, DOI 10.1111/cgf.12528
   Xu L, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.171587
   Yang S., 2020, Advances in Neural Information Processing Systems, V33, P5178
   Yang XS, 2006, COMPUT ANIMAT VIRT W, V17, P281, DOI 10.1002/cav.132
   Zuo Y, 2022, INT J HYDROGEN ENERG, V47, P37040, DOI 10.1016/j.ijhydene.2022.08.255
NR 72
TC 1
Z9 1
U1 8
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2143
EA FEB 2023
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000938610700001
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Zhang, WS
   Nie, YY
   Guo, SH
   Chang, J
   Zhang, JJ
   Tong, RF
AF Zhang, Wenshu
   Nie, Yinyu
   Guo, Shihui
   Chang, Jian
   Zhang, Jianjun
   Tong, Ruofeng
TI Struct2Hair: A hair shape descriptor for hairstyle modeling
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE data-driven modeling; hair shape descriptor; hairstyle modeling
ID CAPTURE; DISTANCE
AB In recent years, it becomes possible to extract hair information for hair reconstruction from multiple cameras or monocular camera. Using a single image as the input avoids the high cost setups and complex calibration compared to multiviewed reconstruction. Taking advantage of an extendible hairstyle database, this paper introduced Struct2Hair, a novel single-viewed hair modelling approach by extracting hair shape descriptor (HSD). The HSD is defined as the fundamental structure-aware feature, which is a combination of critical shapes in a hairstyle. A complete dataset of critical hair shapes is constructed from a known database of three-dimensional (3D) hair models. We first analyze the input two-dimensional (2D) image to extract the orientation information and 2D hair sketch automatically. The extracted information is then used to retrieve the corresponding critical shapes with optimization to build the robust HSD. Finally, the HSD constructs a weighted 3D hair orientation field to guide full-head hair model generation. Our method can preserve local geometric features of hair and retain the whole shape of the hairstyle globally owing to the HSD, which will benefit further hair editing and stylization.
C1 [Zhang, Wenshu] Norwich Univ Arts, Fac Arts & Media, St Andrews House,St Andrews St, Norwich NR2 4TP, Norfolk, England.
   [Nie, Yinyu] Tech Univ Munich, Visual Comp & Artificial Intelligence Lab, Munich, Germany.
   [Guo, Shihui] Xiamen Univ, Sch Informat, Fujian, Peoples R China.
   [Chang, Jian; Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Dorset, England.
   [Tong, Ruofeng] Zhejiang Univ, Coll Comp Sci & Technol, Zhejiang, Peoples R China.
C3 Technical University of Munich; Xiamen University; Bournemouth
   University; Zhejiang University
RP Zhang, WS (corresponding author), Norwich Univ Arts, Fac Arts & Media, St Andrews House,St Andrews St, Norwich NR2 4TP, Norfolk, England.
EM w.zhang@nua.ac.uk
RI Nie, Yinyu/AES-2766-2022
OI Nie, Yinyu/0000-0001-7023-6797; Zhang, Wenshu/0000-0003-0776-7709;
   Chang, Jian/0000-0003-4118-147X; Zhang, Jian/0000-0002-7069-5771
CR [Anonymous], 2016, P 11 INT JOINT C COM
   Baak A., 2013, Consumer Depth Camerasfor Computer Vision: Research Topics and Applications, P71, DOI DOI 10.1007/978-1-4471-4640-7_5
   Chai ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925961
   Chai ML, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818112
   Chai ML, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461990
   Chai ML, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185612
   Chen DS, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766889
   Chen XD, 2010, COMPUT AIDED DESIGN, V42, P1197, DOI 10.1016/j.cad.2010.06.009
   Cheng AHD, 2012, ENG ANAL BOUND ELEM, V36, P220, DOI 10.1016/j.enganabound.2011.07.008
   Gao L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2908736
   Grabli S, 2002, PROC GRAPH INTERF, P51
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Herrera TL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366165
   Hu LW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766931
   Hu LW, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601194
   Jaiswal Ragesh, 2012, Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques. Proceedings 15th International Workshop, APPROX 2012 and 16th International Workshop, RANDOM 2012, P591, DOI 10.1007/978-3-642-32512-0_50
   Jakob W, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618510
   JOHNSON ME, 1990, J STAT PLAN INFER, V26, P131, DOI 10.1016/0378-3758(90)90122-B
   Ju E, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516976
   Kong W., 1998, J I IMAGE INFORM TEL, V52, P1351
   Luo LJ, 2013, PROC CVPR IEEE, P265, DOI 10.1109/CVPR.2013.41
   Luo LJ, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462026
   Luo LJ, 2012, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2012.6247838
   MORRIS MD, 1995, J STAT PLAN INFER, V43, P381, DOI 10.1016/0378-3758(94)00035-T
   Paris S, 2004, ACM T GRAPHIC, V23, P712, DOI 10.1145/1015706.1015784
   Paris S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360629
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Shtof A, 2013, COMPUT GRAPH FORUM, V32, P245, DOI 10.1111/cgf.12044
   Taheri M, 2016, VEHICLE SYST DYN, V54, P653, DOI 10.1080/00423114.2016.1150497
   Wang LD, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531362
   Wei YC, 2005, ACM T GRAPHIC, V24, P816, DOI 10.1145/1073204.1073267
   Wither J, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P33, DOI 10.1109/SMI.2007.31
   Xu K., 2013, ACM Trans. Graph., V32, P1
   Zhang M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073627
   Zhang WS, 2015, IEEE INT CONF INF VI, P411, DOI 10.1109/iV.2015.75
   Zou CQ, 2015, COMPUT GRAPH-UK, V46, P130, DOI 10.1016/j.cag.2014.09.031
NR 36
TC 0
Z9 0
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2128
EA NOV 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000888382400001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Liu, JY
   Deng, ZG
   Mao, TL
   Wang, ZQ
AF Liu, Jingyao
   Deng, Zhigang
   Mao, Tianlu
   Wang, Zhaoqi
TI R-CTM: A data-driven macroscopic simulation model for heterogeneous
   traffic
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cell transmission models; heterogeneous traffic flow; macroscopic
   traffic modeling; recurrent neural networks
ID CELL TRANSMISSION MODEL; FLOW; WAVES
AB There is a well-known trade-off between computational efficiency and computational accuracy in the field of traffic simulation. In this article, we propose a novel recurrent neural network based model with an integrated attention mechanism, called R-CTM, to simulate heterogeneous traffic flow with multiple types of vehicles. It can effectively extract the traffic flow patterns of spatial and temporal changes from training traffic data, which can be real-world traffic data or synthetic traffic data via microscopic simulation models. Through experiments and comparisons, we show that it can significantly outperform the state of the art methods in terms of simulation accuracy. Besides accuracy, we also demonstrate its scalability: its runtime consumption does not linearly increase with respect to the spatial extent.
C1 [Liu, Jingyao; Mao, Tianlu; Wang, Zhaoqi] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   University of Houston System; University of Houston
RP Mao, TL (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing, Peoples R China.
EM ltm@ict.ac.cn
OI Liu, Jingyao/0000-0002-9033-7066; Deng, Zhigang/0000-0003-2571-5865;
   Deng, Zhigang/0000-0002-0452-8676
FU National Key Research and Development Program of China [2017YFC0804900];
   National Natural Science Foundation of China [61532002]
FX National Key Research and Development Program of China, Grant/Award
   Number: 2017YFC0804900; National Natural Science Foundation of China,
   Grant/Award Number: 61532002
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Boden Mikael, 2002, the Dallas project
   Chao QW, 2020, COMPUT GRAPH FORUM, V39, P287, DOI 10.1111/cgf.13803
   Chao QW, 2018, IEEE T VIS COMPUT GR, V24, P1167, DOI 10.1109/TVCG.2017.2648790
   DAGANZO CF, 1994, TRANSPORT RES B-METH, V28, P269, DOI 10.1016/0191-2615(94)90002-7
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kingma D. P., 2014, arXiv
   LIGHTHILL MJ, 1955, PROC R SOC LON SER-A, V229, P317, DOI 10.1098/rspa.1955.0089
   Liu HY, 2015, IEEE T INTELL TRANSP, V16, P2620, DOI 10.1109/TITS.2015.2413995
   Mesa-Arango R, 2014, J INTELL TRANSPORT S, V18, P327, DOI 10.1080/15472450.2013.806846
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Ngoduy D, 2007, PHYSICA A, V385, P667, DOI 10.1016/j.physa.2007.07.041
   Ngoduy D, 2011, TRANSPORTMETRICA, V7, P111, DOI 10.1080/18128600903251334
   Qian Z, 2017, TRANSPORT RES B-METH, V99, P183, DOI 10.1016/j.trb.2017.01.011
   RICHARDS PI, 1956, OPER RES, V4, P42, DOI 10.1287/opre.4.1.42
   Sewall J, 2011, IEEE T VIS COMPUT GR, V17, P26, DOI 10.1109/TVCG.2010.27
   Szeto WY, 2011, COMPUT-AIDED CIV INF, V26, P595, DOI 10.1111/j.1467-8667.2011.00717.x
   Tiaprasert K, 2017, TRANSPORT RES C-EMER, V85, P86, DOI 10.1016/j.trc.2017.09.008
   Tuerprasert K, 2010, J INTELL TRANSPORT S, V14, P68, DOI 10.1080/15472451003719715
   van Lint JWC, 2008, TRANSPORT RES REC, P177, DOI 10.3141/2088-19
   Wang SZ, 2022, IEEE T KNOWL DATA EN, V34, P3681, DOI 10.1109/TKDE.2020.3025580
   Wong GCK, 2002, TRANSPORT RES A-POL, V36, P827, DOI 10.1016/S0965-8564(01)00042-8
NR 25
TC 0
Z9 0
U1 3
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2091
DI 10.1002/cav.2091
EA JUN 2022
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000807224500001
DA 2024-07-18
ER

PT J
AU Chen, LY
   Chen, ZW
   Lin, LH
   Ye, Q
   Guo, SH
   Lin, JC
AF Chen, Liyan
   Chen, Zhangwu
   Lin, Lianhui
   Ye, Qi
   Guo, Shihui
   Lin, Juncong
TI Augmenting deep land use prediction with randomized simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 35th International Conference on Computer Animation and Social Agents
   (CASA)
CY JUL 05-07, 2022
CL Nanjing, PEOPLES R CHINA
SP Nanjing Univ
DE agent based method; deep learning; land use prediction; randomized
   simulation
ID COVER
AB Land use information is the basis of various geo-spatial applications. Traditionally, land use patterns are predicted with agent-based simulation, suffering from a long convergence process. Deep learning techniques have recently been used for land use classification but not prediction, due to the lack and difficulty of collecting enough training data. This paper proposes a novel paradigm for land use data generation with a randomized simulation strategy. We also design a tailored deep land use prediction model, LUPnet, to demonstrate the usage of the paradigm. Experimental results reveal the effectiveness of our method.
C1 [Chen, Liyan; Chen, Zhangwu; Lin, Lianhui; Guo, Shihui; Lin, Juncong] Xiamen Univ Xiamen, Xiamen, Fujian, Peoples R China.
   [Ye, Qi] Informat Ctr Ningbo Human Resources & Social Secu, Ningbo, Zhejiang, Peoples R China.
RP Ye, Q (corresponding author), Informat Ctr Ningbo Human Resources & Social Secu, Ningbo, Zhejiang, Peoples R China.
EM 18957875526@163.com
FU National Natural Science Foundation of China [62077039, 62072383,
   PZ2020016]; Fujian Province Social Science Planning General Project
   [FJ2020B062]
FX This work is supported by National Natural Science Foundation of China
   (62077039, 62072383), Research Project (PZ2020016), and Fujian Province
   Social Science Planning General Project (FJ2020B062).
CR Albert A, 2018, INT GEOSCI REMOTE SE, P2095, DOI 10.1109/IGARSS.2018.8518032
   [Anonymous], 2015, DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving
   Bettum J, 2000, ARCH, V70, P36
   Brail R.K., 2001, PLANNING SUPPORT SYS
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Feng T, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925894
   Golovinskiy A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409098
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Joon-Seok Kim, 2018, SIGSPATIAL Special, V10, P34, DOI 10.1145/3292390.3292397
   Kang Y, 2019, IEEE T INTELL VEHICL, V4, P171, DOI 10.1109/TIV.2018.2886678
   Lechner T., 2006, ACM SIGGRAPH 2006 Research posters on-SIGGRAPH'06, p, P135, DOI DOI 10.1145/1179622
   Pomerleau DA., 1989, ADV NEURAL INFORM PR, V1, P305
   Rakhlin A, 2018, IEEE COMPUT SOC CONF, P257, DOI 10.1109/CVPRW.2018.00048
   Rogan J, 2004, PROG PLANN, V61, P301, DOI 10.1016/S0305-9006(03)00066-7
   Shah S, 2018, FIELD SERVICE ROBOTI, P621, DOI [10.1007/978-3-319-67361-5_40, DOI 10.1007/978-3-319-67361-5_40]
   Song A., 2019, P 14 INT C FDN DIGIT, P1
   Torrens P.M., 2002, Agent-Based Models of Land-Use/Land-Cover Change, P69
   Umetani N, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201325
   Wei LY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778816
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
NR 20
TC 1
Z9 1
U1 3
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2071
DI 10.1002/cav.2071
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 2S4AL
UT WOS:000821735900011
DA 2024-07-18
ER

PT J
AU Shen, Y
   Wang, XY
   Chen, ZM
   Sun, Q
   Zhang, X
   Liang, H
   Pan, JJ
AF Shen, Yang
   Wang, Xinyu
   Chen, Zhangmeng
   Sun, Qi
   Zhang, Xu
   Liang, Hui
   Pan, Junjun
TI Intelligent recognition of portrait sketch components for child autism
   assessment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE autism; deep learning; draw-a-man; sketch segmentation
AB For autistic children with slow language function, it is a classic and easy way to understand the development of their cognitive ability through simple painting experiments. Due to the lack of professional evaluators for painting assessment of autistic children, this article research and implement an intelligent assessment system for child autism through recognition of portrait sketch components. A portrait sketch database is constructed with the sample size of 30,400 after data expansion. The data consists of two formats: stroke vector sequence and 2D image. Then we propose a joint model coupled with LSTM and CNN features to automatically segment the portrait sketch components. It can perform better segmentation for exaggerated proportion and incomplete components samples. Finally, according to the evaluation criteria of the painting, we design an assessment model for child autism. The experiments are conducted in cooperation with relevant rehabilitation institutions to verify the effectiveness of the system. The analysis results show that our painting assessment system has a good ability to identify autistic tendencies. It can accurately evaluate children's autistic tendencies through "draw-a-man" experiments.
C1 [Shen, Yang; Zhang, Xu] Beijing Normal Univ, Collaborat Innovat Ctr Assessment Basic Educ Qual, Beijing, Peoples R China.
   [Wang, Xinyu; Chen, Zhangmeng; Sun, Qi; Pan, Junjun] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Chen, Zhangmeng; Pan, Junjun] Peng Cheng Lab, Shenzhen, Peoples R China.
   [Liang, Hui] Zhengzhou Univ Light Ind, Zhengzhou, Peoples R China.
C3 Beijing Normal University; Beihang University; Peng Cheng Laboratory;
   Zhengzhou University of Light Industry
RP Pan, JJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM pan_junjun@buaa.cdu.cn
RI Wang, Xinyu/IQU-9172-2023; Pan, Junjun/A-1316-2013
OI Wang, Xinyu/0000-0002-3568-2211; , Junjun/0000-0002-7991-9540
FU Fundamental Research Funds for the Central Universities [310422116];
   Beijing Normal University; National Natural Science Foundation of China
   [61872020, 62172437, 61977063, U20A20195]
FX Fundamental Research Funds for the Central Universities, Grant/Award
   Number: 310422116; Beijing Normal University; National Natural Science
   Foundation of China, Grant/Award Numbers: 61872020, 62172437, 61977063,
   U20A20195
CR Dickstein-Fischer L, 2014, IEEE ENG MED BIO, P792, DOI 10.1109/EMBC.2014.6943710
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Golomb C., 1992, The child's creation of a pictorial world
   Goodenough F., 1926, MEASUREMENT INTELLIG
   Grynszpan O, 2014, AUTISM, V18, P346, DOI 10.1177/1362361313476767
   Harris D.B., 1963, Goodenough-Harris drawing test: Manual
   Leel A, 2006, BRIT J DEV PSYCHOL, V24, P547, DOI 10.1348/026151005X49881
   LEWIS V, 1991, BRIT J DEV PSYCHOL, V9, P393, DOI 10.1111/j.2044-835X.1991.tb00885.x
   Li K, 2019, IEEE T IMAGE PROCESS, V28, P3219, DOI 10.1109/TIP.2019.2895155
   Li L, 2019, IEEE COMPUT GRAPH, V39, P38, DOI 10.1109/MCG.2018.2884192
   Lu X., 2017, CHINA SPEC ED, V71, P53
   Quickdraw, About us
   Schneider RG, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2898351
   Seddati O, 2016, INT WORK CONTENT MUL
   Seddati O, 2015, INT WORK CONTENT MUL
   Wu Xingyuan., 2019, RES SKETCH SEGMENTAT
NR 16
TC 2
Z9 2
U1 2
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2059
DI 10.1002/cav.2059
EA JUN 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000804184200001
DA 2024-07-18
ER

PT J
AU Shang, C
   Zhao, HK
   Wang, ML
   Wang, XL
   Jiang, Y
   Gao, Q
AF Shang, Cheng
   Zhao, Hongke
   Wang, MeiLi
   Wang, XiaoLong
   Jiang, Yu
   Gao, Qiang
TI Individual identification of cashmere goats via method of fusion of
   multiple optimization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Cycle-GAN; identification; joint optimization; low-shot learning; smart
   agriculture
AB Facial recognition technology and related research have matured over time, but research in the field of individual animal recognition is still very limited. Therefore, this article focuses on the identification of cashmere goats with similar characteristics. First, the single shot multibox detector network was used to process the dataset. Next, transfer learning was applied to learn the characteristics of the goats, as well as the loss function is composed of Triplet Loss and Label Smoothing CrossEntropy Loss function. The result of Label Smoothing CrossEntropy Loss function is fused by multiple different branches, which is convenient for classification. We added a small number of images of 24 different breeds of sheep to each cashmere goat dataset with different ID to promote the distance between training individuals, and then used the trained model to find the number of goats with the lowest recognition accuracy. The Cycle-Consistent Adversarial Network (Cycle-GAN) learned the goat dataset with a high error rate in individual identification. Unlike previous studies using the Cycle-GAN, we took the novel approach of using this network to learn and combine the features seen in photos of cashmere goats. Since the learned features were all observed in the same goats, this method achieved better results in learning the features of the goats. Finally, we found that recognition can be performed on this data with an accuracy of 93.75%. These results suggest that identification based on deep learning has a high accuracy rate, as well as great value in identifying individual cashmere goats.
C1 [Shang, Cheng; Zhao, Hongke; Wang, MeiLi] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Wang, MeiLi] Minist Agr, Key Lab Agr Internet Things, Yangling, Shaanxi, Peoples R China.
   [Wang, MeiLi] Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling, Shaanxi, Peoples R China.
   [Wang, XiaoLong; Jiang, Yu] Northwest A&F Univ, Coll Anim Sci & Technol, Yangling, Shaanxi, Peoples R China.
   [Gao, Qiang] Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China; Ministry of Agriculture & Rural
   Affairs; Northwest A&F University - China; Northwest A&F University -
   China
RP Wang, ML (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.; Gao, Q (corresponding author), Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
EM wml@nwsuaf.edu.cn; hillfinder@nwafu.edu.cn
RI Jiang, Yu/O-5114-2015
OI Zhao, Hongke/0000-0002-9174-3189
FU Shaanxi Province Key RD Program [2022QFY11-03]; Shaanxi Agricultural
   Science and Technology Innovation Drive Project [2018AIOT-09]; Key
   Laboratory of the Agricultural Internet of Things, Ministry of
   Agriculture and Rural Affairs, Yangling, Shaanxi, China [2018AIOT-09]
FX Shaanxi Province Key R&D Program, Grant/Award Number: 2022QFY11-03;
   Shaanxi Agricultural Science and Technology Innovation Drive Project,
   Grant/Award Number: 2018AIOT-09; the Key Laboratory of the Agricultural
   Internet of Things, Ministry of Agriculture and Rural Affairs, Yangling,
   Shaanxi 712100, China, Grant/Award Number: 2018AIOT-09
CR [Anonymous], 2021, FACE RECOGNITION CNN
   Brock AM, 2018, PROCEEDINGS PERVASIVE DISPLAYS 2018: THE 7TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, DOI 10.1145/3205873.3205877
   Fang C, 2021, COMPUT ELECTRON AGR, V180, DOI 10.1016/j.compag.2020.105863
   Fu LS, 2021, PRECIS AGRIC, V22, P754, DOI 10.1007/s11119-020-09754-y
   Gan HM, 2021, COMPUT ELECTRON AGR, V189, DOI 10.1016/j.compag.2021.106384
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   [何东健 He Dongjian], 2020, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V51, P250
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hong WX, 2018, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2018.00145
   Huang JD, 2021, COMPUT ELECTRON AGR, V180, DOI 10.1016/j.compag.2020.105884
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Ketprom U., 2011, 2011 Annual SRII Global Conference (SRII), P517, DOI 10.1109/SRII.2011.107
   Ketprom U, 2007, PORTL INT CONF MANAG, P1748, DOI 10.1109/PICMET.2007.4349500
   Li XY, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104885
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Ng ML, 2005, IEEE 2005 International Symposium on Microwave, Antenna, Propagation and EMC Technologies for Wireless Communications Proceedings, Vols 1 and 2, P67
   Peng YQ, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105178
   Qiao YL, 2020, IEEE INT CON AUTO SC, P967, DOI [10.1109/case48305.2020.9217026, 10.1109/CASE48305.2020.9217026]
   Qiao YL, 2019, IFAC PAPERSONLINE, V52, P318, DOI 10.1016/j.ifacol.2019.12.558
   Qin X., 2019, J. Hangzhou Dianzi Univ., V39, P12
   Radford A., 2015, ARXIV
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang JL, 2019, NEUROCOMPUTING, V332, P270, DOI 10.1016/j.neucom.2018.12.052
   Taylor L, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1542, DOI 10.1109/SSCI.2018.8628742
   Thi Thi Zin, 2018, International MultiConference of Engineers and Computer Scientists 2018. Proceedings, P320
   Wang D, 2018, COMPUT ELECTRON AGR, V154, P443, DOI 10.1016/j.compag.2018.09.030
   Zaiqiong Wang, 2010, 2010 International Conference on Computer Application and System Modeling (ICCASM 2010), P567, DOI 10.1109/ICCASM.2010.5620675
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 31
TC 1
Z9 1
U1 2
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2023
VL 34
IS 2
AR e2048
DI 10.1002/cav.2048
EA MAY 2022
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D7UU4
UT WOS:000789170400001
DA 2024-07-18
ER

PT J
AU Sun, C
   Ramachandran, S
   Paquette, E
   Lee, WS
AF Sun, Chao
   Ramachandran, Srinivasan
   Paquette, Eric
   Lee, Won-Sook
TI Single-view procedural braided hair modeling through braid unit
   identification
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE braid unit segmentation; procedural hair modeling
ID SIMULATION; CAPTURE
AB We propose the first approach that can generate procedural three-dimensional (3D) hair involving braids modeled from a single-view photograph. Existing single-view image-based hair modeling methods fail to handle braided hairstyles. Our approach combines image processing, deep neural networks, as well as two-dimensional (2D) and 3D geometric algorithms. In order to train our neural network, we create a braid unit data set. Our recognition and segmentation system can successfully segment hair regions, braid and non-braid regions, using convolutional neural networks. We further process the images to obtain the locations, sizes, and orientations of the braid units. Given these braid units, we perform braid structure analysis to obtain the braid strand curves. The procedural modeling of the 3D braids is represented using 3D helical curves where the parameters are extracted from the 2D image analysis. Furthermore, we extract 2D hair strands from the non-braid region using the Gabor filter and orientation maps. Then, a 3D hair volume is generated with the hair region silhouette information. We project the 2D hair strands and braids on the 3D hair volume to obtain the 3D hair strands and 3D braids. The strands for the braid and non-braid regions are used as guides to generate dense hair strands. Dense strands are emitted from the hair root triangle mesh and follow the guide strands. With a sparse set of landmarks, the hair region of the photograph is texture mapped to the 3D hair root mesh and used to color the strands. We successfully tested our approach on photographs showing variations of braid styles and hair color.
C1 [Sun, Chao; Lee, Won-Sook] Univ Ottawa, Sch Elect Engn & Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
   [Ramachandran, Srinivasan; Paquette, Eric] Ecole Technol Super, Informat Technol, Montreal, PQ, Canada.
C3 University of Ottawa; University of Quebec; Ecole de Technologie
   Superieure - Canada
RP Sun, C (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
EM csun014@uottawa.ca
OI Ramachandran, Srinivasan/0000-0002-0632-8862; Paquette,
   Eric/0000-0001-9236-647X
CR Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Chai ML, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818112
   Chai ML, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461990
   Chai ML, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185612
   Dutta A., 2016, VGG image annotator (VIA)
   Dutta A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2276, DOI 10.1145/3343031.3350535
   Ghafourzadeh D., 2020, Proceedings of Graphics Interface 2020, P7
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Hu LW, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3130800.3130887, 10.1145/3130800.31310887]
   Hu LW, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661254
   Hu LW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766931
   Hu LW, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601194
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Jung S, 2018, COMPUT GRAPH FORUM, V37, P355, DOI 10.1111/cgf.13367
   Kingma D. P., 2013, ARXIV13126114
   Lee WS., 2015, P 10 INT C COMP GRAP
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Luo LJ, 2012, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2012.6247838
   Paris S, 2004, ACM T GRAPHIC, V23, P712, DOI 10.1145/1015706.1015784
   Saito S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275019
   Shum HY., 2005, P ACM T GRAPH SIGGRA
   Sun C, 2017, IEEE SYS MAN CYBERN, P1840, DOI 10.1109/SMC.2017.8122884
   Ward K, 2007, IEEE T VIS COMPUT GR, V13, P213, DOI 10.1109/TVCG.2007.30
   Zhang M, 2019, VIS INFORM, V3, P102, DOI 10.1016/j.visinf.2019.06.001
   Zhou Y, 2018, LECT NOTES COMPUT SC, V11215, P249, DOI 10.1007/978-3-030-01252-6_15
NR 28
TC 2
Z9 2
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2007
DI 10.1002/cav.2007
EA MAY 2021
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000653496300001
DA 2024-07-18
ER

PT J
AU Liu, SG
   Gao, S
   Xu, SQ
AF Liu, Shiguang
   Gao, Si
   Xu, Siqi
TI Animating explosion with exploding sound and rigid-body sound
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; explosion; sound synthesis; virtual reality
ID FREQUENCY
AB Visual simulation of explosion animation can be found many applications in virtual reality. In addition to visual simulation, sound synthesis of explosion scenes is also indispensable. However, little attention has been paid to this research area. To this end, this paper proposes an automatic sound synthesis method for explosion scenes. Explosion animation consists of two major events, namely explosive event and interactive rigid-body fracture event. Correspondingly, the sound for an explosion scene can be viewed as the combination of two components, that is, the exploding sound and the rigid-body sound. Among them, the exploding sound often shows similarity in terms of characteristics in frequency domain, while the rigid-body sound is rich in variations due to the unpredictable motion state and different materials of debris. As a result, for the synthesis of the rigid-body sound, firstly, we extract the rigid-body sounds from recording examples by the empirical mode decomposition method. On this basis, a new spectral flux based approach is developed to segment the extracted sounds into a grain dictionary. Then, a cascade sound synthesis method based on impulse response is designed to synchronize the rigid-body sound for fracture events. For the synthesis of exploding sound, due to its similar characteristics in frequency domain, an example-based automatic sound synthesis method is adapted in this paper. Finally, we propose a priority-aware sound blending method to merge these two types of completely different sounds reasonably. Various experimental results demonstrated the effectiveness of our new method.
C1 [Liu, Shiguang; Gao, Si; Xu, Siqi] Tianjin Univ, Sch Comp Sci & Technol, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
   [Liu, Shiguang] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn
CR An SS, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185598
   Avanzini F., 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P445, DOI 10.1109/ICME.2002.1035636
   Bonneel N, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360623
   Cardle M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P349
   Chadwick JN, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185599
   Chadwick JN, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964979
   Chadwick Jeffrey N., 2012, ACM EUROGRAPHICS S C, P265, DOI [10.2312/SCA/SCA12/265-274, DOI 10.2312/SCA/SCA12/265-274]
   Di Scipio A., 1999, P 2 COST G 6 WORKSHO, P109
   Dobashi Y, 2004, COMPUT GRAPH FORUM, V23, P539, DOI 10.1111/j.1467-8659.2004.00785.x
   Doel KVD, 1996, P INT C AUD DISPL 19, P1
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Hahn JK, 2014, PRESENCE, V7, P67
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Liu SG, 2015, VIRTUAL REAL-LONDON, V19, P291, DOI 10.1007/s10055-015-0271-7
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Norton A., 1991, Visual Computer, V7, P210, DOI 10.1007/BF01900837
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   Parker E.G., 2009, PROC S COMP ANIM, P165, DOI DOI 10.1145/1599470.1599492.
   Picard C, 2009, P AES 35 INT C AUD G, P18
   Raghavachary S., 2002, ACM SIGGRAPH 2002 C, P187
   Raghuvanshi N, 2006, P 2006 S INT 3D GRAP, P101, DOI DOI 10.1145/1111411.1111429
   Ren ZM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421637
   Ren ZM, 2010, P IEEE VIRT REAL ANN, P139, DOI 10.1109/VR.2010.5444799
   Roads C., 2004, Microsound
   Schreck C., 2016, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'16, P211
   Schwarz D., 2015, SOUND MUSIC COMPUTIN, P471
   Schwarz D. S., 2010, P INT C SOUND MUS CO, P510
   Schwarz Diemo, 2013, P SOUND MUS MOT 10 I, P372
   Serra X, 1997, LISSE NETHERLANDS SW, P91
   Stam J, 2000, COMMUN ACM, V43, P76, DOI 10.1145/341852.341866
   Stoimenov BL, 2007, TRIBOL INT, V40, P659, DOI 10.1016/j.triboint.2005.11.010
   Strobl G, 2016, P 2006 SOUND MUS COM, P1
   TERZOPOULOS D., 1988, SIGGRAPH COMPUT GRAP, V22, P269
   Tow WT, 2012, CRIT STUD ASIA PAC S, P1
   Wang K, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1835
   WARREN WH, 1984, J EXP PSYCHOL HUMAN, V10, P704, DOI 10.1037/0096-1523.10.5.704
   Yin Q, 2018, IEEE T VIS COMPUT GR, V24, P1179, DOI 10.1109/TVCG.2016.2642958
   Yngve GD, 2000, COMP GRAPH, P29, DOI 10.1145/344779.344801
   Zheng CX, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778806
NR 40
TC 1
Z9 1
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2021
VL 32
IS 1
AR e1970
DI 10.1002/cav.1970
EA SEP 2020
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QP5QT
UT WOS:000573507200001
DA 2024-07-18
ER

PT J
AU Li, MY
   Jiang, XH
   Gu, NB
   Xu, WW
   Xue, JX
   Zhou, B
   Xu, ML
AF Li, Mingyuan
   Jiang, Xiaoheng
   Gu, Ningbo
   Xu, Weiwei
   Xue, Junxiao
   Zhou, Bing
   Xu, Mingliang
TI Disassembling a 3D mechanism for efficient packing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE disassembly; mechanism; pack
AB This paper introduces a disassemble-and-pack algorithm to disassemble a mechanical 3D model in groups that can be efficiently packed within a box, with the objective of reassembling them easily after delivery. Its key feature is that, mostly, the mechanism can be disassembled at the joint and each part can be an adjusted motion structure based on its joint type. Our system consists of two steps: disassembling the mechanical object into a group set and packing them within a box efficiently. The first step consists in the creation of a hierarchy of possible group set of parts that can be tightly packed within their minimum bounding boxes. Use the breadth-first search algorithm to traverse the hierarchy of possible group set in order to disconnect the joints and get the group set. In the second step, according to the reverse order of volume, each group in the set is inserted into the specified box. The fact that mechanism disassembly and shape packing are both an NP-complete problem justifies finding approximated solutions according to efficacy and efficiency. Experimental results show that our approach can really efficiently pack a range of mechanisms from a simple model to complex objects.
C1 [Li, Mingyuan; Jiang, Xiaoheng; Gu, Ningbo; Xue, Junxiao; Zhou, Bing; Xu, Mingliang] Zhengzhou Univ, Sch Informat Engn, 100 Sci Ave, Zhengzhou 450001, Henan, Peoples R China.
   [Xu, Weiwei] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
C3 Zhengzhou University; Zhejiang University
RP Xu, ML (corresponding author), Zhengzhou Univ, Sch Informat Engn, 100 Sci Ave, Zhengzhou 450001, Henan, Peoples R China.
EM iexumingliang@zzu.edu.cn
RI Xue, Junxiao/H-7385-2015
OI Xue, Junxiao/0000-0003-1569-5362
FU National Science Foundation of China [61672469, 61472370, 61822701,
   61732016]; Science & Technology Innovation Talents in Universities of
   Henan Province [18HASTIT020]; Young Scholar in Universities of Henan
   Province [2016GGJS-001]; National Key Technology Research and
   Development Program of China [2017YFC0804401]; Alibaba IDEA Lab and
   fundamental research fund for the central universities [2017YFB1002600]
FX National Science Foundation of China, Grant/Award Number: 61672469,
   61472370, 61822701, and 61732016; Science & Technology Innovation
   Talents in Universities of Henan Province, Grant/Award Number:
   18HASTIT020; Young Scholar in Universities of Henan Province,
   Grant/Award Number: 2016GGJS-001; National Key Technology Research and
   Development Program of China, Grant/Award Number: 2017YFC0804401;
   Alibaba IDEA Lab and fundamental research fund for the central
   universities, Grant/Award Number: 2017YFB1002600
CR [Anonymous], COMBINATORIAL ALGOR
   [Anonymous], 2000, THESIS
   Attene M, 2015, COMPUT GRAPH FORUM, V34, P64, DOI 10.1111/cgf.12608
   Attene M, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2431211.2431214
   Bansal N, 2013, SIAM J COMPUT, V42, P579, DOI 10.1137/070691607
   Chen XL, 2015, J EXP CLIN CANC RES, V34, DOI 10.1186/s13046-014-0117-2
   Chernov N, 2010, COMP GEOM-THEOR APPL, V43, P535, DOI 10.1016/j.comgeo.2009.12.003
   Coros S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461953
   Dong TY, 2006, INT J ADV MANUF TECH, V30, P507, DOI 10.1007/s00170-005-0036-7
   Ericson C., 2004, REAL TIME COLLISION
   Jiménez P, 2001, COMPUT GRAPH-UK, V25, P269, DOI 10.1016/S0097-8493(00)00130-8
   Johnson D.S, 1973, P 5 ACM STOC, P38, DOI DOI 10.1145/800125.804034
   Li M, EFFICIENTLY DISASSEM
   MARSAGLIA G, 1972, ANN MATH STAT, V43, P645, DOI 10.1214/aoms/1177692644
   Mitra NJ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778795
   OROURKE J, 1985, INT J COMPUT INF SCI, V14, P183, DOI 10.1007/BF00991005
   Sander PV, 2003, P 2003 EUR ACM SIGGR
   XU M, 2016, ARTICLE, V35, DOI DOI 10.1145/2980179.2982425
   Xu ML, 2017, J COMPUT SCI TECH-CH, V32, P1162, DOI 10.1007/s11390-017-1791-2
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, NEUROCOMPUTING, V195, P117, DOI 10.1016/j.neucom.2015.08.117
   XU W, 2009, ARTICLE, V28, DOI DOI 10.1145/1531326.1531341
   ZHU L, 2012, ARTICLE, V31, DOI DOI 10.1145/2366145.2366146
NR 23
TC 0
Z9 0
U1 1
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2019
VL 30
IS 2
AR e1861
DI 10.1002/cav.1861
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR7XB
UT WOS:000463367400006
DA 2024-07-18
ER

PT J
AU Çevikbas, SB
   Isler, V
AF Cevikbas, Safak Burak
   Isler, Veysi
TI Phaneros: Visibility-based framework for massive peer-to-peer virtual
   environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE content streaming; distributed virtual environments; peer to peer;
   potentially visible sets; update dissemination; visibility; 3D streaming
ID MANAGEMENT
AB Contemporary distributed virtual environments are growing out of terabytes of 3D content and hundreds of thousands of users. Server-client architectures have become inadequate for fulfilling the scalability requirements. The peer-to-peer architectures provide inherently scalable, cost-effective distributed solutions for distributed virtual environments. We present a fully distributed peer-to-peer framework, Phaneros, which is capable of providing necessary means to realize more efficient and more scalable massive distributed virtual environments. Using the presented visibility-aware interest management, Phaneros performs better than existing overlays, achieving single-hop update dissemination while having lower bandwidth requirements. The provided visibility-aware 3D streaming scheme distributes 3D content more efficiently without creating any significant load on the server. Our test results show significant improvements over existing frameworks.
C1 [Cevikbas, Safak Burak; Isler, Veysi] Middle East Tech Univ, Dept Comp Engn, Ankara, Turkey.
   [Isler, Veysi] Hasan Kalyoncu Univ, Dept Comp Engn, Gaziantep, Turkey.
C3 Middle East Technical University; Hasan Kalyoncu University
RP Isler, V (corresponding author), Middle East Tech Univ, Dept Comp Engn, Ankara, Turkey.
EM isler@ceng.metu.edu.tr
RI Isler, Veysi/A-6801-2016
OI Isler, Veysi/0000-0003-0174-7600
CR Albano M., 2009, ICUMT, P1
   Almashor M, 2013, IEEE J SEL AREA COMM, V31, P310, DOI 10.1109/JSAC.2013.SUP.0513028
   [Anonymous], P 2012 21 INT C COMP
   Cevikba SB, 2018, PHANEROS DEMO
   Cohen-Or D, 2003, IEEE T VIS COMPUT GR, V9, P412, DOI 10.1109/TVCG.2003.1207447
   Ghaffari M, 2015, IEEE T EMERG TOP COM, V3, P289, DOI 10.1109/TETC.2014.2330520
   Gilmore JS, 2012, IEEE T PARALL DISTR, V23, P818, DOI 10.1109/TPDS.2011.210
   Han S, 2008, COMPUT ANIMAT VIRT W, V19, P129, DOI 10.1002/cav.218
   Hu SY, 2008, IEEE INFOCOM SER, P2047
   Hu SY, 2006, IEEE NETWORK, V20, P22, DOI 10.1109/MNET.2006.1668400
   Hu SY, 2010, IEEE INTERNET COMPUT, V14, P54, DOI 10.1109/MIC.2009.98
   Knutsson B, 2004, IEEE INFOCOM SER, P96
   Ng B., 2002, VRST 02, P163
   Ricci L., 2012, 2012 International Conference on High Performance Computing & Simulation (HPCS 2012), P8, DOI 10.1109/HPCSim.2012.6266885
   Rowstron A., 2001, Networked Group Communication. Third International COST264 Workshop, NGC 2001. Proceedings (Lecture Notes in Computer Science Vol.2233), P30
   Rowstron A., 2001, Proceedings of the Middleware 2001, P329, DOI DOI 10.1007/3-540-45518-3_18
   Rueda S, 2008, COMPUT ANIMAT VIRT W, V19, P537, DOI 10.1002/cav.230
   Steed A, 2006, PRESENCE-VIRTUAL AUG, V15, P77, DOI 10.1162/pres.2006.15.1.77
   Stoica I, 2001, ACM SIGCOMM COMP COM, V31, P149, DOI 10.1145/964723.383071
   Teler E, 2001, COMPUT GRAPH FORUM, V20, pC17, DOI 10.1111/1467-8659.00494
NR 20
TC 2
Z9 2
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2019
VL 30
IS 1
AR e1808
DI 10.1002/cav.1808
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8YF
UT WOS:000458275000002
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Im, J
   Kim, JH
   Kim, W
   Park, N
   Kim, T
   Kim, YB
   Lee, J
   Kim, CH
AF Im, Jaeho
   Kim, Jong-Hyun
   Kim, Wook
   Park, Nuri
   Kim, Taehyeong
   Kim, Young Bin
   Lee, Jung
   Kim, Chang-Hun
TI Visual simulation of rapidly freezing water based on crystallization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE ice formation; nucleation energy; rapidly freezing animation
AB We propose a physics-inspired simulation framework that expresses visual effects of flowing water frozen in glaze or directional icicles. The proposed ice model considers the direction of the water flow, which affects the growth of icicles. Water dynamics are computed using a conventional particle-based simulation. Ice glaze and directional icicles are generated by incorporating our freezing solver. To determine whether a water particle is converted into ice or remains liquid, we compute the nucleation energy based on the humidity and water flow. The humidity is approximated as a virtual water film on object surfaces. The water flow is incorporated by introducing a growth direction vector to guide the direction of icicle growth. Ice-generating regions can be controlled using 3-D modeling tools such as Autodesk Maya or 3DS Max. Experiments showed that a realistic ice glaze was created on the surfaces of objects and that icicles grew in the direction of the water flow.
C1 [Im, Jaeho; Kim, Wook; Kim, Chang-Hun] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Park, Nuri; Kim, Taehyeong] Korea Univ, Dept Visual Informat Proc, Seoul, South Korea.
   [Kim, Young Bin] Korea Univ, Interdisciplinary Program Visual Informat Proc, Seoul, South Korea.
   [Kim, Jong-Hyun] Kangnam Univ, Dept Software Applicat, Yongin, Gyeonggi, South Korea.
   [Lee, Jung] Hallym Univ, Dept Convergence Software, Chunchon, Gangwon, South Korea.
C3 Korea University; Korea University; Korea University; Kangnam
   University; Hallym University
RP Kim, CH (corresponding author), Korea Univ, Seoul, South Korea.
EM chkim@korea.ac.kr
OI Kim, TaeHyeong/0000-0002-1862-9208
FU National Research Foundation of Korea (NRF); Ministry of Education,
   Science, ICT and Future Planning [NRF-2016M3C1B6929629,
   NRF-2016M3C1B6929579]; Institute for Information & Communications
   Technology Promotion (IITP) [R-20160404-003511]; Korea Small and Medium
   Business Administration [C0443008]
FX Basic Science Research Program through the National Research Foundation
   of Korea (NRF); Ministry of Education, Science, ICT and Future Planning,
   Grant/Award Number: NRF-2016M3C1B6929629, NRF-2016M3C1B6929579;
   Institute for Information & Communications Technology Promotion (IITP),
   Grant/Award Number: R-20160404-003511; Business for Cooperative R&D
   between Industry, Academy, and Research Institute funded Korea Small and
   Medium Business Administration, Grant/Award Number: C0443008
CR Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Akinci N, 2013, COMPUT ANIMAT VIRT W, V24, P195, DOI 10.1002/cav.1499
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Gagnon J, 2011, VISUAL COMPUT, V27, P451, DOI 10.1007/s00371-011-0584-9
   Im J, 2013, COMPUT GRAPH FORUM, V32, P371, DOI 10.1111/cgf.12057
   Ishikawa T, 2013, ACM SIGGRAPH 2013 PO, DOI 10.1145/2503385.2503400
   Iwasaki K, 2010, COMPUT GRAPH FORUM, V29, P2215, DOI 10.1111/j.1467-8659.2010.01810.x
   Kharitonsky D., 1993, Visual Computer, V10, P88, DOI 10.1007/BF01901945
   Kim JH, 2016, COMPUT ANIMAT VIRT W, V27, P271, DOI 10.1002/cav.1699
   KIM T, 2004, P 2004 ACM SIGGRAPH, P305, DOI DOI 10.1145/1028523.1028564
   Kim T., 2006, Proc 2006 ACM SIGGRAPH/Eurographics Symp Comp Anim, P167
   Lii SY, 2014, VISUAL COMPUT, V30, P531, DOI 10.1007/s00371-013-0878-1
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   MAENO N, 1994, J GLACIOL, V40, P319, DOI 10.3189/S0022143000007401
   Makkonen L, 2000, PHILOS T R SOC A, V358, P2913, DOI 10.1098/rsta.2000.0690
   MAKKONEN L, 1988, J GLACIOL, V34, P64, DOI 10.3189/S0022143000009072
   Miao YB, 2015, 14TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, VRCAI 2015, P17, DOI 10.1145/2817675.2817676
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Nishino T., 2012, SIGGRAPH ASIA 2012 T
   Van der Laan W.J., 2009, P 2009 S INT 3D GRAP, P91, DOI [DOI 10.1145/1507149.1507164, 10.1145/1507149.1507164]
   WICKE M., 2006, Proceedings of Eurographics Symposium on Point-Based Graphics 2006, P137
NR 22
TC 3
Z9 3
U1 2
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1767
DI 10.1002/cav.1767
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200013
DA 2024-07-18
ER

PT J
AU Lee, Y
   Lee, S
   Lee, SH
AF Lee, Youjin
   Lee, Sukwon
   Lee, Sung-Hee
TI Multifinger interaction between remote users in avatar-mediated
   telepresence
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE avatar; hand contact interaction; multifinger interaction; telepresence
AB In avatar-mediated telepresence, remote users find it difficult to engage and maintain contact, such as a handshake, with each other without a haptic device. We address the problem of adjusting an avatar's pose to promote multifinger contact interaction between remote users. To this end, we first construct a contact point database for nine types of contact interactions between hands through contact experiments with human subjects. We then develop an optimization-based framework to compute the avatar's pose that realizes the desired contact learned from the experiment while maintaining the naturalness of the hand pose. We show that our method improves the quality of hand interaction for the predefined set of social interactions.
C1 [Lee, Youjin; Lee, Sukwon; Lee, Sung-Hee] Korea Adv Inst Sci & Technol, Mot Comp Lab, 291 Daehak Ro, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, SH (corresponding author), Korea Adv Inst Sci & Technol, Mot Comp Lab, 291 Daehak Ro, Daejeon 34141, South Korea.
EM leesunghee@kaist.ac.kr
RI Lee, Sung-Hee/I-4721-2013
OI Lee, Sung-Hee/0000-0001-6604-4709
FU Global Frontier RD Program; NRF, MSIP [2015M3A6A3073743]; Sports
   Promotion Fund of Seoul Olympic Sports Promotion Foundation; MCST
FX Global Frontier R&D Program; NRF, MSIP, Grant/Award Number:
   2015M3A6A3073743; Sports Promotion Fund of Seoul Olympic Sports
   Promotion Foundation; MCST
CR Aleotti J, 2012, VIRTUAL REAL-LONDON, V16, P87, DOI 10.1007/s10055-010-0172-8
   [Anonymous], 2014, P SIGGRAPH AS 2014 A
   [Anonymous], 2005, ACM SIGGRAPH EUR S C, DOI DOI 10.1145/1073368.1073413
   ElKoura G., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P110
   Feix T, 2009, ROBOTICS SCI SYSTEMS, V2, P2
   Feix T, 2016, IEEE T HUM-MACH SYST, V46, P66, DOI 10.1109/THMS.2015.2470657
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Ho ESL, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487274
   Koga Y., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P395, DOI 10.1145/192161.192266
   Li Y, 2007, IEEE T VIS COMPUT GR, V13, P732, DOI [10.1109/TVCG.2007.1033, 10.1109/TVCG.2007.1033.]
   Microsoft Research, HOL
   Mordatch I., 2012, P ACM SIGGRAPH EUR S, P137
   Mordatch I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185539
   Oh J., 2016, P 29 INT C COMP AN S, P97
   Rezzonico S., 1995, CONSISTENT GRASPING, P107, DOI [10.1007/978-3-7091-9433-110, DOI 10.1007/978-3-7091-9433-110]
   Vafaei F, 2013, THESIS, P56
   Vogt D, 2014, LECT NOTES ARTIF INT, V8637, P463, DOI 10.1007/978-3-319-09767-1_57
   Ye Y, 2012, ACM T GRAPHIC, V31, P1
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
NR 19
TC 4
Z9 4
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1778
DI 10.1002/cav.1778
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200024
DA 2024-07-18
ER

PT J
AU Lu, DY
   Zhu, DM
   Wang, ZQ
   Gao, JZ
AF Lu, Daying
   Zhu, Dengming
   Wang, Zhaoqi
   Gao, Jinzhu
TI Efficient level of detail for texture-based flow visualization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE level of detail; texture-based visualization; noise optimization;
   efficient acceleration; smooth animation
ID VECTOR-FIELDS; ADVECTION
AB In this paper, we present an efficient level of detail algorithm for texture-based flow visualization. Our goal is to enhance visual perception and performance and generate smooth animation. To achieve our goal, we first model an adaptive input texture taking into account flow patterns to output view-dependent high-quality images. Then, we compute field lines only from sparse sampling points of the input noise texture for outputting volume line integral convolution textures and skip empty space utilizing two quantized binary histograms. To improve image quality, we implement anti-aliasing through adjusting the line integral convolution step size and thickness of trajectory lines with an opacity function. We further extend our solution to unsteady flow. Flow structures and evolution are clearly shown through smooth animation achieved with coherent evolution of particles, handling of discontinuous flow lines, and spatio-temporal linear constraint of the underlying noise volume. In the result section, we show high-quality level of detail of three-dimensional texture-based flow visualization with high performance. We also demonstrate that our algorithm can achieve smooth evolution for unsteady flow with spatio-temporal coherence. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Lu, Daying; Zhu, Dengming; Wang, Zhaoqi] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Lu, Daying] Chinese Acad Sci, Grad Univ, Beijing, Peoples R China.
   [Gao, Jinzhu] Univ Pacific, Sch Engn & Comp Sci, Stockton, CA 95211 USA.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; University of the Pacific
RP Lu, DY (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.; Lu, DY (corresponding author), Chinese Acad Sci, Grad Univ, Beijing, Peoples R China.
EM ludaying@ict.ac.cn
RI Gao, Jinzhu/B-4716-2011
FU National Natural Science Foundation of China [61173067, 61272322,
   61303157, 61379085]
FX The authors would like to thank the reviewers for their valuable
   comments. Thanks to Prof. Roger Crawfis from Ohio State University for
   kindly providing the tornado dataset, and thanks to Wang Z.F. from the
   Institute of Atmospheric Physics in the Chinese Academy of Sciences for
   providing the atmospheric pollution dataset in Pearl River Delta region.
   This work is supported and funded by the National Natural Science
   Foundation of China (No. 61173067, No. 61272322, No. 61303157, No.
   61379085).
CR Bordoloi U, 2002, COMPUT GRAPH FORUM, V21, P605, DOI 10.1111/1467-8659.t01-1-00711
   Burhenne S., 2011, P BUILDING SIMULATIO
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   COOK RL, 1986, ACM T GRAPHIC, V5, P51, DOI 10.1145/7529.8927
   CRAWFIS R., 1992, VVS 92 P 1992 WORKSH, P55
   Falk M, 2008, IEEE T VIS COMPUT GR, V14, P820, DOI 10.1109/TVCG.2008.25
   Fout N, 2012, IEEE T VIS COMPUT GR, V18, P2335, DOI 10.1109/TVCG.2012.227
   Helgeland A, 2004, IEEE T VIS COMPUT GR, V10, P673, DOI 10.1109/TVCG.2004.49
   Helgeland A, 2006, IEEE T VIS COMPUT GR, V12, P1535, DOI 10.1109/TVCG.2006.95
   Huang J, 2013, IEEE T VIS COMPUT GR, V19, P1476, DOI 10.1109/TVCG.2013.62
   Interrante V, 1997, IEEE T VIS COMPUT GR, V3, P98, DOI 10.1109/2945.597794
   Interrante V., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P109, DOI 10.1145/258734.258796
   Interrante V, 1998, IEEE COMPUT GRAPH, V18, P49, DOI 10.1109/38.689664
   Jobard B, 2002, IEEE T VIS COMPUT GR, V8, P211, DOI 10.1109/TVCG.2002.1021575
   Kaufman A., 2005, VISUALIZATION HDB, V2005, P127
   Li GS, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P241, DOI 10.1109/VISUAL.2003.1250378
   Li L, 2006, P SPIE EL IM VIS DAT, V6060, P24
   Liu Z., 2002, Proceedings of the Symposium on Data Visualisation 2002, P43
   Ma KL, 1997, P ACM SIGGRAPH 97 LO, P17
   Marchesin S, 2010, IEEE T VIS COMPUT GR, V16, P1578, DOI 10.1109/TVCG.2010.212
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Muller C., 2006, EG PGV 2006. 6th Eurographics Symposium on Parallel Graphics and Visualization, P59
   Rezk-Salama C., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P233, DOI 10.1109/VISUAL.1999.809892
   Shen HW, 1998, IEEE T VIS COMPUT GR, V4, P98, DOI 10.1109/2945.694952
   Shen HW, 2004, IEEE T VIS COMPUT GR, V10, P434, DOI 10.1109/TVCG.2004.13
   Shen HW, 1996, 1996 SYMPOSIUM ON VOLUME VISUALIZATION, PROCEEDINGS, P63, DOI 10.1109/SVV.1996.558044
   Shi L, 2004, COMPUT ANIMAT VIRT W, V15, P173, DOI 10.1002/cav.19
   Sobol IM, 1999, COMPUT MATH APPL, V37, P33, DOI 10.1016/S0898-1221(99)00057-7
   Stalling D., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P249, DOI 10.1145/218380.218448
   Strugar Filip, 2009, Journal of Graphics Tools, V14, P57
   Tao J, 2013, IEEE T VIS COMPUT GR, V19, P393, DOI 10.1109/TVCG.2012.143
   Telea A, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P233, DOI 10.1109/VISUAL.2003.1250377
   van Wijk JJ, 2002, ACM T GRAPHIC, V21, P745, DOI 10.1145/566570.566646
   Weiskopf D, 2004, PROC GRAPH INTERF, P263
   Weiskopf D, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P107, DOI 10.1109/VISUAL.2003.1250361
   Weiskopf D., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P439
   Weiskopf D, 2008, IEEE T VISUALIZATION, V13, P569
   Weiskopf Daniel., 2006, GPU-Based Interactive Visualization Techniques, V1st
   Xiaoyang Mao, 1997, Visualization in Scientific Computing'97. Proceedings of the Eurographics Workshop, P57
   Xu LJ, 2010, IEEE T VIS COMPUT GR, V16, P1216, DOI 10.1109/TVCG.2010.131
   Zheng L, 2013, IEEE T VIS COMPUT GR, V19, P446, DOI 10.1109/TVCG.2012.144
NR 41
TC 4
Z9 7
U1 1
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2016
VL 27
IS 2
BP 123
EP 140
DI 10.1002/cav.1664
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ2BZ
UT WOS:000374010000004
DA 2024-07-18
ER

PT J
AU Berseth, G
   Usman, M
   Haworth, B
   Kapadia, M
   Faloutsos, P
AF Berseth, Glen
   Usman, Muhammad
   Haworth, Brandon
   Kapadia, Mubbasir
   Faloutsos, Petros
TI Environment optimization for crowd evacuation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE crowd simulation; optimization and analysis
AB The layout of a building, real or virtual, affects the flow patterns of its intended users. It is well established, for example, that the placement of pillars at proper locations can often facilitate pedestrian flow during the evacuation of a building. Such considerations are therefore important for architects, game level developers, and others whose domains involve agents navigating through buildings. In this paper, we take the first steps towards developing a simulation framework that can be used to study the optimal placement of architectural elements, such as pillars or doors, for the purposes of facilitating dense pedestrian flow during the evacuation of a building. In particular, we show that the steering algorithms used to model the local navigation abilities of the agents significantly affect the results, which motivates the need for a statistically valid approach and further study. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Berseth, Glen] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1W5, Canada.
   [Usman, Muhammad; Haworth, Brandon] York Univ, Elect Engn & Comp Sci Dept, Toronto, ON M3J 2R7, Canada.
   [Faloutsos, Petros] York Univ, Dept Comp Sci & Engn, Toronto, ON M3J 2R7, Canada.
C3 University of British Columbia; York University - Canada; York
   University - Canada
RP Berseth, G (corresponding author), Univ British Columbia, Comp Sci, Vancouver, BC V5Z 1M9, Canada.
EM gberseth@cs.ubc.ca
OI Haworth, Brandon/0000-0001-8134-0047; Berseth, Glen/0000-0001-7351-8028;
   Usman, Muhammad/0000-0003-2059-7206
CR Bauers AW, 2013, AUTOMATED REDESIGN L, P190
   Berseth Glen., 2014, Proceedings of the 7th International Conference on Motion in Games, P153, DOI DOI 10.1145/2668084.2668100
   Berseth Glen., 2014, Proceedings of the ACM SIGGRAPH / Eurographics Symposium on Computer Animation, P113
   Berseths G, 2013, P MOT GAM MIG 13 ACM
   Cardamone L, 2011, LECT NOTES COMPUT SC, V6624, P63, DOI 10.1007/978-3-642-20525-5_7
   Davidichs M, 2011, PEDESTRIAN EVACUATIO, P537
   Guys SJ, 2012, ACM T GRAPHIC, V31, P11
   Hansens N, 2011, RR7751 INRIA
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Helbing D, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.046109
   Johanssons A, 2008, ADV COMPLEX SYSTEMS, V11
   Kapadia M., 2013, P 12 ACM SIG GRAPHEU, P115, DOI DOI 10.1145/2485895.2485909
   Kapadia M., 2011, P 2011 ACM SIGGRAPH, P53, DOI DOI 10.1145/2019406.2019414
   Kulpas R, 2011, ACM SIGGRAPH AS, V138
   Lerner A, 2010, COMPUT GRAPH FORUM, V29, P2197, DOI 10.1111/j.1467-8659.2010.01808.x
   McDonnell R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360625
   Musse SR, 2012, COMPUT ANIMAT VIRT W, V23, P49, DOI 10.1002/cav.1423
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Rodriguez S, 2013, IEEE INT C INT ROBOT, P1327, DOI 10.1109/IROS.2013.6696521
   Schuerman M, 2010, COMPUT ANIMAT VIRT W, V21, P267, DOI 10.1002/cav.367
   Seyfried A, 2010, PEDESTRIAN AND EVACUATION DYNAMICS 2008, P145, DOI 10.1007/978-3-642-04504-2_11
   Shis Y, 2013, OPTIMAL COVER PLACEM, P109
   Singh S, 2011, COMPUT ANIMAT VIRT W, V22, P151, DOI 10.1002/cav.403
   Singh S, 2009, COMPUT ANIMAT VIRT W, V20, P533, DOI 10.1002/cav.277
   Singh S, 2008, LECT NOTES COMPUT SC, V5277, P200
   Singh Shawn., 2011, ACM SIGGRAPH I3D, P141
   Sorenson N., 2010, Proceedings of the First International Conference on Computational Creativity (ICCCX), P258
   Sorenson N, 2010, LECT NOTES COMPUT SC, V6024, P131, DOI 10.1007/978-3-642-12239-2_14
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
NR 30
TC 27
Z9 32
U1 2
U2 24
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 377
EP 386
DI 10.1002/cav.1652
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700019
DA 2024-07-18
ER

PT J
AU Kim, N
   Oh, S
   Park, K
AF Kim, Namjung
   Oh, SaeWoon
   Park, Kyoungju
TI Giant soap bubble creation model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE soap bubble; deformable model; viscoelasticity; Gibbs elasticity;
   Marangoni elasticity
ID GIBBS ELASTICITY; SIMULATION; FILM
AB We present a simple and real-time technique for animating giant realistic looking soap bubbles. Unlike small spherical soap bubbles, giant soap bubbles stretch significantly and undergo globally varying and locally consistent deformations because of time-varying surface tensions. For physically plausible surface tensions, we introduce and combine a variable-length mass spring system and Gibbs elasticity and Marangoni elasticity. Using a proposed framework, we deform our models because of general forces from surface tensions, winds, and excessive pressures. Our framework effectively generates a physically plausible animation of giant soap bubbles, differing in shape according to the user's design; generates capillary waves and vibrations while floating in the air; and shows vivid iridescent colors corresponding to the deformations, all of which have been difficult to achieve using previous soap bubble animation methods. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Kim, Namjung; Oh, SaeWoon; Park, Kyoungju] Chung Ang Univ, Dept Image, Seoul 156756, South Korea.
C3 Chung Ang University
RP Park, K (corresponding author), Chung Ang Univ, Dept Image, Seoul 156756, South Korea.
EM kjpark@cau.ac.kr
FU Chung-Ang University
FX This research was supported by the Chung-Ang University Excellent
   Student Scholarship and Research Scholarship Grants in 2010.
CR Barbu L, 2013, Z ANGEW MATH PHYS, V64, P321, DOI 10.1007/s00033-012-0240-x
   Brochu T, 2009, SIAM J SCI COMPUT, V31, P2472, DOI 10.1137/080737617
   Chomaz JM, 2001, J FLUID MECH, V442, P387, DOI 10.1017/S0022112001005213
   Clausen P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451243
   Clavet S., 2005, SCA '05, P219, DOI DOI 10.1145/1073368.1073400
   COUDER Y, 1989, PHYSICA D, V37, P384, DOI 10.1016/0167-2789(89)90144-9
   DIAS ML, 1991, IEEE COMPUT GRAPH, V11, P54, DOI 10.1109/38.75591
   Djado K, 2012, COMPUT ANIMAT VIRT W, V23, P301, DOI 10.1002/cav.1446
   Durikovic R, 2001, COMPUT GRAPH FORUM, V20, pC67
   Fungs YC, 1965, FDN SOLID MECH
   Georgieva D, 2009, SOFT MATTER, V5, P2063, DOI 10.1039/b822568k
   Gibbss JW, 1931, COLLECTED WORKS
   Glassner A, 2000, IEEE COMPUT GRAPH, V20, P99, DOI 10.1109/38.888023
   Glassner A, 2000, IEEE COMPUT GRAPH, V20, P76, DOI 10.1109/38.865884
   Hong M, 2006, IEEE COMPUT GRAPH, V26, P83, DOI 10.1109/MCG.2006.104
   Icart I, 1999, COMPUT GRAPH-UK, V23, P405, DOI 10.1016/S0097-8493(99)00048-5
   Imura M., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, P95, DOI [10.1145/1643928.1643952, DOI 10.1145/1643928.1643952]
   Iwasaki K, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P344, DOI 10.1109/CGI.2004.1309231
   Jaszkowski D, 2003, VISUAL COMPUT, V19, P252, DOI 10.1007/s00371-002-0195-6
   Kang M, 2008, COMPUT FLUIDS, V37, P524, DOI 10.1016/j.compfluid.2007.07.002
   Kück H, 2002, PROC GRAPH INTERF, P81
   Li L, 2006, J COMPUT SCI TECH-CH, V21, P154, DOI 10.1007/s11390-006-0154-1
   LUCASSEN J, 1967, J COLLOID INTERF SCI, V25, P496, DOI 10.1016/0021-9797(67)90060-4
   MARCHAND P, 1983, REV SCI INSTRUM, V54, P1034, DOI 10.1063/1.1137498
   Meyer M., 2002, Visualization and mathematics, V3, P34
   MYSELS KJ, 1961, J PHYS CHEM-US, V65, P1107, DOI 10.1021/j100825a005
   Pans H, 2012, ACM T GRAPHIC, V31
   PRINS A, 1967, J COLLOID INTERF SCI, V24, P84, DOI 10.1016/0021-9797(67)90281-0
   Rey AD, 2000, J CHEM PHYS, V113, P10820, DOI 10.1063/1.1324993
   Rusanov A., 1979, PROG SURF MEMBR SCI, V13, P415
   Schroeder C, 2012, J COMPUT PHYS, V231, P2092, DOI 10.1016/j.jcp.2011.11.021
   Sun YL, 2008, COMPUT GRAPH FORUM, V27, P1607, DOI 10.1111/j.1467-8659.2007.01110.x
   Wyman C, 2009, COMPUT GRAPH FORUM, V28, P309, DOI 10.1111/j.1467-8659.2009.01370.x
   Xiaoming Wei, 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P75
   Zhang YZ, 2012, IEEE T VIS COMPUT GR, V18, P1281, DOI 10.1109/TVCG.2011.141
   Zheng W., 2006, Proc. of the ACM Siggraph/Eurographics Symposium on Computer Animation, P325
NR 36
TC 7
Z9 7
U1 1
U2 26
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 445
EP 455
DI 10.1002/cav.1640
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700026
DA 2024-07-18
ER

PT J
AU Oshita, M
AF Oshita, Masaki
TI Interactive motion synthesis with optimal blending
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion synthesis; motion control; motion transition; motion blending
AB In this paper, we propose an interactive motion synthesis technique that synthesizes a continuous motion sequence from given elementary motions. A user can either specify the execution timings of motions or execute motions in a sequence with automatically determined execution timings. Our method is based on a previous approach that determined the appropriate synthesis method and blending range for each pair of sequential motions, while considering the constraints between the foot and ground in the elementary motions to prevent foot sliding. However, using only the foot-ground constraints to determine the blending range may generate unnatural motions such as nonsmooth, too fast, or too slow transitions. Moreover, simple motion blending with a regular weight function can generate unnatural motions. To solve these problems, we have introduced an optimal blending range and a weight function, which are determined for each blending segment for the upper and lower body. We also introduced extensions for applying this method to interactive character control. We have successfully applied our method to both animation generation and interactive character control. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 Kyushu Inst Technol, Iizuka, Fukuoka, Japan.
C3 Kyushu Institute of Technology
RP Oshita, M (corresponding author), Kyushu Inst Technol, Iizuka, Fukuoka, Japan.
EM oshita@ces.kyutech.ac.jp
FU Japan Society for the Promotion of Science (JSPS) [24500238];
   Grants-in-Aid for Scientific Research [24500238] Funding Source: KAKEN
FX This work was supported in part by a grant-in-aid for scientific
   research (no. 24500238) from the Japan Society for the Promotion of
   Science (JSPS). The author would like to thank Reiko Yamanaka, Yukiko
   Nakatsuka, Takeshi Seki, and Masami Iwatsuki for their help in
   evaluating the Noh dance motions and their valuable comments.
CR Glardon P, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P44
   Gleicher Michael., 2003, I3D 2003: Proceedings of the 2003 Symposium on Interactive 3D Graphics, P181
   Ikemoto L, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P145
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866160
   M S., 2004, SCA'04: Proceedings of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P325
   McCann J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276385, 10.1145/1239451.1239457]
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Oshita M, 2013, VISUAL COMPUT, V29, P1077, DOI 10.1007/s00371-013-0839-8
   Oshita M, 2008, COMPUT GRAPH FORUM, V27, P1909, DOI 10.1111/j.1467-8659.2008.01339.x
   Rose C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P147, DOI 10.1145/237170.237229
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Shum HPH, 2009, COMPUT ANIMAT VIRT W, V20, P385, DOI 10.1002/cav.315
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Witkin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P105, DOI 10.1145/218380.218422
   Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249
NR 17
TC 1
Z9 2
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 313
EP 321
DI 10.1002/cav.1578
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300012
DA 2024-07-18
ER

PT J
AU Luo, GL
   Cordier, F
   Seo, H
AF Luo, Guoliang
   Cordier, Frederic
   Seo, Hyewon
TI Compression of 3D mesh sequences by temporal segmentation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE mesh sequences; compression; temporal segmentation
AB We describe a compression method for three-dimensional animation sequences that has notable advantages over existing techniques. We first aggregate the frame data by similarity and reorganize them into clusters, which results in the sequence split into several motion fragments of varying lengths. To minimize the number of clusters and obtain optimal clustering, we perform frame alignment, which eliminates the global rigid transformation from each frame data and use only pose when evaluating the similarity between frames. We then apply principal component analysis for each cluster, from which we get coordinates of corresponding frames in a reduced dimension. Because similar frames are considered, the number of coefficients required for each frame becomes smaller; thus, we obtain better dimension reduction for a given reconstruction error. Further, we perform intracluster compression based on linear coding. Because every motion fragment presents similar frames, conventional linear predictive coding can be replaced by key frame-based linear coding to achieve minimal reconstruction error. Results show that our method can obtain a high compression ratio, with a limited reconstruction error. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Luo, Guoliang; Seo, Hyewon] Univ Strasbourg, ICube, UMR 7357, CNRS, Strasbourg, France.
   [Cordier, Frederic] Univ Haute Alsace, LMIA, EA 3993, Mulhouse, France.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute
   for Engineering & Systems Sciences (INSIS); Universites de Strasbourg
   Etablissements Associes; Universite de Strasbourg; Universites de
   Strasbourg Etablissements Associes; Universite de Haute-Alsace (UHA)
RP Cordier, F (corresponding author), Univ Haute Alsace, LMIA, EA 3993, Mulhouse, France.
EM frederic.cordier@uha.fr
FU project SHARED [10-CHEX-014-01]; French National Research Agency
FX This work has been supported by the project SHARED (No. 10-CHEX-014-01)
   funded by the French National Research Agency.
CR Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   Amjoun R, 2009, COMPUT AIDED DESIGN, V41, P711, DOI 10.1016/j.cad.2009.02.013
   GORYN D, 1995, IEEE T PATTERN ANAL, V17, P1219, DOI 10.1109/34.476514
   Gumhold S., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P133, DOI 10.1145/280814.280836
   Ibarria L., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P126
   *ISO IEC, 2007, JTC1SC29WG11 ISOIEC
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Kruskal JB, 1978, MULTIDIMENSIONAL SCA
   Mamou K, 2008, IEEE IMAGE PROC, P2676, DOI 10.1109/ICIP.2008.4712345
   Mamou K, 2006, COMPUT ANIMAT VIRT W, V17, P337, DOI 10.1002/cav.137
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Ramanathan S, 2008, IMAGE VISION COMPUT, V26, P1012, DOI 10.1016/j.imavis.2007.11.005
   Sattler M., 2005, P 2005 ACM SIGGRAPH, P209
   Stefanoski N, 2006, IEEE IMAGE PROC, P2973, DOI 10.1109/ICIP.2006.312961
   Stefanoski N, 2010, COMPUT GRAPH FORUM, V29, P101, DOI 10.1111/j.1467-8659.2009.01547.x
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Vása L, 2009, COMPUT GRAPH FORUM, V28, P1529, DOI 10.1111/j.1467-8659.2008.01304.x
   Vása L, 2010, COMPUT GRAPH FORUM, V29, P1921, DOI 10.1111/j.1467-8659.2010.01659.x
NR 19
TC 16
Z9 18
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 365
EP 375
DI 10.1002/cav.1522
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500024
DA 2024-07-18
ER

PT J
AU Nikfetrat, N
   Lee, WS
AF Nikfetrat, Nima
   Lee, Won-Sook
TI Fire pattern analysis and synthesis using EigenFires and motion
   transitions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents Conference (CASA)
CY 2013
CL Istanbul, TURKEY
DE fire; analysis; synthesis; procedural; EigenFire; transition
ID SCENES
AB We introduce novel approaches of intuitive and easy-to-use realistic fire animation, starting from real-life fire by image-based techniques and statistical analysis. The results can be utilized as a pre-rendered sequence of images in video games, motion graphics, and cinematic visual effects. Instead of physics-based simulation, we employ an example-based principal component analysis and introduce EigenFires. We visualize the main features of various fire samples to analyze their tracks and synthesize a new fire by combining various fire samples, recorded with high frame rates, in order to edit given sequences of fire animations. For this purpose, we present how to recognize similarity of the shapes of fire in order to change the pattern from one style of fire to another distinct style of fire procedurally. Our techniques require very little parameter tuning, compared with conventional physically based fire synthesis, video textures, and dynamic textures. A similar level of visually pleasing compressed fire is also easily produced by using principal component analysis techniques. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Nikfetrat, Nima; Lee, Won-Sook] Univ Ottawa, Sch Elect Engn & Comp Sci EECS, Ottawa, ON, Canada.
C3 University of Ottawa
RP Nikfetrat, N (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci EECS, Ottawa, ON, Canada.
EM nnikf006@uottawa.ca
CR ADABALA N, 2004, P COMP AN SOC AG CAS
   Beaudin P., 2001, P GRAPHICS INTERFACE, P159
   Bhat KS, 2004, ACM T GRAPHIC, V23, P360, DOI 10.1145/1015706.1015729
   CHIBA N, 1994, J VISUAL COMP ANIMAT, V5, P37, DOI 10.1002/vis.4340050104
   Doretto G, 2003, PROC CVPR IEEE, P137
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Fuller AR, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P175
   Hasinoff SW, 2007, IEEE T PATTERN ANAL, V29, P870, DOI 10.1109/TPAMI.2007.1056
   Hasinoff SW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1184
   Hongliang L, 2012, INT C COMP COMM INF, P16
   Ihrke Ivo., 2004, ACM SIGGRAPH EUROGRA, P367
   Krüger J, 2005, COMPUT GRAPH FORUM, V24, P685, DOI 10.1111/j.1467-8659.2005.00893.x
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lamorlette A, 2002, ACM T GRAPHIC, V21, P729, DOI 10.1145/566570.566644
   Li WT, 2009, IEEE DECIS CONTR P, P398, DOI 10.1109/CDC.2009.5400123
   Masiero A, 2006, LECT NOTES COMPUT SC, V3952, P283
   Melek Z, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P431, DOI 10.1109/PCCGA.2002.1167889
   Min K, 2007, VISUAL COMPUT, V23, P679, DOI 10.1007/s00371-007-0162-3
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   Nikfetrat N, 2013, FIRE VISUALIZATION U, V441, P189
   Pegoraro V., 2006, Eurographics Workshop on Natural Phenomena, P237
   Perry CH, 1994, P 5 EUR WORKSH AN SI, P114
   Rasmussen N, 2003, ACM T GRAPHIC, V22, P703, DOI 10.1145/882262.882335
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P129, DOI 10.1145/218380.218430
   Stam J, 1993, P 20 ANN C COMP GRAP, P369
   Stam J., 2003, P GAM DEV C
   Takahashi JY, 1997, IEICE T INF SYST, VE80D, P1102
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Umenhoffer T, 2006, PROC GRAPH INTERF, P57
   Wei XM, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P227, DOI 10.1109/VISUAL.2002.1183779
   Yuan L, 2004, LECT NOTES COMPUT SC, V3022, P603
NR 35
TC 0
Z9 0
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 225
EP 235
DI 10.1002/cav.1501
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 145GP
UT WOS:000319003500010
DA 2024-07-18
ER

PT J
AU Karim, AA
   Gaudin, T
   Meyer, A
   Buendia, A
   Bouakaz, S
AF Karim, Ahmad Abdul
   Gaudin, Thibaut
   Meyer, Alexandre
   Buendia, Axel
   Bouakaz, Saida
TI Procedural locomotion of multilegged characters in dynamic environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE procedural animation; level of details; multilegged characters; dynamic
   environments
ID MOTION CAPTURE; STEP LENGTH; TIME; ANIMATION; WALKING; SPEED
AB We present a fully procedural method capable of generating in real time a wide range of locomotion for multilegged characters in a dynamic environment, without using any motion data. The system consists of several independent blocks: a Character Controller, a Gait/Tempo Manager, a three-dimensional (3D) Path Constructor, and a Footprints Planner. The four modules work cooperatively to calculate in real time the footprints and the 3D trajectories of the feet and the pelvis. Our system can animate dozens of creatures using dedicated level of details techniques and is totally controllable allowing the user to design a multitude of locomotion styles through a user-friendly interface. The result is a complete lower body animation that is sufficient for most of the chosen multilegged characters: arachnids, insects, imaginary n-legged robots, and so on. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Karim, Ahmad Abdul; Meyer, Alexandre; Bouakaz, Saida] Univ Lyon 1, CNRS, LIRIS, UMR5205, F-69622 Villeurbanne, France.
   [Karim, Ahmad Abdul; Gaudin, Thibaut; Buendia, Axel] Spir Ops Artificial Intelligence, Paris, France.
   [Buendia, Axel] CNAM CEDRIC, F-75003 Paris, France.
C3 Universite Claude Bernard Lyon 1; Centre National de la Recherche
   Scientifique (CNRS); Institut National des Sciences Appliquees de Lyon -
   INSA Lyon; heSam Universite; Conservatoire National Arts & Metiers
   (CNAM)
RP Karim, AA (corresponding author), Univ Lyon 1, CNRS, UMR5205, F-69622 Villeurbanne, France.
EM hamsho84@gmail.com
OI MEYER, Alexandre/0000-0002-0249-1048
CR Alexander R. M., 1996, Optima for animals
   Alexander R. M., 2003, PRINCIPLES ANIMAL LO
   [Anonymous], ACM T GRAPHICS TOG
   [Anonymous], 1985, P 12 ANN C COMP GRAP
   Barzel R., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P183
   Berthoz A, 2009, SCIENCES
   Blake RW, 2005, CAMBRIDGE ENV CHEM S
   Boulic R., 1990, Visual Computer, V6, P344, DOI 10.1007/BF01901021
   Chestnutt J, 2005, IEEE INT CONF ROBOT, P629
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Coros S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964954
   GIRARD M, 1987, IEEE COMPUT GRAPH, V7, P39, DOI 10.1109/MCG.1987.276895
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Hoyt DF, 2000, J EXP BIOL, V203, P221
   INMAN VT, 1966, CAN MED ASSOC J, V94, P1047
   Johansen R. S., 2009, THESIS
   Kajita S, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P239, DOI 10.1109/IROS.2001.973365
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Kuffner J, 2003, IEEE INT CONF ROBOT, P932
   Kuffner JJ, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P500, DOI 10.1109/IROS.2001.973406
   Kuo AD, 2001, J BIOMECH ENG-T ASME, V123, P264, DOI 10.1115/1.1372322
   Kwon Taesoo, 2010, P 2010 ACM SIGGRAPHE, P129
   Lamarche F, 2009, COMPUT GRAPH FORUM, V28, P649, DOI 10.1111/j.1467-8659.2009.01405.x
   Luenberger DG, 1984, LINEAR NONLINEAR PRO
   McKenna M., 1990, Computer Graphics, V24, P29, DOI 10.1145/97880.97882
   Multon F, 1999, J VISUAL COMP ANIMAT, V10, P39, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<39::AID-VIS195>3.0.CO;2-2
   Multon F, 2008, LECT NOTES COMPUT SC, V5277, P72
   Raibert M., 2008, IFAC P VOLUMES, V41, P10822, DOI [DOI 10.3182/20080706-5-KR-1001.01833, 10.3182/20080706-5-KR-1001.01833]
   Reklaitis GV, 1983, LINEAR NONLINEAR PRO
   Singh S, 2011, S INT 3D GRAPH GAM I, P203
   Torkos N, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P151
   Tsai YY, 2010, IEEE T VIS COMPUT GR, V16, P325, DOI 10.1109/TVCG.2009.76
   van Basten BJH, 2010, COMPUT ANIMAT VIRT W, V21, P433, DOI 10.1002/cav.342
   van Welbergen H, 2010, COMPUT GRAPH FORUM, V29, P2530, DOI 10.1111/j.1467-8659.2010.01822.x
   Wampler K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531366
   Wang JM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778810
   WILSON DM, 1967, J EXP BIOL, V47, P133
   Young JW, 2007, J HUM EVOL, V53, P26, DOI 10.1016/j.jhevol.2007.01.005
NR 40
TC 4
Z9 4
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2013
VL 24
IS 1
BP 3
EP 15
DI 10.1002/cav.1467
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 089PU
UT WOS:000314923300003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, XW
   Zhang, HY
   Zhao, QP
AF Chen, Xiaowu
   Zhang, Hengyuan
   Zhao, Qinping
TI Virtual calligraphic carving through smoothness scalar field and
   brush-pressure distribution
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE virtual calligraphic carving; smoothness scalar field; field reduction;
   brush-pressure distribution
ID MODEL
AB Virtual calligraphic carving aims to generate 3D virtual carving works from 2D calligraphic images. This paper proposes a method of virtual calligraphic carving taking calligraphic carving work as a depth map composed of smoothness scalar field and brush-pressure distribution, which ensures the smoothness of carving surface and interprets the strength of calligraphy, respectively. On one hand, the smoothness scalar field is modeled as a bounded planar scalar field with sources and constructed by applying a series of algorithms. On the other hand, the brush-pressure distribution is represented by a map created by estimating the touching pressures employed by brush on paper. Then the depth map is composed of the smoothness scalar field and brush-pressure distribution map and rendered into a virtual calligraphic carving work. The experiments show that this method can generate virtual calligraphic carving works that are vivid and very similar to that of artists. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Chen, Xiaowu; Zhang, Hengyuan; Zhao, Qinping] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Sch Comp Sci & Engn, Beijing, Peoples R China.
C3 Beihang University
RP Zhang, HY (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Sch Comp Sci & Engn, Beijing, Peoples R China.
EM zhanghy@vrlab.buaa.edu.cn
FU NSFC [60933006]; 863 Program [2012AA011504, 2012AA02A606]; Special
   Program on ITER [2012GB102008]; ASFC [2011ZC51027]; BUAA
   [YWF-12-LKGY-001]
FX This work was partially supported by the NSFC (60933006), 863 Program
   (2012AA011504 and 2012AA02A606), Special Program on ITER (2012GB102008),
   ASFC (2011ZC51027), and BUAA (YWF-12-LKGY-001).
CR [Anonymous], 2002, Proceedings of the Symposium on Non-photorealistic animation and rendering
   Bai BD, 2009, CHINESE J ELECTRON, V18, P302
   Epshtein B, 2010, P IEEE C COMP VIS PA, P2963
   Gan GL, 2009, INT C COMP AID IND D, P1609, DOI 10.1109/CAIDCD.2009.5375213
   Li W, 2003, J COMPUT APPL MATH, V159, P85, DOI 10.1016/S0377-0427(03)00573-9
   Mi XF, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P330, DOI 10.1109/ACV.2002.1182203
   Van Laerhoven T, 2005, COMPUT ANIMAT VIRT W, V16, P429, DOI 10.1002/cav.95
   Wong STS, 2008, COMPUT VIS IMAGE UND, V109, P69, DOI 10.1016/j.cviu.2007.03.001
   Wu ZC, 2004, LECT NOTES COMPUT SC, V3338, P654
   Xiaowu Chen, 2011, 2011 12th International Conference on Computer-Aided Design and Computer Graphics, P450, DOI 10.1109/CAD/Graphics.2011.19
   Yin JB, 2005, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - PROCEEDINGS, P989, DOI 10.1109/CIT.2005.126
   You XG, 2006, INT J PATTERN RECOGN, V20, P361, DOI 10.1142/S0218001406004764
   Zhang Zhenting, 2010, Journal of Computer Aided Design & Computer Graphics, V22, P1010, DOI 10.3724/SP.J.1089.2010.10859
NR 13
TC 1
Z9 1
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 353
EP 361
DI 10.1002/cav.1440
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100022
DA 2024-07-18
ER

PT J
AU Rungjiratananon, W
   Kanamori, Y
   Metaaphanon, N
   Bando, Y
   Chen, BY
   Nishita, T
AF Rungjiratananon, Witawat
   Kanamori, Yoshihiro
   Metaaphanon, Napaporn
   Bando, Yosuke
   Chen, Bing-Yu
   Nishita, Tomoyuki
TI Animating strings with twisting, tearing and flicking effects
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE twisting; tearing; flicking; string animation
ID SIMULATION; CLOTH; MODEL
AB String-like objects in our daily lives, for example shoelaces, threads, rubber cords, plastic fiber and spaghetti, have a wide variety of materials. Such string-like objects also exhibit interesting behaviors such as twisting, tearing (by stretching or twisting), and bouncing back when pulled and released. In this paper, we present a method that enables these behaviors and simulates such materials in traditional string simulation methods that explicitly represent a string by particles and segments. Specifically, we offer the following three contributions. First, we introduce a method for handling twisting effects with both uniform and non-uniform torsional rigidities. Second, we propose a method for estimating the tension acting on inextensible strings in order to reproduce tearing and flicking (bouncing back), whereas the tension for an extensible object can be computed via stretched length. The length of an inextensible object is maintained constant in general, and thus, we need a novel approach. Third, we introduce an optimized grid-based collision detection for accelerating the computation. We demonstrate that our method can produce visually plausible animations of string-like objects with various material properties, and it is a fast framework for interactive applications such as games. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Rungjiratananon, Witawat; Nishita, Tomoyuki] Univ Tokyo, Kashiwa, Chiba, Japan.
   [Kanamori, Yoshihiro] Univ Tsukuba, Grad Sch Syst & Informat Engn, Tsukuba, Ibaraki, Japan.
   [Metaaphanon, Napaporn] Sq Enix, Tokyo, Japan.
   [Bando, Yosuke] Toshiba Co Ltd, Tokyo, Japan.
   [Chen, Bing-Yu] Natl Taiwan Univ, Taipei 10764, Taiwan.
C3 University of Tokyo; University of Tsukuba; Toshiba Corporation;
   National Taiwan University
RP Rungjiratananon, W (corresponding author), Univ Tokyo, Kashiwa, Chiba, Japan.
EM im_witawat@yahoo.com
RI Chen, Bing-Yu/E-7498-2016
OI Chen, Bing-Yu/0000-0003-0169-7682
FU Grants-in-Aid for Scientific Research [10J04748] Funding Source: KAKEN
CR [Anonymous], P 2 WORKSH VIRT REAL
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bergou M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360662
   Bertails F, 2006, ACM T GRAPHIC, V25, P1180, DOI 10.1145/1141911.1142012
   Bhuvenesh CG, 2004, TEXTILE SIZING
   Diziol R., 2009, EUROGRAPHICS 2009 SH, P37
   Goldenthal R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239500
   Hadap S., 2006, PROC ACM SIGGRAPHEUR, P91
   Harada T., 2007, GPU GEMS, V3, P123
   Metaaphanon N, 2009, COMPUT GRAPH FORUM, V28, P1837, DOI 10.1111/j.1467-8659.2009.01561.x
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   PROVOT X, 1995, GRAPH INTER, P147
   Rivers AR, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239533
   Rosenblum R. E., 1991, Journal of Visualization and Computer Animation, V2, P141, DOI 10.1002/vis.4340020410
   Rungjiratananon Witawat, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P192, DOI 10.1007/978-3-642-25090-3_17
   Rungjiratananon W, 2010, COMPUT GRAPH FORUM, V29, P2438, DOI 10.1111/J.1467-8659.2010.01755.x
   Selle A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360663
   Spillmann J, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P63
   Spillmann J, 2008, COMPUT GRAPH FORUM, V27, P497, DOI 10.1111/j.1467-8659.2008.01147.x
NR 19
TC 3
Z9 3
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2012
VL 23
IS 2
BP 113
EP 124
DI 10.1002/cav.1431
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 926VJ
UT WOS:000302859700006
DA 2024-07-18
ER

PT J
AU Slomp, M
   Johnson, MW
   Tamaki, T
   Kaneda, K
AF Slomp, Marcos
   Johnson, Matthew W.
   Tamaki, Toru
   Kaneda, Kazufumi
TI Photorealistic real-time rendering of spherical raindrops with
   hierarchical reflective and refractive maps
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE natural phenomena; rainy scenes; raindrop rendering
ID MODEL
AB Synthesizing rainy images is a common challenge found in film, game engines, driving simulators, and architectural design. Simulating light transport through a raindrop's optical properties is a view-dependent problem, and large quantities of raindrops are required to produce a plausible rainy scene. Accurate methods for rendering raindrops exist but are often off-line techniques that are cost prohibitive for real-time applications. Most real-time solutions use textures to approximate the appearance of moving raindrops as streaks. These approaches produce plausible results but do not address the problem of temporal effects such as slow-motion or paused simulations. In such conditions, streak-based approximations are not suitable, and proper raindrop geometry should be considered. This paper describes a straight-forward approach for rendering raindrops in such temporal conditions. The proposed technique consists of a preprocessing stage that generates a raindrop mask and a run-time stage that renders raindrops as screen-aligned billboards. The mask's contents are adjusted on the basis of the viewpoint, viewing direction, and raindrop position. The proposed method renders millions of raindrops at real-time rates in current graphics hardware, making it suitable for applications that require high-visual quality without compromising performance. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Slomp, Marcos; Tamaki, Toru] Hiroshima Univ, Fac Engn, Dept Informat Engn, Intelligent Syst & Modeling Lab,Grad Sch Engn, Higashihiroshima 724, Japan.
C3 Hiroshima University
RP Slomp, M (corresponding author), Hiroshima Univ, Fac Engn, Dept Informat Engn, Intelligent Syst & Modeling Lab,Grad Sch Engn, Higashihiroshima 724, Japan.
EM mslomp@gmail.com
RI Tamaki, Toru/D-7091-2011; Kaneda, Kazufumi/J-5562-2015
OI Tamaki, Toru/0000-0001-9712-7777; Barnes, Tiffany/0000-0002-6500-9976
CR [Anonymous], 2006, NEW YORK TIMES
   [Anonymous], REAL TIME PHOTOGRAPH
   BEARD KV, 1987, J ATMOS SCI, V44, P1509, DOI 10.1175/1520-0469(1987)044<1509:ANMFTE>2.0.CO;2
   BRAUWERS M, 2007, 13D 07, P89
   Carr NA, 2006, PROC GRAPH INTERF, P203
   Crow F. C., 1984, Computers & Graphics, V18, P207
   DEMERS J, 2005, GPU GEMS PROGRAMMING
   Devlin K., 2002, A review of tone reproduction techniques
   Filion D., 2008, SIGGRAPH 08, P133, DOI DOI 10.1145/1404435.1404441
   Garg K, 2004, PROC CVPR IEEE, P528
   GARG K, 2006, SIGGRAPH 06, P996
   Garg Kshitiz., 2004, PHOTOMETRIC MODEL RA
   GOODNIGHT N, 2005, SIGGRAPH 05, P180
   *GPGPU FOR, 2006, FBO POINT SPRIT
   Heckbert P. S., 1986, Computer Graphics, V20, P315, DOI 10.1145/15886.15921
   Kaneda K, 1999, J VISUAL COMP ANIMAT, V10, P15, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<15::AID-VIS192>3.0.CO;2-P
   KANEDA K, 1993, P COMP AN 93, P177
   Kipfer P., 2004, HWWS 04, P115, DOI [10.1145/1058129.1058146, DOI 10.1145/1058129.1058146]
   Kolb A., 2004, P ACM SIGGRAPHEUROGR, P123
   Krawczyk G., 2005, Proceedings of the 21st spring conference on Computer graphics, P195
   Lee SH, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559756
   Lee S, 2008, COMPUT GRAPH FORUM, V27, P1955, DOI 10.1111/j.1467-8659.2008.01344.x
   MARSHALL JS, 1948, J METEOROL, V5, P165, DOI 10.1175/1520-0469(1948)005<0165:TDORWS>2.0.CO;2
   Purcell TimothyJ., 2005, ACM SIGGRAPH Courses, P268
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Rousseau P, 2006, COMPUT GRAPH-UK, V30, P507, DOI 10.1016/j.cag.2006.03.013
   STARIK S, 2002, P 3 INT WORKSH TEXT, P95
   *TOMS HARDW, 2008, GPU PERF CHART
   Wang CB, 2008, VISUAL COMPUT, V24, P605, DOI 10.1007/s00371-008-0241-0
   Wang HM, 2005, ACM T GRAPHIC, V24, P921, DOI 10.1145/1073204.1073284
   Wang L, 2006, SIGGRAPH 06 ACM SIGG, P156
   WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882
   Wyman C, 2005, ACM T GRAPHIC, V24, P1050, DOI 10.1145/1073204.1073310
NR 33
TC 3
Z9 3
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL-AUG
PY 2011
VL 22
IS 4
BP 393
EP 404
DI 10.1002/cav.421
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 825OW
UT WOS:000295290400007
DA 2024-07-18
ER

PT J
AU He, SF
   Wong, HC
   Pang, WM
   Wong, UH
AF He, Shengfeng
   Wong, Hon-Cheng
   Pang, Wai-Man
   Wong, Un-Hong
TI Real-time smoke simulation with improved turbulence by spatial adaptive
   vorticity confinement
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE smoke animation; vorticity confinement; turbulence; fluid simulation
ID VORTEX PARTICLE METHOD
AB Turbulence modeling has recently drawn many attentions in fluid animation to generate small-scale rolling features. Being one of the widely adopted approaches, vorticity confinement method re-injects lost energy dissipation back to the flow. However, previous works suffer from deficiency when large vorticity coefficient e is used, due to the fact that constant e is applied all over the simulated domain. In this paper, we propose a novel approach to enhance the visual effect by employing an adaptive vorticity confinement which varies the strength with respect to the helicity instead of a user-defined constant. To further improve fine details in turbulent flows, we are not only applying our proposed vorticity confinement to low-resolution grid, but also on a finer grid to generate sub-grid level turbulence. Since the incompressible Navier-Stokes equations are solved only in low-resolution grid, this saves a significant amount of computation. Several experiments demonstrate that our method can produce realistic smoke animation with enhanced turbulence effects in real-time. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [He, Shengfeng; Wong, Hon-Cheng] Macau Univ Sci & Technol, Fac Informat Technol, Taipa, Peoples R China.
   [Wong, Hon-Cheng; Wong, Un-Hong] Macau Univ Sci & Technol, Space Sci Inst, Taipa, Peoples R China.
   [Pang, Wai-Man] Univ Aizu, Comp Arts Lab, Spatial Media Grp, Aizu Wakamatsu, Fukushima, Japan.
C3 Macau University of Science & Technology; Macau University of Science &
   Technology; University of Aizu
RP Wong, HC (corresponding author), Macau Univ Sci & Technol, Fac Informat Technol, Taipa, Peoples R China.
EM hcwong@ieee.org
RI He, Shengfeng/E-5682-2016
OI He, Shengfeng/0000-0002-3802-4644; Wong, Hon-Cheng/0000-0001-5884-1417
CR [Anonymous], 2008, Fluid Simulation for Computer Graphics
   Crane K., 2007, GPU GEMS, P633
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster Nick., 1997, P 24 ANN C COMP GRAP, P181
   HARRIS MJ, 2004, GPU GEMS, P637
   Kim T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360649
   Lentine M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778851
   Moffatt H. K., 1969, J FLUID MECH, V35, P117, DOI DOI 10.1017/S0022112069000991
   MOFFATT HK, 1992, ANNU REV FLUID MECH, V24, P281, DOI 10.1146/annurev.fl.24.010192.001433
   MOFFATT HK, 1981, J FLUID MECH, V106, P27, DOI 10.1017/S002211208100150X
   Narain R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409119
   NIELSEN NB, 2009, P 2009 EUR ACM SIGRR, P217
   ROBINSON M, 2004, P AIAA 42 AER SCI M
   Schechter H., 2008, Symposium on Computer animation, P1
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Sigg C., 2005, GPU GEMS, V2, P313
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   STEINHOFF J, 1994, PHYS FLUIDS, V6, P2738, DOI 10.1063/1.868164
   Yoon JC, 2009, COMPUT GRAPH FORUM, V28, P1853, DOI 10.1111/j.1467-8659.2009.01563.x
   ZHAO Y, 2010, P 2010 ACM SIGGRAPH, P75
NR 21
TC 13
Z9 15
U1 1
U2 5
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 107
EP 114
DI 10.1002/cav.408
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700005
DA 2024-07-18
ER

PT J
AU Si, WX
   Yuan, ZY
   Liao, XY
   Duan, ZL
   Ding, YH
   Zhao, JH
AF Si, Weixin
   Yuan, Zhiyong
   Liao, Xiangyun
   Duan, Zhaoliang
   Ding, Yihua
   Zhao, Jianhui
TI 3D soft tissue warping dynamics simulation based on force asynchronous
   diffusion model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE medical dynamics simulation; soft tissue warping; FADM
AB Soft tissue warping is one of the key technologies of medical dynamics simulation, such as surgical simulation, image guided surgery. In this paper, we present a novel simulation method which is stable and fast like linear models for soft tissue warping simulation. This method performs on the irregular mesh models, and it is able to represent the visual properties of physical processes with low computational complexity using the Force Asynchronous Diffusion Model (FADM) proposed in this paper. It contains three parts: model preprocessing, collision detection and simulation model solution. In model preprocessing, we establish three models based on the triangular mesh: the geometrical model, the physical model and the transitional model. A two-level collision detection algorithm is presented based on the three models. At every time step of the simulation model solution, to more accurately reflect the internal physical properties of the soft tissue, we divide the springs in physical model into three kinds: tissue springs, connection springs and virtual springs; and we propose the asynchronous regions and active regions to simplify the computing process according to the realistic physical warping. Experimental results show the FAMD can achieve good warping effects on speed and realism. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Si, Weixin; Yuan, Zhiyong; Liao, Xiangyun; Duan, Zhaoliang; Ding, Yihua; Zhao, Jianhui] Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
C3 Wuhan University
RP Yuan, ZY (corresponding author), Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
EM yuanzywhu@gmail.com
CR Alterovitz R, 2009, IEEE T INF TECHNOL B, V13, P217, DOI 10.1109/TITB.2008.2008393
   Barbarino G, 2008, LECT NOTES COMPUT SC, V5104, P1, DOI 10.1007/978-3-540-70521-5_1
   Basdogan C, 2007, IEEE COMPUT GRAPH, V27, P54, DOI 10.1109/MCG.2007.51
   CHEN F, 2007, P 29 ANN INT C IEEE
   Choi C, 2009, INT J MED ROBOT COMP, V5, P257, DOI 10.1002/rcs.256
   CHOI KS, 2002, P 7 INT C 3D WEB TEC
   FARAG S, 2010, SIGGRAPH 2010 LOS AN
   Jaillet F, 1998, COMPUT GRAPH-UK, V22, P189, DOI 10.1016/S0097-8493(98)00006-5
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   MOLLER T, 1998, DOKTORSAVHANDLINGAR, V1425, P109
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   NOGAMI R, 2004, P 2004 IEEE RSJ INT
   Pieper S., 1992, Proceedings of the 1992 symposium on Interactive 3D graphics, ACM, Cambridge, Massachusetts, United States, P127
   VERLET L, 1967, PHYS REV, V159, P98, DOI 10.1103/PhysRev.159.98
   XUEMEI L, 2010, 2010 INT C COMP COMM, V10, P548
   YEH TY, 2006, P 2006 ACM SIGGRAPH, P71
   ZHU J, 2010, INFORM AUTOMATION, P771
   Zhuang Y, 1999, ACM SIGGRAPH 99 C, P270, DOI 10.1145/311625.312171
NR 18
TC 3
Z9 5
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 251
EP 259
DI 10.1002/cav.416
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700021
DA 2024-07-18
ER

PT J
AU Tong, J
   Zhang, MM
   Xiang, XQ
   Shen, HQ
   Yan, H
   Chen, ZM
AF Tong, Jing
   Zhang, Mingmin
   Xiang, Xueqin
   Shen, Huaqing
   Yan, Hao
   Chen, Zhengming
TI 3D body scanning with hairstyle using one time-of-flight camera
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE time-of-flight camera; 3D body scanning; hairstyle; 3D shape
   reconstruction
AB Capturing realistic 3D shapes of human bodies is very useful for many computer graphics applications. However, for existing 3D shape capturing devices, such as structured light, laser scanner or multi-view methods, problems arise when dealing with 3D hairstyle scanning and body deformation. To solve these problems, a novel approach is proposed to scan 3D body with hairstyle using only one time-of-flight (TOF) camera. By capturing depth data at video rate, temporal average meshes can be obtained from different views. After some analysis, we found that the local geometric details of real surfaces, after the hair scanning process and low-frequency body deformation, are still preserved in the average meshes. Utilising the restriction that the corresponding surfaces in different views should overlap, a global optimisation process is proposed to iteratively improve the average meshes, while still preserving the geometric details. The proposed system is compact, and can scan 3D human body easily. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Zhang, Mingmin] Zhejiang Univ, State Key Lab CAD & CG, Comp & Engn Dept, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Zhengming] HoHai Univ, Coll Comp & Informat Engn, Dept Comp Sci, Changzhou, Peoples R China.
   [Shen, Huaqing] Zhejiang Univ, Sch Arts, Comp & Engn Dept, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Hohai University; Zhejiang University
RP Zhang, MM (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Comp & Engn Dept, Informat Technol Bldg B,Zijingang Campus, Hangzhou, Zhejiang, Peoples R China.
EM zmm@cad.zju.edu.cn
RI zhang, mm/IWV-4201-2023; Zhang, Miao/JXY-8985-2024
CR Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Bohme M, 2010, COMPUT VIS IMAGE UND, V114, P1329, DOI 10.1016/j.cviu.2010.08.001
   Bolitho M, 2009, LECT NOTES COMPUT SC, V5875, P678, DOI 10.1007/978-3-642-10331-5_63
   Brown BJ, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276404, 10.1145/1239451.1239472]
   Cho JH, 2008, IEEE T CONSUM ELECTR, V54, P1514, DOI 10.1109/TCE.2008.4711195
   Cui Y, 2010, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2010.5540082
   DOUGLAS L, 2009, ACM SIGGRAPH 2009 CO, P1
   Furukawa Y, 2007, PROC CVPR IEEE, P2118
   Jakob W, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618510
   KIM YM, 2008 IEEE COMP SOC C, V1
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   *MESA IM AG, 2010, SR4000 US MAN
   MIAO L, 2009, IEEE 12 INT C COMP V, P167
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Paris S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360629
   Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   SCHUON S, 2008 IEEE COMP SOC C, V1
   Seitz S.M., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI https://doi.org/10.1109/CVPR.2006.19
   SOBOTTKA G., 2006, P CGIV 2006 IEEE COM, P365
   SORKINE O, 2004, P 2004 EUR ACM SIGGR, V71, P175
   Ward K, 2007, IEEE T VIS COMPUT GR, V13, P213, DOI 10.1109/TVCG.2007.30
   Wei YC, 2005, ACM T GRAPHIC, V24, P816, DOI 10.1145/1073204.1073267
   Young Min Kim, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1542, DOI 10.1109/ICCVW.2009.5457430
   Zhu JJ, 2010, IEEE T PATTERN ANAL, V32, P899, DOI 10.1109/TPAMI.2009.68
NR 25
TC 1
Z9 2
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 203
EP 211
DI 10.1002/cav.392
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700016
DA 2024-07-18
ER

PT J
AU Singh, S
   Kapadia, M
   Faloutsos, P
   Reinman, G
AF Singh, Shawn
   Kapadia, Mubbasir
   Faloutsos, Petros
   Reinman, Glenn
TI SteerBench: a benchmark suite for evaluating steering behaviors
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE steering; pedestrians; crowd behaviors; benchmarking
ID SYSTEMS; CROWD
AB Steering is a challenging task, required by nearly all agents in virtual worlds. There is a large and growing number of approaches for steering, and it is becoming increasingly important to ask a fundamental question: how call we objectively compare steering algorithms? To our knowledge, there is no standard way of evaluating or comparing the quality of steering solutions. This paper presents SteerBench: a benchmark framework for objectively evaluating steering behaviors for virtual agents. We propose a diverse set of test cases, metrics of evaluation, and a scoring method that can be used to compare different steering algorithms. Our framework can be easily customized by a user to evaluate specific behaviors and new test cases. We demonstrate our benchmark process oil two example steering algorithms, showing the insight gained from our metrics. We hope that this framework call grow into a standard for steering evaluation. Copyright (C) 2009 from Wiley & Soils, Ltd.
C1 [Singh, Shawn; Faloutsos, Petros; Reinman, Glenn] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.
C3 University of California System; University of California Los Angeles
RP Singh, S (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Boelter Hall 4531-F, Los Angeles, CA 90095 USA.
EM shawnsin@cs.ucla.edu
FU NSF [CCF-0429983]
FX The work in this paper was partially supported by NSF grant No.
   CCF-0429983. We thank Intel Corp., Microsoft Corp., ATI Corp., and AGEIA
   Corp. for their generous support.
CR Brogan DC, 1997, AUTON ROBOT, V4, P137, DOI 10.1023/A:1008867321648
   Goldenstein S, 2001, COMPUT GRAPH-UK, V25, P983, DOI 10.1016/S0097-8493(01)00153-4
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Hodgin Jessica K., 1995, Proceedings of the ACM SIGCHI Conference on Computer Graphics and Interactive Techniques, P71
   Knoblauch R. L., 1996, Transportation research record, V1538, P27, DOI [10.1177/0361198196153800104, DOI 10.3141/1538-04, DOI 10.1177/0361198196153800104]
   KOREN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1398, DOI 10.1109/ROBOT.1991.131810
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Lext J, 2001, IEEE COMPUT GRAPH, V21, P22, DOI 10.1109/38.909012
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pelechano N., 2008, Proceedings of Autonomous Agents and Multiagent Systems, P136
   Reitsma PSA, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289609
   Reynolds Craig W, 1999, OPENSTEER
   Rudomín I, 2005, SIMUL MODEL PRACT TH, V13, P741, DOI 10.1016/j.simpat.2005.08.008
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   SHAO W, 2005, SCA 05, P19
   Sud A, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P99
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   TU X, 1994, SIGGRAPH 94, P43
   van den Berg J, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P139
   Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507
   Wu JC, 2003, ACM T GRAPHIC, V22, P888, DOI 10.1145/882262.882360
NR 25
TC 43
Z9 52
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2009
VL 20
IS 5-6
SI SI
BP 533
EP 548
DI 10.1002/cav.277
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 516RI
UT WOS:000271559700006
DA 2024-07-18
ER

PT J
AU Kim, JS
   Choi, SM
AF Kim, Jeong-Sik
   Choi, Soo-Mi
TI Symmetric deformation of 3D face scans using facial features and
   curvatures
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE 3D symmetrization; face symmetry; 3D facial features; surface curvatures
AB Facial symmetry is one of the number of aesthetic traits associated With health, physical attractiveness and beauty of a person. In this paper, we present a novel method for enhancing the symmetry of a scanned 3D face automatically. To handle detailed areas of the face, We developed a new local 3D shape descriptor based on facial features and surface curvatures. Our shape descriptor can improve the accuracy When deforming a 3D face towards a symmetric configuration, because it provides accurate point pairing with respect to the plane of symmetry. It can also reduce the computational complexity, by dividing the given face into partitioned slices and facial feature regions. In addition, we use point-based representation over all stages of symmetrization without generating a consistent triangle mesh or texture parameterization, Which makes it much easier to support discrete processes such as symmetric deformation and to be combined With more sophisticated manipulations later such as cutting of surfaces. Finally, We performed a statistical analysis to assess subjects' preference for the symmetrized faces by our approach. Copyright(C) 2009 John Wiley & Sons, Ltd.
C1 [Choi, Soo-Mi] Ewha Womans Univ, Ctr Comp Graph & Virtual Real, Seoul, South Korea.
C3 Ewha Womans University
RP Choi, SM (corresponding author), Sejong Univ, Dept Comp Engn, 98 Gunja Dong, Seoul 143747, South Korea.
EM smchoi@sejong.ac.kr
CR ATALLAH MJ, 1985, IEEE T COMPUT, V34, P663, DOI 10.1109/TC.1985.1676605
   Bruce M. K., 2003, STAT REASONING PSYCH
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Grunbaum B., 1963, Proc. Symp. Pure Math., V7, P233
   Guennebaud G, 2005, COMPUT GRAPH FORUM, V24, P657, DOI 10.1111/j.1467-8659.2005.00890.x
   Hadwiger H, 1957, VORLESUNGEN UEBER IN
   Jones BC, 2004, EVOL HUM BEHAV, V25, P24, DOI 10.1016/S1090-5138(03)00080-1
   Kazhdan M., 2004, SGP, P116
   *MAX PLANCK I BIOL, FAC DAT
   Mitra NJ, 2006, ACM T GRAPHIC, V25, P560, DOI 10.1145/1141911.1141924
   Mitra NiloyJ., 2007, ACM T GRAPHICS SIGGR, V26, P1, DOI DOI 10.1145/1276377.1276456
   Perrett DI, 1998, NATURE, V394, P884, DOI 10.1038/29772
   PFISTER F, 2000, P SIGGRAPH, P335
   Podolak J, 2006, ACM T GRAPHIC, V25, P549, DOI 10.1145/1141911.1141923
   Rhodes G, 2001, EVOL HUM BEHAV, V22, P31, DOI 10.1016/S1090-5138(00)00060-X
   Rusinkiewicz S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P486, DOI 10.1109/TDPVT.2004.1335277
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Sun CM, 1997, IEEE T PATTERN ANAL, V19, P164, DOI 10.1109/34.574800
   TAUBIN G, 1996, 4 ECCV IBM
   Thornhill R, 1999, TRENDS COGN SCI, V3, P452, DOI 10.1016/S1364-6613(99)01403-5
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wolter J., 1985, The Visual Computer, V1, P37, DOI DOI 10.1007/BF01901268
   Zaidel DW, 2005, BRAIN COGNITION, V57, P261, DOI 10.1016/j.bandc.2004.08.056
   Zhao W., 2000, AFace Recognition: A Literature Survey
NR 24
TC 7
Z9 7
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 289
EP 300
DI 10.1002/cav.294
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700022
DA 2024-07-18
ER

PT J
AU Tang, JKT
   Leung, H
   Komura, T
   Shum, HPH
AF Tang, Jeff K. T.
   Leung, Howard
   Komura, Taku
   Shum, Hubert P. H.
TI Emulating human perception of motion similarity
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE 3D human motion similarity; human perception; pattern recognition
AB Evaluating the similarity of motions is useful for motion retrieval, motion blending, and performance analysis of dancers and athletes. Euclidean distance between corresponding joints has been Widely adopted in measuring similarity of postures and hence motions. However, such a measure does not necessarily conform to the human perception of motion similarity. In this paper, eve propose a new similarity measure based on machine learning techniques. We make: rise of the results of questionnaires from subjects answering whether arbitrary pairs of motions appear similar or not. Using tire relative distance between the joints as the basic features, we train the system to compute tire similarity of arbitrary pair of motions. Experimental results show that our method outperforms methods based on Euclidean distance between corresponding joints. Our method is applicable to content-based motion retrieval of human motion for large-scale database systems. It is also applicable to e-Learning systems which automatically evaluates the performance of dancers and athletes by comparing tire subjects' motions With those by experts. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Leung, Howard] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Leung, H (corresponding author), City Univ Hong Kong, Dept Comp Sci, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
EM howard@cityu.edu.hk
RI Tang, Jeff K.T./JKI-4848-2023; Shum, Hubert P. H./E-8060-2015
OI Tang, Jeff K.T./0000-0002-5627-1630; Shum, Hubert P.
   H./0000-0001-5651-6039; LEUNG, Wing Ho Howard/0000-0002-2633-2965
CR [Anonymous], 2004, P INT C VERY LARGE D
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Blake R, 2007, ANNU REV PSYCHOL, V58, P47, DOI 10.1146/annurev.psych.57.102904.190152
   BOYD JE, 1998, P IEEE WORKSH EMP EV, P155
   CHAN J, 2007, P 1 INT C IMM TEL IM
   Chua PT, 2003, P IEEE VIRT REAL ANN, P87
   Harada T, 2004, IEEE-RAS INT C HUMAN, P494
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Miura K, 2006, IEEE SYS MAN CYBERN, P1184, DOI 10.1109/ICSMC.2006.384875
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   So CKF, 2005, COMPUT ANIMAT VIRT W, V16, P225, DOI 10.1002/cav.107
   Tang K.-T., 2008, Proceedings of the 2nd international conference on Ubiquitous information management and communication, P396
NR 15
TC 46
Z9 53
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 211
EP 221
DI 10.1002/cav.260
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200006
DA 2024-07-18
ER

PT J
AU Zou, GY
   Hua, J
   Dong, M
   Qin, H
AF Zou, Guangyu
   Hua, Jing
   Dong, Ming
   Qin, Hong
TI Surface matching with salient keypoints in geodesic scale space
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE surface matching; scale space; saliency
ID 3D; RECOGNITION; IMAGES
AB This paper develops a new salient keypoints-based shape description which extracts the salient surface keypoints with detected scales. Salient geometric features can then be defined collectively on all the detected scale normalized local patches to form a shape descriptor for surface snatching purpose. The saliency-driven keypoints are computed as local extrema of the difference of Ganssian function defined over a curved surface in geodesic scale space. This method can properly function on either manifold or non-manifold surface without resorting to any surface snapping or parameterization procedures. Therefore, it has a wide utility in many applications such as shape matching, classification, and recognition. Our experiments on 3D shapes demonstrate that the salient keypoints and local feature descriptors are robust and stable to noisy input and insensitive to resolution change. We have applied our technique to the tasks of 3D shape snatching, and the experimental results showed good performance and the effectiveness of this new method. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Hua, Jing] Wayne State Univ, Graph & Imaging Lab, Detroit, MI 48202 USA.
C3 Wayne State University
RP Hua, J (corresponding author), Wayne State Univ, Graph & Imaging Lab, 5143 Cass Ave,431 State Hall, Detroit, MI 48202 USA.
EM jinghua@wayne.edu
RI Zou, Guangyu J/C-5946-2013
FU Direct For Computer & Info Scie & Enginr [0830183] Funding Source:
   National Science Foundation; Direct For Computer & Info Scie & Enginr;
   Division Of Computer and Network Systems [0751045] Funding Source:
   National Science Foundation; Div Of Information & Intelligent Systems
   [0830183] Funding Source: National Science Foundation
CR Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Gatzke T, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P244, DOI 10.1109/SMI.2005.13
   Gu XF, 2004, IEEE T MED IMAGING, V23, P949, DOI 10.1109/TMI.2004.831226
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kimmel R, 1997, GRAPH MODEL IM PROC, V59, P365, DOI 10.1006/gmip.1997.0442
   Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Li XC, 2005, PROCEEDINGS OF THE 2005 CONFERENCE OF SYSTEM DYNAMICS AND MANAGEMENT SCIENCE, VOL 1, P217
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Liu Y., 2006, Computer Vision and Pattern Recognition, P2025, DOI DOI 10.1109/CVPR.2006.278
   Liu Y.-S., 2007, Proceedings of the ACM Symposium on Solid and Physical Modeling, P277, DOI DOI 10.1145/1236246.1236285
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Novatnack J, 2007, IEEE I CONF COMP VIS, P2001
   Pauly M, 2006, ACM T GRAPHIC, V25, P177, DOI 10.1145/1138450.1138451
   Razdan A, 2005, COMPUT AIDED DESIGN, V37, P1481, DOI 10.1016/j.cad.2005.03.003
   Shilane P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243981
   Shilane P, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P108
   Wang S, 2007, IEEE T PATTERN ANAL, V29, P1209, DOI 10.1109/TPAMI.2007.1050
   Yamauchi H, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P265
   ZHANG D.-Q., 2004, PROC ACM INT C MULTI, P877, DOI DOI 10.1145/1027527.1027730
   ZOU G, 2007, P C MED IM COMP COMP, P367
NR 23
TC 26
Z9 35
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 399
EP 410
DI 10.1002/cav.244
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200022
DA 2024-07-18
ER

PT J
AU Liu, SU
   Wang, ZY
   Gong, Z
   Huang, L
   Peng, QS
AF Liu, Shiguang
   Wang, Zhangye
   Gong, Zheng
   Huang, Lei
   Peng, Qunsheng
TI Physically based animation of sandstorm
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE sandstorm; natural phenomena simulation; physically based animation;
   Multi-Fluid Solver; GPU
ID DYNAMICS
AB This paper describes a physically based method for modeling and animating sandstorm, a type of disastrous natural phenomenon. The method adopts a relatively stable incompressible multiple fluid model to simulate the motion of air, sand, and dust particles. The wind field of sandstorm is established based on Reynold-average Navier-Stokes equations. The sand and dust particle flow is therefore computed taking interaction among the wind, sand, and dust particles into account. To accelerate the modeling process of a dynamic sandstorm scene, a special Multi-Fluid Solver is designed and implemented on GPU. Various illumination effects of sandstorm scenes can be simulated by spectral sampling scattering calculation. Animations of realistic sandstorms occurring in desert and urban areas based on our model are demonstrated. Compared with the real sandstorm photos, our simulated results are satisfactory. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CADCG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Wang, ZY (corresponding author), Zhejiang Univ, State Key Lab CADCG, Hangzhou 310027, Peoples R China.
EM zywang@cad.zju.edu.cn
RI Huang, Li/IUQ-0909-2023; HUANG, LING/HTR-1819-2023; huang,
   lei/GQP-8739-2022; Zhou, Hong/JKJ-1067-2023
CR [Anonymous], 1941, PHYS BLOWN SAND DESE
   Bell N., 2005, P 2005 ACM SIGGRAPH, P77, DOI DOI 10.1145/1073368.1073379
   BENES B, 2004, P WSCG, P17
   Clavet S., 2005, SCA '05, P219, DOI DOI 10.1145/1073368.1073400
   Fan Z., 2005, ACM SIGGRAPHEUROGRAP, P245
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   FELDMAN BE, 2003, P ACM SIGGRAPH 2003, P708
   Génevaux O, 2003, PROC GRAPH INTERF, P31
   HANKIN EH, 1921, INDIA METEOROLOGICAL
   Hong JM, 2003, COMPUT GRAPH FORUM, V22, P253, DOI 10.1111/1467-8659.00672
   IDSO SB, 1972, B AM METEOROL SOC, V53, P930, DOI 10.1175/1520-0477(1972)053<0930:AAH>2.0.CO;2
   Ihm Insung., 2004, Proceedings of the 2004 ACM SIGGRAPH/ Eurographics symposium on Computer animation, SCA '04, P203
   JAKEL D, 1997, COMPUT GRAPH FORUM, V16, P201
   Joseph P. V., 1980, Mausam, V31, P431
   Liu Shi-guang, 2006, Journal of Zhejiang University (Science), V7, P1099, DOI 10.1631/jzus.2006.A1099
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   MARBLE FE, 1970, ANNU REV FLUID MECH, V2, P397, DOI 10.1146/annurev.fl.02.010170.002145
   Mizuno R, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P440, DOI 10.1109/PCCGA.2003.1238291
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   Onoue K, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P427, DOI 10.1109/PCCGA.2000.883978
   Premoze S, 2003, COMPUT GRAPH FORUM, V22, P401, DOI 10.1111/1467-8659.00687
   Prigozhin L, 1999, PHYS REV E, V60, P729, DOI 10.1103/PhysRevE.60.729
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   VANDEHULSTT HC, 1957, LIGHT SCATTERING SMA
   Zhao Y, 2006, COMPUT GRAPH-UK, V30, P519, DOI 10.1016/j.cag.2006.03.009
   ZHU HB, 2006, P COMPUTER ANIMATION, P403
   Zingg A. W., 1949, Agric. Engng., V30, P11
NR 28
TC 8
Z9 14
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 259
EP 269
DI 10.1002/cav.190
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000005
DA 2024-07-18
ER

PT J
AU Douze, M
   Charvillat, V
AF Douze, Matthijs
   Charvillat, Vincent
TI Real-time generation of augmented video sequences by background tracking
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 2D augmented reality; background tracking; matrix downdating
ID MODELS
AB We present a real-time system that outputs a multi-layer augmented video from a normal video stream. The input sequence is captured in a known environment: a panoramic image (the reference background) is provided before shooting. We use background tracking to register each input frame with this reference, and background subtraction to segment the foreground objects. Our background tracking method is a coarse-to-fine integration of three state-of-the-art algorithms that we make resistant to occlusions. In particular, we introduce an algebraic technique to properly adapt the Jurie and Dhome (ID) tracker (the most robust of them). We report experimental results on real and synthetic data which validate our approach. We generate our augmented video sequences by compositing layers: a natural or synthetic background and several natural or synthetic foregrounds. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 INRIA, LEAR Grp, Grenoble, France.
C3 Inria
RP Douze, M (corresponding author), CNRS, UMR, IRIT, Site ENSEEIHT,2 Rue Camichel, F-31071 Toulouse, France.
EM douze@enseeiht.fr
CR BARTOLI A, 2004, COMPUTER ANIMATION V, V15, P511
   BJOORCK A, 1996, NUMERICAL METHODS LE
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   DEHAIS C, 2004, P INT C PATT REC CAM
   Dennis JE., 1996, NUMERICAL METHODS UN
   Golub G.H., 1991, MATRIX COMPUTATIONS, Vsecond
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Huber Peter J, 2011, ROBUST STAT, P1248
   IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982
   Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625
   Kanatani K, 2004, IEEE T PATTERN ANAL, V26, P1307, DOI 10.1109/TPAMI.2004.93
   LIU Q, 2002, P ACM MULT JUAN LES
   Lu Y, 2003, IEEE T CIRC SYST VID, V13, P394, DOI 10.1109/TCSVT.2003.811607
   MASSON L, 2004, P INT C PATT REC CAM
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Pereira F., 2002, IMSC Press multimedia series
   Rogers D.F., 1985, PROCEDURAL ELEMENTS
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   SIMON G, 2000, INT S AUGM REAL OCT
   SUGAYA Y, 2004, P S SENS VIA IM INF
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
NR 23
TC 4
Z9 4
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2006
VL 17
IS 5
BP 537
EP 550
DI 10.1002/cav.116
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 111UX
UT WOS:000242481700004
DA 2024-07-18
ER

PT J
AU Wang, Y
   Liu, ZQ
   Zhou, LZ
AF Wang, Yi
   Liu, Zhi-Qiang
   Zhou, Li-Zhu
TI Key-styling: learning motion style for real-time synthesis of 3D
   animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion synthesis; motion capture data; neural networks; self-organizing
   mixture network
ID MODELS
AB In this paper, we present a novel real-time motion synthesis approach that can generate 3D character animation with required style. The effectiveness of our approach comes from learning captured 3D human motion as a self-organizing mixture network (SOMN); of parametric Gaussians. The learned model describes the motion under the control of a vector variable called style variable, and acts as a probabilistic mapping from the low-dimensional style values to the high-dimensional 3D poses. We design a pose synthesis algorithm to allow the user to generate poses by specifying new style values. We also propose a novel motion synthesis method, the key-styling, which accepts a sparse sequence of key style values and interpolates a dense sequence of style values to synthesize an animation. Key-styling is able to produce animations that are more realistic and natural-looking than those synthesized With the traditional key-keyframing technique. Copyright (c) 2006 John Wiley & Soils, Ltd.
C1 Tsing Hua Univ, Dept Comp Sci, Grad Sch Shenzhen, Shenzhen 618055, Guang Dong Prov, Peoples R China.
C3 Tsinghua Shenzhen International Graduate School; Tsinghua University
RP Wang, Y (corresponding author), Tsing Hua Univ, Dept Comp Sci, Grad Sch Shenzhen, Shenzhen 618055, Guang Dong Prov, Peoples R China.
EM yi.wang.2005@gmail.com
RI Joon, Jong/B-3672-2010
CR Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   BRAND M, 1999, ARTIFICIAL INTELLIGE, V7
   Gales M.J., 1993, The theory of segmental hidden Markov models
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   KOHONEN T, 2001, SELFORGANIZING MAPS
   LAWRENCE ND, 2004, P 16 NIPS
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   Ormoneit D, 1998, IEEE T NEURAL NETWOR, V9, P639, DOI 10.1109/72.701177
   Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
   Yin H., 1997, P WORKSH SELF ORG MA, P304
   Yin HJ, 2001, IEEE T NEURAL NETWOR, V12, P405, DOI 10.1109/72.914534
NR 12
TC 4
Z9 9
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 229
EP 237
DI 10.1002/cav.126
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400010
DA 2024-07-18
ER

PT J
AU Zhang, GF
   Qin, XY
   An, XB
   Chen, W
   Bao, HJ
AF Zhang, Guofeng
   Qin, Xueying
   An, Xiaobo
   Chen, Wei
   Bao, Hujun
TI As-consistent-As-possible compositing of virtual objects and video
   sequences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE structure and motion recovery; 3D reconstruction; multi-baseline stereo;
   Augmented Video; interaction
ID 3-D RECONSTRUCTION
AB We present an efficient approach that merges the virtual objects into video sequences taken by a freely moving camera in a realistic manner. The composition is visually and geometrically consistent through three main steps. First, a robust camera tracking algorithm based oil key frames is proposed, Which precisely recovers the focal length with a novel multi-frame strategy. Next, the concerned 3D models of the real scenes are reconstructed by means of all extended multi-baseline algorithm. Finally, the virtual objects in the form of 3D models are integrated into the real scenes, with special cares on the interaction consistency including shadow casting, occlusions, and object animation. A variety of experiments have been implemented, which demonstrate he robustness and efficiency of our approach. Copyright (c) 2006 Joint Wiley & Sons, Ltd.
EM xyqin@cad.zju.edu.cn
RI Chen, Wei/AAR-9817-2020; Qin, Xueying/AAM-8775-2021
OI Qin, Xueying/0000-0003-0057-295X
CR [Anonymous], 2001, P ACM S VIRTUAL REAL
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   CHUANG YY, 2003, P ACM SIGGRAPH 2003, P494
   Debevec P., 1998, SIGGRAPH98, P189, DOI DOI 10.1145/280814.280864
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzgibbon AW, 2003, INT S VIDEO COMP, V5, P18
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   KOCH R, 1998, P 5 EUR C COMP VIS, V1, P55
   Lepetit V, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P137, DOI 10.1109/ISAR.2000.880937
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Y, 2004, IEEE T SYST MAN CY C, V34, P532, DOI 10.1109/TSMCC.2004.829300
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   Papagiannakis G, 2005, COMPUT ANIMAT VIRT W, V16, P11, DOI 10.1002/cav.53
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   Qin XY, 2002, IEEE COMPUT GRAPH, V22, P68, DOI 10.1109/38.974520
   Sato T, 2002, INT J COMPUT VISION, V47, P119, DOI 10.1023/A:1014537706773
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53
   SMITH AR, P ACM SIGGRAPH 1996, P259
   TRIGGS B, 1991, WORKSH VIS ALG, P298
   ZHANG G, P PAC GRAPH 2005, P78
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
   Zhang ZY, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P343
NR 24
TC 5
Z9 7
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 305
EP 314
DI 10.1002/cav.134
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400017
DA 2024-07-18
ER

PT J
AU Pettre, J
   Laumond, JP
AF Pettre, J
   Laumond, JP
TI A motion capture-based control-space approach for walking mannequins
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE digital mannequins; locomotion control; motion capture; motion blending;
   motion planning
ID COMPUTER ANIMATION
AB Virtual mannequins need to navigate in order to interact with their environment. Their autonomy to accomplish navigation tasks is ensured by locomotion controllers. Control inputs can be user-defined or automatically computed to achieve high-level operations (e.g. obstacle avoidance). This paper presents a locomotion controller based on a motion capture edition technique. Controller inputs are the instantaneous linear and angular velocities of the walk. Our solution works in real time and supports at any time continuous changes of inputs. The controller combines three main components to synthesize locomotion animations in a four-stage process. First, the Motion Library stores motion capture samples. Motion captures are analysed to compute quantitative characteristics. Second, these characteristics are represented in a linear control space. This geometric representation is appropriate for selecting and weighting three motion samples with respect to the input state. Third, locomotion cycles are synthesized by blending the selected motion samples. Blending is done in the frequency domain. Lastly, successive postures are extracted from the synthesized cycles in order to complete the animation of the moving mannequin. The method is demonstrated in this paper in a locomotion-planning context. Copyright (C) 2006 John Wiley & Sons, Ltd.
C1 CNRS, LAAS, F-31077 Toulouse, France.
C3 Centre National de la Recherche Scientifique (CNRS)
RP Laumond, JP (corresponding author), CNRS, LAAS, 7 Ave Colonel Roche, F-31077 Toulouse, France.
EM jpl@laas.fr
RI Pettré, Julien/AAB-2590-2022
CR ALEXANDER RM, 1984, INT J ROBOT RES, V3, P49, DOI 10.1177/027836498400300205
   [Anonymous], SIMULATING HUMANS CO
   [Anonymous], 2012, Robot Motion Planning
   BECKETT R, 1968, Journal of Biomechanics, V1, P147, DOI 10.1016/0021-9290(68)90017-1
   Bernshtein N.A., 1967, The co-ordination and regulation of movements
   Bezier Pierre., 1986, Courbes et Surfaces
   Boulic R., 1990, Visual Computer, V6, P344, DOI 10.1007/BF01901021
   Boulic R, 1996, COMPUT GRAPH, V20, P693, DOI 10.1016/S0097-8493(96)00043-X
   Boulic R., 2004, J. Game Develop., V1, P29
   BRUDERLIN A, 1995, P SIGGRAPH 95
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   DELAUNAY BN, 1924, P INT MATH C TOR
   Earnshaw R, 1998, IEEE COMPUT GRAPH, V18, P20, DOI 10.1109/MCG.1998.708557
   FALOUTSOS P, 2001, P ACM SIGGRAPH 2001
   GIRARD M, 1991, P IEEE INT C ROB AUT
   GLARDON P, 2004, P COMP AN SOC AG CAS
   HODGINS JK, 1995, P ACM SIGGRAPH
   KAVRAKI L, 1996, P IEEE T ROB AUT
   Khatib O, 2002, COMMUN ACM, V45, P46, DOI 10.1145/504729.504753
   KOVAR L, 2002, P SIGGRAPH 02
   KOVAR L, 2002, P ACM SIGGRAPH S COM
   KOVAR L, 2003, P ACM SIGGRAPH S COM
   LAMIRAUX F, 1997, 5 INT S EXP ROB ISER
   Laumond J.- P., 1998, LECT NOTES CONTROL I, V229
   LEE J, 2002, P SIGGRAPH 02
   MAGNENATTHALMAN.N, 1996, INTERACTIVE COMPUTER
   MCMAHON TA, 1984, INT J ROBOT RES, V3, P4, DOI 10.1177/027836498400300202
   MENARDAIS S, 2004, ACM SIGGRAPH EUROGRA
   Multon F, 1999, J VISUAL COMP ANIMAT, V10, P39, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<39::AID-VIS195>3.0.CO;2-2
   Parent Rick., 2001, Computer animation: algorithms and techniques
   PARK S, 2002, P 2002 ACM SIGGRAPH
   PETTRE J, 2003, ACM SIGGRAPH EUR S C
   PETTRE J, 2003, THESIS U TOULOUSE 3
   PETTRE J, 2002, IEEE RSJ INT C INT R
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Sack J.-R., 2000, HDB COMPUTATIONAL GE
   SHILLER Z, 2001, P IEEE INT C ROB AUT
   SIMEON T, 2001, 4 INT S ASS TASK PLA
   SUN HC, 2001, P SIGGRAPH 01
   TOWNSEND MA, 1972, J BIOMECH, V5, P71, DOI 10.1016/0021-9290(72)90020-6
   UNUMA M, 1995, P SIGGRAPH 95
   Watt A., 1992, ADV ANIMATION RENDER
   WILEY D, 1997, P IEEE VIRT REAL ANN
   WITKIN A, 1995, P SIGGRAPH 95
   WITKIN A, 1988, P ACM SIGGRAPH
   YAMANE K, 2004, SPR TRA ADV ROBOT, V9, P1
   ZELTZER D, 1982, IEEE COMPUT GRAPH, V2, P53
NR 47
TC 16
Z9 20
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2006
VL 17
IS 2
BP 109
EP 126
DI 10.1002/cav.76
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040JO
UT WOS:000237375000004
DA 2024-07-18
ER

PT J
AU Inostroza, P
AF Inostroza, P
TI Real-time update of eye features on the 3D head model texture
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Cyberworlds (CW 2003)
CY DEC 03-05, 2003
CL SINGAPORE, SINGAPORE
SP Nanyang Technol Univ, Sch Comp Engn
DE eye tracking; eye animation; videoclone
ID FACE TRACKING; ANIMATION
AB In this paper, a real-time tracking/synthesis loop is proposed to animate the eye texture of a 3D head model using a video camera. The user's eyes, captured by a video camera, are tracked by means of a frame-rate pupil detector technique, based on an active illumination scheme. A small area of interest is selected around each pupil detected in the video. These areas contain the eye and eyebrow features. Substituting the captured areas on the texture Of the 3D model, animation of the eyes and eyebrows is created. To avoid the 'collage' effect, the extracted areas are colour-corrected, stretched and blended with the texture. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Univ Chile, Dept Ciencias Computac, Santiago, Chile.
C3 Universidad de Chile
RP Inostroza, P (corresponding author), Univ Chile, Dept Ciencias Computac, Av Blanco Encalada 2120,Piso 3,Casilla 2777, Santiago, Chile.
EM Patricio.Inostroza@dcc.uchile.cl
CR Ahlberg J, 2003, INT J IMAG SYST TECH, V13, P8, DOI 10.1002/ima.10042
   [Anonymous], THESIS U KARLSRUHE
   [Anonymous], P 31 AS C SIGN SYST
   CROWLEY JL, 1997, COMPUTER VISION PATT
   Eisert P, 1998, IEEE COMPUT GRAPH, V18, P70, DOI 10.1109/38.708562
   ELISEI F, 1999, INT WORKSH SYNTH NAT, P25
   ESCHER M, 1997, COMPUTER ANIMATION 9
   ESSA I, 1996, P COMP AN 96 GEN SWI
   Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   LEUNG WH, 2000, IEEE INT C MULT EXP
   Lin IC, 2002, IEEE COMPUT GRAPH, V22, P72, DOI 10.1109/MCG.2002.1046631
   Morimoto C., 1998, PUPIL DETECTION TRAC
   Otsuka Takahiro, 1998, P INT C ADV MULT CON, P433
   PERLIN K, 2004, RESPONSIVE FACE JAVA
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Scassellati B, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P969
   SCHMIDT R, 2000, LECT NOTES COMPUTER, V1793, P127
   SCHWERDT K, 2000, 4 IEEE INT C AUT FAC
   TAKACS B, 1999, INT WORKSH REC AN TR
   Valente S, 2000, IEEE MULTIMEDIA, V7, P34, DOI 10.1109/93.839309
   Williams L., 1990, Proceedings of SIGGRAPH, V24, P235
NR 22
TC 0
Z9 0
U1 0
U2 0
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2005
VL 16
IS 2
BP 129
EP 136
DI 10.1002/cav.64
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 926BW
UT WOS:000229098800006
DA 2024-07-18
ER

PT J
AU Lee, DH
   Jung, SK
AF Lee, DH
   Jung, SK
TI Multiple path-based approach to image-based street walkthrough
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Cyberworlds (CW 2003)
CY DEC 03-05, 2003
CL SINGAPORE, SINGAPORE
SP Nanyang Technol Univ, Sch Comp Engn
DE image-based rendering; walkthrough; disparity-based view warping;
   capture configuration
AB linage-based rendering for walkthrough in the virtual environment has many advantages should over the geometry-based approach, due to the fast construction of the environment and photo-realistic rendered results. In image-based rendering technique, rays from a set of input images are collected and a novel view image is rendered by the resampling of the stored rays. Current such techniques, however, are limited to a closed capture space. In this paper, we propose a multiple path-based capture configuration that can handle a large-scale scene and a disparity-based warping method for novel view generation. To acquire the disparity image, we segment the input image into vertical slit segments using a robust and inexpensive way of detecting vertical depth discontinuity. The depth slit segments, instead of depth pixels, reduce the processing time for novel view generation. We also discuss a dynamic cache strategy that supports real-time walkthroughs in large and complex street environments. The efficiency of the proposed method is demonstrated with several experiments. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Kyungpook Natl Univ, Dept Comp Engn, Taegu 702701, South Korea.
C3 Kyungpook National University
RP Kyungpook Natl Univ, Dept Comp Engn, 1370 Sangyuk Dong, Taegu 702701, South Korea.
EM skjung@knu.ac.kr
RI Jung, Soon Ki/P-7687-2018
OI Jung, Soon Ki/0000-0003-0239-6785
CR Adelson E.H., 1991, Computational Models of Visual Processing, P3
   Aliaga DG, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P331, DOI 10.1109/VISUAL.2002.1183792
   Aliaga DG, 2001, COMP GRAPH, P443, DOI 10.1145/383259.383311
   Aliaga DG, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P127, DOI 10.1109/ICCV.2001.937508
   BUELER C, 2001, ACM SIGGRAPH, P425
   Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   GOTZ D, 2002, ACM MULTIMEDIA
   HIROSE M, 1999, P INT S MIX REAL, P183
   HUANG HC, 1998, ACM S VIRT REAL SOFT, P9
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   MCMILLAN L, 1995, ACM SIGGRAPH, P32
   McMillan L, 1997, IMAGE BASED APPROACH
   Popescu V, 2000, COMP GRAPH, P433, DOI 10.1145/344779.344979
   Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573
   Takahashi T, 2000, PROC CVPR IEEE, P296, DOI 10.1109/CVPR.2000.854815
   Yang J, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P77, DOI 10.1109/INFVIS.2002.1173151
NR 17
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2005
VL 16
IS 2
BP 85
EP 95
DI 10.1002/cav.62
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 926BW
UT WOS:000229098800002
DA 2024-07-18
ER

PT J
AU Yuan, X
   Chee, YS
AF Yuan, X
   Chee, YS
TI Design and evaluation of Elva: an embodied tour guide in an interactive
   virtual art gallery
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Cyberworlds (CW 2003)
CY DEC 03-05, 2003
CL SINGAPORE, SINGAPORE
SP Nanyang Technol Univ, Sch Comp Engn
DE embodied conversational agent; autonomy; believability; human-computer
   interaction; virtual world
AB The technology of embodied conversational agents provides an attractive approach to achieving natural human-computer interaction if the interaction design is handled sensitively. In view of this, we designed and developed an embodied tour guide, Elva, 'who' is able to engage conversationally with users about gallery exhibits and also capable of behaving non-verbally using gesture and facial expression. The research focuses on the attributes of agent autonomy and believability. To achieve autonomy, we present a three-layer architectural design to ensure appropriate coupling between the agent's perception and action. With regard to believability, we utilize the notion of schema to support structured and coherent verbal behaviours. We also pay careful attention to the design of non-verbal interactions that establish social facts within the virtual world. A user study was performed to evaluate user satisfaction and agent believability. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
C3 National University of Singapore
RP Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
EM yuanxian@comp.nus.edu.sg
CR Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P1
   CHEE YS, 2002, CSCL 2002, P687
   FONER LN, 2000, HUMAN COGNITION SOCI, P323
   Johnson W.L., 2000, INT J ARTIFICIAL INT, V11, P47
   LAAKSOLAHTI J, 2001, 2 INT C INT AG TECHN, P30
   LEE SI, 2001, INTELLIGENT AGENT TE, P305
   Lester JC, 2000, EMBODIED CONVERSATIONAL AGENTS, P123
   PELACHAUD C, 2002, AAMAS 02, P758
   Sloman A., 2000, HUMAN COGNITION SOCI, P163
NR 9
TC 12
Z9 12
U1 2
U2 16
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2005
VL 16
IS 2
BP 109
EP 119
DI 10.1002/cav.65
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 926BW
UT WOS:000229098800004
DA 2024-07-18
ER

PT J
AU Kim, T
   An, I
   Yoon, SE
AF Kim, Taeyoung
   An, Inkyu
   Yoon, Sung-eui
TI Inexpensive indoor acoustic material estimation for realistic sound
   propagation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE acoustic materials; sound rendering; virtual reality
ID IMPULSE RESPONSES; ABSORPTION; OPTIMIZATION; COEFFICIENTS; REFLECTION;
   SIMULATION; IMPEDANCE; MODEL
AB For the realistic and immersive experience in a virtual environment, it is important to estimate and reflect the acoustic characteristic of the real indoor scenes. This article proposes a method of directly measuring the reflection coefficient of a surface, which is an acoustic characteristics in the real environment. Because expensive optimization-based studies that mainly aim to reproduce recorded sounds indirectly estimate acoustic materials, new estimates are required whenever the actual environment changes. Our approach utilizes the method of the acoustics field to enable anyone to easily and directly measure the reflection coefficient of a real environment and generate sound in a virtual environment. We obtain the impulse response (IR) for the target surface, separate the direct sound and the reflected sound, and calculate the reflection coefficient for each surface. The measurement of the IR and the reflection coefficient calculation takes about 2 s. Our result produces a sound with a similar reverberation time to the sound recorded in the real environment.
C1 [Kim, Taeyoung; An, Inkyu; Yoon, Sung-eui] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Yoon, SE (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
EM taeyoungkim@kaist.ac.kr; inkyu.an@kaist.ac.kr; sungeui@kaist.edu
OI Kim, Taeyoung/0000-0002-1894-6596
FU National Research Foundation of Korea (NRF) [2019R1A2C3002833]; Korea
   government (MSIT)
FX This work was supported by the National Research Foundation of Korea
   (NRF, No. 2019R1A2C3002833) Grant funded by the Korea government (MSIT).
CR ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   BARRON M, 1981, J SOUND VIB, V77, P211, DOI 10.1016/S0022-460X(81)80020-X
   Begault D.R., 2000, 3 D SOUND VIRTUAL RE
   BORISH J, 1984, J ACOUST SOC AM, V75, P1827, DOI 10.1121/1.390983
   Bork I, 2000, ACUSTICA, V86, P943
   Brandao E, 2015, ACTA ACUST UNITED AC, V101, P443, DOI 10.3813/AAA.918840
   British Standard E., ISO 3382-2: 2008. Acoustics-measurement of room acoustic
   Chen K., 2015, COMPUT VIS MEDIA, V1, P267, DOI DOI 10.1007/S41095-015-0029-X
   Ciskowski R.D., 1991, BOUNDARY ELEMENT MET
   Cobo P, 2007, APPL ACOUST, V68, P820, DOI 10.1016/j.apacoust.2006.04.007
   CRAMOND AJ, 1984, J ACOUST SOC AM, V75, P382, DOI 10.1121/1.390482
   de Normalizacion OI., 1993, ISO 9613-1: 1993
   Embrechts JJ, 2000, J ACOUST SOC AM, V107, P2068, DOI 10.1121/1.428489
   Ermann M., 2015, Architectural Acoustics Illustrated
   Farina A., 2007, AUDIO ENG SOC CONVEN
   Farina Angelo, 2000, 108 AES CONVENTION
   Foster S., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P929
   Funkhouser T., 1998, P 25 ANN C COMPUTER, P21, DOI DOI 10.1145/280814.280818
   Gelfand S., 2010, Essentials of audiology
   Guidorzi P, 2015, ENRGY PROCED, V78, P1611, DOI 10.1016/j.egypro.2015.11.236
   Härmä A, 2004, J AUDIO ENG SOC, V52, P618
   HESS HM, 1990, J ACOUST SOC AM, V87, P1975, DOI 10.1121/1.399325
   INGARD U, 1951, J ACOUST SOC AM, V23, P509, DOI 10.1121/1.1906796
   Jeong CH., 2016, Uncertainty of input data for room acoustic simulations. Proceedings of the Bi-Annual Baltic-Nordic Acoustic Meeting
   Jeong CH, 2013, J ACOUST SOC AM, V133, P3951, DOI 10.1121/1.4802647
   Johansson M., 1999, The Hilbert Transform. Mathematics. Master's thesis. Vaxjo University
   Kuipers ER, 2012, J ACOUST SOC AM, V132, pEL236, DOI 10.1121/1.4745839
   Kuttruff H., 2016, Room Acoustics
   Lanoye R, 2006, J ACOUST SOC AM, V119, P2826, DOI 10.1121/1.2188821
   Lanoye R., 2004, a practical device to determine the reflection coefficient of acoustic materials in-situ based on a Microflown and microphone sensor
   Larsson P, 2010, HUM-COMPUT INT-SPRIN, P143, DOI 10.1007/978-1-84882-733-2_8
   Li D, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201391
   Liu SG, 2021, Arxiv, DOI arXiv:2011.05538
   Mehra R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451245
   MOMMERTZ E, 1995, APPL ACOUST, V46, P251, DOI 10.1016/0003-682X(95)00027-7
   Monks M, 2000, IEEE COMPUT GRAPH, V20, P76, DOI 10.1109/38.844375
   Pelzer S., 2013, Inversion of a room acoustics model for the determination of acoustical surface properties in enclosed spaces. Proceedings of meetings on acoustics ICA 2013. vol. 19. Acoustical Society of America
   Raghuvanshi N, 2009, IEEE T VIS COMPUT GR, V15, P789, DOI [10.1109/TVCG.2009.27, 10.1109/TVCG.2009.28]
   Rossing TD., 2007, Springer handbook of acoustics, V1
   Sakamoto S., 2006, J Acoust Soc Am, V120, P3008
   Saksela K, 2015, J ACOUST SOC AM, V137, pEL274, DOI 10.1121/1.4915063
   Schissler C., 2011, Gsound: interactive sound propagation for games. Proceedings of the Audio Engineering Society Conference: 41st International Conference: Audio for Games. Audio Engineering Society
   Schissler C, 2018, IEEE T VIS COMPUT GR, V24, P1246, DOI 10.1109/TVCG.2017.2666150
   Standard B., BS EN ISO 354: 2003. Acoustics-measurement of sound absorption in a reverberation room
   Standard S., 2001, EN ISO 10534-2, determination of sound absorption coefficient and acoustic impedance with the interferometer
   Tang ZY, 2020, IEEE T VIS COMPUT GR, V26, P1991, DOI 10.1109/TVCG.2020.2973058
   Taylor MicahT., 2009, MM 09, P271
   Thompson LL, 2006, J ACOUST SOC AM, V119, P1315, DOI 10.1121/1.2164987
   Traer J, 2016, P NATL ACAD SCI USA, V113, pE7856, DOI 10.1073/pnas.1612524113
   Tsingos N, 2001, COMP GRAPH, P545, DOI 10.1145/383259.383323
   VORLANDER M, 1989, J ACOUST SOC AM, V86, P172, DOI 10.1121/1.398336
   Vorlander M., 2020, Auralization, P171
NR 52
TC 0
Z9 0
U1 4
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
AR e2131
DI 10.1002/cav.2131
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:001132545000004
DA 2024-07-18
ER

PT J
AU Zhu, ZP
   You, LH
   Zhang, JJ
AF Zhu, Zaiping
   You, Lihua
   Zhang, Jian Jun
TI Vectorizing binary image boundaries with symmetric shape detection,
   bisection and optimal parameterization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE affine transformation; Bezier curve fitting; binary image boundaries;
   bisection; optimal parameterization; symmetric detection; vectorization
ID CURVE
AB Binary image boundary vectorization is the process of converting raster images into vector images represented with a sequence of Bezier curves. Two main factors in reconstructing parametric curves are to approximate the underlying structure of the boundaries as much as possible while using as few curves as possible. Existing methods do not perform well when considering both of these two main factors. In this article, we mimic the process of human vectorizing image boundaries by first segmenting the boundary points into multiple segments with the corner points. For the boundary points in each segment, we adopt the bisection method to find the largest number of points, which a single curve can fit. More curves will be added if the fitting error is larger than a predefined threshold. The process is repeated until all the points in the segment are fitted, thus minimizing the number of Bezier curves. Besides, symmetric image boundaries can be detected and used to further decrease the number of curves required. Our method can also choose the optimal parameterization method case by case to further reduce the fitting error. We make a comparison with both new and classical methods and show that our method outperforms them.
C1 [Zhu, Zaiping; You, Lihua; Zhang, Jian Jun] Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
C3 Bournemouth University
RP Zhu, ZP (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
EM s5319266@bournemouth.ac.uk
OI Zhu, Zaiping/0000-0001-5810-8346
FU European Union [778035]; China Scholarship Council; Marie Curie Actions
   (MSCA) [778035] Funding Source: Marie Curie Actions (MSCA)
FX PDE-GIR project which has received funding from the European Union
   Horizon 2020 research and innovation programme under the Marie
   Skodowska-Curie Grant agreement No. 778035. Zaiping Zhu is also
   sponsored by the China Scholarship Council.
CR [Anonymous], IND LEAD VECT GRAPH
   Chang HH, 1998, PATTERN RECOGN, V31, P1747, DOI 10.1016/S0031-3203(98)00045-4
   Culjak I., 2012, 2012 35th International Convention on Information and Communication Technology, Electronics and Microelectronics, P1725
   Fang JJ, 2013, COMPUT AIDED DESIGN, V45, P1005, DOI 10.1016/j.cad.2013.01.005
   Farin G., 2014, Curves and Surfaces for Computer-Aided Geometric Design: A Practical Guide
   FontLab, US
   Gálvez A, 2013, APPL SOFT COMPUT, V13, P1491, DOI 10.1016/j.asoc.2012.05.030
   Gonczarowski J., C P RAST IM DIG TYP
   He LF, 2017, PATTERN RECOGN, V70, P25, DOI 10.1016/j.patcog.2017.04.018
   He YC, 2023, IMAGE PROCESS ON LIN, V13, P22, DOI 10.5201/ipol.2023.401
   Hoshyari S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201312
   Iglesias A., P 2015 INT C CYB
   Joshi P., P INT C ADV ENG TECH
   Kirsanov A., P 2010 INT FOR STRAT
   Kopf J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964994
   Magic V.,, US
   Mazzoleni A., US
   McNamee JM, 2013, STUD COMPUT MATH, V16, P1
   Nadal C., P 10 INT C PATT REC
   Pal S, 2007, PATTERN RECOGN, V40, P2730, DOI 10.1016/j.patcog.2007.01.019
   PAVLIDIS T, 1983, ACM T GRAPHIC, V2, P1, DOI 10.1145/357314.357315
   Piegl L., 1997, The Nurbs Book, Vsecond
   Plass M., 1983, Computer Graphics, V17, P229, DOI 10.1145/964967.801153
   Sarfraz M, 2004, FUTURE GENER COMP SY, V20, P1327, DOI 10.1016/j.future.2004.05.024
   Schneider P.J., 1990, Graphics gems, V1, P612
   Shamsuddin SMH., P INT C COMP GRAPH I
   Skora D., P EUR WORKSH SKETCH
   Sun J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239462
   Xia T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618461
   Xie J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6695, DOI 10.1145/3025453.3025872
   Xiong XL, 2017, COMM COM INF SC, V693, P35, DOI 10.1007/978-3-319-64870-5_2
   Yang M, 2016, IEEE T VIS COMPUT GR, V22, P1063, DOI 10.1109/TVCG.2015.2440273
   Zhang Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122311984
   Zou JJ, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P225, DOI 10.1109/CGI.2001.934678
NR 34
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
AR e2191
DI 10.1002/cav.2191
EA MAY 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000991484400001
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Lin, H
   Xu, CC
   Liu, C
AF Lin, Hong
   Xu, Chenchen
   Liu, Chun
TI FAEC-GAN: An unsupervised face-to-anime translation based on edge
   enhancement and coordinate attention
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer vision; deep learning; generative adversarial networks
AB Animation is a widely loved artistic form with high abstraction and powerful expression. The task of image translation from face to anime involves complex geometric and texture transformations, and requires the generated images with clear lines. The existing unsupervised image translation frameworks are often ineffective for this task. According to the characteristics of animation image, we propose an animation translation method based on edge enhancement and coordinate attention, which is called FAEC-GAN. We design a novel edge discrimination network to identify the edge features of images, so that the generated anime images can present clear and coherent lines. And the coordinate attention module is introduced in the encoder to adapt the model to the geometric changes in translation, so as to produce more realistic animation images. In addition, our method combines the focal frequency loss and pixel loss, which can pay attention to both the frequency domain information and pixel information of the generated image to improve the visual effect of the image. The experimental results demonstrate that FAEC-GAN is superior to the state-of-the-art methods in the task of face-to-animation image translation.
C1 [Lin, Hong; Xu, Chenchen; Liu, Chun] Wuhan Univ Technol, Wuhan, Peoples R China.
   [Xu, Chenchen] Univ Technol, Sch Wuhan, Comp Sci & Technol, Wuhan, Peoples R China.
   [Liu, Chun] Univ Queensland, Res Comp Ctr, Brisbane, Australia.
C3 Wuhan University of Technology; University of Queensland
RP Liu, C (corresponding author), Wuhan Univ Technol, Wuhan, Peoples R China.
EM 1950380336@qq.com
OI Liu, Chun/0000-0003-0762-1080
CR Binkowski MikolajDougal J Sutherland., 2018, Demystifying mmd gans
   Chen R., 2020, REUSING DISCRIMINATO
   Chen Y, 2018, PROC CVPR IEEE, P9465, DOI 10.1109/CVPR.2018.00986
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Han YK, 2020, IEEE IC COMP COM NET
   Hensel M, 2017, ADV NEUR IN, V30
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang L., 2021, P IEEECVF INT C COMP
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kim J., 2019, U GAT IT UNSUPERVISE
   Li B, 2022, IEEE T MULTIMEDIA, V24, P4077, DOI 10.1109/TMM.2021.3113786
   Liu S, 2021, IEEE INT CONF COMP, DOI 10.1109/CIVEMSA52099.2021.9493584
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Mnih V, 2014, ADV NEUR IN, V27
   Nizan O., 2020, P IEEECVF C COMPUTER
   Rahaman N., 2018, SPECTRAL BIAS NEURAL
   Ran Yi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8214, DOI 10.1109/CVPR42600.2020.00824
   Shao X., 2021, ARXIV
   Song GX, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459771
   Tang H, 2023, IEEE T NEUR NET LEAR, V34, P1972, DOI 10.1109/TNNLS.2021.3105725
   Tao X., 2019, LANDMARK ASSISTED CY
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yu X., 2019, MULTI MAPPING IMAGE
   Zhao Y., 2020, ECCV, P800
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   US
NR 36
TC 1
Z9 1
U1 1
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2135
EA JAN 2023
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HA1F6
UT WOS:000906500200001
DA 2024-07-18
ER

PT J
AU Peng, C
   Tu, ZL
   Qiu, S
   Li, C
   Wang, CB
   Qin, H
AF Peng, Chen
   Tu, Zaili
   Qiu, Sheng
   Li, Chen
   Wang, Changbo
   Qin, Hong
TI Learning frequency-aware convolutional neural network for
   spatio-temporal super-resolution water surface waves
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE neural networks; super resolution; wave animation
AB As a usual component in virtual scenes, water surface plays an important role in various graphical applications, including special effects, video games, and virtual reality. Although recent years have witnessed significant progress based on Navier-Stokes equations and simplified water models, large-scale water surface waves with high-frequency visual details remain computationally expensive for interactive applications. This article proposes a novel frequency-aware neural network to synthesize consistent and detailed water surface waves from low-resolution input. At its core, our approach leverage the wavelet transformation theory over space, frequency and direction, and incremental supervision to decompose the 4D amplitude function into multiple smaller subproblems. Specifically, we first customize four subnetworks and corresponding loss functions for super-resolution of spatial resolution, temporal evolution, wave direction subdivision, and wave number, respectively. Then, to enforce the upsampling along each dimension orthogonal to each other, we introduce a cooperative training scheme to fine-tune and integrate the proposed subnetworks with carefully designed training dataset. Our method can visually enhance high-resolution spatial details, temporal coherence, interactions with complex boundaries, and various wave patterns with flexible control along multiple dimensions. Through extensive experiments, our method arrives at 13x$$ \times $$ speedup for 32x$$ \times $$ upsampling of various simulation scenarios. We also validate the effectiveness and robustness of our method to produce realistic water surface waves toward artistic innovation.
C1 [Peng, Chen; Tu, Zaili; Qiu, Sheng; Li, Chen; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Technol, 3663 North Zhongshan Rd, Shanghai, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 East China Normal University; State University of New York (SUNY)
   System; State University of New York (SUNY) Stony Brook
RP Li, C (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, 3663 North Zhongshan Rd, Shanghai, Peoples R China.
EM cli@cs.ecnu.edu.cn
OI Tu, Zaili/0000-0001-6316-473X
FU National Science Foundation of USA [IIS-1715985, IIS-1812606]; Natural
   Science Foundation of China [62002121, 62072183]
FX National Science Foundation of USA, Grant/Award Numbers: IIS-1715985,
   IIS-1812606; Natural Science Foundation of China, Grant/Award Numbers:
   62002121, 62072183
CR Bojsen-Hansen M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185549
   Bulat A, 2018, LECT NOTES COMPUT SC, V11210, P187, DOI 10.1007/978-3-030-01231-1_12
   Chentanez N., 2011, ACM T GRAPHIC, V30
   Chentanez N, 2012, IEEE T VIS COMPUT GR, V18, P1191, DOI 10.1109/TVCG.2012.86
   Enright D, 2002, J COMPUT PHYS, V183, P83, DOI 10.1006/jcph.2002.7166
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Fulton L, 2019, COMPUT GRAPH FORUM, V38, P379, DOI 10.1111/cgf.13645
   Gao Y, 2020, COMPUT GRAPH FORUM, V39, P180, DOI 10.1111/cgf.14010
   Hinsinger D., 2002, P 2002 ACM SIGGRAPH, P161
   Holden D., 2015, P SIGGRAPH AS TECH B, DOI DOI 10.1145/2820903.2820918
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Jeschke S, 2020, COMPUT GRAPH FORUM, V39, P47, DOI 10.1111/cgf.14100
   Jeschke S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073678
   Jeschke S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201336
   Kingma D. P., 2014, arXiv
   Li C, 2021, IEEE T VIS COMPUT GR, V27, P3867, DOI 10.1109/TVCG.2020.2991217
   Li LY, 2021, VISUAL COMPUT, V37, P2855, DOI 10.1007/s00371-021-02236-w
   Li T., 2020, PATTERN RECOGN, V107
   Luo R, 2020, IEEE T VIS COMPUT GR, V26, P1745, DOI 10.1109/TVCG.2018.2881451
   Ma PX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201334
   Mardani M., 2020, P INT C NEUR INF PRO
   MASTIN GA, 1987, IEEE COMPUT GRAPH, V7, P16, DOI 10.1109/MCG.1987.276961
   Mouassom LF, 2021, COMMUN NONLINEAR SCI, V102, DOI 10.1016/j.cnsns.2021.105942
   Oh YJ, 2021, COMPUT GRAPH FORUM, V40, P355, DOI 10.1111/cgf.142638
   Osher S, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P3, DOI 10.1007/0-387-21810-6_1
   Peng XB, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3197517.3201311, 10.1145/3450626.3459670]
   Qiu S, 2021, COMPUT GRAPH FORUM, V40, P242, DOI 10.1111/cgf.14270
   Runia TFH., P IEEE CVF C COMP VI
   Santesteban I, 2019, COMPUT GRAPH FORUM, V38, P355, DOI 10.1111/cgf.13643
   Setaluri Rajsekhar, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2661229.2661269
   Shi JJ, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1967
   Skrivan T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392466
   Tompson J, 2017, PR MACH LEARN RES, V70
   Um K, 2018, COMPUT GRAPH FORUM, V37, P171, DOI 10.1111/cgf.13522
   Wen Y, 2019, IEEE T IMAGE PROCESS, V28, P994, DOI 10.1109/TIP.2018.2874285
   Werhahn M, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340251
   Wiewel S, 2020, COMPUT GRAPH FORUM, V39, P15, DOI 10.1111/cgf.14097
   Winchenbach R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073713
   Wojtan C., 2011, ACM SIGGRAPH 2011 CO, P8, DOI [10.1145/2037636.2037644, DOI 10.1145/2037636.2037644]
   Xiao YW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417837
   Xie XG, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1896
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Zhang SF, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1758
   Zhu J, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1973
NR 44
TC 2
Z9 2
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2022
VL 33
IS 6
AR e2116
DI 10.1002/cav.2116
EA AUG 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6Z9LE
UT WOS:000842173000001
OA Bronze
DA 2024-07-18
ER

PT J
AU Agic, A
   Mandic, L
   Skorin-Kapov, L
AF Agic, Ana
   Mandic, Lidija
   Skorin-Kapov, Lea
TI The impact of locomotion techniques on user experience on virtual
   reality on light of different scene contrasts
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cybersickness; heart rate; locomotion techniques; virtual reality
ID MOTION SICKNESS; ENVIRONMENTS
AB Locomotion techniques are an important part of the virtual reality (VR) experience, as they enable a means of movement within simulated computer graphics. Studies have shown that locomotion techniques cause unpleasant effects related to cybersickness. In this article, we report on the results of a user study (N = 29) aimed to investigate and compare three types of locomotion techniques in VR in terms of their impact on cybersickness. The different locomotion techniques are tested in two different contrast scene settings, daytime and nighttime, to further explore the potential impact of scene contrast adjustments. For the evaluation of cybersickness, we used a questionnaire to obtain subjective ratings, and heart rate monitoring as an objective metric. Results show that a linear movement locomotion technique provokes the highest level of cybersickness, and that women have a higher heart rate as compared to men when navigating and interacting in a VR scene. Regarding the influence of scene contrast, results showed that scenes with daylight were better suited to participants in almost all tested scenarios. In addition to reported findings related to locomotion techniques and the impact on cybersickness, we highlight that a key contribution is the utilized test methodology.
C1 [Agic, Ana; Mandic, Lidija] Univ Zagreb, Fac Graph Arts, Zagreb, Croatia.
   [Skorin-Kapov, Lea] Univ Zagreb, Fac Elect Engn & Comp, Zagreb, Croatia.
C3 University of Zagreb; University of Zagreb
RP Agic, A (corresponding author), Univ Zagreb, Fac Graph Arts, Zagreb, Croatia.
EM ana.agic@grf.unizg.hr
RI Mandic, Lidija/HLH-6538-2023
OI Mandic, Lidija/0000-0002-2318-4856; Agic, Ana/0000-0002-1366-0281
FU Croatian Science Foundation [IP-2019-04-9793]
FX Croatian Science Foundation, Grant/Award Number: IP-2019-04-9793
CR Alqahtani AS, 2017, INT J ADV COMPUT SC, V8, P77
   [Anonymous], 2017, P 2017 INT MEAS C
   Arns L., 2002, THESIS LOWA STATE U
   Aron A., 2013, STAT PSYCHOL, P819
   Barrett J., 2004, Side effects of virtual environments: A review of the literature
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   BORST C, 1982, AM J PHYSIOL, V243, pH676, DOI 10.1152/ajpheart.1982.243.5.H676
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Brion M., 2018, P 5 INT C CONVERGENC
   Brunnstrom Kjell., 2017, Quality and User Experience, V2, P1, DOI DOI 10.1007/S41233-016-0003-0
   Cardoso JCS, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P319, DOI 10.1145/2993369.2996327
   Carnegie K, 2015, IEEE COMPUT GRAPH, V35, P34, DOI 10.1109/MCG.2015.98
   Carnegie Kieran., 2015, Mitigating visual discomfort on head mounted displays using estimated gaze dependent depth of field
   Chen Y, 2019, LIGHTING RES TECHNOL, V51, P820, DOI 10.1177/1477153518825387
   Chessa M, 2019, HUM-COMPUT INTERACT, V34, P51, DOI 10.1080/07370024.2016.1243478
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   EGAN D, 2016, EVALUATION HEART RAT
   Gavgani AM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182790
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Griffin NN, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P211, DOI 10.1145/3242671.3242707
   Hoeft R.M., 2003, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V47, P2137, DOI DOI 10.1177/154193120304702013
   Iskenderova A., 2017, DRUNK VIRTUAL REALIT, P561, DOI [10.1145/3116595.3116618, DOI 10.1145/3116595.3116618]
   Kelly HS., 2015, HDB VIRTUAL ENV DESI, V2, P1456, DOI [10.1201/b17360, DOI 10.1201/B17360]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kleinberger T., 2007, UNIVERSAL ACCESS HUM, V4555, P1075, DOI [10.1007/978-3-540-73281-5, DOI 10.1007/978-3-540-73281-5]
   Kline RB., 2005, PRINCIPLES PRACTICE, P384
   Kolasinski EugeniaM., 1995, Simulator sickness in virtual environments
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Medeiros D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P327, DOI 10.1145/2993369.2996348
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   Nabiyouni M., 2016, PROC ACM COMPANION I, P115, DOI DOI 10.1145/3009939.3010076
   Nichols S, 1997, PRESENCE-TELEOP VIRT, V6, P667, DOI 10.1162/pres.1997.6.6.667
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Perkis A., 2020, QUALINET White Paper on Definitions of Immersive Media Experience (IMEx)
   Prabhavathi K, 2014, J CLIN DIAGN RES, V8, pBE1, DOI 10.7860/JCDR/2014/9635.4771
   Rebenitsch L., 2015, XRDS: Crossroads, The ACM Magazine for Students, V22, P46, DOI [10.1145/2810054, DOI 10.1145/2810054]
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Regan C., 1995, VIRTUAL REAL-LONDON, V1, P17, DOI DOI 10.1007/BF02009710
   RYAN SM, 1994, J AM COLL CARDIOL, V24, P1700, DOI 10.1016/0735-1097(94)90177-5
   Schwind V., 2019, USING PRESENCE QUEST, P1
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Suma EA, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P245, DOI 10.1109/VR.2009.4811037
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vlahovic S, 2018, INT WORK QUAL MULTIM, P177
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 51
TC 0
Z9 0
U1 2
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2023
VL 34
IS 2
AR e2103
DI 10.1002/cav.2103
EA JUL 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D7UU4
UT WOS:000822669400001
DA 2024-07-18
ER

PT J
AU Chen, SC
   Liu, GT
   Wong, SK
AF Chen, Shao-Chieh
   Liu, Guan-Ting
   Wong, Sai-Keung
TI Generation of multiagent animation for object transportation using deep
   reinforcement learning and blend-trees
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation; blend-tree; multiagent; object transportation; reinforcement
   learning
ID NAVIGATION
AB This paper proposes a framework that integrates reinforcement learning and blend-trees to generate animation of multiple agents for object transportation. The main idea is that in the learning stage, policies are learned to control agents to perform specific skills, including navigation, pushing, and orientation adjustment. The policies determine the blending parameters of the blend-trees to achieve locomotion control of the agents. In the simulation stage, the policies are combined to control the agents to navigate, push objects, and adjust orientation of the objects. We demonstrated several examples to show that the framework is capable of generating animation of multiple agents in different scenarios.
C1 [Chen, Shao-Chieh; Liu, Guan-Ting; Wong, Sai-Keung] Natl Yang Ming Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Wong, SK (corresponding author), Natl Yang Ming Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
EM cswingo@cs.nctu.edu.tw
FU Ministry of Science and Technology of the ROC [MOST
   109-2221-E-009-121-MY3]
FX The Ministry of Science and Technology of the ROC, Grant/Award Number:
   MOST 109-2221-E-009-121-MY3
CR Al Borno M, 2013, IEEE T VIS COMPUT GR, V19, P1405, DOI 10.1109/TVCG.2012.325
   Amato N, 2016, P IEEE RSJ INT C INT
   Baker B, 2019, ARXIV PREPRINT ARXIV
   Chen H, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1826
   Gil O, 2019, P IB ROB C PORT PORT
   Haarnoja T, 2018, ARXIV PREPRINT
   Heess N, 2017, ARXIV PREPRINT ARXIV
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Juliani A, 2018, ARXIV PREPRINT ARXIV
   Lin GW, 2018, PHYS REV E, V97, DOI 10.1103/PhysRevE.97.062303
   Liu LB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201315
   Meriçli T, 2015, AUTON ROBOT, V38, P317, DOI 10.1007/s10514-014-9414-z
   Mordatch I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508365
   Nishinari K, 2004, IEICE T INF SYST, VE87D, P726
   Oshita M, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1878
   Peng XB., 2019, ADV NEURAL INFORM PR, P3686
   Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201311
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Riedmiller M, 2005, P EUR C MACH LEARN P
   Rohmer E, 2013, IEEE INT C INT ROBOT, P1321, DOI 10.1109/IROS.2013.6696520
   Schulman J, 2017, ARXIV PREPRINT ARXIV
   Sun LB, 2019, IEEE ACCESS, V7, P109544, DOI 10.1109/ACCESS.2019.2933492
   Tuci E, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00059
   Won J, 2018, P INT C MOT INT GAM, V2, P1
   Wong SK, 2018, ACM SIGGRAPH S INTER
   Xiang W, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1867
   Yang HY, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3320283
NR 27
TC 4
Z9 4
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2017
DI 10.1002/cav.2017
EA JUN 2021
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000657860800001
DA 2024-07-18
ER

PT J
AU Hu, ZY
   Xie, HR
   Fukusato, T
   Sato, T
   Igarashi, T
AF Hu, Zhongyuan
   Xie, Haoran
   Fukusato, Tsukasa
   Sato, Takahiro
   Igarashi, Takeo
TI Sketch2VF: Sketch-based flow design with conditional generative
   adversarial network
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE flow control; fluid animation; generative adversarial network; user
   interface
AB We present an interactive user interface to support sketch-based fluid design with a perceptual understanding of human sketches. In particular, the proposed system generates a 2D fluid animation from hand-drawn sketches. The proposed system utilizes a conditional generative adversarial network model to generate stationary velocity fields from a sketch input. The network model is trained with hand-drawn strokes and corresponding 2D velocity fields. On the basis of the generated velocity field, the system calculates fluid dynamics using a semi-Lagrangian method. We ran a user study of the proposed system and confirmed that the proposed interface is effective for a 2D fluid design and that the system achieves good results based on user input.
C1 [Hu, Zhongyuan] Univ Tokyo, Tokyo, Japan.
   [Fukusato, Tsukasa; Sato, Takahiro; Igarashi, Takeo] Univ Tokyo, Comp Sci Dept, Tokyo, Japan.
   [Xie, Haoran] Japan Adv Inst Sci & Technol, Nomi, Ishikawa 9231211, Japan.
C3 University of Tokyo; University of Tokyo; Japan Advanced Institute of
   Science & Technology (JAIST)
RP Xie, HR (corresponding author), Japan Adv Inst Sci & Technol, Nomi, Ishikawa 9231211, Japan.
EM xie@jaist.ac.jp
RI Igarashi, Takeo/ITT-5921-2023; Xie, Haoran/V-6397-2019; Xie,
   Haoran/ADP-8087-2022
OI Xie, Haoran/0000-0002-6926-3082; Xie, Haoran/0000-0002-6926-3082
FU Core Research for Evolutional Science and Technology [JPMJCR17A1]; Japan
   Society for the Promotion of Science [JP17H06574, JP19K20316]
FX Core Research for Evolutional Science and Technology, Grant/Award
   Number: JPMJCR17A1; Japan Society for the Promotion of Science,
   Grant/Award Number: JP17H06574 and JP19K20316
CR Adams NA, 2009, SPRINGER PROC PHYS, V132, P743, DOI 10.1007/978-3-642-03085-7_180
   BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025
   Bridson R., 2015, Fluid simulation for computer graphics
   Chen GN, 2012, IEEE T VIS COMPUT GR, V18, P1717, DOI 10.1109/TVCG.2011.290
   Choi B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925970
   Churi V, 2013, GRAPP IVAPP, P254
   Guay M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766893
   Guay M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508397
   Guérin E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130804
   Han XG, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073629
   Katz J., 2001, Low Speed Aerodynamics, DOI DOI 10.1017/CBO9780511810329
   Kazi RH, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P351, DOI 10.1145/2556288.2556987
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P59, DOI 10.1111/cgf.13619
   Kim Y., 2006, P 2006 ACM SIGGRAPHE, P33
   Madill J., 2013, PROC GRAPHICS INTERF, P125
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mittal R, 2005, ANNU REV FLUID MECH, V37, P239, DOI 10.1146/annurev.fluid.37.061903.175743
   Portenier T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201393
   Stam J, 2015, ART FLUID ANIMATION
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Thürey N, 2009, GRAPH MODELS, V71, P221, DOI 10.1016/j.gmod.2008.12.007
   Weymouth GD, 2015, ARXIV151006886
   Wojtan C., 2006, P 2006 ACM SIGGRAPHE, P15
   Xie HR, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3185767
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Xing J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P755, DOI 10.1145/2984511.2984585
   Yang B, 2014, COMPUT ANIMAT VIRT W, V25, P467, DOI 10.1002/cav.1585
   Yuan Z, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024170
   Zhang S, 2015, PROCEEDINGS - I3D 2015, P61, DOI 10.1145/2699276.2699287
   Zhu B, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024168
NR 30
TC 16
Z9 16
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1889
DI 10.1002/cav.1889
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400022
DA 2024-07-18
ER

PT J
AU Chen, XJ
   Jiang, HM
   Xuan, TT
   Huang, LH
   Liu, LG
AF Chen, Xuejin
   Jiang, Haoming
   Xuan, Tingting
   Huang, Lihan
   Liu, Ligang
TI Designing deployable 3D scissor structures with ball-and-socket joints
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deployable; joints; non-uniform concentration; 3D scissor structure
AB Scissor structures, which transform from a compact state to an expanded state, are widely used in various fields, ranging from architectural design to aerospace applications. We focus on a challenging problem that breaks through the restriction of planarity: to design scissor structures that expand from one given 3D shape to another 3D shape. To achieve this purpose, we propose a three-step algorithm to construct a 3D scissor structure that realizes non-uniform concentration between two different 3D curves. First, the input shapes are divided into scissor segments, which are composed of a sequence of planar scissor units based on the shape correspondence. Secondly, we compute the scissor unit geometry of each segment in a suggestive manner. Finally, the ball-and-socket joints with parameterized guide slits are integrated in order to connect the scissor segments, thereby completing the 3D deployment. Judging from a series of simulation and fabrication results, we demonstrate that our approach generates deployable structures for a wide range of 3D shape pairs.
C1 [Chen, Xuejin] Univ Sci & Technol China, Sch Informat Sci, 96 Jinzhai Rd, Hefei, Anhui, Peoples R China.
   [Jiang, Haoming; Xuan, Tingting; Huang, Lihan] Univ Sci & Technol China, 96 Jinzhai Rd, Hefei, Anhui, Peoples R China.
   [Liu, Ligang] Univ Sci & Technol China, Sch Math Sci, 96 Jinzhai Rd, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS
RP Chen, XJ (corresponding author), Univ Sci & Technol China, 96 Jinzhai Rd, Hefei, Anhui, Peoples R China.
EM xjchen99@ustc.edu.cn
OI Chen, Xuejin/0000-0003-0478-7018
FU National Natural Science Foundation of China [61472377, 61632006,
   61672482, 11626253]; One Hundred Talent Project of the Chinese Academy
   of Sciences
FX National Natural Science Foundation of China, Grant/Award Number:
   61472377, 61632006, 61672482, and 11626253; One Hundred Talent Project
   of the Chinese Academy of Sciences
CR Akgun Y., 2011, THESIS
   Bächer M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185543
   Calì J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366149
   De Temmerman N., 2007, THESIS
   Gruen A, 2005, ISPRS J PHOTOGRAMM, V59, P151, DOI 10.1016/j.isprsjprs.2005.02.006
   Hanaor A., 2001, International Journal of Space Structures, V16, P211, DOI [10.1260/026635101760832172, DOI 10.1260/026635101760832172]
   Langbecker T., 1999, International Journal of Space Structures, V14, P1
   Ovadya A., 2011, THESIS
   Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951
   Stehmann E, EXPANDING LAMP
   Waltz RA, 2006, MATH PROGRAM, V107, P391, DOI 10.1007/s10107-004-0560-5
   Zhang JJ, 2015, COMMUN MATH STAT, V3, P353, DOI 10.1007/s40304-015-0064-z
   Zhang R, 2016, IEEE T VIS COMPUT GR, V22, P1051, DOI 10.1109/TVCG.2015.2430322
   Zhao JS, 2009, MECH MACH THEORY, V44, P324, DOI 10.1016/j.mechmachtheory.2008.03.014
   Zheng C, 2016, P ACM SIGGRAPH EUR S
   [No title captured]
NR 16
TC 0
Z9 0
U1 2
U2 36
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2019
VL 30
IS 1
AR e1848
DI 10.1002/cav.1848
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8YF
UT WOS:000458275000003
OA Bronze
DA 2024-07-18
ER

PT J
AU Kavafoglu, Z
   Kavafoglu, E
   Egges, A
AF Kavafoglu, Zumra
   Kavafoglu, Ersan
   Egges, Arjan
TI Robust standing control with posture optimization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE balance control; character animation; optimization; physics-based
   animation; standing control
ID MOTION
AB Humans need to shift their center of mass during standing for several purpose such as preparing for the upcoming motion or increasing their stability. In this paper, we present a control strategy for robust center of mass shifting motions during standing, In our strategy, the desired posture can be defined with only a few high level features, such as the desired character center of mass position and the foot configurations. An online optimization process is designed for generating a kinematic lower body and pelvis posture that satisfies these high level features together with some criteria that guide a natural standing pose. Natural knee bending behaviours automatically arise as a result of this optimization process. Internal joint torques for tracking this optimized posture together with the given desired upper body pose are calculated by the physics-based control framework. Moreover, a physics-based arm control strategy that regulates the angular momentum of the character is devised in order to increase the robustness of the character under external disturbances. Several experiments are conducted to demonstrate the effectiveness of the proposed strategy. Because the strategy does not include any off-line parameter optimization, equations of motion, or inverse dynamics, it is highly suitable for online applications.
C1 [Kavafoglu, Zumra] Hacettepe Univ, Dept Math, Ankara, Turkey.
   [Kavafoglu, Ersan] Hacettepe Univ, Comp Graph Dept, Ankara, Turkey.
   [Egges, Arjan] Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.
C3 Hacettepe University; Hacettepe University; Utrecht University
RP Kavafoglu, Z (corresponding author), Hacettepe Univ, Dept Math, Ankara, Turkey.
EM zumra.kavafoglu@gmail.com
CR Abdallah M, 2005, IEEE INT CONF ROBOT, P1996
   Abe Y, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P249
   Al Borno M, 2013, IEEE T VIS COMPUT GR, V19, P1405, DOI 10.1109/TVCG.2012.325
   [Anonymous], ACM T GRAPHICS TOG
   Brown David F., 2013, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P55, DOI 10.1145/2485895
   Chapman A.E., 2008, Biomechanical analysis of fundamental human movements
   Coros S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1781156
   Coros S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409066
   Coumans Erwin., 2005, Bullet physics engine
   de Lasa M, 2011, THESIS
   de Lasa M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1781157
   Egges A., 2005, Proceedings of the First International Workshop on Crowd Simulation, P31
   Geijtenbeek T., 2012, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P211
   Ha S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366174
   Hodgins J. K., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P71, DOI 10.1145/218380.218414
   Jain S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477936
   Johnson S. G., 2008, The NLopt Nonlinear-Optimization Package
   Kavafoglu Z., 2015, P 8 ACM SIGGRAPH C M, P183
   KRAFT D, 1994, ACM T MATH SOFTWARE, V20, P262, DOI 10.1145/192115.192124
   Kraft D., 1988, SOFTWARE PACKAGE SEQ
   Kwon Taesoo, 2010, P 2010 ACM SIGGRAPHE, P129
   Lee Y., 2010, ACM T GRAPHIC, V29
   Liu CK, 2002, ACM T GRAPHIC, V21, P408, DOI 10.1145/566570.566596
   LIU L, 2010, ACM T GRAPHIC, V29
   Macchietto A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531386
   Mordatch I., 2010, ACM T GRAPH, V29
   Pratt J, 1997, IEEE INT CONF ROBOT, P193, DOI 10.1109/ROBOT.1997.620037
   Rabbani AH, 2014, P 7 INT C MOT GAM, P71
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Scheflen AlbertE., 1973, Communicational Structure: Analysis of a Psychotherapy Transaction
   Stewart A. J., 1992, Proceedings. Graphics Interface '92, P273
   SUNADA C, 1994, IEEE INT CONF ROBOT, P1910, DOI 10.1109/ROBOT.1994.351182
   Wang JM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778810
   Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507
   Wooten W. L., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P656, DOI 10.1109/ROBOT.2000.844127
   Wu Chun-Chih, 2010, P 2010 ACM SIGGRAPH, P113
   Xu WW, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531341
   Zordan J. K., 2002, P ACM SIGGRAPH EUR S, P89
NR 38
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2018
VL 29
IS 6
AR e1746
DI 10.1002/cav.1746
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HH9VW
UT WOS:000456089800006
DA 2024-07-18
ER

PT J
AU Qiao, FC
   Yao, NM
   Jiao, ZR
   Li, ZH
   Chen, H
   Wang, HA
AF Qiao, Fengchun
   Yao, Naiming
   Jiao, Zirui
   Li, Zhihao
   Chen, Hui
   Wang, Hongan
TI Emotional facial expression transfer from a single image via generative
   adversarial nets
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE dynamic expression sequence; facial expression transfer; generative
   adversarial nets
AB Facial expression transfer from a single image is a challenging task and has drawn sustained attention in the fields of computer vision and computer graphics. Recently, generative adversarial nets (GANs) have provided a new approach to facial expression transfer from a single image toward target facial expressions. However, it is still difficult to obtain a sequence of smoothly changed facial expressions. We present a novel GAN-based method for generating emotional facial expression animations given a single image and several facial landmarks for the in-between stages. In particular, landmarks of other subjects are incorporated into a GAN model to control the generated facial expression from a latent space. With the trained model, high-quality face images and a smoothly changed facial expression sequence can be effectively obtained, which are showed qualitatively and quantitatively in our experiments on the Multi-PIE and CK+ data sets.
C1 [Qiao, Fengchun; Yao, Naiming; Jiao, Zirui; Li, Zhihao; Chen, Hui; Wang, Hongan] Chinese Acad Sci, Inst Software, Beijing Key Lab Human Comp Interact, Beijing 100190, Peoples R China.
   [Qiao, Fengchun; Yao, Naiming; Jiao, Zirui; Chen, Hui; Wang, Hongan] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Wang, Hongan] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS; Chinese
   Academy of Sciences; Institute of Software, CAS
RP Chen, H (corresponding author), Chinese Acad Sci, Inst Software, Beijing Key Lab Human Comp Interact, Beijing 100190, Peoples R China.; Chen, H (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM chenhui@iscas.ac.cn
OI Qiao, Fengchun/0000-0003-2714-2036
FU National Key R&D Program of China [2017YFB1002805]; National Natural
   Science Foundation of China [61661146002]; Key Research Program of
   Frontier Sciences, CAS [QYZDY-SSW-JSC041]
FX National Key R&D Program of China, Grant/Award Number: 2017YFB1002805;
   National Natural Science Foundation of China, Grant/Award Number:
   61661146002; Key Research Program of Frontier Sciences, CAS, Grant/Award
   Number: QYZDY-SSW-JSC041
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2017, ARXIV171203474
   [Anonymous], IEEE 33 INT C MACH L
   [Anonymous], 2017, ARXIV170903842
   [Anonymous], IEEE 31 INT C MACH L
   [Anonymous], 2010 IEEE COMP SOC C
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2017, IEEE ACM T COMPUT BI
   [Anonymous], IEEE 30 INT C MACH L
   [Anonymous], IEEE 32 INT C MACH L
   [Anonymous], 2017, ADV NEURAL INFORM PR
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ARXIV170809126
   [Anonymous], 2016, P ADV NEUR INF PROC
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Fried O, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925933
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   GU G, 2017, ARXIV171110267
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kingma D.P., 2014, ARXIV14126980
   Kingma D. P., 2013, STAT-US
   Krizhevsky Alex., 2012, u International Conference on Neural Information Processing Systems - Volume, V1
   Liu XC, 2008, COMPUT ANIMAT VIRT W, V19, P235, DOI 10.1002/cav.248
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Mohammed U, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531363
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Susskind Joshua M., 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition, P421
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 35
TC 8
Z9 9
U1 1
U2 26
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1819
DI 10.1002/cav.1819
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100010
DA 2024-07-18
ER

PT J
AU Zhang, ZP
   Morishima, S
   Wang, CB
AF Zhang, Zhuopeng
   Morishima, Shigeo
   Wang, Changbo
TI Thickness-aware voxelization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE global illumination; shader; voxelization
AB Voxelization is a crucial process for many computer graphics applications such as collision detection, rendering of translucent objects, and global illumination. However, in some situations, although the mesh looks good, the voxelization result may be undesirable. In this paper, we describe a novel voxelization method that uses the graphics processing unit for surface voxelization. Our improvements on the voxelization algorithm can address a problem of state-of-the-art voxelization, which cannot deal with thin parts of the mesh object. We improve the quality of voxelization on both normal mediation and surface correction. Furthermore, we investigate our voxelization methods on indirect illumination, showing the improvement on the quality of real-time rendering.
C1 [Zhang, Zhuopeng; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Software Engn, 3663 North Zhongshan Rd, Shanghai 200062, Peoples R China.
   [Zhang, Zhuopeng] Waseda Univ, Adv Sci & Engn, Shinjuku Ku, 3-4-1 Okubo, Tokyo 1698555, Japan.
   [Morishima, Shigeo] Waseda Res Inst Sci & Engn JST Crest, Shinjuku Ku, 3-4-1 Okubo, Tokyo 1698555, Japan.
C3 East China Normal University; Waseda University
RP Zhang, ZP (corresponding author), East China Normal Univ, 500 Dongchuan Rd, Shanghai 200241, Peoples R China.; Zhang, ZP (corresponding author), Waseda Univ, Shinjuku Ku, 1-104 Totsukamachi, Tokyo 1698050, Japan.
EM 501801911@qq.com
OI Morishima, Shigeo/0000-0001-8859-6539
FU National Natural Science Foundation of China [61532002, 61672237]
FX National Natural Science Foundation of China, Grant/Award Number:
   61532002 and 61672237
CR Crassin C, 2012, OPENGL INSIGHTS, P303
   Crassin C, 2011, COMPUT GRAPH FORUM, V30, P1921, DOI 10.1111/j.1467-8659.2011.02063.x
   Dachsbacher C., 2005, Proc. Symp. Interactive Graph. and Games, P203, DOI DOI 10.1145/1053427.1053460
   Eisemann Elmar, 2006, P 2006 S INTERACTIVE, P71, DOI DOI 10.1145/1111411.1111424
   Eisemann Elmar., 2008, Proceedings of Graphics Interface, P73
   Everitt C, 2001, INTERACTIVE ORDER IN
   Fang SF, 2000, COMPUT GRAPH-UK, V24, P433, DOI 10.1016/S0097-8493(00)00038-8
   Favera E. C. D., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P142, DOI 10.1109/SIBGRAPI.2012.28
   Fei Y, 2012, P GRAPH INT 2012 GI, P1
   Gaitatzes A, 2011, 19 PAC C COMP GRAPH, P31
   Harada T, 2006, T J SOC COMPUT ENG S, V23
   Kaplanyan A., 2009, Light propagation volumes in cryengine 3
   Keller A., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P49, DOI 10.1145/258734.258769
   Li W., 2005, GPU GEMS 2 CHAPTER 4, P747
   Pantaleoni J, 2011, P ACM SIGGRAPH S HIG
   Rauwendaal R, 2013, J COMPUTER GRAPHICS, V2, P15
   Reinbothe C, 2009, EUR EN MARK C EEMC, P1
   Ren Z, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778792
   RITSCHEL T, 2009, P 2009 S INT 3D GRAP
   Schwarz M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866201
   Thiedemann S, 2011, I3D 11 S INT 3D GRAP
   Veach E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P419, DOI 10.1145/218380.218498
   Yang JC, 2010, COMPUT GRAPH FORUM, V29, P1297, DOI 10.1111/j.1467-8659.2010.01725.x
   Zhang C, 2014, LECT NOTES COMPUT SC, V8690, P112, DOI 10.1007/978-3-319-10605-2_8
   Zhang L, 2007, VISUAL COMPUT, V23, P783, DOI 10.1007/s00371-007-0149-0
NR 25
TC 1
Z9 1
U1 3
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1832
DI 10.1002/cav.1832
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100023
DA 2024-07-18
ER

PT J
AU Flores, JER
   Sánchez, AS
AF Ramirez Flores, Jorge Eduardo
   Susin Sanchez, Antonio
TI Segmentation-based skinning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE mesh segmentation; skinning; weight assignment algorithm; rigging;
   computer animation
ID ANIMATION; SPACE
AB Skeleton-driven animation is popular by its simplicity and intuitive control of the limbs of a character. Linear blend skinning (LBS) is up to date the most efficient and simple deformation method; however, painting influence skinning weights is not intuitive, and it suffers the candy-wrapper artifact. In this paper, we propose an approach based on mesh segmentation for skinning and skeleton-driven computer animation. We propose a novel and fast method, based in watershed segmentation to deal with characters in T-Pose and arbitrary poses, a simple weight assign algorithm based in the rigid skinning obtained with the segmentation algorithm for the LBS deformation method, and finally, a modified version of the LBS that avoids the loss of volume in twist rotations using the segmentation stage output values. Copyright (C) 2015 John Wiley & Sons, Ltd.
C1 [Ramirez Flores, Jorge Eduardo; Susin Sanchez, Antonio] Univ Politecn Cataluna, MOVING, C Jordi Girona 1-3, ES-08034 Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Flores, JER (corresponding author), Univ Politecn Cataluna, MOVING, C Jordi Girona 1-3, ES-08034 Barcelona, Spain.
EM jramirez@lsi.upc.edu
CR [Anonymous], 2005, P 2005 S INTERACTIVE, DOI [DOI 10.1145/1053427.10534294, DOI 10.1145/1053427.1053429]
   [Anonymous], 2001, P 2001 S INTERACTIVE
   [Anonymous], 2009, P 2009 ACM SIGGRAPH
   [Anonymous], 2012, ACM T GRAPHIC, DOI DOI 10.1145/2185520.2185573
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2002, P 2002 ACM SIGGRAPHE
   Baran I, 2007, SIGGRAPH 07 ACM SIGG
   Bharaj G, 2012, COMPUT GRAPH FORUM, V31, P755, DOI 10.1111/j.1467-8659.2012.03034.x
   Chen Xiaobai, 2009, ACM SIGGRAPH 2009 PA
   de Aguiar E, 2008, COMPUT GRAPH FORUM, V27, P389, DOI 10.1111/j.1467-8659.2008.01136.x
   Dionne Olivier., 2013, P 12 ACM SIGGRAPH EU, P173, DOI DOI 10.1145/2485895.2485919
   Jacka D, 2007, AFRIGRAPH 2007: 5TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY, COMPUTER GRAPHICS, VISUALIZATION AND INTERACTION IN AFRICA, P177
   Jacobson A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964973
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Katz S, 2005, VISUAL COMPUT, V21, P649, DOI 10.1007/s00371-005-0344-9
   Kavan L., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games. I3D '09, P49, DOI 10.1145/1507149.1507157
   KAVAN L., 2012, ACM T GRAPHIC, V31
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Kim Y, 2014, COMPUT ANIMAT VIRT W, V25, P323, DOI 10.1002/cav.1604
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Merry B, 2006, ACM T GRAPHIC, V25, P1400, DOI 10.1145/1183287.1183294
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Pan JJ, 2009, COMPUT ANIMAT VIRT W, V20, P121, DOI 10.1002/cav.284
   Pilgrim S, 2007, COMPUT ANIMAT VIRT W, V18, P473, DOI 10.1002/cav.181
   Flores JER, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1687
   Ramirez JE, 2010, LECT NOTES COMPUT SC, V6169, P300, DOI 10.1007/978-3-642-14061-7_29
   Rohmer D, 2008, COMPUT GRAPH FORUM, V27, P1919, DOI 10.1111/j.1467-8659.2008.01340.x
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Tierny J, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P215, DOI 10.1109/SMI.2007.38
   vonsFunck W, 2008, P VIS MOD VIS C 2008, P409
   Weber O, 2007, COMPUT GRAPH FORUM, V26, P265, DOI 10.1111/j.1467-8659.2007.01048.x
   Yang Xiaosong., 2006, Computer Graphics, Imaging and Visualisation, 2006 International Conference on, P323
   Yang XS, 2005, LECT NOTES COMPUT SC, V3482, P1109
   Zhang JJ, 2007, COMPUT ANIMAT VIRT W, V18, P437, DOI 10.1002/cav.211
NR 34
TC 1
Z9 1
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2017
VL 28
IS 1
AR e1687
DI 10.1002/cav.1687
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM0DZ
UT WOS:000394990300004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Choi, JI
   Kim, SJ
   Kim, CH
   Lee, J
AF Choi, Jong-In
   Kim, Sun-Jeong
   Kim, Chang-Hun
   Lee, Jung
TI Let's be a virtual juggler
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE virtual reality; character animation; physics-based animation; real-time
   motion control; handling objects
AB Juggling, which uses both hands to keep several objects in the air at once, is admired by anyone who sees it. However, skillful real-world juggling requires long, hard practice. Therefore, we propose an interesting method to enable anyone to juggle skillfully in the virtual world. In the real world, the human motion has to follow the motion of the moving objects; in the virtual world, the objects' motion can be adjusted together with the human motion. By using this freedom, we have generated a juggling avatar that can follow the user's motion. The user simply makes juggling-like motions in front of a motion sensor. Our system then searches for juggling motions that closely match the user's motions and connects them smoothly. We then generate moving objects that both satisfy the laws of physics and are synchronized with the synthesized motion of the avatar. In this way, we can generate a variety of juggling animations by an avatar in real time. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Choi, Jong-In] Korea Univ, Seoul, South Korea.
   [Kim, Chang-Hun] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Kim, Sun-Jeong; Lee, Jung] Hallym Univ, Dept Convergence Software, Chunchon, South Korea.
C3 Korea University; Korea University; Hallym University
RP Lee, J (corresponding author), Hallym Univ, Chunchon, South Korea.
EM airjung@gmail.com
CR Choi JI, 2015, VISUAL COMPUT, V31, P905, DOI 10.1007/s00371-015-1116-9
   Gleicher M., 2001, P 2001 S INTERACTIVE, P195
   Gleicher M, 2008, ACM SIGGRAPH 2008 CL
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Jain Sumit., 2009, Proceedings of SCA 2009, P47
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee Jehee., 2004, SCA 2004: Proceedings of the 2004 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P79
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lee Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866160
   Levine S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185524
   Levine S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966402
   Popovic J, 2003, ACM T GRAPHIC, V22, P1034, DOI 10.1145/944020.944025
   Popovic J, 2000, COMP GRAPH, P209, DOI 10.1145/344779.344880
   Shiratori T, 2006, COMPUT GRAPH FORUM, V25, P449, DOI 10.1111/j.1467-8659.2006.00964.x
   Thorne M, 2006, ACM SIGGRAPH 2006 CO
   Treuille A, 2007, ACM SIGGRAPH 2007 SI
NR 17
TC 5
Z9 5
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 443
EP 450
DI 10.1002/cav.1701
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300029
DA 2024-07-18
ER

PT J
AU Kochanowicz, J
   Tan, AH
   Thalmann, D
AF Kochanowicz, Jaroslaw
   Tan, Ah-Hwee
   Thalmann, Daniel
TI Social context cognition crowd-sourcing and semi-automatic
   parametrization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE cognitive modeling; social context; crowd-sourcing; social cognition;
   automatic parametrization
AB This paper presents a semi-automatic method of parameterizing an existing social context cognition model. It discusses benefits of the social context cognition models for example in personality modeling and their key issue that is parametrization. It briefly introduces social context cognition model and describes a new method of its crowd-sourcing-based parametrization. Later, validation is provided, and ability to recreate social context cognition in the provided samples is presented with good generalization for the unknown cases. Finally, model's stability for the continuous stream of dynamic social context input data is shown. Presented system contributes to the believable agent modeling and social simulations by making much needed applications of social context cognition models easier by addressing the so far unsolved troublesome parametrization issues. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Kochanowicz, Jaroslaw; Thalmann, Daniel] Nanyang Technol Univ, Inst Media Innovat, Singapore, Singapore.
   [Tan, Ah-Hwee] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Kochanowicz, J (corresponding author), Nanyang Technol Univ, Inst Media Innovat, Singapore, Singapore.
EM jarek108@gmail.com
RI Thalmann, Daniel/A-4347-2008; Tan, Ah-Hwee/A-3729-2011; Thalmann,
   Daniel/AAL-1097-2020
OI Thalmann, Daniel/0000-0002-0451-7491; Tan, Ah Hwee/0000-0003-0378-4069
CR [Anonymous], P 3 INT C AFF COMP I
   [Anonymous], 2014, The Oxford Handbook of Affective Computing
   Bleidorn W, 2009, EUROPEAN J PERSONALI, V23, pn09
   Cervone D., 1999, COHERENCE PERSONALIT
   EPSTEIN S, 1979, J PERS SOC PSYCHOL, V37, P1097, DOI 10.1037/0022-3514.37.7.1097
   Kochanowicz J, 2013, P 2013 INT C AUT AG, P789
   Kochanowicz J, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P1529
   MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x
   MISCHEL W, 1995, PSYCHOL REV, V102, P246, DOI 10.1037/0033-295X.102.2.246
   Neumann M, 2008, JASSS-J ARTIF SOC S, V11
   Riek LD, 2011, LECT NOTES COMPUT SC, V6974, P277, DOI 10.1007/978-3-642-24600-5_31
NR 11
TC 0
Z9 0
U1 0
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 330
EP 339
DI 10.1002/cav.1718
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300017
DA 2024-07-18
ER

PT J
AU Qian, K
   Jiang, T
   Wang, ML
   Yang, XS
   Zhang, JJ
AF Qian, Kun
   Jiang, Tao
   Wang, Meili
   Yang, Xiaosong
   Zhang, Jianjun
TI Energized soft tissue dissection in surgery simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE energized dissection; deformation simulation; strain limiting; surgery
   simulation
AB With the development of virtual reality technology, surgery simulation has become an effective way to train the operation skills for surgeons. Soft tissue dissection, as one of the most frequently performed operations in surgery, is indispensable to an immersive and high-fidelity surgery simulator. Energized dissection tools are much more commonly used than the traditional sharp scalpels for patient safety. Unfortunately, the interaction of such tools with the soft tissues has been largely ignored in the research of surgical simulators. In this paper, we have proposed an energized soft tissue dissection model. We categorize the soft tissues into three types (fascia, membrane, and fat) and simulate their physical property accordingly. The dissection algorithm we propose employs an edge-based structure, which offers an effective mechanism for the generation of incisions dissected with energized tools. The mesh topology will not be changed when it is dissected by an energized tool, rather it is controlled by the heat transfer model. Our dissection method is highly compatible and efficient to the physically based simulation resolved by a pre-factorized linear system. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Qian, Kun; Jiang, Tao] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
   [Yang, Xiaosong] Bournemouth Univ, Natl Ctr Comp Animat, Media Sch, Poole BH12 5BB, Dorset, England.
   [Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Comp Graph, Poole BH12 5BB, Dorset, England.
   [Wang, Meili] Northwest A&F Univ, Coll Informat Engn, Xianyang, Peoples R China.
C3 Bournemouth University; Bournemouth University; Bournemouth University;
   Northwest A&F University - China
RP Wang, ML (corresponding author), Northwest A&F Univ, Xianyang, Peoples R China.
EM meili_w@nwsuaf.edu.cn
OI Zhang, Jian/0000-0002-7069-5771; Yang, Xiaosong/0000-0003-3815-0584
CR Ali-Hamadi D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508415
   [Anonymous], P 20 ACM S VIRT REAL
   [Anonymous], 2004, P 2004 ACM SIGGRAPH, DOI DOI 10.1145/1028523.1028541
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bender J, 2014, COMPUT GRAPH-UK, V44, P1, DOI 10.1016/j.cag.2014.07.004
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P246, DOI 10.1111/cgf.12272
   Berkley J, 2004, IEEE T VIS COMPUT GR, V10, P314, DOI 10.1109/TVCG.2004.1272730
   Bielser D, 2004, GRAPH MODELS, V66, P398, DOI 10.1016/j.gmod.2004.05.009
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Busaryev O, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461920
   Jun W, 2014, STUDIES HLTH TECHNOL, P469
   Kim FJ, 2008, SURG ENDOSC, V22, P1464, DOI 10.1007/s00464-007-9650-9
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Maréchal N, 2010, COMPUT GRAPH FORUM, V29, P449, DOI 10.1111/j.1467-8659.2009.01614.x
   Marieb HK, 2007, HUMAN ANATOMY PHYSL
   Müller MH, 2008, PROGRESS AND CHALLENGES IN TRANSFUSION MEDICINE, HEMOSTASIS AND HEMOTHERAPY: STATE OF THE ART 2008, P1, DOI 10.1159/000176608
   MULLER M., 2006, P VIRTUAL REALITY IN, P71, DOI [10.1007/978-3-319-08234-9_92-1, DOI 10.1007/978-3-319-08234-9_92-1]
   Muller M., 2008, ACM SIGGRAPH 2008 classes, P88
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   Pan JJ, 2015, COMPUT ANIMAT VIRT W, V26, P321, DOI 10.1002/cav.1655
   Qian K, 2015, VIRTUAL REALITY BASE, P69
   Shimi S M, 1995, J R Coll Surg Edinb, V40, P249
   Sifakis E, 2012, ACM SIGGRAPH 2012 CO, DOI [10.1145/2343483.2343501, DOI 10.1145/2343483.2343501]
   Sifakis E, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P73
   Steinemann D, 2006, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2006.74
   Wu J., 2011, VRIPHYS, P29
   Wu J, 2016, IEEE T VIS COMPUT GR, V22, P1195, DOI 10.1109/TVCG.2015.2502588
   Wu J, 2015, COMPUT GRAPH FORUM, V34, P161, DOI 10.1111/cgf.12528
NR 29
TC 6
Z9 7
U1 0
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 280
EP 289
DI 10.1002/cav.1691
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300012
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Vezzaro, L
   Zerbato, D
   Fiorini, P
AF Vezzaro, Luca
   Zerbato, Davide
   Fiorini, Paolo
TI Interactive constrained dynamics for rigid and deformable objects
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE constraints; deformable objects; real time
ID CONTACT
AB Following the continuous increase in computational power of consumer hardware, interactive virtual environments have been recently enriched with more and more complex deformable objects. However, many physics engines are still very limited in the way they handle interacting rigid and deformable objects. This paper proposes a constraint-based approach to real-time simulation of coupled rigid and deformable objects capable of providing two-way interactions. Similar techniques have seen widespread usage for either rigid or deformable objects, but not for the simultaneous simulation of both. By extending such approaches, we show not only how interaction is possible but also how it can be performed at real-time rates. We address contact response and also show how to implement typical constraints to enforce limitations in the degrees of freedom and to enhance the dynamical properties of deformable objects. The method is easily integrated into existing physics engines that use similar constraint solvers and is independent on the kind of deformable object paradigm chosen. The provided simulation results show that the method is fast and effective in handling contacts between rigid and deformable objects and in simulating friction and other kinds of constraints. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Vezzaro, Luca; Zerbato, Davide; Fiorini, Paolo] Univ Verona Ca Vignal 2, Dept Comp Sci, Str Grazie 15, I-37134 Verona, Italy.
RP Vezzaro, L (corresponding author), Univ Verona Ca Vignal 2, Dept Comp Sci, Str Grazie 15, I-37134 Verona, Italy.
EM elvezzaro@gmail.com
FU European Union [248960]
FX This work was supported by the European Union Seventh Framework
   Programme FP7/2007-2013 under grant agreement 248960 (Patient Safety in
   Robotic Surgery).
CR [Anonymous], 2001, Game developers conference
   [Anonymous], COMP GRAPH VIS IADIS
   Baraff D, 1997, TECHNICAL REPORT
   Baumgarte J., 1972, Computer Methods in Applied Mechanics and Engineering, V1, P1, DOI 10.1016/0045-7825(72)90018-7
   Bender J, 2012, EUROGRAPHICS 2013 ST, P1
   Bender Jan, 2006, Virtual Reality Interactions and Physical Simulations (VRIPhys), P81
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Catto E, 2005, GAM DEV C, P1
   Deul C, 2016, COMPUT ANIMAT VIRT W, V27, P103, DOI 10.1002/cav.1614
   Erleben K, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243986
   Gibson S, 1997, TECHNICAL REPORTS ME
   Gibson S. F. F., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P149, DOI 10.1145/253284.253324
   GILBERT EG, 1988, IEEE T ROBOTIC AUTOM, V4, P193, DOI 10.1109/56.2083
   Goldenthal R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239500
   Harada T, 2011, SIGGRAPH ASIA 2011 S, P19
   Jansson J, 2003, VISUAL COMPUT, V19, P280, DOI 10.1007/s00371-002-0187-6
   Kelager M, 2010, P WORKSH VIRT REAL I, P31, DOI [10.2312/PE/vriphys/vriphys10/031-037, DOI 10.2312/PE/VRIPHYS/VRIPHYS10/031-037]
   Lenoir J, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P327, DOI 10.1109/CGI.2004.1309229
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Otaduy MA, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P181
   Otaduy MA, 2009, COMPUT GRAPH FORUM, V28, P559, DOI 10.1111/j.1467-8659.2009.01396.x
   PROVOT X, 1995, GRAPH INTER, P147
   Selle A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360663
   Shinar Tamar., 2008, P 2008 ACM SIGGRAPH, P95
   Sifakis E, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P73
   Smith B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185602
   Stam J, 2009, INT C COMP AID DES C, P1, DOI 10.1109/CADCG.2009.5246818
   Tonge R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185601
NR 31
TC 0
Z9 0
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2016
VL 27
IS 2
BP 151
EP 162
DI 10.1002/cav.1667
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ2BZ
UT WOS:000374010000006
DA 2024-07-18
ER

PT J
AU Boatright, CD
   Kapadia, M
   Shapira, JM
   Badler, NI
AF Boatright, Cory D.
   Kapadia, Mubbasir
   Shapira, Jennie M.
   Badler, Norman I.
TI Generating a multiplicity of policies for agent steering in crowd
   simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE machine learning; synthetic data; crowd simulation; steering
AB Pedestrian steering algorithms range from completely procedural to entirely data-driven, but the former grossly generalize across possible human behaviors and suffer computationally, whereas the latter are limited by the burden of ever-increasing data samples. Our approach seeks the balanced middle ground by deriving a collection of machine-learned policies based on the behavior of a procedural steering algorithm through the decomposition of the space of possible steering scenarios into steering contexts. The resulting algorithm scales well in the number of contexts, the use of new data sets to create new policies, and in the number of controlled agents as the policies become a simple evaluation of the rules asserted by the machine-learning process. We also explore the use of synthetic data from an oracle algorithm that serves as an as-needed source of samples, which can be stochastically polled for effective coverage. We observe that our approach produces pedestrian steering similar to that of the oracle steering algorithm, but with a significant performance boost. Runtime was reduced from hours under the oracle algorithm with 10 agents to on the order of 10 frames per second (FPS) with 3000 agents. We also analyze the nature of collisions in such a framework with no explicit collision avoidance. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Boatright, Cory D.] Grove City Coll, Comp Sci, Grove City, PA 16127 USA.
   [Boatright, Cory D.; Kapadia, Mubbasir; Shapira, Jennie M.; Badler, Norman I.] Univ Penn, Comp & Informat Sci, Philadelphia, PA 19104 USA.
C3 University of Pennsylvania
RP Boatright, CD (corresponding author), Grove City Coll, Comp Sci, 100 Campus Dr, Grove City, PA 16127 USA.
EM cdboatright@gcc.edu
FU U.S. Army Research Laboratory [W911NF-10-2-0016]
FX The research reported in this document/presentation was performed at the
   University of Pennsylvania in connection with Contract Number
   W911NF-10-2-0016 with the U.S. Army Research Laboratory. The views and
   conclusions contained in this document/presentation are those of the
   authors and should not be interpreted as presenting the official
   policies or position, either expressed or implied, of the U.S. Army
   Research Laboratory, or the U.S. Government unless so designated by
   other authorized documents. Citation of manufacturer's or trade names
   does not constitute an official endorsement or approval of the use
   thereof. The U.S. Government is authorized to reproduce and distribute
   reprints for Government purposes notwithstanding any copyright notation
   heron.
CR Ahn Junghyun., 2012, P 11 ACM SIGGRAPH IN, P231
   [Anonymous], 1999, P GAM DEV C
   Courty N, 2007, LECT NOTES COMPUT SC, V4418, P377
   Guy S., 2009, EUR ACM SIGGRAPH S C, P177
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kapadia M., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games, I3D '09, P215
   Kapadia M., 2011, P 2011 ACM SIGGRAPH, P53, DOI DOI 10.1145/2019406.2019414
   Karp R, 1972, COMPLEXITY COMPUTER, V40, P85, DOI 10.1007/978-3-540-68279-08
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Lerner A, 2010, COMPUT GRAPH FORUM, V29, P2197, DOI 10.1111/j.1467-8659.2010.01808.x
   Metoyer RA, 2003, COMP ANIM CONF PROC, P149, DOI 10.1109/CASA.2003.1199318
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Pelechano N., 2007, Proceedings of the 2007 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P108
   Pelechano Nuria., 2008, Virtual Crowds: Methods, Simulation, and Control
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Schneck J.D., 2011, Demand for REDD Carbon Credits - A Primer on Buyers, Markets, and Factors Impacting Prices, P1
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   Singh S, 2011, COMPUT ANIMAT VIRT W, V22, P151, DOI 10.1002/cav.403
   THALMANN D., 2012, Crowd Simulation, V2nd
   Thawonmas R, 2002, ROBOCUP AGENT LEARNI
   Torrens P, 2011, T GIS, V15, P67, DOI 10.1111/j.1467-9671.2011.01261.x
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Turkay C, 2011, COMPUT J, V54, P1810, DOI 10.1093/comjnl/bxr014
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Yersin B, 2008, VISUAL COMPUT, V24, P859, DOI 10.1007/s00371-008-0286-0
NR 28
TC 16
Z9 19
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2015
VL 26
IS 5
BP 483
EP 494
DI 10.1002/cav.1572
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS5NU
UT WOS:000362125800001
DA 2024-07-18
ER

PT J
AU Wong, SK
   Tang, PK
   Li, FS
   Wang, ZM
   Yu, ST
AF Wong, Sai-Keung
   Tang, Pao-Kun
   Li, Fu-Shun
   Wang, Zong-Min
   Yu, Shih-Ting
TI Guidance path scheduling using particle swarm optimization in crowd
   simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE crowd simulation; guidance paths; particle swarm optimization (PSO)
ID SOCIAL FORCE MODEL
AB In this paper, we propose a method for using particle swarm optimization (PSO) to compute optimal guidance paths for various crowd densities in an agent-based crowd simulation. The inputs of our system are guidance paths that provide hints for the movement directions of agents. Input guidance paths may not be located correctly (e.g., leading to congestion or high traveling cost); therefore, our method adjusts the guidance paths by using PSO. We consider several factors for evaluating the quality of a guidance path, including the average traveling time and interaction distance between agents. We apply our method in several examples. Experimental results show that our method can compute adaptive guidance paths for various crowd densities. Our system can simulate organized crowds that move in directions specified by the guidance paths. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Wong, Sai-Keung; Tang, Pao-Kun; Li, Fu-Shun; Wang, Zong-Min; Yu, Shih-Ting] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Wong, SK (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM cswingo@cs.nctu.edu.tw
RI Lu, Wang/JVO-0416-2024
FU National Science Council of ROC (Taiwan) [NSC 102-2221-E-009-103-MY2];
   Ministry of Science and Technology of ROC (Taiwan) [MOST
   103-2221-E-009-122-MY3]
FX We would like to thank all the reviewers for their constructive
   comments. This work was supported by the National Science Council of ROC
   (Taiwan) under the grant no. NSC 102-2221-E-009-103-MY2 and the Ministry
   of Science and Technology of ROC (Taiwan) under the grant no. MOST
   103-2221-E-009-122-MY3.
CR [Anonymous], 2006, IEEE C EM TECHN FACT
   [Anonymous], 2002, P 4 AS PAC C SIM EV
   Curtis S, 2013, VISUAL COMPUT, V29, P1277, DOI 10.1007/s00371-012-0769-x
   Dressler D, 2010, PROCEDIA ENGINEER, V3, P205, DOI 10.1016/j.proeng.2010.07.019
   Fang SW, 2012, KNOWL-BASED SYST, V34, P91, DOI 10.1016/j.knosys.2012.02.017
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Henry Joseph., 2012, Proceedings of the 11th ACM SIGGRAPH / Eurographics conference on Computer Animation, EUROSCA'12, P193
   Johansson A., 2007, Adv. Complex Syst, V10, P271, DOI [10.1142/S0219525907001355, DOI 10.1142/S0219525907001355]
   Ju E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866162
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kretz T, 2011, ADV COMPLEX SYST, V14, P733, DOI 10.1142/S0219525911003281
   Lin YY, 2007, IEEE C EVOL COMPUTAT, P3321
   Olivier A.-H., 2010, P 7 S APPL PERCEPTIO, P117
   Olivier AH, 2014, TRANSP RES PROC, V2, P114, DOI 10.1016/j.trpro.2014.09.015
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   van der Merwe D, 2003, IEEE C EVOL COMPUTAT, P215, DOI 10.1109/CEC.2003.1299577
   Zanlungo F, 2011, EPL-EUROPHYS LETT, V93, DOI 10.1209/0295-5075/93/68005
NR 20
TC 12
Z9 15
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 387
EP 395
DI 10.1002/cav.1636
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700020
DA 2024-07-18
ER

PT J
AU Zhang, JZ
   Zheng, JM
   Magnenat-Thalmann, N
AF Zhang, Juzheng
   Zheng, Jianmin
   Magnenat-Thalmann, Nadia
TI PCMD: personality-characterized mood dynamics model toward personalized
   virtual characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE personality; mood dynamics; personalized virtual characters
ID INDIVIDUAL-DIFFERENCES; TEMPERAMENT
AB How to endow the virtual characters with personalized behavior patterns remains a challenging problem. Instead of heuristically designing behaviors for certain personalities, this paper bridges the gap between personalities and behaviors using a medium concept, mood, to make the behaviors of the characters consistent enough to convey their personalities, while flexible enough to make appropriate response in various situations. We propose a personality-characterized mood dynamics model, in which the emotion weights are computed as a solution of a convex optimization problem that is constructed to make the overall mood approaches the personality after sufficient interactions. The convergence of the algorithm is demonstrated by numerical simulations. The implementation of the personality-characterized mood dynamics model enables an emotion-oriented virtual human, Sophie, to show personalized behaviors in the emotional interactions with users. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Zhang, Juzheng] Nanyang Technol Univ, Inst Media Innovat, Sch Comp Engn, Singapore 639798, Singapore.
   [Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Magnenat-Thalmann, Nadia] Nanyang Technol Univ, Inst Media Innovat, Singapore 639798, Singapore.
C3 Nanyang Technological University; Nanyang Technological University;
   Nanyang Technological University
RP Zhang, JZ (corresponding author), Nanyang Technol Univ, Inst Media Innovat, Sch Comp Engn, Singapore 639798, Singapore.
EM jzhang19@e.ntu.edu.sg
RI Thalmann, Nadia/AAK-5195-2021; Zheng, Jianmin/A-3717-2011
OI Thalmann, Nadia/0000-0002-1459-5960; Zheng, Jianmin/0000-0002-5062-6226
FU Singapore National Research Foundation under its International Research
   Centre @ Singapore Funding Initiative
FX This research, which is carried out at BeingThere Centre, is supported
   by the Singapore National Research Foundation under its International
   Research Centre @ Singapore Funding Initiative and administered by the
   IDM Programme Office.
CR [Anonymous], 2005, INT JOINT C AUTONOMO, DOI DOI 10.1145/1082473.1082478
   Brave S., 2003, HUM FAC ER, P81
   Burgers JM, 2008, PERSONALITY, V7th
   Davidson RichardJ., 1994, The Nature of Emotion!: Fundamental Questions, P51
   El-Nasrs MS, 2000, AUTON AGENT MULTI-AG, V3, P219
   Frijda N.H., 1994, NATURE EMOTION, P197
   Funders DC, 1997, PERSONALITY PUZZLE
   Gebhard P, 2006, LECT NOTES ARTIF INT, V4133, P343
   Gebhard P, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P661
   GOLDBERG LR, 1990, J PERS SOC PSYCHOL, V59, P1216, DOI 10.1037/0022-3514.59.6.1216
   Kang Sin-Hwa., 2012, Proceedings of the 11th international conference on autonomous agents and multiagent systems aamas, P63
   Kasap Z, 2009, IEEE COMPUT GRAPH, V29, P20, DOI 10.1109/MCG.2009.26
   Mairesses F, 2010, USER MODELING USER A, V20, P227
   Marsellas S, 2006, EUR M CYB SYST RES 2
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   MEHRABIAN A, 1978, EDUC PSYCHOL MEAS, V38, P1105, DOI 10.1177/001316447803800431
   Morriss WN, 1989, MOOD FRAME MIND
   Ortonys A, 1988, COGNITIVE STRUCTURE
   Prendinger H, 2005, APPL ARTIF INTELL, V19, P267, DOI 10.1080/08839510590910174
   REISENZEIN R, 1994, J PERS SOC PSYCHOL, V67, P525, DOI 10.1037/0022-3514.67.3.525
   Santoss R, 2009, P 14 PORT C ART INT
   Traum David, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P275, DOI 10.1007/978-3-642-33197-8_29
   Velasquez JD, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P70
NR 23
TC 2
Z9 2
U1 0
U2 15
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 237
EP 245
DI 10.1002/cav.1660
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700006
DA 2024-07-18
ER

PT J
AU Qi, T
   Xiao, J
   Zhuang, YT
   Zhang, HZ
   Yang, XS
   Zhang, JJ
   Feng, YF
AF Qi, Tian
   Xiao, Jun
   Zhuang, Yueting
   Zhang, Hanzhi
   Yang, Xiaosong
   Zhang, Jianjun
   Feng, Yinfu
TI Real-time motion data annotation via action string
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion annotation; action recognition; GMM pose feature; action string;
   string matching
AB Even though there is an explosive growth of motion capture data, there is still a lack of efficient and reliable methods to automatically annotate all the motions in a database. Moreover, because of the popularity of mocap devices in home entertainment systems, real-time human motion annotation or recognition becomes more and more imperative. This paper presents a new motion annotation method that achieves both the aforementioned two targets at the same time. It uses a probabilistic pose feature based on the Gaussian Mixture Model to represent each pose. After training a clustered pose feature model, a motion clip could be represented as an action string. Then, a dynamic programming-based string matching method is introduced to compare the differences between action strings. Finally, in order to achieve the real-time target, we construct a hierarchical action string structure to quickly label each given action string. The experimental results demonstrate the efficacy and efficiency of our method. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Qi, Tian; Xiao, Jun; Zhuang, Yueting; Zhang, Hanzhi; Feng, Yinfu] Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310027, Zhejiang, Peoples R China.
   [Yang, Xiaosong; Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
C3 Zhejiang University; Bournemouth University
RP Xiao, J (corresponding author), Zhejiang Univ, Inst Artificial Intelligence, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM junx@cs.zju.edu.cn
RI Zhang, Hanzhi/GLN-6996-2022
OI Zhang, Hanzhi/0000-0001-7112-2302; Zhang, Jian/0000-0002-7069-5771;
   Yang, Xiaosong/0000-0003-3815-0584
FU National High Technology Research and Development Program
   [2012AA011502]; National Key Technology RD Program [2013BAH59F00];
   Zhejiang Provincial Natural Science Foundation of China [LY13F020001];
   Fundamental Research Funds for the Central Universities [2014FZA5013];
   Zhejiang Province Public Technology Applied Research Projects
   [2014C33090]; Sino-UK Higher Education Research Partnership - Department
   of Business, Innovation and Skills of the British Government; Ministry
   of Education of China
FX This research is supported by the National High Technology Research and
   Development Program (2012AA011502), the National Key Technology R&D
   Program (2013BAH59F00), the Zhejiang Provincial Natural Science
   Foundation of China (LY13F020001), the Fundamental Research Funds for
   the Central Universities (2014FZA5013), Zhejiang Province Public
   Technology Applied Research Projects (No. 2014C33090) and partially
   supported by the grant of the Sino-UK Higher Education Research
   Partnership for PhD Studies Project funded by the Department of
   Business, Innovation and Skills of the British Government and Ministry
   of Education of China.
CR [Anonymous], 2009, P 2009 ACM SIGGRAPH
   [Anonymous], 2005, P ACM SIGGRAPH EUR S, DOI [10.1145/1073368.1073377, DOI 10.1145/1073368.1073377]
   Baak A., 2013, Consumer Depth Camerasfor Computer Vision: Research Topics and Applications, P71, DOI DOI 10.1007/978-1-4471-4640-7_5
   DEFAYS D, 1977, COMPUT J, V20, P364, DOI 10.1093/comjnl/20.4.364
   Gleicher M., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P139, DOI 10.1145/253284.253321
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Jain S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477936
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu G., 2005, P 2005 ACM SIGMOD IN, P924
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Meng J., 2008, Eurographics (Short Papers), P71
   Microsoft, 2013, KIN
   Min J., 2010, P 2010 ACM SIGGRAPH, DOI [10.1145/1730804.1730811, DOI 10.1145/1730804.1730811]
   Muller M., 2007, TECHNICAL REPORTS U
   Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365
   Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qi T, 2013, COMPUT ANIMAT VIRT W, V24, P399, DOI 10.1002/cav.1505
   Shen W, 2012, PROC CVPR IEEE, P1784, DOI 10.1109/CVPR.2012.6247875
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Vieira AW, 2012, INT C PATT RECOG, P2934
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
NR 25
TC 4
Z9 4
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 293
EP 302
DI 10.1002/cav.1590
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300010
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Wang, XJ
   Zhou, LL
   Deng, ZG
   Jin, XG
AF Wang, Xinjie
   Zhou, Linling
   Deng, Zhigang
   Jin, Xiaogang
TI Flock morphing animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE tetrahedralization; shape morphing; flock simulation; flock morphing;
   special effects; computer animation
AB We propose a new animation technique, called flock morphing, to create special morphing effects between two arbitrary 3D objects by combining the features of 3D morphing and flock animation. Its core idea is first to tetrahedralize the source 3D mesh and regard each tetrahedron as an agent in a flock and then continually generate the flock morphing animation until the target mesh emerges, formed by the same set of tetrahedra. By applying plausible trajectory planning scheme and smooth deformation algorithm, we demonstrate that our proposed method can simultaneously achieve visually desired morphing effects. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Wang, Xinjie; Zhou, Linling; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 Zhejiang University; University of Houston System; University of Houston
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM jin@cad.zju.edu.cn
OI Deng, Zhigang/0000-0002-0452-8676; Deng, Zhigang/0000-0003-2571-5865
FU Zhejiang Provincial Natural Science Foundation of China [Z1110154];
   Joint Research Fund for Overseas Chinese, Hong Kong and Macao Young
   Scientists of the National Natural Science Foundation of China
   [61328204]; National Natural Science Foundation of China [61272298]
FX This work was supported by Zhejiang Provincial Natural Science
   Foundation of China (grant no. Z1110154), the Joint Research Fund for
   Overseas Chinese, Hong Kong and Macao Young Scientists of the National
   Natural Science Foundation of China (grant no. 61328204), and the
   National Natural Science Foundation of China (grant no. 61272298). The
   authors would like to thank Junjie Chen for English proofreading.
CR Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575
   Bridson R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276435, 10.1145/1239451.1239497]
   Farin G, 2002, CURVES SURFACES CAGD
   Gomes J., 1998, WARPING MORPHING GRA
   Gu Q, 2013, IEEE COMPUT GRAPH, V33, P20, DOI 10.1109/MCG.2011.87
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Ju E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866162
   Lee KC, 2007, 2007 MOBILE NETWORKING FOR VEHICULAR ENVIRONMENTS, P109, DOI 10.1109/MOVE.2007.4300814
   Patil S, 2011, IEEE T VIS COMPUT GR, V17, P244, DOI 10.1109/TVCG.2010.33
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Shoemake K, 1994, GRAPHICS GEMS, P207
   Si H, 2004, TECHNICAL REPORTS WE, V9
   Takahashi S, 2009, COMPUT GRAPH FORUM, V28, P639, DOI 10.1111/j.1467-8659.2009.01404.x
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Wang XJ, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12277
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Xu JY, 2008, COMPUT ANIMAT VIRT W, V19, P319, DOI 10.1002/cav.231
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
NR 18
TC 7
Z9 7
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 353
EP 362
DI 10.1002/cav.1580
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300016
OA Bronze
DA 2024-07-18
ER

PT J
AU Haciomeroglu, M
   Ozcan, CY
   Barut, O
   Seckin, L
   Sever, H
AF Haciomeroglu, Murat
   Ozcan, Cumhur Yigit
   Barut, Oner
   Seckin, Levent
   Sever, Hayri
TI Hardware-accelerated dynamic clustering of virtualcrowd members
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE real-time crowd simulation; GPU clustering
AB In this study, a hardware-accelerated dynamic clustering of moving virtual entities technique is proposed. By clustering virtual entities, both clustered and unclustered virtual agents became more aware of other agents' topological configurations. Clustering is based on their continuously changing velocity and position vectors. The proposed clustering technique efficiently uses graphics processor's parallel processing capabilities. Therefore, almost no additional central processing unit overhead is required to bring the clustering information into the simulation. In addition, in this paper, how cluster information can be used on top of the proposed virtual human steering technique is explained. The results show that by using the dynamic clustering, the number of collision in the simulation reduces, and the velocities of the the agents in the simulation increase. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Haciomeroglu, Murat] Gazi Univ, Dept Comp Engn, TR-06570 Ankara, Turkey.
   [Ozcan, Cumhur Yigit; Barut, Oner; Seckin, Levent; Sever, Hayri] Hacettepe Univ, Dept Comp Engn, TR-06530 Ankara, Turkey.
C3 Gazi University; Hacettepe University
RP Haciomeroglu, M (corresponding author), Gazi Univ, Dept Comp Engn, Eti Mah, TR-06570 Ankara, Turkey.
EM murath@gazi.edu.tr
RI Ozcan, Cumhur Yigit Y/M-7747-2018; Barut, Oner/K-3319-2018
OI Barut, Oner/0000-0003-3442-1586; Sever, Hayri/0000-0002-8261-0675
CR [Anonymous], EUROGRAPHICS TUTORIA
   [Anonymous], 1999, P GAM DEV C
   [Anonymous], ACM WORKSH GEN PURP
   Cao F, 2006, LECT NOTES COMPUT SC, V4016, P372
   Guy S., 2009, EUR ACM SIGGRAPH S C, P177
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   Haciomeroglu M, 2008, COMPUT ANIMAT VIRT W, V19, P307, DOI 10.1002/cav.232
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hughes RL, 2002, TRANSPORT RES B-METH, V36, P507, DOI 10.1016/S0191-2615(01)00015-7
   Joselli Mark, 2009, Proceedings of the VIII Brazilian Symposium on Games and Digital Entertainment (SBGAMES 2009), P121, DOI 10.1109/SBGAMES.2009.22
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Maïm J, 2009, IEEE COMPUT GRAPH, V29, P44, DOI 10.1109/MCG.2009.76
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Pelechano Nuria., 2008, Virtual Crowds: Methods, Simulation, and Control
   Pettre J., 2005, First Intl. Work- shop on Crowd Simulation, P81
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Shalom SAA, 2008, LECT NOTES COMPUT SC, V5182, P166, DOI 10.1007/978-3-540-85836-2_16
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Sud A, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P91
   Thalmann D, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P1, DOI 10.1109/CW.2009.23
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   vanden Berg J, 2009, 14 INT S ROB RES LUC
   Yilmaz E, 2009, IEEE COMPUT GRAPH, V29, P26, DOI 10.1109/MCG.2009.77
   Zhang Y, 2008, J INTEGR PLANT BIOL, V50, P1053, DOI [10.1109/CSSE.2008.527, 10.1111/j.1744-7909.2008.00734.x]
NR 25
TC 2
Z9 2
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2013
VL 24
IS 2
DI 10.1002/cav.1491
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 131ZB
UT WOS:000318036300007
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Liu, JH
AF Zhao, Yong
   Liu, Jianhui
TI Volumetric subspace mesh deformation with structure preservation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE mesh deformation; structure preservation; volumetric subspace; nonlinear
   energy optimization
AB Existing deformation techniques are oblivious to salient structures that often capture the essence of 3D meshes. Combining with gradient domain technique, we propose an alternative approach to preserve these structures in the volumetric subspace. Through a simple sketching interface, the structures of the input mesh are specified by the user. During deformations, these key structures are constrained to deform rigidly to maintain their original shapes, hence avoiding serious visual artifacts. However, this process leads to a nonlinear optimization problem. To guarantee fast convergence as well as numerical stability, we project the deformation energy onto a volumetric subspace which envelops the input mesh. Then the energy optimization is performed in this subspace to greatly facilitate the editing of large meshes. Massive experimental data demonstrate the effectiveness and efficiency of our algorithm. Copyright (c) ?2012 John Wiley & Sons, Ltd.
C1 [Zhao, Yong; Liu, Jianhui] Ocean Univ China, Sch Math Sci, Qingdao, Peoples R China.
C3 Ocean University of China
RP Zhao, Y (corresponding author), Ocean Univ China, Sch Math Sci, Qingdao, Peoples R China.
EM zhaoyong@cad.zju.edu.cn
FU Research Award Fund for Excellent Young and Middle-aged Scientists of
   Shandong Province, China [BS2012DX043]
FX This work is supported by the Research Award Fund for Excellent Young
   and Middle-aged Scientists of Shandong Province, China (No.
   BS2012DX043).
CR Au O.K.C., 2005, P S GEOM PROC
   Au OKC, 2006, IEEE T VIS COMPUT GR, V12, P386, DOI 10.1109/TVCG.2006.47
   Ben-Chen M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531340
   Botsch M, 2003, COMPUT GRAPH FORUM, V22, P483, DOI 10.1111/1467-8659.00696
   Botsch M., 2006, SGP 06, P11
   Botsch M, 2007, COMPUT GRAPH FORUM, V26, P339, DOI 10.1111/j.1467-8659.2007.01056.x
   Fan LB, 2011, COMPUT GRAPH FORUM, V30, P603, DOI 10.1111/j.1467-8659.2011.01895.x
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Gal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531339
   Guskov I, 1999, COMP GRAPH, P325, DOI 10.1145/311535.311577
   Huang J, 2006, ACM T GRAPHIC, V25, P1126, DOI 10.1145/1141911.1142003
   Huang J, 2009, COMPUT AIDED GEOM D, V26, P617, DOI 10.1016/j.cagd.2008.12.002
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Kobbelt L., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P105, DOI 10.1145/280814.280831
   Kraevoy V, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409064
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Rivers AR, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239533
   Sauvage B, 2007, COMPUT GRAPH FORUM, V26, P275, DOI 10.1111/j.1467-8659.2007.01049.x
   Shi XH, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360628
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Sorkine O., 2004, P 2004 EUR ACM SIGGR, P179
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   XIAN C, 2009, P IEEE INT C SHAP MO, P21
   Xu WW, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531341
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zheng YY, 2011, COMPUT GRAPH FORUM, V30, P563, DOI 10.1111/j.1467-8659.2011.01880.x
   Zhou K, 2005, ACM T GRAPHIC, V24, P496, DOI 10.1145/1073204.1073219
NR 33
TC 1
Z9 1
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2012
VL 23
IS 5
BP 519
EP 532
DI 10.1002/cav.1488
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 021ZW
UT WOS:000309925700007
DA 2024-07-18
ER

PT J
AU Kasap, M
   Chaudhuri, P
   Magnenat-Thalmann, N
AF Kasap, Mustafa
   Chaudhuri, Parag
   Magnenat-Thalmann, Nadia
TI Fast EMG-data driven skin deformation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE skin deformation; electromyography; GPU
ID MUSCLE
AB Virtual characters arc being modeled and animated with increasing accuracy and photorealism ill current games and virtual reality simulations. However, the detailed modeling of dynamic skin deformations due to movement of the muscles during articulation is still prohibitively expensive for real-time simulations. We present ill this paper a fast approach for modeling such deformations driven by Electromyography (EMG) data. We demonstrate the method oil the muscles of the upper leg during a gait cycle. A muscle map, created from a 3D muscle model, is applied as a deformation map to deform the skill surface as per the underlying muscle geometry. EMG signals recorded from a gait cycle tire then used to dynamically vary the weights in the deformation map during animation thus producing the dynamic skin deformations. The whole operation is done on the GPU to make it very fast and suitable for real-time simulations. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Kasap, Mustafa; Chaudhuri, Parag; Magnenat-Thalmann, Nadia] Univ Geneva, MIRALab, Geneva, Switzerland.
   [Magnenat-Thalmann, Nadia] Univ Montreal, Montreal, PQ H3C 3J7, Canada.
C3 University of Geneva; Universite de Montreal
RP Kasap, M (corresponding author), Univ Geneva, MIRALab, Geneva, Switzerland.
EM mustafa.kasap@miralab.unige.ch
RI Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Nadia/0000-0002-1459-5960
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Chadwick J. E., 1989, Computer Graphics, V23, P243, DOI 10.1145/74334.74358
   Dong F, 2002, IEEE T VIS COMPUT GR, V8, P154, DOI 10.1109/2945.998668
   Ivanenko YP, 2004, J PHYSIOL-LONDON, V556, P267, DOI 10.1113/jphysiol.2003.057174
   Ivanenko YP, 2006, NEUROSCIENTIST, V12, P339, DOI 10.1177/1073858406287987
   Kasap M, 2007, 2007 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P160, DOI 10.1109/CW.2007.14
   Kumar P, 2005, J OPTIMIZ THEORY APP, V126, P1, DOI 10.1007/s10957-005-2653-6
   Larboulette Caroline., 2005, Proceedings of the 21st spring conference on Computer graphics, P87, DOI DOI 10.1145/1090122.10901384
   Liu MQ, 2008, J BIOMECH, V41, P3243, DOI 10.1016/j.jbiomech.2008.07.031
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Park SI, 2006, ACM T GRAPHIC, V25, P881, DOI 10.1145/1141911.1141970
   PRATSCHER M, 2005, SCA 05, P329
   Teran J, 2005, IEEE T VIS COMPUT GR, V11, P317, DOI 10.1109/TVCG.2005.42
   Winter DA., 1991, WATERLOO BIOMECHANIC
   ZAJAC FE, 1989, CRIT REV BIOMED ENG, V17, P359
NR 15
TC 1
Z9 1
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 153
EP 161
DI 10.1002/cav.296
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700009
DA 2024-07-18
ER

PT J
AU Lyard, E
   Magnenat-Thalmann, N
AF Lyard, Etienne
   Magnenat-Thalmann, Nadia
TI Motion adaptation based on character shape
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE computer graphics; animation; virtual reality
AB With the increasing performances of the graphics hardware, virtual reality applications are reaching a new level of realism. It is now possible to animate entire crowds of virtual avatars, or to display in real-time highly realistic deformable characters. This new type of applications requires that characters are deformed, either to generate a large number of individuals for creating a crowd, or to match a particular shape. To make the animation fit to the animated character and to prevent self-collisions, adapting the motion is mandatory. Unlike previous approaches which relied on skeletal models, this paper presents a method considering the actual shape of the character's body to perform the adaptation. Our approach uses spacetime optimization to remove the self-penetration, and finally re-establishes the balance of the motion. We also introduce an interpolation scheme based on radial basis functions that can blend pre-calculated adaptations, and thus achieve real-time performances. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Lyard, Etienne] Univ Geneva, MIRALab, Geneva, Switzerland.
   [Lyard, Etienne] Rutgers State Univ, Multisensory Computat Lab, Piscataway, NJ 08855 USA.
   [Magnenat-Thalmann, Nadia] Univ Montreal, MIRALab, Res Lab, Montreal, PQ H3C 3J7, Canada.
   [Magnenat-Thalmann, Nadia] Univ Geneva, Interdisciplinary MIRALab Lab, Geneva, Switzerland.
C3 University of Geneva; Rutgers University System; Rutgers University New
   Brunswick; Universite de Montreal; University of Geneva
RP Lyard, E (corresponding author), Univ Geneva, MIRALab, Geneva, Switzerland.
EM lyard@miralab.unige.ch
RI Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Nadia/0000-0002-1459-5960
CR Abe YH, 2006, GRAPH MODELS, V68, P194, DOI 10.1016/j.gmod.2005.03.006
   [Anonymous], 1997, USERS GUIDE CFSQP VE
   [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], 1955, SPACE REQUIREMENTS S
   Baerlocher P, 2004, VISUAL COMPUT, V20, P402, DOI 10.1007/s00371-004-0244-4
   Buhmann M.D., 2003, C MO AP C M, V12, DOI 10.1017/CBO9780511543241
   CHAI J, 2007, SIGGRAPH 07 ACM SIGG, P8
   Choi KJ, 2000, J VISUAL COMP ANIMAT, V11, P223, DOI 10.1002/1099-1778(200012)11:5<223::AID-VIS236>3.0.CO;2-5
   GLEICHER M, 1997, COMPUTER GRAPHICS P, P139
   JEONG K, 2000, P INT WORKSH HUM MOD, P77
   Kavan L, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P39
   Kovar Lucas., 2002, SCA 2002: Proceedings of the 2002 ACM SIG-GRAPH/Eurographics Symposium on Computer Animation, P97
   Kuffner J, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2265, DOI 10.1109/ROBOT.2002.1013569
   Lee J, 1999, COMP GRAPH, P39
   LIU KC, 2006, SCA 06, P215
   Lyard E, 2007, VISUAL COMPUT, V23, P689, DOI 10.1007/s00371-007-0135-6
   MUSSE SR, 1998, VRST 98, P115
   Peinado M, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P89
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   Seo Hyewon., 2003, Proceedings of the 2003 Symposium on Interactive 3D Graphics, P19, DOI [10.1145/641480.641487, DOI 10.1145/641480.641487]
   Shin HJ, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P194
   Tak S, 2005, ACM T GRAPHIC, V24, P98, DOI 10.1145/1037957.1037963
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   Volino P., 2005, Computer-Aided Design and Applications, V2, P645
   Witkin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P105, DOI 10.1145/218380.218422
   WITKIN A, 1988, P SIGGRAPH 88, P159
   ZHAO XM, 1994, COMPUT AIDED DESIGN, V26, P861, DOI 10.1016/0010-4485(94)90050-7
NR 27
TC 8
Z9 8
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 189
EP 198
DI 10.1002/cav.233
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Oh, S
   Noh, J
   Wohn, K
AF Oh, SeungWoo
   Noh, Junyong
   Wohn, Kwangyun
TI A physically faithful multigrid method for fast cloth simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE cloth simulation; miltigrid; physically based animation
AB We present an efficient multigrid algorithm that is adequate to solve a heavy linear system given in cloth simulation. Although a multigrid solver has been successfully employed to the Poisson problems, it is hard to apply the solver to complicated cloth deformations due to its lack of physical meaning in level construction. We address this problem by developing a physically faithful technique ensuring the conservation of all physical quantities across levels. The performance of our approach is demonstrated on a number of garment simulations implemented by the state of the art techniques: the implicit integration, tyre triangle-based in-plane energy model, and the curvature-based bending energy model. Our multigrid algorithm is about four times faster than the preconditioned Conjugate Gradient method for a garment with 20K particles. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Oh, SeungWoo] Korea Adv Inst Sci & Technol, Inst Entertainment Engn, Taejon 305701, South Korea.
   [Noh, Junyong; Wohn, Kwangyun] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST)
RP Oh, S (corresponding author), Korea Adv Inst Sci & Technol, Inst Entertainment Engn, 335 Gwahangno, Taejon 305701, South Korea.
EM redmong@vr.kaist.ac.kr
RI Noh, Junyong/C-1663-2011; Wohn, Kwangyun/C-2013-2011
CR Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   BERGOU M, 2006, EUR S GEOM PROC
   BOLZ J, 2003, P ACM SIGGRAPH
   Breen David E., 1994, Proceedings of the 21st annual conference on Computer graphics and interactive techniques, P365
   BRIDSON R, 2003, P 2003 ACM SIGGRAPH, P28
   Capell S., 2002, P ACM SIGGRAPH
   Choi K.-J., 2003, Eurographics 2003 Short Presentations, P187
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   DEBUNNE G, 2001, P ACM SIGGRAPH
   Desbrun M, 1999, PROC GRAPH INTERF, P1
   Fish J, 1996, INT J NUMER METH ENG, V39, P1181, DOI 10.1002/(SICI)1097-0207(19960415)39:7<1181::AID-NME899>3.0.CO;2-Y
   Georgii J., 2005, WORKSH VIRT REAL INT
   GREEN S, 2002, ACM S SOL MOD APPL
   Grinspun E., 2002, P ACM SIGGRAPH
   Grinspun E., 2003, P 2003 ACM SIGGRAPH, P62
   Hauth M, 2001, COMPUT GRAPH FORUM, V20, pC319, DOI 10.1111/1467-8659.00524
   HOUSE DH, 2000, CLOTH MODELING ANIMA
   PROVOT X, 1995, GRAPH INTER, P147
   Shewchuk JR, 2002, COMP GEOM-THEOR APPL, V22, P21, DOI 10.1016/S0925-7721(01)00047-5
   SHI L, 2006, P ACM SIGGRAPH
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Thomas JL, 2003, ANNU REV FLUID MECH, V35, P317, DOI 10.1146/annurev.fluid.35.101101.161209
   Villard J., 2002, P 11 INT MESHING ROU, P243
   Volino P, 2005, COMPUT AIDED DESIGN, V37, P593, DOI 10.1016/j.cad.2004.09.003
   Volino P, 2005, COMPUT ANIMAT VIRT W, V16, P163, DOI 10.1002/cav.78
   Volino P., 2005, Computer-Aided Design and Applications, V2, P645
   Volino P, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P257, DOI 10.1109/CGI.2000.852341
   Volino Pascal, 2006, EUR ACM SIGGRAPH S C
   Volkov V., 2005, RES J TEXTILES APPAR, V9, P48
   Wesseling P., 2004, An Introduction to Multigrid Methods
NR 30
TC 11
Z9 18
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 479
EP 492
DI 10.1002/cav.255
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200029
DA 2024-07-18
ER

PT J
AU Chang, J
   Shepherd, DX
   Zhang, JJ
AF Chang, Jian
   Shepherd, Daniel X.
   Zhang, Jian J.
TI Cosserat-beam-based dynamic response modelling
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE computer animation; vibration; deformation; Cosserat beam
ID SIMULATION
AB The Cosserat beam model is traditionally used to describe the mechanics of a flexible beam, which is a one-dimensional entity. In this paper we apply the Cosserat beam model to an arbitrary three-dimensional object for fast simulation of its vibration behaviours. We encage a detailed mesh model of an object inside a much simpler supporting framework whose edges are effectively the beams (struts) of the Cosserat model. The paper focuses first on extracting the modes of vibration of the framework. Once this is done, dynamic deformations can then be quickly simulated with respect to any applied constraints and dynamic stimuli. The aim of this method is to offer realism traditionally only afforded by the finite element methods (FEMs) while providing more sophistication than the mass-spring method. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Bournemouth Univ, Sch Med, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University
RP Zhang, JJ (corresponding author), Bournemouth Univ, Sch Med, Poole BH12 5BB, Dorset, England.
EM jzhang@bmth.ac.uk
OI Chang, Jian/0000-0003-4118-147X
CR [Anonymous], P SIGGRAPH
   Antman S.S., 1995, Nonlinear problems of elasticity, V107
   BARAFF D, 1992, COMP GRAPH, V26, P303, DOI 10.1145/142920.134084
   Barbic J, 2005, ACM T GRAPHIC, V24, P982, DOI 10.1145/1073204.1073300
   Barr A. H., 1984, Computers & Graphics, V18, P21
   Bertails F, 2006, ACM T GRAPHIC, V25, P1180, DOI 10.1145/1141911.1142012
   Chang J, 2004, COMPUT ANIMAT VIRT W, V15, P211, DOI 10.1002/cav.23
   Chang J, 2007, VISUAL COMPUT, V23, P71, DOI 10.1007/s00371-006-0086-3
   Choi MG, 2005, IEEE T VIS COMPUT GR, V11, P91
   Coquillart S., 1990, J. Computer Graphics, V24, P187, DOI DOI 10.1145/97880.97900
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   Garland M., 1997, PROC 24 C COMPUTER G, P209, DOI DOI 10.1145/258734.258849
   Gregoire M., 2006, P 2006 ACM S SOLID P, P95
   GREISSMAIR J, 1989, EUROGRAPHICS 89, P137
   HSU WM, 1992, COMP GRAPH, V26, P177, DOI 10.1145/142920.134036
   HUANG J, 2006, P ACM SIGGRAPH 2006, P1126
   James DL, 2004, ACM T GRAPHIC, V23, P393, DOI 10.1145/1015706.1015735
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   James DL, 2006, ACM T GRAPHIC, V25, P987, DOI 10.1145/1141911.1141983
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   MULLER M, 1949, P 2002 ACM SIGGRAPH
   Nedel LP, 1998, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P156, DOI 10.1109/CGI.1998.694263
   OBrien J.F., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics symposium on Computer animation, P175
   Pai DK, 2002, COMPUT GRAPH FORUM, V21, P347, DOI 10.1111/1467-8659.00594
   PENTLAND A, 1989, COMPUTER GRAPHICS, V23, P207
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Shabana A.A., 1996, THEORY VIBRATION INT, V2nd
   Shinya M., 1992, Computer Graphics Forum, V11, pC119, DOI 10.1111/1467-8659.1130119
   Stam J, 1997, COMPUT GRAPH FORUM, V16, pC159, DOI 10.1111/1467-8659.00152
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
NR 30
TC 11
Z9 13
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 429
EP 436
DI 10.1002/cav.197
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000021
DA 2024-07-18
ER

PT J
AU Lee, EJ
   Kwon, JY
   Lee, IK
AF Lee, Eun-Jung
   Kwon, Ji-Yong
   Lee, In-Kwon
TI Caricature video
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE caricature; facial animation; video cartooning
AB We make moving caricatures from videos con human faces. Using training images, we created a 3D model of an average face. This allows us to transform the image in each frame of an input video, so that it is seen from the front. Then we apply 2D exaggeration rules to caricature each face. Finally, we rotate the face in each frame back to its original position. A panel of viewers gave positive scores to a series of test videos. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
C3 Yonsei University
RP Lee, IK (corresponding author), Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
EM iklee@yonsei.ac.kr
RI Lee, In-Kwon/AGP-6124-2022
OI Lee, In-Kwon/0000-0002-1534-1882; Lee, Eunjung/0000-0001-9989-3555
CR AKLEMAN E, 1997, P ACM SIGGRAPH 97, P145
   [Anonymous], P 1 INT S NON PHOT A
   Blanz Volker., 1999, P 26 ANN C COMPUTER, P187, DOI DOI 10.1145/311535.311556
   BRENNAN SE, 1985, LEONARDO, V18, P170, DOI 10.2307/1578048
   Chen H, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE 11TH USENIX SECURITY SYMPOSIUM, P171
   Chiang P., 2004, P 2004 AS C COMP VIS
   Choi Jung-Ju., 2004, P 17 INT C COMPUTER, P1
   DEBEECK JO, 1996, CARICATURE
   Fujiwara T, 2000, LECT NOTES COMPUT SC, V1948, P151
   Lee S, 1997, IEEE T VIS COMPUT GR, V3, P228, DOI 10.1109/2945.620490
   Leyvand T., 2006, ACM SIGGRAPH 2006 SK, P169
   Liang L, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P386, DOI 10.1109/PCCGA.2002.1167882
   LITWINOWICZ PC, 1991, P 18 ANN C COMP GRAP, P113
   LIU Z, 2000, P ACM MULT 2000, P475
   PIGHIN F, 1998, ANN C SERIES, V32, P75
   Redman L., 1984, DRAW CARICATURES
   Rhodes Gillian., 1997, Superportraits: Caricatures and Recognition
   Spellucci P, 1998, MATH PROGRAM, V82, P413, DOI 10.1007/BF01580078
   STEGMANN MB, 2000, THESIS TECHNICAL U D
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Zhao M, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P597
NR 22
TC 1
Z9 1
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 279
EP 288
DI 10.1002/cav.200
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000007
DA 2024-07-18
ER

PT J
AU Mamou, K
   Zaharia, T
   Prêteux, F
AF Mamou, Khaled
   Zaharia, Titus
   Preteux, Francoise
TI A skinning approach for dynamic 3D mesh compression
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dynamic mesh compression; skinning; 3D animation
AB This paper proposes a novel approach for 3D mesh compression, based oil a skinning animation technique. The core of the proposed method is a piecewise affine predictor coupled with a skinning model and a DCT representation of the residuals errors. The experimental evaluation shows that the proposed skinning-based encoder outperforms (with bitrates gains from 47% to 67%) GV, RT, MPEG-4/AFX-IC, D3DMC, PCA and Dynapack techniques. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Inst Natl Telecommun, ARTEMIS Dept, Grp Ecoles Telecommun, F-91001 Evry, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   SudParis
RP Mamou, K (corresponding author), Inst Natl Telecommun, ARTEMIS Dept, Grp Ecoles Telecommun, 9 Rue Charles Fourier, F-91001 Evry, France.
EM Khaled.Mamou@int-evry.fr
CR Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Bourges-Sévenier M, 2004, IEEE T CIRC SYST VID, V14, P928, DOI 10.1109/TCSVT.2004.830662
   Briceno H. M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P136
   COLLINS G, 2005, P ACM S INT 3D GRAPH, P21
   Guskov I., 2004, Proc. 2004 ACM SIG- GRAPH/Eurographics Symp. Comput. Animation (SCA '04), P183
   Ibarria L., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P126
   Jang ES, 2004, IEEE T CIRC SYST VID, V14, P989, DOI 10.1109/TCSVT.2004.830670
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Lengyel J. E., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P89, DOI 10.1145/300523.300533
   Mamou Khaled., 2005, PROC SPIE C MATH MET, V5916, P44
   MULLER K, 2005, P IEEE INT C IM PROC, V1, P621
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   SANDER P, 2002, MSRTR200227
   Sattler M., 2005, P 2005 ACM SIGGRAPH, P209
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   Zhang JH, 2004, IEEE DATA COMPR CONF, P508
NR 18
TC 42
Z9 44
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 337
EP 346
DI 10.1002/cav.137
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400020
DA 2024-07-18
ER

PT J
AU Paris, S
   Donikian, S
   Bonvalet, N
AF Paris, Sebastien
   Donikian, Stephane
   Bonvalet, Nicolas
TI Environmental abstraction and path planning techniques for realistic
   crowd simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE environment description; path planning; simulation involving virtual
   humans
AB This paper treats two linked subjects underlying behavioural simulation. First, the way to describe a virtual environment through all informed hierarchical abstract graph. This graph stores some pre-computations such as potential visibility sets, oriented grids, or densities of people, which call be used individually by simulated entities. Second, the way to use this abstract graph to perform a realistic and efficient path planning, which takes care of individual preferences as well as individual knowledge of the environment. Moreover, the path planning method we propose is reactive to some events, reflecting the perceived modifications of the environment, which allows the entity to adapt its behaviour ill consequence. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 IRISA, F-35042 Rennes, France.
C3 Universite de Rennes
RP Donikian, S (corresponding author), IRISA, Campus Beaulieu, F-35042 Rennes, France.
EM donikian@irisa.fr
CR ANDUJAR C, 2004, COMPUTER GRAPHICS FO
   [Anonymous], 2012, Robot Motion Planning
   Duckham M, 2003, LECT NOTES COMPUT SC, V2825, P169
   Farenc N, 1999, COMPUT GRAPH FORUM, V18, pC309, DOI 10.1111/1467-8659.00351
   Fernández-Madrigal JA, 2002, IEEE T PATTERN ANAL, V24, P103, DOI 10.1109/34.982887
   FRUIN J.J., 1971, Metropolitan Association of Urban Designers and Environmental Planners
   GLOOR C, 2004, 4 SWISS TRANSP RES C
   Golledge RG, 1995, LECT NOTES COMPUT SC, V988, P207
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Hochmair HH, 2004, LECT NOTES COMPUT SC, V3343, P79
   Kuffner JJ, 1998, LECT NOTES ARTIF INT, V1537, P171
   LAMARCHE F, 2004, COMP GRAPH FOR EUR 0
   MUSSE SR, 1997, COMPUTER ANIMATION S, P39
   OSARAGI T, 2004, AAMAS 04 P 3 INT JOI, P836
   PARIS S, 2005, 1 INT WORKSH CROWD S
   PAULS J, 1984, FIRE TECHNOL, V20, P27, DOI 10.1007/BF02390046
   Predtechenskii V.M., 1978, Planning for Foot Traffic Flow in Buildings
   SHAO W, 2005, DIG HUM MOD DES ENG
   SUNG M, 2005, EUR ACM SIGGRAPH S C, P291
   THOMAS R, 2003, 4 INT SPAC SYNT S LO
NR 20
TC 29
Z9 32
U1 2
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 325
EP 335
DI 10.1002/cav.136
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400019
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Badier, NI
AF Zhang, Yu
   Badier, Norman I.
TI Synthesis of 3D faces using region-based morphing under intuitive
   control
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE face modeling; facial features; region-based morphing; anthropometry;
   texture; 3D scanned data
AB This paper presents a new region-based method for automatically synthesizing varied, natural looking 3D human face models by morphing local facial features according to intuitive control parameters. We automatically compute a one-to-one vertex correspondence among the unregistered face scans in a large database by deforming a generic mesh to fit the specific person's face geometry in a global-to-local fashion. With the obtained correspondence, we transform the generated data sets of feature shapes into vector space representations. We parameterize the example models using the face anthropometric measurements that reflect the facial physical structure, and predefine the interpolation functions for the parameterized example models based on radial basis functions. At runtime, the interpolation functions are evaluated to efficiently generate the appropriate feature shape by taking the anthropometric parameters as input. We use a shape blending approach for generating a seamlessly deformed mesh around the feature region boundary. The correspondence among all example textures is established by parameterizing the 3D generic mesh over a 2D image domain. The new feature texture With desired attributes is synthesized by interpolating the example textures. Our 3D face synthesis method has several advantages: (1) it regulates the naturalness of synthesized faces, maintaining the quality existing in the real face examples; (2) the region-based morphing and comprehensive face shape and texture control parameters allow more diverse faces to be generated readily; and (3) the automatic runtime face synthesis is efficient in time complexity and performs fast. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Univ Penn, Ctr Human Modeling & Simulat, Comp & Informat Sci Dept, Philadelphia, PA 19104 USA.
C3 University of Pennsylvania
RP Zhang, Y (corresponding author), Univ Penn, Ctr Human Modeling & Simulat, Comp & Informat Sci Dept, Philadelphia, PA 19104 USA.
EM yuzha@seas.upenn.edu
CR AKIMOTO T, 1993, IEEE COMPUT GRAPH, V13, P16, DOI 10.1109/38.232096
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626
   [Anonymous], 2001, P 2001 S INTERACTIVE
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   DECARLO D, 1998, P SIGGRAPH 98, P67, DOI DOI 10.1145/280814.280823
   DiPaola S., 1991, Journal of Visualization and Computer Animation, V2, P129, DOI 10.1002/vis.4340020406
   Farkas LG, 1994, Anthropometry of Head and Face, Vsecond
   Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387
   Guskov I, 2000, COMP GRAPH, P95, DOI 10.1145/344779.344831
   Kahler K., 2002, Eurographics Symp. on Comp. Animation, P55, DOI DOI 10.1145/545261.545271
   Lee WS, 2000, IMAGE VISION COMPUT, V18, P355, DOI 10.1016/S0262-8856(99)00057-8
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Liu ZC, 2001, J VISUAL COMP ANIMAT, V12, P227, DOI 10.1002/vis.260
   Magnenat-Thalmann N., 1989, Visual Computer, V5, P32, DOI 10.1007/BF01901479
   Park IK, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P49
   Parke F., 1996, COMPUTER FACIAL ANIM
   PARKS DA, 1982, GASTROENTEROLOGY, V82, P9
   Patel M., 1991, EUROGRAPHICS '91. Proceedings of the European Computer Graphics Conference and Exhibition, P33
   PIGHIN F, 1998, P SIGGRAPH 98, P75
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Seo Hyewon., 2003, Proceedings of the 2003 Symposium on Interactive 3D Graphics, P19, DOI [10.1145/641480.641487, DOI 10.1145/641480.641487]
   *U S FLOR, USF DARPA HUMANID 3D
   YOUNG A, 1986, CONFIGURATIONAL INFO
   ZHANG Y, 2006, P INT C COMP GRAPH T
NR 27
TC 1
Z9 3
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 421
EP 432
DI 10.1002/cav.145
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400028
DA 2024-07-18
ER

PT J
AU Baciu, G
   Iu, BKC
AF Baciu, G
   Iu, BKC
TI Motion retargeting in the presence of topological variations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion retargeting; motion capture; motion editing; motion control;
   animation; inverse kinematics
AB Research on motion retargeting and synthesis for character animation has been mostly focused on character scale variations. In our recent work we have addressed the motion retargeting problem for characters with slightly different topologies. In this paper we present a new method for retargeting captured motion data to an enhanced character skeleton having a topology that is different from that of the original captured motion. The new topology could include altered hierarchical structures and scaled segments. In order to solve this problem, we propose a framework based on the concept of a motion control net (MCN). This is an external structure analogous to the convex hull of a set of control points defining a parametric curve or a surface patch. The MCN encapsulates the motion characteristics of the character. Retargeting is achieved as a generalized inverse kinematics problem using an external MCN. The retargeting solution requires the dynamic modification of the MCN structure. This also allows US to interactively edit the MCN and modify the conditions for the motion analysis. The new method can automatically synthesize new segment information and, by combining the segment motion into the MCN domain with a suitable displacement of control points embedded in the original motion capture sensor data, it can also generate realistic new motions that resemble the motion patterns in the original data. Copyright (C) 2006 Joint Wiley & Sons, Ltd.
C1 Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
EM csgeorge@comp.polyu.edu.hk
RI Baciu, George/AAU-7143-2021
OI BACIU, George/0000-0002-1766-6357
CR [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], P S COMP AN SAN DIEG
   Badler N.I., 1993, PRESENCE-VIRTUAL AUG, V2, P82, DOI 10.1162/pres.1993.2.1.82
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Bruderlin Armin., 1995, Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH '95, P97, DOI DOI 10.1145/218380.218421
   CAMERON G, 1997, P 24 ANN C COMP GRAP, P442
   CHOI KJ, 1999, P INT PAC GRAPH, P32
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   COHEN MF, 1992, COMP GRAPH, V26, P293
   Gleicher M., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P139, DOI 10.1145/253284.253321
   GLEICHER M, 2000, ACM SIGGRAPH COMPUTE, V33, P51
   Gleicher M., 2001, P 2001 S INTERACTIVE, P195
   HUANG A, 2003, P 1 INT C COMP GRAPH, P29
   KACICALESIC Z, 2003, P 2003 ACM SIGGRAPH, P7
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   KOVAR L, 2003, P ACM SIGGRAPH EUR S, P214
   Kovar Lucas., 2002, SCA 2002: Proceedings of the 2002 ACM SIG-GRAPH/Eurographics Symposium on Computer Animation, P97
   Lee J, 1999, COMP GRAPH, P39
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   LI Y, 2003, P 2003 ACM SIGGRAPH, P309
   LITWINOWICZ PC, 1991, P 18 ANN C COMP GRAP, P113
   Liu CK, 2002, ACM T GRAPHIC, V21, P408, DOI 10.1145/566570.566596
   Liu Zicheng., 1994, Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH '94, P35
   Luenberger DG, 1984, LINEAR NONLINEAR PRO
   NEFF M, 2003, P ACM SIGGRAPH EUR S, P239
   Park S, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P105, DOI 10.1109/MOTION.2002.1182221
   PETTRE J, 2003, P 2003 ACM SIGGRAPH, P258
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   PULLEN K, 2002, P 29 ANN C COMP GRAP, P501
   Rose C., 1996, Dans Proc. SIGGRAPH '96, P147
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   SIMMONS M, 2002, P 2002 ACM SIGGRAPH, P139, DOI DOI 10.1145/545261.545284
   TAK S, 2002, COMP AN P
   Wang J., 2003, P 2003 ACM SIGGRAPH, P232
   WITKIN A, 1995, COMPUTER GRAPHICS, V29, P105
   WITKIN A, 1988, P SIGGRAPH 88, P159
NR 36
TC 5
Z9 6
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2006
VL 17
IS 1
BP 41
EP 57
DI 10.1002/cav.72
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 019YN
UT WOS:000235874800004
DA 2024-07-18
ER

PT J
AU Visconti, A
   Calandra, D
   Lamberti, F
AF Visconti, Alessandro
   Calandra, Davide
   Lamberti, Fabrizio
TI Comparing technologies for conveying emotions through realistic avatars
   in virtual reality-based metaverse experiences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE avatar representation; emotions; facial and eye tracking; lip sync
   approximation
ID RECOGNITION
AB With the development of metaverse(s), industry and academia are searching for the best ways to represent users' avatars in shared virtual environments (VEs), where real-time communication between users is required. The expressiveness of avatars is crucial for transmitting emotions that are key for social presence and user experience, and are conveyed via verbal and non-verbal facial and body signals. In this paper, two real-time modalities for conveying expressions in virtual reality (VR) via realistic, full-body avatars are compared by means of a user study. The first modality uses dedicated hardware (i.e., eye and facial trackers) to allow a mapping between the user's facial expressions/eye movements and the avatar model. The second modality relies on an algorithm that, starting from an audio clip, approximates the facial motion by generating plausible lip and eye movements. The participants were requested to observe, for both the modalities, the avatar of an actor performing six scenes involving as many basic emotions. The evaluation considered mainly social presence and emotion conveyance. Results showed a clear superiority of facial tracking when compared to lip sync in conveying sadness and disgust. The same was less evident for happiness and fear. No differences were observed for anger and surprise.
C1 [Visconti, Alessandro; Calandra, Davide; Lamberti, Fabrizio] Politecn Torino, DAUIN, Turin, Italy.
C3 Polytechnic University of Turin
RP Visconti, A (corresponding author), Politecn Torino, DAUIN, Turin, Italy.
EM alessandro.visconti@polito.it
RI Visconti, Alessandro/IQS-8690-2023; Lamberti, Fabrizio/I-9153-2012;
   Calandra, Davide/ABG-3277-2020
OI Visconti, Alessandro/0000-0002-8323-9484; Calandra,
   Davide/0000-0003-0449-5752
CR Ahn SJ, 2011, J ADVERTISING, V40, P93, DOI 10.2753/JOA0091-3367400207
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   Bänziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Bente G., 2011, Face-to-Face Communication over the Internet: Issues, Research, Challenges, P176, DOI [DOI 10.1017/CBO9780511977589.010, 10.1017/CBO9780511977589.010]
   Calandra Davide, 2023, Computer Vision, Imaging and Computer Graphics Theory and Applications: 16th International Joint Conference, VISIGRAPP 2021, Virtual Event, Revised Selected Papers. Communications in Computer and Information Science (1691), P3, DOI 10.1007/978-3-031-25477-2_1
   Calandra D, 2021, GRAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 1: GRAPP, P96, DOI 10.5220/0010319400960105
   Campbell, 2022, THIS VR DOC SHOWS VI
   De Lorenzis F, 2022, VISIGRAPP, P273, DOI 10.5220/0011007800003124
   Dobre Georgiana Cristina, 2022, 2022 CHI C HUM FACT, P1, DOI 10.1145
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   Freeman G., 2020, 2020 CHI C HUM FACT, DOI 10.1145/3334480.3382923
   Hart JD., 2018, P ANN S COMP HUM INT, DOI [10.1145/3270316.3271543, DOI 10.1145/3270316.3271543]
   Hart JD., 2021, P 2021 IEEE INT C IN, DOI [10.1109/ICIR51845.2021.00011, DOI 10.1109/ICIR51845.2021.00011]
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   Hube N., 2020, P 2020 IEEE INT S MI, DOI [10.1109/ISMAR-Adjunct51615.2020.00023, DOI 10.1109/ISMAR-ADJUNCT51615.2020.00023]
   Hube N., 2022, 2022 CHI C HUM FACT, DOI [10.1145/3491101.3519822, DOI 10.1145/3491101.3519822]
   Kasapakis V., 2021, P IEEE C VIRT REAL 3, DOI [10.1109/VRW52623.2021.00205, DOI 10.1109/VRW52623.2021.00205]
   Kim K, 2018, INT SYM MIX AUGMENT, P105, DOI 10.1109/ISMAR.2018.00039
   Kotlyar I, 2013, COMPUT HUM BEHAV, V29, P544, DOI 10.1016/j.chb.2012.11.020
   Krekhov A., 2019, IEEE CONF COMPU INTE, P1
   Nowak KL, 2018, REV COMMUN RES, V6, P30, DOI 10.12840/issn.2255-4165.2018.06.01.015
   Otto O., 2006, VRCIA 06, P145, DOI DOI 10.1145/1128923.1128947
   Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6
   Rhee C.-H., 2013, Int._J._of_Multimedia_and_Ubiquitous_Engineering, V8, P69
   Rodero E, 2011, J VOICE, V25, pE25, DOI 10.1016/j.jvoice.2010.02.002
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P493, DOI 10.1037/0022-3514.57.3.493
   Salem Ben., 2000, Proceedings of the Third International Conference on Collaborative Virtual Environments, DOI DOI 10.1145/351006.351019
   Schafer A., 2021, SURVEY SYNCHRONOUS A, DOI DOI 10.48550/ARXIV.2102.05998
   Xi NN, 2023, INFORM SYST FRONT, V25, P659, DOI 10.1007/s10796-022-10244-x
   Yoon Boram., 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P547, DOI DOI 10.1109/VR.2019.8797719
NR 31
TC 7
Z9 7
U1 5
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2188
EA MAY 2023
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000997065100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Trivedi, H
   Mousas, C
AF Trivedi, Hritik
   Mousas, Christos
TI Human-virtual crowd interaction: Towards understanding the effects of
   crowd avoidance proximity in an immersive virtual environment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE avoidance proximity; crowd interaction; immersive interaction; virtual
   crowd; virtual reality
ID SIMULATION; GAZE; WALKING
AB This paper focuses on understanding how study participants interact and perceive a virtual crowd in an immersive virtual environment. Specifically, our within-group exploratory study investigated how avoidance proximity variations (i.e., low, medium, and high avoidance proximity [defined as avoidance radius]) assigned to crowd agents impacted participants' interaction with the virtual crowd. During the study, we instructed our participants to walk in a virtual environment. At the same time, we had a virtual crowd scripted to walk toward the start position of the participant following a straight path. During the participants' walking task, we collected movement data (i.e., trajectory length and completion time) and immediately after each experimental condition, we asked participants to self-report their experience (i.e., co-presence, behavioral independence, crowd realism, crowd interaction realism, perceived politeness, and emotional reactivity). Based on the collected data, we found that when we exposed our participants to the high avoidance proximity condition, they: (1) followed longer paths, (2) spent more time reaching the target goal, (3) rated the virtual crowd less polite, (4) rated the virtual crowd and their interaction with the virtual crowd less realistic, (5) rated the behavior independence of the virtual crowd lower, and (6) self-reported higher emotional reactivity. We discuss our findings and suggestions for further research on human-virtual crowd interaction.
C1 [Trivedi, Hritik; Mousas, Christos] Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN USA.
   [Mousas, Christos] Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University; Purdue University System;
   Purdue University
RP Mousas, C (corresponding author), Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
EM cmousas@purdue.edu
RI Mousas, Christos/AGV-3533-2022
OI Mousas, Christos/0000-0003-0955-7959
CR Ahrens A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214603
   Allen BF, 2012, COMPUT ANIMAT VIRT W, V23, P569, DOI 10.1002/cav.1472
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Basili P, 2013, GAIT POSTURE, V37, P385, DOI 10.1016/j.gaitpost.2012.08.003
   Berton F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P322, DOI [10.1109/VR46266.2020.1581264804299, 10.1109/VR46266.2020.00-52]
   Berton F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P717, DOI [10.1109/VR.2019.8798204, 10.1109/vr.2019.8798204]
   Bönsch A, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423888
   Bönsch A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P199
   Bönsch A, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P145, DOI 10.1109/3DUI.2016.7460045
   Boroditsky L, 2001, COGNITIVE PSYCHOL, V43, P1, DOI 10.1006/cogp.2001.0748
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   Cohen J., 1988, STAT POWER ANAL BEHA
   De Rosis F., 2005, VIRTUAL SOCIAL AGENT, V65, P79
   Dickinson P, 2019, VIRTUAL REAL-LONDON, V23, P19, DOI 10.1007/s10055-018-0365-0
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Federal Highway Administration U.S. Department of Transportation, 2003, US MAN UN TRAFF CONT
   Gérin-Lajoie M, 2005, MOTOR CONTROL, V9, P242, DOI 10.1123/mcj.9.3.242
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   HALL ET, 1963, AM ANTHROPOL, V65, P1003, DOI 10.1525/aa.1963.65.5.02a00020
   Janeh O, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3022731
   Kim W, 2022, VIRTUAL REAL-LONDON, V26, P173, DOI 10.1007/s10055-021-00551-0
   Koilias A, 2020, BEHAV SCI-BASEL, V10, DOI 10.3390/bs10090130
   Koilias A, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1928
   Krogmeier C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1883
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Marschner L, 2015, INT J PSYCHOPHYSIOL, V97, P85, DOI 10.1016/j.ijpsycho.2015.05.007
   Meerhoff LA, 2018, ACTA PSYCHOL, V190, P248, DOI 10.1016/j.actpsy.2018.07.009
   Moore N., 2010, NONVERBAL COMMUNICAT, V5th
   Mousas C, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P40, DOI 10.1109/VR50410.2021.00024
   Mousas C, 2021, VISUAL COMPUT, V37, P2823, DOI 10.1007/s00371-021-02202-6
   Mousas C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P626, DOI [10.1109/VR46266.2020.00-19, 10.1109/VR46266.2020.1581211592060]
   Mousas C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P726, DOI [10.1109/VR.2019.8798043, 10.1109/vr.2019.8798043]
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   Moussaïd M, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002442
   Nelson MG, 2022, IEEE INT SYMP M AU R, P594, DOI 10.1109/ISMAR-Adjunct57072.2022.00123
   Obaid Mohammad, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P363, DOI 10.1007/978-3-642-23974-8_39
   Olivier AH, 2014, TRANSP RES PROC, V2, P114, DOI 10.1016/j.trpro.2014.09.015
   Pan XN, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032931
   Serafin G., 2004, SOUND DESIGN ENHANCE
   Simeone AL, 2017, IEEE T VIS COMPUT GR, V23, P1359, DOI 10.1109/TVCG.2017.2657038
   Sohre N, 2017, 2017 IEEE VIRTUAL HUMANS AND CROWDS FOR IMMERSIVE ENVIRONMENTS (VHCIE)
   Stüvel SA, 2017, IEEE T VIS COMPUT GR, V23, P1823, DOI 10.1109/TVCG.2016.2545670
   THALMANN D., 2012, Crowd Simulation, V2nd
   van Toll W, 2021, COMPUT GRAPH FORUM, V40, P731, DOI 10.1111/cgf.142664
   Volonte M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P293, DOI [10.1109/VR46266.2020.1581610451331, 10.1109/VR46266.2020.00-55]
   Wilcox Laurie M., 2006, ACM Trans. on Perception, V3, P412, DOI [DOI 10.1145/1190036.1190041, 10.1145/1190036.1190041]
   WILLIAMS EJ, 1949, AUST J SCI RES SER A, V2, P149, DOI 10.1071/CH9490149
   Xu ML, 2014, J COMPUT SCI TECH-CH, V29, P799, DOI 10.1007/s11390-014-1469-y
   Zibrek K, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419985
   Zibrek K, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119887
NR 53
TC 3
Z9 3
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2169
EA MAY 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000986046800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, JW
   Wu, HY
   Chen, Q
   Hachiya, H
AF Zhang, Jiwei
   Wu, Haiyuan
   Chen, Qian
   Hachiya, Hirotaka
TI Multi-feature subspace representation network for person
   re-identification via bird's-eye view image
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE bird's-eye view image; correlation learning; multi-feature; person
   re-identification
ID CLASSIFIER
AB Person re-identification (Re-ID) is one of the most remarkable research topics that widely applied in our daily lives. For person Re-ID in bird's eye scenes, traditional computer vision-based methods used multiple features, for example, texture and color, of a pedestrian's head and shoulders. Those methods are difficult to cope with environments of variety and the change the appearance of different people due to the instability of feature detection. On the other hand, although recent advanced deep learning-based methods are powerful to extract discriminative features, the requirement of a large amount of annotated training data restricts the appliable tasks. To overcome this problem, in this article, we propose a novel method fusing multiple heterogeneous features through a multi-feature subspace representation network (MFSRN) to maximize the classification performance while keeping the disparity among features as small as possible, that is, common-subspace constraints. We conducted comparative experiments with state-of-the-art models on the bird's-eye view person dataset, and extensive experimental results demonstrated that our proposed MFSRN could achieve better recognition performance. Furthermore, the validity and stability of the method are confirmed.
C1 [Zhang, Jiwei; Hachiya, Hirotaka] Wakayama Univ, Dept Syst Engn, Wakayama, Japan.
   [Wu, Haiyuan; Chen, Qian] Sense Time Japan Co Ltd, Kyoto, Japan.
   [Wu, Haiyuan] Sense Time Japan Co Ltd, Kyoto 6040022, Japan.
C3 Wakayama University
RP Wu, HY (corresponding author), Sense Time Japan Co Ltd, Kyoto 6040022, Japan.
EM wuhy@wakayama-u.ac.jp
OI zhang, jiwei/0000-0003-4494-8648
FU Innovation Platform for Society 5.0 from Japan Ministry of Education,
   Culture, Sports, Science and Technology [20K11953]; Grants-in-Aid for
   Scientific Research [20K11953] Funding Source: KAKEN
FX ACKNOWLEDGMENTS This work is partially supported by Innovation Platform
   for Society 5.0 from Japan Ministry of Education, Culture, Sports,
   Science and Technology. Research funding support: 20K11953.
CR Al Taleb AR, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATICS, HEALTH & TECHNOLOGY (ICIHT)
   [Anonymous], IQIYI VID LARGE DATA
   Chen C.-H., 2015, Handbook of pattern recognition and computer vision, DOI DOI 10.1142/9789814656535_0002
   Dadi H.S., 2016, IOSR J. Electron. Commun.Eng., V11, P34, DOI 10.9790/2834-1104013444
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gibbs MN, 2000, IEEE T NEURAL NETWOR, V11, P1458, DOI 10.1109/72.883477
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493
   Kingma D. P., 2014, arXiv
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Luo Y, 2013, OPTIK, V124, P2767, DOI 10.1016/j.ijleo.2012.08.040
   Maillo J, 2017, KNOWL-BASED SYST, V117, P3, DOI 10.1016/j.knosys.2016.06.012
   MITCHELL TJ, 1992, 1992 WINTER SIMULATION CONFERENCE PROCEEDINGS, P565, DOI 10.1145/167293.167638
   Nakatani R, 2012, J ADV COMPUT INTELL, V16, P696, DOI 10.20965/jaciii.2012.p0696
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Ren LL, 2017, PATTERN RECOGN, V72, P446, DOI 10.1016/j.patcog.2017.06.037
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tharwat A, 2016, INT J APPL PATTERN R, V3, P145, DOI 10.1504/IJAPR.2016.079050
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Visa S., 2011, Maics, V710, P120
   Wang K., 2016, A comprehensive survey on cross-modal retrieval
   Wang WR, 2015, PR MACH LEARN RES, V37, P1083
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu H., 2021, PRINC CHINA SER, V32, P40
   Ye M., 2020, Deep learning for person re-identification: A survey and outlook
   Ye M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13547, DOI 10.1109/ICCV48922.2021.01331
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang JW, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2021), P264, DOI 10.1109/ICMA52036.2021.9512734
   Zheng Liang., 2016, Person re-identification: Past, present and future
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
NR 39
TC 0
Z9 0
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2145
EA FEB 2023
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HA0R0
UT WOS:000937660600001
DA 2024-07-18
ER

PT J
AU Li, YQ
   Mao, TL
   Meng, RY
   Yan, QY
   Wang, ZQ
AF Li, Yaqiang
   Mao, Tianlu
   Meng, Ruoyu
   Yan, Qinyuan
   Wang, Zhaoqi
TI DeepORCA: Realistic crowd simulation for varying scenes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 35th International Conference on Computer Animation and Social Agents
   (CASA)
CY JUL 05-07, 2022
CL Nanjing, PEOPLES R CHINA
SP Nanjing Univ
DE crowd simulation; deep learning; ORCA; virtual worlds
AB Crowd simulation is a challenging problem, aiming to generate realistic pedestrians motions in virtual environment. Nowadays, ORCA is a widely used simulation algorithm in practice because of its stable and efficient performance. However, this algorithm cannot regenerate continuity and diversity of pedestrian motions in real data, leading to defects in motion fidelity. Otherwise, trajectory prediction methods based on deep learning have progressed in real pedestrians movement patterns mining. However, they are rarely applied in simulation due to the lack of ability to avoid collision and adapt to manufactured scenarios. Our work proposes a simulation method DeepORCA that integrates ORCA with a CVAE-based velocity probability generator, which can model motion continuity, variable intentions, and scene semantics. Moreover, DeepORCA converts the velocity optimization into quadratic programming, which accelerates the calculation while maintaining the collision-avoidance ability of ORCA. In the experiments of real and artificial scenes, our method produces more realistic crowd simulation results than ORCA quantitatively and qualitatively, while keeps the computational efficiency at the same order of magnitude.
C1 [Li, Yaqiang; Mao, Tianlu; Yan, Qinyuan; Wang, Zhaoqi] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Li, Yaqiang; Yan, Qinyuan] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Meng, Ruoyu] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Beijing University of Posts & Telecommunications
RP Mao, TL (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
EM ltm@ict.ac.cn
OI Li, Yaqiang/0000-0002-6199-2168
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Bera A, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P112
   Best A, 2016, IEEE INT CONF ROBOT, P298, DOI 10.1109/ICRA.2016.7487148
   Boltes M, 2010, PEDESTRIAN AND EVACUATION DYNAMICS 2008, P43, DOI 10.1007/978-3-642-04504-2_3
   Chung Junyoung, 2014, ARXIV14123555
   Ciampi L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185250
   Cunjun Y., 2020, EUROPEAN C COMPUTER, P507
   Curtis S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P128, DOI 10.1109/ICCVW.2011.6130234
   Curtis S., 2014, Pedestrian and Evacuation Dynamics 2012, P875
   Curtis S., 2012, Proceedings of the ACM SIGGRAPH symposium on interactive 3D graphics and games. ACM, P15
   Giuliari F, 2021, INT C PATT RECOG, P10335, DOI 10.1109/ICPR48806.2021.9412190
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   He L, 2016, IEEE INT CONF ROBOT, P292, DOI 10.1109/ICRA.2016.7487147
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Huang YF, 2019, IEEE I CONF COMP VIS, P6281, DOI 10.1109/ICCV.2019.00637
   Ivanovic B, 2019, IEEE I CONF COMP VIS, P2375, DOI 10.1109/ICCV.2019.00246
   Karamouzas I, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.238701
   Kazemnejad A, 2019, Transformer architecture: the positional encoding
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Narang S, 2017, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/aa58ab
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Ren JP, 2021, IEEE T VIS COMPUT GR, V27, P1953, DOI 10.1109/TVCG.2019.2946769
   Salzmann Tim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P683, DOI 10.1007/978-3-030-58523-5_40
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Sohn K., 2015, Neural Information Processing Systems, P3483
   Staniszewski M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174960
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   van Toll W, 2021, COMPUT GRAPH FORUM, V40, P731, DOI 10.1111/cgf.142664
   van Toll W., 2020, P S INTERACTIVE 3D G, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   Yao Y, 2021, IEEE ROBOT AUTOM LET, V6, P1463, DOI 10.1109/LRA.2021.3056339
   Zhao M, 2018, COMPUT GRAPH FORUM, V37, P184, DOI 10.1111/cgf.13259
   Zhao MB, 2018, ACM T MODEL COMPUT S, V28, DOI 10.1145/3177776
NR 35
TC 2
Z9 2
U1 2
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2067
DI 10.1002/cav.2067
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 2S4AL
UT WOS:000821735900022
DA 2024-07-18
ER

PT J
AU Zhang, JJ
   Lei, JS
   Yang, SY
   Yang, XQ
AF Zhang, Jingjing
   Lei, Jingsheng
   Yang, Shengying
   Yang, Xinqi
TI Semantic interaction learning for fine-grained vehicle recognition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE contrastive information collection; fine-grained vehicle recognition;
   pairwise interaction; semantic differences
ID DEEP; CLASSIFICATION
AB Fine-grained vehicle recognition is a challenging problem due to high inter-class confusion among vehicle models under the influence of pose and viewpoint. To effectively describe the discriminative characteristics, many approaches try to learn detailed information from an individual image. Inspired by Siamese network that addresses the case where two inputs are relatively similar, the semantic interaction learning network (SIL-Net) is designed to discover semantic differences between two fine-grained categories via pairwise comparison. Specifically, SIL-Net first collecting contrastive information by learning the mutual feature of input image pair, and then compare it with individual features to generate corresponding semantic features. These features learn semantic differences from contextual comparison, this gives SIL-Net the ability to distinguish between two confusing images via pairwise interaction. After training, SIL-Net can adaptively learn feature priorities under the supervision of the margin ranking loss and converge quickly. SIL-Net performs well on two public vehicle benchmarks (Stanford Cars and CompCars), showing the suitability of SIL-Net to fine-grained vehicle recognition.
C1 [Zhang, Jingjing; Lei, Jingsheng; Yang, Shengying; Yang, Xinqi] Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, 318 Liuhe Rd, Hangzhou 310023, Zhejiang, Peoples R China.
C3 Zhejiang University of Science & Technology
RP Lei, JS; Yang, SY (corresponding author), Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, 318 Liuhe Rd, Hangzhou 310023, Zhejiang, Peoples R China.
EM jshlei@zust.edu.cn; syyang@zust.edu.cn
RI wen, liang/JNR-7720-2023; XIE, WANYING/JNR-9259-2023; WANG,
   JIAXUAN/JMP-8599-2023; Zhang, Jun/JPK-7723-2023; wang,
   zhiwen/JDV-9990-2023
FU Natural Science Foundation of China [61672337, 61972357]; Zhejiang Key
   RD Program [2019C03135]; Medical Science and Technology Project of
   Zhejiang Province [2022KY104]
FX Natural Science Foundation of China, Grant/Award Numbers: 61672337,
   61972357; Zhejiang Key R&D Program, Grant/Award Number: 2019C03135;
   Medical Science and Technology Project of Zhejiang Province, Grant/Award
   Number: 2022KY104
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Biglari M, 2018, IEEE T INTELL TRANSP, V19, P273, DOI 10.1109/TITS.2017.2749961
   Boonsim N, 2017, PATTERN ANAL APPL, V20, P1195, DOI 10.1007/s10044-016-0559-6
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   Chang DL, 2020, IEEE T IMAGE PROCESS, V29, P4683, DOI 10.1109/TIP.2020.2973812
   Cui Y, 2017, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2017.325
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu B, 2017, NEUROCOMPUTING, V243, P60, DOI 10.1016/j.neucom.2017.02.085
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu QC, 2017, IEEE T INTELL TRANSP, V18, P3147, DOI 10.1109/TITS.2017.2679114
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li XX, 2019, IEEE T VEH TECHNOL, V68, P4204, DOI 10.1109/TVT.2019.2895651
   Li XJ, 2021, INT C PATT RECOG, P3660, DOI 10.1109/ICPR48806.2021.9412252
   Liao QV, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173577
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2018, KNOWL-BASED SYST, V160, P167, DOI 10.1016/j.knosys.2018.06.035
   Liu W, 2017, IEEE ACCESS, V5, P24417, DOI 10.1109/ACCESS.2017.2766203
   Liu X, 2016, AIP CONF PROC, V1769, DOI 10.1063/1.4963515
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nauta M, 2021, PROC CVPR IEEE, P14928, DOI 10.1109/CVPR46437.2021.01469
   Parkhi OM, 2011, IEEE I CONF COMP VIS, P1427, DOI 10.1109/ICCV.2011.6126398
   Prokaj J., 2009, Workshop on Applications of Computer Vision, P1
   Shi WW, 2019, IEEE T NEUR NET LEAR, V30, P683, DOI 10.1109/TNNLS.2018.2852721
   Silva B, 2021, IEEE INT CONF AUTON, P209, DOI 10.1109/ICARSC52212.2021.9429780
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Sochor J, 2019, IEEE T INTELL TRANSP, V20, P97, DOI 10.1109/TITS.2018.2799228
   Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Xiang Y, 2020, IEEE T INTELL TRANSP, V21, P2918, DOI 10.1109/TITS.2019.2921732
   Xiao LX, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511399
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xin Q, 2019, IEEE IMAGE PROC, P420, DOI [10.1109/ICIP.2019.8802935, 10.1109/icip.2019.8802935]
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35
   Zhang XF, 2016, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2016.126
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zhang YB, 2020, IEEE T MULTIMEDIA, V22, P1345, DOI 10.1109/TMM.2019.2939747
   Zhao YF, 2021, PROC CVPR IEEE, P15074, DOI 10.1109/CVPR46437.2021.01483
   Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zou C, 2019, IEEE INT CONF BIG DA, P5116
NR 48
TC 3
Z9 3
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2022
VL 33
IS 1
AR e2036
DI 10.1002/cav.2036
EA DEC 2021
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH4XD
UT WOS:000727346000001
DA 2024-07-18
ER

PT J
AU Messaci, A
   Zenati, N
   Belhocine, M
   Otmane, S
AF Messaci, Assia
   Zenati, Nadia
   Belhocine, Mahmoud
   Otmane, Samir
TI <i>Zoom-fwd</i>: Efficient technique for 3D gestual interaction with
   distant and occluded objects in virtual reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D interaction; gesture recognition; virtual reality
ID SELECTION TECHNIQUES
AB In the last decade, there has been an extraordinary acceleration in immersive technologies, including virtual reality (VR) and augmented reality (AR). The VR interfaces have widely explored various 3D interaction-based approaches. 3D interaction is one of the main features of any VR system. However, the problems while selecting and manipulating distant and occluded 3D virtual objects in VR are still unresolved and suffer from a lack of precision and accuracy. To interact with VR/AR systems, various devices such as VR headsets or gloves are used. These devices are not very reliable yet; in fact they are inconvenient and invasive to a person's comfort. Currently, the natural user interfaces (NUIs) are increasingly introduced in human computer interaction (HCI) systems as gestures recognition, which prove to be very useful in the improvement of the user engagement and presence sensing. More particularly, they provide more user-friendly and nonintrusive 3D interaction methods and techniques. In this article, the Zoom-fwd, which is an efficient 3D interaction technique is presented. The proposed technique uses gesture recognition for different 3D interaction tasks like selection and manipulation. This new approach allows an efficient interaction with distant and occluded objects, while providing a precise selection, even when the environment is crowded. The Zoom-fwd technique is a software solution for a number of hardware and software problems. A user study is conducted to determine whether the proposed technique is more suitable when performing interaction tasks. The results show that the Zoom-fwd technique provides effective interaction with distant and occluded objects, by improving the user task completion performance. In addition, this indicates that selection precision has been enhanced significantly with the Zoom-fwd technique.
C1 [Messaci, Assia] Univ Larbi Ben Mhidi Oum El Bouaghi, Dept Math & Informat, Oum El Bouaghi, Algeria.
   [Zenati, Nadia; Belhocine, Mahmoud] Ctr Dev Technol Avancees CDTA Alger, DPR, Baba Hassen, Algeria.
   [Otmane, Samir] Univ Evry, Univ Paris Saclay, IBISC, Evry, France.
C3 Universite d'Oum El Bouaghi; Universite Paris Cite; Universite Paris
   Saclay
RP Messaci, A (corresponding author), Ctr Dev Technol Avancees CDTA Alger, Baba Hassen, Algeria.
EM amessaci@cdta.dz
OI Otmane, Samir/0000-0003-2221-4264; MESSACI, messaci/0000-0002-3548-9542
CR Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Argelaguet F, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.117
   Bacim F, 2013, INT J HUM-COMPUT ST, V71, P785, DOI 10.1016/j.ijhcs.2013.03.003
   Bellarbi A, 2017, 2017 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING - BOUMERDES (ICEE-B), DOI 10.1109/ATNAC.2017.8215417
   Bellarbi B., 2015, EL ENG ICEE 2015 4 I, P1, DOI 10.1109/INTEE.2015.7416813
   Bhowmik AK., 2015, INTERACTIVE DISPLAYS, P165
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Buckwald M., 2015, ELECT SENSOR
   Caggianese G, 2016, LECT NOTES COMPUT SC, V9769, P318, DOI 10.1007/978-3-319-40651-0_26
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Dardas Nasser H, 2011, The Research Bulletin of Jordan ACM, V2, P86
   Davis, 2014, GETTING STARTED LEAP
   Feiner A.O.S., 2003, P UIST, V3, P81
   Forsberg A., 1996, P 9 ANN ACM S USER I, P95, DOI 10.1145/237091.237105
   Hassanpour Reza, 2009, Journal of Computer Engineering, V1, P3
   Hui P., 2019, ARXIV PREPRINT ARXIV
   JACOBY R, 1994, P SOC PHOTO-OPT INS, V2177, P355, DOI 10.1117/12.173892
   Jankowski J, 2015, COMPUT GRAPH FORUM, V34, P152, DOI 10.1111/cgf.12466
   Jia J, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4898
   Khamis S, 2015, PROC CVPR IEEE, P2540, DOI 10.1109/CVPR.2015.7298869
   Kim M, 2016, MULTIMED TOOLS APPL, V75, P16529, DOI 10.1007/s11042-016-3355-9
   LIANG JD, 1994, COMPUT GRAPH, V18, P499, DOI 10.1016/0097-8493(94)90062-0
   Lund A M., 2001, USABILITY INTERFACE, V8, P3, DOI DOI 10.1177/1078087402250360
   Mendes D, 2019, COMPUT GRAPH FORUM, V38, P21, DOI 10.1111/cgf.13390
   Ouramdane N., 2006, P 2006 ACM INT C VIR, P137
   Pierce J. S., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P141, DOI 10.1145/300523.300540
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Sherman WilliamR., 2003, UNDERSTANDING VIRTUA
   Stoakley R., 1995, P SIGCHI C HUM FACT, P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
   Takahashi T., 1992, Systems and Computers in Japan, V23, P38, DOI 10.1002/scj.4690230304
   Vanacken L, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P115
   Wang R., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology. UIST '11, P549
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Wigdor D, 2011, BRAVE NUI WORLD: DESIGNING NATURAL USER INTERFACES FOR TOUCH AND GESTURE, P1
   ZHAI SM, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P459, DOI 10.1145/191666.191822
NR 37
TC 1
Z9 1
U1 6
U2 27
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2022
VL 33
IS 1
AR e2033
DI 10.1002/cav.2033
EA NOV 2021
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH4XD
UT WOS:000713837600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Victor, L
   Meyer, A
   Bouakaz, S
AF Victor, Leon
   Meyer, Alexandre
   Bouakaz, Saida
TI Learning-based pose edition for efficient and interactive design
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character pose design; machine learning for animation
ID INVERSE; FABRIK
AB Authoring an appealing animation for a virtual character is a challenging task. In computer-aided keyframe animation artists define the key poses of a character by manipulating its underlying skeletons. To look plausible, a character pose must respect many ill-defined constraints, and so the resulting realism greatly depends on the animator's skill and knowledge. Animation software provide tools to help in this matter, relying on various algorithms to automatically enforce some of these constraints. The increasing availability of motion capture data has raised interest in data-driven approaches to pose design, with the potential of shifting more of the task of assessing realism from the artist to the computer, and to provide easier access to nonexperts. In this article, we propose such a method, relying on neural networks to automatically learn the constraints from the data. We describe an efficient tool for pose design, allowing Naive users to intuitively manipulate a pose to create character animations.
C1 [Victor, Leon; Meyer, Alexandre; Bouakaz, Saida] Univ Lyon, LIRIS, UMR CNRS 5205, Lyon, France.
   [Victor, Leon] INSA Lyon, Villeurbanne, France.
   [Meyer, Alexandre; Bouakaz, Saida] Univ Claude Bernard Lyon 1, Lyon, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon; Institut
   National des Sciences Appliquees de Lyon - INSA Lyon; Universite Claude
   Bernard Lyon 1
RP Victor, L (corresponding author), Univ Lyon, LIRIS, UMR CNRS 5205, Lyon, France.
EM leon.victor@insa-lyon.fr
OI MEYER, Alexandre/0000-0002-0249-1048; Victor, Leon/0000-0003-1694-7189
CR Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Aristidou A, 2016, COMPUT ANIMAT VIRT W, V27, P35, DOI 10.1002/cav.1630
   Aristidou A, 2011, GRAPH MODELS, V73, P243, DOI 10.1016/j.gmod.2011.05.003
   Berson E, 2020, COMPUT GRAPH FORUM, V39, P241, DOI 10.1111/cgf.14117
   Buss S. R., 2005, Journal of Graphics Tools, V10, P37
   Cani, 2019, P MIG 2019 ACM SIGGR
   Guay M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508397
   Holden D., 2015, P SIGGRAPH AS TECH B, DOI DOI 10.1145/2820903.2820918
   Holden D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392440
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Huang J, 2017, COMPUT GRAPH FORUM, V36, P418, DOI 10.1111/cgf.13089
   Kingma D. P., 2014, arXiv
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Pelachaud C., 2014, P 9 INT C LANG RES E
   Rose C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P147, DOI 10.1145/237170.237229
   Siciliano B, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1, DOI 10.1007/978-3-319-32552-1
   Starke S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356505
   WANG LCT, 1991, IEEE T ROBOTIC AUTOM, V7, P489, DOI 10.1109/70.86079
   Wu XM, 2011, IEEE COMPUT GRAPH, V31, P69, DOI 10.1109/MCG.2009.111
NR 20
TC 1
Z9 1
U1 4
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2013
DI 10.1002/cav.2013
EA JUN 2021
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000659900700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, D
   Yang, WJ
   Li, ML
   Yang, Q
AF Yang, Dong
   Yang, Wenjing
   Li, Minglong
   Yang, Qiong
TI Role-based attention in deep reinforcement learning for games
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE attention; football game; reinforcement learning; role-based
AB Reinforcement learning method that learns while interacting with the environment, relies heavily on the concept of state as the input to the policy and value function. In the task, the view of agent contains a lot of information, and it is difficult for the agent to learn to ignore the irrelevant information and focus on the key information. Inspired by recent work in attention models for computer vision, we present a role-based attention model for reinforcement learning. The proposed model uses convolutional neural networks to generate soft attention maps, adding crucial role information in the task, forcing the agent to focus on important features and distinguish task-related information. To validate the performance in complex problems, the proposed approach is evaluated in a challenging scenario, Football Academy in Google Research Football Environment, a newly released reinforcement learning environment with physics-based three-dimensional simulator. The experimental results demonstrate that agents using role-based attention mechanism can perform better in football games.
C1 [Yang, Dong; Yang, Wenjing; Li, Minglong; Yang, Qiong] Natl Univ Def Technol, Inst Quantum Informat, Coll Comp, Changsha 410073, Peoples R China.
   [Yang, Dong; Yang, Wenjing; Li, Minglong; Yang, Qiong] Natl Univ Def Technol, State Key Lab High Performance Comp, Coll Comp, Changsha 410073, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China
RP Yang, WJ (corresponding author), Natl Univ Def Technol, Inst Quantum Informat, Coll Comp, Changsha 410073, Peoples R China.; Yang, WJ (corresponding author), Natl Univ Def Technol, State Key Lab High Performance Comp, Coll Comp, Changsha 410073, Peoples R China.
EM wenjing.yang@nudt.edu.cn
FU National Key Research and Development Program of China [2017YFB1300203]
FX This work was supported by the National Key Research and Development
   Program of China under Grant 2017YFB1300203.
CR Bengio Y., 2014, TECHNICAL REPORT
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Greydanus S, 2018, PR MACH LEARN RES, V80
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Iqbal S., 2018, PROC INT C MACH LEAR, VVolume 97, P2961
   Ivanov S., 2019, Modern Deep Reinforcement Learning Algorithms
   Mnih V, 2013, ARXIV
   Mott A., 2019, ADV NEUR IN, P12350
   Reizinger P, 2020, INT CONF ACOUST SPEE, P3542, DOI [10.1109/icassp40776.2020.9054546, 10.1109/ICASSP40776.2020.9054546]
   Schulman J., 2017, ARXIV
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sorokin I, 2015, ARXIV PREPRINT ARXIV
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang D, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1978
NR 16
TC 3
Z9 3
U1 1
U2 24
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2021
VL 32
IS 2
AR e1978
DI 10.1002/cav.1978
EA JAN 2021
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RK2HP
UT WOS:000613136000001
DA 2024-07-18
ER

PT J
AU Kim, SU
   Jang, H
   Kim, J
AF Uk Kim, Seong
   Jang, Hanyoung
   Kim, Jongmin
TI A variational U-Net for motion retargeting
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deep learning; human motion; motion retargeting
AB Motion retargeting is the process of copying motion from one character (source) to another (target) when the source and target body sizes and proportions (of arms, legs, torso, etc.) are different. The problem of automatic motion retargeting has been studied for several decades; however, the motion quality obtained with the application of current approaches is on occasion unrealistic. This is because previous methods, which are mainly based on numerical optimization, generally do not incorporate prior knowledge of the details and nuances of human movements. To address these issues, we present a novel human motion retargeting system using a deep learning framework with large-scale motion data to produce high-quality retargeted human motion. We establish a deep-learning-based motion retargeting system using a variational deep autoencoder combining the deep convolutional inverse graphics network (DC-IGN) and the U-Net. The DC-IGN is utilized for disentangling the motion of each body part, while the U-Net is employed to preserve details of the original motion. We conduct several experiments to validate the proposed motion retargeting system, and find that ours achieves better accuracy along with reduced computational burden when compared with the conventional motion retargeting approach and other neural network architectures.
C1 [Uk Kim, Seong; Kim, Jongmin] Kangwon Natl Univ, Comp Sci & Engn, Chunchon, South Korea.
   [Jang, Hanyoung] NCSOFT, Game AI Lab, Mot AI Team, Seongnam, South Korea.
C3 Kangwon National University
RP Kim, J (corresponding author), Kangwon Natl Univ, Comp Sci & Engn, Chunchon, South Korea.
EM jongmin.kim@kangwon.ac.kr
OI Kim, Seong Uk/0000-0002-3467-9758
FU National Research Foundation of Korea (NRF) - Korea government
   [NRF-2019R1F1A1063467]; NCSOFT
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (NRF-2019R1F1A1063467). It
   was also supported by NCSOFT.
CR [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2015, P IEEE INT C COMP VI
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Buss S. R., 2004, IEEE J ROBOTIC AUTOM, V17, P16
   Choi KJ, 2000, J VISUAL COMP ANIMAT, V11, P223, DOI 10.1002/1099-1778(200012)11:5<223::AID-VIS236>3.0.CO;2-5
   CMU, 2013, CMU CARNEGIE MELLON
   Cui QJ, 2020, NEURAL COMPUT APPL, V32, P10127, DOI 10.1007/s00521-019-04543-9
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Huang J, 2017, COMPUT GRAPH FORUM, V36, P418, DOI 10.1111/cgf.13089
   Kulkarni TD, 2015, ADV NEUR IN, V28
   Lee J, 1999, COMP GRAPH, P39
   Lim Jongin, 2019, BMVC
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Sorkine O., 2009, TECHNICAL NOTES, V120, P3
   Taylor G, 2009, P 26 ANN INT C MACH
   Taylor GW, 2007, ADV NEURAL INFORM PR, P1345, DOI DOI 10.7551/MITPRESS/7503.003.0173
   Villegas R, 2018, PROC CVPR IEEE, P8639, DOI 10.1109/CVPR.2018.00901
   Yang YH, 2018, CONFERENCE PROCEEDINGS OF THE 6TH INTERNATIONAL SYMPOSIUM ON PROJECT MANAGEMENT (ISPM2018), P935
NR 21
TC 3
Z9 3
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1947
DI 10.1002/cav.1947
EA SEP 2020
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000567585600001
DA 2024-07-18
ER

PT J
AU Oshita, M
   Senju, Y
AF Oshita, Masaki
   Senju, Yuta
TI Generating hand motion from body motion based on hand pose estimation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; hand motion; machine learning; pattern recognition
AB In this paper, we propose a method to generate hand motion from full-body motion. We assume that hand pose can be estimated from full-body pose. We use a support vector machine to choose one of four key hand poses based on the full-body pose. The training model is constructed from a number of full-body motions with manually specified hand-pose keyframes. The output poses are synthesized to include the generated continuous hand motion. We realize smooth transitions between key hand poses and add small movements of fingers for generating plausible hand motions. Because our method does not require future poses, it is valid for both on-line and off-line animation. Our experimental results show that our model is applicable to a wide range of full-body motions.
C1 [Oshita, Masaki; Senju, Yuta] Kyushu Inst Technol, Iizuka, Fukuoka, Japan.
C3 Kyushu Institute of Technology
RP Oshita, M (corresponding author), Kyushu Inst Technol, Iizuka, Fukuoka, Japan.
EM oshita@ces.kyutech.ac.jp
FU JSPS [24500238, 151-102704]; Grants-in-Aid for Scientific Research
   [24500238, 15H02704] Funding Source: KAKEN
FX Grant-in-Aid for Scientific Research, Grant/Award Number: 24500238,
   151-102704, JSPS
CR [Anonymous], 1985, ACM SIGGRAPH COMPUTE
   Bai Y, 2014, IEEE INT C ROB AUT I, P309
   Faloutsos P, 2001, COMP GRAPH, P251, DOI 10.1145/383259.383287
   Grassia F. S., 1998, J. Graph. Tools, V6, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]
   Jörg S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366208
   Jorg S., 2010, P 7 S APPL PERCEPTIO, P129, DOI DOI 10.1145/1836248.1836273
   Levine S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778861
   Levine S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618518
   Liu K, 2009, ACM T GRAPHIC, V28
   Majkowska A, 2006, P 2006 ACM SIGGRAPH, P309, DOI DOI 10.1145/1218064.1218106
   Neff M, 2006, MODELING RELAXED HAN
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   Oshita M, 2015, COMP ANIM VIRTUAL WO
   PERLIN K, 1995, IEEE T VIS COMPUT GR, V1, P5, DOI 10.1109/2945.468392
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Vapnik VN, 2000, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-3264-1
   Wheatland N, 2013, AUTOMATIC HAND OVER, P197
   Wheatland N, 2015, COMPUT GRAPH FORUM, V34, P735, DOI 10.1111/cgf.12595
   YE YT, 2012, ACM T GRAPHIC, V31, DOI DOI 10.1145/2185520.2185537
   Zordan V, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P81
NR 20
TC 0
Z9 0
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2018
VL 29
IS 6
AR e1730
DI 10.1002/cav.1730
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HH9VW
UT WOS:000456089800003
DA 2024-07-18
ER

PT J
AU Tsuruga, J
   Iwasaki, K
AF Tsuruga, Junki
   Iwasaki, Kei
TI Sawtooth cycle revisited
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE conjugate gradient method; multigrid; pressure Poisson equation;
   sawtooth cycle; V-cycle
ID MULTIGRID POISSON SOLVER
AB Solving the pressure Poisson equation dominates a large portion of computational time for incompressible fluid flow simulations. To solve the pressure Poisson equation efficiently, geometric multigrid methods are used directly or used as the preconditioner for the conjugate gradient (CG) method. Conventionally, the V-cycle multigrid method is widely employed, and little attention has been paid to other cycles. In this paper, we introduce the sawtooth cycle multigrid method and its simple extension called N-cycle, which provides better convergence in equal time comparison with the V-cycle as a direct solver of the pressure Poisson equation. We also apply the N-cycle to the preconditioner of the CG method and show that the N-cycle multigrid CG method can provide better convergence than the V-cycle multigrid CG method.
C1 [Tsuruga, Junki; Iwasaki, Kei] Wakayama Univ, Wakayama, Japan.
   [Iwasaki, Kei] Dwango Co Ltd, Dwango CG Res, Tokyo, Japan.
C3 Wakayama University
RP Iwasaki, K (corresponding author), Wakayama Univ, Wakayama, Japan.; Iwasaki, K (corresponding author), Dwango Co Ltd, Dwango CG Res, Tokyo, Japan.
EM iwasaki@sys.wakayama-u.ac.jp
RI Iwasaki, Kei/GNH-6504-2022
OI Iwasaki, Kei/0000-0002-5235-536X
FU Japan Society for the Promotion of Science KAKENHI (JSPS KAKENHI)
   [JP15H05924]
FX Japan Society for the Promotion of Science KAKENHI (JSPS KAKENHI),
   Grant/Award Number: JP15H05924
CR Aanjaneya M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073625
   [Anonymous], MANTAFLOW
   [Anonymous], 2010, P 2010 ACM SIGGRAPHE
   Bolz J, 2003, ACM T GRAPHIC, V22, P917, DOI 10.1145/882262.882364
   Chentanez N., 2011, ACM T GRAPHIC, V30
   Chentanez N., 2011, P 2011 ACM SIGGRAPHE, P83
   Dick C, 2016, IEEE T VIS COMPUT GR, V22, P2480, DOI 10.1109/TVCG.2015.2511734
   Goodnight N., 2003, P ACM SIGGRAPHEUROGR, P102
   Jung HR, 2013, COMPUT ANIMAT VIRT W, V24, P185, DOI 10.1002/cav.1498
   Kazhdan M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360620
   Krishnan D, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024211
   Lyengar SRK, 1992, NUMER METH PART D E, V8, P113
   Setaluri R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661269
   Shi L, 2006, ACM T GRAPHIC, V25, P1108, DOI 10.1145/1141911.1142001
   Shi XH, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618519
   Takahashi T, 2016, COMPUT GRAPH FORUM, V35, P517, DOI 10.1111/cgf.13048
   Tamstorf R, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818081
   Trottenberg U, 2000, Multigrid
   Weber D, 2015, COMPUT GRAPH FORUM, V34, P481, DOI 10.1111/cgf.12577
NR 19
TC 0
Z9 0
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1836
DI 10.1002/cav.1836
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100027
DA 2024-07-18
ER

PT J
AU Tsai, TY
   Wong, SK
   Chou, YH
   Lin, GW
AF Tsai, Tsung-Yu
   Wong, Sai-Keung
   Chou, Yi-Hung
   Lin, Guan-Wen
TI Directing virtual crowds based on dynamic adjustment of navigation
   fields
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE agent-based; crowd simulation; guidance path; navigation field
ID PATH; MODEL
AB Navigation fields are a popular data structure for directing the movement of virtual crowds. However, the congestion problem may occur at the corners of objects in using a navigation field because the agents move quite closely to each other. The agents may congest at the corners even though there is room for the agents to move away from the congested regions. In this paper, we propose to place crowd monitors at the corners to collect the data such as the movement direction of crowds and crowd densities. Then the navigation field is adjusted dynamically so that the crowds are led to move away from the congested regions. We also propose a simple data structure for speeding up the collision detection process between agents and objects. Experimental results show that our approach successfully alleviates the congestion problem at the corners.
C1 [Tsai, Tsung-Yu] Natl Chiao Tung Univ, Hsinchu, Taiwan.
   [Wong, Sai-Keung] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Wong, Sai-Keung; Lin, Guan-Wen] Natl Chiao Tung Univ, Inst Multimedia Engn, Hsinchu, Taiwan.
   [Chou, Yi-Hung] Natl Chiao Tung Univ, Dept Multimedia Engn, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University; National Yang Ming Chiao Tung University; National Yang Ming
   Chiao Tung University
RP Wong, SK (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.; Wong, SK (corresponding author), Natl Chiao Tung Univ, Inst Multimedia Engn, Hsinchu, Taiwan.
EM wingo.wong@gmail.com
FU Ministry of Science and Technology of ROC (Taiwan) [MOST
   103-2221-E-009-122-MY3, MOST 104-2221-E-009-051-MY3]
FX Ministry of Science and Technology of ROC (Taiwan), Grant/Award Number:
   MOST 103-2221-E-009-122-MY3, MOST 104-2221-E-009-051-MY3
CR Amato NM, 1996, IEEE INT CONF ROBOT, P113, DOI 10.1109/ROBOT.1996.503582
   [Anonymous], 2009, P 4 INT C FDN DIGITA, DOI DOI 10.1145/1536513.1536540
   DeBerg M, 2000, COMPUTATIONAL GEOMET
   Ferguson D, 2007, SPRINGER TRAC ADV RO, V28, P239
   Geraerts R, 2007, COMPUT ANIMAT VIRT W, V18, P107, DOI 10.1002/cav.166
   Geraerts R, 2010, IEEE INT CONF ROBOT, P1997, DOI 10.1109/ROBOT.2010.5509263
   Guy S., 2009, EUR ACM SIGGRAPH S C, P177
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Karamouzas I, 2008, COMPUT ANIMAT VIRT W, V19, P283, DOI 10.1002/cav.242
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   LaValle S. M., 2006, Planning algorithms
   Lopez T, 2012, COMPUT ANIMAT VIRT W, V23, P87, DOI 10.1002/cav.1428
   Misa TJ, 2010, COMMUN ACM, V53, P41, DOI 10.1145/1787234.1787249
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Patil S, 2011, IEEE T VIS COMPUT GR, V17, P244, DOI 10.1109/TVCG.2010.33
   Silveira R, 2008, COMPUT ANIMAT VIRT W, V19, P295, DOI 10.1002/cav.261
   Snape J., 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P4584, DOI 10.1109/IROS.2010.5652073
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van den Berg J, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P139
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   Wong SK, 2015, COMPUT ANIMAT VIRT W, V26, P387, DOI 10.1002/cav.1636
   Zeng W, 2009, INT J GEOGR INF SCI, V23, P531, DOI 10.1080/13658810801949850
NR 24
TC 8
Z9 8
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2018
VL 29
IS 1
AR e1765
DI 10.1002/cav.1765
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FV0GZ
UT WOS:000424235300001
DA 2024-07-18
ER

PT J
AU Kim, K
   Maloney, D
   Bruder, G
   Bailenson, JN
   Welch, GF
AF Kim, Kangsoo
   Maloney, Divine
   Bruder, Gerd
   Bailenson, Jeremy N.
   Welch, Gregory F.
TI The effects of virtual human's spatial and behavioral coherence with
   physical objects on social presence in AR
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE augmented reality; copresence; physical-virtual coherence; social
   presence; virtual human
ID ENVIRONMENTS; REALISM
AB In augmented reality, people can feel the illusion of virtual humans (VHs) integrated into a real (physical) space. However, affordances of the real world and virtual contents might conflict, for example, when the VHs and real objects collide by occupying the same space. This implausible conflict can cause a break in presence in real-virtual human interactions. In this paper, we address an effort to avoid this conflict by maintaining the VH's spatial and behavioral coherence with respect to the physical objects or events (e.g., natural occlusions and appropriate help-requesting behaviors to avoid implausible physical-virtual collisions). We present a human subject experiment examining the effects of the physical-virtual coherence on human perceptions, such as social/copresence and behaviors with the VH. The basic ideas, experimental design, and results supporting the benefit of the VH's spatial and behavioral coherence are presented and discussed.
C1 [Kim, Kangsoo; Bruder, Gerd; Welch, Gregory F.] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
   [Maloney, Divine] Sewanee, Dept Comp Sci, Sewanee, TN USA.
   [Bailenson, Jeremy N.] Stanford Univ, Dept Commun, Stanford, CA 94305 USA.
C3 State University System of Florida; University of Central Florida;
   Sewanee: University of the South; Stanford University
RP Kim, K (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
EM kskim@knights.ucf.edu
RI Kim, Kangsoo/AAL-9592-2020
OI Kim, Kangsoo/0000-0002-0925-378X; Welch, Gregory/0000-0002-8243-646X
FU Office of Naval Research (ONR) [N00014-14-1-0248, N00014-12-1-1003];
   Florida Hospital Endowed Chair in Healthcare Simulation
FX Office of Naval Research (ONR) Code 30, Grant/Award Number:
   N00014-14-1-0248, N00014-12-1-1003; Florida Hospital Endowed Chair in
   Healthcare Simulation
CR Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Blascovich J, 2002, COMP SUPP COMP W SER, P127
   Blascovich J., 2002, P 4 INT C COLL VIRT, P25, DOI [https://doi.org/10.1145/571878.571883, DOI 10.1145/571878.571883]
   Freeman J, 2000, PRESENCE-TELEOP VIRT, V9, P149, DOI 10.1162/105474600566691
   Fuhrmann A, 1999, COMPUT GRAPH-UK, V23, P809, DOI 10.1016/S0097-8493(99)00107-7
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   Holz T, 2011, INT J HUM-COMPUT ST, V69, P251, DOI 10.1016/j.ijhcs.2010.10.001
   Jo D, 2015, COMPUT ANIMAT VIRT W, V26, P259, DOI 10.1002/cav.1645
   Kim K, 2016, INT C ART REAL TEL E, P115
   Kim K, 2015, IEEE INT S MIX AUGM, P15
   Microsoft, 2016, SPAT MAPP WIND MIX R
   Park S, 2007, HUM FACTORS, V49, P1054, DOI 10.1518/001872007X249910
NR 15
TC 37
Z9 42
U1 2
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1771
DI 10.1002/cav.1771
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200017
DA 2024-07-18
ER

PT J
AU Etemad, SA
   Arya, A
   Parush, A
   DiPaola, S
AF Etemad, S. Ali
   Arya, Ali
   Parush, Avi
   DiPaola, Steve
TI Perceptual validity in animation of human motion
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation; motion; perception; body; face; perceptual validity
ID POINT-LIGHT; BIOLOGICAL MOTION; VISUAL-PERCEPTION; GAIT PERCEPTION;
   EMOTION; RECOGNITION; EXPRESSION; GENDER; SUBJECTIVITY; GENERATION
AB The crucial concept of modeling and synthesis/control of human motion (including face and body) for animation has been widely studied and explored in the literature. In this regard, the audience's perception of generated or recorded animation scenes is of critical importance. In this paper, we explore and conceptualize the general notions that need to be taken into account for human motion to maintain perceptual accuracy. We propose a paradigm called Perceptual Validity composed of four major components, which are discussed in detail. The model is concerned with different aspects of the scene such as correct illustration of the stimuli, context, and local/global relations of various visual cues present in human motion. Satisfying all the proposed principles, based on the literature, seems compulsory and vital for synthesis of perceptually valid animation scenes of human motion. We investigate the relative significance of the different components of the paradigm using feedback from expert animators and conduct a case study on one of the components of the paradigm. For further evaluation and exploration, Disney's principles of animation are discussed and compared against our proposed paradigm. We argue that while there are significant parallels and overlaps, our model is only focused on and more inclusive towards human motion and can therefore provide a valuable set of guidelines for animators in the field of character animation. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Etemad, S. Ali] Carleton Univ, Dept Syst & Comp Engn, Ottawa, ON K1S 5B6, Canada.
   [Arya, Ali] Carleton Univ, Sch Informat Technol, Ottawa, ON K1S 5B6, Canada.
   [Parush, Avi] Carleton Univ, Dept Psychol, Ottawa, ON K1S 5B6, Canada.
   [DiPaola, Steve] Simon Fraser Univ, Sch Interact Arts & Technol, Surrey, BC, Canada.
C3 Carleton University; Carleton University; Carleton University; Simon
   Fraser University
RP Etemad, SA (corresponding author), Carleton Univ, Dept Syst & Comp Engn, Ottawa, ON K1S 5B6, Canada.
EM ali.etemad@carleton.ca
RI Parush, Avi/AFQ-3490-2022; DiPaola, Stephen/M-5861-2013
OI DiPaola, Stephen/0000-0001-7549-9545
FU Natural Sciences and Engineering Council of Canada (NSERC); Ontario
   Centers of Excellence (OCE)
FX This work was supported in part by the Natural Sciences and Engineering
   Council of Canada (NSERC) and Ontario Centers of Excellence (OCE).
CR Aizawa K, 2000, IEEE T CIRC SYST VID, V10, P323, DOI 10.1109/76.825731
   Alam M, 2001, ARCH DERMATOL, V137, P795
   [Anonymous], 97 KSL
   [Anonymous], MULTIVARIATE BEHAV R
   [Anonymous], 1975, PICTURES FACIAL AFFE
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   [Anonymous], 2002, P 2 INT S SMART GRAP
   [Anonymous], LIFE TIMES ANIMATED
   [Anonymous], 1970, KINESICS CONTEXT ESS
   [Anonymous], EFFECT AVATAR PERCEP
   [Anonymous], EUROGRAPHICS STATE A
   [Anonymous], P COMP GRAPH INT OTT
   Arya A, 2006, COMPUT ANIMAT VIRT W, V17, P371, DOI 10.1002/cav.140
   Arya A, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/48757
   Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   BARCLAY CD, 1978, PERCEPT PSYCHOPHYS, V23, P145, DOI 10.3758/BF03208295
   Baron-Cohen S, 1998, NATURE, V392, P459, DOI 10.1038/33076
   BARTLETT JC, 1993, COGNITIVE PSYCHOL, V25, P281, DOI 10.1006/cogp.1993.1007
   Barzel R., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P183
   BERTENTHAL BI, 1994, PSYCHOL SCI, V5, P221, DOI 10.1111/j.1467-9280.1994.tb00504.x
   Blake R, 2007, ANNU REV PSYCHOL, V58, P47, DOI 10.1146/annurev.psych.57.102904.190152
   Browne C, 2010, IEEE T COMP INTEL AI, V2, P1, DOI 10.1109/TCIAIG.2010.2041928
   Calder AJ, 2005, NAT REV NEUROSCI, V6, P641, DOI 10.1038/nrn1724
   CALVERT TW, 1982, IEEE COMPUT GRAPH, V2, P41
   Cassell J., 1994, P 21 ANN C COMP GRAP, P413, DOI DOI 10.1145/192161.192272
   Cohn J.F., 2006, Proceedings of the 8th international conference on Multimodal interfaces-ICMI'06, P233, DOI DOI 10.1145/1180995.1181043
   Colton S., 2008, AAAI SPRING S CREATI, P14
   Coulson M, 2004, J NONVERBAL BEHAV, V28, P117, DOI 10.1023/B:JONB.0000023655.25550.be
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   CUTTING JE, 1978, BEHAV RES METH INSTR, V10, P91, DOI 10.3758/BF03205105
   CUTTING JE, 1978, PERCEPTION, V7, P393, DOI 10.1068/p070393
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DITTRICH WH, 1993, PERCEPTION, V22, P15, DOI 10.1068/p220015
   Dittrich WH, 1996, PERCEPTION, V25, P727, DOI 10.1068/p250727
   Egges A, 2003, LECT NOTES ARTIF INT, V2773, P453
   Eisenhauer JF, 2006, STUD ART EDUC, V47, P155, DOI 10.1080/00393541.2006.11650491
   Etemad SA, 2014, NEUROSCI LETT, V558, P132, DOI 10.1016/j.neulet.2013.11.010
   Etemad SA, 2014, NEUROCOMPUTING, V129, P585, DOI 10.1016/j.neucom.2013.09.001
   Etemad SA, 2009, P 2 IEEE INT C IMAGE, P1
   Etemad SA, 2010, GRAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P307
   Garcia M, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P107
   Harrison J, 2004, ACM T GRAPHIC, V23, P569, DOI 10.1145/1015706.1015761
   Hodgins JK, 1998, IEEE T VIS COMPUT GR, V4, P307, DOI 10.1109/2945.765325
   Jhala A, 2010, IEEE T COMP INTEL AI, V2, P69, DOI 10.1109/TCIAIG.2010.2046486
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Jokisch D, 2006, PERCEPTION, V35, P911, DOI 10.1068/p5540
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Kovar Lucas., 2002, SCA 2002: Proceedings of the 2002 ACM SIG-GRAPH/Eurographics Symposium on Computer Animation, P97
   Kowalska M., 2017, HDB COGNITION EMOTIO, P1, DOI [https://doi.org/10.1007/978-3-319-28099-8495-1, DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740
   Lasseter J., 1987, Proc. SIGGRAPH 87, V21, P35, DOI DOI 10.1145/37402.37407
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   MATHER G, 1994, P ROY SOC B-BIOL SCI, V258, P273, DOI 10.1098/rspb.1994.0173
   Mcdonnell R, 2009, ACM T APPL PERCEPT, V5, DOI 10.1145/1462048.1462051
   MCKELVIE SJ, 1995, BRIT J SOC PSYCHOL, V34, P325, DOI 10.1111/j.2044-8309.1995.tb01067.x
   MEHRABIAN A, 1995, GENET SOC GEN PSYCH, V121, P339
   Miller EugeneE., 1985, ESSAYS MORAL POLITIC
   Murray M P, 1970, Arch Phys Med Rehabil, V51, P637
   Murray M P, 1967, Am J Phys Med, V46, P290
   MURRAY MP, 1964, J BONE JOINT SURG AM, V46, P335, DOI 10.2106/00004623-196446020-00009
   NAPIER J, 1967, SCI AM, V216, P56, DOI 10.1038/scientificamerican0467-56
   Neff M, 2006, GRAPH MODELS, V68, P133, DOI 10.1016/j.gmod.2005.03.003
   Neff M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P239
   Neff M., 2005, Proceedings of ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P161
   Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47
   Patterson H., 2001, Proceedings of the 23rd Annual Conference of the Cognitive Science Society, P756
   Pedersen C, 2010, IEEE T COMP INTEL AI, V2, P54, DOI 10.1109/TCIAIG.2010.2043950
   Pelachaud C, 2003, LECT NOTES ARTIF INT, V2650, P300
   Pelachaud C, 2009, PHILOS T R SOC B, V364, P3539, DOI 10.1098/rstb.2009.0186
   Pollick FE, 2001, COGNITION, V82, pB51, DOI 10.1016/S0010-0277(01)00147-0
   Popovic Z., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P670, DOI 10.1109/ROBOT.2000.844129
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Reitsma PSA, 2003, ACM T GRAPHIC, V22, P537, DOI 10.1145/882262.882304
   Ren L, 2005, ACM T GRAPHIC, V24, P1090, DOI 10.1145/1073204.1073316
   Roether CL, 2009, J VISION, V9, DOI 10.1167/9.6.15
   Ruth JA, 2002, J ACAD MARKET SCI, V30, P44, DOI 10.1177/03079459994317
   Sánchez D, 2003, INFORM PROCESS MANAG, V39, P251, DOI 10.1016/S0306-4573(02)00050-X
   Saunders DR, 2010, J VISION, V10, DOI 10.1167/10.11.9
   SAUNDERS JBDM, 1953, J BONE JOINT SURG AM, V35-A, P543, DOI 10.2106/00004623-195335030-00003
   Tang JKT, 2008, COMPUT ANIMAT VIRT W, V19, P211, DOI 10.1002/cav.260
   Thomas Frank, 1995, The illusion of life: Disney animation, V1st
   Tiedens LZ, 2001, J PERS SOC PSYCHOL, V81, P973, DOI 10.1037//0022-3514.81.6.973
   Wallraven C, 2008, ACM T APPL PERCEPT, V4, DOI 10.1145/1278760.1278764
   Yannakakis GN, 2009, IEEE T COMP INTEL AI, V1, P121, DOI 10.1109/TCIAIG.2009.2024533
   YIN RK, 1969, J EXP PSYCHOL, V81, P141, DOI 10.1037/h0027474
NR 85
TC 5
Z9 6
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2016
VL 27
IS 1
BP 58
EP 71
DI 10.1002/cav.1631
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA DD4BX
UT WOS:000369868600005
DA 2024-07-18
ER

PT J
AU Kazmi, IK
   You, LH
   Yang, XS
   Jin, XG
   Zhang, JJ
AF Kazmi, Ismail Khalid
   You, Lihua
   Yang, Xiaosong
   Jin, Xiaogang
   Zhang, Jian J.
TI Efficient sketch-based creation of detailed character models through
   data-driven mesh deformations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE detailed character creation; sketch-based modeling; 3D template models;
   skeleton-based deformation; mean value coordinates; Laplacian mesh
   editing
ID CONTOURS
AB Creation of detailed character models is a very challenging task in animation production. Sketch-based character model creation from a 3D template provides a promising solution. However, how to quickly find correct correspondences between user's drawn sketches and the 3D template model, how to efficiently deform the 3D template model to exactly match user's drawn sketches, and realize real-time interactive modeling is still an open topic. In this paper, we propose a new approach and develop a user interface to effectively tackle this problem. Our proposed approach includes using user's drawn sketches to retrieve a most similar 3D template model from our dataset and marrying human's perception and interactions with computer's highly efficient computing to extract occluding and silhouette contours of the 3D template model and find correct correspondences quickly. We then combine skeleton-based deformation and mesh editing to deform the 3D template model to fit user's drawn sketches and create new and detailed 3D character models. The results presented in this paper demonstrate the effectiveness and advantages of our proposed approach and usefulness of our developed user interface. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Kazmi, Ismail Khalid; You, Lihua] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
   [Yang, Xiaosong] Bournemouth Univ, Natl Ctr Comp Animat, Media Sch, Poole BH12 5BB, Dorset, England.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Zhang, Jian J.] Bournemouth Univ, Media Sch, Poole BH12 5BB, Dorset, England.
   [Zhang, Jian J.] Southwest Jiaotong Univ, Tract Power State Key Lab, Chengdu, Peoples R China.
C3 Bournemouth University; Bournemouth University; Zhejiang University;
   Bournemouth University; Southwest Jiaotong University
RP Kazmi, IK (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
EM ikazmi@bournemouth.ac.uk
OI Zhang, Jian/0000-0002-7069-5771; Kazmi, Ismail/0000-0001-8005-7354;
   Yang, Xiaosong/0000-0003-3815-0584
FU grants of International Exchanges Scheme [IE131367]; Royal Society,
   United Kingdom; Sino-UK Higher Education Research Partnership for Ph.D.
   Studies Project; National Natural Science Foundation of China, China
   [61272298, 61472351]; project Dr. Inventor [FP7-ICT-2013.8.1 611383]
FX This research is supported by the grants of 2013 International Exchanges
   Scheme (Grant no. IE131367), the Royal Society, United Kingdom, and the
   Sino-UK Higher Education Research Partnership for Ph.D. Studies Project.
   Xiaogang Jin was supported by the National Natural Science Foundation of
   China (Grant nos. 61272298, 61472351), China. We would also like to
   acknowledge partial support from project Dr. Inventor (FP7-ICT-2013.8.1
   611383).
CR [Anonymous], 2004, P 2004 EUR ACM SIGGR
   [Anonymous], 2009, P 6 EUR S SKETCH BAS, DOI DOI 10.1145/1572741.1572749]
   Bae SH, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P151
   Bénard P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2558307
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Buchanan P., 2013, Proceedings of the international symposium on sketch-based interfaces and modeling, P5, DOI 10.1145/2487381.2487385
   Chen CY, 2009, INT CONF BIOMED, P1
   Chen T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508378
   Cook MT, 2009, INTERACT COMPUT, V21, P201, DOI 10.1016/j.intcom.2009.05.004
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185527
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Gingold Y, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1616494, 10.1145/1618452.1618494]
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321
   Kraevoy Vladislav., 2006, International Journal of Shape Modeling, V12, P29
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Nieto J.R., 2013, Deformation Models: Tracking, Animation and Applications, V7, P75, DOI 10.1007/978-94-007-5446-13
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rivers A, 2010, ACM, V29, P1
   Shtof A, 2013, COMPUT GRAPH FORUM, V32, P245, DOI 10.1111/cgf.12044
   Wuhrer S., 2012, 2012 Canadian Conference on Computer and Robot Vision, P236, DOI 10.1109/CRV.2012.38
   Xu BX, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601128
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
NR 28
TC 6
Z9 7
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 469
EP 481
DI 10.1002/cav.1656
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700028
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Jang, BG
   Kim, GJ
AF Jang, Bong-gyu
   Kim, Gerard Jounghyun
TI Evaluation of grounded isometric interface for whole-body navigation in
   virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE isometric interface; grounded Interface; whole-body interaction;
   presence; immersion
ID TASK-PERFORMANCE; TELEOPERATION; SENSE
AB Whole-body interaction is an effective way to promote the level of presence and immersion in virtual reality systems. In this paper, we introduce G-Bar, a grounded isometric interaction device that naturally induces whole-body interaction without complicated sensing and active haptic feedback apparatus. G-Bar takes advantage of the significant passive reaction force feedback sensed throughout the body to produce an enhanced level of presence/immersion and possibly even task performance. For detailed investigation in the contributing factors, two experiments were carried out to assess the comparative effectiveness of G-Bar to the following: (1) grounded but isotonic device (with force feedback and without); and (2) nongrounded handheld devices (both isotonic and isometric). The results showed that the G-Bar induced significantly higher presence and competitive task performance (fixed velocity navigation) than the isotonic (grounded or handheld) and nongrounded isometric interfaces. Compared with the grounded isometric device with active force feedback, G-Bar produced competitive performance. In particular, the analysis of the subjective evaluation revealed a high correlation between the level of presence and whole-body interaction. On the other hand, whole-body experience was not induced as much with just the active force-feedback devices. Thus, for appropriate tasks, the grounded isometric interface can be a viable alternative to expensive and mechanically limiting active force-feedback devices in enhancing user experience. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Jang, Bong-gyu; Kim, Gerard Jounghyun] Korea Univ, Digital Experience Lab, Seoul, South Korea.
C3 Korea University
RP Kim, GJ (corresponding author), Korea Univ, Digital Experience Lab, 145 Anam Ro, Seoul, South Korea.
EM gjkim@korea.ac.kr
FU Forensic Research Program of the National Forensic Service (NFS),
   Ministry of Security and Public Administration, Korea; National Research
   Foundation of Korea (NRF) grant from the Korea government (MEST)
   [2013-067321]
FX This research was funded by the Forensic Research Program of the
   National Forensic Service (NFS), Ministry of Security and Public
   Administration, Korea and the National Research Foundation of Korea
   (NRF) grant from the Korea government (MEST) (No. 2013-067321).
CR [Anonymous], P ROB SCI SYST
   Benyons D, 2009, PRESENCE EVERYONEA S
   Bergamascos M, 2011, P IEEE S ROB HUM INT
   Boulic R, 2010, LECT NOTES COMPUT SC, V6459, P59
   Bowmans DA, 2005, 3D USER INTERFACES T
   Buxton William, 1986, USER CTR SYSTEM DESI, V1986, P319
   DENNERLEIN JT, 2000, P C HUM FACT COMP SY, P423
   Elhajj I, 2001, IEEE-ASME T MECH, V6, P295, DOI 10.1109/3516.951367
   Fong T, 2001, AUTON ROBOT, V11, P77, DOI 10.1023/A:1011212313630
   Groenegresss C, 2010, THESIS U BARCELONA
   Hanyus R, 2010, INT WORKSH ADV MOT C, P691
   Hwangs J, 2006, P ACM S VIRT REAL SO, V1, P356
   Interlink Electronics, 2010, FORC SENS RES INT GU
   Jangs B, 2011, P INT C VIRT MIX REA, VI, P243
   Lecuyer A., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P83, DOI 10.1109/VR.2000.840369
   Lees S, 2008, INT J HUMAN COMPUTER, V66, P701
   Lindeman R.W., 2004, ACM Symposium on Virtual Reality Software and Technology, P146, DOI DOI 10.1145/1077534.1077562
   Meehans M, 2002, ACM SIGGRAPH COMPUTE, P75
   MINE MR, 1997, ACM SIGGRAPH, P19
   Petersons B, 1998, THESIS U WASHINGTON
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Richardson B., 2006, VIRTUAL REAL-LONDON, V9, P234, DOI [10.1007/s10055-006-0020-z, DOI 10.1007/S10055-006-0020-Z]
   Robles-De-La-Torre G, 2006, IEEE MULTIMEDIA, V13, P24, DOI 10.1109/MMUL.2006.69
   Sallnas E.-L., 2000, ACM Transactions on Computer-Human Interaction, V7, P461, DOI 10.1145/365058.365086
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Toffins D, 2003, P DRIV SIM C
   Viciana-Abad R, 2010, PRESENCE-TELEOP VIRT, V19, P197, DOI 10.1162/pres.19.3.197
   Welch RB, 1999, PRESENCE-TELEOP VIRT, V8, P574, DOI 10.1162/105474699566387
   Zatsiorskys VM, 2006, ISOMETRIC EXERCISES
   ZHAI SM, 1998, ACM SIGGRAPH COMPUTE, V32, P50, DOI DOI 10.1145/307710
   Zhais S, 1993, P HUM FACT ERG SOC A
NR 33
TC 1
Z9 2
U1 0
U2 7
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2014
VL 25
IS 5-6
BP 561
EP 575
DI 10.1002/cav.1561
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AR9DE
UT WOS:000343871000006
DA 2024-07-18
ER

PT J
AU Park, SI
   Quek, F
   Cao, Y
AF Park, Seung In
   Quek, Francis
   Cao, Yong
TI Simulating and animating social dynamics: embedding small pedestrian
   groups in crowds
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents Conference (CASA)
CY 2013
CL Istanbul, TURKEY
DE group modeling; crowd simulation; common ground theory
AB We present a crowd model informed by common ground theory to accommodate high-level socially aware behavioral realism of characters in crowd simulations. In our approach, group members maintain group cohesiveness by communicating and adapting their behaviors to each other. The resulting character behaviors in animations form a consequential chain interpreted as a coherent story by observers. We demonstrate that our model produces more believable animations from the viewpoint of human observers through a series of user studies. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Park, Seung In; Quek, Francis; Cao, Yong] Virginia Tech, Comp Sci, Blacksburg, VA 24060 USA.
C3 Virginia Polytechnic Institute & State University
RP Park, SI (corresponding author), Virginia Tech, Comp Sci, 220 Kraft Dr, Blacksburg, VA 24060 USA.
EM spark80@vt.edu
FU National Science Foundation (NSF) [IIS-0940723]; Direct For Computer &
   Info Scie & Enginr; Division Of Computer and Network Systems [1059398]
   Funding Source: National Science Foundation
FX This research has been funded by National Science Foundation (NSF)
   grant, "EAGER: Drummer Game: A Massive Interactive Socially-Enabled
   Strategy Game," IIS-0940723.
CR [Anonymous], 2011, Rvo2 library: Reciprocal collision avoidance for real-time multi-agent simulation
   AVENI AF, 1977, SOCIOMETRY, V40, P96, DOI 10.2307/3033551
   Badler N, 2008, SYNTHESIS LECT COMPU
   BRUNER J, 1991, CRIT INQUIRY, V18, P1, DOI 10.1086/448619
   Clark H. H., 1996, USING LANGUAGE
   COLEMAN JS, 1961, SOCIOMETRY, V24, P36, DOI 10.2307/2785927
   Ennis C, 2012, COMPUT ANIMAT VIRT W, V23, P321, DOI 10.1002/cav.1453
   Ennis C, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870078
   Ju E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866162
   Karamouzas I, 2012, IEEE T VIS COMPUT GR, V18, P394, DOI 10.1109/TVCG.2011.133
   Kim Manmyung, 2012, P ACM SIGGRAPH EUROG, P117
   Kirby Rachel, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P607, DOI 10.1109/ROMAN.2009.5326271
   Klein G, 2005, ORGANIZATIONAL SIMULATION, P139, DOI 10.1002/0471739448.ch6
   Lemercier S, 2012, COMPUT GRAPH FORUM, V31, P489, DOI 10.1111/j.1467-8659.2012.03028.x
   Mateas M, 2003, ADV CONSCIOUSNESS RE
   Moussaïd M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Neale D.C., 2004, Proc. of the 2004 ACM conf. on Computer supported cooperative work, P112
   Park SI, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 2, P180, DOI 10.1109/WI-IAT.2012.169
   Park SI, 2012, P WINT SIM C BERL GE, V113, p[113, 12]
   Peters C, 2009, IEEE COMPUT GRAPH, V29, P54, DOI 10.1109/MCG.2009.69
   Qiu FS, 2010, SIMUL MODEL PRACT TH, V18, P190, DOI 10.1016/j.simpat.2009.10.005
   Reynolds C. W., 1999, P GAM DEV C, P763
   Strauss A., 1990, BASICS QUALITATIVE R
   Thalmann Daniel., 2007, CROWD SIMULATION
NR 24
TC 7
Z9 9
U1 2
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 155
EP 164
DI 10.1002/cav.1512
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 145GP
UT WOS:000319003500003
DA 2024-07-18
ER

PT J
AU Wang, CB
   Li, CH
   Dai, JQ
   Li, Y
AF Wang, Changbo
   Li, Chenhui
   Dai, Jinqiu
   Li, Yang
TI Adaptive lattice-based light rendering of participating media
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE participating media; lattice; multi-scale; lighting rendering
AB The visual world around us displays a rich set of light effects because of translucent and participating media. It is hard and time consuming to render these effects with scattering, caustic, and shaft because of the complex interaction between light and different media. This paper presents a new rendering method based on adaptive lattice for lighting participating media of translucent materials such as marble, wax, and shaft light. Firstly, on the basis of the lattice-based photon tracing model, multi-scale hierarchical lattice was constructed by mixed lattice types sampling combined cubic Cartesian and face-centered cubic with view-dependent adaptive resolution. Then, an adaptive method to trace diffuse photons and marked specular photons with different phase functions was suggested. Multiple lights and heterogeneous materials were also considered here. Further, the mixed rendering method and GPU accelerate technology were introduced to render different light effects under different participating media. Copyright (c) 2011 John Wiley & Sons, Ltd.
C1 [Wang, Changbo; Li, Chenhui; Dai, Jinqiu; Li, Yang] E China Normal Univ, Inst Software Engn, Shanghai 200062, Peoples R China.
C3 East China Normal University
RP Wang, CB (corresponding author), E China Normal Univ, Inst Software Engn, Shanghai 200062, Peoples R China.
FU Natural Science Foundation of China [61070128]; State Key Lab. of
   CADAMP;CG, Zhejiang University, China [A1008]; Shanghai Maritime
   University [S30602]; Fundamental Research Funds for the Central
   Universities
FX This paper was supported by the Natural Science Foundation of China
   under grant no. 61070128, Open Project of State Key Lab. of CAD&CG,
   Zhejiang University, China, under grant A1008, Open Project of Shanghai
   Maritime University under grant S30602, and the Fundamental Research
   Funds for the Central Universities.
CR Alim UR, 2009, IEEE T VIS COMPUT GR, V15, P630, DOI 10.1109/TVCG.2008.201
   [Anonymous], P GRAPH INT MONTR CA
   Dachille F, 2000, PROC GRAPH INTERF, P205
   Donner C, 2005, ACM T GRAPHIC, V24, P1032, DOI 10.1145/1073204.1073308
   DONNER C, 2003, P ACM SIGGRAPH EUROG, P41
   GAO Y, 2007, EUROGRAPHICS
   Geist R., 2004, Proceedings of the 15th Eurographics Conference on Rendering Techniques (EGSR'04), Norkooping, Sweden, June 21-23, P355, DOI [10.2312/EGWR/EGSR04/355-362, DOI 10.2312/EGWR/EGSR04/355-362]
   IHRKE I, 2010, P 2010 ACM SIGGRAPH, P109
   Ihrke L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451,1239510
   Iwasaki K, 2002, COMPUT GRAPH FORUM, V21, P701, DOI 10.1111/1467-8659.00628
   Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319
   Jensen HW, 2002, ACM T GRAPHIC, V21, P576, DOI 10.1145/566570.566619
   JENSEN HW, 1998, P SIGGRAPH 98, P311, DOI DOI 10.1145/280814.280925
   JENSEN HW, 2009, ACM SIGGRAPH 2009 PA
   Kniss J, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P109, DOI 10.1109/VISUAL.2002.1183764
   LLAMAS I, 2007, GPU GEMS 3 REAL TIME
   Martin S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778776
   Narasimhan SG, 2006, ACM T GRAPHIC, V25, P1003, DOI 10.1145/1141911.1141986
   PAPAIOANNOU G, 2009, P GRAPHICON, P89
   Petkov K, 2009, IEEE T VIS COMPUT GR, V15, P802, DOI 10.1109/TVCG.2009.32
   Qiu F, 2007, IEEE T VIS COMPUT GR, V13, P1576, DOI 10.1109/TVCG.2007.70573
   Shah MA, 2009, IEEE COMPUT GRAPH, V29, P66, DOI 10.1109/MCG.2009.11
   Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612
   Sun X, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360634
   WANG JP, 1929, ACM T GRAPHIC, V29
   Xu K, 2007, COMPUT GRAPH FORUM, V26, P545, DOI 10.1111/j.1467-8659.2007.01077.x
   Yao CH, 2010, COMPUT GRAPH FORUM, V29, P1315, DOI 10.1111/j.1467-8659.2010.01727.x
   Zhang L, 2007, VISUAL COMPUT, V23, P783, DOI 10.1007/s00371-007-0149-0
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 29
TC 0
Z9 0
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2011
VL 22
IS 6
BP 487
EP 498
DI 10.1002/cav.426
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856IA
UT WOS:000297631200002
DA 2024-07-18
ER

PT J
AU Meng, M
   Fan, LB
   Liu, LG
AF Meng, Min
   Fan, Lubin
   Liu, Ligang
TI iCutter: a direct cut-out tool for 3D shapes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE mesh cutting; semantic parts; harmonic field; isolines
ID MESH; DECOMPOSITION
AB We present a novel sketch-based tool, called iCutter (short for intelligent cutter), for cutting out semantic parts of 3D shapes. When a user performs a cutting task, he only needs to draw a freehand stroke to roughly specify where cuts should be made without much attention. Then, iCutter intelligently returns the best cut that meets the user's intention and expectation. We develop a novel scheme for selecting the optimal isoline from a well-designed scalar field induced from the input stroke, which respects the part saliency as well as the input stroke. We demonstrate various examples to illustrate the flexibility and applicability of our iCutter tool. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Meng, Min; Fan, Lubin; Liu, Ligang] Zhejiang Univ, Dept Math, Hangzhou 310027, Peoples R China.
   Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Liu, LG (corresponding author), Zhejiang Univ, Dept Math, Hangzhou 310027, Peoples R China.
EM ligangliu@zju.edu.cn
FU National Natural Science Foundation of China [61070071]; 973 National
   Key Basic Research Foundation of China [2009CB320801]; Fundamental
   Research Funds for the Central Universities [2010QNA3039]
FX This work is supported by the National Natural Science Foundation of
   China (61070071), the 973 National Key Basic Research Foundation of
   China (2009CB320801), and the Fundamental Research Funds for the Central
   Universities (2010QNA3039).
CR Brown S., 2009, PROC GRAPHICS INTERF, P23
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Gregory A, 1999, VISUAL COMPUT, V15, P453, DOI 10.1007/s003710050192
   Ji ZP, 2006, COMPUT GRAPH FORUM, V25, P283, DOI 10.1111/j.1467-8659.2006.00947.x
   LAI YK, 2008, P ACM S SOL PHYS MOD, P183, DOI DOI 10.1145/1364901.1364927
   Lee Y, 2005, COMPUT AIDED GEOM D, V22, P444, DOI 10.1016/j.cagd.2005.04.002
   Lee YJ, 2002, COMPUT GRAPH FORUM, V21, P229, DOI 10.1111/1467-8659.t01-1-00582
   Meng Min, 2008, Journal of Computer Aided Design & Computer Graphics, V20, P1146
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Sharf A, 2006, VISUAL COMPUT, V22, P835, DOI 10.1007/s00371-006-0068-5
   Xiao CX, 2009, VISUAL COMPUT, V25, P267, DOI 10.1007/s00371-008-0226-z
   Xu K, 2009, COMPUT GRAPH-UK, V33, P391, DOI 10.1016/j.cag.2009.03.022
   Zayer R, 2005, COMPUT GRAPH FORUM, V24, P601, DOI 10.1111/j.1467-8659.2005.00885.x
   Zhang J, 2010, IEEE T VISUALIZATION, V16, P1
   Zhang JY, 2010, COMPUT GRAPH FORUM, V29, P517, DOI 10.1111/j.1467-8659.2009.01621.x
   Zheng YY, 2010, COMPUT GRAPH FORUM, V29, P527, DOI 10.1111/j.1467-8659.2009.01622.x
NR 17
TC 15
Z9 19
U1 0
U2 9
PU WILEY-BLACKWELL
PI MALDEN
PA COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL-AUG
PY 2011
VL 22
IS 4
BP 334
EP 342
DI 10.1002/cav.422
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 825OW
UT WOS:000295290400002
DA 2024-07-18
ER

PT J
AU Yeh, IC
   Lin, CH
   Chien, HJ
   Lee, TY
AF Yeh, I-Cheng
   Lin, Chao-Hung
   Chien, Hung-Jen
   Lee, Tong-Yee
TI Efficient camera path planning algorithm for human motion overview
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE camera path planning; viewpoint selection; visualisation
ID VIEW
AB Camera path planning for character motions is a fundamental and important research topic, benefiting many animation applications. Existing optimal-based approaches are generally computationally expensive and infeasible for interactive applications. In this paper, we propose an efficient approach that can take many constraints of finding the camera path into account and can potentially enable interactive camera control. Instead of solving a highly complicated camera optimization problem in a spatiotemporal four-dimensional space, we heuristically determine the camera path based on an efficient greedy-based tree traversal approach. The experimental results show that the proposed approach can efficiently generate a smooth, informative, and aesthetic camera path that can reveal the significant features of character motions. Moreover, the conducted user study also shows that the generated camera paths are comparable to those of a state-of-the-art approach and those made by professional animators. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Yeh, I-Cheng; Lee, Tong-Yee] Natl Cheng Kung Univ, CGVSLab CSIE, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
   [Lin, Chao-Hung] Natl Cheng Kung Univ, DGLab Geomat, Dept Geomat, Tainan 70101, Taiwan.
C3 National Cheng Kung University; National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, CGVSLab CSIE, Dept Comp Sci & Informat Engn, 1 Dasyue Rd, Tainan 70101, Taiwan.
EM tonylee@mail.ncku.edu.tw
OI Yeh, I-Cheng/0000-0003-1045-843X
CR [Anonymous], THESIS U YORK
   APOLLONI B, 1989, STOCH PROC APPL, V33, P233, DOI 10.1016/0304-4149(89)90040-9
   Assa J, 2010, COMPUT GRAPH FORUM, V29, P595, DOI 10.1111/j.1467-8659.2009.01629.x
   Assa J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409068
   BARES WH, 2000, AAAI 2000 SPRING S S, P84
   Benhamou F., 2004, ACM Transactions on Computational Logic, V5, P732, DOI 10.1145/1024922.1024927
   Blanz V, 1999, PERCEPTION, V28, P575, DOI 10.1068/p2897
   Christie M, 2005, LECT NOTES COMPUT SC, V3638, P40
   DRUCKER SM, 1995, 1995 S INT 3D GRAPH, P139
   Halper N, 2001, COMPUT GRAPH FORUM, V20, pC174, DOI 10.1111/1467-8659.00510
   HALPER N., 2000, AAAI Spring Symposium, P92
   HE LW, 1996, P 23 ANN C COMP GRAP, P217
   Jardillier F, 1998, COMPUT GRAPH FORUM, V17, pC175, DOI 10.1111/1467-8659.00265
   Kwon JY, 2008, VISUAL COMPUT, V24, P475, DOI 10.1007/s00371-008-0228-x
   LIN TC, 2004, WSCG, P289
   Mortara M, 2009, COMPUT GRAPH-UK, V33, P280, DOI 10.1016/j.cag.2009.03.003
   Olivier P., 1999, AISB S ALAND CREATIV, P22
   Polonsky O, 2005, VISUAL COMPUT, V21, P840, DOI 10.1007/s00371-005-0326-y
NR 18
TC 9
Z9 11
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 239
EP 250
DI 10.1002/cav.398
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700020
DA 2024-07-18
ER

PT J
AU Feng, W
   Zhang, HX
   Huang, J
   Wang, CY
   Bao, HJ
AF Feng, Wei
   Zhang, Hongxin
   Huang, Jin
   Wang, Caoyu
   Bao, Hujun
TI Repairing topological inconsistency of mesh sequences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE topology repairing; mesh sequence; curve skeleton
ID RECONSTRUCTION; SKELETON; MOTION; MODELS
AB We propose a novel approach for repairing topological inconsistency of mesh sequences with a few user interactions. The main idea of our approach is to leverage curve skeletons to detect the inconsistency of a mesh sequence. The skeleton of one mesh in the sequence is edited by user, which produces a prototype skeleton. We propagate this prototype using graph matching in-between frames. By using temporal coherence cues, the matching procedure can be dramatically accelerated. Finally, the mesh sequence is repaired according to the inconsistencies by comparing matched skeletons and original skeletons. As demonstrated in the results, our approach avoids manually editing in all meshes, and is able to output a mesh sequence with consistent topology. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Feng, Wei; Zhang, Hongxin; Huang, Jin; Wang, Caoyu; Bao, Hujun] Zhejiang Univ, State Key Lab CAD&CG, Hangchow, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Huang, J (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangchow, Zhejiang, Peoples R China.
EM hj@cad.zju.edu.cn
RI Zhang, Hongxin/T-3714-2019
CR Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Cordella L.P., 1996, ICPR, P180
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Couprie M, 2007, IMAGE VISION COMPUT, V25, P1543, DOI 10.1016/j.imavis.2006.06.020
   Ju T, 2004, ACM T GRAPHIC, V23, P888, DOI 10.1145/1015706.1015815
   Ju T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.12394593
   Meijster A, 2000, COMP IMAG VIS, V18, P331
   Pekelny Y, 2008, COMPUT GRAPH FORUM, V27, P399, DOI 10.1111/j.1467-8659.2008.01137.x
   Remy E, 2005, IMAGE VISION COMPUT, V23, P167, DOI 10.1016/j.imavis.2004.06.007
   Sharf A, 2007, COMPUT GRAPH FORUM, V26, P323, DOI 10.1111/j.1467-8659.2007.01054.x
   Sharf A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409063
   Sharf A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239494
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tagliasacchi Andrea, 2009, ACM T GRAPHICS, V28, P3
   WAND M, 2007, S GEOM PROC, P49
   Wand M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1516522.1516526
   Wood Z, 2004, ACM T GRAPHIC, V23, P190, DOI 10.1145/990002.990007
   Zhou QY, 2007, IEEE T VIS COMPUT GR, V13, P675, DOI 10.1109/TVCG.2007.1015
NR 19
TC 1
Z9 1
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 355
EP 364
DI 10.1002/cav.351
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400022
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gerdelan, A
   O'Sullivan, C
AF Gerdelan, Anton
   O'Sullivan, Carol
TI A genetic-fuzzy system for optimising agent steering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE agent navigation and steering; genetic algorithms; fuzzy logic
AB Fuzzy controllers are a popular method for animated character perception and control. A drawback of fuzzy systems is that time intensive manual calibration of system parameters is required. We introduce a new Genetic-Fuzzy System (GFS) that automates the tuning process of rules for animated character steering. An advantage of our GFS is that it is able to adapt the rules for steering behaviour during run time. We explore the parameter space of the new GFS, and discuss how the GFS can be implemented to run as a background process during normal execution of a simulation. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Gerdelan, Anton] Trinity Coll Dublin, Dept Comp Sci, Graph Vis & Visualisat Grp GV2, Dublin 2, Ireland.
C3 Trinity College Dublin
RP Gerdelan, A (corresponding author), Trinity Coll Dublin, Dept Comp Sci, Graph Vis & Visualisat Grp GV2, Dublin 2, Ireland.
EM gerdelaa@cs.tcd.ie
OI O'Sullivan, Carol/0000-0003-3772-4961
CR ALLEN BF, 2009, 2 INT WORKSH MOT GAM
   [Anonymous], 1998, Fuzzy control
   [Anonymous], BRIDGE
   Bellman R. E., 1971, Decision-making in a fuzzy environment, DOI 10.1287/mnsc.17.4.B141
   Cordón O, 2004, FUZZY SET SYST, V141, P5, DOI 10.1016/S0165-0114(03)00111-8
   Dougherty M, 2000, TRANSPORT REV, V20, P145, DOI 10.1080/014416400295220
   HERRERA F, 1995, INT J APPROX REASON, V12, P299, DOI 10.1016/0888-613X(94)00033-Y
   MOHAMMADIAN M, 1994, FUZZY LOGIC GENETIC, P149
   NEVES R, 2002, 1 INT C FUZZ SYST KN
   STANLEY KO, 2006, 21 NAT C ART INT BOS
   WON J, 2006, ADV MULTIMEDIA MODEL, V4352, P613, DOI DOI 10.1007/978-3-540-69429-8
NR 11
TC 4
Z9 4
U1 0
U2 2
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 453
EP 461
DI 10.1002/cav.360
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400031
DA 2024-07-18
ER

PT J
AU Mamou, K
   Zaharia, T
   Prêteux, F
AF Mamou, Khaled
   Zaharia, Titus
   Preteux, Francoise
TI TFAN: A low complexity 3D mesh compression algorithm
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE 3D mesh compression; real-time decoding; low complexity; MPEG-4 standard
AB This paper proposes a novel approach for mono-resolution 3D mesh compression, called TFAN (Triangle Fan-based compression). TFAN treats in a unified manner meshes of arbitrary topologies, i.e., manifold or not, oriented or not, while offering a linear computational complexity (with respect to the number of mesh vertices) for both encoding and decoding algorithms. In addition, the TFAN compressed representation is optimized for real-time decoding applications. In order to validate the proposed approach, two databases have been considered for experimentations. The first is the MPEG-4 test set, Which includes over 3500 general purpose manifold meshes. Vie second, related to the French national project SEMANTIC-3D, includes over 4000 computer assisted design (CAD) meshes of highly irregular, non-manifold topologies. In both cases, the TFAN approach outperforms existing techniques such as MPEG-4/3DMC (3D Mesh Coding) or Touma and Gotsman, with decoding times lower by an order of magnitude at equivalent or even better levels of compression efficiency (+/- 10% in bitrate). In addition, When applied to non-manifold 3D data, the compression performances are significantly enhanced (6-30% gain in bitrate). Due to its high compression performances the TFAN approach has been recently retained for ISO standardization, within the framework of the MPEG-4/AFX standard. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Zaharia, Titus; Preteux, Francoise] TELECOM SudParis, Inst TELECOM, ARTEMIS Dept, F-91011 Evry, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   SudParis; IMT Atlantique
RP Zaharia, T (corresponding author), TELECOM SudParis, Inst TELECOM, ARTEMIS Dept, 9 Rue Charles Fourier, F-91011 Evry, France.
EM titus.zaharia@it-sudparis.eu
CR AKELEY K, 1990, PROGRAM SGI DEV TOOL
   ALLIEZ P, 2001, EUROGRAPHICS, P480
   [Anonymous], 147721 ISOIEC
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Chow MM, 1997, VISUALIZATION '97 - PROCEEDINGS, P347, DOI 10.1109/VISUAL.1997.663902
   DEERING M, 1995, GEOMETRY COMPRESSION, P13
   Evans F, 1996, IEEE VISUAL, P319, DOI 10.1109/VISUAL.1996.568125
   Evans F., 1996, Completing Sequential Triangulations is Hard
   Galin E, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P326, DOI 10.1109/SMI.2005.20
   Gumhold S., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P133, DOI 10.1145/280814.280836
   GUMHOLD S, 1999, OT ERL WORKSH VIS MO, P261
   *ISO IEC JTC1 SC29, 2008, M15667 ISOIECJTC1SC2
   *ISO IEC JTC1 SC29, 2001, 1449622001 ISOIECJTC
   LAZARUS F, 2001, IEEE TRANSMISSION VI, V7, P136
   Le Bonhomme B, 2008, IEEE IMAGE PROC, P2700, DOI 10.1109/ICIP.2008.4712351
   LEE SW, 2008, N9888 ISOIECJTC1SC29
   MAMOU K, 2008, THESIS U PARIS 5 FRA
   MAMOU K, 2005, ACTES 4 ATELIERS TRA, P381
   Moffat A, 1998, ACM T INFORM SYST, V16, P256, DOI 10.1145/290159.290162
   Parks D., 1999, IEEE Conference Record - Abstracts. 1999 IEEE International Conference on Plasma Science. 26th IEEE International Conference (Cat. No.99CH36297), DOI 10.1109/PLASMA.1999.829630
   SON G, 2007, INT C CONV INF TECHN, P2175
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   TOUMA C, 1998, P GRAPH INT VANC CAN, P24
   TURAN G, 1984, DISCRETE APPL MATH, V8, P289, DOI 10.1016/0166-218X(84)90126-4
   XIANG X, 1999, S INT 3D GRAPH, P71
NR 25
TC 42
Z9 47
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 343
EP 354
DI 10.1002/cav.319
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700027
DA 2024-07-18
ER

PT J
AU Yang, XS
   Southern, R
   Zhang, JJ
AF Yang, Xiaosong
   Southern, Richard
   Zhang, Jian Jun
TI Fast simulation of skin sliding
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE skinning; skin deformation; parameterization
AB Skin sliding is the phenomenon of the skin moving over underlying layers of fat, muscle and bone. Due to the complex interconnections between these separate layers and their differing elasticity properties, it is difficult to model and expensive to compute. We present a novel method to simulate this phenomenon at real-time by remeshing the surface based oil a parameter space resampling. In order to evaluate the surface parametrization, We borrow a technique from structural engineering known as the force density method (FDM) which solves for an energy minimizing form With a sparse linear system. Our method creates a realistic approximation of skin sliding in real-time, reducing texture distortions in the region of the deformation. In addition it is flexible, simple to use, and call be incorporated into any animation pipeline. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Zhang, Jian Jun] Bournemouth Univ, Media Sch, Comp Animat Res Ctr, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University
RP Zhang, JJ (corresponding author), Bournemouth Univ, Media Sch, Comp Animat Res Ctr, Poole BH12 5BB, Dorset, England.
EM jzhang@bmth.ac.uk
OI Southern, Richard/0000-0002-1933-3951; Yang,
   Xiaosong/0000-0003-3815-0584
CR Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626
   [Anonymous], 2002, P 2002 ACM SIGGRAPHE
   Aubel A, 2001, COMP ANIM CONF PROC, P167, DOI 10.1109/CA.2001.982390
   *AUT MAY, DOC
   Catmull Edwin., 1972, ACM '72 Proceedings of the ACM annual conference, V1, P422
   Chadwick J. E., 1989, Computer Graphics, V23, P243, DOI 10.1145/74334.74358
   Eck M, 1995, P 22 ANN C COMP GRAP, P173, DOI DOI 10.1145/218380.218440
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Hormann K, 2006, ACM T GRAPHIC, V25, P1424, DOI 10.1145/1183287.1183295
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Meyer M., 2002, Journal of Graphics Tools, V7, P13, DOI 10.1080/10867651.2002.10487551
   Piponi D, 2000, COMP GRAPH, P471, DOI 10.1145/344779.344990
   Scheepers F., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P163, DOI 10.1145/258734.258827
   SCHEK JJ, 1974, COMPUTER METHODS APP, V3, P115
   STINSON WT, 2004, ACM SIGGRAPH 2004 SK, P65
   TURNER P, 1993, P CG INT, P399
   Tutte W.T., 1963, Proc. London Math. Soc., V13, P743, DOI DOI 10.1112/PLMS/S3-13.1.743
   Venkataraman K, 2005, COMPUT GRAPH-UK, V29, P756, DOI 10.1016/j.cag.2005.08.024
   Weber O, 2007, COMPUT GRAPH FORUM, V26, P265, DOI 10.1111/j.1467-8659.2007.01048.x
   WIEDMANN J, 2002, 500 3D OBJECTS
NR 21
TC 2
Z9 4
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 333
EP 342
DI 10.1002/cav.292
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700026
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Çakmak, H
   Maass, H
   Trantakis, C
   Strauss, G
   Nowatius, E
   Kühnapfel, U
AF Cakmak, H.
   Maass, H.
   Trantakis, C.
   Strauss, G.
   Nowatius, E.
   Kuehnapfel, U.
TI Haptic ventriculostomy simulation in a grid environment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE endoscopy; ventriculostomy; surgical training; simulation; grid;
   collaboration; haptics
ID VIRTUAL-REALITY SIMULATOR; FORCE FEEDBACK; SURGERY
AB We present a pill featured surgery simulator for endoscopic third ventriculostomy (ETV) in air interactive grid environment. The basic ventriculostomy simulator introduced previously has been extended with new 3D models and animation methods for raising the simulation realism. It enables full haptic interaction with textured deformable models of a hydrocephalic configured human ventricular system derived from MR-data. Visual effects like bleeding in the cerebrospinal fluid (CSF) have been implemented for faulty interactions during training sessions which are recorded in a database for further evaluation, Based on the training data comparative studies were carried out whereas the benefits of virtual reality (VR)-based training have been demonstrated. Furthermore, KisGrid is presented as all interactive grid environment for real-time surgical simulators. It enables collaborative and supervised haptic training over networks with access to remote surgical models and hardware. The grid applet ViCoM is introduced as a tool for audio-visual communication, monitoring, and training session archiving. Long distance tests have been successfully carried out for multicast video conferencing, training session monitoring, and haptic surgical collaboration with deformable models. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Cakmak, H.] Forschungszentrum Karlsruhe, Inst Angewandte Informat, D-76021 Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Çakmak, H (corresponding author), Forschungszentrum Karlsruhe, Inst Angewandte Informat, D-76021 Karlsruhe, Germany.
EM Hueseyin.Cakmak@iai.fzk.de
RI Çakmak, Hüseyin Kemâl/G-1507-2018
OI Çakmak, Hüseyin Kemâl/0000-0002-1463-7606
FU German ministry of education and research (BMBF) through
   Projekttrager-Informationstechnik (PT-IT, DLR) [O1IRA03]
FX This work has been funded in part by the German ministry of education
   and research (BMBF) through Projekttrager-Informationstechnik (PT-IT,
   DLR) within the funding program "Virtual and Augmented Reality (VR-AR)-
   (Ref: O1IRA03, HapticIO). The authors also acknowledge F. Strauss, J.
   Adermann, and N. Ritter from ICCAS.
CR Agus M, 2002, ST HEAL T, V85, P17
   [Anonymous], INT J COMPUT ASSIST
   BAHRAMI N, 2006, SIMULATION MASTOIDEK, V77, P95
   BOUKERCHE A, 2006, HAPTICS, P77
   BOULANGER P, 2006, P IEEE INT WORKSH HA, P21
   Bro-Nielsen M, 1998, P IEEE, V86, P490, DOI 10.1109/5.662874
   Bro-Nielsen M, 1999, STUD HEALTH TECHNOL, V62, P76
   Brown N, 2006, STUD HEALTH TECHNOL, V119, P73
   Çakmak H, 2005, MINIM INVASIV THER, V14, P134, DOI 10.1080/13645700510033958
   CAKMAK H, 2008, INT J COMPUTER AS S1, V3, P129
   Çakmak HK, 2000, SPRING COMP SCI, P173
   CHRISOCHOIDES N, 2006, ACM IEEE SC C SC 06, P37
   Clatz O, 2007, IEEE T BIO-MED ENG, V54, P755, DOI 10.1109/TBME.2006.890146
   ERSAHIN Y, 2003, J NEUROLOGICAL SCI D, V20, P4
   Foster I, 2001, INT J HIGH PERFORM C, V15, P200, DOI 10.1177/109434200101500302
   Foster I., 2004, The Grid, V2
   Glencross M, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P115
   Gunn C, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P481
   Gunn C, 2004, ST HEAL T, V98, P121
   *HAVNET, 2008, HAVNET FIN SUMM REP
   Hikichi K, 2002, GLOB TELECOMM CONF, P1492
   Hutchins M., 2006, Virtual Reality, V9, P97, DOI DOI 10.1007/s10055-005-0015-1
   *IBM, 2008, IBM DEF GRID COMP
   Jacomides L, 2004, J UROLOGY, V171, P320, DOI 10.1097/01.ju.0000101515.70623.4a
   Jay C, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P655
   KUHN C, 1996, P COMP ASS RAD CAR 9
   Kühnapfel U, 2000, COMPUT GRAPH-UK, V24, P671, DOI 10.1016/S0097-8493(00)00070-4
   Lemole GM, 2007, NEUROSURGERY, V61, P142, DOI 10.1227/01.neu.0000279734.22931.21
   LOGAN IP, 1996, SOC COMPUTER SIMULAT, V28, P17
   Maass H, 2003, LECT NOTES COMPUT SC, V2673, P165
   Mettler L, 2004, INT CONGR SER, V1271, P274, DOI 10.1016/j.ics.2004.05.144
   MULLER T, 2005, BILDVERARBEITUNG MED, V246, P420
   Neubauer A, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P513, DOI 10.1109/VISUAL.2004.98
   Panchaphongsaphak B, 2005, ST HEAL T, V111, P378
   Panchaphongsaphak B, 2006, ST HEAL T, V119, P428
   Phillips NI, 2000, NEUROSURGERY, V46, P933, DOI 10.1097/00006123-200004000-00031
   POSSNECK A, 2006, CHIRURG ERGEBNISSE R, V77, P44
   Schijven M, 2003, SURG ENDOSC, V17, P1978, DOI 10.1007/s00464-003-9000-5
   Shen XJ, 2008, IEEE MULTIMEDIA, V15, P64, DOI 10.1109/MMUL.2008.9
   STRAUSS E, 2004, THESIS U LEIPZIG D
   Székely G, 1998, LECT NOTES COMPUT SC, V1496, P550, DOI 10.1007/BFb0056240
   Tang CY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON INTEGRATION TECHNOLOGY, PROCEEDINGS, P253, DOI 10.1109/ICITECHNOLOGY.2007.4290473
   Trantakis C, 2003, INT CONGR SER, V1256, P782, DOI 10.1016/S0531-5131(03)00292-9
   TRANTAKIS C, 2004, P COMP ASS RAD CARS, P707
   TRANTAKIS C, 2005, BIOMEDIZINISCHE T S1, V50
   Wang D, 2003, 2ND IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2003, P7, DOI 10.1109/HAVE.2003.1244717
   Wongwirat O, 2006, IEEE MULTIMEDIA, V13, P62, DOI 10.1109/MMUL.2006.54
   You Y, 2008, IEEE ICC, P1824, DOI 10.1109/ICC.2008.350
NR 48
TC 12
Z9 12
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2009
VL 20
IS 1
BP 25
EP 38
DI 10.1002/cav.272
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 407WD
UT WOS:000263394100004
DA 2024-07-18
ER

PT J
AU Anderson, JN
   Davidson, N
   Morton, H
   Jack, MA
AF Anderson, James N.
   Davidson, Nancie
   Morton, Hazel
   Jack, Mervyn A.
TI Language learning with interactive virtual agent scenarios and speech
   recognition: Lessons learned
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer-assisted language learning; speech recognition; virtual worlds;
   embodied virtual agents; usability evaluation
AB The SPELL (Spoken Electronic Language Learning) system is a self-access computer-assisted language learning (CALL) package that integrates speaker-independent continuous speech recognition technology with virtual worlds and embodied virtual agents to create an environment in which learners can converse in the target language within meaningful contextualized scenarios. In this paper we provide an overview of the functionality, architecture, and implementation of the SPELL system. We also describe four phases of usability evaluation conducted with the system and summarize the main results of these user assessments. Finally, we discuss the most significant lessons learned in the development and evaluation of the system. The paper focuses on the technological aspects of the system and its evaluation for usability and robustness, rather than its pedagogical methodology. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Anderson, James N.; Davidson, Nancie] Univ Edinburgh, Ctr Commun Interface Res, Edinburgh EH9 3JL, Midlothian, Scotland.
C3 University of Edinburgh
RP Anderson, JN (corresponding author), Univ Edinburgh, Ctr Commun Interface Res, Alexander Graham Bell Bldg,Kings Bldg, Edinburgh EH9 3JL, Midlothian, Scotland.
EM jad@ccir.ed.ac.uk
FU Scottish Enterprise Proof of Concept Fund; Nuance Communications Inc.
FX The SPELL project was made possible due to financial support from the
   Scottish Enterprise Proof of Concept Fund. We also note the generous
   support of Nuance Communications Inc. in this work.
CR André E, 1999, APPL ARTIF INTELL, V13, P415, DOI 10.1080/088395199117306
   [Anonymous], 1998, Perceiving talking faces: From speech perception to a behavioral principle
   [Anonymous], P IJCAI 97 WORKSH AN
   [Anonymous], 1999, Proceedings of the SIGCHI conference on human factors in computing systems, DOI [10.1145/302979.303150, DOI 10.1145/302979.303150]
   *BITM, BITM BS CONT VRML X3
   BOUSELMI G, 2006, P ICASSP 2006
   BOUSELMI G, 2006, P INTERSPEECH 2006 P
   Derwing TM, 2000, TESOL QUART, V34, P592, DOI 10.2307/3587748
   Ehsani Farzad., 1998, LANG LEARN TECHNOL, V2, P45
   Eskenazi M., 1999, CALICO Journal, V16, P447
   Hinkcs R., 2002, P ICSLP, P733
   Holland V. M., 1999, CALICO Journal, V16, P339
   Ijsselsteijn W, 2003, EMERG COMMUNICAT, V5, P3
   Johnson W.L., 2000, INT J ARTIFICIAL INT, V11, P47
   JOHNSON WL, 2004, P INSTIL ICALL 2004
   Lester J. C., 1997, P ACM SIGCHI C HUM F, P359, DOI [10.1145/258549.258797, DOI 10.1145/258549.258797]
   Lester JC, 1997, FR ART INT, V39, P23
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   LOMBARD M, 1997, J COMPUTER MED COMMU, V3
   Long M.H., 1996, HDB 2 LANGUAGE ACQUI, P413, DOI DOI 10.1016/B978-012589042-7/50015-3
   Long MH, 1998, MOD LANG J, V82, P357
   Marsella S, 2004, COG TECH, P317
   McBreen H, 2002, MU S ART SOC SIM ORG, V3, P267
   McBreen HM, 2001, IEEE T SYST MAN CY A, V31, P394, DOI 10.1109/3468.952714
   MORGAN JJ, 2004, P IN STIL ICALL 2004
   Morton H., 2005, Computer Assisted Language Learning, V18, P171, DOI 10.1080/09588220500173344
   Morton H., 2008, Handbook of research on computer-enhanced language acquisition and learning, P219, DOI [DOI 10.4018/978-1-59904-895-6.CH013, 10.4018/978-159904-895-6.ch013, DOI 10.4018/978-159904-895-6.CH013]
   MORTON H, 2005, SPOKEN ELECT LANGUAG
   MORTON H, 2008, COMPUTER AS IN PRESS
   Neri Ambra, 2003, P 15 INT C PHON SCI, P1157
   Noma T, 2000, IEEE COMPUT GRAPH, V20, P79, DOI 10.1109/38.851755
   Shaw E., 1999, Proceedings of the Third International Conference on Autonomous Agents, P283, DOI 10.1145/301136.301210
   H ANIM 1 1 SPECIFICA
NR 33
TC 14
Z9 21
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2008
VL 19
IS 5
BP 605
EP 619
DI 10.1002/cav.265
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 377KO
UT WOS:000261250300007
DA 2024-07-18
ER

PT J
AU Park, K
AF Park, Kyoungju
TI Physiologically correct animation of the heart
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE heart animation; cross-parameterization; variational implicit surface;
   blending; deformation coupling
ID SPATIAL MODULATION; DEFORMABLE MODELS; MOTION; MAGNETIZATION; IMAGES;
   WALL
AB Physiologically correct animation of the heart should incorporate non-homogeneous and nonlinear motions of the heart. Therefore, we introduce a methodology that estimates deformations from volume images and utilizes them for animation. Since volume images are acquired at regular slicing intervals, they miss information between slices and recover deformation on the slices. Therefore, the estimated finite element models (FEMs) result in coarse meshes with chunk elements the sizes of which depend on the slice intervals. Thus, we introduce a method of generating a detailed model using implicit surfaces and transferring a deformation from a FEM to implicit surfaces. An implicit surface heart model is reconstructed using contour data points and then cross-parameterized to the heart FEM, the time-varying deformation of which has been estimated by tracking the insights of the heart wall. The implicit surface heart models are composed of four heart walls that are blended into one model. A correspondence map between the source and the target meshes is made using the template fitting method. Deformation coupling transfers the deformation of a coarse heart FEM model to a detailed implicit model by factorizing linear equations. We demonstrate the system and show the resulting deformation of an implicit heart model. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 Chung Ang Univ, Dept Imaging Sci, Seoul 156756, South Korea.
C3 Chung Ang University
RP Park, K (corresponding author), Chung Ang Univ, Dept Imaging Sci, 221 Heukseok Dong, Seoul 156756, South Korea.
EM kjpark@cau.ac.kr
CR [Anonymous], 2002, APPROXIMATION THEORY
   AXEL L, 1989, RADIOLOGY, V172, P349, DOI 10.1148/radiology.172.2.2748813
   BLOOMENTHAL J, 1994, GRAPHICS GEMS, V4, P324
   DAVIS TA, 2004, TR04003 U FLOR
   DeCarlo D, 1996, IEEE T PATTERN ANAL, V18, P443, DOI 10.1109/34.491626
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Frangi AF, 2001, IEEE T MED IMAGING, V20, P2, DOI 10.1109/42.906421
   Galbraitht C, 2004, COMPUT GRAPH FORUM, V23, P351, DOI 10.1111/j.1467-8659.2004.00766.x
   HORMANN K, 2007, SIGGRAPH 07 ACM SIGG, P13
   Hu ZH, 2003, MED IMAGE ANAL, V7, P435, DOI 10.1016/S1361-8415(03)00032-X
   Metaxas D.N., 1996, PHYS BASED DEFORMABL
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Park J, 1996, IEEE T MED IMAGING, V15, P278, DOI 10.1109/42.500137
   Park K, 2005, COMMUN ACM, V48, P43, DOI 10.1145/1042091.1042118
   PARK K, 2005, MODELING SIMULATION
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   TERZOPOULOS D, 1987, SIGGRAPH COMPUT GRAP, V21, P205
   Turk G, 2002, ACM T GRAPHIC, V21, P855, DOI 10.1145/571647.571650
   Turk G, 1999, COMP GRAPH, P335, DOI 10.1145/311535.311580
   Turk G., 1999, VARIATIONAL IMPLICIT
   Young A A, 1999, Med Image Anal, V3, P361, DOI 10.1016/S1361-8415(99)80029-2
   YOUNG AA, 1992, RADIOLOGY, V185, P241, DOI 10.1148/radiology.185.1.1523316
NR 24
TC 1
Z9 1
U1 0
U2 2
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 527
EP 535
DI 10.1002/cav.241
PG 9
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 354GZ
UT WOS:000259628200033
DA 2024-07-18
ER

PT J
AU You, LH
   Yang, XS
   Zhang, JJ
AF You, L. H.
   Yang, Xiaosong
   Zhang, Jian J.
TI Dynamic skin deformation with characteristic curves
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE dynamic skin deformation; time-dependent 3D trigonometric curve;
   character animation
ID MUSCLE; SPACE
AB By simulating motion and deformation of a set of 3D characteristic curves defining surfaces, we introduce a new skin deformation technique to animate skin deformation of character models. This technique consists of two parts, representation of characteristic curves and dynamic skin deformation. The first part is to extract characteristic curves of an existing model, that is a polygon model or a NURBS model, represent the characteristic curves with tune-dependent 3D trigonometric curves, and relate the surface points of the model to these trigonometric curves. The advantage of such a treatment is that it can transform an original 3D problem into a 2D problem, making it much quicker and easier to process and compute. In the second part, a vector-valued dynamic fourth-order differential equation is employed to govern the behaviour of the time-dependent 3D trigonometric curves. These dynamic differential equations incorporate both the time component and the physical properties of the material, which are given by the user. Thus, the character model can be made to animate (deform) following tire user-specified behaviour parameters. Our experiments demonstrate that this technique is able to produce realistic skin deformations efficiently and avoid the undesirable skinning problems suffered by some existing skinning techniques. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Zhang, Jian J.] Bournemouth Univ, Sch Med, Poole BH12 5BB, Dorset, England.
   [Zhang, Jian J.] Bournemouth Univ, Bournemouth Media Sch, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
   [Zhang, Jian J.] Bournemouth Univ, Bournemouth Media Sch, Comp Animat Res Ctr, Poole BH12 5BB, Dorset, England.
   [Yang, Xiaosong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Yang, Xiaosong] Chinese Univ Hong Kong, Virtual Real Visualisat & Imaging Res Ctr, Hong Kong, Hong Kong, Peoples R China.
C3 Bournemouth University; Bournemouth University; Bournemouth University;
   Tsinghua University; Chinese University of Hong Kong
RP Zhang, JJ (corresponding author), Bournemouth Univ, Sch Med, Poole BH12 5BB, Dorset, England.
EM jzhang@bournemouth.ac.uk
OI Yang, Xiaosong/0000-0003-3815-0584
CR Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626
   Angelidis A, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P129
   [Anonymous], 2005, P 2005 S INTERACTIVE, DOI [DOI 10.1145/1053427.10534294, DOI 10.1145/1053427.1053429]
   [Anonymous], 2002, P 2002 ACM SIGGRAPHE
   Au OKC, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239534, 10.1145/1276377.1276481]
   Aubel A, 2001, COMP ANIM CONF PROC, P167, DOI 10.1109/CA.2001.982390
   Capell S, 2002, ACM T GRAPHIC, V21, P586, DOI 10.1145/566570.566622
   Capell S, 2007, GRAPH MODELS, V69, P71, DOI 10.1016/j.gmod.2006.09.001
   CHEN DT, 1992, COMP GRAPH, V26, P89, DOI 10.1145/142920.134016
   Guo Z, 2005, COMPUT GRAPH FORUM, V24, P373, DOI 10.1111/j.1467-8659.2005.00862.x
   Hyun DE, 2005, VISUAL COMPUT, V21, P542, DOI 10.1007/s00371-005-0343-x
   James DL, 2002, ACM T GRAPHIC, V21, P582, DOI 10.1145/566570.566621
   Kurihara Tsuneya, 2004, P 2004 ACM SIGGRAPHE, P355
   Lander J., 1998, Game Developer Magazine, V5, P11
   Lander J., 1999, GAME DEV MAGAZIN OCT, P11
   Larboulette C, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P522, DOI 10.1109/CGI.2004.1309258
   Larboulette Caroline., 2005, Proceedings of the 21st spring conference on Computer graphics, P87, DOI DOI 10.1145/1090122.10901384
   LEWIS LP, 2000, P 27 ANN C COMP GRAP, P165
   Merry B, 2006, ACM T GRAPHIC, V25, P1400, DOI 10.1145/1183287.1183294
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Nedel LP, 2000, VISUAL COMPUT, V16, P306, DOI 10.1007/PL00007212
   Nedel LP, 1998, COMP ANIM CONF PROC, P34, DOI 10.1109/CA.1998.681905
   Pratscher Michael., 2005, SCA 05, P329
   Pyun H, 2004, COMPUT GRAPH-UK, V28, P757, DOI 10.1016/j.cag.2004.06.013
   Rhee T, 2006, COMPUT GRAPH FORUM, V25, P439, DOI 10.1111/j.1467-8659.2006.00963.x
   SCHEEPERS F, 1997, P 24 ANN C COMP GRAP, P163, DOI DOI 10.1145/258734.258827
   SHAMIR A, 2008, COMPUT GRAPH FORUM, P1
   SHEN J, 1994, P COMP GRAPH INT MEL
   SIMMONS M, 2002, P 2002 ACM SIGGRAPH, P139, DOI DOI 10.1145/545261.545284
   Singh K., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P405, DOI 10.1145/280814.280946
   Teran J, 2005, IEEE T VIS COMPUT GR, V11, P317, DOI 10.1109/TVCG.2005.42
   THALMANN NM, 1988, P GRAPH INT, P26
   Venkataraman K, 2005, COMPUT GRAPH-UK, V29, P756, DOI 10.1016/j.cag.2005.08.024
   von Funck W, 2006, ACM T GRAPHIC, V25, P1118, DOI 10.1145/1141911.1142002
   Weber J, 2000, P GAM DEV C
   Weber O, 2007, COMPUT GRAPH FORUM, V26, P265, DOI 10.1111/j.1467-8659.2007.01048.x
   WILHELMS J, 1997, P SIGGRAPH 97, P173
   Yang X, 2006, COMPUT ANIMAT VIRT W, V17, P293, DOI 10.1002/cav.133
   Yang YL, 2006, CATAL COMMUN, V7, P281, DOI 10.1016/j.catcom.2005.11.014
   You LH, 2007, COMPUT GRAPH FORUM, V26, P313, DOI 10.1111/j.1467-8659.2007.01053.x
NR 40
TC 10
Z9 11
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 433
EP 444
DI 10.1002/cav.235
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200025
DA 2024-07-18
ER

PT J
AU Pilgrim, S
   Steed, A
   Aguado, A
AF Pilgrim, Simon
   Steed, Anthony
   Aguado, Alberto
TI Progressive skinning for character animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE animation; skinning; compression; level of detail
AB Previous works have shown that for characters with obvious articulation, animations comprising the blending of skeletal bone transformations, significantly reduce the computation and data requirements, permitting much greater visual detail. However increasingly, animators and engine designers must produce animations that can run on platforms with quite different runtime capabilities. They may simply author multiple skeletons and sets Of animations, or reduce the temporal or spatial detail to achieve acceptable frame rates. In this paper we show how these skeletal skinning methods can be extended to support a continuous level of animation detail. We show that by manipulating the skeletal hierarchy and skinning parameters we can throttle the computational load of a character model in real-time according to its position in a scene and any hardware constraints. Our method is compatible with additional geometric level of detail (LoD) methods. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 UCL, Dept Comp Sci, London WC1E 6BT, England.
   Univ Surrey, CVSSP, Guildford GU2 5XH, Surrey, England.
C3 University of London; University College London; University of Surrey
RP Pilgrim, S (corresponding author), UCL, Dept Comp Sci, London WC1E 6BT, England.
EM spilgrim@europe.ea.com
OI Steed, Anthony/0000-0001-9034-3020
CR AHN J, 2004, P COMP AN SOC AG CAS, P129
   Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   CLARK JH, 1976, COMMUN ACM, V19, P547, DOI 10.1145/360349.360354
   FREIDLIN B, 2001, MSDN MAGAZINE    JUN
   FUNKHOUSER T, 1993, ACM SIGGRAPH 93, V27, P247
   HEJL J, 2005, S13D 05 P 2005 S INT, P9
   HOPPE H, 1996, SIGGRAPH 96, P99, DOI DOI 10.1145/237170.237216
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   KAVAN L, 2007, 2007 ACM SIGGRAPH S
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Sander P. V., 2006, ACM SIGGRAPH 2006 CO, P1, DOI [10.1145/1185657.1185826, DOI 10.1145/1185657.1185826]
   SHAMIR A, 2001, VRST 01 P ACM S VIRT, P77
   Wang XiaohuanGorina., 2002, S COMPUTER ANIMATION, P129
   WATT A, 2003, 3D GANES ANIMATION A
NR 14
TC 3
Z9 3
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 473
EP 481
DI 10.1002/cav.181
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000026
DA 2024-07-18
ER

PT J
AU Sugisaki, E
   Kazama, Y
   Morishima, S
   Tanaka, N
   Sato, A
AF Sugisaki, Eiji
   Kazama, Yosuke
   Morishima, Shigeo
   Tanaka, Natsuko
   Sato, Akiko
TI Hair motion cloning from cartoon animation sequences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cel animation; cartoon animation; hair dynamics; 3D animation; motion
   cloning
AB This paper describes a new approach to create cartoon hair animation that allows users to use existing cel character animation sequences. We demonstrate the generation of cartoon hair animation accentuated in 'anime-like' motions. The novelty of this method is that users can choose the existing cel animation of a character's hair animation and apply environmental elements such as wind to other characters With a three-dimensional structure. In fact, users can reuse existing cartoon sequences as input to endow another character with environmental elements as if both characters exist in the same scene. A three-dimensional character's hair motions are created based on hair motions from input cartoon animation sequences. First, users extract hair shapes at each frame from input sequences from Which they then construct physical equations. 'Anime-like' hair motion is created by using these physical equations. Copyright (c) 2006 John Wiley & Soils, Ltd.
C1 Waseda Univ, Tokyo 160, Japan.
C3 Waseda University
RP Sugisaki, E (corresponding author), Waseda Univ, Tokyo 160, Japan.
EM eijil11@toki.waseda.jp
OI Morishima, Shigeo/0000-0001-8859-6539
CR ANJYO K, 1992, P SIGGRAPH 92, P111
   Chang JohnnyT., 2002, P 2002 ACM SIGGRAPHE, P73
   Hadap S, 2001, COMPUT GRAPH FORUM, V20, pC329, DOI 10.1111/1467-8659.00525
   Lasseter John., 1987, Proceedings of the 14th annual conference on Computer graphics and interactive techniques, P35
   Mao XY, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P142
   Noble P, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P60
   Rademacher P, 1999, COMP GRAPH, P439, DOI 10.1145/311535.311612
   Sugisaki E., 2005, P WSCG 2005, P117
   ZHOU K, 2005, P ACM SIGGRAPH, P496
NR 9
TC 3
Z9 3
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 491
EP 499
DI 10.1002/cav.151
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400034
DA 2024-07-18
ER

PT J
AU Guo, XH
   Qin, H
AF Guo, XH
   Qin, H
TI Real-time meshless deformation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE physics-based animation; point-based animation; meshless method
AB In this paper, we articulate a meshless computational paradigm for the effective modeling, accurate physical simulation, and real-time animation of point-sampled solid objects. Both the interior and the boundary geometry of our volumetric object representation only consist of points, further extending the powerful and popular method of point-sampled surfaces to the volumetric setting. We build the point-based physical model upon continuum mechanics, which affords to effectively model the dynamic elastic behavior of point-based volumetric objects. When only surface samples are provided, our prototype system first generates both interior volumetric points and a volumetric distance field with octree structure. The physics of these volumetric points in a solid interior are simulated using the Meshless Moving Least Squares (MLS) shape functions. In sharp contrast to the traditional finite element method (FEM), the meshless property of our new technique expedites the accurate representation and precise simulation of the underlying discrete model, without the need of domain meshing. In order to achieve real-time simulations, we utilize the warped modal analysis method that is locally linear in nature but globally warped to account for rotational deformation. The structural simplicity and real-time performance of our meshless simulation framework are ideal for interactive animation and game/movie production. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 SUNY Stony Brook, Dept Comp Sci, Ctr Visual Comp, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Guo, XH (corresponding author), SUNY Stony Brook, Dept Comp Sci, Ctr Visual Comp, Stony Brook, NY 11794 USA.
EM xguo@cs.sunysb.edu; qin@cs.sunysb.edu
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Amenta N, 2004, ACM T GRAPHIC, V23, P264, DOI 10.1145/1015706.1015713
   [Anonymous], 1989, P 16 ANN C COMP GRAP
   BAO Y, 2005, COMPUTERS ANIMATION, V16
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   BELYTSCHKO T, 1994, INT J NUMER METH ENG, V37, P229, DOI 10.1002/nme.1620370205
   Belytschko T, 1996, COMPUT METHOD APPL M, V139, P3, DOI 10.1016/S0045-7825(96)01078-X
   Choi MG, 2005, IEEE T VIS COMPUT GR, V11, P91
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   GUO X, 2004, POINT BASED DYNAMIC
   Guo XH, 2004, IEEE COMPUT GRAPH, V24, P43, DOI 10.1109/MCG.2004.16
   Guo XH, 2004, IEEE COMPUT GRAPH, V24, P31, DOI 10.1109/MCG.2004.63
   Hauser KK, 2003, PROC GRAPH INTERF, P247
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   James DL, 2002, DYRT DYNAMIC RESPONS, P582
   Levoy M., 1985, Tech. Rep. 85-022
   METAXAS D, 1992, COMP GRAPH, V26, P309, DOI 10.1145/142920.134085
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
NR 22
TC 20
Z9 24
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 189
EP 200
DI 10.1002/cav.98
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000006
DA 2024-07-18
ER

PT J
AU Jain, N
   Kabul, L
   Govindaroju, NK
   Manocha, D
   Lin, M
AF Jain, N
   Kabul, L
   Govindaroju, NK
   Manocha, D
   Lin, M
TI Multi-resolution collision handling for cloth-like simulations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE chromatic decomposition; collision detection; multi-resolution
   simulation; collision response
AB We present a novel multi-resolution algorithm for simulation of complex cloth-like deforming meshes. Our algorithm precomputes a multi-resolution hierarchy by using a combination of 'chromatic decomposition'(1) and polygonal simplification of the underlying mesh. At runtime we selectively refine or coarsen the mesh based on the collision proximity of the mesh primitives with non-adjacent primitives. Our algorithm handles all kind of contacts, including self collisions among mesh primitives. The multi-resolution hierarchy is used to compute simplification of contact manifolds and to accelerate collision detection and response computations. We have implemented our algorithm on a high-end PC and applied it to complex simulations with tens of thousands of polygons. In practice, our algorithm is able to achieve interactive performance, while maintaining good visual fidelity. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.
EM nitin@cs.unc.edu
OI Manocha, Dinesh/0000-0001-7047-9801
CR [Anonymous], 1996, An Introduction to Computer Simulation Methods: Applications to Physical Systems
   [Anonymous], P ACM SIGGRAPH
   [Anonymous], EUROGRAPHICS
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   BARAFF D, 2003, P ACM SIGGRAPH, P862
   Baraff David, 1992, Dynamic Simulation of Non-penetrating Rigid Bodies
   Breen David E., 1994, Proceedings of the 21st annual conference on Computer graphics and interactive techniques, P365
   BRIDSON R, 2003, EUROGRAPHICS SIGGRAP
   Capell S., 2002, P ACM SIGGRAPH
   Capell S., 2002, P 2002 ACM SIGGRAPHE, P41
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   Choi S.W., 2002, P 7 ACM S SOL MOD AP, P344
   Cohen J. D., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P189, DOI 10.1145/199404.199437
   Cordier F, 2002, COMPUT GRAPH FORUM, V21, P327, DOI 10.1111/1467-8659.t01-1-00592
   DEBUNNE G, 2001, P ACM SIGGRAPH
   DEROSE T, 1998, P ACM SIGGRAPH
   Eck M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P173, DOI 10.1145/218380.218440
   Ehmann SA, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P2101, DOI 10.1109/IROS.2000.895281
   FUHRMANN A, 2003, P WINT SCH COMP GRAP, P203
   GANOVELLI F, 2000, COMPUTER GRAPHICS FO, V19
   GOVINDARAJU N, 2005, ACM T GRAPH P ACM SI
   Grinspun E, 2002, ACM T GRAPHIC, V21, P281, DOI 10.1145/566570.566578
   GUIBAS L, 1999, P ACM S COMP GEOM
   Hirota G, 2000, COMPUT AIDED DESIGN, V32, P499, DOI 10.1016/S0010-4485(00)00038-5
   HIROTA G, 1999, P ACM S SOL MOD APPL
   HOUSE DH, 2000, CLOTH MODELING ANIMA
   HUH S, 2001, COMPUTER ANIMATION, P604
   James DL, 2003, ACM T GRAPHIC, V22, P47, DOI 10.1145/588272.588278
   Kang YM, 2002, COMP ANIM CONF PROC, P203, DOI 10.1109/CA.2002.1017538
   Meyer M, 2001, J VISUAL COMP ANIMAT, V12, P1, DOI 10.1002/vis.244
   Mezger J, 2003, WSCG'2003, VOL 11, NO 2, CONFERENCE PROCEEDINGS, P322
   Molino N, 2003, P 12 INT MESH ROUNDT
   O'Brien D, 2001, COMP ANIM CONF PROC, P210, DOI 10.1109/CA.2001.982395
   Otaduy M. A., 2003, Symposium on Geometry Processing, P94
   Otaduy MA, 2003, ACM T GRAPHIC, V22, P543, DOI 10.1145/882262.882305
   Provot Xavier, 1997, COMPUTER ANIMATION S, P177
   Schroder P., 1998, ACM SIGGRAPH 1998
   VOLINO P, 1994, COMPUT GRAPH FORUM, V13, pC155, DOI 10.1111/1467-8659.1330155
   VOLINO P, 2000, COMPUTER ANIMATION
   VOLKOV V, 2003, P IEEE VIS
   Wu XL, 2001, COMPUT GRAPH FORUM, V20, pC349
   YOON S, 2004, EUR S GEOM PROC
NR 42
TC 2
Z9 3
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 141
EP 151
DI 10.1002/cav.106
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000002
DA 2024-07-18
ER

PT J
AU Tamura, N
   Johan, H
   Nishita, T
AF Tamura, N
   Johan, H
   Nishita, T
TI Deferred shadowing for real-time rendering of dynamic scenes under
   environment illumination
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE deferred shadowing; photo-realistic animation; real-time rendering;
   environment illumination
AB Environment illumination, which is a complex and distant lighting environment represented by images, is often applied to create photo-realistic images. However, creating photo-realistic animations under environment illumination is exceedingly compute intensive. The Precomputed Radiance Transfer (PRT) methods achieve real-time rendering under environment illumination; however, these methods only have a limited application in animation because the objects in the scene cannot be moved or rotated. In this paper, we propose a method for rendering photo-realistic animations of dynamic scenes under environment illumination in real time. We notice the fact that when objects are moved or rotated, changes of radiances occur mainly in the regions of shadows cast by other objects. Our method makes a distinction between self-shadow and shadows cast by other objects and computes these two kinds of shadows efficiently. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Univ Tokyo, Nishita Lab, Kashiwa, Chiba 2778561, Japan.
C3 University of Tokyo
RP Nishita, T (corresponding author), Univ Tokyo, Nishita Lab, Kiban Bldg,5-1-5 Kashiwa No Ha, Kashiwa, Chiba 2778561, Japan.
EM nis@nis-lab.is.s.u-tokyo.ac.jp
RI Johan, Henry/A-3707-2011
CR Agrawala M, 2000, COMP GRAPH, P375, DOI 10.1145/344779.344954
   Akenine-Moller T., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P297
   [Anonymous], 1978, P 5 ANN C COMPUTER G, P270
   ARVO J, 2004, P EUR 2004, P271
   Assarsson U, 2003, ACM T GRAPHIC, V22, P511, DOI 10.1145/882262.882300
   CHAN E, 2003, P EUR S REND, P208
   CROW F, 1977, P SIGGRAPH 77, P242
   Debevec Paul, Light probe image gallery
   DOBASHI Y, 1995, J I IMAGE ELECT ENG, V24, P196
   Heckbert P.S., 1997, CMUCS97104
   Heidrich W, 2000, SPRING COMP SCI, P269
   James DL, 2003, ACM T GRAPHIC, V22, P879, DOI 10.1145/882262.882359
   Kautz J., 2004, Proceedings of the Eurographics Symposium on Rendering, P179
   KAUTZ J, 2002, P 13 EUR WORKSH REND, P291
   Keller Alexander., 1997, SIGGRAPH 97 P 24 ANN, P49
   KOLLIG T, 2003, P 14 EUR WORKSH REND, P45
   KONTKANEN J, 2005, P ACM SIGGRAPH 2005, P41
   Krivanek J., 2004, P 20 SPRING C COMP G, P106
   LEHTINEN J, 2003, P 2003 S INT 3D GRAP, P59
   Mei CH, 2004, COMPUT GRAPH FORUM, V23, P281, DOI 10.1111/j.1467-8659.2004.00759.x
   Ng R, 2004, ACM T GRAPHIC, V23, P477, DOI 10.1145/1015706.1015749
   Ng R, 2003, ACM T GRAPHIC, V22, P376, DOI 10.1145/882262.882280
   NISHITA T, 1985, ACM T GRAPHIC, V4, P124, DOI 10.1145/282918.282938
   NISHITA T, 1986, P SIGGRAPH 86, P125
   NISHITA T, 1985, P SIGGRAPH 85, P23
   Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317
   Sloan PP, 2003, ACM T GRAPHIC, V22, P382, DOI 10.1145/882262.882281
   Sloan PP, 2003, ACM T GRAPHIC, V22, P370, DOI 10.1145/882262.882279
   SLOAN PP, 2002, P ACM SIGGRAPH, P527
   SOLER C, 1998, P SIGGRAPH 98, P321
   Wyman C., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P202
NR 31
TC 3
Z9 3
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 475
EP 486
DI 10.1002/cav.108
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000030
DA 2024-07-18
ER

PT J
AU Mathur, P
   Upadhyay, C
   Chaudhuri, P
   Kalra, P
AF Mathur, P
   Upadhyay, C
   Chaudhuri, P
   Kalra, P
TI A measure for mesh compression of time-variant geometry
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE time-dependent geometry compression; computer animation
AB We present a novel measure for compression of time-variant geometry. Compression of time-variant geometry has become increasingly relevant as transmission of high quality geometry streams is severely limited by network bandwidth. Some work has been done on such compression schemes, but none of them give a measure for prioritizing the loss of information from the geometry stream while doing a lossy compression. In this paper we introduce a cost function which assigns a cost to the removal of particular geometric primitives during compression, based upon their importance in preserving the complete animation. We demonstrate that the use of this measure visibly enhances the performance of existing compression schemes. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Indian Inst Technol, Dept Math, Delhi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Indian Inst Technol, Dept Math, Delhi, India.
EM prasun@cse.iitd.ernet.in
CR Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   BAJAJ C, 2001, COMPUTATIONAL GEOMET, V14, P167
   Briceno H. M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P136
   DEERING M, 1995, P 22 ANN C COMP GRAP, P13
   Garland M., 1997, PROC 24 C COMPUTER G, P209, DOI DOI 10.1145/258734.258849
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   IBARRIA L, 2003, P 2003 ACM SIGGRAPH, P126
   Kim SJ, 2002, COMPUT GRAPH-UK, V26, P657, DOI 10.1016/S0097-8493(02)00121-8
   KWATRA V, 2002, INT C SHAP MOD APPL
   Lee A. W., 1998, Proceedings of the 25th annual conference on Computer graphics and interactive techniques, P95, DOI DOI 10.1145/280814.280828
   LENGYEL JE, 1999, 1999 ACM S INT 3D GR, P89
   Shamir A, 2000, IEEE VISUAL, P423, DOI 10.1109/VISUAL.2000.885724
   Szecsi L, 2003, GRAPHICS PROGRAMMING, P315
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
NR 14
TC 2
Z9 2
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 289
EP 296
DI 10.1002/cav.31
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shi, L
   Yu, YZ
AF Shi, L
   Yu, YZ
TI Inviscid and incompressible fluid simulation on triangle meshes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE advection; the Poisson equation; velocity interpolation
ID SURFACES
AB ySimulating fluid motion on manifold surfaces is an interesting but rarely explored area because of the difficulty of establishing plausible physical models. In this paper, we introduce a novel method for inviscid fluid simulation over meshes. It can enforce incompressibility on closed surfaces by utilizing a discrete vector field decomposition algorithm. It also includes effective implementations of semi-Lagrangian tracing and velocity interpolation schemes. Different from previous work, our method performs simulations directly on triangle meshes and thus eliminates parametrization distortions. Our implementation can produce convincing fluid motion on surfaces and has interactive performance for meshes with tens of thousands of faces. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Illinois, Urbana, IL 61801 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign
RP Univ Illinois, 201 N Goodwin Ave, Urbana, IL 61801 USA.
EM linshi@uiuc.edu
RI YU, YIZHOU/D-1603-2013; /F-3345-2010
OI /0000-0002-0470-5548
CR [Anonymous], P EUR WORKSH SCI VIS
   [Anonymous], 1988, MANIFOLDS TENSOR ANA
   Bertalmío M, 2001, J COMPUT PHYS, V174, P759, DOI 10.1006/jcph.2001.6937
   Catmull Edwin Earl, 1974, A Subdivision Algorithm for Computer Display of Curved Surfaces
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   FOSTER N, 1997, SIGGRAPH 97 C P ANN, P181
   Loop C, 1987, THESIS U UTAH
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J, 2003, ACM T GRAPHIC, V22, P724, DOI 10.1145/882262.882338
   STANIFORTH A, 1991, MON WEATHER REV, V119, P2206, DOI 10.1175/1520-0493(1991)119<2206:SLISFA>2.0.CO;2
   Tong YY, 2003, ACM T GRAPHIC, V22, P445, DOI 10.1145/882262.882290
   WEI X, 2003, ACM S COMPUTER ANIMA
NR 12
TC 30
Z9 38
U1 0
U2 0
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 173
EP 181
DI 10.1002/cav.19
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700006
DA 2024-07-18
ER

PT J
AU Pasko, G
   Pasko, A
   Kunii, T
AF Pasko, Galina
   Pasko, Alexander
   Kunii, Tosiyasu
TI Space-time blending
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE metamorphosis; blending; function representation; animation
AB Shape transformation between objects of different topology and positions in space is all open modelling problem. We propose a new approach to solving this problem for two given 2D or 3D shapes. The key steps of the proposed algorithm are: increase dimension by converting two input kD shapes into half-cylinders in (k + 1)D space-time, applying bounded blending with added material to the half-cylinders, and making cross-sections for getting intermediate shapes wider the transformation. The additional dimension is considered as a time coordinate for making animation. We use the bounded blending set operations ill space-time defined using R-functions and displacement functions with the localized area of influence applied to the functionally defined half-cylinders. The proposed approach is general enough to handle input shapes With arbitrary topology defined as polygonal objects With holes and disjoint components, set-theoretic objects, or analytically defined implicit surface. The obtained unusual amoeba-like behaviour of the shape combines metamorphosis with the non-linear motion. Copyright (C) 2004 John Wiley & Sons, Ltd.
C1 [Pasko, Alexander] Hosei Univ, Fac Comp & Informat Sci, Koganei, Tokyo 1848584, Japan.
   [Pasko, Alexander; Kunii, Tosiyasu] Univ Aizu, Aizu Wakamatsu, Fukushima, Japan.
   [Kunii, Tosiyasu] Univ Tokyo, Ctr Comp, Tokyo 1138654, Japan.
C3 Hosei University; University of Aizu; University of Tokyo
RP Pasko, A (corresponding author), Hosei Univ, Fac Comp & Informat Sci, 3-7-2 Kajino Cho, Koganei, Tokyo 1848584, Japan.
EM pasko@k.hosei.ac.jp
RI Pasko, Alexander/H-9344-2017
OI Pasko, Alexander/0000-0002-4785-7066
CR ADZHIEV V, 1999, IMPLICIT SURFACES 99, P59
   [Anonymous], 1997, Introduction to Implicit Surfaces
   Brandel S, 2000, J VISUAL COMP ANIMAT, V11, P261, DOI 10.1002/1099-1778(200012)11:5<261::AID-VIS232>3.0.CO;2-J
   COHENOR D, 1996, CONTOUR BLENDING USI, P165
   Fausett E, 2000, COMP ANIM CONF PROC, P140, DOI 10.1109/CA.2000.889070
   Galin E, 2000, COMPUT GRAPH FORUM, V19, P257, DOI 10.1111/1467-8659.00462
   Goodwin JM, 2001, VSMM 2001: SEVENTH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA, PROCEEDINGS, P345, DOI 10.1109/VSMM.2001.969689
   Lazarus F, 1998, VISUAL COMPUT, V14, P373, DOI 10.1007/s003710050149
   PASKO A, 1995, VISUAL COMPUT, V11, P429, DOI 10.1007/BF02464333
   PASKO A, 1994, SET THEORETIC SOLID, P151
   PASKO A, 1996, IMPL SURF 96 EUR SIG, P163
   Pasko G, 2002, SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P95, DOI 10.1109/SMI.2002.1003533
   Rvachev VL., 1974, METHODS LOGIC ALGEBR
   Sederberg T.W., 1993, SIGGRAPH 93, P15
   SEDERBERG TW, 1992, COMP GRAPH, V26, P25, DOI 10.1145/142920.134001
   SHAPIRA M, 1995, IEEE COMPUT GRAPH, V15, P44, DOI 10.1109/38.365005
   Surazhsky T, 2001, COMPUT GRAPH-UK, V25, P29, DOI 10.1016/S0097-8493(00)00105-9
   TURK G, 1999, SIGGRAPH 99 P 26 ANN, P35
   Wyvill B., 1986, Visual Computer, V2, P235, DOI 10.1007/BF01900347
   Zhang YF, 2000, VISUAL COMPUT, V16, P106, DOI 10.1007/s003710050200
NR 20
TC 8
Z9 9
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2004
VL 15
IS 2
BP 109
EP 121
DI 10.1002/cav.12
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA V10FD
UT WOS:000207449000005
DA 2024-07-18
ER

PT J
AU Liu, PF
   Zhou, Y
   Wei, XL
   Su, QZ
   Song, WP
   Kou, QL
   Jin, XG
AF Liu, Pengfei
   Zhou, Yang
   Wei, Xilei
   Su, Qizhong
   Song, Weipeng
   Kou, Qilong
   Jin, Xiaogang
TI Character hit reaction animations using physics and inverse kinematics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE behavioral animation; character animation; motion control; physics-based
   animation
AB Character hit reaction is an inherent component in game development. Natural hit reactions in games are typically achieved through the use of artist-created hit animations and motion capture. To improve the realism of impact reactions, game developers combine physics simulation with distinct hit animations based on character statuses. However, there is currently no method that can automatically produce hit reactions based on hit information in game development. To this end, we propose a physics-driven inverse kinematic method for generating character reaction animations. We postulate that a character's hit reactions are the result of an assault impulse spreading throughout the body and forcing the body to move. Five IK (inverse kinematics) solvers are used to control character poses. Each IK solver is used to control the movement of a different part of the body. The IK solvers, which are used to determine the positions of various bodily parts, are driven by unconstrained physics simulation. Furthermore, physics simulation with constraints is used to fine-tune the character's movements. Experiment results show that our method outperforms Unreal Engine-based hit animation and physics simulation.
C1 [Liu, Pengfei; Zhou, Yang; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
   [Wei, Xilei; Su, Qizhong; Song, Weipeng; Kou, Qilong] Tencent, MoreFun Studios, Shenzhen, Peoples R China.
C3 Zhejiang University; Tencent
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
EM jin@cad.zju.edu.cn
RI Liu, Pengfei/B-9291-2018
OI Liu, Pengfei/0000-0001-5983-7305; Jin, Xiaogang/0000-0001-7339-2920
FU Key R&D Program of Zhejiang [2023C01047]; National Natural Science
   Foundation of China [62036010]
FX ACKNOWLEDGMENTS This work was supported by Key R&D Program of Zhejiang
   (grant number 2023C01047) and the National Natural Science Foundation of
   China (grant number 62036010).
CR Adobe Systems, 2023, MIXAMO WEBSITE
   Coros S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1781156
   Eom H, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3360905
   Epic Games, UNREAL ENGINE SOFTWA
   Flores P., 2015, Concepts and Formulations for Spatial Multibody Dynamics, DOI DOI 10.1007/978-3-319-16190-7
   Geyer H, 2003, P ROY SOC B-BIOL SCI, V270, P2173, DOI 10.1098/rspb.2003.2454
   Han D, 2014, COMPUT GRAPH FORUM, V33, P245, DOI 10.1111/cgf.12323
   Harvey FG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392480
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Hong S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322963
   Hu B., 2022, ACM T GRAPHIC, V41, P1
   Lee HC, 2007, IEEE INT SYM MULTIM, P169, DOI 10.1109/ISM.2007.30
   Lee S., DEEP COMPLIANT CONTR
   Lee S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3196492
   Lee SH, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559756
   Peng X. B., 2022, ACM Transactions On Graphics (TOG), V41, P1
   Peng XB, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275014
   Shapiro A., HYBRID CONTROL INTER
   Song S, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00919-y
   Starke S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459881
   Starke S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392450
   WANG LCT, 1991, IEEE T ROBOTIC AUTOM, V7, P489, DOI 10.1109/70.86079
   Won J, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530067
   Yao HY, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555434
   Zordan J. K., 2002, P ACM SIGGRAPH EUR S, P89
NR 25
TC 0
Z9 0
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2170
EA MAY 2023
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000987285800001
DA 2024-07-18
ER

PT J
AU Wang, YN
   Hou, F
   Wang, WC
AF Wang, Yunong
   Hou, Fei
   Wang, Wencheng
TI FFT-based efficient Poisson solver in nonrectangular domain
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fast Fourier transform; fluid simulation; multigrid solver; Poisson's
   equation
AB Poisson's equation is one of the most popular partial differential equation (PDE), which is widely used in image processing, computer graphics and other fields. However, solving a large-scale Poisson's equation always costs huge computational resources. Fast Fourier transform (FFT) is an efficient Poisson solver but it only works in rectangular domain. In this paper, we propose a FFT-based Poisson solver in nonrectangular domain on regular grids combined with algebraic multigrid (AMG). We extend the original Poisson's equation to a rectangular domain to construct an equivalent equation, so that it can use FFT algorithm to accelerate the solving to Poisson's equation. Experiments show that the FFT-based Poisson solver can improve the solving speed of large-scale Poisson's equations in nonrectangular domain. We demonstrate the solver in applications of image processing and fluid simulation.
C1 [Wang, Yunong; Wang, Wencheng] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Hou, Fei] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Hou, Fei] Univ Chinese Acad Sci, 4, Zhong Guan CunSouthern 4th St, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Hou, F (corresponding author), Univ Chinese Acad Sci, 4, Zhong Guan CunSouthern 4th St, Beijing 100190, Peoples R China.
EM houfei@ios.ac.cn
RI WANG, SHIHAO/KHC-8263-2024; Wang, Fei/KEH-6292-2024
OI Hou, Fei/0000-0001-8226-6635
FU National Natural Science Foundation of China [61872347, 62072446];
   Special Plan for the Development of Distinguished Young Scientists of
   ISCAS [Y8RC535018]
FX ACKNOWLEDGMENTS This research has been partially supported by National
   Natural Science Foundation of China (61872347, 62072446), Special Plan
   for the Development of Distinguished Young Scientists of ISCAS
   (Y8RC535018).
CR [Anonymous], 2010, P 2010 ACM SIGGRAPHE
   Bridson R., 2015, Fluid simulation for computer graphics
   Chen J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459851
   Chern A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925868
   Costa P, 2022, COMPUT PHYS COMMUN, V271, DOI 10.1016/j.cpc.2021.108194
   Demidov D, 2020, SOFTW IMPACTS, V6, DOI 10.1016/j.simpa.2020.100037
   Dick C, 2016, IEEE T VIS COMPUT GR, V22, P2480, DOI 10.1109/TVCG.2015.2511734
   Greenfeld D., 2019, LEARNING OPTIMIZE MU, P2415
   Krishnan D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461992
   LECOZ YL, 1992, SOLID STATE ELECTRON, V35, P1005, DOI 10.1016/0038-1101(92)90332-7
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Luz I., 2020, LEARNING ALGEBRAIC M, P6489
   Owhadi H, 2017, SIAM REV, V59, P99, DOI 10.1137/15M1013894
   Sawhney R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392374
   Tamstorf R, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818081
   Teunissen J, 2023, COMPUT PHYS COMMUN, V286, DOI 10.1016/j.cpc.2023.108665
   Thuerey Nils, 2018, MantaFlow
   Weymouth GD, 2022, COMPUT FLUIDS, V246, DOI 10.1016/j.compfluid.2022.105620
   Xiao XY, 2020, IEEE T VIS COMPUT GR, V26, P1454, DOI 10.1109/TVCG.2018.2873375
   Zhu YN, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731054
NR 20
TC 1
Z9 1
U1 3
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2185
EA MAY 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000987527600001
DA 2024-07-18
ER

PT J
AU Li, TT
   Wang, ML
   Liu, XX
   Liang, H
   Chang, J
   Zhang, JJ
AF Li, Tingting
   Wang, Meili
   Liu, Xiaoxiao
   Liang, Hui
   Chang, Jian
   Zhang, Jian Jun
TI Point cloud synthesis with stochastic differential equations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE point cloud reconstruction; point cloud synthesis; stochastic
   differential equations
AB In this article, we propose a point cloud synthesis method based on stochastic differential equations. We view the point cloud generation process as smoothly transforming from a known prior distribution toward the high-likelihood shape by point-level denoising. We introduce a conditional corrector sampler to improve the quality of point clouds. By leveraging Markov chain Monte Carlo sample, our method can synthesize realistic point clouds. We additionally prove that our approach can be trained in an auto-encoding fashion and reconstruct the point cloud faithfully. Furthermore, our model can be extended on a downstream application of point cloud completion. Experimental results demonstrate the effectiveness and efficiency of our method.
C1 [Li, Tingting; Liu, Xiaoxiao; Chang, Jian; Zhang, Jian Jun] Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
   [Wang, Meili] Northwest Agr & Forestry Univ, Coll Informat Engn, Xianyang, Peoples R China.
   [Liang, Hui] Zhengzhou Univ Light Ind, Zhengzhou, Peoples R China.
C3 Bournemouth University; Northwest A&F University - China; Zhengzhou
   University of Light Industry
RP Liang, H (corresponding author), Zhengzhou Univ Light Ind, Zhengzhou, Peoples R China.
EM hliang@zzuli.edu.cn
FU Jie Bang Gua Shuai Science and Technology Project of Henan Province
   [211110110500]; Scientific and Technological Project in Henan Province
   [222102210030]
FX Jie Bang Gua Shuai Science and Technology Project of Henan Province,
   Grant/Award Number: 211110110500;Scientific and Technological Project in
   Henan Province, Grant/Award Number:222102210030
CR Achlioptas P, 2018, PR MACH LEARN RES, V80
   Anderson B.D., 1982, Stochastic Processes and their Applications, V12, P313, DOI [10.1016/0304-4149(82)90051-5, DOI 10.1016/0304-4149(82)90051-5]
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Cai R., 2020, P EUROPEAN C COMPUTE
   Chen X., VARIATIONAL LOSSY AU
   Dinh Laurent, Density estimation using real nvp, 1605.08803
   Gadelha M., LECT NOTES COMPUT SC
   Gal R., MRGAN MULTI ROOTED 3
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Kim H., 2020, Adv. Neural Inf. Process. Syst., V33, P16388
   Kiyosi It., 1973, Vector and Operator Valued Measures and Applications. Ed. by, P141, DOI DOI 10.1016/B978-0-12-702450-9.50020-8
   Klokov Roman, 2020, EUR C COMP VIS, P694, DOI [DOI 10.1007/978-3-030-58592-141, 10.1007/978-3-030-58592-1_41, 10.1007/978-3-030-58592]
   Li KJ, 2018, LECT NOTES COMPUT SC, V11216, P508, DOI 10.1007/978-3-030-01258-8_31
   Luo ST, 2021, PROC CVPR IEEE, P2836, DOI 10.1109/CVPR46437.2021.00286
   Lyu Z., CONDITIONAL POINT DI
   Nichol A, 2021, PR MACH LEARN RES, V139
   Oksendal B., 2003, STOCHASTIC DIFFERENT, P65, DOI DOI 10.1007/978-3-642-14394-6-5
   PARISI G, 1981, NUCL PHYS B, V180, P378, DOI 10.1016/0550-3213(81)90056-0
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2017, ADV NEUR IN, V30
   Ramasinghe S, 2020, IEEE INT C INT ROBOT, P8169, DOI 10.1109/IROS45743.2020.9341265
   Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530
   Shu DW, 2019, IEEE I CONF COMP VIS, P3858, DOI 10.1109/ICCV.2019.00396
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Song Y., IMPROVED TECHNIQUES
   Song Y., SCORE BASED GENERATI
   Song Y, 2019, ADV NEUR IN, V32
   Su H, Shapenet: An information-rich 3d model repository
   Sun YB, 2020, IEEE WINT CONF APPL, P61, DOI [10.1109/wacv45572.2020.9093430, 10.1109/WACV45572.2020.9093430]
   Tancik M., P ADV NEUR INF PROC
   Valsesia D., 2018, P INT C LEARNING REP
   Watson D., LEARNING EFFICIENTLY
   Wu J., P 30 INT C ADV NEUR
   Yang GD, 2019, IEEE I CONF COMP VIS, P4540, DOI 10.1109/ICCV.2019.00464
   Zamorski M, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102921
   Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595
   Zhao YH, 2019, PROC CVPR IEEE, P1009, DOI 10.1109/CVPR.2019.00110
   Zhou LQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5806, DOI 10.1109/ICCV48922.2021.00577
NR 39
TC 0
Z9 0
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2140
EA FEB 2023
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000939665400001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wang, J
   Liu, TT
   Liu, Z
   Chai, YJ
AF Wang, Jing
   Liu, Tingting
   Liu, Zhen
   Chai, Yanjie
TI Exploring the influencing factors of wall-following behavior in a
   virtual reality fire evacuation game
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE environmental familiarity; neighbor behavior; smoke level; VR game;
   wall-following behavior
ID EXIT CHOICE; EMERGENCY EVACUATION; LIMITED VISIBILITY; SOCIAL-INFLUENCE;
   ROUTE-CHOICE; CROWD; MODEL
AB In most of fire evacuation, people follow the walls. The reasons behind this escape behavior have not been verified by experiments. In this article, we design a virtual reality (VR) fire evacuation game with realistic virtual environment to explore the effects of smoke concentration, individual familiarity with the environment, and neighbor behavior on individual wall-following behavior. Individuals' familiarity with the environment is obtained through experimental training and the frequencies of their behavior along the wall at different smoke concentrations are recorded. From a subjective perspective, we use the presence scale to assess the immersion of the designed VR game. The results show that users have a good level of presence in the designed VR game. From an objective perspective, we analyze the game data using a statistically based approach. The analysis shows that high concentration of smoke, unfamiliar with the environment will increase individuals' reliance on walls, but neighbor behavior along the wall has no significant effect on individual wall-following behavior.
C1 [Wang, Jing; Liu, Zhen; Chai, Yanjie] Ningbo Univ, Fac Informat Sci & Technol, Ningbo, Peoples R China.
   [Liu, Tingting] Ningbo Univ, Coll Sci & Technol, Cixi, Peoples R China.
C3 Ningbo University; Ningbo University
RP Liu, TT (corresponding author), Ningbo Univ, Coll Sci & Technol, Cixi, Peoples R China.
EM liutingting@nbu.edu.cn
OI liu, tingting/0000-0002-3469-275X
FU Ningbo Science Technology Plan Projects [2022Z077, 2021S091]; Natural
   Science Foundation of Zhejiang Province [LY20F020007]
FX This work was partially sponsored by the Ningbo Science Technology Plan
   Projects (Grants 2022Z077 and 2021S091) and Natural Science Foundation
   of Zhejiang Province (Grant LY20F020007).
CR Arias S, 2021, FIRE MATER, V45, P462, DOI 10.1002/fam.2922
   Bode NWF, 2013, ANIM BEHAV, V86, P347, DOI 10.1016/j.anbehav.2013.05.025
   Bruun A, 2021, ACM T COMPUT-HUM INT, V28, DOI 10.1145/3453479
   Cao LJ, 2019, COMPUT HUM BEHAV, V90, P37, DOI 10.1016/j.chb.2018.08.041
   Cao SC, 2018, FIRE SAFETY J, V102, P27, DOI 10.1016/j.firesaf.2018.10.003
   Cao SC, 2015, PHYSICA A, V436, P45, DOI 10.1016/j.physa.2015.05.019
   Daylamani-Zad D, 2022, INT J HUM-COMPUT ST, V162, DOI 10.1016/j.ijhcs.2022.102790
   Drury J, 2009, BEHAV RES METHODS, V41, P957, DOI 10.3758/BRM.41.3.957
   Farr AC, 2012, TRANSPORT REV, V32, P715, DOI 10.1080/01441647.2012.712555
   Fridolf K, 2013, FIRE SAFETY J, V59, P8, DOI 10.1016/j.firesaf.2013.03.007
   Fu MQ, 2021, SAFETY SCI, V140, DOI 10.1016/j.ssci.2021.105245
   Fu MQ, 2021, AUTOMAT CONSTR, V126, DOI 10.1016/j.autcon.2021.103644
   Haghani M, 2018, TRANSPORT RES B-METH, V107, P253, DOI 10.1016/j.trb.2017.06.017
   Isobe M, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066132
   Kim YM, 2021, INT J HUM-COMPUT ST, V155, DOI 10.1016/j.ijhcs.2021.102691
   Kim YC, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14074057
   Kinateder M, 2018, SAFETY SCI, V106, P170, DOI 10.1016/j.ssci.2018.03.015
   Kinateder M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00043
   Kinateder M, 2014, ACSIS-ANN COMPUT SCI, V2, P313
   Kinateder M, 2014, TRANSPORT RES F-TRAF, V26, P116, DOI 10.1016/j.trf.2014.06.003
   Kobes M, 2010, FIRE SAFETY J, V45, P1, DOI 10.1016/j.firesaf.2009.08.005
   Li CY, 2017, IEEE T VIS COMPUT GR, V23, P1388, DOI 10.1109/TVCG.2017.2656958
   Li HL, 2019, TRANSPORT RES C-EMER, V107, P120, DOI 10.1016/j.trc.2019.08.012
   Lin J, 2020, ADV ENG INFORM, V43, DOI 10.1016/j.aei.2020.101040
   Lin J, 2020, SAFETY SCI, V122, DOI 10.1016/j.ssci.2019.104540
   Lorusso P, 2022, BUILDINGS-BASEL, V12, DOI 10.3390/buildings12020223
   Lovreglio R, 2016, TRANSPORT RES A-POL, V92, P59, DOI 10.1016/j.tra.2016.06.018
   Nilsson D, 2009, FIRE SAFETY J, V44, P71, DOI 10.1016/j.firesaf.2008.03.008
   Normoyle A., 2012, EGRESS ONLINE LEVERA
   Pelechano N, 2006, IEEE COMPUT GRAPH, V26, P80, DOI 10.1109/MCG.2006.133
   Phillips J, 2013, GEOFORUM, V47, P113, DOI 10.1016/j.geoforum.2013.04.002
   Proulx G., 2001, P 9 INT FIRE PROTECT, P219
   Ronchi E., 2013, FIRE SCI REV, V2, P7, DOI [10.1186/2193-0414-2-7, DOI 10.1186/2193-0414-2-7]
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Seike M, 2021, TUNN UNDERGR SP TECH, V112, DOI 10.1016/j.tust.2021.103934
   Snopková D, 2022, SPAT COGN COMPUT, V22, P30, DOI 10.1080/13875868.2021.1913497
   Tong YH, 2022, J R SOC INTERFACE, V19, DOI 10.1098/rsif.2022.0061
   Tucker A, 2018, FIRE SAFETY J, V99, P1, DOI 10.1016/j.firesaf.2018.04.011
   Vilar E, 2013, APPL ERGON, V44, P618, DOI 10.1016/j.apergo.2012.12.002
   Wang GN, 2022, PHYSICA A, V603, DOI 10.1016/j.physa.2022.127638
   Xue SQ, 2020, TRANSPORTMETRICA A, V16, P626, DOI 10.1080/23249935.2020.1722281
   Yamada T., 2016, SFPE HDB FIRE PROTEC, VII, P2181
   Yang YJ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311284
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zhu RH, 2020, SAFETY SCI, V127, DOI 10.1016/j.ssci.2020.104691
   Zou H, 2017, J COMPUT CIVIL ENG, V31, DOI 10.1061/(ASCE)CP.1943-5487.0000679
NR 46
TC 1
Z9 1
U1 10
U2 38
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2023
VL 34
IS 1
SI SI
AR e2122
DI 10.1002/cav.2122
EA AUG 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Z2BA
UT WOS:000842321300001
DA 2024-07-18
ER

PT J
AU Yang, FC
   Mousas, C
   Adamo, N
AF Yang, Fu-Chia
   Mousas, Christos
   Adamo, Nicoletta
TI Holographic sign language avatar interpreter: A user interaction study
   in a mixed reality classroom
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE holographic avatar; mixed reality; sign language animation; user
   interaction
AB We explored user interactions with a holographic sign language interpreter in a mixed reality (MR) classroom for deaf and hard of hearing students. The developed MR application projects a holographic signing avatar that translates in real time the lecture while a speaking instructor is teaching. Our study explored user interaction with the MR system, intending to provide design guidelines for digital MR sign language interpreters. We recruited eight participants and conducted a usability test focused on avatar framing (full-body vs. half-body) and avatar manipulation (fixed position, scale, and orientation vs. user-adjustable position, scale, and orientation) in the MR classroom. We used a mixed-method approach to analyze quantitative and qualitative data through recordings, surveys, and interviews. The results show user preferences toward viewing holographic signing avatars in the MR environment and user acceptability toward such applications.
C1 [Yang, Fu-Chia; Mousas, Christos; Adamo, Nicoletta] Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Yang, FC (corresponding author), Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
EM yang1684@purdue.edu
RI Mousas, Christos/AGV-3533-2022
OI Mousas, Christos/0000-0003-0955-7959; Adamo,
   Nicoletta/0000-0001-8311-5302
FU Purdue University, Instructional Innovation Grant
FX Purdue University, Instructional Innovation Grant
CR Adamo-Villani N., 2017, E-Learning, E-Education, and Online Training, P54, DOI DOI 10.1007/978-3-319-49625-2_7
   Constantinou V, 2020, UNIVERSAL ACCESS INF, V19, P195, DOI 10.1007/s10209-018-0630-8
   Guo Ru., 2020, Population Growth and Structural Change China Ethnic Statistical Yearbook 2020, P1
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Huenerfauth Matt., 2009, Universal Access Handbook, V38, P14
   Jain D, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P81, DOI 10.1145/3234695.3236362
   Kaneko H., 2010, Proceedings of the 9th ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications in Industry, P289, DOI [10.1145/1900179.1900240, DOI 10.1145/1900179.1900240]
   Kang ZH, 2019, 2019 INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING SYSTEMS (SPSS 2019), P159, DOI 10.1145/3364908.3365300
   Kaur K, 2016, PROCEDIA COMPUT SCI, V89, P794, DOI 10.1016/j.procs.2016.06.063
   Kaur R, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2727, DOI 10.1109/ICACCI.2014.6968333
   Kipp Michael, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P113, DOI 10.1007/978-3-642-23974-8_13
   LEE J, 1993, J VISUAL COMP ANIMAT, V4, P63, DOI 10.1002/vis.4340040203
   Miller Ashley., 2017, P 2017 CHI C HUM FAC, P1909, DOI [DOI 10.1145/3027063.3053117, 10.1145/3027063.3053117]
   Parton BS, 2017, TECHTRENDS, V61, P141, DOI 10.1007/s11528-016-0090-z
   Peng YH, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173867
   Saladin S.P., 2004, Psychosocial variables in the adoption of assistive technology among deaf and hard-of-hearing adults
   Smith C.P., 2000, HDB RES METHODS SOCI
   Vesel J, 2013, J RES TECHNOL EDUC, V45, P361, DOI 10.1080/15391523.2013.10782610
   Vinayagamoorthy V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300762
   Vinayagamoorthy V, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P179, DOI 10.1145/3210825.3213562
   Zirzow NK., 2019, TECHNOLOGY USE BY TEACHERS OF DEAF AND HARD-OF- HEARING STUDENTS Department of Special Education
NR 21
TC 3
Z9 3
U1 3
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2082
DI 10.1002/cav.2082
EA JUN 2022
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000808189700001
DA 2024-07-18
ER

PT J
AU Chen, ZH
   Zhou, Y
   Li, R
   Li, P
   Sheng, B
AF Chen, Zhihua
   Zhou, Yu
   Li, Ran
   Li, Ping
   Sheng, Bin
TI SCPA-Net: Self-calibrated pyramid aggregation for image dehazing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE image dehazing; pyramid upsampling structure; self-attention;
   self-calibration
AB Dehazing as an important image processing field has developed for many years, there exist many excellent methods for exploring more complex networks to solve this problem. In this paper, instead of designing a complex network structure, we propose a novel dehazing network based on the consideration of enhancing feature aggregation and feature representation abilities of dehazing architecture. Specifically, we propose a self-calibrated pyramid aggregation network (SCPA-Net) for image dehazing, which is based on an encoder-decoder architecture. In the encoder, we build a self-attention block as a unit to aggregate information from a neighborhood to adapt to its content. In the decoder, we introduce a self-calibration block to capture long-range spatial and channel dependencies to produce more discriminative representations. Finally, to learn the scale information, the pyramid upsampling structure is applied to aggregate the multiscale self-calibrated attentive features. Experimental results show our SCPA-Net can achieve impressive dehazing performance.
C1 [Chen, Zhihua; Zhou, Yu; Li, Ran] East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Sch Design, Hung Hom, Hong Kong, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
C3 East China University of Science & Technology; Hong Kong Polytechnic
   University; Hong Kong Polytechnic University; Shanghai Jiao Tong
   University
RP Chen, ZH (corresponding author), East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai, Peoples R China.; Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
EM czh@ecust.edu.cn; shengbin@sjtu.edu.cn
RI Li, Ping/AAO-2019-2020
OI Li, Ping/0000-0002-1503-0240; Sheng, Bin/0000-0001-8678-2784
FU National Natural Science Foundation of China [61572316, 61872241];
   Shanghai Municipal Science and Technology Major Project
   [2021SHZDZX0102]; Hong Kong Polytechnic University [P0030419, P0030929,
   P0035358]
FX National Natural Science Foundation of China, Grant/Award Numbers:
   61572316, 61872241; Shanghai Municipal Science and Technology Major
   Project, Grant/Award Number: 2021SHZDZX0102; Hong Kong Polytechnic
   University, Grant/Award Numbers: P0030419, P0030929, P0035358
CR Berman D, 2020, IEEE T PATTERN ANAL, V42, P720, DOI 10.1109/TPAMI.2018.2882478
   Chen ZY, 2021, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR46437.2021.00710
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Dong Y, 2020, AAAI CONF ARTIF INTE, V34, P10729
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hong M, 2020, PROC CVPR IEEE, P3459, DOI 10.1109/CVPR42600.2020.00352
   Jiang-Jiang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10093, DOI 10.1109/CVPR42600.2020.01011
   Kaihua Cheng, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P453, DOI 10.1007/978-3-030-67070-2_27
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li LRH, 2020, IEEE T IMAGE PROCESS, V29, P2766, DOI 10.1109/TIP.2019.2952690
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu Y, 2019, IEEE I CONF COMP VIS, P2492, DOI 10.1109/ICCV.2019.00258
   Ni ZL, 2020, AAAI CONF ARTIF INTE, V34, P11782
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wan Q., 2021, P IEEECVF C COMPUTER, P5983
   Wang C, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2517, DOI 10.1145/3394171.3413559
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhao H., 2020, P IEEE CVF C COMP VI, V2020, P10076, DOI 10.1109/CVPR42600.2020.01009
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao SY, 2021, IEEE T IMAGE PROCESS, V30, P3391, DOI 10.1109/TIP.2021.3060873
NR 25
TC 5
Z9 5
U1 2
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2061
DI 10.1002/cav.2061
EA JUN 2022
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000805154000001
DA 2024-07-18
ER

PT J
AU Zhu, CZ
   Wang, H
   Xiao, YL
   Dai, YL
   Liu, ZX
   Zou, BJ
AF Zhu, Chengzhang
   Wang, Han
   Xiao, Yalong
   Dai, Yulan
   Liu, Zixi
   Zou, Beiji
TI OVS-Net: An effective feature extraction network for optical coherence
   tomography angiography vessel segmentation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 35th International Conference on Computer Animation and Social Agents
   (CASA)
CY JUL 05-07, 2022
CL Nanjing, PEOPLES R CHINA
SP Nanjing Univ
DE feature extraction; optical coherence tomography angiography; retinal
   vessel segmentation
AB Optical coherence tomography angiography (OCTA), as a noninvasive imaging modality, has been widely used in clinical ophthalmology. However, the segmentation of retinal vessels in OCTA is under-studied due to OCTA is a relatively new technology. In this article, an effective feature extraction network, OVS-Net, is proposed for OCTA vessel segmentation. The OVS-Net is divided into coarse stage and refine stage which structures are basically the same. In each stage, we utilize OctaveResBlock as the basic block to better extract the hierarchical multifrequency features of OCTA and capture the multiscale semantic features of the vessels. In order to improve the feature characterization, feature enhanced attention block is introduced into the network, which is proved to be more conducive for microvessel segmentation in our experiments. Multiscale feature blocks are introduced into the network to promote the deep integration of semantic features at different scales. Experiments on OCTA-SS and OCTA-500 datasets show that our proposed OVS-Net achieves more competitive segmentation results than the existing methods, especially for microvessel segmentation.
C1 [Zhu, Chengzhang; Wang, Han; Xiao, Yalong; Dai, Yulan; Liu, Zixi; Zou, Beiji] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
   [Zhu, Chengzhang; Xiao, Yalong] Cent South Univ, Coll Literature & Journalism, Changsha, Peoples R China.
   [Zhu, Chengzhang; Wang, Han; Xiao, Yalong; Dai, Yulan; Liu, Zixi; Zou, Beiji] Mobile Hlth Minist Educ China Mobile Joint Lab, Changsha, Peoples R China.
C3 Central South University; Central South University
RP Xiao, YL (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
EM ylxiao@csu.edu.cn
RI Liu, Zixi/GRS-0065-2022
OI Liu, Zixi/0000-0003-2930-5118
FU National Key R&D Program of China [2018AAA0102100]; Scientific and
   Technological Innovation Leading Plan of High-Tech Industry of Hunan
   Province [2020GK2021]; National Natural Science Foundation of China
   [61902434]; Natural Science Foundation of Hunan Province, China
   [2019JJ50826]; International Science and Technology Innovation Joint
   Base of Machine Vision and Medical Image Processing in Hunan Province
   [2021CB1013]
FX This work is supported by the National Key R&D Program of China
   (2018AAA0102100), the Scientific and Technological Innovation Leading
   Plan of High-Tech Industry of Hunan Province (2020GK2021), the National
   Natural Science Foundation of China (61902434), the Natural Science
   Foundation of Hunan Province, China (2019JJ50826), and the International
   Science and Technology Innovation Joint Base of Machine Vision and
   Medical Image Processing in Hunan Province (2021CB1013).
CR Alom M. Z., 2018, ARXIV180206955, V6, P014006, DOI 10.1109/NAECON.2018.8556686
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen YP, 2019, IEEE I CONF COMP VIS, P3434, DOI 10.1109/ICCV.2019.00353
   Fan Z., 2019, ACCURATE RETINAL VES
   Giarratano Y, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.13.5
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Li MZ, 2021, AAAI CONF ARTIF INTE, V35, P4189
   Li M, 2022, ARCH PHYSIOL BIOCHEM, V128, P1259, DOI 10.1080/13813455.2020.1764051
   Li MC, 2020, IEEE T MED IMAGING, V39, P3343, DOI 10.1109/TMI.2020.2992244
   Li WS, 2022, MED PHYS, V49, P3830, DOI 10.1002/mp.15608
   Ma YH, 2021, IEEE T MED IMAGING, V40, P928, DOI 10.1109/TMI.2020.3042802
   Mou L, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101874
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Peng LK, 2021, LECT NOTES COMPUT SC, V12970, P42, DOI 10.1007/978-3-030-87000-3_5
   Ren X, 2019, CHIN J ANATOMY CLIN, V24, P5
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Wang ZY, 2020, AAAI CONF ARTIF INTE, V34, P6315
   Zhang S, 2021, J GANNAN MED U, V41, P5
NR 21
TC 3
Z9 3
U1 2
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2096
DI 10.1002/cav.2096
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 2S4AL
UT WOS:000821735900008
DA 2024-07-18
ER

PT J
AU Wu, FY
   Pang, CY
   Zhang, BL
AF Wu, Fangyu
   Pang, Chaoyi
   Zhang, Bailing
TI FaceCaps for facial expression recognition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE capsule network; facial expression recognition; feature embedding
AB Facial expression recognition (FER) is a significant research task in the computer vision field. In this paper, we present a novel network FaceCaps for facial expression recognition with the following novel characteristics: an embedding structure based on a Capsule network which encodes relative spatial relationships between features; incorporates the feature polymerization property of FaceNet, thus offering a more efficient approach to discriminate complex facial expressions; a target reconstruction loss as a better regularization term for Capsule networks. Experimental results on both lab-controlled datasets (CK+) and real-world databases (RAF-DB and SFEW 2.0) demonstrate that the method significantly outperforms the state-of-the-art.
C1 [Wu, Fangyu] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Wu, Fangyu; Pang, Chaoyi; Zhang, Bailing] NingboTech Univ, Sch Comp & Data Engn, 1 Qianhu South Rd, Ningbo, Zhejiang, Peoples R China.
C3 Zhejiang University; NingboTech University
RP Zhang, BL (corresponding author), NingboTech Univ, Sch Comp & Data Engn, 1 Qianhu South Rd, Ningbo, Zhejiang, Peoples R China.
EM bailing.zhang@nit.zju.edu.cn
RI Pang, Chaoyi/JQX-1513-2023
OI wu, fangyu/0000-0001-9618-8965
FU Ningbo 2025 Key Scientific Research Programs [2019B10128]
FX The paper is supported by Ningbo 2025 Key Scientific Research Programs,
   Grant/Award Number: 2019B10128.
CR Acharya D, 2018, IEEE COMPUT SOC CONF, P480, DOI 10.1109/CVPRW.2018.00077
   Afshar P, 2020, PATTERN RECOGN LETT, V138, P638, DOI 10.1016/j.patrec.2020.09.010
   [Anonymous], 2015, ICM P 2015 ACM INT, DOI DOI 10.1145/2823327.2823332
   Deng W, 2018, ARXIV PREPRINT ARXIV
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Lei K, 2020, NEUROCOMPUTING, V391, P65, DOI 10.1016/j.neucom.2020.01.091
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Liang LQ, 2021, IEEE T INF FOREN SEC, V16, P482, DOI 10.1109/TIFS.2020.3007327
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu YY, 2018, IEEE INT CONF AUTOMA, P458, DOI 10.1109/FG.2018.00074
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   Ly ST, 2019, IEEE COMPUT SOC CONF, P2927, DOI 10.1109/CVPRW.2019.00353
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098
   Sabour S, 2017, ADV NEUR IN, V30
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Vielzeuf V, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P589, DOI 10.1145/3242969.3264980
   Xiang CQ, 2018, IEEE SIGNAL PROC LET, V25, P1850, DOI 10.1109/LSP.2018.2873892
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang T., 2017, ADV INTELLIGENT SYST, P345
NR 27
TC 5
Z9 5
U1 4
U2 28
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2021
DI 10.1002/cav.2021
EA JUN 2021
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000657431700001
DA 2024-07-18
ER

PT J
AU Wang, MN
   Cao, JQ
AF Wang, Monan
   Cao, Jiaqi
TI A review of collision detection for deformable objects
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Review
DE collision detection; deformable objects; inter-object collision
   detection; intra-object collision detection
AB In the process of simulating and modeling real objects, the phenomenon of objects penetrating each other may occur in the model, which is unrealistic and then the research of collision detection (CD) is generated. As a bottleneck of virtual environment simulation, researchers have conducted in-depth research on CD, especially the CD of deformable objects. In this paper, we briefly review the related research on CD of deformable objects regarding relevant literature. First, we briefly introduce previous reviews of CD. Second, we review the popular research methods and limitations of CD between deformable objects. Third, we review the popular research methods and limitations of self-collision detection in deformable objects. Finally, we discuss future directions of development. This review can be used as a reference for the application of CD in all directions.
C1 [Wang, Monan; Cao, Jiaqi] Harbin Univ Sci & Technol, Mech & Power Engn Coll, Harbin, Peoples R China.
C3 Harbin University of Science & Technology
RP Wang, MN (corresponding author), Harbin Univ Sci & Technol, Mech & Power Engn Coll, Harbin, Peoples R China.
EM mnwang@hrbust.edu.cn
OI Wang, Monan/0000-0003-0927-6487
FU Natural Science Foundation of Heilongjiang Province [61972117]; Natural
   Science Foundation of Heilongjiang Province of China [ZD2019E007]
FX Natural Science Foundation of Heilongjiang Province, Grant/Award Number:
   61972117; Natural Science Foundation of Heilongjiang Province of China,
   Grant/Award Number: ZD2019E007
CR Abam MA, 2009, ALGORITHMICA, V53, P457, DOI 10.1007/s00453-007-9019-4
   Aila T., 2013, P 5 HIGH PERFORMANCE, P101
   Allard J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778819
   [Anonymous], 2002, P S VIRT REAL BRAS
   [Anonymous], P 2010 ACM SIGGRAPH
   Avril Q., 2014, J VIRTUAL REALITY BR, V10, P1
   Baciu G, 1999, J VISUAL COMP ANIMAT, V10, P181, DOI 10.1002/(SICI)1099-1778(199910/12)10:4<181::AID-VIS211>3.0.CO;2-Q
   BANDI S, 1995, COMPUT GRAPH FORUM, V14, pC259
   BARAN I, 2007, ACM SIGGRAPH 2007 PA, DOI DOI 10.1145/1276377.1276467
   Barbic J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778818
   Bittner J, 2013, COMPUT GRAPH FORUM, V32, P85, DOI 10.1111/cgf.12000
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Brochu T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185592
   Calakli F, 2011, COMPUT GRAPH FORUM, V30, P1993, DOI 10.1111/j.1467-8659.2011.02058.x
   Capannini G., 2016, P 16 EUR S PAR GRAPH, P1
   Capannini G, 2018, IEEE T VIS COMPUT GR, V24, P2064, DOI 10.1109/TVCG.2017.2709313
   Capell S, 2002, ACM T GRAPHIC, V21, P586, DOI 10.1145/566570.566622
   Choi AR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184334
   Choi AR, 2017, FRONT INFORM TECH EL, V18, P1117, DOI 10.1631/FITEE.1500498
   Cohen J. D., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P189, DOI 10.1145/199404.199437
   Coumans Erwin., BULLET PHYS LIB
   Curtis S, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P61
   Ehmann SA, 2001, COMPUT GRAPH FORUM, V20, pC500
   Eloe NW, 2014, J VISUAL LANG COMPUT, V25, P764, DOI 10.1016/j.jvlc.2014.09.014
   Falipou, SCA 08 P 2008 ACM SI, P155
   Fan WS, 2011, COMPUT GRAPH FORUM, V30, P1451, DOI 10.1111/j.1467-8659.2011.02019.x
   Fatahalian G., 2013, P 5 HIGH PERF GRAPH, P81, DOI 10.1145/2492045.2492054
   Frisken S.F., 2006, ACM SIGGRAPH COURSE, P60
   Frisken SF, 2000, COMP GRAPH, P249, DOI 10.1145/344779.344899
   Fukuhara A., 2014, ROBOMECH J, DOI 10.1186/s40648-014-0006-7
   GANTER MA, 1993, J MECH DESIGN, V115, P150, DOI 10.1115/1.2919312
   GARCIAALONSO A, 1994, IEEE COMPUT GRAPH, V14, P36, DOI 10.1109/38.279041
   Geleri F, 2013, EUROMICRO WORKSHOP P, P384, DOI 10.1109/PDP.2013.62
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Govindaraju NK, 2007, COMPUT GRAPH-UK, V31, P5, DOI 10.1016/j.cag.2006.09.005
   Govindaraju NK, 2005, ACM T GRAPHIC, V24, P991, DOI 10.1145/1073204.1073301
   Haber J, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P52, DOI 10.1109/PCCGA.2000.883881
   He L, 2015, PROCEEDINGS - I3D 2015, P47, DOI 10.1145/2699276.2699286
   Heidelberger B, 2003, VISION, MODELING, AND VISUALIZATION 2003, P461
   Heidelberger B., 2004, PROC WSCG, P145
   Held M., 1995, 7 CANADIAN C COMPUTE, V3, P205
   Hoberock, 2011, APPL GPU COMPUTING S, V2, P359
   Hubbard P. M., 1993, Proceedings IEEE 1993 Symposium on Research Frontiers in Virtual Reality (Cat. No.93TH0585-0), P24, DOI 10.1109/VRAIS.1993.378267
   Hubbard PM, 1996, ACM T GRAPHIC, V15, P179, DOI 10.1145/231731.231732
   HUBBARD PM, 1995, IEEE T VIS COMPUT GR, V1, P218, DOI 10.1109/2945.466717
   Hutter M, 2007, JOURNAL WSCG, V15, P25
   Hyun DE, 2005, VISUAL COMPUT, V21, P542, DOI 10.1007/s00371-005-0343-x
   Jamriska O., 2010, P 14 CENTR EUR SEM C, V2
   Jian H, 2001, IEEE VISUAL, P247
   Jiménez P, 2001, COMPUT GRAPH-UK, V25, P269, DOI 10.1016/S0097-8493(00)00130-8
   Jimenez T, 2012, IEEE T SYST MAN CY A, V42, P1194, DOI 10.1109/TSMCA.2012.2183360
   Ju T, 2002, ACM T GRAPHIC, V21, P339
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kim DJ, 1998, IEEE T VIS COMPUT GR, V4, P230, DOI 10.1109/2945.722297
   Kim D, 2009, COMPUT GRAPH FORUM, V28, P1791, DOI 10.1111/j.1467-8659.2009.01556.x
   Kim M, 2019, MULTIMED TOOLS APPL, V78, P4851, DOI 10.1007/s11042-018-6063-9
   Kim YJ, 2015, COMPUT ANIMAT VIRT W, V26, P423, DOI 10.1002/cav.1661
   Klosowski JT, 1998, IEEE T VIS COMPUT GR, V4, P21, DOI 10.1109/2945.675649
   Kockara S, 2007, IEEE SYS MAN CYBERN, P4046, DOI 10.1109/ICSMC.2007.4414258
   KOPPERMAN R, 1991, DISCRETE COMPUT GEOM, V6, P155, DOI 10.1007/BF02574681
   Korf RE, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P650
   KORF RE, 1993, ARTIF INTELL, V62, P41, DOI 10.1016/0004-3702(93)90045-D
   KORF RE, 1985, ARTIF INTELL, V27, P97, DOI 10.1016/0004-3702(85)90084-0
   Koschier D, 2017, IEEE T VIS COMPUT GR, V23, P2208, DOI 10.1109/TVCG.2017.2730202
   Kroiss, 2013, COLLISION DETECTION, P45
   Larsen E., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3719, DOI 10.1109/ROBOT.2000.845311
   Larsen Eric., 1999, Fast proximity queries with swept sphere volumes
   Larsson T, 2006, COMPUT GRAPH-UK, V30, P450, DOI 10.1016/j.cag.2006.02.011
   Lauterbach C, 2010, COMPUT GRAPH FORUM, V29, P419, DOI 10.1111/j.1467-8659.2009.01611.x
   Lauterbach C, 2009, COMPUT GRAPH FORUM, V28, P375, DOI 10.1111/j.1467-8659.2009.01377.x
   Lee J, 2006, COMPUT ANIMAT VIRT W, V17, P479, DOI 10.1002/cav.150
   Li CQ, 2018, IEEE ACCESS, V6, P75572, DOI 10.1109/ACCESS.2018.2883679
   Li X, 2008, INT J MED ROBOT COMP, V4, P77, DOI 10.1002/rcs.177
   Lin M.C., 1998, Proceedings of IMA Conference on Mathematics of Surfaces, P1
   Liu FC, 2014, IEEE T VIS COMPUT GR, V20, P714, DOI 10.1109/TVCG.2013.268
   Liu F, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866180
   MacDonald J. D., 1990, Visual Computer, V6, P153, DOI 10.1007/BF01911006
   Maciel A, 2008, COMPUT ANIMAT VIRT W, V19, P151, DOI 10.1002/cav.224
   Maciel A, 2007, IEEE T VIS COMPUT GR, V13, P518, DOI 10.1109/TVCG.2007.1016
   Mitchell N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818100
   Moller T., 1997, J. Graph. Tools, V2, P25, DOI [DOI 10.1080/10867651.1997.10487472, 10.1080/10867651.1997.10487472]
   Morvan T, 2012, COMPUT GRAPH FORUM, V31, P62, DOI 10.1111/j.1467-8659.2011.02084.x
   Müller M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766907
   MYSZKOWSKI K, 1995, VISUAL COMPUT, V11, P497, DOI 10.1007/BF02439645
   Pabst S, 2010, COMPUT GRAPH FORUM, V29, P1605, DOI 10.1111/j.1467-8659.2010.01769.x
   PALMER IJ, 1995, COMPUT GRAPH FORUM, V14, P105, DOI 10.1111/1467-8659.1420105
   Pan J, 2012, IEEE INT CONF ROBOT, P3859, DOI 10.1109/ICRA.2012.6225337
   Park J, 2013, COMPUT ANIMAT VIRT W, V24, P317, DOI 10.1002/cav.1510
   Perry RN, 2001, COMP GRAPH, P47, DOI 10.1145/383259.383264
   Popov Stefan., 2009, P C HIGH PERFORMANCE, P15, DOI DOI 10.1145/1572769.1572772
   Provot X, 1997, GRAPHICS INTERFACE, P177, DOI DOI 10.1007/978-3-7091-6874-5_13
   Raghupathi L, 2004, IEEE T VIS COMPUT GR, V10, P708, DOI 10.1109/TVCG.2004.36
   Rosin PL, 2000, IEEE T SYST MAN CY A, V30, P202, DOI 10.1109/3468.833102
   SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930
   Sanchez M., 2012, Proceedings of the 28th Spring Conference on Computer Graphics, P101
   Sanna A, 2004, 8TH WORLD MULTI-CONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL II, PROCEEDINGS, P144
   Serpa YR., 2017, COMPUT GRAPH FORUM, V38, P1
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Shinya M., 1991, J VISUAL COMP ANIMAT, V2, P132
   Sigurgeirson H, 2001, J COMPUT PHYS, V172, P766, DOI 10.1006/jcph.2001.6858
   Smith Russell L., Open dynamics engine
   St?phane G., 2004, RR5136 INRIA
   Stich M., 2009, P C HIGH PERF GRAPH, P7, DOI DOI 10.1145/1572769.1572771
   Sun K, 2014, IEEE J TRANSL ENG HE, V2, DOI 10.1109/JTEHM.2014.2327628
   Tang L, 2018, J INTEGR AGR, V17, P306, DOI 10.1016/S2095-3119(17)61769-6
   Tang M., 2009, 2009 SIAM/ACM Joint Conference on Geometric and Physical Modeling. SPM'09, P355
   Tang M, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203188
   Tang M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275005
   Tang M, 2016, COMPUT GRAPH FORUM, V35, P511, DOI 10.1111/cgf.12851
   Tang M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2517108
   Tang M, 2013, COMPUT GRAPH FORUM, V32, P21, DOI 10.1111/cgf.12208
   Tang M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019630
   Tang M, 2010, GRAPH MODELS, V72, P7, DOI 10.1016/j.gmod.2010.01.001
   Tang M, 2009, IEEE T VIS COMPUT GR, V15, P544, DOI 10.1109/TVCG.2009.12
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47
   Thibault W.C., 1987, SIGGRAPH COMPUT GRAP, P153, DOI [DOI 10.1145/37402.37421, 10.1145/37402.37421, DOI 10.1145/3740137421, 10.1145/37401.37421]
   Tian Y, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1846
   Tracy DJ, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P191, DOI 10.1109/VR.2009.4811022
   Tropp O, 2006, COMPUT ANIMAT VIRT W, V17, P527, DOI 10.1002/cav.115
   van den Bergen G., 1997, Journal of Graphics Tools, V2, P1, DOI 10.1080/10867651.1997.10487480
   Vassilev T, 2001, COMPUT GRAPH FORUM, V20, pC260, DOI 10.1111/1467-8659.00518
   Vassilev TI, 2012, WSCG'2012, CONFERENCE PROCEEDINGS, PTS I & II, P19
   Volino P., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P137, DOI 10.1145/218380.218432
   VOLINO P, 1994, COMPUT GRAPH FORUM, V13, pC155, DOI 10.1111/1467-8659.1330155
   Wald I, 2009, COMPUT GRAPH FORUM, V28, P1691, DOI 10.1111/j.1467-8659.2008.01313.x
   Wang HM, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601114
   Wang MN, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1987
   Wang MN, 2019, CLUSTER COMPUT, V22, pS8769, DOI 10.1007/s10586-018-1967-8
   Wang TT, 2018, COMPUT GRAPH-UK, V73, P70, DOI 10.1016/j.cag.2018.04.001
   Wang TT, 2017, COMPUT GRAPH FORUM, V36, P487, DOI 10.1111/cgf.13095
   Wang XL, 2018, COMPUT GRAPH FORUM, V37, P227, DOI 10.1111/cgf.13356
   Wang ZD, 2015, COMPUT GRAPH FORUM, V34, P289, DOI 10.1111/cgf.12767
   Wei L, 2018, IEEE T HAPTICS, V11, P73, DOI 10.1109/TOH.2017.2749221
   Weller R, 2013, NEW GEOMETRIC DATA S, DOI [10.1007/978-3-319-01020-5, DOI 10.1007/978-3-319-01020-5]
   Weller R, 2017, COMPUT GRAPH FORUM, V36, P131, DOI 10.1111/cgf.13113
   Wodniok D, 2016, GRAPHICS INTERFACE, P101
   Wodniok D, 2017, COMPUT GRAPH-UK, V62, P41, DOI 10.1016/j.cag.2016.12.003
   Wong SK, 2016, VISUAL COMPUT, V32, P67, DOI 10.1007/s00371-014-1056-9
   Wong SK, 2015, VISUAL COMPUT, V31, P377, DOI 10.1007/s00371-014-0933-6
   Wong SK, 2014, COMPUT GRAPH FORUM, V33, P143, DOI 10.1111/cgf.12284
   Wong SK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461951
   Wong TH, 2014, VISUAL COMPUT, V30, P729, DOI 10.1007/s00371-014-0954-1
   Wong TH, 2012, VISUAL COMPUT, V28, P829, DOI 10.1007/s00371-012-0706-z
   Wu JH, 2003, VISION, MODELING, AND VISUALIZATION 2003, P513
   Wu NN, 2018, IEEE ACCESS, V6, P25921, DOI 10.1109/ACCESS.2018.2837013
   Wu YZ, 2014, GRAPH MODELS, V76, P214, DOI 10.1016/j.gmod.2014.04.011
   Xu H., 2014, LOCAL METROPOLITAN A, P1, DOI [DOI 10.1109/LANMAN.2014.7028620, DOI 10.1111/PBI.12277]
   Xu HY, 2017, IEEE T HAPTICS, V10, P151, DOI 10.1109/TOH.2016.2613872
   Ye JT, 2017, COMPUT GRAPH FORUM, V36, P217, DOI 10.1111/cgf.13287
   Ye XF, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0148-3
   Ye XF, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2689, DOI 10.1109/ICInfA.2015.7279740
   Zachmann G, 1998, P IEEE VIRT REAL ANN, P90, DOI 10.1109/VRAIS.1998.658428
   Zhang XY, 2014, IEEE T VIS COMPUT GR, V20, P447, DOI 10.1109/TVCG.2013.239
   Zheng CX, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185594
   Zou YN, 2017, CLUSTER COMPUT, V20, P1765, DOI 10.1007/s10586-017-0815-6
NR 156
TC 5
Z9 6
U1 6
U2 91
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2021
VL 32
IS 5
AR e1987
DI 10.1002/cav.1987
EA FEB 2021
PG 23
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WJ5HR
UT WOS:000613560900001
DA 2024-07-18
ER

PT J
AU Zhao, J
   Yang, WJ
   Yang, ML
   Huang, WR
   Yang, Q
   Zhang, HG
AF Zhao, Jing
   Yang, Wenjing
   Yang, Mingliang
   Huang, Wanrong
   Yang, Qiong
   Zhang, Hongguang
TI One-shot video-based person re-identification with variance subsampling
   algorithm
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer vision; one-shot learning; person re-identification; variance
   confidence; variance subsampling algorithm
AB Previous works propose the distance-based sampling for unlabeled datapoints to address the few-shot person re-identification task, however, many selected samples may be assigned with wrong labels due to poor feature quality in these works, which negatively affects the learning procedure. In this article, we propose a novel sampling strategy to improve the quality of assigned pseudo-labels, thus promoting the final performance. To illustrate, we first propose the concept of variance confidence to measure the credibility of pseudo-labels, then we apply a novel variance subsampling algorithm to improve the accuracy of the selected sample labels. Our method combines distance confidence and variance confidence as a two-round sampling criterion. Meanwhile, a variation decay strategy is used in our sampling process in combination with the actual distribution of features. We evaluate our approach on two publicly available datasets, MARS and DukeMTMC-VideoReID, and achieve state-of-the-art one-shot performance.
C1 [Zhao, Jing; Yang, Wenjing; Yang, Mingliang; Yang, Qiong; Zhang, Hongguang] Natl Univ Def Technol, Coll Comp, Inst Quantum Informat, Changsha 410073, Hunan, Peoples R China.
   [Zhao, Jing; Yang, Wenjing; Yang, Mingliang; Yang, Qiong; Zhang, Hongguang] Natl Univ Def Technol, Coll Comp, State Key Lab High Performance Comp, Changsha 410073, Hunan, Peoples R China.
   [Huang, Wanrong] Natl Innovat Inst Def Technol, Artificial Intelligence Res Ctr, Beijing, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China
RP Yang, WJ (corresponding author), Natl Univ Def Technol, Coll Comp, Inst Quantum Informat, Changsha 410073, Hunan, Peoples R China.; Yang, WJ (corresponding author), Natl Univ Def Technol, Coll Comp, State Key Lab High Performance Comp, Changsha 410073, Hunan, Peoples R China.
EM wenjing.yang@nudt.edu.cn
OI Zhao, Jing/0000-0002-0049-1802; Huang, Wanrong/0000-0001-5778-9055;
   Yang, Mingliang/0000-0002-1390-9673
FU National Key Researchand Development Program of China [2017YFB1300203]
FX National Key Researchand Development Program of China, Grant/Award
   Number: 2017YFB1300203
CR Alfassy A, 2019, PROC CVPR IEEE, P6541, DOI 10.1109/CVPR.2019.00671
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee YG, 2017, IEEE T CIRC SYST VID, V27, P470, DOI 10.1109/TCSVT.2016.2637818
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Tian H, 2019, NEUROCOMPUTING, V359, P93, DOI 10.1016/j.neucom.2019.05.037
   Wei Z, 2019, IEEE ACCESS, V7, P132438
   Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Ye M, 2017, IEEE I CONF COMP VIS, P5152, DOI 10.1109/ICCV.2017.550
   Zhang HG, 2019, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2019.00288
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
NR 21
TC 3
Z9 3
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1964
DI 10.1002/cav.1964
EA SEP 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000567473800001
DA 2024-07-18
ER

PT J
AU Feng, Q
   Shum, HPH
   Morishima, S
AF Feng, Qi
   Shum, Hubert P. H.
   Morishima, Shigeo
TI Resolving hand-object occlusion for mixed reality with joint deep
   learning and model optimization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deep learning; hand tracking; mixed reality; occlusion; optimization
ID TRACKING
AB By overlaying virtual imagery onto the real world, mixed reality facilitates diverse applications and has drawn increasing attention. Enhancing physical in-hand objects with a virtual appearance is a key component for many applications that require users to interact with tools such as surgery simulations. However, due to complex hand articulations and severe hand-object occlusions, resolving occlusions in hand-object interactions is a challenging topic. Traditional tracking-based approaches are limited by strong ambiguities from occlusions and changing shapes, while reconstruction-based methods show a poor capability of handling dynamic scenes. In this article, we propose a novel real-time optimization system to resolve hand-object occlusions by spatially reconstructing the scene with estimated hand joints and masks. To acquire accurate results, we propose a joint learning process that shares information between two models and jointly estimates hand poses and semantic segmentation. To facilitate the joint learning system and improve its accuracy under occlusions, we propose an occlusion-aware RGB-D hand data set that mitigates the ambiguity through precise annotations and photorealistic appearance. Evaluations show more consistent overlays compared with literature, and a user study verifies a more realistic experience.
C1 [Feng, Qi] Waseda Univ, Tokyo, Japan.
   [Shum, Hubert P. H.] Northumbria Univ, Newcastle Upon Tyne, Tyne & Wear, England.
   [Morishima, Shigeo] Waseda Res Inst Sci & Engn, Tokyo, Japan.
C3 Waseda University; Northumbria University; Waseda University
RP Shum, HPH (corresponding author), Northumbria Univ, Newcastle Upon Tyne, Tyne & Wear, England.
EM hubert.shum@northumbria.ac.uk
RI Shum, Hubert P. H./E-8060-2015; FENG, Qi/ABC-6684-2020
OI Shum, Hubert P. H./0000-0001-5651-6039; FENG, Qi/0000-0002-6892-3122;
   Morishima, Shigeo/0000-0001-8859-6539
FU JSC ACCEL [JPMJAC1602]; JSPS KAKENHI [JP17H06101, JP19H01129]; JST-Mirai
   Program [JP-MJMI19B2]; Royal Society [IES\R2\181024]
FX JSC ACCEL, Grant/Award Number: JPMJAC1602; JSPS KAKENHI, Grant/Award
   Numbers: JP17H06101, JP19H01129; JST-Mirai Program, Grant/Award Number:
   JP-MJMI19B2; Royal Society, Grant/Award Number: IES\R2\181024
CR [Anonymous], 2016, ACM T GRAPHICS TOG
   Azuma RT, 2017, IMAGING APPL OPTICS
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong ZR, 2010, PROCEEDINGS OF THE 4TH INTERNATIONAL YELLOW RIVER FORUM ON ECOLOGICAL CIVILIZATION AND RIVER ETHICS, VOL I, P55
   Du C, 2016, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR.2016.17
   Gupta A, 2019, IEEE SYST J, V13, P3501, DOI 10.1109/JSYST.2019.2896061
   Kopf J., 2019, ACM T GRAPH, V37, P1
   Kyriazis N, 2016, ADV INTELL SYST, V391, P19, DOI 10.1007/978-3-319-23437-3_2
   Lepetit V, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P137, DOI 10.1109/ISAR.2000.880937
   Liang H, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P743, DOI 10.1145/2733373.2807972
   Lu YZ, 2009, J COMPUT INF SCI ENG, V9, DOI 10.1115/1.3130144
   Mueller F, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322958
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Mueller Franziska, 2017, P IEEE INT C COMP VI
   Patney A., 2016, ACM SIGGRAPH 2016 emerging technologies, P1, DOI [10.1145/2929464.2929472, DOI 10.1145/2929464.2929472]
   Qian C, 2014, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2014.145
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Simon T, 2017, ENCYCLOPEDIA OF SOIL SCIENCE, VOLS I-III, 3RD EDITION, P1144, DOI 10.1081/E-ESS3-120045569
   Tagliasacchi A, 2015, COMPUT GRAPH FORUM, V34, P101, DOI 10.1111/cgf.12700
   Tekin B, 2019, PROC CVPR IEEE, P4506, DOI 10.1109/CVPR.2019.00464
   Tian Y, 2015, NEUROCOMPUTING, V156, P96, DOI 10.1016/j.neucom.2014.12.081
   Tian Y, 2010, SENSORS-BASEL, V10, P2885, DOI 10.3390/s100402885
   Walton DR, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139153
   Zhang Jiawei, 2016, ARXIV161007214
NR 24
TC 4
Z9 4
U1 3
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1956
DI 10.1002/cav.1956
EA SEP 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000564475200001
DA 2024-07-18
ER

PT J
AU Je, S
   Abileva, Y
   Bianchi, A
   Bazin, JC
AF Je, Seungwoo
   Abileva, Yekaterina
   Bianchi, Andrea
   Bazin, Jean-Charles
TI A computational approach for spider web-inspired fabrication of string
   art
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE fabrication; image halftoning; string art
AB Creating objects with threads is commonly referred to as string art. It is typically a manual, tedious work reserved for skilled artists. In this paper, we investigate how to automatically fabricate string art pieces from one single continuous thread in such a way that it looks like an input image. The proposed system consists of a thread connection optimization algorithm and a custom-made fabrication machine. It allows casual users to create their own personalized string art pieces in a fully automatic manner. Quantitative and qualitative evaluations demonstrated our system can create visually appealing results.
C1 [Je, Seungwoo; Bianchi, Andrea] Korea Adv Inst Sci & Technol, Dept Ind Design, Daejeon, South Korea.
   [Abileva, Yekaterina] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
   [Bazin, Jean-Charles] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon 34141, South Korea.
   [Bazin, Jean-Charles] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST); Korea Advanced Institute of
   Science & Technology (KAIST); Korea Advanced Institute of Science &
   Technology (KAIST)
RP Bazin, JC (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon 34141, South Korea.; Bazin, JC (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
EM bazinjc@kaist.ac.kr
RI Bazin, Jean-Charles/M-5124-2017; Bianchi, Andrea/K-8977-2015
OI Je, Seungwoo/0000-0002-3968-7298
FU KAIST Interdisciplinary Research on the 4th Industrial Revolution;
   National Research Foundation of Korea (NRF) - Korean government
   (Ministry of Science and ICT) [2018R1A5A7025409]; Adobe
FX KAIST Interdisciplinary Research on the 4th Industrial Revolution;
   Adobe; National Research Foundation of Korea (NRF) funded by the Korean
   government (Ministry of Science and ICT), Grant/Award Number:
   2018R1A5A7025409
CR Birsak M, 2018, COMPUT GRAPH FORUM, V37, P263, DOI 10.1111/cgf.13359
   Chang JH, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618508
   Chen WK, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130817
   Chu HK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508408
   Chu HK, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778788
   Deussen O, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130819
   Gal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531339
   Galea B, 2017, P 2017 IEEE RSJ INT
   Huang H, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024189
   Kopf J, 2006, ACM T GRAPHIC, V25, P509, DOI 10.1145/1141911.1141916
   Kopf J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964994
   Lubin Y.D., 1982, Bulletin of the British Arachnological Society, V5, P399
   Maharik R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964995
   Martin Tobias, 2015, ACM T GRAPHIC, V34, P4
   McCann J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925940
   Pang WM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360688
   Pappas TN, 1999, IEEE T IMAGE PROCESS, V8, P1102, DOI 10.1109/83.777090
   Prévost R, 2016, COMPUT GRAPH-UK, V55, P108, DOI 10.1016/j.cag.2015.11.001
   Schüller C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925914
   Shen JH, 2009, SIAM REV, V51, P567, DOI 10.1137/060653317
   Shilkrot R, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2699649
   Skouras M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601166
   Skouras M, 2012, COMPUT GRAPH FORUM, V31, P835, DOI 10.1111/j.1467-8659.2012.03064.x
   Wu X, 1991, P 18 ANN C COMP GRAP
   Zhao HS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2907049
NR 25
TC 1
Z9 1
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1904
DI 10.1002/cav.1904
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400025
DA 2024-07-18
ER

PT J
AU Wu, NN
   Deng, ZG
   Huang, Y
   Liu, C
   Zhang, DL
   Jin, XG
AF Wu, Nannan
   Deng, Zhigang
   Huang, Yue
   Liu, Chen
   Zhang, Dongliang
   Jin, Xiaogang
TI A fast garment fitting algorithm using skeleton-based error metric
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE cloth simulation; garment fitting; pose recovery; skeleton-based error
   metric
AB We present a fast and automatic method to fit a given 3D garment onto a human model with various shapes and poses, without using a reference human model. Our approach uses a novel skeleton-based error metric to find the pose that best fits the input garment. Specifically, we first generate the skeleton of the given human model and its corresponding skinning weights. Then, we iteratively rotate each bone to find its best position to fit the garment. After that, we rig the surface of the human model according to the transformations of the skeleton. Potential penetrations are resolved using collision handling and physically based simulation. Finally, we restore the human model back to the original pose in order to obtain the desired fitting result. Our experiment results show that besides its efficiency and automation, our method is about two orders of magnitudes faster than existing approaches, and it can handle various garments, including jacket, trousers, skirt, a suit of clothing, and even multilayered clothing.
C1 [Wu, Nannan; Huang, Yue; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Deng, Zhigang] East China Jiaotong Univ, Virtual Real & Interact Tech Inst, Nanchang, Jiangxi, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
   [Liu, Chen] LINCTEX, Shanghai 200331, Peoples R China.
   [Zhang, Dongliang] Zhejiang Univ, Int Design Inst, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Zhejiang University; East China Jiaotong University; University of
   Houston System; University of Houston; Zhejiang University
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.; Deng, ZG (corresponding author), East China Jiaotong Univ, Virtual Real & Interact Tech Inst, Nanchang, Jiangxi, Peoples R China.; Deng, ZG (corresponding author), Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
EM zhigang.deng@gmail.com; jin@cad.zju.edu.cn
OI Deng, Zhigang/0000-0002-0452-8676; Deng, Zhigang/0000-0003-2571-5865;
   Jin, Xiaogang/0000-0001-7339-2920
FU National Natural Science Foundation of China [61732015, 61472355];
   National Key RAMP;D Program of China [2017YFB1002600]; Key Research and
   Development Program of Zhejiang Province [2018C01090]
FX National Natural Science Foundation of China, Grant/Award Number:
   61732015; National Key R&D Program of China, Grant/Award Number:
   2017YFB1002600; Key Research and Development Program of Zhejiang
   Province, Grant/Award Number: 2018C01090; National Natural Science
   Foundation of China, Grant/Award Number: 61472355
CR Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Durupinar F, 2007, IEEE INT CONF INF VI, P862, DOI 10.1109/IV.2007.17
   Guan P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185531
   Gültepe U, 2014, COMPUT GRAPH-UK, V43, P31, DOI 10.1016/j.cag.2014.06.001
   Huang LC, 2016, VISUAL COMPUT, V32, P705, DOI 10.1007/s00371-016-1236-x
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Lee Y, 2013, COMPUT GRAPH-UK, V37, P911, DOI 10.1016/j.cag.2013.07.005
   Li JT, 2013, TEXT RES J, V83, P519, DOI 10.1177/0040517512450758
   Li JT, 2011, COMPUT IND, V62, P693, DOI 10.1016/j.compind.2011.04.002
   Li JT, 2010, COMPUT GRAPH-UK, V34, P742, DOI 10.1016/j.cag.2010.07.008
   Li Z, 2009, INT C COMP AID DES C, P74, DOI 10.1109/CADCG.2009.5246928
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Tisserand Y, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1770
   Zhang DL, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P328, DOI 10.1109/PCCGA.2000.883956
   Zhong YQ., 2008, J FIBER BIOENGINEERI, V1, P21, DOI [10.3993/jfbi06200804, DOI 10.3993/JFBI06200804]
   Zhong YQ, 2010, TEXT RES J, V80, P904, DOI 10.1177/0040517509349790
   Zhong YQ, 2009, TEXT RES J, V79, P792, DOI 10.1177/0040517508090779
NR 18
TC 6
Z9 8
U1 1
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1811
DI 10.1002/cav.1811
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100002
DA 2024-07-18
ER

PT J
AU Guo, RK
   Samaraweera, G
   Quarles, J
AF Guo, Rongkai
   Samaraweera, Gayani
   Quarles, John
TI Mobility impaired users respond differently than healthy users in
   virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE presence; avatars; physiological measures; gait analysis; virtual
   environments; user studies
ID REALITY SYSTEM; LATENCY; PEOPLE; AVATAR
AB Virtual environments (VEs) have been shown to be beneficial in physical rehabilitation, increasing motivation and the range of exercises that can be safely performed. However, little is known about how disabilities may impact a user's responses to a VE, which could affect rehabilitation motivation. Thus, the primary objective of this research is to understand how VEs affect users with mobility impairments (MI). Specifically, we investigate the influence of full body avatars that have canes. To begin investigating this, we designed a VE that included a range of multimodal feedback to induce a strong sense of presence and was novel to the participants. Using this VE, we conducted a study with two different populations: eight persons with MI and eight healthy persons as a control. The healthy participants were of similar demographics (e.g., age, weight, height, and previous VE experience) to the participants with MI who walked with a cane (i.e., on the basis of strict selection criteria to maintain homogeneity). This is one of the first studies to investigate how a VE can affect the gait of the users with MI, physiological response, presence, behavior, and the influence of avatars. Results of the study suggest generalizable guidelines for the design of VEs for users with MI. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Guo, Rongkai; Samaraweera, Gayani; Quarles, John] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
C3 University of Texas System; University of Texas at San Antonio (UTSA)
RP Guo, RK (corresponding author), Univ Texas San Antonio, Dept Comp Sci, One UTSA Circle, San Antonio, TX 78249 USA.
EM rguo70@gmail.com
FU National Science Foundation [IIS-1153229, IIS-1218283]
FX The authors wish to thank the study participants and Dr. Suzanne Gazda
   from the Neurology Institute of San Antonio. This work was supported by
   grants from the National Science Foundation (IIS-1153229 and
   IIS-1218283).
CR Ababsa FE, 2004, IEEE INT CONF ROBOT, P1021, DOI 10.1109/ROBOT.2004.1307284
   Allison RS, 2001, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2001.913793
   Alm N, 1998, IEEE SYS MAN CYBERN, P1174, DOI 10.1109/ICSMC.1998.727865
   Barab S, 2004, J LEARN SCI, V13, P1, DOI 10.1207/s15327809jls1301_1
   Betker AL, 2007, PHYS THER, V87, P1389, DOI 10.2522/ptj.20060229
   Blanke O, 2012, NAT REV NEUROSCI, V13, P556, DOI 10.1038/nrn3292
   Crosbie J., 2008, Proc. 7th ICDVRAT with ArtAbilitation, P229
   Delaney D, 2006, 8 INT WORKSH 1 TEL V, V15
   Fung J, 2006, CYBERPSYCHOL BEHAV, V9, P157, DOI 10.1089/cpb.2006.9.157
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Jay C, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1275511.1275514
   Khasnis A, 2003, J Postgrad Med, V49, P169
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kizony R, 2003, J VISUAL COMP ANIMAT, V14, P261, DOI 10.1002/vis.323
   Lee C, 2010, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2010.5444820
   Lok B, 2003, P IEEE VIRT REAL ANN, P125, DOI 10.1109/VR.2003.1191130
   Maki-Patola T, 2005, NIME 05 P 2005 SING
   Mania K, 2004, APGV 04 P 1 S APPL P
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Meehan Michael, 2003, VIRT REAL 2003 P IEE
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Perez-Marcos D, 2012, COGN NEURODYNAMICS, V6, P295, DOI 10.1007/s11571-011-9178-5
   Rongkai Guo, 2012, 2012 IEEE VR Workshop on Perceptual Illusions in Virtual Environments, P1, DOI 10.1109/PIVE.2012.6229792
   Russell I, 2001, ACM S VIRT REAL SOFT
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Slater M., 1993, VR93 Virtual Reality International 93. Proceedings of the Third Annual Conference on Virtual Reality, P34
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   So RHY, 2006, ENG MED BIOL SOC 200, P5006
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Wilson PN, 1998, IEE C 2 DEC, p6/1
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Youngblut C., 2007, WHAT DECADE EXPT REV
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
NR 36
TC 6
Z9 7
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2015
VL 26
IS 5
BP 509
EP 526
DI 10.1002/cav.1610
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS5NU
UT WOS:000362125800003
DA 2024-07-18
ER

PT J
AU Baek, S
   Um, K
   Han, J
AF Baek, Seungho
   Um, Kiwon
   Han, JungHyun
TI Muddy water animation with different details
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE muddy water; fluid simulation; SPH
ID FLUIDS; SPH
AB Muddy water is an example of suspension, which is a mixture containing particles that separate into distinct layers if left undisturbed. When stirred, however, the mud substance flows like a liquid and again begins settling out. Mud is composed of various sized particles, and they produce different effects when it is blended with water. This paper classifies the mud particles into three types and proposes different simulation methods for the types. The experimental results demonstrate that the proposed methods effectively produce visually plausible muddy water effects. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Baek, Seungho; Um, Kiwon] Korea Univ, Seoul 136701, South Korea.
   [Han, JungHyun] Korea Univ, Dept Comp Sci & Engn, Seoul 136701, South Korea.
   [Han, JungHyun] Korea Univ, Interact Media Lab 3D, Seoul 136701, South Korea.
   [Han, JungHyun] Korea Univ, Game Res Ctr, Seoul 136701, South Korea.
C3 Korea University; Korea University; Korea University; Korea University
RP Han, J (corresponding author), Korea Univ, 311 WooJung Informat & Commun Bldg,145 Anam Ro, Seoul 136701, South Korea.
EM jhan@korea.ac.kr
RI Um, Kiwon/AAO-6776-2020
OI /0000-0002-4139-9308
FU Ministry of Culture, Sports and Tourism (MCST) Korea Creative Content
   Agency (KOCCA) in the Culture Technology(CT) Research and Development
   Program
FX This research is supported by the Ministry of Culture, Sports and
   Tourism (MCST) and the Korea Creative Content Agency (KOCCA) in the
   Culture Technology(CT) Research and Development Program 2014.
CR Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Alduan I., 2011, P 2011 ACM SIGGRAPH, P25, DOI DOI 10.1145/2019406.2019410
   Ando R, 2012, IEEE T VIS COMPUT GR, V18, P1202, DOI 10.1109/TVCG.2012.87
   [Anonymous], 2009, PROC CONGRESO ESPANO
   Bao K, 2010, COMPUT ANIMAT VIRT W, V21, P401, DOI 10.1002/cav.356
   Bell N., 2005, P 2005 ACM SIGGRAPH, P77, DOI DOI 10.1145/1073368.1073379
   Boyd L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159522
   Bradys JE, 2007, CHEM MATTER ITS CHAN
   Bridsons R, 2008, FLUID SIMULATION COM
   Cornelis J, 2014, COMPUT GRAPH FORUM, V33, P255, DOI 10.1111/cgf.12324
   Degueldre C, 2009, COLLOID SURFACE A, V337, P117, DOI 10.1016/j.colsurfa.2008.12.007
   Hiemenzs P. C., 1997, PRINCIPLES COLLOID S
   Hong JM, 2005, ACM T GRAPHIC, V24, P915, DOI 10.1145/1073204.1073283
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Ihmsen M, 2013, COMPUT GRAPH-UK, V37, P800, DOI 10.1016/j.cag.2013.04.010
   Ihmsen M, 2012, VISUAL COMPUT, V28, P669, DOI 10.1007/s00371-012-0697-9
   Ihmsen M, 2011, COMPUT GRAPH FORUM, V30, P99, DOI [10.1111/j.1467-8659.2010.01832.x, 10.1111/j.1467-8659.2010.01834.x]
   Ihmsens M, 2014, EUROGRAPHICS 2014 ST
   Kang N, 2010, COMPUT GRAPH FORUM, V29, P685, DOI 10.1111/j.1467-8659.2009.01638.x
   Kims B, 2010, ACM T GRAPHIC, V29
   Lenaerts T, 2009, COMPUT GRAPH FORUM, V28, P213, DOI 10.1111/j.1467-8659.2009.01360.x
   Liu SG, 2011, VISUAL COMPUT, V27, P241, DOI 10.1007/s00371-010-0531-1
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Mao H, 2006, PROC GRAPH INTERF, P49
   Misztal MK, 2014, IEEE T VIS COMPUT GR, V20, P4, DOI 10.1109/TVCG.2013.97
   Myungjoo Kang, 2000, Journal of Scientific Computing, V15, P323, DOI 10.1023/A:1011178417620
   Narain R, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866195
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Oshers SJ, 2002, LEVEL SET METHODS DY
   Park J, 2008, COMPUT ANIMAT VIRT W, V19, P455, DOI 10.1002/cav.256
   Rens B, 2014, ACM T GRAPHIC, V33
   Rungjiratananon W, 2008, COMPUT GRAPH FORUM, V27, P1887, DOI 10.1111/j.1467-8659.2008.01336.x
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Solenthaler B., 2008, P 2008 ACM SIGGRAPH, P211, DOI 10.2312/SCA/SCA08/211-218
   Zhu HB, 2006, COMPUT ANIMAT VIRT W, V17, P403, DOI 10.1002/cav.143
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 38
TC 3
Z9 3
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 347
EP 355
DI 10.1002/cav.1646
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700016
DA 2024-07-18
ER

PT J
AU Huang, C
   Zhu, J
   Sun, HQ
   Wu, EH
AF Huang, Chen
   Zhu, Jian
   Sun, Hanqiu
   Wu, Enhua
TI Parallel-optimizing SPH fluid simulation for realistic VR environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE active; inactive particle; neighbor search; SPH fluids; parallel HPMC;
   GPU; virtual environments
AB In virtual environments, real-time simulation and rendering of dynamic fluids have always been the pursuit for virtual reality research. In this paper, we present a real-time framework for realistic fluid simulation and rendering on graphics processing unit. Because of the high demand for interactive fluids with larger particle set, the computational need is becoming higher. The proposed framework can effectively reduce the computational burden through avoiding the computation in inactive areas, where many particles with similar properties and low local pressure cluster together. While in active areas, the computation is fully carried out; thus, the fluid dynamics are largely preserved. Here, a robust particle classification technique is introduced to classify particles into either active or inactive. The test results have shown that the technique improves the time performance of fluid simulation largely. We then incorporate parallel surface reconstruction technique using marching cubes to extract the surfaces of the fluid. The introduced histogram pyramid-based marching cubes technique is fast and memory efficiency. As a result, we are able to produce plausible and interactive fluids with the proposed framework for large-scale virtual environments. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Huang, Chen; Sun, Hanqiu] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
   [Zhu, Jian; Wu, Enhua] Univ Macau, Fac Sci & Technol, Comp Graph & Multimedia Lab, Macau, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
C3 Chinese University of Hong Kong; University of Macau; Chinese Academy of
   Sciences; Institute of Software, CAS
RP Huang, C (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
EM hcmorning@hotmail.com; hanqiu@cse.cuhk.edu.hk
FU RGC research grant [416212]; UGC direct grant for research [2050485];
   National Natural Science Foundation of China [61272326]; University of
   Macau
FX The work was supported by RGC research grant (ref. 416212), UGC direct
   grant for research (no. 2050485), National Natural Science Foundation of
   China (Grant No. 61272326), and research grant of University of Macau.
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Akinci G, 2012, COMPUT GRAPH FORUM, V31, P1797, DOI 10.1111/j.1467-8659.2012.02096.x
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Amada T, 2004, ACM WORKSH GEN PURP
   [Anonymous], P ACM SIGGRAPH EUR S
   Ataie-Ashtiani B, 2006, FLUID DYN RES, V38, P241, DOI 10.1016/j.fluiddyn.2005.12.002
   Bayraktar Serkan, 2009, Journal of Graphics Tools, V14, P31
   Chentanez N., 2011, ACM T GRAPHIC, V30
   Dyken C, 2008, COMPUT GRAPH FORUM, V27, P2028, DOI 10.1111/j.1467-8659.2008.01182.x
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P178, DOI 10.1109/CGI.1997.601299
   Fraedrich R, 2010, IEEE T VIS COMPUT GR, V16, P1533, DOI 10.1109/TVCG.2010.148
   Goswami P., 2010, P 2010 ACM SIGGRAPHE, P55
   Harada T., 2007, P COMP GRAPH INT
   Ihmsen M., 2012, WORKSHOP VIRTUAL REA, P53
   Ihmsen M, 2012, VISUAL COMPUT, V28, P669, DOI 10.1007/s00371-012-0697-9
   Irving G, 2006, ACM T GRAPHIC, V25, P805, DOI 10.1145/1141911.1141959
   Kipfer P., 2004, HWWS 04, P115, DOI [10.1145/1058129.1058146, DOI 10.1145/1058129.1058146]
   Kipfer P, 2006, PROC GRAPH INTERF, P41
   Kolb Andreas., 2005, Proceedings of the 18th Symposium on Simulation Technique, P722
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   MONAGHAN JJ, 1994, J COMPUT PHYS, V110, P399, DOI 10.1006/jcph.1994.1034
   Müller M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P9
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Narain R, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866195
   Owens John D., 2005, Computer Graphics Forum, P21
   Rustico E, 2012, P 20 EUR C PAR DISTR
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Solenthaler B, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964976
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Van der Laan W.J., 2009, P 2009 S INT 3D GRAP, P91, DOI [DOI 10.1145/1507149.1507164, 10.1145/1507149.1507164]
   Van Kooten K, 2008, GPU GEMS, P123
   Wu EH, 2004, COMPUT ANIMAT VIRT W, V15, P139, DOI 10.1002/cav.16
   Zhang Yanci., 2008, Proceedings of the Fifth Euro- graphics / IEEE VGTC Conference on Point-Based Graphics, SPBG'08, P137
NR 36
TC 4
Z9 5
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2015
VL 26
IS 1
BP 43
EP 54
DI 10.1002/cav.1564
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CC1LW
UT WOS:000350103200005
DA 2024-07-18
ER

PT J
AU Chu, ML
   Parigi, P
   Law, K
   Latombe, JC
AF Chu, Mei Ling
   Parigi, Paolo
   Law, Kincho
   Latombe, Jean-Claude
TI Modeling social behaviors in an evacuation simulator
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; egress simulation; social agents; social behavior;
   simulated perception
AB Building occupants perceive information about the surrounding environment and navigate for safety during emergency evacuation (egress). They often choose their actions by interacting with their social groups and observing the actions of the surrounding crowd. Most egress simulators, however, ignore individuals' crowd perceptions and social interactions. This paper presents a novel platform, SAFEgress (Social Agent For Egress), in which building occupants are modeled as agents who decide their evacuation actions on the basis of their knowledge of the building and their interactions with the social groups and the neighboring crowd. Results from the SAFEgress prototype show that both agents' familiarity with the building and social influence can significantly impact egress performance. By simulating different occupants' behaviors, architects and facility managers may better understand the influence of human and social factors on evacuation and consequently design safer buildings and egress procedures. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Chu, Mei Ling] Stanford Univ, Stanford, CA 94305 USA.
   [Parigi, Paolo] Stanford Univ, Dept Sociol, Stanford, CA 94305 USA.
   [Law, Kincho] Stanford Univ, Dept Civil & Environm Engn, Stanford, CA 94305 USA.
   [Latombe, Jean-Claude] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
C3 Stanford University; Stanford University; Stanford University; Stanford
   University
RP Chu, ML (corresponding author), Stanford Univ, Rm 279,Y2E2 473 Via Ortega, Stanford, CA 94305 USA.
EM mlchu@stanford.edu
FU Center for Integrated Facility Engineering at Stanford University;
   Croucher Foundation Scholarship; Leavell Fellowship
FX This research is partially supported by the Center for Integrated
   Facility Engineering at Stanford University. The first author is also
   supported by the Croucher Foundation Scholarship and the Leavell
   Fellowship.
CR Aguirre BE, 2011, CONTEMP SOC SCI, V6, P415, DOI 10.1080/21582041.2011.609380
   Challenger A, 2009, UNDERSTANDING CROWD
   Chu M. L., 2012, P 5 INT S HUM BEH FI, P569
   CHU ML, 2013, J COMPUT CIVIL ENG, V27, P699, DOI DOI 10.1061/(ASCE)CP.1943-5487.0000313
   Donald I., 1990, Fires and Human Behavior, V2nd, P15
   Drury J, 2009, BRIT J SOC PSYCHOL, V48, P487, DOI 10.1348/014466608X357893
   González-Baños HH, 2002, INT J ROBOT RES, V21, P829, DOI 10.1177/0278364902021010834
   Kuligowski ED, 2011, THESIS U COLORADO
   Marsella S., 2011, P 10 INT C AUT AG MU, P457
   Mawson AR, 2005, PSYCHIATRY, V68, P95, DOI 10.1521/psyc.2005.68.2.95
   McPhail Clark., 1991, The Myth of the Madding Crowd
   Moussaïd M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Rydgren J, 2009, OXFORD HDB ANAL SOCI, P72
   Turner A, 2002, ENVIRON PLANN B, V29, P473, DOI 10.1068/b12850
   Veeraswamy A, 2009, P 4 INT S HUM BEH FI, P501
NR 16
TC 33
Z9 38
U1 1
U2 28
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 375
EP 384
DI 10.1002/cav.1595
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300018
DA 2024-07-18
ER

PT J
AU Wang, H
   Mao, TL
   Kang, XC
   Wang, ZQ
AF Wang, Hua
   Mao, Tianlu
   Kang, Xingchen
   Wang, Zhaoqi
TI An all-in-one efficient lane-changing model for virtual traffic
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE lane-changing conditions; the Frenet frame; lane-changing trajectory;
   lane-changing decision
ID SIMULATION
AB Modeling lane changes realistically play an important role in traffic animations. Existing models for traffic simulations mostly focus on lane-changing decision-making. They cannot describe how lane-changing processes go on. Though some methods in motion planning can be further used to describe the processes, they are time-consuming. In this paper, we present an all-in-one model for lane-changing animations. We transform all conditions for lane-changing decision-making into constraints on lane-changing trajectories. We use two polynomials designed in moving reference frames to describe the trajectories. The whole lane-changing process, whether it can occur and how it goes on, is determined by whether there is a valid trajectory. It only takes O(1) time for the determination. Experiment results show that our model can describe lane-changing processes realistically and efficiently. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Wang, Hua; Kang, Xingchen] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wang, Hua; Mao, Tianlu; Kang, Xingchen; Wang, Zhaoqi] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100864, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Wang, H (corresponding author), 6 Kexueyuan South Rd Zhongguancun, Beijing, Peoples R China.
EM wanghua@ict.ac.cn
RI li, chunyuan/IQW-1618-2023
FU National Natural Science Foundation of China [61173053, 61100086,
   61272322]; National Key Technology RD Program [2013467058, 2012BAH39B01,
   2013AA013902]
FX This work is supported and funded by the National Natural Science
   Foundation of China (Grant No. 61173053, 61100086, 61272322) and the
   National Key Technology R&D Program (Grant No. 2013467058, 2012BAH39B01,
   2013AA013902). We would like to thank the reviewers for their
   constructive comments and suggestions.
CR Ammoun S, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P1278
   Hidas P, 2005, TRANSPORT RES C-EMER, V13, P37, DOI 10.1016/j.trc.2004.12.003
   Hidas P, 2002, TRANSPORT RES C-EMER, V10, P351, DOI 10.1016/S0968-090X(02)00026-8
   Kesting A, 2007, TRANSPORT RES REC, P86, DOI 10.3141/1999-10
   Kind MT, 2009, TRAFFIC AND GRANULAR FLOW '07, P211
   Lee SE, 2004, TECHNICAL REPORTS NA
   Lu X, 2013, 26 C COMP AN SOC AG, P1
   NAGEL K, 1992, J PHYS I, V2, P2221, DOI 10.1051/jp1:1992277
   Papadopoulos E, 2002, INT J ROBOT RES, V21, P367, DOI 10.1177/027836402320556377
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   Sewall J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024169
   Sewall J, 2011, IEEE T VIS COMPUT GR, V17, P26, DOI 10.1109/TVCG.2010.27
   Shen JJ, 2012, GRAPH MODELS, V74, P265, DOI 10.1016/j.gmod.2012.04.002
   Thiemann C, 2008, TRANSPORT RES REC, P90, DOI 10.3141/2088-10
   Toledo T, 2003, TRANSPORT RES REC, P30
   Treiber M, 2000, PHYS REV E, V62, P1805, DOI 10.1103/PhysRevE.62.1805
   Treiber M, 2010, IEEE INTEL TRANSP SY, V2, P6, DOI 10.1109/MITS.2010.939208
   Wang HL, 2005, P IEEE VIRT REAL ANN, P155
   Wang R., 2008, COMPUTATIONAL GEOMET
   Werling M, 2010, IEEE INT CONF ROBOT, P987, DOI 10.1109/ROBOT.2010.5509799
   Xu WD, 2011, IEEE INT CONF ROBOT, P2267, DOI 10.1109/ICRA.2011.5980101
   Yang Q, 1996, TRANSPORT RES C-EMER, V4, P113, DOI 10.1016/S0968-090X(96)00006-X
   Zhang HM, 2002, TRANSPORT RES B-METH, V36, P275, DOI 10.1016/S0191-2615(00)00050-3
NR 23
TC 7
Z9 10
U1 1
U2 25
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 385
EP 393
DI 10.1002/cav.1576
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300019
DA 2024-07-18
ER

PT J
AU Jin, C
   Fevens, T
   Mudur, S
AF Jin, Chao
   Fevens, Thomas
   Mudur, Sudhir
TI Optimized keyframe extraction for 3D character?animations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE keyframes; animation saliency; character animation; computer animation;
   LLE
ID MOTION; ANIMATION; COMPRESSION
AB In this paper, we propose a new method to automatically extract keyframes from animation sequences. Our method can be applied equally to both skeletal and mesh animations. It uses animation saliency computed on the original data to help select the group of keyframes that can reconstruct the input animation with less perception error. For computational efficiency, we perform nonlinear dimension reduction using locally linear embedding and then carry out the optimal search in much lower-dimensional space. With this approach, reconstruction of the animation from the extracted keyframes shows much better results as compared with earlier approaches. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Jin, Chao; Fevens, Thomas; Mudur, Sudhir] Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Jin, C (corresponding author), Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ, Canada.
EM chao_jin@cse.concordia.ca
RI Fevens, Thomas/T-1687-2019
FU NSERC
FX This research was supported in part by NSERC Discovery Grants awarded to
   S. Mudur and T. Fevens.
CR [Anonymous], 1993, Advances in neural information processing systems
   Arikan O, 2006, ACM T GRAPHIC, V25, P890, DOI 10.1145/1141911.1141971
   Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953
   Bregler C., 1995, Advances in Neural Information Processing Systems 7, P973
   Bulbul A., 2010, P 7 S APPL PERC GRAP, P81, DOI DOI 10.1145/1836248.1836263
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Girgensohn A, 2000, MULTIMED TOOLS APPL, V11, P347, DOI 10.1023/A:1009630817712
   Halit C, 2011, COMPUT ANIMAT VIRT W, V22, P3, DOI 10.1002/cav.380
   Hinsinger D., 2002, P 2002 ACM SIGGRAPH, P161
   Hormann K., 2007, Mesh parameterization: Theory and practice
   Huang KS, 2005, VISUAL COMPUT, V21, P532, DOI 10.1007/s00371-005-0316-0
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jin C, 2007, VISUAL COMPUT, V23, P753, DOI [10.1007/s00371-007-0141-8, 10.1007/S00371-007-0141-8]
   Kircher S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1356682.1356685
   Kohonen T., 1997, Self-Organizing Maps
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Lee TY, 2008, IEEE T CIRC SYST VID, V18, P478, DOI 10.1109/TCSVT.2008.918456
   Li S, 2005, INT C COMMUN CIRCUIT, P833
   Lim IS, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P829, DOI 10.1109/ICME.2002.1035910
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   Park MJ, 2004, COMPUT ANIMAT VIRT W, V15, P245, DOI 10.1002/cav.27
   Pullen K, 2002, ACM T GRAPHIC, V21, P501
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sumner RW, 2005, ACM T GRAPHIC, V24, P488, DOI 10.1145/1073204.1073218
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Xu WW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239535
NR 27
TC 9
Z9 10
U1 3
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2012
VL 23
IS 6
BP 559
EP 568
DI 10.1002/cav.1471
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 051NL
UT WOS:000312134000005
OA Bronze
DA 2024-07-18
ER

PT J
AU Zong, D
   Li, CP
   Xia, SH
   Wang, ZQ
AF Zong, Dan
   Li, Chunpeng
   Xia, Shihong
   Wang, Zhaoqi
TI Planning interactive task for intelligent characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character animation; interactive behavior graph; motion planning;
   reinforcement learning
AB Motion planning is an important problem in character animation and interactive simulation. However, few planning methods have considered domain-specific knowledge that governs the agent's behaviors, and none of them is capable of planning the interactive task in which the agent interacts with the objects in the virtual environment. This paper presents a novel method to plan the interactive task based on Q-learning for intelligent characters. The approach can be described as a three-phase framework: data preprocessing phase, controller learning phase, and motion-synthesis phase. In the data preprocessing phase, we abstract the motion clips as high-level behaviors and construct the interactive behavior graph (IBG) to define the interactive capabilities of the agent in terms of interactive features. For the controller training phase, with IBG, Q-learning algorithm is employed to train the control policy in the discrete domain with interactive features. In the motion-synthesis phase, the optimal motion sequences can be generated by following the policy to accomplish the interactive task finally. The experimental results demonstrate that the uniform framework can generate reasonable and realistic motion sequences to plan interactive task in complex environment. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Zong, Dan; Li, Chunpeng; Xia, Shihong; Wang, Zhaoqi] Chinese Acad Sci, Adv Comp Res Lab, Inst Comp Technol, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Zong, D (corresponding author), Chinese Acad Sci, Adv Comp Res Lab, Inst Comp Technol, 6 Kexueyuan S Rd Zhongguancun, Beijing, Peoples R China.
EM zongdan@ict.ac.cn
RI Li, Chunpeng/AAE-6134-2019
FU National Natural Science Foundation of China [60903140, 61173055,
   61100086]; NSFC-Guangdong Joint Fund [U0935003]; Key Lab of Mobile
   Computing and Pervasive Devices
FX This work is supported and funded by the National Natural Science
   Foundation of China (grant nos 60903140, 61173055, 61100086),
   NSFC-Guangdong Joint Fund (no. U0935003), and the Key Lab of Mobile
   Computing and Pervasive Devices. Also, we would like to thank the
   anonymous reviewers for their valuable comments and suggestions.
CR Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Blumberg B, 2002, ACM T GRAPHIC, V21, P417, DOI 10.1145/566570.566597
   Bruderlin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P97, DOI 10.1145/218380.218421
   Chiu B, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P73
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Gleicher Michael., 2003, I3D 2003: Proceedings of the 2003 Symposium on Interactive 3D Graphics, P181
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Huang YZ, 2011, IEEE INT C INT ROBOT, P2653, DOI 10.1109/IROS.2011.6048734
   IKEMOTO L., 2005, ACM SIGGRAPH SKETCH, P46
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Kallmann M, 2011, IROS WORKSH PROGR OP
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kron Taesoo., 2005, EUROGRAPHICSACM SIGG, P29, DOI DOI 10.1145/1073368.1073373
   Kwon T, 2008, IEEE T VIS COMPUT GR, V14, P707, DOI 10.1109/TVCG.2008.22
   Lau M., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA '05, P271
   Lau Manfred., 2006, P ACM SIGGRAPHEUROGR, P299
   Lee J, 2006, GRAPH MODELS, V68, P158, DOI 10.1016/j.gmod.2005.03.004
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lee KH, 2006, ACM T GRAPHIC, V25, P898, DOI 10.1145/1141911.1141972
   Lee S. J., 2010, ACM T GRAPHIC, V29, P1
   Lee Yongjoon., 2009, SIGGRAPH ASIA 09 ACM, P1
   Lo Wan-Yen, 2008, Proceedings of the 2008 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P29
   McCann J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276385, 10.1145/1239451.1239457]
   Pullen K, 2002, ACM T GRAPHIC, V21, P501
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Shin H.J., 2006, Proceedings of ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P291
   Shum HPH, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P131
   Shum HPH, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409067
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
   Watkins C. J. C. H., 1989, Learning from Delayed Rewards
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
NR 32
TC 1
Z9 2
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2012
VL 23
IS 6
BP 547
EP 557
DI 10.1002/cav.1470
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 051NL
UT WOS:000312134000004
DA 2024-07-18
ER

PT J
AU Jund, T
   Kraemer, P
   Cazier, D
AF Jund, Thomas
   Kraemer, Pierre
   Cazier, David
TI A unified structure for crowd simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE crowd simulation; topological model; proximity queries; collision
   avoidance; path planning
ID NAVIGATION
AB Realistic simulation of crowds is an important issue for the production of virtual worlds for games, entertainment or architectural and urban planning. Difficult issues need to be addressed such as collision avoidance and the handling of dynamic environments. In this paper, we present a unified structure for the simulation of crowds in complex urban environments. We propose a topological multiresolution model supporting different levels of details, allowing efficient proximity querying and compatible with real-time rendering and hierarchical path planning. A fine exploitation of the multiscale aspect of the underlying model allows to achieve the same efficiency as the fastest existing methods. The generality of the approach allows the simulation to be executed on any two manifold, and the unified approach eases the handling of dynamic environments. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Jund, Thomas; Kraemer, Pierre; Cazier, David] Univ Strasbourg, LSIIT, Strasbourg, France.
C3 Universites de Strasbourg Etablissements Associes; Universite de
   Strasbourg
RP Kraemer, P (corresponding author), Univ Strasbourg, LSIIT, Strasbourg, France.
EM kraemer@unistra.fr
OI Cazier, David/0000-0001-5247-6404
CR [Anonymous], SIAM ACM GDSPM
   [Anonymous], 2004, Journal of Game Development
   Badler N, 2008, SYNTHESIS LECT COMPU
   Braun A, 2003, COMP ANIM CONF PROC, P143, DOI 10.1109/CASA.2003.1199317
   CGoGN, COMB GEOM MOD GEN N
   Fiorini P, 1998, INT J ROBOT RES, V17, P760, DOI 10.1177/027836499801700706
   Gayle R, 2009, IEEE T VIS COMPUT GR, V15, P34, DOI 10.1109/TVCG.2008.84
   Goldenstein S, 2001, COMPUT GRAPH-UK, V25, P983, DOI 10.1016/S0097-8493(01)00153-4
   Guy S., 2009, EUR ACM SIGGRAPH S C, P177
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   Jiang H, 2010, COMPUT GRAPH-UK, V34, P537, DOI 10.1016/j.cag.2010.05.013
   Jund T, 2010, VRIPHYS COP DAN, P69
   Kraemer P, 2009, VISUAL COMPUT, V25, P149, DOI 10.1007/s00371-008-0211-6
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Paris S, 2006, COMPUT ANIMAT VIRT W, V17, P325, DOI 10.1002/cav.136
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Sud A, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P99
   Tecchia F, 2002, COMPUT GRAPH FORUM, V21, P753, DOI 10.1111/1467-8659.00633
   Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47
   Thalmann D, 2006, EUROGRAPHICS 2006 TU, P869
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
NR 22
TC 10
Z9 13
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 311
EP 320
DI 10.1002/cav.1449
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100018
DA 2024-07-18
ER

PT J
AU Wagoum, AUK
   Chraibi, M
   Mehlich, J
   Seyfried, A
   Schadschneider, A
AF Wagoum, Armel Ulrich Kemloh
   Chraibi, Mohcine
   Mehlich, Jonas
   Seyfried, Armin
   Schadschneider, Andreas
TI Efficient and validated simulation of crowds for an evacuation assistant
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE pedestrian dynamics; real-time simulation; evacuation; cellular
   automata; continuous models
ID PEDESTRIAN DYNAMICS; FORCE MODEL; FLOW
AB To improve safety at mass events, an evacuation assistant that supports security services in case of emergencies is developed. One central aspect is forecasting the emergency egress of large crowds in complex buildings. This requires realistic models of pedestrian dynamics that can be simulated faster than real-time by using methods applied in high performance computing. We give an overview of the project and present the actual results. We also describe the modeling approaches used thereby focusing on the runtime optimization and parallelization concepts. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Wagoum, Armel Ulrich Kemloh; Chraibi, Mohcine; Seyfried, Armin] Forschungszentrum Julich, Julich Supercomp Ctr, D-52428 Julich, Germany.
   [Chraibi, Mohcine; Seyfried, Armin] Univ Wuppertal, D-42285 Wuppertal, Germany.
   [Mehlich, Jonas] VEDA GmbH, D-52477 Alsdorf, Germany.
   [Schadschneider, Andreas] Univ Cologne, Inst Theoret Phys, D-50937 Cologne, Germany.
C3 Helmholtz Association; Research Center Julich; University of Wuppertal;
   University of Cologne
RP Wagoum, AUK (corresponding author), Forschungszentrum Julich, Julich Supercomp Ctr, D-52428 Julich, Germany.
EM u.kemloh@fz-juelich.de
RI Chraibi, Mohcine/Q-9749-2019; Seyfried, Armin/T-4868-2017
OI Chraibi, Mohcine/0000-0002-0999-6807; Seyfried,
   Armin/0000-0001-8888-0978; Schadschneider, Andreas/0000-0002-2054-7973
FU German Government, Federal Ministry of Education and Research; 
   [13N9952];  [13N9960]
FX This work has been performed within the program "Research for Civil
   Security" in the field "Protecting and Saving Human Life" funded by the
   German Government, Federal Ministry of Education and Research. The
   project is supported under the grant nos. 13N9952 and 13N9960.
CR Allen M.P., 1989, COMPUTER SIMULATION, V18
   [Anonymous], 2008, REF AS VERS 4 6, P6
   [Anonymous], P 2006 ACM SIGGRAPH
   [Anonymous], 2007, Numerical Simulation in Molecular Dynamics: Numerics, Algorithms, Parallelization, Applications
   Burstedde C, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P87
   Burstedde C, 2001, PHYSICA A, V295, P507, DOI 10.1016/S0378-4371(01)00141-8
   Chandra R., 2001, PARALLEL PROGRAMMING, DOI DOI 10.5555/355074
   Chraibi M, 2011, NETW HETEROG MEDIA, V6, P425, DOI 10.3934/nhm.2011.6.425
   Chraibi M, 2010, PHYS REV E, V82, DOI 10.1103/PhysRevE.82.046111
   Ezaki T, 2012, PHYSICA A, V391, P291, DOI 10.1016/j.physa.2011.07.056
   Ferrucci L., 2003, P 17 EUR SIM MULT, P9
   FRUIN JJ, 1971, PEDESTRAIN PLANNING
   Galea E. R., 2004, BUILDINGEXODUS V 4 0
   Geimer M, 2010, CONCURR COMP-PRACT E, V22, P702, DOI 10.1002/cpe.1556
   HANKIN BD, 1958, OPER RES QUART, V9, P81, DOI 10.2307/3006732
   Hanxleden RV, 1993, SCAL HIGH PERF COMP, P95
   Hegarty D. F., 1996, Applied Parallel Computing. Computation in Physics, Chemistry and Engineering Science. Second International Workshop, PARA '95. Proceedings, P303
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Helbing D, 2007, DYNAMICS CROWS DISAS, V75
   Henein CM, 2007, PHYSICA A, V373, P694, DOI 10.1016/j.physa.2006.06.023
   Holl S., 2009, INSIDE, V7, P60
   JANAK JF, 1992, J COMPUT CHEM, V13, P1098, DOI 10.1002/jcc.540130908
   Kemloh Wagoum AU, 2011, ADV COMPLEX SYST
   Kirchner A, 2004, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2004/10/P10011
   Kirchner A, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.056122
   Kirchner A, 2003, PHYSICA A, V324, P689, DOI 10.1016/S0378-4371(03)00076-1
   Kirchner A, 2002, PHYSICA A, V312, P260, DOI 10.1016/S0378-4371(02)00857-9
   Korhonen T., 2008, P 4 INT C PED EV DYN
   Kretz T, 2006, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2006/10/P10014
   Lewin K., 1976, Field theory in social science
   Message P Forum, 1994, Technical Report
   Molnar P., 1995, THESIS U STUTTGART
   MORI M, 1987, TRANSPORT RES A-POL, V21, P223, DOI 10.1016/0191-2607(87)90016-1
   Oeding D, 1963, STRASSENBAU STRASSEN
   Pettré J, 2006, COMPUT ANIMAT VIRT W, V17, P445, DOI 10.1002/cav.147
   PLIMPTON S, 1995, ACS SYM SER, V592, P114
   Quinn M.J., 2003, P 2 INT C PEDESTRIAN, P63
   Raney B, 2006, ROUTL STUD BUS ORGAN, P305
   Richmond P, 2008, P EUROSIS ESM 2008 E
   Rogsch C., 2007, Pedestrian and Evacuation Dynamics 2005, P357
   Schadschneider A, 2011, STOCHASTIC TRANSPORT IN COMPLEX SYSTEMS: FROM MOLECULES TO VEHICLES, P1
   Schadschneider A, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P75
   Schadschneider A., 2009, Encyclopedia of complexity and systems science, P3142, DOI [DOI 10.1007/978-0-387-30440-3_187, 10.1007/978-0-387-30440-3_187]
   Schadschneider A, 2009, PEDESTRIAN BEHAVIOR: MODELS, DATA COLLECTION AND APPLICATIONS, P27
   Schadschneider A, 2010, PHYS WORLD, V23, P21
   Seyfried A., 2010, PEDESTRIAN EVACUATIO, P363
   Seyfried A, 2009, TRANSPORT SCI, V43, P395, DOI 10.1287/trsc.1090.0263
   Steffen B, 2011, 2 INT C PAR DISTR GR
   Sutmann G, 2006, J MOL LIQ, V125, P197
   Tavares RM, 2009, BUILD ENVIRON, V44, P1005, DOI 10.1016/j.buildenv.2008.07.019
   Thalmann Daniel., 2007, CROWD SIMULATION
   THOMPSON PA, 1995, FIRE SAFETY J, V24, P131, DOI 10.1016/0379-7112(95)00019-P
   TraffGo HT GmbH, 2005, HDB PEGO 2
   VERLET L, 1967, PHYS REV, V159, P98, DOI 10.1103/PhysRev.159.98
   Wang SW, 2003, PARALLEL COMPUT, V29, P1481, DOI 10.1016/j.parco.2003.04.003
   Yu WJ, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.026112
NR 56
TC 16
Z9 18
U1 2
U2 30
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2012
VL 23
IS 1
BP 3
EP 15
DI 10.1002/cav.1420
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 897SH
UT WOS:000300675800003
DA 2024-07-18
ER

PT J
AU Ulusoy, I
   Akagunduz, E
   Yirci, M
AF Ulusoy, Ilkay
   Akagunduz, Erdem
   Yirci, Murat
TI Anatomical and dynamic volume spline model applied to facial soft tissue
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE spline; volume spline; DNURBS; volume spline fitting; physically based
   modeling
ID HUMAN SKIN; MECHANICAL-PROPERTIES; IDENTIFICATION; SIMULATION
AB Biomechanical modeling of soft tissue is a complex problem for achieving realistic surgical simulations, surgical planning, and scientific analysis. In the literature, three categories of biomechanical models: spline based models, spring models, and finite element models (FEMs) are mainly used for dealing with this problem. Among these, spline based models offer relatively fast and realistic soft tissue simulations by utilizing both the spring and FEMs. In this paper, a new dynamic volume spline model for human face skin is proposed and the performance of our model is discussed by estimating the results of facial surgery of three different patients. Face models of the patients are obtained from 3D CT/MR scans by segmenting the skull, muscle, and skin layers. In these face models, the skull and the muscle layers are considered as the rigid boundary for the skin layer and the skin layer is modeled by our dynamic volume spline. The control points of the dynamic volume spline are localized masses with viscoelastic material properties (stiffness, damping, and mass). These parameters are computed from the skin material properties that were published in the literature. Once the face models are generated, facial surgery plannings are simulated. Infact, the pre-surgery face models are modified according to the surgical plans and the estimated post-surgery face models are compared with the actual post-surgery face models. Moreover, in order to discuss the performance of our dynamic volume spline model, the same analyses are performed on the post-surgery estimations of a conventional tool. Copyright (c) 2011 John Wiley & Sons, Ltd.
C1 [Ulusoy, Ilkay; Akagunduz, Erdem; Yirci, Murat] ODTU EEMB, METU, Ankara, Turkey.
RP Ulusoy, I (corresponding author), ODTU EEMB, METU, Ankara, Turkey.
EM ilkay@metu.edu.tr
RI Akagündüz, Erdem/W-1788-2018; , ilkay/AAZ-9415-2020
OI Akagündüz, Erdem/0000-0002-0792-7306; 
FU  [TUBITAK105E128]
FX This work is partially supported by TUBITAK105E128. We thank to Asoc.
   Prof. Ozlem Ucok, Asst. Prof. Serkan Gorgulu and Asst. Prof. Fidan
   Sabuncuoglu from GATA Dentistry, for providing us the medical data and
   for evaluating the comparative results.
CR [Anonymous], MODERN CONTROL ENG 4
   [Anonymous], MIMICS
   [Anonymous], HDB NUMERICAL ANAL
   [Anonymous], P SIGGR
   [Anonymous], P 28 ANN C COMP GRAP
   BOYER G, 2007, P 29 ANN INT C IEEE
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cignoni P., 2008, P EUR IT CHAPT C, P129, DOI [DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136, 10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/129-136]
   DELINGETTE H, 1998, 3506 INRIA
   Duchemin G, 2005, IEEE T BIO-MED ENG, V52, P160, DOI 10.1109/TBME.2004.840505
   Gambarotta L, 2005, J BIOMECH, V38, P2237, DOI 10.1016/j.jbiomech.2004.09.034
   Gennisson JL, 2004, IEEE T ULTRASON FERR, V51, P980, DOI 10.1109/TUFFC.2004.1324402
   HAUTH M, 2003, P EUR SIGGR S COMP A, P17
   Kaipatur NR, 2009, J ORAL MAXIL SURG, V67, P751, DOI 10.1016/j.joms.2008.11.006
   KOCH R.M., 1996, P SIGGRAPH, P421
   Pailler-Mattei C, 2008, MED ENG PHYS, V30, P599, DOI 10.1016/j.medengphy.2007.06.011
   Pailler-Mattei C, 2009, COLLOID SURFACE B, V68, P200, DOI 10.1016/j.colsurfb.2008.10.005
   Qin H, 1996, IEEE T VIS COMPUT GR, V2, P85, DOI 10.1109/2945.489389
   Schoner JL, 2004, COMPUT GRAPH FORUM, V23, P547, DOI 10.1111/j.1467-8659.2004.00786.x
   Schwartz JM, 2005, MED IMAGE ANAL, V9, P103, DOI 10.1016/j.media.2004.11.002
   Sedef M, 2006, IEEE COMPUT GRAPH, V26, P58, DOI 10.1109/MCG.2006.135
   Tran H. V., 2007, Computer Methods in Biomechanics and Biomedical Engineering, V10, P401, DOI 10.1080/10255840701550287
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 23
TC 0
Z9 0
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2011
VL 22
IS 6
BP 543
EP 554
DI 10.1002/cav.386
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856IA
UT WOS:000297631200007
DA 2024-07-18
ER

PT J
AU Xiang, N
   Zhao, HY
   Zhou, XJ
   Xu, ML
   El Rhalibi, A
   Wu, Y
AF Xiang, Nan
   Zhao, Haiying
   Zhou, Xiaojian
   Xu, Mingliang
   El Rhalibi, Abdennour
   Wu, Yu
TI UEGM: uncertain emotion generator under multi-stimulus
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE affective computing; virtual human; uncertain emotion generation;
   emotion expression; particle filter
ID MEMORY
AB In this paper, we introduce a novel particle filtering architecture to simulate uncertain emotion generation under multi-stimulus, to enrich emotions for virtual characters. Particles are exploited to predict emotions by sampling possible natural emotional reactions from individuals' memories and common reactions, and the prediction is subsequently adjusted through likelihood function constructed through appraisals of the cognitive component. Thus this generation process combines the natural reactions and cognitive results of individuals' into a unified architecture. Furthermore, the expression of emotion as a communicative act is implemented by setting moral standards that an individual must obey, no matter what his or her real emotional reaction is to the stimulus. This generation and expression process is implemented with our uncertain emotion generator under multi-stimulus system (UEGM). Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Zhao, Haiying] Xinjiang Normal Univ, Dept Comp Sci & Technol, Xinjiang, Peoples R China.
   [Xiang, Nan; Zhou, Xiaojian; Xu, Mingliang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
   [El Rhalibi, Abdennour] Liverpool John Moores Univ, Sch Comp & Maths, Liverpool L3 5UX, Merseyside, England.
   [Wu, Yu] Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing, Peoples R China.
C3 Xinjiang Normal University; Zhejiang University; Liverpool John Moores
   University; Chongqing University of Posts & Telecommunications
RP Zhao, HY (corresponding author), Xinjiang Normal Univ, Dept Comp Sci & Technol, Xinjiang, Peoples R China.
EM xiangnan@zjucadcg.cn; zhaohaiying2008@gmail.com;
   programming.game@gmail.com
CR [Anonymous], 2006, EUROGRAPHICS 2006 ST, DOI DOI 10.2312/EGST.20061052
   ARELLANO D, 2003, COMPUTER ANIMATION V, V19, P259
   Banich MT, 2009, NEUROSCI BIOBEHAV R, V33, P613, DOI 10.1016/j.neubiorev.2008.09.010
   Becker-Asano C, 2010, AUTON AGENT MULTI-AG, V20, P32, DOI 10.1007/s10458-009-9094-9
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   DESEVIN E, 2005, P AG WANT LIK MOT EM
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Egges A, 2004, COMPUT ANIMAT VIRT W, V15, P1, DOI 10.1002/cav.3
   El-Nasr MS, 2000, AUTON AGENT MULTI-AG, V3, P219, DOI 10.1023/A:1010030809960
   Elliott Clark, 1992, PhD thesis.
   Gratch J., 2004, Cogn. Syst. Res, V5, P269, DOI [10.1016/j.cogsys.2004.02.002, DOI 10.1016/J.COGSYS.2004.02.002]
   Haidt J, 2007, SCIENCE, V316, P998, DOI 10.1126/science.1137651
   Hudlicka E, 2004, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON COGNITIVE MODELING, P118
   Kasap Z, 2008, STUD COMPUT INTELL, V140, P43
   Kasap Z, 2009, IEEE COMPUT GRAPH, V29, P20, DOI 10.1109/MCG.2009.26
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   LaBar KS, 2006, NAT REV NEUROSCI, V7, P54, DOI 10.1038/nrn1825
   Laird JE, 2008, FRONT ARTIF INTEL AP, V171, P224
   Lang PJ, 2010, BIOL PSYCHOL, V84, P437, DOI 10.1016/j.biopsycho.2009.10.007
   Marinier RP, 2009, COGN SYST RES, V10, P48, DOI 10.1016/j.cogsys.2008.03.004
   Mendl M, 2009, APPL ANIM BEHAV SCI, V118, P161, DOI 10.1016/j.applanim.2009.02.023
   Mikami D, 2009, PROC CVPR IEEE, P999, DOI 10.1109/CVPRW.2009.5206661
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Raouzaiou A, 2006, ENTERPRISE INFORMATION SYSTEMS VI, P301, DOI 10.1007/1-4020-3675-2_36
   REILLY WSN, 1996, THESIS CITESEER
   Scherer Klaus R, 2001, APPRAISAL PROCESSES, V92, P57
   Yang HW, 2008, KNOWL ENG REV, V23, P321, DOI 10.1017/S0269888908000027
NR 27
TC 4
Z9 4
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 141
EP 149
DI 10.1002/cav.411
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700009
DA 2024-07-18
ER

PT J
AU Zhu, JJ
   Pan, ZG
   Sun, C
   Chen, WZ
AF Zhu, Jiejie
   Pan, Zhigeng
   Sun, Chao
   Chen, Wenzhi
TI Handling occlusions in video-based augmented reality using depth
   information
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; occlusion handling; stereo
AB Augmented Reality (AR) composes virtual objects with real scenes in a mixed environment where human-computer interaction has more semantic meanings. To seamlessly merge virtual objects with real scenes, correct occlusion handling is a significant challenge. We present an approach to separate occluded objects in multiple layers by utilizing depth, color, and neighborhood information. Scene depth is obtained by stereo cameras and two Gaussian local kernels are used to represent color, spatial smoothness. These three cues are intelligently fused in a probability framework, where the occlusion information can be safely estimated. We apply our method to handle occlusions in video-based AR where virtual objects are simply overlapped on real scenes. Experiment results show the approach can correctly register virtual and real objects in different depth layers, and provide a spatial-awareness interaction environment. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Zhu, Jiejie] Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA.
   [Pan, Zhigeng; Sun, Chao] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Wenzhi] Zhejiang Univ, Dept Comp Sci, Hangzhou, Zhejiang, Peoples R China.
C3 University of Kentucky; Zhejiang University; Zhejiang University
RP Pan, ZG (corresponding author), Beihang Univ, State Key Lab Virtual Real & Syst, Beijing 100191, Peoples R China.
EM zgpan@cad.zju.edu.cn
RI 陳, 文誌/AAI-6255-2021
OI Pan, Zhi-geng/0000-0003-0717-5850
FU NSFC [60533080]; State Key Lab of VR, Beihang University; 863 project on
   Digital Media Authoring Platform [2006AA01Z335]
FX This research work is co-supported by NSFC project on Virtual Olympic
   Museum (grant no:60533080), 863 project on Digital Media Authoring
   Platform (grant no:2006AA01Z335), and Open Project of State Key Lab of
   VR, Beihang University.
CR [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   BAJURA M, 1992, COMP GRAPH, V26, P203, DOI 10.1145/142920.134061
   Berger MO, 1997, PROC CVPR IEEE, P91, DOI 10.1109/CVPR.1997.609304
   BIRCHFIELD S, 1998, IEEE C PATT AN MACH, P401
   BOGDAN M, 2006, IEEE T PATTERN ANAL, V28, P1537
   FORTIN PA, 2006, P CAN C COMP ROB VIS
   FUHRMANN A, 1998, COMPUT GRAPH-UK, V23, P255
   Gordon G, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P14, DOI 10.1109/ISMAR.2002.1115063
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hayashi K., 2005, P 2005 INT C AUGMENT, P180
   HOWARD IP, 1995, DEPTH PERCEPTION SEE
   Lepetit V, 2000, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2000.854794
   NORIEGA P, 2006, P INT C COMP VIS THE, P67
   OHTA Y, 2001, P 2 INT S MIX REAL I, P64
   PANG Y, 2006, P AUIC, P25
   Swan JE, 2007, IEEE T VIS COMPUT GR, V13, P429, DOI 10.1109/TVCG.2007.1035
   Uratani K, 2005, P IEEE VIRT REAL ANN, P295
   Vallerand S, 2003, P IEEE VIRT REAL ANN, P271, DOI 10.1109/VR.2003.1191154
   Wither J, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P92, DOI 10.1109/ISWC.2005.41
   YOKOYA N, 1999, P 1 INT S MIX REAL Y, P85
   Yoon KJ, 2005, PROC CVPR IEEE, P924
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   CAMERA CALIBRATION A
NR 24
TC 15
Z9 21
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2010
VL 21
IS 5
BP 509
EP 521
DI 10.1002/cav.326
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 672VP
UT WOS:000283615300004
DA 2024-07-18
ER

PT J
AU Baiget, P
   Fernández, C
   Roca, X
   Gonzàlez, J
AF Baiget, Pau
   Fernandez, Carles
   Roca, Xavier
   Gonzalez, Jordi
TI Generation of augmented video sequences combining behavioral animation
   and multi-object tracking
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; behavioral animation; virtual human agents
ID EXPRESSION RECOGNITION; REAL
AB In this paper we present a novel approach to generate augmented video sequences in real-time, involving interactions between virtual and real agents in real scenarios. On the one hand, real agent motion is estimated by means of a multi-object tracking algorithm, which determines real objects' position over the scenario for each time step. On the other hand, virtual agents are provided with behavior models considering their interaction with the environment and with other agents. The resulting framework allows to generate video sequences involving behavior-based virtual agents that react to real agent behavior and has applications in education, simulation, and in the game and movie industries. We show the performance of the proposed approach in an indoor and outdoor scenario simulating human and vehicle agents. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Baiget, Pau; Fernandez, Carles; Roca, Xavier] Univ Autonoma Barcelona, Comp Vis Ctr, Barcelona, Spain.
   [Roca, Xavier] Univ Autonoma Barcelona, Dept Comp Sci, Barcelona, Spain.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Autonomous University of Barcelona
RP Baiget, P (corresponding author), Univ Autonoma Barcelona, Comp Vis Ctr, Barcelona, Spain.
EM pbaiget@cvc.uab.es
RI Gonzàlez, Jordi/I-1812-2015; Roca Marva, F. Xavier/I-2013-2015
OI Gonzàlez, Jordi/0000-0001-8033-0306; Roca Marva, F.
   Xavier/0000-0002-7043-7334
CR AMATO A, 2008, 19 INT C PATT REC IC
   [Anonymous], 2008, P 19 BRIT MACH VIS C
   Arens M, 2008, IMAGE VISION COMPUT, V26, P53, DOI 10.1016/j.imavis.2005.07.026
   ARENS M, 2003, P 26 GERM C ART INT, P149
   Badler NI, 1999, COMMUN ACM, V42, P64, DOI 10.1145/310930.310975
   BAIGET P, 2008, 5 INT C ART MOT DEF, P299
   BAIGET P, 2007, 10 INT C COMP GRAPH
   Balcisoy S, 1997, COMP ANIM CONF PROC, P31, DOI 10.1109/CA.1997.601037
   BLUMBERG BM, 1995, P SIGGRAPH 95, P47
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Cheng JC, 1999, IEEE T MULTIMEDIA, V1, P144, DOI 10.1109/6046.766736
   COLMERAUER A, 1990, COMMUN ACM, V33, P69, DOI 10.1145/79204.79210
   Conde T, 2005, LECT NOTES ARTIF INT, V3661, P88
   CONDE T, 2006, AAMAS 06, P89
   Dornaika F, 2008, INT J COMPUT VISION, V76, P257, DOI 10.1007/s11263-007-0059-7
   Douze M, 2006, COMPUT ANIMAT VIRT W, V17, P537, DOI 10.1002/cav.116
   Gelenbe E, 2005, J SYST SOFTWARE, V74, P255, DOI 10.1016/j.jss.2004.01.016
   Gonzàlez J, 2003, LECT NOTES COMPUT SC, V2652, P287
   Gonzàlez J, 2009, IMAGE VISION COMPUT, V27, P1433, DOI 10.1016/j.imavis.2008.02.004
   Haag M, 2000, IMAGE VISION COMPUT, V18, P137, DOI 10.1016/S0262-8856(99)00021-9
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hughes CE, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.139
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170
   MAGNENAT N, 1997, MULTIMEDIA SYSTEMS, V5, P113
   Papagiannakis G, 2005, COMPUT ANIMAT VIRT W, V16, P11, DOI 10.1002/cav.53
   Papagiannakis G, 2008, COMPUT ANIMAT VIRT W, V19, P3, DOI 10.1002/cav.221
   Perlin Ken., 1996, SIGGRAPH 96, P205
   PIEKARSKI W, 2003, ISMAR 03, P247
   ROWE D, 2008, THESIS U AUTONOMA BA
   SCHAFER K, 1997, P 7 WORKSH TEMP NONC, P23
   Schmidt T, 2008, DANCE THEAT J, V23, P35
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   TAMBELLINI W, 2003, P LNAI, V2792, P175
   Zhang GF, 2006, COMPUT ANIMAT VIRT W, V17, P305, DOI 10.1002/cav.134
NR 36
TC 3
Z9 5
U1 4
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL-AUG
PY 2009
VL 20
IS 4
BP 473
EP 489
DI 10.1002/cav.320
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 488QG
UT WOS:000269364200004
DA 2024-07-18
ER

PT J
AU Haciomeroglu, M
   Laycock, RG
   Day, AM
AF Haciomeroglu, M.
   Laycock, R. G.
   Day, A. M.
TI Dynamically populating large urban environments with ambient virtual
   humans
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE real-time crowd simulation
ID SIMULATION; DETAIL; CROWDS
AB Creating an interactive simulation of a large urban environment populated With virtual humans poses a number of interesting challenges, ranging from how to initialise tire virtual humans in the correct locations to maintaining a real-time simulation. When considering a large environment it is beneficial to investigate automatic techniques that create and simulate virtual humans using the available computing resources effectively. In this paper; two contributions towards the population of a large environment are described. The first presents two methods that use an automatic analysis of tire urban environment to determine tire required population densities throughout the scene. These methods ensure that the virtual humans are distributed such that main high streets consistently exhibit a higher number of virtual humans than other areas. The methods presented here achieve above 90% correlation to the predicted population densities for the environment, which outperforms tire state of the art. The second contribution concerns the optimisation of the two methods to facilitate their applicability to large environments. The methods presented are modified to insert virtual humans dynamically into the behaviour system when required. The approach limits the required computing resources whilst achieving above 75% correlation to the predicted population values. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Haciomeroglu, M.; Laycock, R. G.] Univ E Anglia, Crowd Simulat Grp, Norwich NR4 7TJ, Norfolk, England.
   [Day, A. M.] Univ E Anglia, Comp Graph Res Grp, Norwich NR4 7TJ, Norfolk, England.
C3 University of East Anglia; University of East Anglia
RP Haciomeroglu, M (corresponding author), Univ E Anglia, Crowd Simulat Grp, Norwich NR4 7TJ, Norfolk, England.
EM muratm@cmp.uea.ac.uk
FU EPSRC [EP/E035639/1] Funding Source: UKRI
CR [Anonymous], 1986, The Ecological Approach toVisual Perception
   [Anonymous], GAME DEV C
   Braun A., 2005, Proceedings of the ACM symposium on Virtual reality software and technology, P244
   Brom C, 2007, LECT NOTES ARTIF INT, V4722, P1
   CHENNEY S, 2000, SIGGRAPH 2000 TECHNI
   HACIOMEROGLU M, 2007, CYBERWORLDS 2007, P152
   Hillier B., 1984, The Social Logic of Space, DOI DOI 10.1017/CBO9780511597237
   O'Sullivan C, 2002, COMPUT GRAPH FORUM, V21, P733, DOI 10.1111/1467-8659.00631
   Paris S, 2006, COMPUT ANIMAT VIRT W, V17, P325, DOI 10.1002/cav.136
   Penn A, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P99
   Pettré J, 2006, COMPUT ANIMAT VIRT W, V17, P445, DOI 10.1002/cav.147
   STYLIANOU S, 2004, VRST 04, P65
   Turner A, 2007, ENVIRON PLANN B, V34, P539, DOI 10.1068/b32067
NR 13
TC 7
Z9 7
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 307
EP 317
DI 10.1002/cav.232
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200014
DA 2024-07-18
ER

PT J
AU Liu, XC
   Mao, TL
   Xia, SH
   Yu, Y
   Wang, ZQ
AF Liu, Xuecheng
   Mao, Tianlu
   Xia, Shihong
   Yu, Yong
   Wang, Zhaoqi
TI Facial animation by optimized blendshapes from motion capture data
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE blendshape facial animation; facial motion retarget; motion capture;
   optimization
AB This paper presents a labor-saving method to construct optimal facial animation blendshapes front given blendshape sketches and facial motion capture data. At first, a mapping function is established between target "Marker Face" and performer's face by RBF interpolating selected feature points. Sketched blendshapes are transferred to performer's "Marker Face" by using motion vector adjustment technique. Then, the blendshapes of performer's "Marker Face" are optimized according to the facial motion capture data. At last, the optimized blendshapes are inversely transferred to target facial model. Apart from that, this paper also proposes a method of computing blendshape weights from facial motion capture data more accurately. Experiments show that expressive facial animation can be acquired. Copyright 0( 2008 John Wiley & Sons, Ltd.
C1 [Liu, Xuecheng] Chinese Acad Sci, Inst Comp Technol, Virtual Real Lab, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Liu, XC (corresponding author), Chinese Acad Sci, Inst Comp Technol, Virtual Real Lab, Beijing 100080, Peoples R China.
EM liuxuecheng@ict.ac.cn
CR Choe B, 2001, J VISUAL COMP ANIMAT, V12, P67, DOI 10.1002/vis.246
   CHOE B, 2001, P COMP AN
   Chuang E, 2005, ACM T GRAPHIC, V24, P331, DOI 10.1145/1061347.1061355
   CHUANG E, 2002, P 10 PAC C COMP GRAP
   Coleman TF, 1996, SIAM J OPTIMIZ, V6, P1040, DOI 10.1137/S1052623494240456
   CURIO C, 2006, P 3 S APPL PERC GRAP
   DENG Z, 2006, P 2006 S INT 3D GRAP
   Ekman P, 1978, FACIAL ACTION CODING
   FRATARCANGELI M, 2007, GRAPHIC MODEL, V69, P89
   HARDY RL, 1971, J GEOPHYS RES, V76, P1905, DOI 10.1029/JB076i008p01905
   HAVALDAR P, 2006, SIGGRAPH COURSES
   JIANG D, 2002, 35 ANN SIM S
   Joshi P, 2003, EUR SIGGRAPH S COMP
   KSHIRSAGAR S, 2000, IFIP C P, V196, P24
   LI Q, 2008, UHCS0712 DEP COMP SC
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   Parke F., 1996, COMPUTER FACIAL ANIM
   Parke F., 1974, UTECCSC75047 U UT
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   PIGHIN F, 1998, SYNTHESIZING REALIST
   PIGHIN F, 2006, SIGGRAPH COURSES
   PYUN H, 2003, EUR SIGGRAPH S COMP
   SAGAR M, 2006, ACM SIGGRAPH 2006 SK
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Wang Y., 2004, EUROGRAPHICS
NR 27
TC 14
Z9 24
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 235
EP 245
DI 10.1002/cav.248
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200008
DA 2024-07-18
ER

PT J
AU Badawi, M
   Donikian, S
AF Badawi, M.
   Donikian, S.
TI The generic description and management of interaction between autonomous
   agents and objects in an informed virtual environment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE computer animation; informed environment; interactive objects
AB Autonomous agents cannot exist in an environment without interacting with the world surrounding them. In this paper we propose an informed environment based on synoptic objects which contain a synopsis of the interactions they can undergo. Through the use of interactive surfaces (ISs) we manage to describe the surfaces of interest on the object itself and the space affected by the object during interaction. Then, by defining a set of seven basic actions, the objects can describe the interaction process through these actions to any agent implementing them. The description of the interaction process is done through complex actions which indicate the order in which the basic actions need to be accomplished and what to do depending on the result of the undertaken action. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 IRISA, Bunraku Team, INRIA, Rennes, France.
C3 Inria
RP Donikian, S (corresponding author), IRISA, Bunraku Team, INRIA, Rennes, France.
EM donikian@irisa.fr
CR ABACI T, 2006, THESIS ECOLE POLYTEC
   [Anonymous], 1981, Inside Computer Understanding Five Programs Plus Miniatures
   Badler N., 2000, AAAI SPRING S
   COSTA M, 2000, SIGGRAPH
   Douville B, 1996, PRESENCE-TELEOP VIRT, V5, P416, DOI 10.1162/pres.1996.5.4.416
   EHMANN SA, 2001, EUROGRAPHICS
   Gibson J., 1979, Perceiving acting, and knowing, P127
   HERT S, 2006, CGAL 3 2 USER REFERN
   JORISSEN P, 2004, 4 INT S SMART GRAPH, P154
   KALLMANN M, 2001, THESIS EPFL SWITZERL
   MOLLET N, 2006, EDUTAINMENT
   NORMAN D, 1988, DESIGN EVERYDAY THIN, P54
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   SANSO RM, 1994, EUROGRAPHICS
   Schaeffer R., 1969, Proceedings of the international conference on properties of nuclear states, DOI 10.3115/990403.990405
NR 15
TC 4
Z9 5
U1 0
U2 1
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 559
EP 569
DI 10.1002/cav.204
PG 11
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 221EU
UT WOS:000250211000034
OA Bronze
DA 2024-07-18
ER

PT J
AU Lee, TY
   Lin, CH
   Chu, HK
   Wang, YS
   Yen, SW
   Tsai, CR
AF Lee, Tong-Yee
   Lin, Chao-Hung
   Chu, Hung-Kuo
   Wang, Yu-Shuen
   Yen, Shoo-Wei
   Tsai, Chang-Rung
TI Mesh pose-editing using examples
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE pose-editing; example mesh; animation; deformation; skeleton
ID METAMORPHOSIS
AB An easy-to-use mesh pose-editing system is presented. We take advantage of both skeleton-based and example-based approaches in order to provide an intuitive way for artists to edit mesh poses. Our system automatically extracts the skeletons of the remaining example models once the skeleton of a reference mesh is constructed. In our editing system the desired skeleton can be easily and naturally posed using an inverse kinematics (IK) algorithm incorporated with searching the optimal weights in the defined skeleton space of examples meshes. Eventually, the desired shape with detailed deformation can be constructed by blending the example meshes. Experimental results show that the proposed system provides an easy and intuitive control on mesh pose-editing. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Comp Graphics Grp, Visual Syst Lab, Tainan 70101, Taiwan.
C3 National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Comp Graphics Grp, Visual Syst Lab, No 1 Ta-Hsueh Rd, Tainan 70101, Taiwan.
EM tonylee@mail.ncku.edu.tw
OI Wang, Yu-Shuen/0000-0003-2550-2990
CR Alexa M, 2002, ACM T GRAPHIC, V21, P380, DOI 10.1145/566570.566592
   Boulic R., 1990, Visual Computer, V6, P344, DOI 10.1007/BF01901021
   Chadwick J. E., 1989, Computer Graphics, V23, P243, DOI 10.1145/74334.74358
   Der KG, 2006, ACM T GRAPHIC, V25, P1174, DOI 10.1145/1141911.1142011
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Guo Z, 2005, COMPUT GRAPH FORUM, V24, P373, DOI 10.1111/j.1467-8659.2005.00862.x
   Huang J, 2006, ACM T GRAPHIC, V25, P1126, DOI 10.1145/1141911.1142003
   IGRASHI T, 2005, ACM SIGGRAPH EUR S C, P107
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   KOGA Y, 1994, COMPUTER GRAPHICS, V28, P395
   Lee TY, 2006, VISUAL COMPUT, V22, P729, DOI 10.1007/s00371-006-0059-6
   Lee TY, 2003, IEEE T VIS COMPUT GR, V9, P85, DOI 10.1109/TVCG.2003.1175099
   LEE TY, 2005, P INT C COMP AN SOC
   Lin CH, 2005, IEEE T VIS COMPUT GR, V11, P2
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Murray RM, 1994, MATH INTRO ROBOTIC M
   Rose CF, 2001, COMPUT GRAPH FORUM, V20, pC239
   SHOEMAKE K, 1992, MATRIC ANIMATION POL, P259
   Sorkine O, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P191, DOI 10.1109/SMI.2004.1314506
   Sorkine O., 2004, P 2004 EUR ACM SIGGR, P179
   Sumner RW, 2005, ACM T GRAPHIC, V24, P488, DOI 10.1145/1073204.1073218
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   VONFUNCK W, 2006, SIGGRAPH COMPUTER GR, P1118
   WANG LCT, 1991, IEEE T ROBOTIC AUTOM, V7, P489, DOI 10.1109/70.86079
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   ZHOU K, 2005, SIGGRAPH 05 ACM SIGG, P496
NR 27
TC 7
Z9 7
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 235
EP 245
DI 10.1002/cav.178
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000003
DA 2024-07-18
ER

PT J
AU Geraerts, R
   Overmars, MH
AF Geraerts, Roland
   Overmars, Mark H.
TI The corridor map method: a general framework for real-time high-quality
   path planning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE path planning; corridor map method; high-quality paths
AB In many virtual environment applications, paths have to be planned for characters to traverse from a start to a goal position in the virtual world while avoiding obstacles. Contemporary applications require a path planner that is fast (to ensure real-time interaction with the environment) and flexible (to avoid local hazards such as small and dynamic obstacles). In addition, paths need to be smooth and short to ensure natural looking motions.
   Current path planning techniques do not obey these criteria simultaneously. For example, A* approaches generate unnatural looking paths, potential field-based methods are too slow, and sampling-based path planning techniques are inflexible. We propose a new technique, the Corridor Map Method (CMM), which satisfies all the criteria. In an off-line construction phase, the CMM creates a system Of collision-free corridors for the static obstacles in an environment. In the query phase, paths can be planned inside the corridors for different types of characters while avoiding dynamic obstacles. Experiments show that high-quality paths for single characters or groups of characters can be obtained in real-time. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Univ Utrecht, Inst Informat & Comp Sci, AGS, NL-3508 TA Utrecht, Netherlands.
C3 Utrecht University
RP Geraerts, R (corresponding author), Univ Utrecht, Inst Informat & Comp Sci, AGS, NL-3508 TA Utrecht, Netherlands.
EM roland@cs.uu.nl
RI Geraerts, Roland/B-3859-2016
OI Geraerts, Roland/0000-0002-8161-579X
CR Amato NM, 1996, IEEE INT CONF ROBOT, P113, DOI 10.1109/ROBOT.1996.503582
   [Anonymous], 2012, Robot Motion Planning
   Barraquand J, 1997, INT J ROBOT RES, V16, P759, DOI 10.1177/027836499701600604
   Bouix S, 2003, PROC CVPR IEEE, P449
   Burgard W., 2005, Principles of Robot Motion: Theory, Algorithms, and Implementations
   Geraerts R, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P4074, DOI 10.1109/IROS.2005.1545605
   Geraerts R, 2004, IEEE INT CONF ROBOT, P2386, DOI 10.1109/ROBOT.2004.1307418
   Geraerts R, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4355, DOI 10.1109/IROS.2006.282009
   Kamphuis A., 2004, SCA '04: Proceedings of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P19
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Khosla P., 1988, Proceedings of IEEE International Conference on Robotics and Automation, P1778, DOI DOI 10.1109/ROBOT.1988.12323
   LaValle S. M., 2006, Planning algorithms
   NIEUWENHUISEN D, 2008, INT C COMP GAM ART I, P285
   RIMON E, 1992, IEEE T ROBOTIC AUTOM, V8, P501, DOI 10.1109/70.163777
   v d Bergen G., 2003, COLLISION DETECTION
   Wein R., 2006, INT WORKSH ALG FDN R
   [No title captured]
NR 17
TC 52
Z9 60
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2007
VL 18
IS 2
BP 107
EP 119
DI 10.1002/cav.166
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 181AO
UT WOS:000247409300004
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Li, TY
   Chen, JR
AF Li, Tsai-Yen
   Chen, Je-Ren
TI Procedural rhythmic character animation: an interactive Chinese lion
   dance
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE rhythmic character animation; motion planning; Chinese lion dance;
   high-level animation control
ID MOTION
AB The creation of a stylistic animation through the use of high-level controls has always been a design goal for computer animation software. In this paper, we propose a procedural animation system, called rhythmic character animation playacting (RhyCAP), which allows a designer to interactively direct animated characters by adjusting rhythmic parameters such as tempo, exaggeration, and timing. The motions thus generated reflect the intention of the director and also adapt to environmental obstacle constraints. We use a sequence of martialart steps in the performance of a Chinese lion dance to illustrate the effectiveness of the system. The animation is generated by composition of common motion elements, concisely represented in an action graph. We have implemented an animation control program that allows Chinese lion dance to be choreographed interactively. This authoring tool also serves as a useful means for preserving this part of world cultural heritage. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Natl Chengchi Univ, Dept Comp Sci, Taipei, Taiwan.
C3 National Chengchi University
RP Li, TY (corresponding author), Natl Chengchi Univ, Dept Comp Sci, 64,Sec 2,Zhi Nan Rd, Taipei, Taiwan.
EM li@nccu.edu.tw
CR [Anonymous], 2012, Robot Motion Planning
   [Anonymous], GLUT OPENGL UTILITY
   [Anonymous], 1985, P 12 ANN C COMP GRAP
   BARRAQUAND J, 1992, IEEE T SYST MAN CYB, V22, P224, DOI 10.1109/21.148426
   BLUMBERG BM, 1995, P SIGGRAPH 95, P47
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   BRUDERLIN A, 1989, P SIGGRAPH 1989 C JU, V23, P233
   Faloutsos P, 2001, COMPUT GRAPH-UK, V25, P933, DOI 10.1016/S0097-8493(01)00171-6
   Hodgins JessicaK., 1995, Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1995, Los Angeles, CA, USA, August 6-11, P71, DOI DOI 10.1145/218380.218414
   HSIEH CH, 2005, P 13 ANN ACM INT C M
   ISLA D, 2001, P 2001 INT JOINT C A
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   KOGA Y, 1994, P SIGGRAPH 94, P395
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   LASSETER J, 1987, P ACM SIGGRAPH, V21, P35
   LI TY, 2003, P 2003 INT C ROB AUT
   Liu CK, 2002, ACM T GRAPHIC, V21, P408, DOI 10.1145/566570.566596
   PARENT R, 2001, COMPUTER ANIMATION A, P10
   Reynolds C. W., 1999, P GAM DEV C, P763
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   ROSE CF, 2001, COMPUT GRAPH FORUM, V20, P239
   Sims K., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P15, DOI 10.1145/192161.192167
   Sun HC, 2001, COMP GRAPH, P261, DOI 10.1145/383259.383288
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   TSENG GC, 1997, ART LION DANCE
   Urtasun R, 2004, COMPUT GRAPH FORUM, V23, P799, DOI 10.1111/j.1467-8659.2004.00809.x
   vandePanne M, 1997, COMPUT GRAPH FORUM, V16, P211, DOI 10.1111/1467-8659.00181
   MIDIIO CROSS PLATFOR
   OPEN INVENTOR OBJECT
   SOGLUT RENDERAREA
   2003, M WEBSTERS COLLEGIAT
NR 33
TC 1
Z9 1
U1 2
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2006
VL 17
IS 5
BP 551
EP 564
DI 10.1002/cav.154
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 111UX
UT WOS:000242481700005
DA 2024-07-18
ER

PT J
AU Hsieh, CM
   Luciani, A
AF Hsieh, Chi-Min
   Luciani, Annie
TI Minimal dynamic modeling for dance verbs
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE physically based particle modeling; dance verbs; free dance
ID ANIMATION
AB As quoting in the philosophy of free dance: 'understanding the directions for a free dance performer steins mainly from the qualities and energy of the movement rather from spatial criteria, 'we advocate generating computing dance movement by dynamic and energy. In this paper, we present a set of dynamic models according to dance verbs: 'to sway,' 'to squat down,' 'to develop,' 'to walk,' 'to turn,' and 'half turn step over step.' For each of them, we designed the simplest physically based particle model. Among them, user has a high-level motion control to modify the quality of such dynamically generated movement for example, light, strong, sudden, sustained, etc. These dynamic models are hence well suited to produce spontaneous motion that looks natural and plausible. Furthermore, by designing dance movement only With the necessary minimal models, it is possible to produce complex dance movement that exhibits energetic consistency as underlain by the philosophy of free dance. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Inst Natl Polytechn Grenoble, Lab ACROE, Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble
RP Hsieh, CM (corresponding author), Inst Natl Polytechn Grenoble, Lab ACROE, Grenoble, France.
EM chimin.hsieh@imag.fr
CR [Anonymous], 1993, P SIGGRAPH 93, P335
   [Anonymous], PARTICLE MODELING
   ARNOUX N, 1997, HIST CULTURELLE SPOR
   BADLER N, 1989, DANCE TECHNOLOGY CUR
   BADLER NI, 1979, COMPUT SURV, V11, P19, DOI 10.1145/356757.356760
   BISHKO L, 1992, DANCE TECHNOLOGY, V1, P1
   BODAK S, 2001, MEMOIRE VIVE HERITAG
   Calvert T, 2005, IEEE COMPUT GRAPH, V25, P6, DOI 10.1109/MCG.2005.33
   CI D, 2000, P SIGGRAPH 00, P173
   DESOYE S, 1991, VERBES DANSE
   EVRARD M, 2006, P CASA
   HERBISONEVANS D, 1991, 422 U SYDN BASS DEP
   Laban Rudolf., 1974, Effort: Economy in Body Movement, V2nd
   Laws K., 1984, PHYS DANCE
   Laws Kenneth, 1994, PHYS DANCE PAS DEUX
   Laws Kenneth., 2002, Physics and the Art of Dance: Understanding Movement
   LUCIANI A, 1991, P EUR 91 VIENN AUSTR
   Multon F, 1999, J VISUAL COMP ANIMAT, V10, P39, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<39::AID-VIS195>3.0.CO;2-2
   Neagle R.J, 2004, P AISB 2004 LANG SPE, P86
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   vandePanne M, 1997, COMPUT GRAPH FORUM, V16, P211, DOI 10.1111/1467-8659.00181
   VANDEPANNE M, 1994, GRAPH INTER, P208
NR 22
TC 3
Z9 3
U1 1
U2 1
PU WILEY-BLACKWELL
PI MALDEN
PA COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 359
EP 369
DI 10.1002/cav.139
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400022
DA 2024-07-18
ER

PT J
AU Lee, TY
   Lin, PH
   Yan, SU
   Lin, CH
AF Lee, TY
   Lin, PH
   Yan, SU
   Lin, CH
TI Mesh decomposition using motion information from animation sequences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE mesh decomposition; PCA; motion complexity; motion similarity;
   compression
ID SURFACE DECOMPOSITION; METAMORPHOSIS
AB In computer graphics, mesh decomposition is a fundamental problem and it can benefit many applications. In this paper, we propose a novel mesh decomposition algorithm using motion information derived from a given animation sequence. The proposed algorithm first use principal component analysis (PCA) to construct a compact representation of a given animation sequence. Next, from this representation, we derive several motion parameters including motion complexity and similarity. Finally, we decompose a given mesh into sub-meshes using derived motion information and subdivide the triangles along the cutting paths for the smoother borders between the mesh parts. Our experimental results show that this new decomposition scheme can bring the benefit of good compression ratios on animation sequences. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Comp Graph Grp, Visual Syst Lab, Tainan 70101, Taiwan.
C3 National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Comp Graph Grp, Visual Syst Lab, Tainan 70101, Taiwan.
EM tonylee@mail.ncku.edu.tw
CR ALEXA M, 2002, EURO GRAPHICS 02, P411
   FUNKHOUSER T, 2004, SIGGRAPH 04 P, P649
   Garland M., 2001, I3D 01, P49, DOI [DOI 10.1145/364338.364345, 10.1145/364338.364345]
   Gregory A, 1999, VISUAL COMPUT, V15, P453, DOI 10.1007/s003710050192
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Lee TY, 2003, IEEE T VIS COMPUT GR, V9, P85, DOI 10.1109/TVCG.2003.1175099
   Lee Y, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P279
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Lin CH, 2005, IEEE T VIS COMPUT GR, V11, P2
   Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348
   Razdan A, 2003, COMPUT AIDED DESIGN, V35, P783, DOI 10.1016/S0010-4485(02)00101-X
   Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307
   SANDER PV, 2003, P EUR ACM SIGGRAPH S, P146
   Shamir A, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P82
   Shlafman S, 2002, COMPUT GRAPH FORUM, V21, P219, DOI 10.1111/1467-8659.00581
   Zöckler M, 2000, VISUAL COMPUT, V16, P241, DOI 10.1007/PL00013396
   Zuckerberger E, 2002, COMPUT GRAPH-UK, V26, P733, DOI 10.1016/S0097-8493(02)00128-0
NR 19
TC 19
Z9 20
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 519
EP 529
DI 10.1002/cav.79
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000034
DA 2024-07-18
ER

PT J
AU Park, B
   Chung, HJ
   Nishita, T
   Shin, SY
AF Park, B
   Chung, HJ
   Nishita, T
   Shin, SY
TI A feature-based approach to facial expression cloning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE facial animation; virtual humans and avatars; motion retargeting;
   emotions and personality
AB In this paper, we present a feature-based approach to cloning facial expressions from an input face model to an output model, using predefined source key-models and the corresponding target key-models. Adopting a scattered data interpolation technique, our approach consists of two parts: analysis of face key-models and synthesis of facial expressions. In the analysis part carried out once at the beginning, key-models are segmented automatically into five regions, each containing one of five facial features, that is, eyes, cheeks, and the mouth, which give rise to five sets of source key-shapes and the corresponding sets of target key-shapes. Using the key-shapes of each source feature, those of the corresponding target feature are parameterized. In the synthesis part, given a sequence of face models comprising an input animation, five output features are obtained separately by blending their own target key-shapes. These separately produced features are combined to synthesize the output face model at each frame. Our feature-based approach enables cloning of diverse expressions including asymmetric ones convincingly with a small number of face key-models while exhibiting an on-line, real-time performance. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Korea Adv Inst Sci & Technol, TCLab, Dept Elect Engn & Comp Sci, Taejon 305701, South Korea.
   Univ Tokyo, Dept Complex Sci & Engn, Tokyo, Japan.
   Univ Tokyo, Dept Informat Sci, Tokyo, Japan.
C3 Korea Advanced Institute of Science & Technology (KAIST); University of
   Tokyo; University of Tokyo
RP Korea Adv Inst Sci & Technol, TCLab, Dept Elect Engn & Comp Sci, 373-1 Guseong Dong, Taejon 305701, South Korea.
EM onion@jupiter.kaist.ac.kr
RI Shin, Sung Yong/C-1955-2011
CR [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], 2002, MPEG4 FACIAL ANIMATI
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   BUCK I, 2000, P S NONPHOT AN REND
   Choe B, 2001, J VISUAL COMP ANIMAT, V12, P67, DOI 10.1002/vis.246
   CHUANG E., 2002, PERFORMANCE DRIVEN F
   Ekman P., 2003, UNMASKING FACE GUIDE
   Ezzat T, 1998, COMP ANIM CONF PROC, P96, DOI 10.1109/CA.1998.681913
   Fidaleo D, 2004, COMPUT ANIMAT VIRT W, V15, P15, DOI 10.1002/cav.4
   FIDALEO D, 2000, P INT WORKSH DIG COM
   FISHER CG, 1968, J SPEECH HEAR RES, V11, P796, DOI 10.1044/jshr.1104.796
   Haralick R.M., 1983, FUNDAMENTALS COMPUTE, P209
   JOSHI P, 2003, 2003 ACM SIGGRAPH EU, P187
   Kleiser J., 1989, SIGGRAPH'89 Course Notes 22: State of the Art in Facial Animation
   Kouadio C, 1998, COMP ANIM CONF PROC, P128, DOI 10.1109/CA.1998.681917
   Lee J, 1999, COMP GRAPH, P39
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Park SI, 2004, COMPUT ANIMAT VIRT W, V15, P125, DOI 10.1002/cav.15
   Park SI., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. SCA2, P105, DOI DOI 10.1145/545261.545279
   Parke F., 1996, COMPUTER FACIAL ANIM
   PARKS DA, 1982, GASTROENTEROLOGY, V82, P9
   Pighin F., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P143, DOI 10.1109/ICCV.1999.791210
   PYUN H, 2003, 2003 ACM SIGGR EUR S, P167
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   SLOAN PPJ, 2001, 2001 ACM S INT 3D GR, P135
   Young AW, 1997, COGNITION, V63, P271, DOI 10.1016/S0010-0277(97)00003-6
NR 29
TC 5
Z9 10
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 291
EP 303
DI 10.1002/cav.81
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000015
DA 2024-07-18
ER

PT J
AU Qiu, J
   Seah, HS
   Tian, F
   Chen, Q
   Wu, ZL
AF Qiu, J
   Seah, HS
   Tian, F
   Chen, Q
   Wu, ZL
TI Enhanced auto coloring with hierarchical region matching
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE hierarchy; region matching; auto coloring; 2D animation
AB This paper proposes a Hierarchical Region Matching (HRM) approach for computer-assisted auto coloring. The region-level analysis in traditional 2D animation is expanded into several component levels with a novel hierarchization method. With the hierarchy, various region matching algorithms can be applied from the first/highest to the last/lowest component level. HRM improves the matching accuracy and may deal with matching errors caused by occlusion, thus making the matching more robust, as verified by the results. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Nanyang Technol Univ, Ctr Adv Media Technol, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Ctr Adv Media Technol, Nanyang Ave, Singapore 639798, Singapore.
EM qiujie@pmail.ntu.edu.sg
RI Seah, Hock Soon/AAK-9900-2020
OI Seah, Hock Soon/0000-0003-2699-7147
CR Chang CW, 1997, J VISUAL COMP ANIMAT, V8, P165, DOI 10.1002/(SICI)1099-1778(199707)8:3<165::AID-VIS157>3.0.CO;2-2
   DURAND CX, 1991, P ACM SIGGRAPH, P285
   HU L, 2003, ANIMATION TECHNIQUES, V1
   LIUYU S, 1992, P 11 IAPR INT C IM S, V3, P569
   Madeira JS, 1996, VISUAL COMPUT, V12, P1
   Nasr N, 2002, 20TH EUROGRAPHICS UK CONFERENCE, PROCEEDINGS, P145, DOI 10.1109/EGUK.2002.1011284
   Patmore C., 2003, The complete animation course, V2nd
   QING Y, 2002, P 16 INT C PATT REC, V2, P282
   Qiu J, 2004, PROCEEDINGS OF THE SEVENTH IASTED INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND IMAGING, P26
   Qiu J, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P175
   Seah HS, 2000, VISUAL COMPUT, V16, P289, DOI 10.1007/s003719900068
   Yu MP, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P401, DOI 10.1109/ISIMP.2001.925418
NR 12
TC 10
Z9 11
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 463
EP 473
DI 10.1002/cav.86
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000029
DA 2024-07-18
ER

PT J
AU Baxter, W
   Liu, YX
   Lin, MC
AF Baxter, W
   Liu, YX
   Lin, MC
TI A viscous paint model for interactive applications
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE non-photorealistic rendering; painting systems; simulation of
   traditional graphical styles
AB We present a viscous paint model for use in an interactive painting system based on the well-known Stokes' equations for viscous flow. Our method is, to our knowledge, the first unconditionally stable numerical method that treats viscous fluid with a free surface boundary. We have also developed a real-time implementation of the Kubelka-Munk reflectance model for pigment mixing, compositing and rendering entirely on graphics hardware, using programmable fragment shading capabilities. We have integrated our paint model with a prototype painting system, which demonstrates the model's effectiveness in rendering viscous paint and capturing a thick, impasto-like style of painting. Several users have tested our prototype system and were able to start creating original art work in an intuitive manner not possible with the existing techniques in commercial systems. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27514 USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27514 USA.
EM baxter@cs.unc.edu
CR [Anonymous], 2002, SURFACES
   Baxter B, 2001, COMP GRAPH, P461, DOI 10.1145/383259.383313
   Carlson M., 2002, ACM SIGGRAPH/Eurographics Symp. Comp. Anim, P167
   CHEN JX, 1995, GRAPH MODEL IM PROC, V57, P107, DOI 10.1006/gmip.1995.1012
   Cockshott T., 1992, Computer Graphics Forum, V11, pC217, DOI 10.1111/1467-8659.1130217
   Curtis C. J., 1997, Proceedings of the 24th annual conference on Computer graphics and interactive techniques, P421
   Dorsey J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P387, DOI 10.1145/237170.237278
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Golub G. H., 1983, MATRIX COMPUTATIONS
   GRIEBEL M, 1990, NUMERICAL SIMULATION
   HAASE CS, 1992, ACM T GRAPHIC, V11, P305, DOI 10.1145/146443.146452
   HARLOW FH, 1965, J PHYSICS FLUIDS, V8, P12
   Hirt C., 1968, JCP, V2, P403
   HIRT CW, 1981, J COMPUT PHYS, V39, P201, DOI 10.1016/0021-9991(81)90145-5
   Kass M., 1990, P SIGGRAPH, P49
   KUBELKA P, 1948, J OPT SOC AM, V38, P448, DOI 10.1364/JOSA.38.000448
   KUBELKA P, 1954, J OPT SOC AM, V44, P330, DOI 10.1364/JOSA.44.000330
   Kubelka P., 1931, Z TECH PHYS, V12, P259, DOI DOI 10.4236/MSCE.2014.28004
   LI W, 2003, P COMPUTER ANIMATION
   NICHOLS BD, 1971, J COMPUT PHYS, V8, P434, DOI 10.1016/0021-9991(71)90022-2
   OBrien J.F., 1995, Proceedings of the Computer Animation, P198
   SHEWCHUK J, 1994, CMUCSTR94125 CARN ME
   SMITH AR, 1978, PAINT TM7
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
NR 27
TC 17
Z9 23
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 433
EP 441
DI 10.1002/cav.47
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700034
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yahia-Cherif, L
   Gilles, B
   Molet, T
   Magnenat-Thalmann, N
AF Yahia-Cherif, L
   Gilles, B
   Molet, T
   Magnenat-Thalmann, N
TI Motion capture and visualization of the hip joint with dynamic MRI and
   optical systems
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE hip joint; anatomical modelling; optical motion capture; dynamic MRI
AB We present a methodology for motion tracking and visualization of the hip joint by combining MR images and optical motion capture systems. MRI is typically used to capture the subject's anatomy while optical systems are used to capture and analyse the relative movement between adjacent bones of the joint. Reflective markers are attached to the subject's skin and their trajectories are tracked and processed. However, the skin surface deforms while in motion due to muscle contraction leading to significant errors in the estimation of trajectories. In order to reduce these errors, we use MR images to capture both the anatomy and the trajectories of the bone. Prior to the scanning, we attach skin markers to the subject in order to analyse the markers displacements relative to the bone. We reconstruct the anatomical models of the subject and we compute the markers trajectories from the images. Using these calculated trajectories, we select the best markers configuration based on the criteria of markers displacements. The optimized configuration is used for recording external movements with the optical motion capture system. The resulting animation is mapped onto the virtual body of the subject including internal bones and the joint motion is visualized. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Geneva, MIRALab, CH-1211 Geneva, Switzerland.
C3 University of Geneva
RP Univ Geneva, MIRALab, 24 Rue Gen-Dufour, CH-1211 Geneva, Switzerland.
EM yahia@miralab.unige.ch
RI Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Nadia/0000-0002-1459-5960
CR BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Holden M, 2000, IEEE T MED IMAGING, V19, P94, DOI 10.1109/42.836369
   KANG M, 2003, HIP JOINT MODELING C
   Kang MJ, 2002, COMP ANIM CONF PROC, P215, DOI 10.1109/CA.2002.1017539
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Lotjonen J., 2001, International Journal of Bioelectromagnetism, V3, P37
   MAGNENATTHALMAN.N, 2002, P IEEE COMP GRAPH IN
   Molet T, 1999, PRESENCE-VIRTUAL AUG, V8, P187, DOI 10.1162/105474699566161
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   PONDER M, 2003, VHD DEV FRAMEWORK EX
   Rohr K, 1996, LECT NOTES COMPUT SC, V1131, P297, DOI 10.1007/BFb0046967
   SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010
   Seo Hyewon., 2003, Proceedings of the 2003 Symposium on Interactive 3D Graphics, P19, DOI [10.1145/641480.641487, DOI 10.1145/641480.641487]
   YAHIACHERIF L, 2004, 8 INT S 3D AN HUM MO
NR 15
TC 11
Z9 13
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 377
EP 385
DI 10.1002/cav.41
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700028
DA 2024-07-18
ER

PT J
AU Xu, YX
   Liu, SG
AF Xu, Yixin
   Liu, Shiguang
TI Botanical-based simulation of color change in fruit ripening: Taking
   tomato as an example
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE botanical-based simulation; color; fruit ripening; gene; pigment
ID LYCOPENE
AB The color change of plant fruit in ripening is a typical time-varying phenomenon involving various factors. Due to its complexity and biodiversity, it is challenging to model this phenomenon. To address this issue, we take the tomato as an example and propose a botanical-based framework considering variety, environment, phytohormone, and genes to simulate fruit color change during the ripening process. Specifically, we propose a first-order kinetic model that integrates varietal, environmental, and phytohormonal factors to represent the variation of pigment concentrations in the pericarp. Moreover, we introduce a logistic model to describe the change in pigment concentration in the epidermis. Based on the gene expression pathway of tomato color in botany, we propose a genotype-to-phenotype simulation method to represent its biodiversity. An improved method is proposed to convert pigment concentrations into color accurately. Furthermore, we propose a gradient descent-based method to assist the user in quickly setting pigment concentration parameters. Experiments verified that the proposed framework can simulate a wide range of tomato colors. Both qualitative and quantitative experiments validated the proposed method. Furthermore, our framework can be applied to more fruits.
   This paper proposes a botanical-based framework considering variety, environment, phytohormone, and genes to simulate fruit color change during the ripening process. We present a first-order kinetic model and a logistic model to represent the pigment concentration variations in the pericarp and epidermis, respectively. We propose a gradient descent-based method that can quickly match the target color with the multiple pigment concentrations involved.image
C1 [Xu, Yixin; Liu, Shiguang] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
   [Xu, Yixin] Tianjin Acad Agr Sci, Informat Inst, Tianjin, Peoples R China.
   [Liu, Shiguang] Tianjin Univ, Coll Intelligence & Comp, 135,Yaguan Rd, Tianjin 300350, Peoples R China.
C3 Tianjin University; Tianjin Academy of Agricultural Sciences; Tianjin
   University
RP Liu, SG (corresponding author), Tianjin Univ, Coll Intelligence & Comp, 135,Yaguan Rd, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Abbey D., UNPUB
   Abdul-Hammed M, 2022, PHYS CHEM RES, V10, P151, DOI 10.22036/pcr.2021.283758.1916
   Alenazi MM, 2020, SAUDI J BIOL SCI, V27, P1467, DOI 10.1016/j.sjbs.2020.03.026
   Alsweis M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1723
   Annpomah-Dwamena C, 2012, J EXP BOT, V63, P4497, DOI 10.1093/jxb/ers134
   [Anonymous], 1989, JAP C BIOCH LIP
   Bertie JE., 2006, GLOSSARY TERMS USED, V1, P1
   BISOGNI CA, 1976, J FOOD SCI, V41, P333, DOI 10.1111/j.1365-2621.1976.tb00612.x
   BlenderNation, 2022, BLENDER
   Braitmaier M, 2004, THEORY AND PRACTICE OF COMPUTER GRAPHICS 2004, PROCEEDINGS, P152, DOI 10.1109/TPCG.2004.1314465
   Carrillo-López A, 2014, J FOOD SCI TECH MYS, V51, P2720, DOI 10.1007/s13197-012-0782-0
   Chattopadhyay T, 2021, PLANT CELL REP, V40, P767, DOI 10.1007/s00299-020-02650-9
   Chen AJ, 2021, PEERJ, V9, DOI 10.7717/peerj.11504
   Chi Xiao-Yu, 2009, Journal of Software, V20, P702, DOI 10.3724/SP.J.1001.2009.03299
   Cirdei B., 2018, ACM SIGGRAPH 2018
   Dai S., 2006, THESIS SICHUAN U
   Desbenoit B., 2006, EG SHORT PAPERS, P1
   España L, 2014, PLANT PHYSIOL, V166, P1371, DOI 10.1104/pp.114.246405
   Fan DF, 2013, 2013 INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND VISUALIZATION (ICVRV 2013), P199, DOI 10.1109/ICVRV.2013.38
   Frenkel C, 2012, J FOOD SCI, V77, pS365, DOI 10.1111/j.1750-3841.2012.02910.x
   Fu XP, 2016, FOOD ANAL METHOD, V9, P2501, DOI 10.1007/s12161-016-0440-7
   Guennebaud G., 2010, Eigen
   Jakob W., 2022, Mitsuba 3 Renderer
   Jeong S, 2013, COMPUT GRAPH FORUM, V32, P204, DOI 10.1111/cgf.12009
   Jiao SH, 2012, IEEE COMPUT GRAPH, V32, P78, DOI 10.1109/MCG.2011.34
   Kider JT, 2011, COMPUT GRAPH FORUM, V30, P257, DOI 10.1111/j.1467-8659.2011.01857.x
   Kim J, 2013, COMPUT ANIMAT VIRT W, V24, P237, DOI 10.1002/cav.1506
   Li JF, 2015, COMPUT ANIMAT VIRT W, V26, P433, DOI 10.1002/cav.1647
   Lichtenthaler HK., 2001, CURR PROTOCOL FOOD A, V1, pF4.3.1, DOI 10.1002/0471142913.faf0403s01
   Liu YQ, 2012, COMPUT ANIMAT VIRT W, V23, P395, DOI 10.1002/cav.1459
   Lu ShengLian Lu ShengLian, 2014, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V45, P250
   Matsushita M, 1999, PHYSICA A, V274, P190, DOI 10.1016/S0378-4371(99)00328-3
   Mimura M, 2000, PHYSICA A, V282, P283, DOI 10.1016/S0378-4371(00)00085-6
   Mochizuki S., 2005, ACM SIGGRAPH 2005 PO, P39
   Peng F, 2019, COMPUT ELECTRON AGR, V157, P146, DOI 10.1016/j.compag.2018.12.045
   Qian YL, 2019, GRAPH MODELS, V103, DOI 10.1016/j.gmod.2019.101029
   Ringer T, 2021, J FOOD MEAS CHARACT, V15, P4426, DOI 10.1007/s11694-021-01009-2
   Rosa-Martínez E, 2023, FRONT PLANT SCI, V14, DOI 10.3389/fpls.2023.1135237
   Skolik P, 2019, BMC PLANT BIOL, V19, DOI 10.1186/s12870-019-1852-5
   Sun CL, 2020, MOL PLANT, V13, P42, DOI 10.1016/j.molp.2019.10.010
   Tadmor Y, 2010, J AGR FOOD CHEM, V58, P10722, DOI 10.1021/jf1021797
   Wang HJ, 2020, FOOD CHEM, V333, DOI 10.1016/j.foodchem.2020.127439
   Wang IR, 2004, COMPUT ANIMAT VIRT W, V15, P237, DOI 10.1002/cav.26
   Wang JP, 2006, ACM T GRAPHIC, V25, P754, DOI 10.1145/1141911.1141951
   Yang MX, 2022, FORESTS, V13, DOI 10.3390/f13040616
   Yoo HJ, 2017, MOLECULES, V22, DOI 10.3390/molecules22050764
   Zechmeister L, 1943, J AM CHEM SOC, V65, P1940, DOI 10.1021/ja01250a039
   Zhou N., 2006, 2006 2 INT S PLANT G
   Zhou N., 2007, MODELING VISUALIZATI
NR 49
TC 0
Z9 0
U1 3
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2225
EA NOV 2023
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001115272100001
DA 2024-07-18
ER

PT J
AU Ren, JW
   Lin, HW
AF Ren, Jingwen
   Lin, Hongwei
TI Nonlinear cloth simulation with isogeometric analysis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cloth simulation; isogeometric analysis; nonlinear elasticity;
   physically based simulation
AB Physically based cloth simulation with nonlinear behaviors is studied in this article by employing isogeometric analysis (IGA) for the surface deformation in 3D space. State-of-the-art simulation techniques, which primarily rely on the triangular mesh to calculate physical points on the cloth directly, require a large number of degrees of freedom. An effective method for the cloth deformation that employs high-order continuous B-spline surfaces dependent on control points is proposed. This method leads to the merit of fewer degrees of freedom and superior smoothness. The deformation gradient on the high-order IGA element is then represented by the gradient of the B-spline function. An iterative method for solving the nonlinear optimization transferred from the implicit integration and a direct implicit-explicit method are derived on the basis of elastic force calculation to improve efficiency. The knots of the representation are effectively utilized in collision detection and response to reduce the computational burden. Experiments of nonlinear cloth simulation demonstrate the superiority of the proposed method considering performance and efficiency, achieving accurate, efficient, and stable deformation.
   This article presents a continuum-based nonlinear cloth simulation method employing isogeometric analysis for the surface deformation in 3D space. The proposed algorithm achieves better performance with fewer DoFs than state-of-the-art models in terms of time efficiency and smoothness, and enables efficient collision detection and response. image
C1 [Ren, Jingwen; Lin, Hongwei] Zhejiang Univ, Sch Math Sci, Hangzhou, Zhejiang, Peoples R China.
   [Lin, Hongwei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Lin, HW (corresponding author), Zhejiang Univ, Sch Math Sci, Hangzhou, Zhejiang, Peoples R China.
EM hwlin@zju.edu.cn
OI Ren, Jingwen/0000-0003-2407-1420; Lin, Hongwei/0000-0002-9337-9624
FU National Natural Science Foundation of China;  [62272406];  [61872316]
FX This work is supported by the National Natural Science Foundation of
   China under Grant nos. 62272406 and 61872316.
CR Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bender J., 2017, P EUR ASS COMP GRAPH, DOI DOI 10.2312/EGT.20171034
   BERGOU M, 2006, P 4 EUR S GEOM PROC, P227
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Chen L, 2021, J COMPUT SCI TECH-CH, V36, P478, DOI 10.1007/s11390-021-1331-y
   Chen M, 2010, VISUAL COMPUT, V26, P853, DOI 10.1007/s00371-010-0467-5
   Dinev D, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3153420
   Fung Y. C., 1981, Biomechanics. Mechanical properties of living tissues
   Goldenthal R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239500
   Hughes TJR, 2005, COMPUT METHOD APPL M, V194, P4135, DOI 10.1016/j.cma.2004.10.008
   Kim T, 2020, COMPUT GRAPH FORUM, V39, P171, DOI 10.1111/cgf.14111
   Les P., 1997, NURBS BOOK
   Li C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417763
   Li YF, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3527660
   Liu TT, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2990496
   Liu TT, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508406
   Lu J, 2014, COMPUT METHOD APPL M, V268, P475, DOI 10.1016/j.cma.2013.09.016
   Macosko C.W., 1994, Rheology Principles, Measurements, and Applications
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Narain R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366171
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Newmark NM, 1959, J.Eng. Mech. Div., V85, P67, DOI [10.1061/JMCEA3.0000098, DOI 10.1061/JMCEA3.0000098]
   Ogden R. W., 1984, Non-linear elastic deformations, DOI 10.1016/0264-682X(84)90061-3
   Overby M, 2017, IEEE T VIS COMPUT GR, V23, P2222, DOI 10.1109/TVCG.2017.2730875
   Pascal V., 2009, ACM T GRAPHIC, V28, p7.1
   Peng X, 2023, CMES-COMP MODEL ENG, V134, P1837, DOI 10.32604/cmes.2022.022367
   PROVOT X, 1995, GRAPH INTER, P147
   Serpa YR, 2020, COMPUT GRAPH FORUM, V39, P436, DOI 10.1111/cgf.13884
   Shin SG, 2020, COMPUT METHOD APPL M, V362, DOI 10.1016/j.cma.2020.112871
   Sifakis E, 2012, ACM SIGGRAPH 2012 CO, DOI [10.1145/2343483.2343501, DOI 10.1145/2343483.2343501]
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   van den Bergen G., 1997, Journal of Graphics Tools, V2, P1, DOI 10.1080/10867651.1997.10487480
   Wang HM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980236
   Wang HM, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818063
   Wang ZD, 2018, COMPUT GRAPH FORUM, V37, P131, DOI 10.1111/cgf.13554
   Wirtz Andreas, 2020, Procedia CIRP, V88, P270, DOI 10.1016/j.procir.2020.05.047
NR 36
TC 0
Z9 0
U1 5
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2204
EA AUG 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JG4S4
UT WOS:001151993100001
DA 2024-07-18
ER

PT J
AU Shit, S
   Das, DK
   Ray, DN
   Roy, B
AF Shit, Sahadeb
   Das, Dibyendu Kumar
   Ray, Dip Narayan
   Roy, Bappadittya
TI An encoder-decoder based CNN architecture using end to end dehaze and
   detection network for proper image visualization and detection
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE artificial intelligence; convolutional neural network; intelligent
   transportation system; object detection; sensor networks; surveillance
   monitor
AB Industrial sectors are reinventing in automation, stability, and robustness due to the rapid development of artificial intelligence technologies, resulting in significant increases in quality and production. Visual-based sensor networks capture various views of the surrounding environment and are used to monitor industrial and transportation sectors. However, due to unclean suspended air particles that damage the whole monitoring and transportation systems, the visual quality of the images is degraded under adverse weather conditions. This research proposed a convolutional neural network-based image dehazing and detection approach, called end to end dehaze and detection network (EDD-N), for proper image visualization and detection. This network is trained on real-time hazy images that are directly used to recover dehaze images without a transmission map. EDD-N is robust, and accuracy is higher than any other proposed model. Finally, we conducted extensive experiments using real-time foggy images. The quantitative and qualitative evaluations of the hazy dataset verify the proposed method's superiority over other dehazing methods. Moreover, the proposed method validated real-time object detection tasks in adverse weather conditions and improved the intelligent transportation system.
C1 [Shit, Sahadeb; Das, Dibyendu Kumar; Ray, Dip Narayan] CSIR, Cent Mech Engn Res Inst, Durgapur 713209, India.
   [Shit, Sahadeb; Das, Dibyendu Kumar; Ray, Dip Narayan] Acad Sci & Innovat Res, Ghaziabad 201002, India.
   [Roy, Bappadittya] VIT AP Univ, Sch Elect Engn, Amaravati, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Mechanical Engineering Research Institute (CMERI); Academy of
   Scientific & Innovative Research (AcSIR); VIT-AP University
RP Roy, B (corresponding author), VIT AP Univ, Sch Elect Engn, Amaravati, India.
EM bappadittya13@gmail.com
CR Bhola A, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01173-x
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chakrabarty N, 2013, PROCD SOC BEHV, V104, P1048, DOI 10.1016/j.sbspro.2013.11.200
   Chen ZH, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2061
   Das DK, 2022, VISUAL COMPUT, V38, P3803, DOI 10.1007/s00371-021-02222-2
   Das DK., 2022, ADV INTELLIGENT SYST, V1373, DOI [10.1007/978-981-16-4369-9_7, DOI 10.1007/978-981-16-4369-9_7]
   Fang S, 2014, OPT EXPRESS, V22, P19523, DOI 10.1364/OE.22.019523
   Gao SH, 2021, PROC CVPR IEEE, P8665, DOI 10.1109/CVPR46437.2021.00856
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jia Z, 2012, MACH VISION APPL, V23, P1059, DOI 10.1007/s00138-012-0416-6
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim SE, 2020, IEEE T IMAGE PROCESS, V29, P1985, DOI 10.1109/TIP.2019.2948279
   Kingma D. P., 2014, arXiv
   Li CY, 2020, IEEE T MULTIMEDIA, V22, P704, DOI 10.1109/TMM.2019.2933334
   Li SY, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01248-9
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Moghimi MK, 2021, J REAL-TIME IMAGE PR, V18, P1509, DOI 10.1007/s11554-020-01052-0
   Paszke A., 2019, ADV NEURAL INFORM PR, P8026, DOI DOI 10.48550/ARXIV.1912.01703
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Raikwar SC, 2020, IEEE T IMAGE PROCESS, V29, P4832, DOI 10.1109/TIP.2020.2975909
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schechner YY., 2006, P IEEE COMPUTER SOC, P17
   Sharma PK, 2021, VISUAL COMPUT, V37, P2083, DOI 10.1007/s00371-020-01971-w
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Ullah H, 2021, IEEE T IMAGE PROCESS, V30, P8968, DOI 10.1109/TIP.2021.3116790
   Wu QB, 2020, IEEE T IMAGE PROCESS, V29, P1788, DOI 10.1109/TIP.2019.2942504
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang YZ, 2022, VISUAL COMPUT, V38, P2647, DOI 10.1007/s00371-021-02143-0
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
   Zhang SD, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01082-5
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhou JJ, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P243, DOI 10.1109/IMSNA.2013.6743260
   Zhou Y, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2011
NR 39
TC 4
Z9 4
U1 5
U2 25
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2147
EA FEB 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HA0P8
UT WOS:000928813500001
DA 2024-07-18
ER

PT J
AU Schröder-Dering, C
   Zachmann, G
   Weller, R
AF Schroeder-Dering, Christoph
   Zachmann, Gabriel
   Weller, Rene
TI Dynparity: Dynamic disparity adjustment to avoid stereo window
   violations on stationary stereoscopic displays
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE stereo window violation; stereoscopic 3D; user studies; visual
   discomfort
ID 3D
AB We propose a novel method to avoid stereo window violations at screen borders. These occur for objects in front of the zero parallax plane, which appear in front of the (physical) screen, and that are clipped for one eye while still being visible for the other eye. This contradicts other stereo cues, particularly disparity, potentially resulting in eye strain and simulator sickness. In interactive and dynamic virtual environments, where the user controls the camera, for example, via head tracking, it is impossible to avoid stereo window violations completely. We propose Dynparity, a novel rendering method to eliminate the conflict between clipping and negative disparity, by introducing a nonuniform stereoscopic projection. For each vertex in front of the zero parallax plane, we compute the stereoscopic projection such that the parallax approaches zero toward the edge of the screen. Our approach works entirely on the GPU in real-time and can be easily included in modern game engines. We conducted a user study comparing our method to the standard stereo projection on a large-screen stereo wall with head tracking. Our results show significantly reduced simulator sickness when using Dynparity compared to the standard stereo rendering.
C1 [Schroeder-Dering, Christoph; Zachmann, Gabriel; Weller, Rene] Univ Bremen, Comp Graph & Virtual Real, Bremen, Germany.
C3 University of Bremen
RP Schröder-Dering, C (corresponding author), Univ Bremen, Comp Graph & Virtual Real, Bremen, Germany.
EM schroeder.c@uni-bremen.de
RI Zachmann, Gabriel/AAI-9685-2020
OI Zachmann, Gabriel/0000-0001-8155-1127; Schroder-Dering,
   Christoph/0000-0003-0722-9222
FU Projekt DEAL
FX We would like to thank Olaf Schmidt-Kiy from the Fielmann Akademie
   Schloss Plon for helping us with the study by providing the Titmus Fly
   Test. Open Access funding enabled and organized by Projekt DEAL.
CR [Anonymous], 2012, Recommendation ITU-R P. 684-6: Prediction of Field Strength at Frequencies below about 150 kHz
   [Anonymous], 2014, IEEE MTT S INT MICRO, DOI DOI 10.1109/TVT.2014.2345415
   Avan E, 2022, COMPUT GRAPH-UK, V102, P390, DOI 10.1016/j.cag.2021.09.016
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.00098, 10.1109/VRW50115.2020.0-178]
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Bruder G, 2016, PRESENCE-TELEOP VIRT, V25, P1, DOI 10.1162/PRES_a_00241
   Celikcan U, 2013, VISUAL COMPUT, V29, P685, DOI 10.1007/s00371-013-0804-6
   Chen MJ, 2012, IEEE IMAGE PROC, P617, DOI 10.1109/ICIP.2012.6466935
   Deutschen Ophthalmologischen, 2008, EMPF DTSCH OPHTH GES
   Devisme C, 2008, VISION RES, V48, P753, DOI 10.1016/j.visres.2007.12.003
   Didyk P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964991
   Geng Sun, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7237, DOI 10.1117/12.807136
   Hirzle T, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445361
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Ide K., 2010, 3DTV C TRUE VIS CAPT, P1
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kooima R., 2019, VR DEVELOPER GEMS
   Koulieris GA, 2016, P IEEE VIRT REAL ANN, P113, DOI 10.1109/VR.2016.7504694
   Krosnick JA, 2010, HANDBOOK OF SURVEY RESEARCH, 2ND EDITION, P263
   Lang M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778812
   Lin H., 2011, SIGGRAPH Asia 2011 Sketches
   Lou R., 2022, EUROGRAPHICS 2022 PO
   Lou RD, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1058, DOI [10.1109/vr.2019.8798164, 10.1109/VR.2019.8798164]
   Mendiburu Bernard, 2012, 3D movie making: stereoscopic digital cinema from script to screen
   Mochizuki H., 2012, KITASATO MED J, V42, P5
   Oskam T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024223
   López JP, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-62
   Pritch Y, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P54, DOI 10.1109/OMNVIS.2000.853805
   QUADE D, 1979, J AM STAT ASSOC, V74, P680, DOI 10.2307/2286991
   Smith TJ, 2013, J VISION, V13, DOI 10.1167/13.8.16
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   Terzic K, 2016, SIGNAL PROCESS-IMAGE, V47, P402, DOI 10.1016/j.image.2016.08.002
   THEODORSSONNORHEIM E, 1987, COMPUT BIOL MED, V17, P85, DOI 10.1016/0010-4825(87)90003-5
   Wardle SG, 2012, J VISION, V12, DOI 10.1167/12.6.12
   Ware C, 1998, IEEE T SYST MAN CY A, V28, P56, DOI 10.1109/3468.650322
   Xu D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P394, DOI 10.1109/ICCE.2012.6161918
NR 36
TC 0
Z9 0
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2022
VL 33
IS 6
AR e2099
DI 10.1002/cav.2099
EA AUG 2022
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6Z9LE
UT WOS:000840713800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, JW
   Li, C
   Wang, CB
   He, GQ
AF Zhang, Jiawen
   Li, Chen
   Wang, Changbo
   He, Gaoqi
TI ORCANet: Differentiable multi-parameter learning for crowd simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; deep learning networks; differentiable simulator; ORCA
   model
AB Realistic crowd simulation has always been an important research field in computer graphics. While both agent-based motion models and data-driven behavior models have made some progress, they are still suffering from either huge effort of multi-parameter tuning or limited realistic motion. In this article, we propose a novel and differentiable multi-parameter learning method for crowd simulation, which is called ORCANet. The main idea is to learn from real data and inverse evaluating the multi-parameter for subsequent simulation. ORCANet uses classic optimal reciprocal collision avoidance (ORCA) as a basic motion model which is integrated into the deep learning framework. Addressing the feature of linear programming and non-differentiable operation, a Gaussian kernel is added to approximate the role of neighbor distance in collision avoidance, which turns the original discrete operation into a fully differentiable forward simulation. Furthermore, we leverage ORCANet to optimize the multi-parameter combination in synthetic and real-world datasets. ORCANet is proved to rapidly converge to correct parameter values and regenerate the input synthetic sequence. Moreover, experiments on real-world datasets by the metric of pedestrian trajectories verified that a more realistic crowd simulation has been generated through ORCANet.
C1 [Zhang, Jiawen; Li, Chen; Wang, Changbo; He, Gaoqi] East China Normal Univ, Sch Comp Sci & Technol, 3663 North Zhongshan Rd, Shanghai 200241, Peoples R China.
C3 East China Normal University
RP Li, C; He, GQ (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, 3663 North Zhongshan Rd, Shanghai 200241, Peoples R China.
EM cli@cs.ccnu.edu.cn; gqhe@cs.ecnu.edu.cn
RI Zhang, Jiawen/AAO-1138-2020
OI He, Gaoqi/0000-0001-8365-0970
FU National Natural Science Foundation of China [62002121, 62072183];
   Natural Science Foundation of Shanghai [19ZR1415800]; Open Project
   Program of the State Key Laboratory of Computer Aided Design and
   Computer Graphics [A2203]; Research Project of Shanghai Science and
   Technology Commission [20dz2260300]
FX National Natural Science Foundation of China, Grant/Award Numbers:
   62002121, 62072183; Natural Science Foundation of Shanghai, Grant/Award
   Number: 19ZR1415800; The Open Project Program of the State Key
   Laboratory of Computer Aided Design and Computer Graphics, Grant/Award
   Number: A2203; The Research Project of Shanghai Science and Technology
   Commission, Grant/Award Number: 20dz2260300
CR Amirian J, 2019, PROCEEDINGS OF THE 32ND INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2019), P7, DOI 10.1145/3328756.3328769
   Fiorini P, 1998, INT J ROBOT RES, V17, P760, DOI 10.1177/027836499801700706
   Flagg M, 2013, IEEE T VIS COMPUT GR, V19, P1935, DOI 10.1109/TVCG.2012.317
   Guy S.J., 2011, P 2011 ACM SIGGRAPH, P43, DOI [10.1145/2019406.2019413, DOI 10.1145/2019406.2019413]
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   Haworth B., 2015, P ACM SIGGRAPH EUR S, P113
   He FX, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392407
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Huang BH, 2021, LECT NOTES COMPUT SC, V13002, P190, DOI 10.1007/978-3-030-89029-2_15
   Jordao K, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12316
   Le Lidec Q, 2021, IEEE ROBOT AUTOM LET, V6, P3413, DOI 10.1109/LRA.2021.3062323
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Liu WX, 2016, IEEE T MULTIMEDIA, V18, P2398, DOI 10.1109/TMM.2016.2598091
   Musse S. R., 2021, VISUAL COMPUT, P1
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Ren JP, 2021, IEEE T VIS COMPUT GR, V27, P1953, DOI 10.1109/TVCG.2019.2946769
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Schenck C., 2018, C ROBOT LEARNING, P317
   Song X, 2021, IEEE T INTELL TRANSP, V22, P3285, DOI 10.1109/TITS.2020.2981118
   Stüvel SA, 2017, IEEE T VIS COMPUT GR, V23, P1823, DOI 10.1109/TVCG.2016.2545670
   Ummenhofer B., 2019, P INT C LEARN REPR
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Wang Xinjie, 2015, P 14 ACM SIGGRAPHEUR, P111, DOI DOI 10.1145/2786784.2786790
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Zhang P, 2022, IEEE T PATTERN ANAL, V44, P2742, DOI 10.1109/TPAMI.2020.3038217
NR 27
TC 4
Z9 4
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2023
VL 34
IS 1
SI SI
AR e2114
DI 10.1002/cav.2114
EA AUG 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Z2BA
UT WOS:000843757000001
DA 2024-07-18
ER

PT J
AU Song, D
   Wang, T
   Zhang, CM
   Li, XY
   Tong, RF
AF Song, Dan
   Wang, Teng
   Zhang, Chumeng
   Li, Xuanya
   Tong, Ruofeng
TI Source-enhanced prototypical alignment for single image 3D model
   retrieval
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D model retrieval; domain adaptation; transfer learning
ID NETWORK
AB Single image 3D model retrieval has attracted a lot of attentions with the convenience of organizing large-scale unlabeled 3D models. Existing methods transfer the knowledge from well-annotated 2D images (i.e., source domain) to unlabeled 3D models (i.e., target domain) to improve the discriminability of 3D models and align the feature distributions of 2D images and 3D models. However, during the alignment, the feature learning target of improving the discriminability of 3D models sometimes confuses the boundaries between 2D image categories, where prior methods ignore keeping the discriminability of 2D images. Motivated by this observation, we propose a source-enhanced prototypical alignment framework to first remain the discriminability of 2D images and then guide the category-level cross-domain alignment with better image representations. Specifically, a novel separation and compactness loss is proposed for images to separate the samples from different categories and compact the samples within the same category. Then we perform prototypical alignment to make 2D image features assist in the discriminative feature learning for 3D models. We evaluate the proposed method on the commonly used cross-domain 3D model retrieval benchmarks, namely MI3DOR and MI3DOR-2, and the results demonstrate the effectiveness of the proposed method.
C1 [Song, Dan; Wang, Teng; Zhang, Chumeng] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Li, Xuanya] Baidu Inc, Beijing, Peoples R China.
   [Tong, Ruofeng] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
C3 Tianjin University; Baidu; Zhejiang University
RP Tong, RF (corresponding author), Zhejiang Univ, Hangzhou, Peoples R China.
EM trf@zju.edu.cn
OI Wang, Teng/0000-0002-5799-7361
FU National Nature Science Foundation of China [61902277, 61972342]; Baidu
   Program
FX This work was supported in part by the National Nature Science
   Foundation of China (61902277, 61972342) and the Baidu Program.
CR Cui SH, 2020, PROC CVPR IEEE, P3940, DOI 10.1109/CVPR42600.2020.00400
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dominguez M, 2021, INT C PATT RECOG, P7439, DOI 10.1109/ICPR48806.2021.9413220
   Ertugrul E, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1959
   Fan Y., 2020, COMPUT ANIMAT VIR WO, V31, P4
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Z, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377876
   Ghadai S., 2019, P CVPR WORKSHOPS
   Goh GD, 2021, ARTIF INTELL REV, V54, P63, DOI 10.1007/s10462-020-09876-9
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huo JF, 2022, COMPUT INTELL-US, V38, P38, DOI 10.1111/coin.12442
   Li J., 2021, ICLR OPENREVIEW NET
   Li Wenhui, 2019, PROC 3DOR EUROGRAPHI, P103
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Long MS, 2017, PR MACH LEARN RES, V70
   Lu Yijuan, 2019, 12 EUROGRAPHICS WORK, P41
   Ma Y., 2019, FRONT DATA COMPUT, V1, P105, DOI [DOI 10.11871/JFDC, DOI 10.11871/JFDC.ISSN.2096.742X.2019.01.011]
   Nie WZ, 2022, IEEE T CYBERNETICS, V52, P1862, DOI 10.1109/TCYB.2020.2995415
   Nie WZ, 2022, IEEE T CIRC SYST VID, V32, P992, DOI 10.1109/TCSVT.2021.3070969
   Nima S., 2017, P BRIT MACHINE VISIO
   Paddlepaddle P., PADDL EAS TO US EAS
   Qi CR, 2017, ADV NEUR IN, V30
   Que X, 2021, ALGORITHMS, V14, DOI 10.3390/a14060184
   Ranasinghe K., 2021, P 2021 IEEE CVF INT, P12313
   Savva M., P WORKSH 3D OBJ RETR, P39
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Su YT, 2019, IEEE ACCESS, V7, P95285, DOI 10.1109/ACCESS.2019.2929109
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun SL, 2021, IEEE ACCESS, V9, P3451, DOI 10.1109/ACCESS.2020.3047820
   van Kreveld M, 2022, COMP GEOM-THEOR APPL, V100, DOI 10.1016/j.comgeo.2021.101817
   Wang JD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P402, DOI 10.1145/3240508.3240512
   Xu Y, 2021, IEEE T IMAGE PROCESS, V30, P5299, DOI 10.1109/TIP.2021.3082310
   You HX, 2019, AAAI CONF ARTIF INTE, P9119
   Yuan CX, 2022, J INTELL MANUF, V33, P425, DOI 10.1007/s10845-021-01885-x
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhou H., 2020, P MM 20 28 ACM INT C
   Zhou H., 2020, P ACM INT C MULT ACM, DOI [10.1145/3394171.3413631, DOI 10.1145/3394171.3413631]
   Zhou HY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1667, DOI 10.1145/3343031.3351011
NR 43
TC 0
Z9 0
U1 7
U2 25
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2065
DI 10.1002/cav.2065
EA JUN 2022
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000811371100001
DA 2024-07-18
ER

PT J
AU Ghafourzadeh, D
   Fallahdoust, S
   Rahgoshay, C
   Beauchamp, A
   Aubame, A
   Popa, T
   Paquette, E
AF Ghafourzadeh, Donya
   Fallahdoust, Sahel
   Rahgoshay, Cyrus
   Beauchamp, Andre
   Aubame, Adeline
   Popa, Tiberiu
   Paquette, Eric
TI Local control editing paradigms for part-based 3D face morphable models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer graphics; computing methodologies; mesh models; shape modeling
AB We propose an approach to construct realistic 3D facial morphable models (3DMM) that allows an intuitive facial attribute editing workflow. Current face modeling methods using 3DMM suffer from a lack of local control. We thus create a 3DMM by combining local part-based 3DMM for the eyes, nose, mouth, ears, and facial mask regions. Our local principal component analysis (PCA)-based approach uses a novel method to select the best eigenvectors from the local 3DMM to ensure that the combined 3DMM is expressive, while allowing accurate reconstruction. We provide different editing paradigms, all designed from the analysis of the data set. Some use anthropometric measurements from the literature and others allow the user to control the dominant modes of variation extracted from the data set. Our part-based 3DMM is compact, yet accurate, and compared to other 3DMM methods, it provides a new trade-off between local and global control. We tested our approach on a data set of 135 scans used to derive the 3DMM, plus 19 scans that served for validation. The results show that our part-based 3DMM approach has excellent generative properties and allows the user intuitive local control.
C1 [Ghafourzadeh, Donya; Fallahdoust, Sahel; Rahgoshay, Cyrus; Beauchamp, Andre; Aubame, Adeline] Ubisoft La Forge, Montreal, PQ, Canada.
   [Popa, Tiberiu] Concordia Univ, Comp Sci & Software Engn, Montreal, PQ, Canada.
   [Paquette, Eric] Ecole Technol Super, Software Engn & IT, Montreal, PQ, Canada.
C3 Concordia University - Canada; University of Quebec; Ecole de
   Technologie Superieure - Canada
RP Ghafourzadeh, D (corresponding author), Ubisoft La Forge, Montreal, PQ, Canada.
EM gh.dony@gmail.com
OI Paquette, Eric/0000-0001-9236-647X; Rahgoshay, Cyrus/0000-0002-2254-5605
FU Ubisoft Inc.; Mitacs Accelerate Program; Ecole de technologie superieure
FX This work was supported by Ubisoft Inc., the Mitacs Accelerate Program,
   and Ecole de technologie superieure.
CR Alabort-i-Medina J, 2017, INT J COMPUT VISION, V121, P26, DOI 10.1007/s11263-016-0916-3
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Amberg Brian, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Cao C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275093
   Cao C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766943
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Castrillón-Santana M, 2011, LECT NOTES ARTIF INT, V7023, P313, DOI 10.1007/978-3-642-25274-7_32
   Chi J, 2017, VISUAL COMPUT, V33, P981, DOI 10.1007/s00371-017-1387-4
   Et?z A., 2012, HDB ANTHROPOMETRY PH, P919
   Farkas LG, 2005, J CRANIOFAC SURG, V16, P615, DOI 10.1097/01.scs.0000171847.58031.9e
   Farkas LG, 1994, Anthropometry of Head and Face, Vsecond
   Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493
   Ghafourzadeh D., 2020, Proceedings of Graphics Interface 2020, P7
   Ichim AE, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073664
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Lacko D, 2015, APPL ERGON, V48, P70, DOI 10.1016/j.apergo.2014.11.008
   Lee J-H, 2006, INT J HUMAN ECOL, P7
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Lüthi M, 2018, IEEE T PATTERN ANAL, V40, P1860, DOI 10.1109/TPAMI.2017.2739743
   Neumann T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508417
   Park CW, 2018, ARCH AESTHET PLAST S, V24, P105, DOI 10.14730/aaps.2018.24.3.105
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Pflug A, 2012, IET BIOMETRICS, V1, P114, DOI 10.1049/iet-bmt.2011.0003
   Raed M., 2015, INT J MULTIMED UBIQU, V10, P373
   Ramachandran S, 2018, COMPUT GRAPH-UK, V74, P202, DOI 10.1016/j.cag.2018.05.021
   Ramanathan N., 2006, 2006 IEEE COMP SOC C, V1, P387
   Seidel H.-P, 2004, 2 EUROGRAPHICS S GEO, P175, DOI DOI 10.1145/1057432.1057456
   Shi FH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661290
   Sorkine O, 2007, S GEOM PROC, V4, P109, DOI [10.1145/1073204.1073323, DOI 10.1145/1073204.1073323]
   Streuber S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925981
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Wu CL, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925882
   Zell E., 2013, Symposium on Non-Photorealistic Animation and Rendering, P15
   Zhuang ZQ, 2010, ANN OCCUP HYG, V54, P391, DOI 10.1093/annhyg/meq007
NR 38
TC 5
Z9 5
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2021
VL 32
IS 6
AR e2028
DI 10.1002/cav.2028
EA JUN 2021
PG 23
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XW9UC
UT WOS:000656712600001
DA 2024-07-18
ER

PT J
AU Zhang, ZX
   Li, K
   Yin, XF
   Piao, XL
   Wang, YX
   Yang, X
   Yin, BC
AF Zhang, Zhaoxuan
   Li, Kun
   Yin, Xuefeng
   Piao, Xinglin
   Wang, Yuxin
   Yang, Xin
   Yin, Baocai
TI Point cloud semantic scene segmentation based on coordinate convolution
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE classification; convolutional neural network; coordinate convolution;
   semantic scene segmentation
AB Point cloud semantic segmentation, a crucial research area in the 3D computer vision, lies at the core of many vision and robotics applications. Due to the irregular and disordered of the point cloud, however, the application of convolution on point clouds is challenging. In this article, we propose the "coordinate convolution," which can effectively extract local structural information of the point cloud, to solve the inapplicability of conventional convolution neural network (CNN) structures on the 3D point cloud. The "coordinate convolution" is a projection operation of three planes based on the local coordinate system of each point. Specifically, we project the point cloud on three planes in the local coordinate system with a joint 2D convolution operation to extract its features. Additionally, we leverage a self-encoding network based on image semantic segmentation U-Net structure as the overall architecture of the point cloud semantic segmentation algorithm. The results demonstrate that the proposed method exhibited excellent performances for point cloud data sets corresponding to various scenes.
C1 [Zhang, Zhaoxuan; Li, Kun; Yin, Xuefeng; Wang, Yuxin; Yang, Xin; Yin, Baocai] Dalian Univ Technol, Dalian, Peoples R China.
   [Piao, Xinglin; Yin, Baocai] Peng Cheng Lab, Shenzhen, Peoples R China.
C3 Dalian University of Technology; Peng Cheng Laboratory
RP Wang, YX (corresponding author), Dalian Univ Technol, Dalian, Peoples R China.; Piao, XL (corresponding author), Peng Cheng Lab, Shenzhen, Peoples R China.
EM piaoxl@pcl.ac.cn; wyx@dlut.edu.cn
RI Wang, Yuxin/ABF-2724-2020
OI , Xin/0000-0002-8046-722X
FU NSFC [91748104, 61972067, 61632006, U1811463, U1908214, 61751203,
   61902053]; National Key Research and Development Program of China
   [2018AAA0102003]
FX This work was partly supported by NSFC Grants 91748104, 61972067,
   61632006, U1811463, U1908214, 61751203, 61902053, and the National Key
   Research and Development Program of China, Grant 2018AAA0102003.
CR [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2016, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI [DOI 10.1109/CVPR.2016.170, 10.1109/CVPR.2016.170]
   Chen H, 2018, NEUROIMAGE, V170, P446, DOI 10.1016/j.neuroimage.2017.04.041
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Gupta S, 2015, INT J COMPUT VISION, V112, P133, DOI 10.1007/s11263-014-0777-6
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang QG, 2018, PROC CVPR IEEE, P2626, DOI 10.1109/CVPR.2018.00278
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Jiang M., 2018, ARXIV180700652
   Kingma D. P., 2014, arXiv
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Li YY, 2018, ADV NEUR IN, V31
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang P., 2017, INT J ROBUST NONLIN, V4, P1
   Wang XL, 2019, PROC CVPR IEEE, P4091, DOI 10.1109/CVPR.2019.00422
   Wang Y, 2019, INFORM TECHNOLOGY NE, V38, P1
   Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571
NR 28
TC 9
Z9 9
U1 2
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1948
DI 10.1002/cav.1948
EA SEP 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000568117000001
DA 2024-07-18
ER

PT J
AU Ozgen, O
   Kallmann, M
   Brown, E
AF Ozgen, Oktar
   Kallmann, Marcelo
   Brown, Eric
TI An SPH model to simulate the dynamic behavior of shear thickening fluids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fluid simulation; fractional derivatives; shear thickening fluids
ID EQUATION
AB While significant research has been dedicated to the simulation of fluids, not much attention has been given to exploring new interesting behavior that can be generated with different types of non-Newtonian fluids with nonconstant viscosity. Going in this direction, this paper introduces a computational model for simulating the most interesting phenomena observed in non-Newtonian shear thickening fluids, which are fluids where viscosity increases with increased stress. These fluids have unique and unconventional behavior, and they often appear in real-world scenarios such as when sinking in quicksand or when experimenting with popular cornstarch and water mixtures. The fluid exhibits unique phase changes between solid and liquid states, great impact resistance in its solid state, and strong hysteresis effects. Our proposed approach builds on existing non-Newtonian smoothed particle hydrodynamics (SPH) fluid models in computer graphics and introduces an efficient history-based stiffness term that is essential to produce the most interesting types of shear thickening phenomena. The history-based stiffness is formulated through the use of fractional derivatives, leveraging the fractional calculus ability to depict both the viscoelastic behavior and the history effects of history-dependent systems. Simulations produced by our method are compared against real experiments, and the results demonstrate that the proposed model successfully captures key phenomena specific to discontinuous shear thickening fluids.
C1 [Ozgen, Oktar; Kallmann, Marcelo] Univ Calif Merced, Comp Sci & Engn Dept, Merced, CA 95340 USA.
   [Ozgen, Oktar; Brown, Eric] Yale Univ, Sch Engn & Appl Sci, New Haven, CT USA.
   [Ozgen, Oktar] Indoors Inc, TR-34906 Istanbul, Turkey.
C3 University of California System; University of California Merced; Yale
   University
RP Ozgen, O (corresponding author), Univ Calif Merced, Comp Sci & Engn Dept, Merced, CA 95340 USA.
EM oktarozgen@gmail.com
RI Kallmann, Marcelo/HSC-7222-2023
OI Kallmann, Marcelo/0000-0001-5138-0603
CR BAGLEY RL, 1983, J RHEOL, V27, P201, DOI 10.1122/1.549724
   Barreiro H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130854
   Bender J., 2015, P 14 ACM SIGGRAPH EU, P147, DOI DOI 10.1145/2786784.2786796
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   BRADY JF, 1985, J FLUID MECH, V155, P105, DOI 10.1017/S0022112085001732
   Brown E, 2012, J RHEOL, V56, P875, DOI 10.1122/1.4709423
   Carlson M., 2002, ACM SIGGRAPH/Eurographics Symp. Comp. Anim, P167
   Clavet S., 2005, SCA '05, P219, DOI DOI 10.1145/1073368.1073400
   Coimbra CFM, 1998, J FLUID MECH, V370, P53, DOI 10.1017/S0022112098001967
   Coimbra CFM, 2004, J FLUID MECH, V504, P353, DOI 10.1017/S002211200400789X
   Coimbra CFM, 2003, ANN PHYS-BERLIN, V12, P692, DOI 10.1002/andp.200310032
   de Oliveira EC, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/238459
   Deegan RD, 2010, PHYS REV E, V81, DOI 10.1103/PhysRevE.81.036319
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Desbrun M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P287, DOI 10.1145/218380.218456
   Discovery Channel, 2009, DISCOVERY CHANNEL
   Gemant A, 1938, PHILOS MAG, V25, P540
   Goktekin TG, 2004, ACM T GRAPHIC, V23, P463, DOI 10.1145/1015706.1015746
   Han ED, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12243
   Hanlon M., 2006, NEW SHEAR THICKENING
   Heibig A, 2008, J MATH PHYS, V49, DOI 10.1063/1.2907578
   Howard B, 2008, NONNEWTONIAN FLUID S
   Ihmsen M, 2014, 35 ANN C EUR ASS COM
   L'Espérance D, 2005, EXP FLUIDS, V38, P112, DOI 10.1007/s00348-004-0905-0
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Maharjan R, 2018, PHYS REV E, V97, DOI 10.1103/PhysRevE.97.052602
   Maharjan R, 2017, PHYS REV FLUIDS, V2, DOI 10.1103/PhysRevFluids.2.123301
   MAKRIS N, 1993, J ENG MECH-ASCE, V119, P1663, DOI 10.1061/(ASCE)0733-9399(1993)119:8(1663)
   Mukhopadhyay S, 2018, PHYS REV E, V97, DOI 10.1103/PhysRevE.97.052604
   Ozgen O, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805967
   Palade LI, 1999, INT J ENG SCI, V37, P315, DOI 10.1016/S0020-7225(98)00080-9
   Peer A, 2017, IEEE T VIS COMPUT GR, V23, P2656, DOI 10.1109/TVCG.2016.2636144
   Qi HT, 2009, NONLINEAR ANAL-REAL, V10, P2700, DOI 10.1016/j.nonrwa.2008.07.008
   Soon CM, 2005, ANN PHYS-BERLIN, V14, P378, DOI 10.1002/andp.200410140
   Takahashi T, 2015, COMPUT GRAPH FORUM, V34, P493, DOI 10.1111/cgf.12578
   Terzopoulos D., 1989, Proceeding of Graphics Interface, P219
   Teschner M, 2003, P VIS MOD VIS 2003 V
   von Kann S, 2013, PHYS REV E, V87, DOI 10.1103/PhysRevE.87.042301
   von Kann S, 2011, PHYS REV E, V84, DOI 10.1103/PhysRevE.84.060401
   Wagner NJ, 2009, PHYS TODAY, V62, P27, DOI 10.1063/1.3248476
   Wilson T.V., 2007, LIQUID BODY ARMOR WO
   Yue Y, 2015, ACM T GRAPH
   Zhu B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766981
NR 43
TC 11
Z9 12
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2019
VL 30
IS 5
AR e1870
DI 10.1002/cav.1870
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JD7JT
UT WOS:000490157800003
DA 2024-07-18
ER

PT J
AU Xiang, W
   Ren, JP
   Wang, K
   Deng, ZG
   Jin, XG
AF Xiang, Wei
   Ren, Jiaping
   Wang, Kuan
   Deng, Zhigang
   Jin, Xiaogang
TI Biologically inspired ant colony simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE ant colony simulation; biologically inspired; information transfer;
   unified motion controller
ID MODEL; ORDER
AB We present a unified biologically inspired approach to simulate ant colonies inspired by the key observation of collective behaviors of ants in nature. To generate the trajectories of virtual ants, we construct a motion controller to determine the motion states and the paths of virtual ants, considering dynamic internal and external interactions. The motion controller computes a target position for each ant at every time step according to its motion states. The motion states include four states: basic movement, the stop state, and two dynamic interactions (i.e., internal and external, respectively referring to interaction with neighbors for necessary information transfer about the destination, and interaction with surroundings such as food sources, nests, and obstacles) to represent basic exploration, casual or intentional stop, and purposeful movement, respectively. Based on the motion states, the motion controller plans an optimal path for each virtual ant. Through many simulation experiments, we demonstrate that our method is controllable, scalable, and flexible to simulate hybrid colonies with a large number of ants.
C1 [Xiang, Wei; Ren, Jiaping; Wang, Kuan; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 Zhejiang University; University of Houston System; University of Houston
RP Jin, XG (corresponding author), Univ Houston, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM jin@cad.zju.edu.cn
OI Deng, Zhigang/0000-0003-2571-5865; Xiang, Wei/0000-0002-0656-2851; Deng,
   Zhigang/0000-0002-0452-8676; Jin, Xiaogang/0000-0001-7339-2920
FU National Key R&D Program of China [2017YFB1002600]
FX National Key R&D Program of China, Grant/Award Number: 2017YFB1002600
CR Amorim P, 2015, J THEOR BIOL, V385, P160, DOI 10.1016/j.jtbi.2015.08.026
   [Anonymous], 1999, P GAM DEV C
   Burstedde C, 2001, PHYSICA A, V295, P507, DOI 10.1016/S0378-4371(01)00141-8
   Chaudhuri D, 2015, PHYS REV E, V91, DOI 10.1103/PhysRevE.91.012706
   Chowdhury D, 2002, J PHYS A-MATH GEN, V35, pL573, DOI 10.1088/0305-4470/35/41/103
   Collins RobertJ., 1990, Antfarm: Towards simulated evolution
   Dutra TB, 2017, COMPUT GRAPH FORUM, V36, P337, DOI 10.1111/cgf.13130
   Fourcassié V, 2010, J EXP BIOL, V213, P2357, DOI 10.1242/jeb.031237
   Gu Q., 2011, Graphics Interface 2011, P266, DOI DOI 10.5555/1992917.1992919
   Gu Q, 2013, IEEE COMPUT GRAPH, V33, P20, DOI 10.1109/MCG.2011.87
   Gu Q, 2011, IEEE COMPUT GRAPH, V31, P54, DOI 10.1109/MCG.2010.38
   Guo SH, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1779
   Guo SH, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12471
   Guo SH, 2014, COMPUT GRAPH-UK, V38, P78, DOI 10.1016/j.cag.2013.10.021
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hildenbrandt H, 2010, BEHAV ECOL, V21, P1349, DOI 10.1093/beheco/arq149
   Holldobler B., 1990, pi
   Hughes R, 2015, P 8 ACM SIGGRAPH C M
   Jackson DE, 2006, CURR BIOL, V16, pR570, DOI 10.1016/j.cub.2006.07.015
   John Alexander, 2008, Swarm Intelligence, V2, P25, DOI 10.1007/s11721-008-0010-8
   Ju E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866162
   Karamouzas I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073705
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Li LX, 2014, P NATL ACAD SCI USA, V111, P8392, DOI 10.1073/pnas.1407083111
   Li WZ, 2015, COMPUT GRAPH FORUM, V34, P425, DOI 10.1111/cgf.12572
   Li Y., 2012, Eurographics Symposium on Computer Animation, P201
   Lukeman R, 2010, P NATL ACAD SCI USA, V107, P12576, DOI 10.1073/pnas.1001763107
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Nishinari K, 2006, PHYSICA A, V372, P132, DOI 10.1016/j.physa.2006.05.016
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Panait L., 2004, P 3 INT JOINT C AUTO, P36
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Ren JP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155698
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Sauter J. A., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P434
   TONER J, 1995, PHYS REV LETT, V75, P4326, DOI 10.1103/PhysRevLett.75.4326
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Wang XJ, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12277
   Wang Xinjie, 2015, P 14 ACM SIGGRAPHEUR, P111, DOI DOI 10.1145/2786784.2786790
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
NR 42
TC 6
Z9 7
U1 2
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2019
VL 30
IS 5
AR e1867
DI 10.1002/cav.1867
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JD7JT
UT WOS:000490157800004
DA 2024-07-18
ER

PT J
AU Charalambous, C
   Yumak, Z
   van der Stappen, AF
AF Charalambous, Constantinos
   Yumak, Zerrin
   van der Stappen, A. Frank
TI Audio-driven emotional speech animation for interactive virtual
   characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE audio-driven speech animation; emotional speech; procedural animation
AB We present a procedural audio-driven speech animation method for interactive virtual characters. Given any audio with its respective speech transcript, we automatically generate lip-synchronized speech animation that could drive any three-dimensional virtual character. The realism of the animation is enhanced by studying the emotional features of the audio signal and its effect on mouth movements. We also propose a coarticulation model that takes into account various linguistic rules. The generated animation is configurable by the user by modifying the control parameters, such as viseme types, intensities, and coarticulation curves. We compare our approach against two lip-synchronized speech animation generators. Our results show that our method surpasses them in terms of user preference.
C1 [Charalambous, Constantinos; Yumak, Zerrin; van der Stappen, A. Frank] Univ Utrecht, Dept Informat & Comp Sci, NL-3512 JE Utrecht, Netherlands.
C3 Utrecht University
RP Yumak, Z (corresponding author), Univ Utrecht, Dept Informat & Comp Sci, NL-3512 JE Utrecht, Netherlands.
EM z.yumak@uu.nl
OI van der Stappen, Frank/0000-0001-7965-2818
FU Horizon 2020 RAGE - Realizing an Applied Gaming Eco-system project
   [644187]; H2020 - Industrial Leadership [644187] Funding Source: H2020 -
   Industrial Leadership
FX Horizon 2020 RAGE - Realizing an Applied Gaming Eco-system project,
   Grant/Award Number: 644187
CR Albrecht I., 2005, J VIRTUAL REALITY, V8, P201, DOI DOI 10.1007/S10055-005-0153-5
   [Anonymous], 2012, SPECIAL INTEREST GRO
   [Anonymous], ACM TRANSACTIONS ON
   Bailly Gerard, 1997, SPEECH COMMUN, V22, P2
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bevacqua E, 2004, COMPUT ANIMAT VIRT W, V15, P297, DOI 10.1002/cav.32
   Bregler C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P353, DOI 10.1145/258734.258880
   Cao C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925873
   Charalambous C, AUDIO DRIVEN SPEECH
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   Cosi P, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P505, DOI 10.1109/ICMI.2002.1167047
   Deng ZG, 2006, IEEE T VIS COMPUT GR, V12, P1523, DOI 10.1109/TVCG.2006.90
   Edwards P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925984
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Ito T, 2004, J APPL PHYSIOL, V96, P2318, DOI 10.1152/japplphysiol.01048.2003
   Jiao Y, 2014, IEEE POSITION LOCAT, P37, DOI 10.1109/PLANS.2014.6851355
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Kim T, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P577, DOI 10.1145/2783258.2783356
   King SA, 2005, IEEE T VIS COMPUT GR, V11, P341, DOI 10.1109/TVCG.2005.43
   LEE KF, 1990, IEEE T ACOUST SPEECH, V38, P35, DOI 10.1109/29.45616
   LINDBLOM B, 1963, J ACOUST SOC AM, V35, P1773, DOI 10.1121/1.1918816
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Maestri G, 2011, COMPUT GRAPH WORLD, V34, P44
   Maniwa K, 2009, J ACOUST SOC AM, V125, P3962, DOI 10.1121/1.2990715
   Massaro D. W., 2012, AUDIOVISUAL SPEECH P, P309, DOI [https://doi.org/10.1017/CBO9780511843891.014, DOI 10.1017/CBO9780511843891.014]
   Pelachaud C, 1996, COGNITIVE SCI, V20, P1, DOI 10.1207/s15516709cog2001_1
   Riaziat M, 2013, 2013 IEEE PHOTONICS SOCIETY SUMMER TOPICAL MEETING SERIES, P13, DOI 10.1109/PHOSST.2013.6614443
   Rogo Digital, ROG DIG LIPSYNC
   Schiel F, 2011, WORKSH TOOLS METH VE
   Seymour M, 2017, ACM SIGGRAPH 2017 VR
   Story BH, 1998, J ACOUST SOC AM, V104, P471, DOI 10.1121/1.423298
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Traunmuller H., 1994, The frequency range of the voice fundamental in the speech of male and female adults
   Young S.J., 1993, HTK HIDDEN MARKOV MO
NR 34
TC 11
Z9 11
U1 3
U2 21
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1892
DI 10.1002/cav.1892
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400013
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Luo, YL
   Gao, B
   Deng, YY
   Zhu, XM
   Jiang, TZ
   Zhao, XD
   Yang, ZY
AF Luo, Yanlin
   Gao, Bin
   Deng, Yiyi
   Zhu, Xiaoming
   Jiang, Tianzi
   Zhao, Xudong
   Yang, Zhengyi
TI Automated brain extraction and immersive exploration of its layers in
   virtual reality for the rhesus macaque MRI data sets
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE bimanual gesture interaction; brain extraction; rhesus macaque; volume
   visualization; 3D inspection
ID VOLUME; VISUALIZATION; SEGMENTATION; MORPHOMETRY
AB As we know, the rhesus macaque as a nonhuman primate is quite similar to a human being in genetics. Moreover, it has become essential in animal model anatomy and physiology in many modern medicine research such as the cardiovascular and cerebrovascular diseases in the recent years. This paper describes a pipeline from the raw rhesus macaque brain magnetic resonance imaging data to intuitive 3D inspection of its layers. Brain extraction is an initial step for subsequent analyses, but most of the existing methods so far are designed for human brain, which does not work well with the rhesus macaque. Firstly, we propose a reliable and efficient method to extract the brain from magnetic resonance imaging data sets based on dividing the brain into blocks. Then, we design a trapezoid opacity transfer function based on Compute Unified Device Architecture (CUDA)-based real-time volume ray casting, which is dedicated to volume rendering to make the inspection more intuitive. Besides, for an immersive exploration in virtual reality benefits understanding the volumetric data sets, so we also design a layer filter for the segmented rhesus macaque brain data sets, which facilitates the inspection of the interior in Region of Interest (ROI) by an intuitive bimanual interaction via a Leap Motion sensor. Our experiments prove usability and efficiency.
C1 [Luo, Yanlin; Deng, Yiyi; Zhu, Xiaoming] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing, Peoples R China.
   [Gao, Bin; Jiang, Tianzi; Yang, Zhengyi] Chinese Acad Sci, Inst Automat, Brainnetome Ctr, Beijing, Peoples R China.
   [Zhao, Xudong] Chinese Acad Sci, Inst Biophys, State Key Lab Brain & Cognit Sci, Beijing, Peoples R China.
C3 Beijing Normal University; Chinese Academy of Sciences; Institute of
   Automation, CAS; Chinese Academy of Sciences; Institute of Biophysics,
   CAS
RP Yang, ZY (corresponding author), Chinese Acad Sci, Inst Automat, Brainnetome Ctr, Beijing, Peoples R China.
EM luoyl@bnu.edu; gaobin3@jd.com; 201411212043@mail.bnu.edu.cn;
   zhuxm@bnu.edu.cn; jiangtz@nlpr.ia.ac.cn; xdzhao@bcslab.ibp.ac.cn;
   zhengyi.yang@nlpr.ia.ac.cn
RI gao, bin/JYW-5418-2024; xin, li/JCO-3925-2023; Li, Juan/JEO-6872-2023;
   LI, Wenhui/JCD-9947-2023; Jiang, Tianzi/I-4256-2012
FU Strategic Priority Research Program of the Chinese Academy of Sciences
   [XD-B02030300]; Natural Science Foundation of China [91132301,
   91432302]; National Social Science Foundation of China [BCA150050]
FX Strategic Priority Research Program of the Chinese Academy of Sciences,
   Grant/Award Number: XD-B02030300; Natural Science Foundation of China,
   Grant/Award Number: 91132301 and 91432302; National Social Science
   Foundation of China, Grant/Award Number: BCA150050
CR Arsiwalla XD, 2014, BMC NEUROSCI, V14, pP407
   Assassi L, 2009, COMPUT ANIMAT VIRT W, V20, P53, DOI 10.1002/cav.266
   Ballanger B, 2013, NEUROIMAGE, V77, P26, DOI 10.1016/j.neuroimage.2013.03.029
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Doshi J, 2013, ACAD RADIOL, V20, P1566, DOI 10.1016/j.acra.2013.09.010
   Engel K, 2001, P ACM SIGGRAPH EUROG
   Gallo L, P SIGGRAPH AS 2013 T, P28
   Gobbetti E, 2008, VISUAL COMPUT, V24, P797, DOI 10.1007/s00371-008-0261-9
   Gobbetti E, 2012, COMPUT GRAPH FORUM, V31, P1315, DOI 10.1111/j.1467-8659.2012.03124.x
   Hänel C, 2014, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00042
   Hikishima K, 2015, NEUROSCIENCE, V300, P585, DOI 10.1016/j.neuroscience.2015.05.041
   Hikishima K, 2011, NEUROIMAGE, V54, P2741, DOI 10.1016/j.neuroimage.2010.10.061
   Laha B, 2012, IEEE T VIS COMPUT GR, V18, P597, DOI 10.1109/TVCG.2012.42
   Liang Ronghua, 2009, Journal of Computer Aided Design & Computer Graphics, V21, P1381
   Luo YL, 2012, COMPUT SCI ENG, V14, P63, DOI 10.1109/MCSE.2011.114
   McLaren DG, 2010, METHODS, V50, P157, DOI 10.1016/j.ymeth.2009.10.003
   McLaren DG, 2009, NEUROIMAGE, V45, P52, DOI 10.1016/j.neuroimage.2008.10.058
   Monclus E., 2009, PROC ACM S VIRTUAL R, P119, DOI [10.1145/1643928.1643955, DOI 10.1145/1643928.1643955]
   O'Hara K, 2014, COMMUN ACM, V57, P70, DOI 10.1145/2541883.2541899
   Quallo MM, 2010, NEUROIMAGE, V52, P1328, DOI 10.1016/j.neuroimage.2010.05.006
   Rezk-Salama C, 2006, COMPUT GRAPH FORUM, V25, P597, DOI 10.1111/j.1467-8659.2006.00979.x
   Risser L, 2014, IEEE ENG MED BIO, P6695, DOI 10.1109/EMBC.2014.6945164
   Rohlfing T, 2012, FRONT NEUROINFORM, V6, DOI 10.3389/fninf.2012.00027
   Shattuck DW, 2009, NEUROIMAGE, V45, P431, DOI 10.1016/j.neuroimage.2008.10.066
   Shen JC, 2016, VISUAL COMPUT, V32, P359, DOI 10.1007/s00371-016-1209-0
   Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Wang R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531397
   Wang YP, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0077810, 10.1371/journal.pone.0101303, 10.1371/journal.pone.0096339]
   Wigdor D, 2011, BRAVE NUI WORLD: DESIGNING NATURAL USER INTERFACES FOR TOUCH AND GESTURE, P1
   Wu Fuli, 2010, Journal of Computer Aided Design & Computer Graphics, V22, P1810
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
NR 32
TC 12
Z9 13
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2019
VL 30
IS 1
AR e1841
DI 10.1002/cav.1841
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8YF
UT WOS:000458275000006
OA Bronze
DA 2024-07-18
ER

PT J
AU Cui, LQ
   Ma, CY
   Chen, G
AF Cui, Liqun
   Ma, Chunyong
   Chen, Ge
TI Physical-based spatio-temporal resolution enhancement of scalar data for
   fluid visualization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE convex optimization; Navier-Stokes equations; velocity estimation;
   visualization
ID FLOW
AB We present a method that improves the spatio-temporal resolution of original data with fluid scalar data. The basis of the method, velocity estimation, is constructed to be inverse and optimized problem. We reduce the calculation cost through convex optimization and make the velocity field more accurate by coupling with Navier-Stokes equations. The spatial resolution receives significant enhancement by applying advection on original data with higher-resolution velocity field data generated by our method. The temporal resolution is improved by generating intermediate velocity fields through the solution of Navier-Stokes equations. In this paper, we demonstrate that the accuracy of our velocity estimation method is clearly better than that of optical flow methods and the enhanced data show an attractive performance in fluid visualization. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Cui, Liqun; Ma, Chunyong; Chen, Ge] Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
C3 Ocean University of China
RP Ma, CY (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
EM chunyongma@ouc.edu.cn
CR Bridson R., 2015, Fluid simulation for computer graphics
   Etiene T, 2014, IEEE T VIS COMPUT GR, V20, P140, DOI 10.1109/TVCG.2013.90
   Gregson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601147
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Kadri-Harouna S, 2013, INT J COMPUT VISION, V103, P80, DOI 10.1007/s11263-012-0595-7
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Liu TS, 2008, J FLUID MECH, V614, P253, DOI 10.1017/S0022112008003273
   Meinhardt-Llopis E, 2013, IMAGE PROCESS ON LIN, V3, P151, DOI 10.5201/ipol.2013.20
   Mullen P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531344
   Potts S, 2004, PROC GRAPH INTERF, P57
   Scharsach H, 2005, P CESCG, V5, P67
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Stam J, 2001, ACM T GRAPHIC, V1999, P121
   Vlasenko A, 2009, NOTES NUMER FLUID ME, V106, P247
   Yuan J, 2007, J MATH IMAGING VIS, V28, P67, DOI 10.1007/s10851-007-0014-9
   Zhang Y, 2013, J EXP CLIN CANC RES, V32, DOI 10.1186/1756-9966-32-7
NR 16
TC 0
Z9 0
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 405
EP 414
DI 10.1002/cav.1694
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300025
DA 2024-07-18
ER

PT J
AU Yang, C
   Yang, XB
   Xiao, XY
AF Yang, Cheng
   Yang, Xubo
   Xiao, Xiangyun
TI Data-driven projection method in fluid simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE artificial neural network; data-driven; grid-based fluid simulation;
   projection step
AB Physically based fluid simulation requires much time in numerical calculation to solve Navier-Stokes equations. Especially in grid-based fluid simulation, because of iterative computation, the projection step is much more time-consuming than other steps. In this paper, we propose a novel data-driven projection method using an artificial neural network to avoid iterative computation. Once the grid resolution is decided, our data-driven method could obtain projection results in relatively constant time per grid cell, which is independent of scene complexity. Experimental results demonstrated that our data-driven method drastically speeded up the computation in the projection step. With the growth of grid resolution, the speed-up would increase strikingly. In addition, our method is still applicable in different fluid scenes with some alterations, when computational cost is more important than physical accuracy. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Yang, Cheng; Yang, Xubo; Xiao, Xiangyun] Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, XB (corresponding author), Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.
EM yangxubo@sjtu.edu.cn
CR [Александрова Мария Викторовна Aleksandrova M.], 2010, [Проблемы Дальнего Востока, Problemy Dal'nego Vostoka], P65
   [Anonymous], 2003, P GAME DEVELOPER C
   [Anonymous], 2015, COMPUTER GRAPHICS FO
   [Anonymous], 2003, NONLINEAR PROGRAMMIN
   Bolz J, 2003, ACM T GRAPHIC, V22, P917, DOI 10.1145/882262.882364
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Hagan MT, 1997, NEURAL NETWORK DESIG
   Han J, 1995, LECT NOTES COMPUT SC, V930, P195
   HARLOW FH, 1965, PHYS FLUIDS, V8, P2182, DOI 10.1063/1.1761178
   Kaastra I, 1996, NEUROCOMPUTING, V10, P215, DOI 10.1016/0925-2312(95)00039-9
   Kim T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360649
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ladicky L, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818129
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Narain R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409119
   Raveendran K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601126
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Treuille A, 2006, ACM T GRAPHIC, V25, P826, DOI 10.1145/1141911.1141962
   Zhu B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461999
NR 22
TC 66
Z9 78
U1 3
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 415
EP 424
DI 10.1002/cav.1695
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300026
DA 2024-07-18
ER

PT J
AU Aristidou, A
   Chrysanthou, Y
   Lasenby, J
AF Aristidou, Andreas
   Chrysanthou, Yiorgos
   Lasenby, Joan
TI Extending FABRIK with model constraints
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation; FABRIK; human modelling; inverse kinematics; joint
   configuration
ID INVERSE KINEMATIC SOLUTIONS; OPTIMIZATION; ALGORITHM; ROBOT
AB Forward and Backward Reaching Inverse Kinematics (FABRIK) is a recent iterative inverse kinematics solver that became very popular because of its simplicity, convergence speed and control performance, especially in models with multiple end effectors. In this paper, we extend and/or adjust FABRIK to be used in problems with leaf joints and closed-loop chains and to control a fixed inter-joint distance in a kinetic chain with unsteady data. In addition, we provide optimisation solutions when the target is unreachable and a proof of convergence when a solution is available. We also present various techniques for constraining anthropometric and robotic joint models using FABRIK and provide clarifications and solutions to many questions raised since the first publication of FABRIK. Finally, a human-like model that has been structured hierarchically and sequentially using FABRIK is presented, utilising most of the suggested joint models; it can efficiently trace targets in real time, without oscillations or discontinuities, verifying the effectiveness of FABRIK. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Aristidou, Andreas; Chrysanthou, Yiorgos] Univ Cyprus, Dept Comp Sci, CY-1678 Nicosia, Cyprus.
   [Lasenby, Joan] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
C3 University of Cyprus; University of Cambridge
RP Aristidou, A (corresponding author), Univ Cyprus, Dept Comp Sci, CY-1678 Nicosia, Cyprus.
EM a.aristidou@ieee.org
RI Aristidou, Andreas/AAI-8096-2020
OI Aristidou, Andreas/0000-0001-7754-0791; Lasenby,
   Joan/0000-0002-0571-0218
FU Office of Naval Research Global [N62909-13-1-V090]; European Regional
   Development Fund; Republic of Cyprus through the Research Promotion
   Foundation [DIDAKTOR/0311/73]
FX This project is co-financed by the Office of Naval Research Global
   (N62909-13-1-V090), the European Regional Development Fund and the
   Republic of Cyprus through the Research Promotion Foundation
   (DIDAKTOR/0311/73). The authors would also like to thank Dr Chrysis
   Georgiou (University of Cyprus), Mr Tracy McSheery and Dr Kan Anant
   (PhaseSpace Inc.) for their valuable help.
CR Alver J, 2011, THESIS CHALMERS U TE
   [Anonymous], 1984, P 23 IEEE C DEC CONT
   [Anonymous], 1985, P 1985 IEEE INT C RO
   [Anonymous], REV ELECTRONIQUE FRA
   Aristidou A, 2009, TECHNICAL REPORTS F
   Aristidou A., 2011, GUIDE GEOMETRIC ALGE, P47
   Aristidou A, 2008, LECT NOTES COMPUT SC, V5098, P238, DOI 10.1007/978-3-540-70517-8_23
   Aristidou A, 2013, VISUAL COMPUT, V29, P7, DOI 10.1007/s00371-011-0671-y
   Aristidou A, 2011, GRAPH MODELS, V73, P243, DOI 10.1016/j.gmod.2011.05.003
   Badler N. I., 1993, Simulating humans: computer graphics animation and control
   Baerlocher P, 2001, INT FED INFO PROC, V68, P180
   Balestrino A., 1984, P 9 IFAC WORLD C, V5, P2435, DOI [10.1016/S1474-6670(17)61347-8, DOI 10.1016/S1474-6670(17)61347-8]
   Bentrah A, 2014, LECT NOTES COMPUT SC, V8584, P681, DOI 10.1007/978-3-319-09153-2_51
   Blow J., 2012, GAME DEV MAGAZINE, P16
   Brown J, 2004, VISUAL COMPUT, V20, P165, DOI 10.1007/s00371-003-0226-y
   Buss S. R., 2005, Journal of Graphics Tools, V10, P37
   Cameron J, 2005, ACM SIGGRAPH, P107
   Courty N, LNCS, V5098, P1
   Der KG, 2006, ACM T GRAPHIC, V25, P1174, DOI 10.1145/1141911.1142011
   FLETCHER R., 1987, PRACTICAL METHODS OP
   Fu Z, 2013, J MECH ROBOT, V5, P1
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Harrison J, 2004, ACM T GRAPHIC, V23, P569, DOI 10.1145/1015706.1015761
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Herda L, 2003, INT J ROBOTICS RES, V22
   Ho ESL, 2013, COMPUTER GRAPHICS FO
   Hwang S, 2014, P INT C COMP GRAPH V
   Jing Huang, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P278, DOI 10.1007/978-3-642-34710-8_26
   Kaimakis P, 2007, LECT NOTES COMPUT SC, V4841, P24
   Kenwright B., 2013, International Journal on Advances in Intelligent Systems, V6, P53
   Klopcar N, 2007, J BIOMECH, V40, P86, DOI 10.1016/j.jbiomech.2005.11.010
   Korein JamesU., 1985, GEOMETRIC INVESTIGAT
   Kulpa R, 2005, IEEE-RAS INT C HUMAN, P38
   Liu Y-C, 2012, THESIS NATL TAIPEI U
   Lo HS, 2013, IEEE ASME INT C ADV, P798, DOI 10.1109/AIM.2013.6584191
   Maurel W, 2000, COMPUT GRAPH-UK, V24, P203, DOI 10.1016/S0097-8493(99)00155-7
   MONHEIT G, 1991, IEEE COMPUT GRAPH, V11, P29, DOI 10.1109/38.75588
   Moya S., 2013, P 24 C INT SOC BIOME, P1
   Mukundan R, 2009, INT J COMPUT APPL T, V34, P303, DOI 10.1504/IJCAT.2009.024084
   Muller-Cajar R, 2007, P IM VIS COMP HAM NE, P181
   Munshi SM, 2012, THESIS U NEW S WALES
   Murray RM, 1994, MATH INTRO ROBOTIC M
   NAKAMURA Y, 1986, J DYN SYST-T ASME, V108, P163, DOI 10.1115/1.3143764
   Paul RP, 1988, IEEE T SYST MAN CYB, V11, P1398
   Pechev AN, 2008, IEEE INT CONF ROBOT, P2005, DOI 10.1109/ROBOT.2008.4543501
   Poddighe R, 2013, P 25 BELG NETH ART I
   Ramachandran S, 2013, P EUR UK THEOR PRACT
   RIJPKEMA H, 1991, COMP GRAPH, V25, P339, DOI 10.1145/127719.122754
   Sumner RW, 2005, ACM T GRAPHIC, V24, P488, DOI 10.1145/1073204.1073218
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   WAMPLER CW, 1986, IEEE T SYST MAN CYB, V16, P93, DOI 10.1109/TSMC.1986.289285
   WANG LCT, 1991, IEEE T ROBOTIC AUTOM, V7, P489, DOI 10.1109/70.86079
   Wang XG, 1998, J VISUAL COMP ANIMAT, V9, P33, DOI 10.1002/(SICI)1099-1778(199801/03)9:1<33::AID-VIS174>3.0.CO;2-Q
   Wei XLK, 2011, IEEE COMPUT GRAPH, V31, P78, DOI 10.1109/MCG.2009.132
   White AugaustA., 1990, CLIN BIOMECH, V2e
   Wilhelms J., 2001, Journal of Graphics Tools, V6, P27, DOI 10.1080/10867651.2001.10487539
   Wu XM, 2011, IEEE COMPUT GRAPH, V31, P69, DOI 10.1109/MCG.2009.111
   Yamane K, 2003, IEEE T VIS COMPUT GR, V9, P352, DOI 10.1109/TVCG.2003.1207443
NR 58
TC 39
Z9 40
U1 1
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2016
VL 27
IS 1
BP 35
EP 57
DI 10.1002/cav.1630
PG 23
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4BX
UT WOS:000369868600004
DA 2024-07-18
ER

PT J
AU Lemercier, S
   Auberlet, JM
AF Lemercier, Samuel
   Auberlet, Jean-Michel
TI Towards more behaviours in crowd simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE multi-agent systems; computer animation; model development
ID DYNAMICS; ENVIRONMENT
AB While collision avoidance has been the most active topic in pedestrian simulation, the modelling of other kinds of behaviours appears to be essential for better realism. Thus higher cognitive levels of perception and behaviour improve simulation quality. Furthermore, giving an agent the possibility to choose the nature of its interactions with the others can not only improve simulation realism but also bring heterogeneity in the simulated population because each agent individually perceives the situation according to its own characteristics. In this paper, we aim at providing the pedestrian agent the ability to obtain an individual representation of the environment that allows him to adapt its behaviour according to the situation. We base our work on the analysis and interpretation of the environment, which makes the agent decide the behaviour it is going to adopt. We focus on two kinds of behaviours, following and group avoidance behaviours, and on their integration in classical avoidance simulations. We integrate recent works about following behaviour and propose to model interactions directly with groups of people instead of individuals. We aim at providing perception rules totally independent from the collision avoidance model used in the simulation. Because of the improved perception process, we observe emerging speed waves, group behaviours and lane formation in our simulations. Our results demonstrate the interest of modelling such behaviours to obtain more realistic simulations and show that specific patterns and collective behaviours emerge when using several types of behaviours in simulations. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Lemercier, Samuel; Auberlet, Jean-Michel] Univ Paris Est IFSTTAR, CoSyS, LEPSIS 14-20,Blvd Newton Cite Descartes, F-77447 Champs Sur Marne 2, Marne La Vallee, France.
C3 Universite Gustave-Eiffel
RP Auberlet, JM (corresponding author), Univ Paris Est IFSTTAR, CoSyS, LEPSIS 14-20,Blvd Newton Cite Descartes, F-77447 Champs Sur Marne 2, Marne La Vallee, France.
EM jean-michel.auberlet@ifsttar.fr
CR [Anonymous], GAM DEV C SAN JOS CA
   [Anonymous], P 11 IT WORKSH OBJ A
   [Anonymous], PEDESTRIAN EVACUATIO
   [Anonymous], 5 INT C AG ART INT B
   [Anonymous], 2012, PROC T EDUTAINMENT 7
   [Anonymous], 2012, Pedestrian and Evacuation Dynamics
   Braun A, 2003, COMP ANIM CONF PROC, P143, DOI 10.1109/CASA.2003.1199317
   Burstedde C, 2001, PHYSICA A, V295, P507, DOI 10.1016/S0378-4371(01)00141-8
   Chang PHM, 2005, LECT NOTES COMPUT SC, V3374, P57
   Chraibi M, 2010, PHYS REV E, V82, DOI 10.1103/PhysRevE.82.046111
   Daamen W., 2003, PEDESTRIAN EVACUATIO, P121
   Fajen BR, 2003, J EXP PSYCHOL HUMAN, V29, P343, DOI 10.1037/0096-1523.29.2.343
   Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176
   Golas A, 2014, IEEE T VIS COMPUT GR, V20, P1022, DOI 10.1109/TVCG.2013.235
   He L, 2013, IEEE INT CONF ROBOT, P2839, DOI 10.1109/ICRA.2013.6630970
   Helbing D, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.046109
   Helleboogh A, 2007, AUTON AGENT MULTI-AG, V14, P87, DOI 10.1007/s10458-006-0014-y
   Jelic A, 2012, PHYS REV E, V85, DOI 10.1103/PhysRevE.85.036111
   Johansson A., 2007, Adv. Complex Syst, V10, P271, DOI [10.1142/S0219525907001355, DOI 10.1142/S0219525907001355]
   Kapadia M, 2012, VISUAL COMPUT, V28, P1209, DOI 10.1007/s00371-011-0669-5
   Karamouzas I, 2012, IEEE T VIS COMPUT GR, V18, P394, DOI 10.1109/TVCG.2011.133
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Lemercier S, 2012, COMPUT GRAPH FORUM, V31, P489, DOI 10.1111/j.1467-8659.2012.03028.x
   Li TY, 2001, COMP ANIM CONF PROC, P93, DOI 10.1109/CA.2001.982381
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Moussaïd M, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002442
   Moussaïd M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Peters C, 2009, IEEE COMPUT GRAPH, V29, P54, DOI 10.1109/MCG.2009.69
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Qiu FS, 2010, SIMUL MODEL PRACT TH, V18, P190, DOI 10.1016/j.simpat.2009.10.005
   Sarmady S, 2009, 2009 THIRD ASIA INTERNATIONAL CONFERENCE ON MODELLING & SIMULATION, VOLS 1 AND 2, P520, DOI 10.1109/AMS.2009.16
   Schuerman M, 2010, COMPUT ANIMAT VIRT W, V21, P267, DOI 10.1002/cav.367
   Seyfried A, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/10/P10002
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   Singh H, 2009, APPL MATH MODEL, V33, P4408, DOI 10.1016/j.apm.2009.03.020
   Singh Shawn., 2011, ACM SIGGRAPH I3D, P141
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   Weyns D, 2007, AUTON AGENT MULTI-AG, V14, P5, DOI 10.1007/s10458-006-0012-0
   Yamori K, 1998, PSYCHOL REV, V105, P530, DOI 10.1037/0033-295X.105.3.530
   YEH H., 2008, SCA 08 P 2005 ACM SI, P39
   Yijiang Zhang, 2011, 2011 12th International Conference on Computer-Aided Design and Computer Graphics, P275, DOI 10.1109/CAD/Graphics.2011.48
NR 46
TC 20
Z9 25
U1 0
U2 24
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2016
VL 27
IS 1
BP 24
EP 34
DI 10.1002/cav.1629
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4BX
UT WOS:000369868600003
OA Bronze
DA 2024-07-18
ER

PT J
AU Jo, D
   Kim, KH
   Kim, GJ
AF Jo, Dongsik
   Kim, Ki-Hong
   Kim, Gerard Jounghyun
TI SpaceTime: adaptive control of the teleported avatar for improved AR
   tele-conference experience
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE tele-conference; augmented reality; teleportation; motion adaptation;
   scene matching; collaborative virtual environments
AB With the continued technology innovation in object sensing and human motion tracking, the traditional two-dimensional video-based tele-conference systems are projected to evolve into the three-dimensional immersive and augmented reality (AR) based on which one can communicate with the teleported remote other as if present, moving and interacting naturally in the same location. One technical hurdle to this vision is the need to resolve the environmental differences and the resulting teleported avatar motion anomaly between the remote and local sites. This paper presents a novel method to first establish a spatial and object-level match between the remote and local sites and adapts the position and motion of the teleported avatar into the local AR space according to the matched information. This results in a natural looking and spatially correct rendering of the remote user in the local augmented space and a significantly improved tele-conference experience and communication performance. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Jo, Dongsik] Elect & Telecommun Res Inst, Virtual Real Team, Taejon 305606, South Korea.
   [Jo, Dongsik] Korea Univ, Dept Comp Sci & Engn, Taejon, South Korea.
   [Kim, Ki-Hong] Elect & Telecommun Res Inst, Creat Content Res Div, Taejon 305606, South Korea.
   [Kim, Gerard Jounghyun] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Korea University; Electronics & Telecommunications Research Institute -
   Korea (ETRI); Korea University
RP Kim, GJ (corresponding author), Korea Univ, 145 Anam Ro, Seoul, South Korea.
EM gjkim@korea.ac.kr
FU ICT R&D program of MSIP/IITP [15501-14-1016]; National Research
   Foundation of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [2014-050807]
FX This work was supported by the ICT R&D program of MSIP/IITP.
   (15501-14-1016, Instant 3D object-based Join & Joy content technology
   supporting simultaneous participation of users in remote places and
   enabling realistic experience), and the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Science, ICT & Future Planning (No. 2014-050807).
CR Al-Asqhar Rami Ali, 2013, P 12 ACM SIGGRAPHEUR, P45
   Au OKC, 2010, COMPUT GRAPH FORUM, V29, P645, DOI 10.1111/j.1467-8659.2009.01634.x
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Bradner Erin., 2002, Proceedings of the 2002 ACM conference on Computer supported cooperative work, CSCW '02, P226
   Breiteneder CJ, 2006, P EUR WORKSH VIRT EN, P41
   Cho MS, 2013, IEEE I CONF COMP VIS, P25, DOI 10.1109/ICCV.2013.11
   DeSilva LC, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB607
   Firestone S, VOIC VID C FUND
   Hirai K, 2009, PSYCHOL HEALTH, V24, P149, DOI 10.1080/08870440701623124
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Jo D, 2013, ETRI J, V35, P356, DOI 10.4218/etrij.13.0212.0170
   Jo DS, IEEE VR 2014 3DCVE M
   Kang CG, 2014, COMPUT GRAPH FORUM, V33, P1, DOI 10.1111/cgf.12468
   Kim YG, 2012, ETRI J, V34, P791, DOI 10.4218/etrij.12.0212.0112
   Le Naour T, 2013, COMPUT ANIMAT VIRT W, V24, P419, DOI 10.1002/cav.1518
   Lehment NH, 2014, INT SYM MIX AUGMENT, P201, DOI 10.1109/ISMAR.2014.6948428
   Lyard E, 2008, COMPUT ANIMAT VIRT W, V19, P189, DOI 10.1002/cav.233
   Maimone A, 2013, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2013.6549352
   Pan Y, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1397, DOI 10.1145/2556288.2557276
   Papagiannakis G, 2005, COMPUT ANIMAT VIRT W, V16, P11, DOI 10.1002/cav.53
   Pece F, 2013, ACM CHI C HUM FACT C, P1319
   Raskar R., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P179, DOI 10.1145/280814.280861
   Shapiro A, 2014, COMPUT ANIMAT VIRT W, V25, P201, DOI 10.1002/cav.1579
   Steed A, 2012, IEEE COMPUT GRAPH, V32, P10, DOI 10.1109/MCG.2012.110
   Taylor MJ, 2001, COGNITIVE BRAIN RES, V10, P333, DOI 10.1016/S0926-6410(00)00051-3
   van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x
   Wu YX, 2014, IEEE T VIS COMPUT GR, V20, P626, DOI 10.1109/TVCG.2014.19
   Yamashita N, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P177
NR 28
TC 27
Z9 28
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 259
EP 269
DI 10.1002/cav.1645
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700008
DA 2024-07-18
ER

PT J
AU Huang, ZP
   Han, L
   Gong, GH
AF Huang, Zhanpeng
   Han, Liang
   Gong, Guanghong
TI A local adaptive Catmull-Rom to reduce numerical dissipation of
   semi-Lagrangian advection
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE interpolation; numerical dissipation; semi-Lagrangian advection; fluid
   simulation; computer animation
AB We propose an adaptive Catmull-Rom interpolation to improve accuracy of semi-Lagrangian advection for smoke simulation. Original Catmull-Rom improves numerical accuracy but overshoot violates global stability. Monotonic Catmull-Rom is unconditionally stable, whereas it sweeps out detail features due to overly suppression operations. Our method modifies original Catmull-Rom to obtain second-order accuracy and unconditional stability. It flattens locations where interpolations might break through global bounds but maintains local overshoots to conserve diversity of fluid flow. The scheme is easy to collaborate with existing fluid simulators to improve small features. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Huang, Zhanpeng; Han, Liang; Gong, Guanghong] Beihang Univ, Adv Simulat Technol Lab, Beijing 100191, Peoples R China.
C3 Beihang University
RP Huang, ZP (corresponding author), Beihang Univ, Adv Simulat Technol Lab, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM soaroc@asee.buaa.edu.cn
RI Han, Liang/KFR-6745-2024
CR Bridsons R, 2008, FLUID SIMULATION COM, P29
   Bryans E, 2005, P ACM SIGGRAPH LOS A, V24, P904
   Catmull E, 1974, inCom-puter Aided Geometric Design, P317, DOI [DOI 10.1016/B978-0-12-079050-0.50020-5, 10.1016/B978-0-12-079050-0.50020-5]
   Elcott S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1189762.1189766
   FELDMAN BE, 2005, P S COMP AN 2005, P255
   Georges W, 1999, P COMP GRAPH INT ALB, P188
   Kims B, 2005, P EUR WORKSH NAT PHE, V2, P47
   Kims D, 2008, EUROGRAPHICS C P CRE, V27, P467
   Klingner BM, 2006, ACM T GRAPHIC, V25, P820, DOI 10.1145/1141911.1141961
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Mullens P, 2009, P ACM SIGGRAPH NEW O, V28, P1
   NVIDIA Corporation, 2011, CUDA C PROGR GUID VE
   Oshers S, 2002, LEVEL SET METHODS DY, P32
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Takahashis T, 2003, EUROGRAPHICS C P GRA, V22, P102
   [No title captured]
NR 17
TC 4
Z9 5
U1 0
U2 4
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2015
VL 26
IS 2
BP 141
EP 146
DI 10.1002/cav.1559
PG 6
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CG3GB
UT WOS:000353165400005
DA 2024-07-18
ER

PT J
AU Zhu, XQ
   Jin, XG
   You, LH
AF Zhu, Xiaoqiang
   Jin, Xiaogang
   You, Lihua
TI Analytical solutions for tree-like structure modelling using subdivision
   surfaces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE branching structure modelling; Catmull-Clark subdivision; limit surface;
   CUDA
ID B-SPLINE SURFACES; CURVE INTERPOLATION; DESIGN
AB We present a novel approach to efficiently modelling branch structures with high-quality meshes. Our approach has the following advantages. First, the limit surface can fit the target skeleton models as tightly as possible by reversely calculating the control vertices of subdivision surfaces. Second, high performance is achieved through our proposed analytical solutions and the parallel subdivision scheme on a graphics processing unit. Third, a smooth manifold quad-only mesh is produced from the adopted Catmull-Clark scheme. A number of examples are given to demonstrate applications of our approach in various branch structures, such as tree branches, animal torsos, and vasculatures. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Zhu, Xiaoqiang; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Zhu, Xiaoqiang] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [You, Lihua] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
C3 Zhejiang University; Shanghai University; Bournemouth University
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM jin@cad.zju.edu.cn
FU National Natural Science Foundation of China [61272298, 61373084];
   Zhejiang Provincial Natural Science Foundation of China [Z1110154];
   China 863 programme [2012AA011503]; Major Science and Technology
   Innovation Team [2010R50040]
FX This work was supported by the National Natural Science Foundation of
   China (grant nos. 61272298 and 61373084), Zhejiang Provincial Natural
   Science Foundation of China (grant no. Z1110154), the China 863
   programme (grant no. 2012AA011503), and the Major Science and Technology
   Innovation Team (grant no. 2010R50040).
CR [Anonymous], ACM SIGGRAPH ASIA 20
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Bærentzen JA, 2012, COMPUT GRAPH-UK, V36, P555, DOI 10.1016/j.cag.2012.03.016
   Barthe L, 2003, LECT NOTES COMPUT SC, V2768, P40
   Cao J., 2010, SHAP MOD INT C SMI 2, P187, DOI [DOI 10.1109/SMI.2010.25, 10.1109/SMI.2010.25]
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   DOO D, 1978, COMPUT AIDED DESIGN, V10, P356, DOI 10.1016/0010-4485(78)90111-2
   Fabri A, 2000, SOFTWARE PRACT EXPER, V30, P1167, DOI 10.1002/1097-024X(200009)30:11<1167::AID-SPE337>3.0.CO;2-B
   Felkel P, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P70, DOI 10.1109/CGI.2004.1309194
   Hahn HK, 2001, IEEE VISUAL, P395, DOI 10.1109/VISUAL.2001.964538
   Ji ZP, 2010, COMPUT GRAPH FORUM, V29, P2169, DOI 10.1111/j.1467-8659.2010.01805.x
   Kanitsar A, 2001, IEEE VISUAL, P477, DOI 10.1109/VISUAL.2001.964555
   Klein J, 2009, COMPUT GRAPH-UK, V33, P554, DOI 10.1016/j.cag.2009.04.006
   Lluch J, 2004, GRAPH MODELS, V66, P89, DOI 10.1016/j.gmod.2004.01.002
   Loop C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618497
   Loops C., 1987, THESIS U UTAH UTAH
   Nasri A, 1997, COMPUT AIDED GEOM D, V14, P13, DOI 10.1016/S0167-8396(96)00018-0
   Nasri A., 2009, Proceedings of the 6th Eurographics Symposium on Sketch-Based Interfaces and Modeling, P53, DOI DOI 10.1145/1572741.1572751
   Nasri AH, 2000, COMPUT AIDED GEOM D, V17, P595, DOI 10.1016/S0167-8396(00)00015-7
   Nasri AH, 2002, GEOMETRIC MODELING AND PROCESSING: THEORY AND APPLICATIONS, PROCEEDINGS, P83, DOI 10.1109/GMAP.2002.1027499
   Nasri AH, 2002, COMPUT GRAPH-UK, V26, P393, DOI 10.1016/S0097-8493(02)00082-1
   Oeltze S, 2005, IEEE T MED IMAGING, V24, P540, DOI 10.1109/TMI.2004.843196
   Oeltze S., 2004, Proceedings of IEEE/Eurographics Symposium on Visualization (VisSym), P311
   Patney A., 2009, Proceedings of the Conference on High Performance Graphics 2009, P99
   Pihuit A., 2010, Eurographics Workshop on Sketch-Based Interfaces and Modeling (SBIM), P151
   Pirk S., 2012, ACM T GRAPHIC, V31, DOI DOI 10.1145/2185520.2185546
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366188
   Ritter F, 2006, IEEE T VIS COMPUT GR, V12, P877, DOI 10.1109/TVCG.2006.172
   Samavati FF, 1999, COMPUT GRAPH FORUM, V18, P97, DOI 10.1111/1467-8659.00361
   Schwarz M, 2009, COMPUT GRAPH FORUM, V28, P365, DOI 10.1111/j.1467-8659.2009.01376.x
   Sovakar A, 2004, COMPUT GRAPH-UK, V28, P67, DOI 10.1016/j.cag.2003.10.005
   Stam J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P395, DOI 10.1145/280814.280945
   Tobler RF, 2002, SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P35, DOI 10.1109/SMI.2002.1003526
   Xia J., 2011, S INTERACTIVE 3D GRA, P151
   Xu H, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289610
   Zhu XiaoQiang, 2013, Science China, Information Sciences, V56, DOI 10.1007/s11432-013-4790-0
NR 36
TC 3
Z9 4
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2015
VL 26
IS 1
BP 29
EP 42
DI 10.1002/cav.1563
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CC1LW
UT WOS:000350103200004
DA 2024-07-18
ER

PT J
AU Liu, SG
   Xu, YX
   Noh, JY
   Tong, YY
AF Liu, Shiguang
   Xu, Yixin
   Noh, Junyong
   Tong, Yiying
TI Visual fluid animation via lifting wavelet transform
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE physically based modeling; wavelet transform; detail enhancement
ID VORTEX PARTICLE METHOD; SMOKE SIMULATION; TURBULENCE; WATER
AB While small-scale fluid details are crucial elements for the creation of visually pleasing fluid animations, their synthesis often requires heavy computation with traditional grid-based fluid simulation methods. This paper proposes a novel method for enhancing the appearance of small-scale details through frequency-domain analysis. Different from previous work, our method detects and improves fluid details in the frequency-domain via lifting wavelet decomposition. Based on a coarse-to-fine mechanism, the lifting wavelet composition first transforms the velocity in a fine grid into the frequency domain. Next, the velocity field is enhanced separately for different frequency bands. A novel velocity fusion method is developed for the enhancement of low-frequency parts. On the other hand, high-frequency parts are enhanced using a specially designed vorticity confinement method. Finally, the application of the inverse lifting wavelet transform determines the final velocity field with increased fine details. Our method can generate perceptually interesting fluid details, matching human visual perception theory. The results of various experiments validate the effectiveness and efficiency of our method. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Liu, Shiguang; Xu, Yixin] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Noh, Junyong] Korea Adv Inst Sci & Technol, Taejon 305701, South Korea.
   [Tong, Yiying] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
   [Liu, Shiguang] Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300072, Peoples R China.
C3 Tianjin University; Korea Advanced Institute of Science & Technology
   (KAIST); Michigan State University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM lsg@tju.edu.cn
RI Noh, Junyong/C-1663-2011; Tong, Yiying/D-9202-2012
OI Tong, Yiying/0000-0002-7929-4333
FU Natural Science Foundation of China [61170118, 60803047]; Application
   Foundation Research Plan Project of Tianjin [14JCQNJC00100]; Open
   Project Program of the State Key Lab of CAD&CG, Zhejiang University
   [A1210]
FX The authors would like to thank the anonymous reviewers for their
   insightful comments, which greatly helped improving the manuscript. This
   work was supported by the Natural Science Foundation of China under
   grant nos. 61170118 and 60803047, the Application Foundation Research
   Plan Project of Tianjin under grant no. 14JCQNJC00100, and the Open
   Project Program of the State Key Lab of CAD&CG, Zhejiang University,
   under grant no. A1210.
CR [Anonymous], WAVELET TOUR SIGNAL
   [Anonymous], P ACM SIGGRAPH AS
   [Anonymous], 2008, P 2008 ACM SIGGRAPHE
   BERGER MJ, 1984, J COMPUT PHYS, V53, P484, DOI 10.1016/0021-9991(84)90073-1
   Bridson R, 2007, P SIGGRAPH SAN DIEG, P46
   Cornelis J, 2014, P EUR STRASB FRANC
   Cornsweet T.N., 1970, Visual Perception
   Dupont TF, 2003, J COMPUT PHYS, V190, P311, DOI 10.1016/S0021-9991(03)00276-6
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P181, DOI 10.1145/258734.258838
   Gao Y, 2013, IEEE T VIS COMPUT GR, V19, P178, DOI 10.1109/TVCG.2012.117
   Gao Y, 2009, COMPUT GRAPH FORUM, V28, P1845, DOI 10.1111/j.1467-8659.2009.01562.x
   Hansen BC, 2006, VISION RES, V46, P4398, DOI 10.1016/j.visres.2006.07.016
   He S, 2013, COMPUT GRAPH FORUM, V32, P27, DOI 10.1111/j.1467-8659.2012.03228.x
   He SF, 2011, COMPUT ANIMAT VIRT W, V22, P107, DOI 10.1002/cav.408
   Ihmsen M, 2012, VISUAL COMPUT, V28, P669, DOI 10.1007/s00371-012-0697-9
   Jang T, 2012, P COMP GRAPH INT BOU
   Kim B., 2005, P 1 EUROGRAPHICS C N, DOI DOI 10.2312/NPH/NPH05/051-056
   Kim D, 2012, IEEE T VIS COMPUT GR, V18, P1488, DOI 10.1109/TVCG.2011.264
   Kim T., 2008, P ACM SIGGRAPH
   Lamorlette A, 2002, ACM T GRAPHIC, V21, P729, DOI 10.1145/566570.566644
   Lentine M., 2010, P SIGGRAPH
   Li Z, 2001, P VRCAI HONG KONG, P557
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Narain R, 2008, P SIGGRAPH LOS ANG, P166
   Nielsen MichaelB., 2009, SCA '09: Proc. of the 2009 ACM SIGGRAPH/Eurographics Symp. on Comput. Anim, P217
   Rasmussen N, 2003, ACM T GRAPHIC, V22, P703, DOI 10.1145/882262.882335
   Ren B, 2013, IEEE T VIS COMPUT GR, V19, P1708, DOI 10.1109/TVCG.2013.73
   Schechter H., 2008, Symposium on Computer animation, P1
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J., 1993, Computer Graphics Proceedings, P369, DOI 10.1145/166117.166163
   Wang J, 2011, P ACM SCA VANC BC CA
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Witt TD, 2012, ACM T GRAPHIC, V31, P10
   Yoon JC, 2009, COMPUT GRAPH FORUM, V28, P1853, DOI 10.1111/j.1467-8659.2009.01563.x
   Yuan Z, 2011, P SIGGRAPH AS HONG K, P136
   Zhu B, 2010, COMPUT GRAPH FORUM, V29, P2207, DOI 10.1111/j.1467-8659.2010.01809.x
NR 39
TC 1
Z9 2
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 475
EP 485
DI 10.1002/cav.1574
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300028
DA 2024-07-18
ER

PT J
AU Sun, LB
   Li, XN
   Qin, WH
AF Sun, Libo
   Li, Xiaona
   Qin, Wenhu
TI Simulating realistic crowd based on agent trajectories
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents Conference (CASA)
CY 2013
CL Istanbul, TURKEY
DE crowd simulation; main characters; background characters; agent
   trajectory; SVM classifier
AB This paper presents a model for simulating realistic crowd behaviors at low computation cost. The proposed model is inspired by video data. In our approach, we first classify the crowd into two categories: main and background characters. Whether the agents are main characters or not is influenced by two factors, one is the agent's trajectories and the other one is the change of the environment. In the second stage, we adopt two approaches to simulate the behaviors of main and background characters. Main characters are intelligent agents with the perception, the memory, the planning, and the psychology so that they can make decisions themselves. Background characters are informed of the behavior options for execution by the smart environment. Finally, we simulate the road-crossing scenario in a three-dimensional virtual environment. The experimental results demonstrate that our approach not only well reflects the characteristics of agent behaviors but also reduces the computation complexity of simulating realistic crowd. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Sun, Libo; Li, Xiaona; Qin, Wenhu] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Qin, WH (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM qinwenhu@seu.edu.cn
CR [Anonymous], THESIS TIANJIN U TIA
   [Anonymous], COMPUTER DIGITAL ENG
   Chenney Stephen., 2004, Proceedings of the 2004 ACM SIGGRAPH/Euro- graphics symposium on Computer animation, P233, DOI [10.1145/1028523.1028553, DOI 10.1145/1028523.1028553.]
   Funge J, 1999, COMP GRAPH, P29, DOI 10.1145/311535.311538
   Guy S.J., 2011, P 2011 ACM SIGGRAPH, P43, DOI [10.1145/2019406.2019413, DOI 10.1145/2019406.2019413]
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Jiang Sheng, 2012, Journal of Southeast University (Natural Science Edition), V42, P1233, DOI 10.3969/j.issn.1001-0505.2012.06.038
   Kallmann M., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P124, DOI 10.1145/323663.323683
   Kim S., 2012, P ACM SIGGRAPH S INT, P55, DOI [DOI 10.1145/2159616.2159626, 10.1145/2159616.2159626]
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Narain R., 2009, ACM T GRAPHIC, V28, P8
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   Silverman BG, 2006, PRESENCE-VIRTUAL AUG, V15, P139, DOI 10.1162/pres.2006.15.2.139
   Stocker C, 2010, LECT NOTES ARTIF INT, V6356, P15, DOI 10.1007/978-3-642-15892-6_2
   Sun Li-Bo, 2010, Journal of Software, V21, P1171, DOI 10.3724/SP.J.1001.2010.03415
   Sun LB, 2009, I C COMP GRAPH IM VI, P106, DOI 10.1109/CGIV.2009.43
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Vapnik V., 1963, AUTOMAT REM CONTR, V24, P774, DOI DOI 10.12691/JGG-2-3-9
   Yu QX, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P119
NR 23
TC 7
Z9 9
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 165
EP 172
DI 10.1002/cav.1507
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 145GP
UT WOS:000319003500004
DA 2024-07-18
ER

PT J
AU Tan, CI
   Tai, WK
AF Tan, Charlie Irawan
   Tai, Wen Kai
TI Characteristics preserving racer animation: a data-driven race path
   synthesis in formation space
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE race path synthesis; formation field; racing game
AB We propose a race path synthesis framework based on a data-driven approach that provides good controllability for synthesizing race paths with characteristics preserved for racer animations. We introduce formation field, a data structure that samples regions in formation space that contains formations of exciting and realistic race paths, generated using a set of collected race paths in a path database. By traversing the regions according to a given constraint, we generate a path in formation space that defines how to synthesize the desired race path by interpolation. Because the new race path is synthesized from existing paths with quality guaranteed, it also provides the same level of quality. As the experimental and user study results show, our framework produces good results effectively and is suitable for both real-time applications such as horse racing games and race-path-generating tools. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Tan, Charlie Irawan; Tai, Wen Kai] Natl Dong Hwa Univ, Shoufeng 974, Hualien, Taiwan.
C3 National Dong Hwa University
RP Tai, WK (corresponding author), Natl Dong Hwa Univ, Sec 2,Da Hsueh Rd, Shoufeng 974, Hualien, Taiwan.
EM wktai@mail.ndhu.edu.tw
FU National Science Council, Taiwan, ROC [NSC99-2221-E-259-021]
FX The authors would like to thank all participants who contributed to this
   study. Also, we are grateful to anonymous reviewers for their helpful
   comments. This work was partially funded by the National Science
   Council, Taiwan, ROC, under grant NSC99-2221-E-259-021.
CR [Anonymous], CYAN MICR
   [Anonymous], 2012, Robot Motion Planning
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Burgard W., 2005, Principles of Robot Motion: Theory, Algorithms, and Implementations
   Chaperot B., 2006, 2006 IEEE Symposium on Computational Intelligence and Games (IEEE Cat. No. 06EX1415), P181, DOI 10.1109/CIG.2006.311698
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   LAVALLE S.M., 2006, Planning algorithms, DOI DOI 10.1017/CBO9780511546877
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Munkres JR, 1993, SIMPLICES
   Sidhe Interactive, MELB CUP CHALL
   Sud A, 2008, IEEE T VISUALIZATION, V14, P55
   Takahashi S, 2009, COMPUT GRAPH FORUM, V28, P526
   Tan Charlie Irawan, 2008, 2008 International Conference on Machine Learning and Cybernetics (ICMLC), P3132, DOI 10.1109/ICMLC.2008.4620946
   Tan CI, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P2939, DOI 10.1109/ICMLC.2009.5212595
   Tan CI, 2010, INT J ARTIF INTELL T, V19, P679, DOI 10.1142/S0218213010000364
   The Hong Kong Jockey Club, HONG KONG JOCK CLUB
   Togelius J, 2005, IEEE C EVOL COMPUTAT, P1906
   Togelius J, 2006, IEEE C EVOL COMPUTAT, P1172
NR 22
TC 0
Z9 0
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 215
EP 223
DI 10.1002/cav.1445
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100009
DA 2024-07-18
ER

PT J
AU Thalmann, D
   Ali, S
   Faloutsos, P
AF Thalmann, Daniel
   Ali, Saad
   Faloutsos, Petros
TI Editorial for the CAVW special issue on real-time crowd simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
NR 0
TC 0
Z9 0
U1 0
U2 1
PU WILEY-BLACKWELL
PI MALDEN
PA COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2012
VL 23
IS 1
BP 1
EP 1
DI 10.1002/cav.1425
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 897SH
UT WOS:000300675800002
DA 2024-07-18
ER

PT J
AU Huang, D
   Tang, W
   Wan, TR
   John, NW
   Gould, D
   Ding, Y
   Chen, Y
AF Huang, D.
   Tang, W.
   Wan, T. R.
   John, N. W.
   Gould, D.
   Ding, Y.
   Chen, Y.
TI A new approach to haptic rendering of guidewires for use in minimally
   invasive surgical simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE physics simulation; 1D soft bodies; haptic interaction; multimodal
   interactive virtual environment
ID REAL
AB Guidewire insertion is an imperative task of minimally invasive medical procedures. During the procedure, surgeons need to steer long flexible thin wires through patient's blood vessels to reach a clinical target. In this paper, we present a novel approach to model haptics of guidewire insertion process for training simulation. The algorithm also allows for the analysis of the insertion process through subtle physical behaviours of guidewires via force feedbacks. The method includes a 6-DoF dynamic coupling between a rigid body, i.e. the virtual tool and the deformation of the wire simulated as an elastic rod. Instead of using the frictional contact force or the acceleration of the guidewire tip for haptic feedbacks, we compute constrained forces by directly connecting the virtual tool to the end of the guidewire. Therefore, the coupling scheme transmits haptic interactions through constrained dynamics between the virtual tool and the guidewire. Both positional and rotational control modes are implemented and evaluated with respect to the dynamics of the guidewire, user inputs and feedback forces. Experiments highlight the usability of our algorithm for an insertion procedure simulation with complex blood vessel structures. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Tang, W.] Univ Teesside, Sch Comp, Middlesbrough TS1 3BA, Cleveland, England.
   [Huang, D.; Chen, Y.] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Huang, D.; Chen, Y.] Shanghai Univ, Sch Comp Engn Sci, Shanghai, Peoples R China.
   [Wan, T. R.] Univ Bradford, Sch Informat & Media, Bradford BD7 1DP, W Yorkshire, England.
   [Wan, T. R.] Univ Bradford, Sch Informat, Bradford BD7 1DP, W Yorkshire, England.
   [John, N. W.] Bangor Univ, Sch Comp Sci, Bangor, Gwynedd, Wales.
   [Gould, D.] Royal Liverpool Univ Hosp, Dept Radiol, Liverpool, Merseyside, England.
   [Ding, Y.] Shanghai Univ, Sch Film & TV Arts Technol, Shanghai, Peoples R China.
C3 University of Teesside; Shanghai University; Shanghai University;
   University of Bradford; University of Bradford; Bangor University;
   University of Liverpool; Royal Liverpool & Broadgreen University
   Hospitals NHS Trust; Royal Liverpool University Hospital; Shanghai
   University
RP Tang, W (corresponding author), Univ Teesside, Sch Comp, Middlesbrough TS1 3BA, Cleveland, England.
EM w.tang@tees.ac.uk
RI John, Nigel/ABC-8011-2020
OI John, Nigel/0000-0001-5153-182X
CR Alderliesten T, 2007, IEEE T BIO-MED ENG, V54, P29, DOI 10.1109/TBME.2006.886659
   BARAFF D, 1991, SIGGRAPH 91 P, V25, P31
   BARAFF D, 1994, SIGGRAPH 94, P23, DOI DOI 10.1145/192161.192168
   Bergou M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360662
   Bertails F, 2006, ACM T GRAPHIC, V25, P1180, DOI 10.1145/1141911.1142012
   Bertails F, 2009, COMPUT GRAPH FORUM, V28, P417, DOI 10.1111/j.1467-8659.2009.01381.x
   BONANNI U, 2009, P VRST 09 P 16 ACM S
   Brown J, 2004, VISUAL COMPUT, V20, P165, DOI 10.1007/s00371-003-0226-y
   Çavusoglu MC, 2002, PREN HAL IMSC P MULT, P217
   Çavusoglu MC, 1999, IEEE T ROBOTIC AUTOM, V15, P728, DOI 10.1109/70.782027
   Coles TR, 2011, IEEE T HAPTICS, V4, P51, DOI [10.1109/TOH.2010.19, 10.1109/ToH.2010.19]
   Cotin S, 2005, LECT NOTES COMPUT SC, V3750, P534, DOI 10.1007/11566489_66
   Cotin S, 2000, Stud Health Technol Inform, V70, P59
   GREGOIRE M, 2006, S SOL PHYS MOD, P95
   Johnson DE, 2005, IEEE T VIS COMPUT GR, V11, P661, DOI 10.1109/TVCG.2005.106
   KUHI C, 2002, ESAIM P
   LENOIR J, 2008, P 4 INT S BIOM SIM, V5104, P215
   LENOIR J, 2002, MS4CMS ROCQ 12 15 NO
   Lin M.C., 2008, HAPTIC RENDERING FOU
   LUNDERQUIST A, 1995, CARDIOVASC INTER RAD, V18, P209
   Magnenat-Thalmann N., 2007, The International Journal of Virtual Reality, V6, P35
   Ohnishi K, 2009, ARTIF LIFE ROBOT, V13, P383, DOI 10.1007/s10015-008-0624-3
   Pai DK, 2002, COMPUT GRAPH FORUM, V21, P347, DOI 10.1111/1467-8659.00594
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Shi F, 2008, LECT NOTES COMPUT SC, V5024, P599
   Spillmann J., 2007, PROC ACM SIGGRAPHEUR, P209
   Stone, 1992, LINEAR COMPLEMENTARI
   Tang W, 2010, VISUAL COMPUT, V26, P1157, DOI 10.1007/s00371-010-0442-1
   Villard PF, 2009, STUD HEALTH TECHNOL, V142, P401, DOI 10.3233/978-1-58603-964-6-401
   WANG F, 2005, EUR C 2005 S HAPT IN, P507
   ZORCOLO A, 2000, 6 EUR WORKSH VIRT EN
   ZORCOLO A, 1999, 1 PHANTOM US RES S P
NR 32
TC 8
Z9 10
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 261
EP 268
DI 10.1002/cav.417
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700022
DA 2024-07-18
ER

PT J
AU Liu, KY
   Ma, WC
   Chang, CF
   Wang, CC
   Debevec, P
AF Liu, Ko-Yun
   Ma, Wan-Chun
   Chang, Chun-Fa
   Wang, Chuan-Chang
   Debevec, Paul
TI A framework for locally retargeting and rendering facial performance
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE expression synthesis; facial retargeting; normal map blending
ID UNIFIED APPROACH
AB We present a facial motion retargeting method that enables the control of a blendshape rig according to marker-based motion capture data. The main purpose of the proposed technique is to allow a blendshape rig to create facial expressions, which conforms best to the current motion capture input, regardless the underlying blendshape poses. In other words, even though all of the blendshape poses may comprise symmetrical facial expressions only, our method is still able to create asymmetrical expressions without physically splitting any of them into more local blendshape poses. An automatic segmentation technique based on the analysis of facial motion is introduced to create facial regions for local retargeting. We also show that it is possible to blend normal maps for rendering in the same framework. Rendering with the blended normal map significantly improves surface appearance and details. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Liu, Ko-Yun] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Ma, Wan-Chun; Debevec, Paul] Univ So Calif, Inst Creat Technol, Los Angeles, CA 90089 USA.
   [Chang, Chun-Fa] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Chang, Chun-Fa] Natl Taiwan Normal Univ, Dept Comp Sci, Taipei, Taiwan.
C3 National Tsing Hua University; University of Southern California;
   National Taiwan Normal University; National Taiwan Normal University
EM coco.kyliu@gmail.com; ma@ict.usc.edu; chunfa@ntnu.edu.tw
CR Alexander O, 2010, IEEE COMPUT GRAPH, V30, P20, DOI 10.1109/MCG.2010.65
   [Anonymous], 2007, P 18 EUROGRAPHICS C, DOI [10.2312/EGWR/EGSR07/183-194., DOI 10.2312/EGWR/EGSR07/183-194.6]
   Bickel B., 2008, Proceedings of the 2008 ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA '08), P57
   Bickel B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239484
   BORSHUKOV G, 2003, SIGGRAPH SKETCHES
   Buck I., 2000, Proceedings of the 1st international symposium on Non-photorealistic animation and rendering, NPAR '00, P101
   CHUANG E, 2004, THESIS STANFORD U
   Deng Z., 2006, P 2006 S INT 3D GRAP, P43, DOI DOI 10.1145/1111411.1111419]
   Ekman P, 1978, FACIAL ACTION CODING
   Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387
   Hassenzahl M, 2003, Berichte Des Ger Chapter Acm, V2003, P187
   Hawkins Tim., 2004, Rendering Techniques 2004, P309, DOI DOI 10.2312/EGWR/EGSR04/309-319
   Kautz J, 2000, SPRING COMP SCI, P185
   Lewis JP, 2010, IEEE COMPUT GRAPH, V30, P42, DOI 10.1109/MCG.2010.41
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   LEWIS JP, 2007, P IM VIS COMP NZ, P187
   Li Q, 2008, IEEE COMPUT GRAPH, V28, P76, DOI 10.1109/MCG.2008.120
   Liu XC, 2008, COMPUT ANIMAT VIRT W, V19, P235, DOI 10.1002/cav.248
   Ma WC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409074
   MARTIN GC, 1997, PRESTON BLAIR PHOMEN
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   OAT C, 2007, SIGGRAPH COURSES
   PIGHIN F, 2006, SIGGRAPH COURSES
   PIGHIN F, 1998, P SIGGRAPH 98, P75
   PYUN H, 2003, P ACM SIGGRAPH EUR S, P167
   SANCHEZ MA, 2006, THESIS U SHEFFIELD
   Williams L., 1990, Proceedings of SIGGRAPH, V24, P235
NR 27
TC 4
Z9 6
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 159
EP 167
DI 10.1002/cav.404
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700011
DA 2024-07-18
ER

PT J
AU Süssmuth, J
   Zollhöfer, M
   Greiner, G
AF Suessmuth, Jochen
   Zollhoefer, Michael
   Greiner, Guenther
TI Animation transplantation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE animation transfer; animation transplantation; facial animation;
   non-rigid registration
ID NONRIGID REGISTRATION
AB We present a novel method to animate a static geometry by cloning a captured animation sequence. More precisely, given a sequence of range scans of a deforming object which has been captured by a real-time 3D scanner, we describe a novel algorithm to clone the animation of the recorded geometry onto another triangle mesh. To achieve this, we reconstruct a coherent animated mesh of the input sequence using a template deformation approach. Then we employ a new algorithm for robust marker-less non-rigid registration to deform one frame of the generated animation such that it matches a different 3D model. The resulting registration is further used to find correspondences between the animation and the target object which are in turn used to transfer the animation of the recorded sequence onto the target shape. Transferring the entire geometry of the animations results in very convincing facial expressions since even the smallest expression wrinkles are preserved. We evaluate the robustness and the performance of the proposed algorithms using a variety of data sets, including facial animations and whole body animations. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Suessmuth, Jochen] Univ Erlangen Nurnberg, Comp Graph Grp, D-91058 Erlangen, Germany.
   [Greiner, Guenther] Univ Erlangen Nurnberg, Fac Engn, D-8520 Erlangen, Germany.
C3 University of Erlangen Nuremberg; University of Erlangen Nuremberg
RP Süssmuth, J (corresponding author), Univ Erlangen Nurnberg, Comp Graph Grp, Wolfsmantel 33, D-91058 Erlangen, Germany.
EM suessmuth@informatik.uni-erlangen.de
CR [Anonymous], P ACM SIGGRAPH
   Bickel B., 2008, Proceedings of the 2008 ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA '08), P57
   Chang W, 2009, COMPUT GRAPH FORUM, V28, P447, DOI 10.1111/j.1467-8659.2009.01384.x
   Chang W, 2008, COMPUT GRAPH FORUM, V27, P1459, DOI 10.1111/j.1467-8659.2008.01286.x
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Huang QX, 2008, COMPUT GRAPH FORUM, V27, P1449, DOI 10.1111/j.1467-8659.2008.01285.x
   Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Ma WC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409074
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Shinya M., 2004, Proceedings. 2nd International Symposium on 3D Data Processing, Visualization, and Transmission, P904, DOI 10.1109/TDPVT.2004.1335411
   Sorkine O, 2007, S GEOM PROC, V4, P109, DOI [10.1145/1073204.1073323, DOI 10.1145/1073204.1073323]
   Süssmuth J, 2008, COMPUT GRAPH FORUM, V27, P1469, DOI 10.1111/j.1467-8659.2008.01287.x
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   SUSSMUTH J, 2010, COMPUTER GR IN PRESS, V29
   Wand M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1516522.1516526
   Wand Michael, 2007, ACM International Conference Proceeding Series, V257, P49, DOI 10.2312/SGP/SGP07/049-058
   Wang SL, 2008, PUBLIC FINANCE IN CHINA: REFORM AND GROWTH FOR A HARMONIOUS SOCIETY, P1
   WEISE T, 2009, P SCA 09
   Weise T., 2007, IEEE CVPR, P1, DOI DOI 10.1109/CVPR.2007.383291
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang S, 2006, OPT ENG, V45, DOI 10.1117/1.2336196
NR 22
TC 5
Z9 5
U1 4
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 173
EP 182
DI 10.1002/cav.364
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400005
DA 2024-07-18
ER

PT J
AU Yang, Y
   Rong, GD
   Torres, L
   Guo, XH
AF Yang, Yin
   Rong, Guodong
   Torres, Luis
   Guo, Xiaohu
TI Real-time hybrid solid simulation: spectral unification of deformable
   and rigid materials
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE GPU; hybrid simulation; modal analysis; physically-based animation
AB A novel framework is proposed in this paper to simulate hybrid solids with deformable and rigid materials in real-time. Both types of materials are uniformly integrated into one spectral simulator. Based on the modal warping technique, we employ a new constraint strategy which eliminates the accumulation of approximation errors at the boundary interfaces, thus naturally gluing different materials. We also utilize the GPU to accelerate the run-time computation when updating the geometry of the hybrid solid the most expensive step in this framework. This work provides a general-purpose solution of simulating hybrid objects in real-time, even for large-scale models. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Torres, Luis; Guo, Xiaohu] Univ Texas Dallas, Dept Comp Sci, Dallas, TX 75230 USA.
C3 University of Texas System; University of Texas Dallas
RP Guo, XH (corresponding author), Univ Texas Dallas, Dept Comp Sci, Dallas, TX 75230 USA.
EM xguo@utdallas.edu
RI Rong, Guodong/A-7851-2009
OI Yang, Yin/0000-0001-7645-5931
CR [Anonymous], P 2007 ACM SIGGRAPH
   Baraff D., 1997, CMURITR9733
   Capell S, 2002, ACM T GRAPHIC, V21, P586, DOI 10.1145/566570.566622
   Choi MG, 2005, IEEE T VIS COMPUT GR, V11, P91
   CHOI MG, 2007, P EUR 07, P349
   Galoppo N., 2006, Proc. Symp. on Computer Animation, P73
   Guo XH, 2005, COMPUT ANIMAT VIRT W, V16, P189, DOI 10.1002/cav.98
   Huang J, 2006, COMPUT GRAPH-UK, V30, P927, DOI 10.1016/j.cag.2006.08.014
   James DL, 2002, ACM T GRAPHIC, V21, P582, DOI 10.1145/566570.566621
   JOHAN J, 2003, VISUAL COMPUT, V19, P280
   KHAREVYCH L, 2009, SIGGRAPH 09, P1
   Lenoir J, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P327, DOI 10.1109/CGI.2004.1309229
   METAXAS D, 1992, COMP GRAPH, V26, P309, DOI 10.1145/142920.134085
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   Nesme M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531358
   PENTLAND A, 1989, SIGGRAPH COMPUT GRAP, V23, P207
   RAGHUVANSHI N, 2009, EUR AC ASS S AUR
   Robinson-Mosher A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360645
   TAMAR S, 2008, P 2008 ACM SIGGRAPH, P95
   TERZOPOULOS D, 1988, IEEE COMPUT GRAPH, V8, P41, DOI 10.1109/38.20317
   Xu WW, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531341
NR 21
TC 5
Z9 5
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 151
EP 159
DI 10.1002/cav.373
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400003
DA 2024-07-18
ER

PT J
AU Chen, C
   Zhuang, YT
   Xiao, J
   Liang, Z
AF Chen, Cheng
   Zhuang, Yueting
   Xiao, Jun
   Liang, Zhang
TI Perceptual 3D pose distance estimation by boosting relational geometric
   features
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE pose similarity; pose distance; geometric feature; pose analysis
ID MOTION; EXTRACTION
AB Traditional pose similarity functions based on joint coordinates or rotations often do not conform to human perception. We propose a new perceptual pose distance: Relational Geometric Distance that accumulates the differences over a set of features that reflects the geometric relations between different body parts. An extensive relational geometric feature pool that contains a large number of potential features is defined, and the features effective for pose similarity estimation are selected using a set of labeled data by Adaboost. The extensive feature pool guarantees that a wide diversity of features is considered, and the boosting ensures that the selected features are optimized when used jointly. Finally, the selected features form a pose distance function that can be used for novel poses. Experiments show that our method outperforms others in emulating human perception in pose similarity. Our method call also adapt to specific motion types and capture the features that are important for pose similarity of a certain motion type. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Chen, Cheng; Xiao, Jun; Liang, Zhang] ZJU, Microsoft Visual Percept Lab, Hangzhou, Zhejiang, Peoples R China.
   [Zhuang, Yueting] ZJU, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Chen, C (corresponding author), Zhejiang Univ, Dept Comp Sci, 38 Zheda Rd, Hangzhou 310027, Peoples R China.
EM cchen@zju.edu.cn
CR [Anonymous], 2006, CS0608 BROWN U DEP C
   [Anonymous], 2004, P INT C VERY LARGE D
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Arikan O, 2006, ACM T GRAPHIC, V25, P890, DOI 10.1145/1141911.1141971
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Harada T, 2004, IEEE-RAS INT C HUMAN, P494
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lee MW, 2009, IEEE T PATTERN ANAL, V31, P27, DOI 10.1109/TPAMI.2008.35
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   So CKF, 2005, COMPUT ANIMAT VIRT W, V16, P225, DOI 10.1002/cav.107
   Tang JKT, 2008, COMPUT ANIMAT VIRT W, V19, P211, DOI 10.1002/cav.260
   XIAO J, 2006, P COMP GRAPH INT, P494
   Zhao J, 2004, COMPUT ANIMAT VIRT W, V15, P407, DOI 10.1002/cav.44
NR 15
TC 10
Z9 12
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 267
EP 277
DI 10.1002/cav.297
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700020
DA 2024-07-18
ER

PT J
AU Kim, JW
   Fouad, H
   Sibert, JL
   Hahn, JK
AF Kim, Jae Woo
   Fouad, Hesham
   Sibert, John L.
   Hahn, James K.
TI Perceptually motivated automatic dance motion generation for music
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE animation analysis and structuring; behavioral animation; gesture
   generation
AB In this paper, we describe a novel method to automatically generate synchronized dance motion that is perceptually matched to a given musical piece. The proposed method extracts 30 musical features from musical data as Well as 37 motion features from motion data. A matching process is then performed between the two feature spaces considering the correspondence of the relative changes in both feature spaces and the correlations between musical and motion features. Similarity matrices are introduced to match the amount of relative changes in both feature spaces and correlation coefficients are used to establish the correlations between musical features and motion features in measuring the strength of correlation between each pair of the musical and motion features. By doing this, the progressions of musical and dance motion patterns and perceptual changes between two consecutive musical and motion segments are matched. To demonstrate the effectiveness of the proposed approach, we designed and carried out a user opinion study to assess the perceived quality of the proposed approach. The statistical analysis of the user study results showed that the proposed approach generated results that Were significantly better than those produced using a random walk through the dance motion database. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Kim, Jae Woo; Sibert, John L.; Hahn, James K.] George Washington Univ, Dept Comp Sci, Washington, DC 20052 USA.
C3 George Washington University
RP Kim, JW (corresponding author), George Washington Univ, Dept Comp Sci, 801 22nd St NW, Washington, DC 20052 USA.
EM zoltar@gwu.edu
RI Hahn, James/AAF-8272-2021
CR Alankus G, 2005, COMPUT ANIMAT VIRT W, V16, P259, DOI 10.1002/cav.99
   Cardle M, 2002, 20TH EUROGRAPHICS UK CONFERENCE, PROCEEDINGS, P38, DOI 10.1109/EGUK.2002.1011270
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   DOBRIAN C, 2003, NIME 03, P161
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Laban Rudolf., 1980, The Mastery of Movement, V4th
   Lee HC, 2005, COMPUT GRAPH FORUM, V24, P353, DOI 10.1111/j.1467-8659.2005.00860.x
   MORIOKA H, 2004, ACE 04, P296
   SAUER D, ACM T MULTIMEDIA COM
   Shiratori T, 2006, COMPUT GRAPH FORUM, V25, P449, DOI 10.1111/j.1467-8659.2006.00964.x
   Shiratori T, 2006, IEEE INT CONF ROBOT, P3654, DOI 10.1109/ROBOT.2006.1642260
   TZANETAKIS G, 2002, THESIS PRINCETON
NR 13
TC 11
Z9 12
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 375
EP 384
DI 10.1002/cav.314
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700030
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Liu, XG
   Xiao, CX
   Peng, QS
AF Zhao, Yong
   Liu, Xinguo
   Xiao, Chunxia
   Peng, Qunsheng
TI A unified shape editing framework based on tetrahedral control mesh
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE interactive deformation; deformation transfer; tetrahedral control mesh;
   rigidity energy; error-driven refinement; volumetric correspondence
AB It is a fundamental but challenging problem to efficiently edit complex 3D objects. By embedding the input models into coarse tetrahedral control meshes, this paper develops a unified framework to discuss two useful editing operations: interactive deformation and deformation transfer. First, a new rigidity energy is proposed to make the tetrahedral control mesh deform as rigidly as possible, which yields intuitive detail and volume preservation even under large deformations. And an error-driven refinement approach is presented to further improve the deformation result. Then, based on this deformation scheme, a volumetric correspondence method is introduced to perform the deformation transfer task between the tetrahedral control meshes of the source and target models, which greatly lessens the burden of the user. Experimental results show our algorithm is effective, easy to control, supports various shape representations, and Well transfers deformations between non-homeomorphous models. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Liu, Xinguo] Zhejiang Univ, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
   [Peng, Qunsheng] Zhejiang Univ, Dept Math, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Zhao, Y (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
EM zhaoyong@cad.zju.edu.cn
CR [Anonymous], 2007, S GEOMETRY PROCESSIN
   Au OKC, 2006, IEEE T VIS COMPUT GR, V12, P386, DOI 10.1109/TVCG.2006.47
   Botsch M, 2003, COMPUT GRAPH FORUM, V22, P483, DOI 10.1111/1467-8659.00696
   Botsch M., 2006, SGP 06, P11
   Botsch M, 2007, COMPUT GRAPH FORUM, V26, P339, DOI 10.1111/j.1467-8659.2007.01056.x
   CHANG Y, 2006, P COMP GRAPH INT
   Guskov I, 1999, COMP GRAPH, P325, DOI 10.1145/311535.311577
   Huang J, 2006, ACM T GRAPHIC, V25, P1126, DOI 10.1145/1141911.1142003
   Huang J, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P241
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   RIVER AR, 2007, ACM T GRAPHICS, V26
   Sauvage B, 2007, COMPUT GRAPH FORUM, V26, P275, DOI 10.1111/j.1467-8659.2007.01049.x
   Shi XH, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239532
   SONG W, 2007, P GRAPH INT, P319
   Sorkine O., 2004, P 2004 EUR ACM SIGGR, P179
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tong YY, 2003, ACM T GRAPHIC, V22, P445, DOI 10.1145/882262.882290
   Wang YS, 2008, VISUAL COMPUT, V24, P765, DOI 10.1007/s00371-008-0258-4
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zayer R, 2005, COMPUT GRAPH FORUM, V24, P601, DOI 10.1111/j.1467-8659.2005.00885.x
   Zhou K, 2005, ACM T GRAPHIC, V24, P496, DOI 10.1145/1073204.1073219
NR 25
TC 5
Z9 5
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 301
EP 310
DI 10.1002/cav.302
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700023
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, C
   Jin, XG
   Wang, CCL
AF Zhou, Chuan
   Jin, Xiaogang
   Wang, Charlie C. L.
TI Shear buckling and dynamic bending in cloth simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE cloth simulation; physically based animation; shear; bending
ID ANIMATION; ELEMENT
AB This paper addresses the problem of simulating the mechanical behavior of cloth in computer animation, which is very important and challenging. The micro-structure of Woven fabrics leads to significantly different shear reaction from other sheet materials, Which has been neglected in previous approaches of cloth simulation. Therefore, it is beneficial for cloth simulation to model the shear buckling and structural bending separately. We analyze the shear buckling yielded by the micro-structure of woven and the dynamic bending based on the thin-shell theory, and develop a compact implementation of the new model oil mass-spring systems. Experimental results show that the animations generated using this technique are with wrinkles and folds appearing and vanishing ill a snore natural Way than other approaches. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Zhou, Chuan; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Wang, Charlie C. L.] Chinese Univ Hong Kong, Dept Automat & Comp Aided Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Zhejiang University; Chinese University of Hong Kong
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM jin@cad.zju.edu.cn
RI Wang, Charlie C. L./B-3730-2010
OI Wang, Charlie C. L./0000-0003-4406-8480
CR Ascough J, 1996, J TEXT I, V87, P152, DOI 10.1080/00405009608659063
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   BRIDSON R, 2003, P 2003 ACM SIGGRAPH, P28
   CARIGNAN M, 1992, COMP GRAPH, V26, P99, DOI 10.1145/142920.134017
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   Desbrun M, 1999, PROC GRAPH INTERF, P1
   EBERHARDT B, 2000, P EUR WORKSH COMP AN
   EISCHEN J, 2000, CLOTH MODELING ANIMA, P196
   Eischen JW, 2000, CLOTH MODELING ANIMA, P79
   ETZMUSS O, 2003, IEEE T VISUALIZATION, V9, P533
   FUHRMANN A, 2003, P WINT SCH COMP GRAP, P203
   Fung Y.C., 2001, CLASSICAL COMPUTATIO
   Grinspun E., 2003, P 2003 ACM SIGGRAPH, P62
   Kang YM, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P247, DOI 10.1109/CGI.2000.852340
   KANG YM, 2003, THESIS PUSAN NATL U
   Liu JD, 1996, VISUAL COMPUT, V12, P234
   MEZGER J, 2003, P WINT SCH COMP GRAP, P322
   PROVOT X, 1995, GRAPH INTER, P147
   Tan ST, 1999, VISUAL COMPUT, V15, P90, DOI 10.1007/s003710050164
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   THOMASZWESKI B, 2005, WSI200519 U TUB
   Volino P, 1996, IEEE COMPUT GRAPH, V16, P42, DOI 10.1109/38.536274
   VOLINO P, 1995, P SIGGRAPH 95, P137
   VOLINO P, 2000, P COMP AN CA 2000 IE
   Zhou C, 2008, PROG NAT SCI-MATER, V18, P879, DOI 10.1016/j.pnsc.2008.02.008
   Zhou C, 2008, COMPUT SCI ENG, V10, P30, DOI 10.1109/MCSE.2008.93
NR 27
TC 12
Z9 18
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 493
EP 503
DI 10.1002/cav.253
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200030
DA 2024-07-18
ER

PT J
AU He, HT
   Xu, DQ
AF He, HT
   Xu, DQ
TI Real-time cartoon animation of smoke
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE smoke; particle system; physics-based simulation; cartoon animation;
   non-photorealistic rendering
AB In this paper, we present a practical framework to generate cartoon style animations of smoke, which consists of two components: a smoke simulator and a rendering system. In the simulation stage, the smoke is modelled as a set Of smoothed particles and the physical parameters such as velocity and force are defined on particles directly. The smoke is rendered in flicker-free cartoon style with two-tone shading and silhouettes. Both the simulation and rendering are intuitive and easy to implement. In the most moderate scale scene, an impressive cartoon animation is generated with about a thousand particles at real-time frame rate. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
EM xdq@zju.edu.cn
CR BANDO Y, 2003, P EUROGRAPHICS, P411
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Chenney S., 2002, INT S NONPHOTOREALIS, P133, DOI DOI 10.1145/508530.508553
   Desbrun M., 1996, P EUROGRAPHICS WORKS, P61
   Deussen O, 2000, COMP GRAPH, P13, DOI 10.1145/344779.344792
   DIFIORE F, 2004, P COMP AN SOC AG CAS, P171
   Dobashi Y, 2000, COMP GRAPH, P19, DOI 10.1145/344779.344795
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   GOOCH B, 1999, P SIGGRAPH, P133
   HADAP S, 2001, P EUROGRAPHICS, P329
   Kowalski MA, 1999, COMP GRAPH, P433, DOI 10.1145/311535.311607
   LUCY LB, 1977, ASTRON J, V82, P1013, DOI 10.1086/112164
   MARKOSIAN L, 2000, P NPAR 2000, P59
   MCGUIRE M, 2004, P SIGGRAPH
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Muller M., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, P154
   O'Brien D, 2001, COMP ANIM CONF PROC, P210, DOI 10.1109/CA.2001.982395
   Premoze S, 2003, COMPUT GRAPH FORUM, V22, P401, DOI 10.1111/1467-8659.00687
   Rasmussen N, 2003, ACM T GRAPHIC, V22, P703, DOI 10.1145/882262.882335
   SCHAUFLER G, 1997, P 8 EUR WORKSH REND, P151
   Selle Andrew., 2004, Proceedings of the 3rd International Symposium on Non-Photorealistic Animation and Rendering. NPAR'04, P57, DOI [10.1145/987657.987666, DOI 10.1145/987657.987666]
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam Jos., 1995, Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, SIGGRAPH '95, P129
   Stora D, 1999, PROC GRAPH INTERF, P203
   YU J, 2000, J COMPUTERS, V23, P987
NR 27
TC 2
Z9 4
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 441
EP 449
DI 10.1002/cav.103
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000027
DA 2024-07-18
ER

PT J
AU Van Laerhoven, T
   Van Reeth, F
AF Van Laerhoven, T
   Van Reeth, F
TI Real-time simulation of watery paint
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE paint systems; physically based modeling; non-photorealistic rendering
AB Existing work on applications for thin watery paint is mostly focused on automatic generation of painterly-style images from input images, ignoring the fact that painting is a process that intuitively should be interactive. Efforts to create real-time interactive systems are limited to a single paint medium and results Often suffer from a trade-off between real-timeness and simulation complexity. We report on the design of a new system that allows the real-time, interactive creation of images with thin watery paint. We mainly target the simulation of watercolor, but the system is also capable of simulating gouache and Oriental black ink. The motion of paint is governed by both physically based and heuristic rules in a layered canvas design. A final image is rendered by optically composing the layers using the Kubelka-Munk diffuse reflectance model. All algorithms that participate in the dynamics phase and the rendering phase of the simulation are implemented on graphics hardware. Images made with the system contain the typical effects that can be recognized in images produced with real thin paint, like the dark-edge effect, watercolor glazing, wet-on-wet painting and the use of different pigment types. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Hasselt Univ, Expertise Ctr Digital Media & Transnat, Univ Limburg, BE-3590 Diepenbeek, Belgium.
C3 Hasselt University
RP Hasselt Univ, Expertise Ctr Digital Media & Transnat, Univ Limburg, Wetenschapspk 2, BE-3590 Diepenbeek, Belgium.
EM tom.vanlaerhoven@uhasselt.be
RI Li, Mengqi/AAG-6804-2021
OI VAN REETH, Frank/0000-0002-3705-7807
CR Baxter B, 2001, COMP GRAPH, P461, DOI 10.1145/383259.383313
   Baxter William., 2004, Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering, P45
   COCKSHOTT MT, 1991, THESIS GLASGOW U
   Curtis C. J., 1997, Proceedings of the 24th annual conference on Computer graphics and interactive techniques, P421
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   GREENE R, 1985, P SIGGRAPH 85, P103
   Guo QL, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P152, DOI 10.1109/CGI.2003.1214460
   Kubelka P., 1931, Z TECH PHYS, V12, P593
   Kundu PK, 2002, Fluid mechanics, Vsecond
   LEE J, 1997, P 5 INT C COMP GRAPH, P1571
   LEE J, 1999, SIMULATING ORIENTAL, V19, P74
   SMALL D, 1991, P SPIE, V1460
   Sousa MC, 2000, COMPUT GRAPH FORUM, V19, P27, DOI 10.1111/1467-8659.00386
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   STAM J, 2003, P GAM DEV MAR
   Strassmann S., 1986, Computer Graphics, V20, P225, DOI 10.1145/15886.15911
   Van Laerhoven T, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P640, DOI 10.1109/CGI.2004.1309281
   Wolfram S., 2002, A new kind of science
   Worley S., 1996, P 23 ANN C COMPUTER, P291, DOI [DOI 10.1145/237170.237267, 10.1145/237170.237267]
   Yu YJ, 2003, WSCG'2003, VOL 11, NO 3, CONFERENCE PROCEEDINGS, P538
   Zhang Q, 1999, J VISUAL COMP ANIMAT, V10, P27, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<27::AID-VIS194>3.0.CO;2-C
NR 22
TC 27
Z9 31
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 429
EP 439
DI 10.1002/cav.95
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000026
DA 2024-07-18
ER

PT J
AU Nicolau, S
   Garcia, A
   Pennec, X
   Soler, L
   Ayache, N
AF Nicolau, S
   Garcia, A
   Pennec, X
   Soler, L
   Ayache, N
TI An augmented reality system to guide radio-frequency tumour ablation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; radio-frequency ablation; 3D/2D registration; needle
   tracking
ID REGISTRATION; IMAGES
AB Radio-frequency ablation is a difficult operative task that requires a precise needle positioning in the centre of the pathology. This article presents an augmented reality system for hepatic therapy guidance that superimposes in real-time 3D reconstructions (from CT acquisition) and a virtual model of the needle on external views of a patient. The superimposition of reconstructed models is performed with a 3D/2D registration based on radio-opaque markers stuck on to the patient's skin. The characteristics of the problem (accuracy, robustness and time processing) led us to develop automatic procedures to extract and match the markers and to track the needle in real time. Experimental studies confirmed that our algorithms are robust and reliable. Preliminary experiments conducted on a human abdomen phantom showed that our system is highly accurate (needle positioning error within 3 mm) and enables the surgeon to reach a target in less than 1 minute on average. Our next step will be to perform an in vivo evaluation. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 IRCAD, F-67091 Strasbourg, France.
RP IRCAD, 1 Pl Hop, F-67091 Strasbourg, France.
EM stephane.nicolau@ircad.u-strasbg.fr
RI Pennec, Xavier/L-2537-2013
OI Pennec, Xavier/0000-0002-6617-7664
CR ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751
   GERING DT, 1999, P MICCAI 99, P808
   Grimson WEL, 1996, IEEE T MED IMAGING, V15, P129, DOI 10.1109/42.491415
   Guéziec A, 1998, IEEE T MED IMAGING, V17, P715, DOI 10.1109/42.736023
   LANGO T, 2002, SMIT SOC MED INN TEC
   LAVALLEE S, 1997, CONT PERSPECTIVES 3, P239
   Maurer CR, 1997, IEEE T MED IMAGING, V16, P447, DOI 10.1109/42.611354
   McGahan JP, 2001, AM J ROENTGENOL, V176, P3, DOI 10.2214/ajr.176.1.1760003
   MERLOZ P, 2000, OPERATIVE TECHNIQUES, V10, P56
   Mitschke M, 2000, LECT NOTES COMPUT SC, V1935, P858
   MOURGUES F, 2003, THESIS U NICE SOPHIA
   NICOLAU S, 2003, IS4TM LNCS, V2673, P274
   PEUCHOT B, 1995, P 1 INT C COMP VIS V, P550
   Soler L, 2001, Comput Aided Surg, V6, P131, DOI 10.1002/igs.1016
   Zhang Z., 1998, FLEXIBLE NEW TECHNIQ
NR 16
TC 40
Z9 49
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2005
VL 16
IS 1
BP 1
EP 10
DI 10.1002/cav.52
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 912IF
UT WOS:000228070300002
DA 2024-07-18
ER

PT J
AU Bartoli, A
   Dalal, N
   Horaud, R
AF Bartoli, A
   Dalal, N
   Horaud, R
TI Motion panoramas
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE video mosaicking; panoramic visualization; layered representation;
   motion segmentation; background subtraction; texture alignment
ID MOSAICS
AB In this paper we describe a method for analysing video sequences and for representing them as mosaics or panoramas. Previous work on video mosaicking essentially concentrated on static scenes. We generalize these approaches to the case of a rotating camera observing both static and moving objects where the static portions of the scene are not necessarily dominant, as it has been often hypothesized in the past. We start by describing a robust technique for accurately aligning a large number of video frames under unknown camera rotations and camera settings. The alignment technique combines a feature-based method (initialization and refinement) with rough motion segmentation followed by a colour-based direct method (final adjustment). This precise frame-to-frame alignment allows the dynamic building of a background representation as well as an efficient segmentation of each image such that moving regions of arbitrary shape and size are aligned with the static background. Thus a motion panorama visualizes both dynamic and static scene elements in a geometrically consistent way. Extensive experiments applied to archived videos of track-and-field events validate the approach. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 INRIA Rhone Alpes, F-38330 Montbonnot St Martin, France.
RP INRIA Rhone Alpes, 655 Ave Europe, F-38330 Montbonnot St Martin, France.
EM radu.horaud@inrialpes.fr
RI Horaud, Radu/AAR-5982-2021
OI Horaud, Radu/0000-0001-5232-024X
CR Alexander DC, 2001, INT J COMPUT VISION, V44, P87, DOI 10.1023/A:1011870913626
   BERGEN JR, 1992, P 2 EUR C COMP VIS, P237
   Chen SN, 1995, SWIMMING THROUGH TROUBLED WATER, P29
   DALAL N, 2002, P IEEE WORKSH MOT VI, P593
   *DARTFISH LTD, 2001, DARTTR SOFTW US MAN
   DUFAUX F, 1996, P IEEE INT C IM PROC, V1, P673
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   HARTLEY RI, 1994, P ECCV, P471
   Horaud R, 2000, IEEE T PATTERN ANAL, V22, P1446, DOI 10.1109/34.895977
   IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883
   IRANI M, 1999, VISION ALGORITHMS TH, P267
   IRANI M, 1996, SIGNAL PROCESSING IM, V8
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346
   Peleg S, 2000, IEEE T PATTERN ANAL, V22, P1144, DOI 10.1109/34.879794
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   *REALVIZS A, 2002, STITCH 3 5 SOFTW US
   Sawhney H. S., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P583, DOI 10.1109/ICCV.1995.466886
   Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169
   Torr P. H. S., 2000, COMPUTER VISION IMAG, V78, P2000
   TORR PHS, 1999, VISION ALGORITHMS TH, P278
   Triggs B., 1999, VISION ALGORITHMS TH, P298
   WANG JYA, 1994, P SPIE DIG VID COMPR
   Zoghlami I, 1997, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.1997.609359
NR 25
TC 27
Z9 31
U1 0
U2 1
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2004
VL 15
IS 5
BP 501
EP 517
DI 10.1002/cav.13
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 880TP
UT WOS:000225812600004
DA 2024-07-18
ER

PT J
AU Bevacqua, E
   Pelachaud, C
AF Bevacqua, E
   Pelachaud, C
TI Expressive audio-visual speech
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE audio-visual speech; coarticulation; emotion
AB We aim at the realization of an Embodied Conversational Agent able to interact naturally and emotionally with user. In particular, the agent should behave expressively. Specifying for a given emotion, its corresponding facial expression will not produce the sensation of expressivity. To do so, one needs to specify parameters such as intensity, tension, movement property. Moreover, emotion affects also lip shapes during speech. Simply adding the facial expression of emotion to the lip shape does not produce lip readable movement. In this paper we present a model based on real data from a speaker on which was applied passive markers. The real data covers natural speech as well as emotional speech. We present an algorithm that determines the appropriate viseme and applies coarticulation and correlation rules to consider the vocalic and the consonantal contexts as well as muscular phenomena such as lip compression and lip stretching. Expressive qualifiers are then used to modulate the expressivity of lip movement. Our model of lip movement is applied on a 3D facial model compliant with MPEG-4 standard. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Roma La Sapienza, Dept Comp & Syst Sci, Rome, Italy.
C3 Sapienza University Rome
RP Bevacqua, E (corresponding author), Univ Roma La Sapienza, Dept Comp & Syst Sci, Rome, Italy.
EM elisabetta.bevacqua@libero.it
CR [Anonymous], P 3 ESCA COCOSDA WOR
   BESKOW J, 2003, THESIS CTR SPEECH TE
   BLANZ V, 2003, COMP GRAPH FOR P EUR, V22
   Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537
   BREGLER C, 1997, COMPUTER GRAPHICS P
   Chuang ES, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P68, DOI 10.1109/PCCGA.2002.1167840
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   COSI P, 2002, P ICMI 2002 PITTSB P
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   King SA, 2003, COMP ANIM CONF PROC, P17, DOI 10.1109/CASA.2003.1199299
   LEGOFF B, 1997, THESIS I NATL POLYTE
   LOFQVIST A, 1990, NATO ADV SCI I D-BEH, V55, P289
   MAGNOCALDOGNETT.E, 2003, ISCA TUT RES WORKSH
   MASSARO D, 1997, PRECEIVING TALKING F
   OHMAN SEG, 1967, J ACOUST SOC AM, V41, P310
   Pelachaud C, 1996, COGNITIVE SCI, V20, P1, DOI 10.1207/s15516709cog2001_1
   Pelachaud C., 2002, MPEG4 FACIAL ANIMATI
   REVERET L, 1996, P ICSLP 00 INT C SPO, V2, P755
   WALTHER EF, 1982, LIPREADING
NR 19
TC 16
Z9 18
U1 0
U2 3
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 297
EP 304
DI 10.1002/cav.32
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700019
DA 2024-07-18
ER

PT J
AU Hong, JM
   Kim, CH
AF Hong, JM
   Kim, CH
TI Controlling fluid animation with geometric potential
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE fluid control; potential fields; physically based modeling; simulation
   technique; natural simulation; computer animation
AB We propose a new fluid control technique that uses a geometrically induced potential field. Instead of optimizing the control forces exerted at each frame, as was done in previous work, a potential is added as an extra dimension to the simulation space which coerces the fluid inside this space to form the target shape. This type of shape control requires practically no additional computing by the Navier-Stokes solver at run-time, and adds little overhead to implementation. The confinement potentials are induced from geometric information given by animators, and so the control forces that take fluids to a lower potential can be decided in a preprocessing step. We show that a slightly generalized Navier-Stokes equation for fluids in potential fields can be simulated without changing the solver itself. A harmonic potential function can be quickly found with the Poisson solver which is already implemented as a part of the Navier-Stokes solver. 2 and 3 dimensional flows designed by common methods such as hand drawing, traditional shape modeling and key-framing, can be animated efficiently with our control technique. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Korea Univ, Comp Graph Lab, Seoul, South Korea.
C3 Korea University
RP Korea Univ, Comp Graph Lab, Seoul, South Korea.
EM chkim@korea.ac.kr
CR ADLER R, 1975, INTRO GEN RELATIVITY
   [Anonymous], 1995, POTENTIAL THEORY GRA, DOI [DOI 10.1017/CBO9780511549816, 10.1017/CBO9780511549816]
   Chenney S, 2000, COMP GRAPH, P219, DOI 10.1145/344779.344882
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P178, DOI 10.1109/CGI.1997.601299
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Foster Nick., 1997, P 24 ANN C COMP GRAP, P181
   Fox R.W., 1993, Introduction to Fluid Mechanics, VFourth
   Franklin GF., 2002, Feedback control of dynamic systems
   Hong JM, 2003, COMPUT GRAPH FORUM, V22, P253, DOI 10.1111/1467-8659.00672
   Popovic J, 2000, COMP GRAPH, P209, DOI 10.1145/344779.344880
   POPOVIC J, 2000, COMPUTER GRAPHICS AC
   Press W. H., 1988, Numerical Recipes
   Sethian J., 1999, LEVEL SET METHODS FA
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Turk G, 1999, COMP GRAPH, P335, DOI 10.1145/311535.311580
   ZHAO HK, 2000, P 1 IEEE WORKSH VAR, P194
   ZHOA HK, 2001, P 1 IEEE WORKSH VAR, P194
NR 22
TC 53
Z9 60
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 147
EP 157
DI 10.1002/cav.17
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700004
DA 2024-07-18
ER

PT J
AU Méndez-Feliu, A
   Sbert, M
AF Méndez-Feliu, A
   Sbert, M
TI Combining light animation with obscurances for glossy environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE computer graphics; three-dimensional graphics and realism; raytracing;
   rendering; light animation
AB Obscurances is a powerful technique that approximates indirect global illumination in a much faster way than classic methods as radiosity or path tracing. In this method, the local environment of a point or a patch is sampled to estimate the amount of occlusion that surrounds it. Fine effects as color reflection can be added and visually pleasant rendering of corners and soft shadows are easily computed. Combined with ray tracing techniques, non-diffuse and specular effects can be added to the surfaces, obtaining thus beautiful and realistic rendered images. Since direct and indirect illumination are decoupled, obscurances are very useful to render animation frames for moving light sources, as they have to be computed only for the first frame and then reused. Ambient light intensity can also be decoupled from obscurances and estimated for every frame, resulting in beautiful color-changing effects. Light animation help in light design and to convey shape and features of the objects in the scene. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Girona, Inst Informat & Aplicat, E-17071 Girona, Spain.
C3 Universitat de Girona
RP Univ Girona, Inst Informat & Aplicat, Campus Montilivi, E-17071 Girona, Spain.
EM amendez@ima.udg.es
RI Sbert, Mateu/G-6711-2011
OI Sbert, Mateu/0000-0003-2164-6858
CR [Anonymous], SIGGRAPH COURSE NOTE
   Christensen PT., 2003, SVARTSKALLAR SA FUNK, P31
   Cook R. L., 1984, COMPUT GRAPH, P165
   Iones A., 2003, IEEE Computer Graphics and..
   JENSEN HW, 1995, COMPUT GRAPH, V19, P215, DOI 10.1016/0097-8493(94)00145-O
   LAFORTUNE EP, COMPUGRAPHICS 93 C P, P145
   Martín I, 1998, COMPUT GRAPH, V22, P601, DOI 10.1016/S0097-8493(98)00066-1
   MENDEZ A, EUROGRAPHICS 2003
   MENDEZ A, 2003, P SPRING C COMP GRAP
   Pharr M., 2004, GPU Gems
   Veach E, 1995, SIGGRAPH 95 C P, P419, DOI DOI 10.1145/218380.218498
   Ward G. J., 1992, Proceedings of the Third Eurographics Workshop on Rendering, P85
   ZHUKOV S, P EUR REND WORKSH 98, P45
   [No title captured]
NR 14
TC 2
Z9 2
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 463
EP 470
DI 10.1002/cav.50
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700037
DA 2024-07-18
ER

PT J
AU Dzardanova, E
   Nikolakopoulou, V
   Kasapakis, V
   Vosinakis, S
   Xenakis, I
   Gavalas, D
AF Dzardanova, Elena
   Nikolakopoulou, Vasiliki
   Kasapakis, Vlasios
   Vosinakis, Spyros
   Xenakis, Ioannis
   Gavalas, Damianos
TI Exploring the impact of non-verbal cues on user experience in immersive
   virtual reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE non verbal communication; virtual characters; virtual reality
AB Face-to-face communication relies extensively on non-verbal cues (NVCs) which complement, or at times dominate, the communicative process as they convey emotions with intense salience, thus definitively affecting interpersonal communication. The capture, transference, and subsequent interpretation of NVCs becomes complicated in computer-mediated communicative processes, particularly in shared virtual worlds, for which there is growing interest both in regard to NVCs technological integration and their affective impact. This paper presents a between-groups experimental setup which is facilitated in immersive virtual reality (IVR), and examines NVCs effects on user experience, with special emphasis on degree of attention toward each NVC as an isolated controlled variable of a scripted performance by a virtual character (VC). This study aims to evaluate NVCs fidelity based on the capabilities of the motion-capture technologies utilized to address cue integration developmental challenges and examines NVCs impact on users' perceived realism of the VC, their empathy toward him, and the degree of social presence experienced. To meet the objectives set the affective impact of low-fidelity automated NVCs and high-fidelity real-time captured NVCs were compared. The findings of the evaluation suggest that although NVCs do impact user experience to an extent, their effects are notably more subtle compared to previous studies.
   Exploring the impact of non-verbal cues on user experience in immersive virtual reality.image
C1 [Dzardanova, Elena; Nikolakopoulou, Vasiliki; Vosinakis, Spyros; Xenakis, Ioannis; Gavalas, Damianos] Univ Aegean, Dept Prod & Syst Design Engn, Syros, Greece.
   [Kasapakis, Vlasios] Univ Aegean, Dept Cultural Technol & Commun, Lesvos, Greece.
C3 University of Aegean; University of Aegean
RP Kasapakis, V (corresponding author), Univ Aegean, Dept Cultural Technol & Commun, Lesvos, Greece.
EM v.kasapakis@aegean.gr
RI Vlasis, Kasapakis/AAS-8169-2020
OI Xenakis, Ioannis/0000-0001-5607-3514; Kasapakis,
   Vlasios/0000-0002-4048-6047
FU Hellenic Foundation for Research and Innovation
FX No Statement Available
CR Aburumman N, 2022, INT J HUM-COMPUT ST, V164, DOI 10.1016/j.ijhcs.2022.102819
   Allen I Elaine, 2007, QUAL PROG, V40, P64, DOI DOI 10.1111/J.1365-2929.2004.02012.X
   Bhagavathula Rajaram, 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P2056, DOI 10.1177/1541931218621464
   Burgoon J.K., 2002, PERSUASION HDB, P445
   Dagnes N, 2019, J BIOMECH, V93, P86, DOI 10.1016/j.jbiomech.2019.06.012
   Dharmawansa A.D., 2015, International Education Studies, V8, P82, DOI 10.5539/ies.v8n6p82
   Dong YZ, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2040
   Dzardanova E., 2022, 1 IMPRESSIONS MATTER
   Dzardanova E, 2022, VIRTUAL REAL-LONDON, V26, P737, DOI 10.1007/s10055-021-00564-9
   Dzardanova E, 2018, IEEE CONSUM ELECTR M, V7, P44, DOI 10.1109/MCE.2018.2816204
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Freeman Guo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432938
   Geraets CNW, 2021, INTERNET INTERV, V25, DOI 10.1016/j.invent.2021.100432
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   HSEE CK, 1990, COGNITION EMOTION, V4, P327, DOI 10.1080/02699939008408081
   Johannessen E, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106393
   Kasapakis V., 2023, Computers & Education: X Reality, V2
   Kasapakis V, 2022, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2022.2146140
   Kimmel S, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580707
   Knapp M.L., 2013, Cengage Learning
   Koskela T, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174926
   Krogmeier C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1883
   Kyrlitsias C, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.02254
   Ma F., 2022, P C VIRT REAL 3D US
   Maloney D., 2020, PROC ACM HUM COMPUT, V4, P1, DOI DOI 10.1145/3415246
   Pastel S, 2021, J MOTOR BEHAV, V53, P693, DOI 10.1080/00222895.2020.1843390
   Phutela D., 2015, IUP J SOFT SKILLS, V9, P43
   Reale M., 2011, P CVPR WORKSH
   Ripka G., 2020, PRESERVICE TEACHERSE
   Rivu R., 2021, ALTERING NON VERBAL
   Rozsa S, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.931955
   Rubio-Tamayo Jose Luis, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040021
   Shafer DM, 2019, GAMES HEALTH J, V8, P15, DOI 10.1089/g4h.2017.0190
   Theonas G., 2008, International Journal of Virtual Reality, V7, P31
   Volonte M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P293, DOI [10.1109/VR46266.2020.1581610451331, 10.1109/VR46266.2020.00-55]
NR 35
TC 0
Z9 0
U1 4
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2224
EA DEC 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001129373000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, Q
   Wang, P
   Liu, ZX
   Zhang, HY
   Song, YJ
   Zhang, YX
AF Li, Qiang
   Wang, Peng
   Liu, Zexue
   Zhang, Haoyan
   Song, Yujie
   Zhang, Yuxin
TI Using scaffolding theory in serious games to enhance traditional Chinese
   murals culture learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cultural heritage; learning achievements; scaffolding educational
   theory; serious game
ID STUDENTS MOTIVATION; COMPUTER GAMES; DESIGN; ENGAGEMENT; IMPACTS
AB This study explores a game model that uses scaffolding to learn about cultural heritage based on adventure games. A case study using traditional Chinese murals tested the effectiveness of serious games in improving learning performance and knowledge acquisition. This study observed and evaluated the learning outcomes of 64 students by using serious game learning compared to traditional video learning in an experimental setting. Changes in knowledge acquisition, intrinsic motivation, cognitive load (extrinsic load vs. germane load), and engagement were collected through a series of tests and scales. Experimental results show that digital adventure games have better learning performance and knowledge retention effects, higher intrinsic motivation, germane load, and engagement than traditional video learning. The reasons affecting academic performance were analyzed from the data, and it was found that intrinsic motivation and germane cognitive load positively affected game performance, and external cognitive load hurt game performance. This study provides experience on the design of serious games in cultural heritage learning.
   This study explores a game model that uses scaffolding to learn about cultural heritage based on adventure games. A case study using traditional Chinese murals tested the effectiveness of serious games in improving learning performance and knowledge acquisition. Changes in knowledge acquisition, intrinsic motivation, cognitive load (extrinsic load vs. germane load), and engagement were collected through a series of tests and scales. Finally, the experimental data are analyzed and discussed, and conclusions are presented. This study provides experience on the design of serious games in cultural heritage learning. image
C1 [Li, Qiang; Wang, Peng; Liu, Zexue] Shenyang Aerosp Univ, Dept Digital Media Art, Shenyang, Peoples R China.
   [Zhang, Haoyan; Song, Yujie; Zhang, Yuxin] Shenyang Aerosp Univ, Dept Ind Design, Shenyang, Peoples R China.
   [Li, Qiang] Shenyang Aerosp Univ, Dept Digital Media Art, 37 Daoyi South Ave, Shenyang 110136, Peoples R China.
C3 Shenyang Aerospace University; Shenyang Aerospace University; Shenyang
   Aerospace University
RP Li, Q (corresponding author), Shenyang Aerosp Univ, Dept Digital Media Art, 37 Daoyi South Ave, Shenyang 110136, Peoples R China.
EM qiangli@sau.edu.cn
RI Song, Yujie/AFM-6022-2022; Liu, Zexue/AAR-8161-2020; li,
   qiang/GZA-3285-2022
OI Liu, Zexue/0000-0002-7333-3119; Li, Qiang/0000-0002-6360-3357
CR Andreoli R, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3064644
   [Anonymous], 2012, Measuring the economic contribution to cultural industries
   [Anonymous], 2005, Framework Convention on the Value of Cultural Heritage for Society
   [Anonymous], SERIOUS GAMES MECH E
   Azevedo R, 2005, INSTR SCI, V33, P367, DOI 10.1007/s11251-005-1272-9
   Boyle EA, 2016, COMPUT EDUC, V94, P178, DOI 10.1016/j.compedu.2015.11.003
   Buckley P, 2016, INTERACT LEARN ENVIR, V24, P1162, DOI 10.1080/10494820.2014.964263
   Caton H, 2014, INT J GAME-BASED LEA, V4, P1, DOI 10.4018/ijgbl.2014070101
   Chen CH, 2016, COMPUT HUM BEHAV, V55, P1201, DOI 10.1016/j.chb.2015.03.010
   Dijkstra J, 2012, BMC MED EDUC, V12, DOI 10.1186/1472-6920-12-20
   Filsecker M, 2014, COMPUT EDUC, V75, P136, DOI 10.1016/j.compedu.2014.02.008
   Fuller A., 2015, UNLOCKING YOUR CHILD, p256p
   Furini M., 2008, Comput Entertain, V6, P1, DOI https://doi.org/10.1145/1371216.1371222
   George R., DEFINING URBAN GRAPH
   Heaney LF., 1989, INT J ED MANAGE INTE, V3
   Hendriana Y, 2015, 2015 INTERNATIONAL SEMINAR ON INTELLIGENT TECHNOLOGY AND ITS APPLICATIONS (ISITIA), P251, DOI 10.1109/ISITIA.2015.7219987
   Holmes JB, 2016, HORIZON, V24, P1, DOI 10.1108/OTH-11-2015-0069
   Hwang GJ, 2023, INTERACT LEARN ENVIR, V31, P156, DOI 10.1080/10494820.2020.1765391
   Isen AM, 2005, MOTIV EMOTION, V29, P297, DOI 10.1007/s11031-006-9019-8
   Jin S, 2022, INT J HUM-COMPUT INT, V38, P213, DOI 10.1080/10447318.2021.1930389
   Kao GYM, 2017, COMPUT EDUC, V113, P294, DOI 10.1016/j.compedu.2017.05.022
   Kim MC, 2011, COMPUT EDUC, V56, P403, DOI 10.1016/j.compedu.2010.08.024
   Leppink J, 2013, BEHAV RES METHODS, V45, P1058, DOI 10.3758/s13428-013-0334-1
   Li Q, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2085
   Markopoulos A.P., 2015, International Journal of Mechanical Engineering Education, V43, P118, DOI DOI 10.1177/0306419015591324
   Mayer RE, 2015, EDUC PSYCHOL-US, V50, P349, DOI 10.1080/00461520.2015.1133307
   Mettler T, 2015, IEEE T ENG MANAGE, V62, P256, DOI 10.1109/TEM.2015.2413494
   Sabourin JL, 2014, IEEE T AFFECT COMPUT, V5, P45, DOI 10.1109/T-AFFC.2013.27
   Skinner B.F., 2011, BEHAVIORISM
   Subhash S, 2018, COMPUT HUM BEHAV, V87, P192, DOI 10.1016/j.chb.2018.05.028
   Sun CT, 2018, COMPUT EDUC, V119, P95, DOI 10.1016/j.compedu.2018.01.001
   Sung HY, 2017, COMPUT EDUC, V110, P143, DOI 10.1016/j.compedu.2017.03.014
   Wang RX, 2018, INT J HUM-COMPUT INT, V34, P533, DOI 10.1080/10447318.2017.1373457
   Wenjie D., 1991, DUNHUANG RES, V11, P116
   Ye L., 2022, INTERACT LEARN ENVIR, V9, P1
   Ye L, 2021, J EDUC COMPUT RES, V59, P287, DOI 10.1177/0735633120963828
   Yoon SA, 2012, INT J COMP-SUPP COLL, V7, P519, DOI 10.1007/s11412-012-9156-x
   Yuehai Z., 2010, ART 100, V26, P196
   Zainuddin Z, 2020, EDUC RES REV-NETH, V30, DOI 10.1016/j.edurev.2020.100326
NR 39
TC 0
Z9 0
U1 17
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2213
EA AUG 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JK2X2
UT WOS:001151750300001
DA 2024-07-18
ER

PT J
AU Gao, MY
   Wang, PJ
AF Gao, Mengying
   Wang, Pengjie
TI Personalized facial makeup transfer based on outline correspondence
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE image to image translation; makeup transfer; semantic correspondence
AB Most existing makeup transfer techniques focus on light makeup styles, which limits the task of makeup transfer to color manipulation issues such as eye shadow and lip gloss. However, the makeup in real life is diverse and personalized, not only the most basic foundation, eye makeup, but also the painted patterns on the face, jewelry decoration and other personalized makeup. Inspired by the painting steps of drawing the outline first and then coloring, we propose a makeup transfer network for personalized makeup, which realizes face makeup transfer by learning outline correspondence. Specifically, we propose the outline feature extraction module and outline loss that can promote outline correspondence. Our network can not only transfer daily light makeup, but also complete transfer for complex facial painting patterns. Experiments show that our method can obtain visually more accurate makeup transfer results. Quantitative and qualitative experimental results show that the method proposed in this paper achieves superior results in extreme makeup transfer compared to the state-of-the-art methods.
C1 [Gao, Mengying; Wang, Pengjie] Dalian Minzu Univ, Sch Comp Sci & Engn, Dalian, Peoples R China.
   [Wang, Pengjie] Dalian Minzu Univ, Sch Comp Sci & Engn, 31,Jinshi Rd,Jinshitan St, Dalian, Peoples R China.
C3 Dalian Minzu University; Dalian Minzu University
RP Wang, PJ (corresponding author), Dalian Minzu Univ, Sch Comp Sci & Engn, 31,Jinshi Rd,Jinshitan St, Dalian, Peoples R China.
EM pengjiewang@qq.com
RI Wang, Pengjie/KHE-3288-2024
OI Wang, Pengjie/0000-0003-1276-9776
FU Natural Science Foundation of Liaoning Province [2023-MS-133]; Dalian
   Minzu University [110222, 140140]
FX ACKNOWLEDGMENTS We thank the Natural Science Foundation of Liaoning
   Province, grant/award number: 2023-MS-133; Dalian Minzu University,
   grant/award numbers: 110222, 140140 and the university for their support
   and assistance. The method proposed in this paper is for academic
   research only and cannot be used in any commercial field for profit.
CR Aberman K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201332
   Chang HW, 2018, PROC CVPR IEEE, P40, DOI 10.1109/CVPR.2018.00012
   Choy CB, 2016, ADV NEUR IN, V29
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Gu Q, 2019, IEEE I CONF COMP VIS, P10480, DOI 10.1109/ICCV.2019.01058
   Ham B, 2018, IEEE T PATTERN ANAL, V40, P1711, DOI 10.1109/TPAMI.2017.2724510
   Han K, 2017, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2017.203
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Hensel M, 2017, ADV NEUR IN, V30
   Jiang WT, 2020, PROC CVPR IEEE, P5193, DOI 10.1109/CVPR42600.2020.00524
   Kim S., 2017, CVPR, P6560
   Lee J, 2019, PROC CVPR IEEE, P2273, DOI 10.1109/CVPR.2019.00238
   Lee J, 2020, PROC CVPR IEEE, P5800, DOI 10.1109/CVPR42600.2020.00584
   Li TT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P645, DOI 10.1145/3240508.3240618
   Liao J., 2017, VISUAL ATTRIBUTE TRA
   Liu S, 2022, IEEE T PATTERN ANAL, V44, P8538, DOI 10.1109/TPAMI.2021.3083484
   Long J, 2014, ADV NEUR IN, V27
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Sarfraz MS., 2019, CONTENT COLOUR DISTI
   Sun ZY, 2022, AAAI CONF ARTIF INTE, P2325
   Nguyen T, 2021, PROC CVPR IEEE, P13300, DOI 10.1109/CVPR46437.2021.01310
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Wan ZY, 2022, IEEE WINT CONF APPL, P3113, DOI 10.1109/WACV51458.2022.00317
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang Xiaoyu, 2022, P IEEECVF WINTER C A, P1434
   Zhang H., 2019, DISENTANGLED MAKEUP
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zhou Bolei, 2017, PROC CVPR IEEE, P633, DOI DOI 10.1109/CVPR.2017.544
NR 30
TC 0
Z9 0
U1 9
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2199
EA JUL 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001034363600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Guo, WC
   Huang, YY
   Chen, ZR
   Zhang, ZX
   Sun, GY
   Zeng, QX
   Li, X
AF Guo, Wenchen
   Huang, Yiyuan
   Chen, Zhirui
   Zhang, Zixun
   Sun, Guoyu
   Zeng, Qingxiang
   Li, Xiao
TI The "rebirth" of traditional musical instrument: An interactive
   installation based on augmented reality and somatosensory technology to
   empower the exhibition of chimes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; Chinese chimes; cultural heritage; somatosensory
   interaction; user experience
ID INTERACTION DESIGN
AB Tangible cultural heritage is rich in historical, artistic and scientific value, but due to its own characteristics and the constraints of museum displays, the key issue facing us today is how to utilize and activate cultural heritage to enhance the experience and learning interest of the audience. Focusing on the Chinese cultural treasure, the chimes, this article innovatively proposes an interaction system based on digital augmented projection and somatosensory technology to empower the aesthetic expression and knowledge dissemination of chimes. On this basis, a series of evaluations were carried out and the results showed that the system effectively provides a satisfying, personalized and fun way for users to interact with chimes and learn the traditional culture, successfully bringing this ancient instrument back to life. Moreover, this article shares in detail the research, design and development process, which provides inspiration and examples for other museums to present their tangible cultural heritage through mixed reality and interactive technology.
C1 [Guo, Wenchen; Huang, Yiyuan] Beijing Inst Graph Commun, Dept Digital Media Art, Beijing, Peoples R China.
   [Guo, Wenchen; Sun, Guoyu; Li, Xiao] Commun Univ China, Sch Animat & Digital Arts, Beijing, Peoples R China.
   [Guo, Wenchen] Peking Univ, Sch Software & Microelect, Beijing, Peoples R China.
   [Chen, Zhirui; Zeng, Qingxiang] Univ Chinese Acad Social Sci, Sch Journalism & Commun, Beijing, Peoples R China.
   [Zhang, Zixun] Yanshan Univ, Sch Foreign Studies, Qinhuangdao, Peoples R China.
   [Li, Xiao] Univ Edinburgh, Coll Arts Humanities & Social Sci, Edinburgh, Scotland.
C3 Communication University of China; Peking University; Chinese Academy of
   Social Sciences; University of Chinese Academy of Social Sciences;
   Yanshan University; University of Edinburgh
RP Guo, WC; Huang, YY (corresponding author), Beijing Inst Graph Commun, Dept Digital Media Art, Beijing, Peoples R China.; Guo, WC; Sun, GY (corresponding author), Commun Univ China, Sch Animat & Digital Arts, Beijing, Peoples R China.; Guo, WC (corresponding author), Peking Univ, Sch Software & Microelect, Beijing, Peoples R China.
EM beihuanfanchen@sina.com; yiyuan.huang@bigc.edu.cn; guoyusun_cuc@126.com
OI Chen, Zhirui/0000-0002-1550-8259; Guo, Wenchen/0000-0001-7757-1037
FU National Key Research and Development Program of China [2020AAA0105200]
FX National Key Research and Development Program of China, Grant/Award
   Number:2020AAA0105200
CR Adikari A., 2017, IOSR J COMPUT ENG, V19, P80, DOI [10.9790/0661-1903028085, DOI 10.9790/0661-1903028085]
   Chen Y., 2021, CULTURE COMPUTING IN, P225
   Eisinga R, 2013, INT J PUBLIC HEALTH, V58, P637, DOI 10.1007/s00038-012-0416-3
   Graham HC., 2016, SCI MUS GROUP J, V5, P1
   Huang J., 2021, SOC SCI, V492, P136
   Huang Yiyuan, 2022, HCI International 2022 - Late Breaking Papers: HCI for Today's Community and Economy: 24th International Conference on Human-Computer Interaction, HCII 2022, Virtual Event, Proceedings. Lecture Notes in Computer Science (13520), P20, DOI 10.1007/978-3-031-18158-0_2
   Ioannides M., 2017, Mixed reality and gamification for cultural heritage, P161
   Jin S, 2022, INT J HUM-COMPUT INT, V38, P213, DOI 10.1080/10447318.2021.1930389
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Larsen S, 2007, SCAND J HOSP TOUR, V7, P7, DOI 10.1080/15022250701226014
   Li Q, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2085
   Lin WY, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2064
   Liu C., 2017, APPL RES BELL ELEMEN
   Liu Y., 2020, Built Heritage, V4, P14, DOI DOI 10.1186/S43238-020-00016-4
   Mine M, 2012, COMPUTER, V45, P32, DOI 10.1109/MC.2012.154
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Qin JY, 2009, INT C COMP AID IND D, P1452, DOI 10.1109/CAIDCD.2009.5375319
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Rinaldi A, 2021, LECT NOTE NETW SYST, V260, P397, DOI 10.1007/978-3-030-80829-7_49
   Rogers K., 2014, P 9 ACM INT C INT TA
   Sloboda JA., 1991, PSYCHOL MUSIC, V19, P110, DOI DOI 10.1177/0305735691192002
   Von Falkenhausen Lothar., 1993, Suspended Music: Chime-Bells in the Culture of Bron%20e Age China
   Wang ZF, 2015, 2015 INTERNATIONAL CONFERENCE OF EDUCATIONAL INNOVATION THROUGH TECHNOLOGY - EITT 2015, P64, DOI 10.1109/EITT.2015.20
   Wu LY, 2022, HERIT SCI, V10, DOI 10.1186/s40494-022-00828-w
   Xu JF, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND APPLICATIONS, VOLS 1 AND 2, P264, DOI 10.1109/ICPCA.2008.4783590
   Xu R, 2022, LECT NOTES COMPUT SC, V13304, P243, DOI 10.1007/978-3-031-05412-9_18
   Yan YL, 2013, AIP CONF PROC, V1517, P43, DOI 10.1063/1.4794219
   Zhang H, 2007, CHINESE SCI BULL, V52, P2167, DOI 10.1007/s11434-007-0322-x
   Zhang W., 2012, JIANNAN LIT, V338, P103
NR 30
TC 1
Z9 1
U1 20
U2 46
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2171
EA MAY 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000993001600001
DA 2024-07-18
ER

PT J
AU Lin, JY
   Li, JF
   She, YY
   Lin, L
   Wu, H
   Zhang, E
   Lei, JY
   Huang, W
   Li, JF
AF Lin, Jiayu
   Li, Jiefeng
   She, Yingying
   Lin, Lin
   Wu, Hang
   Zhang, E.
   Lei, Jiayi
   Huang, Wei
   Li, Jufeng
TI Using a social robot for children with autism: A therapist-robot
   interactive model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE children with autism; human robot interaction; social robot
ID SPECTRUM DISORDERS; SKILLS; PROBO; PLAY
AB Social robots have great potential for the therapy of children with autism spectrum disorder, but the practical use of them is challenging. In this article, we presented a social robot YANG, which can interact with children with autism in their daily training. We propose a therapist-robot interactive (TRI) model, which integrates with the practice of discrete trial training (DTT), a basic method utilized in autism training. To evaluate the TRI model, we implemented the model in YANG and conducted a single-subject experiment in a rehabilitation training center. Data were collected on three children (ages 3-4) and their three therapists as they interacted with YANG in training sessions. Results showed that the children's learning ability significantly improved. YANG formed natural and friendly relationships with the children and delivered substantial support to therapists. Our research brings insight into using social robots for children with autism.
C1 [Lin, Jiayu; Li, Jiefeng; Lei, Jiayi] Xiamen Univ, Sch Informat, Xiamen, Fujian, Peoples R China.
   [She, Yingying] Xiamen Univ, Sch Film, Xiamen, Fujian, Peoples R China.
   [She, Yingying] Xiamen Univ, Natl Inst Data Sci Hlth & Med, Xiamen, Fujian, Peoples R China.
   [Lin, Lin] Xiamen Univ, Inst Creat & Innovat, Xiamen, Fujian, Peoples R China.
   [Wu, Hang] Together Learning Ctr, Fuzhou, Fujian, Peoples R China.
   [Zhang, E.] Univ Kansas, Med Ctr, Lawrence, KS 66045 USA.
   [Huang, Wei] Commun Univ China, State Key Lab Media Convergence & Commun, Beijing, Peoples R China.
   [Li, Jufeng] UCL, Inst Educ, London, England.
C3 Xiamen University; Xiamen University; Xiamen University; Xiamen
   University; University of Kansas; University of Kansas Medical Center;
   Communication University of China; University of London; University
   College London; UCL Institute of Education
RP She, YY (corresponding author), Xiamen Univ, Sch Film, Xiamen, Fujian, Peoples R China.; Lin, L (corresponding author), Xiamen Univ, Inst Creat & Innovat, Xiamen, Fujian, Peoples R China.
EM yingyingshe@xmu.edu.cn; linlinxiamen@xmu.edu.cn
OI Li, Jiefeng/0000-0002-0258-0913; Lin, Jiayu/0000-0002-4759-0410; She,
   Yingying/0000-0002-6770-4622; ZHANG, E/0000-0002-9468-4890
FU Fujian Science and Technology Program Guiding Project [2020H0001]; Open
   Project Program of State Key Laboratory of Virtual Reality Technology
   and Systems, Beihang University [VRLAB2020B16]
FX Fujian Science and Technology Program Guiding Project, Grant/Award
   Number: 2020H0001; Open Project Program of State Key Laboratory of
   Virtual Reality Technology and Systems, Beihang University, Grant/Award
   Number: VRLAB2020B16
CR [Anonymous], 2013, Paladyn, Journal of Behavioral Robotics, DOI DOI 10.2478/S13230-013-0107-7
   [Anonymous], 2013, DIAGNOSTIC STAT MANU, P5
   Byiers BJ, 2012, AM J SPEECH-LANG PAT, V21, P397, DOI 10.1044/1058-0360(2012/11-0036)
   Cabibihan JJ, 2013, INT J SOC ROBOT, V5, P593, DOI 10.1007/s12369-013-0202-2
   Costa A, 2018, IEEE ROMAN, P534, DOI 10.1109/ROMAN.2018.8525747
   David DO, 2020, J EDUC COMPUT RES, V58, P29, DOI 10.1177/0735633119830344
   David DO, 2018, INT J SOC ROBOT, V10, P595, DOI 10.1007/s12369-017-0457-0
   Dickstein-Fischer L, 2017, ACMIEEE INT CONF HUM, P107, DOI 10.1145/3029798.3038390
   Dickstein-Fischer L, 2014, IEEE ENG MED BIO, P792, DOI 10.1109/EMBC.2014.6943710
   Dickstein-Fischer L, 2011, IEEE ENG MED BIO, P5319, DOI 10.1109/IEMBS.2011.6091316
   Diehl JJ, 2012, RES AUTISM SPECT DIS, V6, P249, DOI 10.1016/j.rasd.2011.05.006
   Elsabbagh M, 2012, AUTISM RES, V5, P160, DOI 10.1002/aur.239
   Feil-Seifer D, 2011, IEEE ROBOT AUTOM MAG, V18, P24, DOI 10.1109/MRA.2010.940150
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Gauthier A., 2022, ACM T COMPUTER HUMAN, V29, P1
   Huijnen CAGJ, 2019, J AUTISM DEV DISORD, V49, P11, DOI 10.1007/s10803-018-3683-x
   Huijnen CAGJ, 2017, J AUTISM DEV DISORD, V47, P3079, DOI 10.1007/s10803-017-3235-9
   Javed H, 2018, ACMIEEE INT CONF HUM, P131, DOI 10.1145/3173386.3177082
   Javed H, 2020, ACM T HUM-ROBOT INTE, V9, DOI 10.1145/3359613
   Kim ES, 2013, J AUTISM DEV DISORD, V43, P1038, DOI 10.1007/s10803-012-1645-2
   Kozima H, 2009, INT J SOC ROBOT, V1, P3, DOI 10.1007/s12369-008-0009-8
   LOVAAS OI, 1987, J CONSULT CLIN PSYCH, V55, P3, DOI 10.1037/0022-006X.55.1.3
   McBain RK, 2020, J AM ACAD CHILD PSY, V59, P113, DOI 10.1016/j.jaac.2019.04.027
   Pop CA, 2014, INTERACT STUD, V15, P292, DOI 10.1075/is.15.2.14pop
   Ricks DJ, 2010, IEEE INT CONF ROBOT, P4354, DOI 10.1109/ROBOT.2010.5509327
   Scassellati B, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat7544
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036
   Schadenberg BR, 2021, ACM T COMPUT-HUM INT, V28, DOI 10.1145/3468849
   Short ES, 2017, J HUM-ROBOT INTERACT, V6, P21, DOI 10.5898/JHRI.6.3.Short
   Simut RE, 2016, J AUTISM DEV DISORD, V46, P113, DOI 10.1007/s10803-015-2556-9
   So WC, 2019, RES DEV DISABIL, V95, DOI 10.1016/j.ridd.2019.103515
   So WC, 2020, J AUTISM DEV DISORD, V50, P467, DOI 10.1007/s10803-019-04270-z
   Vanderborght B, 2012, INTERACT STUD, V13, P348, DOI 10.1075/is.13.3.02van
   Wainer J, 2014, INT J SOC ROBOT, V6, P45, DOI 10.1007/s12369-013-0195-x
   Warren Z, 2015, J AUTISM DEV DISORD, V45, P3870, DOI 10.1007/s10803-014-2334-0
   Warren ZE, 2015, J AUTISM DEV DISORD, V45, P3726, DOI 10.1007/s10803-013-1918-4
   Wong C, 2015, J AUTISM DEV DISORD, V45, P1951, DOI 10.1007/s10803-014-2351-z
   Yun SS, 2017, AUTISM RES, V10, P1306, DOI 10.1002/aur.1778
   Zheng Z, 2016, IEEE T NEUR SYS REH, V24, P682, DOI 10.1109/TNSRE.2015.2475724
NR 39
TC 1
Z9 1
U1 6
U2 30
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2022
VL 33
IS 5
AR e2109
DI 10.1002/cav.2109
EA AUG 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5E9FV
UT WOS:000842813200001
DA 2024-07-18
ER

PT J
AU Li, YH
   Huang, TY
   Liu, YF
   Chang, XJ
   Ding, GY
AF Li, Yihao
   Huang, Tianyu
   Liu, Yifan
   Chang, Xiaojun
   Ding, Gangyi
TI Anchor-based crowd formation transformation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation; crowd simulation; formation transformation
ID ASSIGNMENT; SIMULATION; NAVIGATION
AB Crowd formation transformation is the process of controlling crowd movement under high constraints, which has received massive attention in recent years due to its ability to generate high-quality visual effects. It is challenging because of the complexity and the lack of evaluation standard. This study introduces an anchor-based crowd formation transformation control method that achieves highly controllable crowd movement by extracting anchors and optimizing a loss function based on anchor constraints. In addition, we propose a series of metrics to assist users in quantifying a segment of group motion. Some cases not considered in past work are designed to demonstrate the superiority of this method. With the help of proposed metrics, it could be found that in addition to being able to uniquely accomplish some tasks, our method also exhibits higher control over the crowd in other scenarios. Compared with methods of other research, our method has significant advantages in diversity and controllability of the generated results.
C1 [Li, Yihao; Huang, Tianyu; Liu, Yifan; Chang, Xiaojun; Ding, Gangyi] Beijing Inst Technol, 5 Yard,Zhong Guan Cun South St, Beijing, Peoples R China.
C3 Beijing Institute of Technology
RP Huang, TY (corresponding author), Beijing Inst Technol, 5 Yard,Zhong Guan Cun South St, Beijing, Peoples R China.
EM huangtianyu@bit.edu.cn
RI li, chunlin/KFS-0761-2024; Wang, Junzhe/KCK-4991-2024; Wang,
   Yitong/KBA-1959-2024; Zhang, Zhipeng/KHY-2239-2024; Li,
   Shiyu/KHE-1376-2024
OI Li, Yihao/0000-0001-9159-0373
FU National Natural Science Foundation of China [62177005]; National Key
   Research and Development Program of China [2020YFC20-07200,
   2020YFF0305200]
FX This project was funded by National Natural Science Foundation of China
   62177005, National Key Research and Development Program of China
   2020YFC20-07200 and 2020YFF0305200.
CR Akkiraju N., 1995, P 1 INT COMPUTATIONA, P66
   Allain P, 2014, GRAPH MODELS, V76, P1, DOI 10.1016/j.gmod.2013.09.001
   Aouaidjia K, 2021, IEEE T SYST MAN CY-S, V51, P2774, DOI 10.1109/TSMC.2019.2916896
   Del Ser J, 2019, SWARM EVOL COMPUT, V48, P220, DOI 10.1016/j.swevo.2019.04.008
   Duives DC, 2013, TRANSPORT RES C-EMER, V37, P193, DOI 10.1016/j.trc.2013.02.005
   Gu Q., 2011, IEEE COMPUT GRAPH, V33, P20
   Guy SJ, 2012, PHYS REV E, V85, DOI 10.1103/PhysRevE.85.016110
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Henry J, 2014, IEEE T VIS COMPUT GR, V20, P211, DOI 10.1109/TVCG.2013.116
   Henry Joseph., 2012, Proceedings of the 11th ACM SIGGRAPH / Eurographics conference on Computer Animation, EUROSCA'12, P193
   Jen-Yao Chang, 2008, 2008 IEEE Conference on Cybernetics and Intelligent Systems, P131, DOI 10.1109/ICCIS.2008.4670865
   Jiang JW, 2020, GRAPH MODELS, V111, DOI 10.1016/j.gmod.2020.101077
   Jin XG, 2008, IEEE COMPUT GRAPH, V28, P37, DOI 10.1109/MCG.2008.117
   Kamel A, 2019, INT J HUM-COMPUT INT, V35, P427, DOI 10.1080/10447318.2018.1543081
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Karambakhsh A, 2019, INT J INFORM MANAGE, V45, P328, DOI 10.1016/j.ijinfomgt.2018.03.004
   Kim J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601170
   Kim M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531385
   Krontiris A, 2010, LECT NOTES COMPUT SC, V6459, P121
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Li Y., 2020, IEEE ACCESS, V8, P685
   Liu B, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/9819156
   Lv L, 2014, COMPUT ANIMAT VIRT W, V25, P171, DOI 10.1002/cav.1544
   Antonio LM, 2018, SOFT COMPUT, V22, P5491, DOI 10.1007/s00500-018-3164-3
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nasir FM, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P289, DOI 10.1145/3013971.3014017
   Patil S, 2011, IEEE T VIS COMPUT GR, V17, P244, DOI 10.1109/TVCG.2010.33
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Shen YJ, 2018, COMPUT GRAPH FORUM, V37, P382, DOI 10.1111/cgf.13333
   Takahashi S, 2009, COMPUT GRAPH FORUM, V28, P639, DOI 10.1111/j.1467-8659.2009.01404.x
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Xu JY, 2008, COMPUT ANIMAT VIRT W, V19, P319, DOI 10.1002/cav.231
   Xu ML, 2014, J COMPUT SCI TECH-CH, V29, P799, DOI 10.1007/s11390-014-1469-y
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Yang SW, 2020, GRAPH MODELS, V111, DOI 10.1016/j.gmod.2020.101081
   Zeghoud S, 2022, VISUAL COMPUT, V38, P1345, DOI 10.1007/s00371-021-02229-9
   Zhang P, 2015, VISUAL COMPUT, V31, P5, DOI 10.1007/s00371-013-0900-7
   Zheng LP, 2014, COMPUT GRAPH-UK, V38, P268, DOI 10.1016/j.cag.2013.10.035
   Zheng X., 2021, GRAPH MODELS, V116, P101
NR 42
TC 2
Z9 2
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2022
VL 33
IS 5
AR e2111
DI 10.1002/cav.2111
EA AUG 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5E9FV
UT WOS:000842697800001
DA 2024-07-18
ER

PT J
AU Askin, MB
   Celikcan, U
AF Askin, Mehmet Bahadir
   Celikcan, Ufuk
TI Learning based versus heuristic based: A comparative analysis of visual
   saliency prediction in immersive virtual reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deep learning; virtual reality; visual saliency
ID ATTENTION; VR; IMAGES
AB While visual saliency has been used for various purposes in virtual reality (VR), the efforts to properly understand the saliency mechanism in VR remain insufficient. In this paper, we present an extensive comparative analysis of learning-based and heuristic-based approaches to visual saliency prediction in immersive VR experienced using head-mounted-displays with a particular focus on the contribution of the depth cue. To this end, we use three learning-based RGB-D image saliency detection methods and two heuristic-based RGB-D image saliency detection methods on a VR dataset curated from three distinct virtual environments under two-dimensional and three-dimensional viewing conditions. Additionally, we extend the analysis by including a heuristic-based RGB video saliency detection method and its depth-infused version. The results acquired using these seven methods reveal the superiority of the learning-based RGB-D image saliency prediction methods in VR and validate the importance of the depth cue in the saliency prediction of virtual environments.
C1 [Askin, Mehmet Bahadir] TED Univ, Dept Comp Engn, Ankara, Turkey.
   [Celikcan, Ufuk] Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
C3 Ted University; Hacettepe University
RP Celikcan, U (corresponding author), Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
EM ufuk.celikcan@gmail.com
RI Celikcan, Ufuk/H-1191-2017
OI Celikcan, Ufuk/0000-0001-6421-185X
FU Turkiye Bilimsel ve Teknolojik Arastirma Kurumu [116E280]
FX Turkiye Bilimsel ve Teknolojik Arastirma Kurumu, Grant/Award Number:
   116E280
CR Alexiou E, 2019, IEEE IMAGE PROC, P4325, DOI [10.1109/icip.2019.8803479, 10.1109/ICIP.2019.8803479]
   [Anonymous], 2017, P 27 NOSSDAV, DOI DOI 10.1145/3083165.3083180
   [Anonymous], 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, DOI DOI 10.1109/CVPR.2016.257
   [Anonymous], 2017, P INT C 3D IMM IC3D
   Celikcan U, 2020, COMPUT GRAPH-UK, V88, P70, DOI 10.1016/j.cag.2020.03.006
   Celikcan U, 2013, VISUAL COMPUT, V29, P685, DOI 10.1007/s00371-013-0804-6
   Chang CH, 2011, IEEE T MULTIMEDIA, V13, P589, DOI 10.1109/TMM.2011.2116775
   Chao FY, 2018, IEEE INT CONF MULTI
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Cho SH, 2013, LECT NOTES COMPUT SC, V8033, P290, DOI 10.1007/978-3-642-41914-0_29
   Cong RM, 2020, IEEE T CYBERNETICS, V50, P3627, DOI 10.1109/TCYB.2019.2932005
   De Abreu A., 2017, INT WORK QUAL MULTIM, P1
   Du RF, 2021, IEEE COMPUT GRAPH, V41, P99, DOI 10.1109/MCG.2021.3080320
   Duan H., 2022, arXiv
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Fu KR, 2022, IEEE T PATTERN ANAL, V44, P5541, DOI 10.1109/TPAMI.2021.3073689
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hu ZM, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P543, DOI [10.1109/VRW50115.2020.0-153, 10.1109/VRW50115.2020.00123]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Kroner A, 2020, NEURAL NETWORKS, V129, P261, DOI 10.1016/j.neunet.2020.05.004
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lin H., 2011, SIGGRAPH Asia 2011 Sketches
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533
   Lungu AJ, 2021, EXPERT REV MED DEVIC, V18, P47, DOI 10.1080/17434440.2021.1860750
   Mankyu Sung, 2017, 2017 International Symposium on Ubiquitous Virtual Reality (ISUVR). Proceedings, P16, DOI 10.1109/ISUVR.2017.17
   Marmitt G., 2002, EUROGRAPHICS 2002 SH
   McDonnell R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531361
   Monroy R, 2018, SIGNAL PROCESS-IMAGE, V69, P26, DOI 10.1016/j.image.2018.05.005
   Nie GY, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P75, DOI 10.1109/ISMAR-Adjunct.2017.35
   Oyekoya Oyewole., 2009, Proceedings of the 16th acm symposium on virtual reality software and technology, P199, DOI [10.1145/1643928.1643973, DOI 10.1145/1643928.1643973]
   Ozcinar C, 2018, INT WORK QUAL MULTIM, P1
   Pan J., 2017, ARXIV
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Poreddy A. K. R., 2021, Proc. SPIE, V11841, P160
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rai Y, 2017, INT WORK QUAL MULTIM
   Rivu R, 2021, LECT NOTES COMPUT SC, V12936, P147, DOI 10.1007/978-3-030-85607-6_10
   Shao F, 2015, DISPLAYS, V39, P125, DOI 10.1016/j.displa.2015.10.001
   Shi PT, 2020, COMPUT GRAPH-UK, V91, P83, DOI 10.1016/j.cag.2020.06.007
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Ullah I, 2020, MULTIMED TOOLS APPL, V79, P34605, DOI 10.1007/s11042-020-08849-y
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514
   Xia ZP, 2016, J SOC INF DISPLAY, V24, P633, DOI 10.1002/jsid.508
   Yoon YJ, 2017, IEICE T INF SYST, VE100D, P2245, DOI 10.1587/transinf.2016EDL8246
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
   Zhu CB, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3319368
   Zhu CB, 2018, MULTIMED TOOLS APPL, V77, P25181, DOI 10.1007/s11042-018-5780-4
NR 56
TC 1
Z9 1
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2022
VL 33
IS 6
AR e2106
DI 10.1002/cav.2106
EA JUL 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6Z9LE
UT WOS:000829283000001
DA 2024-07-18
ER

PT J
AU Xu, Q
   LiU, F
   Fu, ZW
   Zhou, AM
   Qi, JY
AF Xu, Qing
   LiU, Feng
   Fu, Ziwang
   Zhou, Aimin
   Qi, Jiayin
TI AeS-GCN: Attention-enhanced semantic-guided graph convolutional networks
   for skeleton-based action recognition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE adaptive graph; attention-enhanced; computation efficiency;
   computational affection; semantics; skeleton-based action recognition
AB Skeleton-based action recognition has been extensively studied in recent years and applied in virtual reality, detection systems and other cases with strong requirements for low cost as well as high accuracy, but most of the existing methods mainly focus on complex architecture of deep neural networks without considering computation efficiency. To balance accuracy and computation cost well, this paper proposes a simple and efficient attention-enhanced semantic-guided graph convolutional network (AeS-GCN) for skeleton-based action recognition. Firstly, we fuse semantics of joint type and frame index and dynamics together as representation of skeleton. Then, we use spatial attention block (SAB) to explore important features in spatial structure, in which adaptive GCN layer is adopted to adaptively model skeleton topology structure. Next, we use temporal attention block (TAB) to extract latent temporal information. The model proposed is a lightweight network and achieves the state-of-the-art performance on mainstream datasets with less parameters and less computational complexity.
C1 [Xu, Qing; Fu, Ziwang] Beijing Univ Posts & Telecommun, Natl Pilot Software Engn Sch, Sch Comp Sci, Beijing, Peoples R China.
   [LiU, Feng; Zhou, Aimin] East China Normal Univ, Inst AI Educ, 3663 North Zhongshan Rd, Shanghai, Peoples R China.
   [LiU, Feng; Zhou, Aimin] East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
   [LiU, Feng; Zhou, Aimin] East China Normal Univ, Sch Psychol & Cognit Sci, Shanghai Key Lab Mental Hlth & Psychol Crisis Int, Shanghai, Peoples R China.
   [LiU, Feng; Qi, Jiayin] Shanghai Univ Int Business & Econ, Inst Artificial Intelligence & Change Management, Shanghai, Peoples R China.
C3 Beijing University of Posts & Telecommunications; East China Normal
   University; East China Normal University; East China Normal University;
   Shanghai University of International Business & Economics
RP LiU, F (corresponding author), East China Normal Univ, Inst AI Educ, 3663 North Zhongshan Rd, Shanghai, Peoples R China.; Qi, JY (corresponding author), Shanghai Univ Int Business & Econ, Inst Artificial Intelligence & Change Management, Shanghai, Peoples R China.
EM lsttoy@163.com; qijiayin@139.com
RI Zhou, Aimin/ABB-6721-2020; Liu, Feng/ABB-1886-2021
OI Liu, Feng/0000-0002-5289-5761
FU Research Project of Shanghai Science and Technology Commission
   [20dz2260300]
FX Research Project of Shanghai Science and Technology Commission,
   Grant/Award Number: 20dz2260300
CR Baradel F, 2018, PROC CVPR IEEE, P469, DOI 10.1109/CVPR.2018.00056
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Cho S, 2020, IEEE WINT CONF APPL, P624, DOI [10.1109/wacv45572.2020.9093639, 10.1109/WACV45572.2020.9093639]
   Dianlong You, 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), DOI 10.1109/ICME51207.2021.9428213
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Kingma D. P., 2014, arXiv
   Li C.T., 2018, ARXIV
   Li J, 2022, IEEE T ENG MANAGE, V69, P1902, DOI 10.1109/TEM.2019.2940702
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li N, 2021, 2021 IEEE 6TH INTERNATIONAL CONFERENCE ON BIG DATA ANALYTICS (ICBDA 2021), P51, DOI 10.1109/ICBDA51983.2021.9402996
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
NR 23
TC 3
Z9 3
U1 4
U2 26
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2070
DI 10.1002/cav.2070
EA JUN 2022
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000809736500001
DA 2024-07-18
ER

PT J
AU Cui, XY
   Cai, RF
   Tang, XJ
   Deng, ZG
   Jin, XG
AF Cui, Xiaoyu
   Cai, Ruifan
   Tang, Xiangjun
   Deng, Zhigang
   Jin, Xiaogang
TI Sketch-based shape-constrained fireworks simulation in head-mounted
   virtual reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE particle systems; shape constraints; sketch-based shape retrieval;
   virtual reality
AB In this paper we present a novel shape-constrained fireworks simulation method with rich textures in an HMD (Helmet Mounted Display) virtual environment using sketched feature lines as input. Our approach first retrieves an object from a three-dimensional (3D) model database using a sketch-based 3D shape retrieval algorithm. Then, in order to approximate models with complex structures, we introduce a novel point sampling algorithm based on Gaussian curvatures, which stores not only the positions of the selected vertices but also the texture (UV) coordinates information for texture display. In addition, we introduce a multilevel explosion process so that the fireworks can dynamically form specific, visually pleasing shapes. Through our experiments, we demonstrate that our approach can produce better results than state-of-the-art approaches.
C1 [Cui, Xiaoyu; Cai, Ruifan; Tang, Xiangjun; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 Zhejiang University; University of Houston System; University of Houston
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
EM jin@cad.zju.edu.cn
OI Deng, Zhigang/0000-0003-2571-5865; Deng, Zhigang/0000-0002-0452-8676;
   Jin, Xiaogang/0000-0001-7339-2920
FU Key Research and Development Program of Zhejiang Province [2018C01090];
   National Key R&D Program of China [2017YFB1002600]; National Natural
   Science Foundation of China [61972344]; Science and Technology Project
   on Preservation of Cultural Relics, Cultural Heritage Bureau of Zhejiang
   Province [2018009]
FX Key Research and Development Program of Zhejiang Province, 2018C01090;
   National Key R&D Program of China, 2017YFB1002600; National Natural
   Science Foundation of China, 61972344; Science and Technology Project on
   Preservation of Cultural Relics, Cultural Heritage Bureau of Zhejiang
   Province, 2018009
CR [Anonymous], 2003, P 19 ANN S COMP GEOM, DOI DOI 10.1145/777792.777839
   Chang HT, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P251, DOI 10.1109/BigMM.2016.74
   Dyn N, 2001, MATH METHODS CURVES, V36, P2084
   Eitz M., 2012, ACM T GRAPHIC, V31, P1, DOI DOI 10.1145/2185520.2335395
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Ge H, 2019, ANN ONCOL, V30, P3
   Hu ZY, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1889
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Kim T, 2017, VISUAL COMPUT, V33, P1029, DOI 10.1007/s00371-017-1374-9
   Li F.-F., 2007, RECOGNIZING LEARNING
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   MORETON HP, 1992, COMP GRAPH, V26, P167, DOI 10.1145/142920.134035
   Pu JT, 2005, LECT NOTES COMPUT SC, V3515, P343
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   Saavedra JM, 2010, LECT NOTES COMPUT SC, V6376, P432
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Squire DM, 2000, PATTERN RECOGN LETT, V21, P1193, DOI 10.1016/S0167-8655(00)00081-7
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Vása L, 2016, COMPUT GRAPH FORUM, V35, P271, DOI 10.1111/cgf.12982
   Wang XJ, 2014, COMPUT ANIMAT VIRT W, V25, P353, DOI 10.1002/cav.1580
   Wang YT, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1821
   Witten I.H., 1994, MANAGING GIGABYTES C
   Yang B, 2014, COMPUT ANIMAT VIRT W, V25, P467, DOI 10.1002/cav.1585
   YOON S.M., 2010, Proceedings of the international conference on Multimedia, P193
   Yuksel C, 2015, COMPUT GRAPH FORUM, V34, P25, DOI 10.1111/cgf.12538
   Zhao HL, 2009, COMPUT ANIMAT VIRT W, V20, P185, DOI 10.1002/cav.287
NR 27
TC 0
Z9 0
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2020
VL 31
IS 2
AR e1920
DI 10.1002/cav.1920
EA FEB 2020
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LC0VU
UT WOS:000516707000001
DA 2024-07-18
ER

PT J
AU Xiao, Z
   Deling, Y
AF Xiao, Zhang
   Deling, Yang
TI Literature review: The distributed postproduction of cultural knowledge
   for artworks in online museums
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Review
DE art; context; distribution; knowledge postproduction; online museums
AB The purpose of this study is to explore how online museums distribute the postproduction of cultural knowledge related to artworks in a network society. This study has implications for how online museums will adapt to the future development of knowledge societies. The core innovation of this study is exploring distributed knowledge postproduction in online museums from the perspective of Mode 2 knowledge production and online distributed knowledge production. This study will also examine distributed knowledge postproduction in online museums, which co-constructs knowledge and meaning. This paper covers how online museums transform artworks into a resource for cultural postproduction through digital means and engage in Mode 2 knowledge postproduction. Online museums convey knowledge of artworks, creating narratives of phenomena, extending the aura of works of art, and increasing the volume of disseminated knowledge. Through the Semantic Web, online museums construct distributed online systems of knowledge, bringing together machines, technologies, and people and enriching the cultural understanding and innovation of systems of knowledge. Through hyperlinks, exhibitions in online museums intervene in social contexts anytime and anywhere, distributing the cultural knowledge postproduction of artworks. By establishing interactive connections with various contexts, online museums co-construct knowledge and meaning. Compared with previous work, this study explores how new technological applications in online museums co-construct knowledge and meaning through interactions with various social contexts, which will influence the future development of knowledge societies.
C1 [Xiao, Zhang; Deling, Yang] Guangzhou Acad Fine Arts, Guangzhou, Peoples R China.
   Guangzhou Acad Fine Arts, Zhang Xiao, Guangzhou, Peoples R China.
C3 Guangzhou Academy of Fine Arts; Guangzhou Academy of Fine Arts
RP Xiao, Z (corresponding author), Guangzhou Acad Fine Arts, Guangzhou, Peoples R China.
EM 742717769@qq.com
RI xiao, zhang/AFO-8560-2022
OI xiao, zhang/0000-0001-6969-2357
CR Adorno G, 2008, TLS-TIMES LIT SUPPL, P32
   [Anonymous], ART
   [Anonymous], KNOWLEDGE
   Baudrillard J, 1993, SYMBOLIC EXCHANGE DE, P75
   Benjamin Walter., 2008, WORK ART AGE ITS TEC
   Blascovich Jim., 2011, Infinite Reality, P9
   Bourriaud N, 2002, POSTPRODUCTION, P36
   Bourriaud N, 2002, POSTPRODUCTION CULTU, P7
   Bourriaud N, 2002, POSTPRODUCTION, P96
   Bourriaud N, 1998, RELATIONAL AESTHETIC, P26
   Bourriaud N, 2002, POSTPRODUCTION, P14
   Bourriaud N, 2002, POSTPRODUCTION, P83
   Bourriaud N, 2002, POSTPRODUCTION, P6
   Burke P, 2008, EYEWITNESSING USES I, P11
   Ch'ng E., 2017, PRESENCE, V26, piii
   F Hayes-Roth, 1983, BUILDING EXPERT SYST, P6
   Gibbons M, 1994, NEW PRODUCTION KNOWL, P101
   Gibbons M, 1994, NEW PRODUCTION KNOWL, P168
   Gibbons M, 1994, NEW PRODUCTION KNOWL, P167
   Gibbons M, 1994, NEW PRODUCTION KNOWL, P14
   Gibbons M, 1994, NEW PRODUCTION KNOWL, P108
   Gibbons M, 1994, NEW PRODUCTION KNOWL, P102
   Google Arts & Culture, 2017, EYE DET ZOOM 1000 AR
   Guangming Net, 2021, PAL TICK AR HARD GET
   Harari YN, 2015, SAPIENS BRIEF HIST H, V37, P31
   Ministry of Education of the People's Republic of China, 2018, PUT GAOD XUEX BENK Z
   Polycarpou C, 2018, VIMM DEFINITION VIRT
   The Palace Museum, 2017, MEIR GUG 365 DAYS MA
   The Palace Museum, 2017, WECHAT SHUZ GUGONG G
   United Nations Educational Scientific and Cultural Organization, 2005, KNOWL SOC, P19
   United Nations Educational Scientific and Cultural Organization, 2005, KNOWL SOC, P189
   United Nations Educational Scientific and Cultural Organization, 2018, GEN C 32 SESS
   United Nations Educational Scientific and Cultural Organization, 2005, KNOWL SOC, P51
   W3C, 2018, SEMANTIC WEB
   Yang DL, 2019, 2018 INTERNATIONAL CONFERENCE ON BIG DATA AND ARTIFICIAL INTELLIGENCE (ICBDAI 2018), P169, DOI 10.25236/icbdai.2018.026
   Zhang XJ, 2019, IEEE T CONTR SYST T, V27, P1, DOI 10.1109/TCST.2017.2769019
NR 36
TC 2
Z9 2
U1 2
U2 49
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2020
VL 31
IS 1
AR e1877
DI 10.1002/cav.1877
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KR0SC
UT WOS:000517329600001
DA 2024-07-18
ER

PT J
AU Wu, HY
AF Wu, Huayue
TI An adaptive character skinning algorithm based on the property of real
   skin
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character skinning; dual quaternion skinning; linear blend skinning;
   property of real skin
AB Current methods for character skinning usually include weight binding and automatic skinning such as linear blend skinning (LBS) and dual quaternion skinning (DQS). However, weight binding is a tedious work; LBS and DQS suffer from their own artifacts. The latest research studies could produce better effect; however, their application in real-time situations is limited due to the requirement of a large amount of first-phase preparations and huge computation. This paper proposed a new approach that uses the property of real skin for skinning, which could produce a more natural and realistic effect and could greatly promote skinning efficiency. An optimized mathematical model is also used to compute mesh deformation; therefore, the render speed is greatly promoted and the effect of bulging muscles and fat could also be simulated.
C1 [Wu, Huayue] Changan Univ, Sch Informat Engn, Xian 710064, Shaanxi, Peoples R China.
C3 Chang'an University
RP Wu, HY (corresponding author), Changan Univ, Sch Informat Engn, Xian 710064, Shaanxi, Peoples R China.
EM whyinvr@126.com
FU Collaborative Innovation Planning Project of Shaanxi Province
   [2014XT-12]
FX Collaborative Innovation Planning Project of Shaanxi Province,
   Grant/Award Number: 2014XT-12
CR Abu Rumman N, 2015, COMPUT GRAPH FORUM, V34, P240, DOI 10.1111/cgf.12533
   [Anonymous], 2005, P 2005 S INTERACTIVE, DOI [DOI 10.1145/1053427.10534294, DOI 10.1145/1053427.1053429]
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Le BH, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925959
   Dionne Olivier., 2013, P 12 ACM SIGGRAPH EU, P173, DOI DOI 10.1145/2485895.2485919
   Forstmann S, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P141
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Kavan L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366215
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Kim Y, 2014, COMPUT ANIMAT VIRT W, V25, P323, DOI 10.1002/cav.1604
   Li JT, 2011, COMPUT GRAPH-UK, V35, P945, DOI 10.1016/j.cag.2011.07.005
   Li JT, 2011, VISUAL COMPUT, V27, P585, DOI 10.1007/s00371-011-0585-8
   McAdams A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964932
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Mukai T, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925905
   Mukai T, 2015, PROCEEDINGS - I3D 2015, P77, DOI 10.1145/2699276.2699278
   Nieto J.R., 2013, Deformation Models: Tracking, Animation and Applications, V7, P75, DOI 10.1007/978-94-007-5446-13
   Tao J, 2008, ACM T GRAPHIC, V27
   Thiery JM, 2018, COMPUT GRAPH FORUM, V37, P32, DOI 10.1111/cgf.13161
   Wang Cheng, 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P299, DOI 10.1109/ISVRI.2011.5759655
   Xu WW, 2009, J COMPUT SCI TECH-CH, V24, P6, DOI 10.1007/s11390-009-9209-4
   Yan L, 2005, COMPUTE RES DEV, V42, P888
NR 22
TC 1
Z9 1
U1 2
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2019
VL 30
IS 5
AR e1868
DI 10.1002/cav.1868
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JD7JT
UT WOS:000490157800001
DA 2024-07-18
ER

PT J
AU Yang, ZY
   Liu, S
AF Yang, Zhongyao
   Liu, Shiguang
TI An optimization on water wave diffraction approximation based on wave
   packets
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE diffraction approximation; Green function; water simulation; wave
   packets
ID RADIATION
AB This paper proposes a novel approach for diffraction approximation in two-dimensional water wave simulation. Our method is based on wave packets, which ensures unconditionally stability. We introduce the Green function in order to generate diffraction patterns that are used to judge whether our method can produce realistic diffraction effects. This method also implements propagation direction optimization for diffractive wave packets to handle the efficiency problem existed in the state-of-the-art approach. Various results indicate that our new method can produce more appealing diffractive effects than current particle-based approaches. Besides, from the efficiency perspective, compared to current approaches, our implementation greatly enhances the computational efficiency for scenes with high curvature obstacle boundaries.
C1 [Yang, Zhongyao; Liu, Shiguang] Tianjin Univ, Sch Comp Sci & Technol, Div Intelligence & Comp, Tianjin 300350, Peoples R China.
C3 Tianjin University
RP Liu, S (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Div Intelligence & Comp, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn
OI Yang, Zhongyao/0000-0002-6396-7134
FU National Natural Science Foundation of China [61672375, 61170118];
   National Key Research and Development Program of China [2018YFC1407405]
FX National Natural Science Foundation of China, Grant/Award Number:
   61672375 and 61170118; National Key Research and Development Program of
   China, Grant/Award Number: 2018YFC1407405
CR [Anonymous], 1969, Introduction to Potential Theory
   Bridson R., 2015, Fluid simulation for computer graphics
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   Ihmsen Markus, 2014, P 35 ANN C EUR ASS C, DOI [10.2312/egst.20141034, DOI 10.2312/EGST.20141034]
   Jeschke S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073678
   Jeschke S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201336
   Jeschke S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2714572
   Liang H, 2018, APPL OCEAN RES, V74, P80, DOI 10.1016/j.apor.2018.02.025
   LOVISCACH J, 2002, EUR 2002 SHORT PAP P, P381
   ONURAL L, 1993, OPT LETT, V18, P846, DOI 10.1364/OL.18.000846
   Ottosson B, 2011, THESIS
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Taylor BR, 2017, EXTENDING WAVE PARTI
   TELSTE JG, 1986, J SHIP RES, V30, P69
   Tessendorf J, 2001, ACM SIGGRAPH COURSES, V1
   Tessendorf Jerry, 2004, GAME PROGRAMMING GEM, V4, P265
   Wu HY, 2017, EUR J MECH B-FLUID, V65, P54, DOI 10.1016/j.euromechflu.2017.02.008
   Yang S., 2016, S COMP ANIM, P29
   Yu JH, 2012, COMPUT GRAPH FORUM, V31, P815, DOI 10.1111/j.1467-8659.2012.03062.x
   Yuksel C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239550
   Zhang XY, 2015, COMPUT ANIMAT VIRT W, V26, P357, DOI 10.1002/cav.1637
   Zheng SM, 2015, OCEAN ENG, V104, P329, DOI 10.1016/j.oceaneng.2015.04.065
NR 22
TC 2
Z9 2
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1886
DI 10.1002/cav.1886
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400004
DA 2024-07-18
ER

PT J
AU Kyrlitsias, C
   Michael-Grigoriou, D
AF Kyrlitsias, Christos
   Michael-Grigoriou, Despina
TI Asch conformity experiment using immersive virtual reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE agents; Asch experiment; avatars; behavioral realism; conformity;
   virtual reality
AB Virtual reality is used in fields of cognitive sciences to study the participants' behavior. In such cases, existence of other digital humanoid representations in the virtual environment is a crucial factor. Conformitythe act of matching attitudes, beliefs, and behaviors to fit with the majorityis one of the most powerful aspects of social influence. In this study, we investigated conformity to virtual humans in an immersive virtual environment, using two experiments. In the first experiment, we investigated whether agents have social influence on the participants by conducting the 1951 Asch conformity experiment. Findings demonstrate that the participants' response times were affected by the judgments of the agents in the virtual environment. In the second experiment, we used a similar method to study how the factors agency and behavioral real ism affect social conformity. Agency is the extent of a user's belief that other humanoid representations represent real people. Behavioral realism is the degree to which humanoid representations behave as they would do in the real world. The results of the experiment showed that conformity can be caused by virtual humans in immersive virtual environments. However, there are no significant results regarding the influence of agency and behavioral realism on conformity.
C1 [Kyrlitsias, Christos; Michael-Grigoriou, Despina] Cyprus Univ Technol, Dept Multimedia & Graph Arts, GET Lab, Limassol, Cyprus.
C3 Cyprus University of Technology
RP Kyrlitsias, C (corresponding author), Cyprus Univ Technol, Dept Multimedia & Graph Arts, GET Lab, Limassol, Cyprus.
EM c.kyrlitsias@gmail.com; despina.grigoriou@cut.ac.cy
RI Michael-Grigoriou, Despina/ABE-5748-2022
OI Michael-Grigoriou, Despina/0000-0003-0824-7684; Kyrlitsias,
   Christos/0000-0003-0810-1685
CR Asch S.E., 1951, ORG INFLUENCE PROCES, P295
   ASCH SE, 1955, SCI AM, V193, P31, DOI 10.1038/scientificamerican1155-31
   ASCH SE, 1956, PSYCHOL MONOGR, V70, P1, DOI 10.1037/h0093718
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Bailenson Jeremy N, 2004, Berkshire Encyclopedia of Human-Computer Interaction, P64, DOI DOI 10.1108/095041206106853731
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Baron RS, 1996, J PERS SOC PSYCHOL, V71, P915, DOI 10.1037/0022-3514.71.5.915
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   DEUTSCH MORTON, 1955, JOUR ABNORMAL AND SOCIAL PSYCHOL, V51-31, P629, DOI 10.1037/h0046408
   Friedman D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00943
   Guadagno RE, 2011, COMPUT HUM BEHAV, V27, P2380, DOI 10.1016/j.chb.2011.07.017
   Hertz N, 2016, P HUM FACT ERG SOC A
   Hoyt CL, 2003, PRESENCE TELEOPERATO, V12
   Midden C, 2015, PERSUASIVE 2015 INT
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153
   Rayborn-Reeves R, 2013, J VIRTUAL WORLDS RES, V6
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Swinth K R., 2002, PRESENCE 2002 5 ANN
   Tarr MJ, 2002, NAT NEUROSCI, V5, P1089, DOI 10.1038/nn948
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   von der Pütten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Wilson CJ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/151702
   Wu J, 2016, PROGR IS, P293, DOI 10.1007/978-3-319-22041-3_11
NR 27
TC 16
Z9 20
U1 1
U2 47
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2018
VL 29
IS 5
AR e1804
DI 10.1002/cav.1804
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA GW0KS
UT WOS:000446555300007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kim, H
   Hwang, JI
AF Kim, Hyejin
   Hwang, Jae-In
TI Manipulating augmented virtual character using dynamic hierarchical
   pointing interface
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE augmented reality; bare-hand interaction; manipulation; virtual
   character
AB In this paper, we introduce a bare-hand interaction method for controlling an augmented virtual character. Our method is utilizing a dynamic hierarchical structure of virtual buttons on the natural marker of the environment. Unlike the existing virtual button method, the proposed method can be used to select a very fine level. This method is adequate for controlling an augmented virtual character with a users' various intentions. We implemented several examples of manipulating an augmented virtual character such as guiding the character, selecting part of the character, and selecting a target object for the character. We also compared the performance of full arrangement and dynamic hierarchical arrangement of virtual buttons. Our method outperforms the full arrangement method, especially in the low index of difficulty. In the user study with 15 participants, the users responded that the proposed method was significantly better than the existing full arrangement method regarding efficiency and satisfaction in the case of the fine level selection.
C1 [Kim, Hyejin; Hwang, Jae-In] Korea Inst Sci & Technol, LG Elect, Seoul, South Korea.
C3 LG Electronics; Korea Institute of Science & Technology (KIST)
RP Hwang, JI (corresponding author), Korea Inst Sci & Technol, Seoul, South Korea.
EM hji@kist.re.kr
FU Korea Institute of Science and Technology (KIST) Institutional Program;
   Korea Creative Content Agency
FX Korea Institute of Science and Technology (KIST) Institutional Program;
   Korea Creative Content Agency
CR [Anonymous], GAM DEV C SAN JOS CA
   [Anonymous], 2011, P 24 ANN ACM S US IN, DOI DOI 10.1145/2047196.2047255
   [Anonymous], 2017, ARXIV171201057
   Baldauf M., 2011, Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services, P539, DOI DOI 10.1145/2037373.2037457
   Buchmann V., 2004, VIRTUAL REAL-LONDON, V1, P212
   Chun W. H., 2013, P 2013 INT C INT US, P307, DOI [DOI 10.1145/2449396.2449435, 10.1145/2449396.2449435]
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Hammer Jan Hendrik, 2013, Human-Computer Interaction. Interaction Modalities and Techniques. 15th International Conference, HCI International 2013. Proceedings. LNCS 8007, P252, DOI 10.1007/978-3-642-39330-3_27
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Kim H, 2015, IEEE VIRT REAL 2015
   Lee Gun A, 2004, PROC 2004 ACM SIGGRA, P419
   Lee T, 2008, VIRT REAL C REN NE
   Mistry P., 2009, P CHI 09 EXTENDED AB, P4111, DOI [DOI 10.1145/1520340.1520626, 10.1145/1520340.1520626]
   Seo B-K, 2008, VRCAI 08 P 7 ACM SIG
   Shen Y, 2011, INT J HUM-COMPUT INT, V27, P523, DOI 10.1080/10447318.2011.555297
   Ventura J, 2014, INT SYM MIX AUGMENT
NR 16
TC 0
Z9 0
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1824
DI 10.1002/cav.1824
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100015
OA hybrid
DA 2024-07-18
ER

PT J
AU Bulbul, A
   Dahyot, R
AF Bulbul, Abdullah
   Dahyot, Rozenn
TI Populating virtual cities using social media
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; crowd simulations; social media; virtual worlds
ID CROWDS
AB We propose to automatically populate geo-located virtual cities by harvesting and analyzing online contents shared on social networks and websites. We show how pose and motion paths of agents can be realistically rendered using information gathered from social media. 3D cities are automatically generated using open-source information available online. To provide our final rendering of both static and dynamic urban scenes, we use Unreal game engine.
C1 [Bulbul, Abdullah] Yildirim Beyazit Univ, Comp Engn Dept, Ankara, Turkey.
   [Dahyot, Rozenn] Trinity Coll Dublin, Stat, Dublin, Ireland.
C3 Ankara Yildirim Beyazit University; Trinity College Dublin
RP Bulbul, A (corresponding author), Yildirim Beyazit Univ, Bati Kampus,Ayvali 150 Sokak, TR-06010 Ankara, Turkey.
EM abulbul@ybu.edu.tr
RI Bulbul, Abdullah/AAC-6616-2020; Dahyot, Rozenn/AAN-4260-2020
OI Bulbul, Abdullah/0000-0002-2527-2729; Dahyot, Rozenn/0000-0003-0983-3052
FU EU [612334]
FX EU FP7-PEOPLE-2013-IAPP GRAI Search, Grant/Award Number: 612334
CR [Anonymous], P 3 INT S 3D DAT PRO
   [Anonymous], 2013, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'13
   Bera A, 2015, P 41 GRAPH INT C, P65
   Chao QW, 2015, COMPUT ANIMAT VIRT W, V26, P405, DOI 10.1002/cav.1654
   Dahyot R, 2015, INT WORKSH COMP INT
   Ennis C, 2012, COMPUT ANIMAT VIRT W, V23, P321, DOI 10.1002/cav.1453
   Ennis C, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870078
   Karamouzas I, 2012, IEEE T VIS COMPUT GR, V18, P394, DOI 10.1109/TVCG.2011.133
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Lerner A, 2009, LECT NOTES COMPUT SC, V5884, P75, DOI 10.1007/978-3-642-10347-6_7
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   O' Sullivan C, 2011, 3 INT C GAM VIRT WOR
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Peters C, 2008, P EUR SHORT PAP, P227
   Pettré J, 2006, COMPUT ANIMAT VIRT W, V17, P445, DOI 10.1002/cav.147
   Prusinkiewicz P., 1990, ALGORITHMIC BEAUTY P
   Ren ZG, 2013, VISUAL COMPUT, V29, P927, DOI 10.1007/s00371-013-0853-x
   Schwarz M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766956
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Terzopoulos D., 2008, IEEE VIRT REAL 2008, P1
   Thomas G, 2000, COMPUT GRAPH FORUM, V19, pC71, DOI 10.1111/1467-8659.00399
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu C., 2007, Siftgpu: A gpu implementation of david lowe's scale invariant feature transform (sift)
   Xiao JX, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618460
   Zandbergen PA, 2009, T GIS, V13, P5, DOI 10.1111/j.1467-9671.2009.01152.x
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
NR 28
TC 5
Z9 5
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2017
VL 28
IS 5
AR e1742
DI 10.1002/cav.1742
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9XG
UT WOS:000417251100007
DA 2024-07-18
ER

PT J
AU Yang, K
   Youn, K
   Lee, K
   Lee, J
AF Yang, Kyungyong
   Youn, Kibeom
   Lee, Kyungho
   Lee, Jehee
TI Controllable data sampling in the space of human poses
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE human pose recognition; uniform sampling; machine learning; motion
   capture
ID HUMAN MOTION; REGRESSION
AB Markerless human pose recognition using a single-depth camera plays an important role in interactive graphics applications and user interface design. Recent pose recognition algorithms have adopted machine learning techniques, utilizing a large collection of motion capture data. The effectiveness of the algorithms is greatly influenced by the diversity and variability of training data. We present a new sampling method that resamples a collection of human motion data to improve the pose variability and achieve an arbitrary size and level of density in the space of human poses. The space of human poses is high dimensional, and thus, brute-force uniform sampling is intractable. We exploit dimensionality reduction and locally stratified sampling to generate either uniform or application specifically biased distributions in the space of human poses. Our algorithm learns to recognize such challenging poses as sitting, kneeling, stretching, and doing yoga using a remarkably small amount of training data. The recognition algorithm can also be steered to maximize its performance for a specific domain of human poses. We demonstrate that our algorithm performs much better than the Kinect software development kit for recognizing challenging acrobatic poses while performing comparably for easy upright standing poses. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Yang, Kyungyong; Youn, Kibeom; Lee, Kyungho; Lee, Jehee] Seoul Natl Univ, Sch Comp Sci & Engn, Movement Res Lab, Seoul 151742, South Korea.
C3 Seoul National University (SNU)
RP Lee, J (corresponding author), Seoul Natl Univ, Sch Comp Sci & Engn, Movement Res Lab, 1 Gwanak Ro, Seoul 151742, South Korea.
EM jehee@mrl.snu.ac.kr
RI Lee, Jehee/V-7545-2019
FU National Research Foundation of Korea (NRF) - Korean government (MSIP)
   [2011-0018340, 2007-0056094]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean government (MSIP; no. 2011-0018340 and
   no. 2007-0056094).
CR [Anonymous], 2011, P BRIT MACH VIS C
   Baak A, 2011, IEEE I CONF COMP VIS, P1092, DOI 10.1109/ICCV.2011.6126356
   Brox T, 2007, LECT NOTES COMPUT SC, V4814, P152
   COOK RL, 1986, ACM T GRAPHIC, V5, P51, DOI 10.1145/7529.8927
   Dunbar D, 2006, ACM T GRAPHIC, V25, P503, DOI 10.1145/1141911.1141915
   Gallo L, 2011, COMP MED SY, DOI 10.1109/CBMS.2011.5999138
   Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141
   Girshick R, 2011, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2011.6126270
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61
   Lau M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618517
   Lawrence N, 2005, J MACH LEARN RES, V6, P1783
   Lee J, 1999, COMP GRAPH, P39
   Lee KH, 2006, ACM T GRAPHIC, V25, P898, DOI 10.1145/1141911.1141972
   Levina Elizaveta, 2004, Advances in neural information processing systems, V17
   Li R, 2006, LECT NOTES COMPUT SC, V3952, P137
   Min JY, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640452
   Ren Z., 2011, P 19 ACM INT C MULT, P759
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shin HJ, 2006, COMPUT ANIMAT VIRT W, V17, P219, DOI 10.1002/cav.125
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Sok KW, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276511, 10.1145/1239451.1239558]
   Sun M, 2012, PROC CVPR IEEE, P3394, DOI 10.1109/CVPR.2012.6248079
   VERVEER PJ, 1995, IEEE T PATTERN ANAL, V17, P81, DOI 10.1109/34.368147
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Wei XL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366207
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Yamada M, 2012, LECT NOTES COMPUT SC, V7575, P674, DOI 10.1007/978-3-642-33765-9_48
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
NR 30
TC 2
Z9 2
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 457
EP 467
DI 10.1002/cav.1662
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700027
DA 2024-07-18
ER

PT J
AU Wang, CB
   Zhang, Q
   Kong, FL
   Gao, YS
AF Wang, Changbo
   Zhang, Qiang
   Kong, Fanlong
   Gao, Yusheng
TI Fast animation of debris flow with mixed adaptive grid refinement
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE debris flow; adaptive grid; interaction; enhanced details; animating
ID LATTICE-BOLTZMANN METHOD; SIMULATION; WATER
AB Animating debris flow is one of the most challenging tasks in computer graphics, because of its complex dynamic mechanism and the interaction between flows and solids in so large scale region. The difficulty focuses on how to resolve the contradiction between lower computational load and higher request of animating quality. A highly effective method of modeling and animating of debris flow with adaptive grid is presented. First, the debris flow is modeled as Bingham plastic fluid with view-dependent adaptive grid that is adopted to model the flow volume, and the boundless grids can cover the large scale region of debris flow. Then the mixed grids are built for confluent flows, and the two-way coupling interaction between flows and environment is considered. After extracting the debris flow surface, adaptive surface tension combining wave particles equation is used to enhance the details and sprays are generated by particles considering the interaction between two fluid volumes. Finally, different dynamic realistic scenes with debris flow are successfully animating at interactive rates. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Wang, Changbo; Zhang, Qiang; Kong, Fanlong; Gao, Yusheng] E China Normal Univ, Inst Software Engn, Shanghai 200062, Peoples R China.
   [Wang, Changbo] E China Normal Univ, Shanghai Key Lab Trustworthy Comp, Shanghai 200062, Peoples R China.
C3 East China Normal University; East China Normal University
RP Wang, CB (corresponding author), E China Normal Univ, Inst Software Engn, Shanghai 200062, Peoples R China.
EM cbwangcg@gmail.com
FU Natural Science Foundation of China [61070128, 61272199]; Innovation
   Program of the Shanghai Municipal Education Commission [12ZZ042];
   Natural Science Foundation of Shanghai Municipality of China
   [11ZR1411100]; Fundamental Research Funds for the Central Universities;
   Shanghai Knowledge Service Platform for Trustworthy Internet of Things
   [ZF1213]
FX This paper was partially supported by the Natural Science Foundation of
   China (Grant No. 61070128, 61272199), the Innovation Program of the
   Shanghai Municipal Education Commission (Grant No. 12ZZ042), the Natural
   Science Foundation of Shanghai Municipality of China(Grant No.
   11ZR1411100), the Fundamental Research Funds for the Central
   Universities, and the Shanghai Knowledge Service Platform for
   Trustworthy Internet of Things (Grant No. ZF1213).
CR Alduan I, 2011, P 2011 ACM SIGGRAPH
   Alim UR, 2009, IEEE T VIS COMPUT GR, V15, P630, DOI 10.1109/TVCG.2008.201
   [Anonymous], 1993, Journal of hydraulic engineering, DOI 10.1061/(asce)0733-9429(1993)119
   [Anonymous], 2004, COMPUTER ANIMATION 2, DOI DOI 10.1145/1028523.1028549
   Armanini A, 2009, COMPUT GEOSCI-UK, V35, P993, DOI 10.1016/j.cageo.2007.11.008
   Bayraktar S, 2010, J VISUAL-JAPAN, V13, P327, DOI 10.1007/s12650-010-0041-2
   BELL N, 2005, P 2005 ACM SIGGRAPH
   Brochu T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778784
   Bunlutangtum Rinchai, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P204, DOI 10.1007/978-3-642-25090-3_18
   D'Ambrosio D, 2007, ENVIRON MODELL SOFTW, V22, P1417, DOI 10.1016/j.envsoft.2006.09.009
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Filippova O, 1998, J COMPUT PHYS, V147, P219, DOI 10.1006/jcph.1998.6089
   Houston B, 2006, ACM T GRAPHIC, V25, P151, DOI 10.1145/1122501.1122508
   Iovine G, 2005, GEOMORPHOLOGY, V66, P287, DOI 10.1016/j.geomorph.2004.09.017
   Irving G, 2006, ACM T GRAPHIC, V25, P805, DOI 10.1145/1141911.1141959
   Iverson RM, 1997, REV GEOPHYS, V35, P245, DOI 10.1029/97RG00426
   Jan C.-D., 2008, RECENT DEV DEBRIS FL, P93
   Johnson A.M., 1970, Zeitschrift fur Geomorphologie, V9, P168
   Kass M., 1990, Computer Graphics, V24, P49, DOI 10.1145/97880.97884
   Liu HF, 2009, COMPUT FLUIDS, V38, P1108, DOI 10.1016/j.compfluid.2008.11.005
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Petkov K, 2009, IEEE T VIS COMPUT GR, V15, P802, DOI 10.1109/TVCG.2009.32
   Shah Maurya., 2004, PROC 2004 ACM SIGGRA, P213
   Thuerey N., 2004, VISION MODELING VISU, P199
   Thuerey N., 2006, PROC VIS MODEL VIS, V2006, P193
   Thürey N, 2009, COMPUT VIS SCI, V12, P247, DOI 10.1007/s00791-008-0090-4
   THUREY N., 2010, ACM T GRAPHIC, V29, P48
   Thurey N, 2006, P 2006 EUR ACM SIGGR
   Tubbs KR, 2009, ADV WATER RESOUR, V32, P1767, DOI 10.1016/j.advwatres.2009.09.008
   Wang CH, 2008, PHYSICA A, V387, P4740, DOI 10.1016/j.physa.2008.04.008
   Wang Y-Y, 1982, J SEDIMENT RES, V6, P75
   Wei XM, 2004, IEEE T VIS COMPUT GR, V10, P719, DOI 10.1109/TVCG.2004.48
   Yan H, 2009, COMPUT ANIMAT VIRT W, V20, P417, DOI 10.1002/cav.300
   Yang Z., 2008, Proc. Pecora, V17, P1
   Yuksel C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239550
   Zhu B, 2010, COMPUT GRAPH FORUM, V29, P2207, DOI 10.1111/j.1467-8659.2010.01809.x
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 37
TC 6
Z9 7
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2015
VL 26
IS 1
BP 3
EP 14
DI 10.1002/cav.1542
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CC1LW
UT WOS:000350103200002
OA Bronze
DA 2024-07-18
ER

PT J
AU Almajano, P
   Lopez-Sanchez, M
   Rodriguez, I
   Trescak, T
AF Almajano, Pablo
   Lopez-Sanchez, Maite
   Rodriguez, Inmaculada
   Trescak, Tomas
TI Assistant agents to advice users in hybrid structured 3D virtual
   environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE personal assistant agents; social model; structured 3D virtual
   environment; OCMAS planning
AB Hybrid structured 3D Virtual Environments model serious activities in immersive 3D spaces, where participants are human and software agents, and their interactions are regulated by an Organization Centered Multi-Agent System (OCMAS). In this context, both OCMAS social model and the tasks that users need to accomplish can be rather complex, and thus, users may benefit from having an assistance service. Hence, we propose personal assistant agents (PA), which, based on knowledge about the OCMAS specification and current system state, provide the user with an advice (a plan) to achieve her or his goal. Additionally, we implement this service with PLAN-EA, an Extension of the A* algorithm that generates plans for a user whose actions may depend on other users' actions. Thus, PAs provide plans that do not only include assisted user actions but also other users' ones. We illustrate our approach by means of v-mWateran online water marketand make a comparative analysis, with and without assistance, where efficiencyin terms of number of user actionsshows an improvement (7 vs 10.8), efficacypercentage of completed tasksalso improves (93% vs 77%), and assistance's overall satisfaction is positive. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Almajano, Pablo] Univ Barcelona, IIIA CSIC, Barcelona, Spain.
   [Lopez-Sanchez, Maite; Rodriguez, Inmaculada] Univ Barcelona, Barcelona, Spain.
   [Trescak, Tomas] Univ Western Sydney, Sydney, NSW, Australia.
C3 University of Barcelona; Consejo Superior de Investigaciones Cientificas
   (CSIC); CSIC - Instituto de Investigacion en Inteligencia Artificial
   (IIIA); University of Barcelona; Western Sydney University
RP Almajano, P (corresponding author), Univ Barcelona, IIIA CSIC, Barcelona, Spain.
EM palmajano@iiia.csic.es
RI Lopez-Sanchez, Maite/ABG-2682-2021; Rodriguez, Inmaculada/H-9298-2015
OI Lopez-Sanchez, Maite/0000-0002-1838-5928; Trescak,
   Tomas/0000-0002-2540-6002; Rodriguez, Inmaculada/0000-0001-5931-7713
FU Spanish research projects [CSD2007-0022, TIN2011-24220,
   TIN2012-38876-C02-02]
FX Work funded by Spanish CSD2007-0022, TIN2011-24220 and
   TIN2012-38876-C02-02 research projects.
CR Almajano P, 2012, ITMAS 2012, P93
   [Anonymous], 2012, P 2012 ACM INT C INT
   [Anonymous], GRAPP 13
   Bourazeri A, 2012, INT CONF SELF SELF, P145, DOI 10.1109/SASOW.2012.33
   Chalupsky H., 2001, P 13 C INNOVATIVE AP, P51
   Chittaro Luca., 2004, PSYCHNOLOGY J SPECIA, V2, P24
   Esteva M., 2004, Third International Joint Conference on Autonomous Agents and Multiagent Systems, V1, P236, DOI DOI 10.1109/AAMAS.2004.10060
   Faulring A, 2010, IUI 2010, P61
   Ferber J, 2004, LECT NOTES COMPUT SC, V2935, P214
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Kumar S, 2002, AAAI 2002 FALL S SER, P30
   Lujak M., 2013, Agreement Technologies, P597
   Oh J, 2013, ENG APPL ARTIF INTEL, V26, P863, DOI 10.1016/j.engappai.2012.12.006
   van Dijk E. MAG, 2003, INFORM SCI SPECIAL S, V6, P115
NR 14
TC 1
Z9 2
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 497
EP 506
DI 10.1002/cav.1598
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300030
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Stüvel, SA
   Magnenat-Thalmann, N
   Thalmann, D
   Egges, A
   van der Stappen, AF
AF Stuevel, Sybren A.
   Magnenat-Thalmann, Nadia
   Thalmann, Daniel
   Egges, Arjan
   van der Stappen, A. Frank
TI Hierarchical structures for collision checking between virtual
   characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE collision detection; hierarchical data structure; geometric algorithms;
   shape approximation
AB Simulating a crowded scene like a busy shopping street requires tight packing of virtual characters. In such cases, collisions are likely to occur, and the choice in collision detection shape will influence how characters are allowed to intermingle. Full collision detection is too expensive for crowds, so simplifications are needed. The most common simplification, the fixed-width, pose-independent cylinder, does not allow intermingling of characters, as it will either cause too much empty space between characters or undetected penetrations. As a possible solution to this problem, we introduce the bounding cylinder hierarchy (BCH), a bounding volume hierarchy that uses vertical cylinders as bounding shapes. Because the BCH is a generalization of the single cylinder, we expect that this representation can be easily integrated with existing crowd simulation systems. We compare our BCH with commonly used collision shapes, namely the single cylinder and oriented bounding box tree, in terms of query time, construction time, and represented volume. To get an indication of possible crowd densities, we investigate how close characters can be before collision is detected and finally propose a critical maximum depth for the BCH. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Stuevel, Sybren A.; Egges, Arjan] Univ Utrecht, VHTLab, Dept Informat & Comp Sci, Utrecht, Netherlands.
   [van der Stappen, A. Frank] Univ Utrecht, VHTLab, Utrecht, Netherlands.
   [Magnenat-Thalmann, Nadia; Thalmann, Daniel] Nanyang Technol Univ, Inst Media Innovat, Singapore 639798, Singapore.
C3 Utrecht University; Utrecht University; Nanyang Technological University
RP Stüvel, SA (corresponding author), Univ Utrecht, VHTLab, Dept Informat & Comp Sci, Utrecht, Netherlands.
EM s.a.stuvel@uu.nl
RI Thalmann, Daniel/AAL-1097-2020; Thalmann, Nadia/AAK-5195-2021; Thalmann,
   Daniel/A-4347-2008
OI Thalmann, Daniel/0000-0002-0451-7491; Thalmann,
   Nadia/0000-0002-1459-5960; van der Stappen, Frank/0000-0001-7965-2818
FU Dutch nationally funded project COMMIT
FX This research is supported by the Dutch nationally funded project
   COMMIT. Part of this work has been performed during the stay of Sybren
   A. Stuvel and Arjan Egges at Nanyang Technological University,
   Singapore. Contour calculations were performed using the Clipper library
   [24]. All graphs were made with Python, Matplotlib, and Numpy. All other
   images were made with Blender.
CR Allen BF, 2012, COMPUT ANIMAT VIRT W, V23, P569, DOI 10.1002/cav.1472
   [Anonymous], 2009, P 4 INT C FDN DIGITA, DOI DOI 10.1145/1536513.1536540
   [Anonymous], 1997, J GRAPH TOOLS, DOI DOI 10.1080/10867651.1997.10487480
   Dube C., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2397, DOI 10.1109/ROBIO.2011.6181657
   Gain J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409629
   Geraerts R, 2010, IEEE INT CONF ROBOT, P1997, DOI 10.1109/ROBOT.2010.5509263
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Gottschalk S., 2000, Collision queries using oriented bounding boxes
   Guy S.J., 2011, P 2011 ACM SIGGRAPH, P43, DOI [10.1145/2019406.2019413, DOI 10.1145/2019406.2019413]
   Heidelberger B, 2004, VIS MOD VIS 2004 P
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Hubbard PM, 1996, ACM T GRAPHIC, V15, P179, DOI 10.1145/231731.231732
   Johnson A., 2014, CLIPPER OPEN SOURCE
   Klosowski JT, 1998, IEEE T VIS COMPUT GR, V4, P21, DOI 10.1109/2945.675649
   Kockara S, 2007, IEEE SYS MAN CYBERN, P4046, DOI 10.1109/ICSMC.2007.4414258
   Kolowski JT, 1998, THESIS STATE U NEW Y
   O'Sullivan C., 1999, PROC SPRING C COMPUT, P83
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Reynolds C.W., 2006, SIGGRAPH symposium on Videogames, P113, DOI [DOI 10.1145/1183316.1183333, 10.1145/1183316.1183333]
   Stuvel SA, 2013, MOT GAM 2013 DUBL IR
   van Basten BJH, 2011, P GRAPHICS INTERFACE
   van den Bergen G, 2004, COLLISION DETECTION
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   Vigueras G, 2010, APPL SOFT COMPUT, V10, P225, DOI 10.1016/j.asoc.2009.07.004
NR 24
TC 3
Z9 5
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 333
EP 342
DI 10.1002/cav.1592
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300014
DA 2024-07-18
ER

PT J
AU Zhou, LY
   Shang, LF
   Shum, HPH
   Leung, H
AF Zhou, Liuyang
   Shang, Lifeng
   Shum, Hubert P. H.
   Leung, Howard
TI Human motion variation synthesis with multivariate Gaussian processes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human motion variation; human motion synthesis; semiparametric latent
   factor model; computer animation
AB Human motion variation synthesis is important for crowd simulation and interactive applications to enhance synthesis quality. In this paper, we propose a novel generative probabilistic model to synthesize variations of human motion. Our key idea is to model the conditional distribution of each joint via a multivariate Gaussian process model, namely semiparametric latent factor model (SLFM). SLFM can effectively model the correlations between degrees of freedom (DOFs) of joints rather than dealing with each DOF separately as implemented in existing methods. A detailed evaluation is performed to show that the proposed approach can effectively synthesize variations of different types of motions. Motions generated by our method show a richer variation compared with existing ones. Finally, our user study shows that the synthesized motion has a similar level of naturalness to captured human motions. Our method is best applied in computer games and animations to introduce motion variations. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Zhou, Liuyang; Leung, Howard] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Shang, Lifeng] Noahs Ark Lab, Huawei, Hong Kong, Peoples R China.
   [Shum, Hubert P. H.] Northumbria Univ, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
C3 City University of Hong Kong; Huawei Technologies; Northumbria
   University
RP Zhou, LY (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
EM liuyang.zhou@my.cityu.edu.hk
RI Shum, Hubert P. H./E-8060-2015
OI Shum, Hubert P. H./0000-0001-5651-6039; LEUNG, Wing Ho
   Howard/0000-0002-2633-2965
FU City University of Hong Kong [7004045]
FX The work described in this paper was supported by a grant from City
   University of Hong Kong (Project No. 7004045).
CR [Anonymous], 2007, P 24 INT C MACHINE L, DOI DOI 10.1145/1273496.1273619
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Deng LQ, 2012, COMPUT GRAPH FORUM, V31, P202, DOI 10.1111/j.1467-8659.2011.02095.x
   Feng Andrew, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P232, DOI 10.1007/978-3-642-34710-8_22
   Grassia F. S., 1998, J. Graph. Tools, V6, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Harris CM, 1998, NATURE, V394, P780, DOI 10.1038/29528
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Ikemoto L, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477927
   Kim Y., 2012, Proceedings of ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P165
   Komura T, 2005, COMPUT ANIMAT VIRT W, V16, P213, DOI 10.1002/cav.101
   Kovar Lucas., 2002, SCA 2002: Proceedings of the 2002 ACM SIG-GRAPH/Eurographics Symposium on Computer Animation, P97
   Lau M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618517
   Lawrence ND, 2007, Proceedings of the 24th international conference on machine learning, P481, DOI DOI 10.1145/1273496.1273557
   Lawrence NeilD., 2004, NIPS
   Ma W., 2010, P ACM SIGGRAPH EUR S, P21
   Ma Xiaohan., 2009, Proceedings of SCA 2009, P123
   McDonnell R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360625
   Miller Thomas E., 1986, BIOMETR J
   Min J., 2010, P 2010 ACM SIGGRAPH, DOI [10.1145/1730804.1730811, DOI 10.1145/1730804.1730811]
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Muller M., 2007, TECHNICAL REPORTS U
   Oshita M, 2008, COMPUT GRAPH FORUM, V27, P1909, DOI 10.1111/j.1467-8659.2008.01339.x
   PERLIN K, 1995, IEEE T VIS COMPUT GR, V1, P5, DOI 10.1109/2945.468392
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Shang L, 2013, APPROXIMATE INFERENC
   Teh Y., 2005, PMLR, P333
   Urtasun R, COMPUTER GRAPHICS FO, V23, P799
   Wang J., 2005, NIPS '05, V18, P1441
   Wei XL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966398
NR 31
TC 5
Z9 5
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 303
EP 311
DI 10.1002/cav.1599
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300011
DA 2024-07-18
ER

PT J
AU Wu, HY
   Chen, XW
   Yang, MX
   Fang, ZH
AF Wu, Hongyu
   Chen, Xiaowu
   Yang, Mengxia
   Fang, Zhihong
TI Facial performance illumination transfer from a single video using
   interpolation in non-skin region
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE illumination transfer; facial performance; single video; propagation;
   interpolation
ID IMAGE
AB This paper proposes a novel video-based method to transfer the illumination from a single reference facial performance video to a target one taken under nearly uniform illumination. We first filter the key frames of the reference and the target face videos with an edge-preserving filter. Then, the illumination component of reference key frame is extracted through dividing the filtered reference key frames by the corresponding filtered target key frames in skin region. The differences in non-skin region caused by different expressions between the reference and target face may bring about artifacts. Therefore, we interpolate the illumination component of the non-skin region by that of the surrounded skin region to ensure the spatial smoothness and consistency. After that, the illumination components of key frames are propagated to non-key frames to ensure the temporal consistency between the two adjacent frames. We obtain convincing results by transferring the illumination effects of a single reference facial performance video to a target one with the spatial and temporal consistencies preserved. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Wu, Hongyu; Chen, Xiaowu; Yang, Mengxia; Fang, Zhihong] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Sch Comp Sci & Engn, Beijing, Peoples R China.
C3 Beihang University
RP Chen, XW (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Sch Comp Sci & Engn, Beijing, Peoples R China.
EM chen@buaa.edu.cn
FU NSFC [60933006]; 863 Program [2012AA011504]; RD Program [2012BAH07B01];
   ITER [2012GB102008]
FX We would like to thank the anonymous reviewers for their help in
   improving the paper. This work was partially supported by NSFC
   (60933006), 863 Program (2012AA011504), R&D Program (2012BAH07B01), and
   ITER (2012GB102008).
CR Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Chen JS, 2010, LECT NOTES COMPUT SC, V6314, P44, DOI 10.1007/978-3-642-15561-1_4
   Chen XW, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366151
   Chen XW, 2012, COMPUT GRAPH FORUM, V31, P1425, DOI 10.1111/j.1467-8659.2012.03138.x
   Chen XW, 2011, PROC CVPR IEEE, P281, DOI 10.1109/CVPR.2011.5995473
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Lee S, 1996, IEEE T VIS COMPUT GR, V2, P337, DOI 10.1109/2945.556502
   Li Q, 2010, VISUAL COMPUT, V26, P41, DOI 10.1007/s00371-009-0375-8
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Peers P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239503
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Yin WT, 2005, LECT NOTES COMPUT SC, V3752, P73
NR 15
TC 4
Z9 4
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 255
EP 263
DI 10.1002/cav.1519
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500013
DA 2024-07-18
ER

PT J
AU Bae, M
   Kim, J
   Kim, YJ
AF Bae, Myungsoo
   Kim, Jinwook
   Kim, Young J.
TI User-guided volumetric approximation using swept sphere volumes for
   physically based animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE volumetric approximation; swept sphere volumes; mesh segmentation
ID MEDIAL-AXIS; MESH
AB We present an efficient, user-guided volumetric approximation algorithm, specifically designed for physically based animation. Our method combines automatic and interactive segmentation methods to give users an intuitive and easy way to approximate 3D meshes. Our approach first constructs the simplified medial axis transform of the input mesh object, and segments the medial axis into parts in terms of swept sphere volumes using a region growing method. Then, we decompose the object surface into regions based on the mapping between the segmented medial axis and the object surface. Each segmented region is approximated with a swept sphere volume. These decomposed surface regions can be interactively refined further by splitting and/or merging using a sketch-based input. Experimental results show that our approach produces good volumetric approximation results for different types of object shapes. Moreover, rigid-body dynamics simulation based on our volumetric approximation provides a visually pleasing result. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Kim, Young J.] Ewha Womans Univ, Comp Sci & Engn Dept, Seoul, South Korea.
   [Kim, Jinwook] Korea Inst Sci & Technol, Seoul, South Korea.
C3 Ewha Womans University; Korea Institute of Science & Technology (KIST)
RP Kim, YJ (corresponding author), Ewha Womans Univ, Comp Sci & Engn Dept, Seoul, South Korea.
EM kimy@ewha.ac.kr
OI Kim, Young J./0000-0003-2159-4832
FU IT R&D program of MKE/MCST/KOCCA [KI001818]; NRF in Korea
   [NRF-2011-013-D00112]
FX This research was supported in part by IT R&D program of MKE/MCST/KOCCA
   (KI001818) and NRF in Korea (NRF-2011-013-D00112).
CR Amenta Nina, 2001, P 6 ACM S SOL MOD AP
   [Anonymous], 2002, P 7 ACM S SOLID MODE, DOI DOI 10.1145/566282.566333
   Attene M, 2006, SMI06 P IEEE INT C S
   Bradshaw G, 2004, ACM T GRAPHIC, V23, P1, DOI 10.1145/966131.966132
   Chang B, 2008, COMPUT GRAPH FORUM, V27, P799, DOI 10.1111/j.1467-8659.2008.01210.x
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Cheng ZQ, 2007, LECT NOTES COMPUT SC, V4842, P671
   Chevalier L., 2003, J WINTER SCH COMPUTE
   Choi HI, 1997, PAC J MATH, V181, P57, DOI 10.2140/pjm.1997.181.57
   Coeurjolly D, 2007, IEEE T PATTERN ANAL, V29, P437, DOI 10.1109/TPAMI.2007.54
   Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0
   Du H., 2004, SM 04, P25
   Foskey M., 2003, J. Comput. Inf. Sci. Eng., V3, P274, DOI DOI 10.1145/781606.781623
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Huebner K, 2008, IEEE INT CONF ROBOT, P1628, DOI 10.1109/ROBOT.2008.4543434
   Ji ZP, 2006, COMPUT GRAPH FORUM, V25, P283, DOI 10.1111/j.1467-8659.2006.00947.x
   Katz S, 2005, VISUAL COMPUT, V21, P649, DOI 10.1007/s00371-005-0344-9
   Larsen E., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3719, DOI 10.1109/ROBOT.2000.845311
   Lee Y, 2005, COMPUT AIDED GEOM D, V22, P444, DOI 10.1016/j.cagd.2005.04.002
   Leonardis A, 1997, IEEE T PATTERN ANAL, V19, P1289, DOI 10.1109/34.632988
   Lien J. M., 2007, P ACM S SOL PHYS MOD, P121, DOI [10.1145/1236246.1236265, DOI 10.1145/1236246.1236265]
   Lin M.C., 1998, PROC IMA C MATH SURF, P37
   Liu Shengjun, 2007, P 2007 ACM S SOLID P, P303
   Mademlis A, 2008, IEEE T MULTIMEDIA, V10, P819, DOI 10.1109/TMM.2008.922790
   Manzanera A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P337, DOI 10.1109/ICCV.1999.791239
   Meng M, 2011, COMPUT ANIMAT VIRT W, V22, P334, DOI 10.1002/cav.422
   Mirtich B, 1994, P WORKSH ALG FDN ROB
   Poppinga J, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3378, DOI 10.1109/IROS.2008.4650729
   Raab R., 2004, International Journal of Shape Modeling, V10, P1, DOI 10.1142/S0218654304000584
   Reniers D, 2008, VISUAL COMPUT, V24, P383, DOI 10.1007/s00371-008-0220-5
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Stolpner S, 2012, IEEE T PATTERN ANAL, V34, P1234, DOI 10.1109/TPAMI.2011.254
   Wu Huai-Yu., 2007, COMPUTER GRAPHICS IN
   Xia H, 2009, PROCEEDINGS OF THE 18TH INTERNATIONAL MESHING ROUNDTABLE, P247, DOI 10.1007/978-3-642-04319-2_15
   Zha HB, 1998, INT C PATT RECOG, P658, DOI 10.1109/ICPR.1998.711230
NR 35
TC 5
Z9 5
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 385
EP 394
DI 10.1002/cav.1461
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100025
DA 2024-07-18
ER

PT J
AU Sun, LB
   Shoulson, A
   Huang, PF
   Nelson, N
   Qin, WH
   Nenkova, A
   Badler, NI
AF Sun, Libo
   Shoulson, Alexander
   Huang, Pengfei
   Nelson, Nicole
   Qin, Wenhu
   Nenkova, Ani
   Badler, Norman I.
TI Animating synthetic dyadic conversations with variations based on
   context and agent attributes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE conversation model; agent attributes; smart event; behavior trees; crowd
   simulation
ID SIMULATION; MODEL
AB Conversations between two people are ubiquitous in many inhabited contexts. The kinds of conversations that occur depend on several factors, including the time, the location of the participating agents, the spatial relationship between the agents, and the type of conversation in which they are engaged. The statistical distribution of dyadic conversations among a population of agents will therefore depend on these factors. In addition, the conversation types, flow, and duration will depend on agent attributes such as interpersonal relationships, emotional state, personal priorities, and socio-cultural proxemics. We present a framework for distributing conversations among virtual embodied agents in a real-time simulation. To avoid generating actual language dialogues, we express variations in the conversational flow by using behavior trees implementing a set of conversation archetypes. The flow of these behavior trees depends in part on the agents' attributes and progresses based on parametrically estimated transitional probabilities. With the participating agents' state, a smart event model steers the interchange to different possible outcomes as it executes. Example behavior trees are developed for two conversation archetypes: buyerseller negotiations and simple askinganswering; the model can be readily extended to others. Because the conversation archetype is known to participating agents, they can animate their gestures appropriate to their conversational state. The resulting animated conversations demonstrate reasonable variety and variability within the environmental context. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Shoulson, Alexander; Huang, Pengfei; Nelson, Nicole; Nenkova, Ani; Badler, Norman I.] Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA.
   [Sun, Libo; Qin, Wenhu] Southeast Univ, Sch Instrument Sci & Engn, Nanjing, Jiangsu, Peoples R China.
C3 University of Pennsylvania; Southeast University - China
RP Badler, NI (corresponding author), Univ Penn, Dept Comp & Informat Sci, 200 S 33Rd St, Philadelphia, PA 19104 USA.
EM badler@seas.upenn.edu
FU Jiangsu Province Development Foundation [BE2009662]; Applied Basic
   Research and Cutting-Edge Technology Research Scheme of Tianjin
   [08JCYBJC14300]; US Army Research Laboratory [W911NF10-2-0016]
FX The authors wish to acknowledge contributions to the marketplace scene
   by Alice Yang, Kaitlin Reese, Daniel Garcia, and Robert Mead. This
   research has been supported by the Jiangsu Province Development
   Foundation under Grant No. BE2009662 and the Applied Basic Research and
   Cutting-Edge Technology Research Scheme of Tianjin under Grant No.
   08JCYBJC14300. The research reported in this document was performed in
   connection with Contract Number W911NF10-2-0016 with the US Army
   Research Laboratory. The views and conclusions contained in this
   document are those of the authors and should not be interpreted as
   presenting the official policies or position, either expressed or
   implied, of the US Army Research Laboratory or the US Government unless
   so designated by other authorized documents. Citation of manufacturers
   or trade names does not constitute an official endorsement or approval
   of the use thereof. The US Government is authorized to reproduce and
   distribute reprints for Government purposes notwithstanding any
   copyright notation herein.
CR Allbeck JM, 2010, LECT NOTES ARTIF INT, V6356, P1, DOI 10.1007/978-3-642-15892-6_1
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Cassell J., 2000, Embodied Conversational Agents
   Devillers F, 2002, J VISUAL COMP ANIMAT, V13, P263, DOI 10.1002/vis.295
   Ennis C, 2010, THESIS TRINITY COLL
   Ennis C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778828
   HOSTETLER TR, 2002, THESIS U IOWA
   Jan D, 2005, LECT NOTES ARTIF INT, V3661, P65
   Jan D, 2007, AUTON AGENT MULTI-AG, P47
   Jan D, 2007, LECT NOTES ARTIF INT, V4722, P45
   Kallmann M, 2006, HDB VIRTUAL HUMANS, P303
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Levine S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618518
   Maim Jonathan., 2007, P 8 INT S VIRTUAL RE
   McDonnell R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360625
   Moulin B, 2002, ESSAYS SPEECH ACT TH
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   O'Sullivan C, 2002, COMPUT GRAPH FORUM, V21, P733, DOI 10.1111/1467-8659.00631
   Pedica C, 2008, LECT NOTES COMPUT SC, V5208, P104
   Pelechano Nuria., 2008, Virtual Crowds: Methods, Simulation, and Control
   Poggi I, 1998, SPEECH COMMUN, V26, P5, DOI 10.1016/S0167-6393(98)00047-8
   Prendinger H, 2011, IEEE T VIS COMPUT GR, V17, P655, DOI 10.1109/TVCG.2010.66
   Schuerman M, 2010, COMPUTER ANIMATION V, V21, P267
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   Shoulson A, 2011, SPRINGER LNCS, P7069
   Stocker C, 2010, LECT NOTES ARTIF INT, V6356, P15, DOI 10.1007/978-3-642-15892-6_2
   Thiebaux Marcus., 2008, P AAMAS 08, P151
   Thórisson KR, 2008, LECT NOTES COMPUT SC, V5208, P131
   Vilhjálmsson H, 2007, LECT NOTES ARTIF INT, V4722, P99
   Yeh H., 2008, P ACM SIGGRAPH EUR S
   Yu QX, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P119
NR 32
TC 9
Z9 12
U1 0
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2012
VL 23
IS 1
BP 17
EP 32
DI 10.1002/cav.1421
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 897SH
UT WOS:000300675800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Donikian, S
   Petta, P
AF Donikian, Stephane
   Petta, Paolo
TI A survey of research work in computer science and cognitive science
   dedicated to the modeling of reactive human behaviors
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE behavioral animation; human cognition; virtual humans
ID ACTION-SELECTION; MINDS
AB Modeling believable autonomous agents needs to take into account many different aspects from very different disciplines, ranging from cognitive psychology to mechanics. In this paper, we focus on research work dedicated to the modeling of human decision in a reactive way, a domain in-between the biomechanical motion control of the activity and the rational and social background which motivates and shapes the execution of such activities. We cover models of reactive human behaviors introduced in computer science and cognitive science, assessing and comparing them from the application-oriented perspective of modeling credible real-time virtual anthropomorphic actors. Copyright (C) 2010 JohnWiley & Sons, Ltd.
C1 [Petta, Paolo] Austrian Res Inst Artificial Intelligence, OFAI, A-1010 Vienna, Austria.
   [Donikian, Stephane] CNRS, F-75700 Paris, France.
   [Donikian, Stephane] Golaem SA, F-35700 Rennes, France.
C3 Centre National de la Recherche Scientifique (CNRS)
RP Donikian, S (corresponding author), Golaem SA, 80 Ave Buttes Coesmes, F-35700 Rennes, France.
EM stephane.donikian@golaem.com
FU European Commission [FP7-ICT-231824]; Austrian Federal Ministry for
   Science and Research; Austrian Federal Ministry for Transport,
   Innovation and Technology
FX This work has been funded in part by the European Commission under grant
   agreement IRIS (FP7-ICT-231824). The Austrian Research Institute for
   Artificial Intelligence is supported by the Austrian Federal Ministry
   for Science and Research and the Austrian Federal Ministry for
   Transport, Innovation and Technology.
CR Adolphs R, 2006, BRAIN RES, V1079, P25, DOI 10.1016/j.brainres.2005.12.127
   Agre P, 1997, J ARTIF INTELL RES, V6, P111, DOI 10.1613/jair.342
   AHMAD O, 1994, C AI PLANN SIM HIGH
   [Anonymous], DESIGNING AUTONOMOUS
   [Anonymous], 2001, THESIS MIT
   [Anonymous], 2009, SOCIAL COGNITION SOC
   [Anonymous], 1995, Foundational Issues in Artificial Intelligence and Cognitive Science: Impasse and Solution
   [Anonymous], 1987, Proceedings of the 6th National Conference on Artificial Intelligence, San Mateo, CA: Morgan Kaufmann
   BADLER NI, 1997, CREATING PERSONALITI, V1195, P43
   BERTHOZ A, 2006, PHYSIOL ACTION PHENO
   Berthoz A., 2006, Emotion and Reason: The Cognitive Neuroscience of Decision Making
   BLUMBERG B, 1994, COM ADAP SY, P108
   BOOTH M, 1993, 4 EUR WORKSH AN SIM, P103
   Brooks R. A., 1990, Robotics and Autonomous Systems, V6, P3, DOI 10.1016/S0921-8890(05)80025-9
   Brooks RodneyA., 1985, A robust layered control system for a mobile robot
   Bryson JJ, 2007, ADAPT BEHAV, V15, P5, DOI 10.1177/1059712306076247
   Chernova S, 2007, ADAPT BEHAV, V15, P199, DOI 10.1177/1059712306076255
   Clancey W., 2002, Cognitive Systems Research, V3, P471, DOI 10.1016/S1389-0417(02)00053-0
   Clancey WilliamJ., 1997, Situated Cognition: On Human Knowledge and Computer Representations
   CODERRE B, 1989, P INT WORKSH SYNTH S, V6, P407
   De Giacomo G., 2009, MULTIAGENT PROGRAMMI, P31, DOI DOI 10.1007/978-0-387-89299-3_2
   DECUGIS V, 1998, AUTONOMOUS AGENTS 98, P354
   Dewey J., 1896, PSYCHOL REV, V3, P357, DOI 10.1037/h0070405
   DONIKIAN S, 1995, EUR WORKSH PROGR PAR, P137
   Donikian S., 2001, AGENTS '01, P401
   DONIKIAN S, 1999, LECT NOTES CONTR INF, V243, P321
   Dreyfus HL, 2007, PHILOS PSYCHOL, V20, P247, DOI 10.1080/09515080701239510
   FUNGE J, 1998, THESIS U TORONTO
   Gibson J. J., 2014, The ecological approach to visual perception, Vclassic
   HALPERIN JRP, 1995, COMP APPROACHES COGN
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Hexmoor H, 1997, J EXP THEOR ARTIF IN, V9, P145, DOI 10.1080/095281397147031
   Hirose N., 2002, COGN SYST RES, V3, P289, DOI DOI 10.1016/S1389-0417(02)00044-X
   HORSWILL I, 1995, ARTIF INTELL, V73, P1, DOI 10.1016/0004-3702(94)00057-8
   Horswill I., 2009, International Conference on Foundations of Digital Games, P91
   Horswill ID, 2009, IEEE T COMP INTEL AI, V1, P39, DOI 10.1109/TCIAIG.2009.2019631
   Keijzer F., 2002, COGNITIVE SYSTEMS RE, V3, P275, DOI [10.1016/S1389-0417(02)00043-8, DOI 10.1016/S1389-0417(02)00043-8]
   Kuhl J, 1984, Prog Exp Pers Res, V13, P99
   Kunde Wilfried, 2007, Cogn Process, V8, P71, DOI 10.1007/s10339-007-0162-2
   Laird JE, 2008, FRONT ARTIF INTEL AP, V171, P224
   LAMARCHE F, 2002, AUTONOMOUS AGENTS MU
   Le Hy R, 2004, ROBOT AUTON SYST, V47, P177, DOI 10.1016/j.robot.2004.03.012
   LORD RG, 1994, APPL PSYCHOL-INT REV, V43, P335, DOI 10.1111/j.1464-0597.1994.tb00828.x
   MALLOT HA, 1999, KOGNITIONSWISSENSCHA, V8, P40
   Mateas M, 2002, IEEE INTELL SYST, V17, P39, DOI 10.1109/MIS.2002.1024751
   Mateas M, 2004, COG TECH, P135
   MATEAS M, 2002, CMUCS02198 SCH COMP
   McCarthy J., 1969, Machine Intelligence, VVol. 4, P463
   McFarland D., 1993, Intelligent behavior in animals and robots
   Newell A., 1994, UNIFIED THEORIES COG
   NGO JT, 1993, COMPUTER GRAPHICS SI, V27, P343
   Nilsson NJ, 1993, J ARTIF INTELL RES, V1, P139, DOI 10.1613/jair.30
   Noser H, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P189, DOI 10.1109/CGI.1997.601300
   Pfeifer R., 1994, Proceedings. From Perception to Action Conference, P1, DOI 10.1109/FPA.1994.636076
   RANK S, 2010, THESIS VIENNA U TECH
   Reiter R., 2001, Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   RHODES BJ, 1996, THESIS MIT
   ROSENSCHEIN SJ, 2001, ARTIF INTELL, V73, P149
   Russell S., 2016, Artificial intelligence a modern approach
   Scherl RB, 2003, ARTIF INTELL, V144, P1, DOI 10.1016/S0004-3702(02)00365-X
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038
   SHALLICE T, 1982, PHILOS T R SOC B, V298, P199, DOI 10.1098/rstb.1982.0082
   SIERHUIS M, 2001, THESIS U AMSTERDAM
   Sun R, 2008, CAMB HANDB PSYCHOL, P1, DOI 10.1017/CBO9780511816772
   TERZOPOULOS D, 2008, AAMAS 2008, V1, P17
   THALMANN NM, 1990, J VISUAL COMP ANIMAT, V1, P18
   Thomas G, 2000, COMP ANIM CONF PROC, P112, DOI 10.1109/CA.2000.889057
   TRAVERS M, 1988, ARTIF LIFE, P421
   Tu X., 1994, Computer Graphics, V28, P43
   Van de Panne M., 1993, Computer Graphics Proceedings, P335, DOI 10.1145/166117.166159
   Vernon D, 2007, IEEE T EVOLUT COMPUT, V11, P151, DOI 10.1109/TEVC.2006.890274
   Vernon D, 2007, LECT NOTES ARTIF INT, V4850, P53
   VONUEXKULL J, 1956, STREIFZUGE DUCH UMWE
   Warren W.H., 1995, PERCEPTION SPACE MOT, P263, DOI [DOI 10.1016/B978-012240530-3/50010-9, 10.1016/B978-012240530-3/50010-9]
   WIHELMS J, 1989, GRAPHICS INTERFACE, P1
   YU Q, 2007, EUROGRAPHICS ACM SIG, P119
   Ziemke T., 2002, Cognitive Systems Research, V3, P271, DOI [10.1016/S1389- 0417(02)00068-2, DOI 10.1016/S1389-0417(02)00068-2]
NR 78
TC 2
Z9 2
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2011
VL 22
IS 5
BP 445
EP 455
DI 10.1002/cav.375
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 856HY
UT WOS:000297631000005
DA 2024-07-18
ER

PT J
AU Ho, ESL
   Komura, T
AF Ho, Edmond S. L.
   Komura, Taku
TI A finite state machine based on topology coordinates for wrestling games
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character animation; motion capture; interactive games
ID MOTIONS
AB This paper proposes a new framework to simulate the real-time attack-and-defense interactions by two virtual wrestlers in 3D computer games. The characters are controlled individually by two different players-one player controls the attacker and the other controls the defender. A finite state machine of attacks and defenses based on topology coordinates is precomputed and used to control the virtual wrestlers during the game play. As the states are represented by topology coordinates, which is an abstract representation for the spatial relationship of the bodies, the players have much more degree of freedom to control the virtual characters even during attacks and defenses. Experimental results show the methodology can simulate realistic competitive interactions of wrestling in real time, which is difficult by previous methods. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Ho, Edmond S. L.; Komura, Taku] Univ Edinburgh, Sch Informat, Inst Percept Act & Behav, Edinburgh, Midlothian, Scotland.
C3 University of Edinburgh
RP Ho, ESL (corresponding author), Univ Edinburgh, Sch Informat, Inst Percept Act & Behav, 10 Crichton St, Edinburgh, Midlothian, Scotland.
EM S.L.Ho@sms.ed.ac.uk
RI Ho, Edmond S. L./JDW-1835-2023
OI Ho, Edmond S. L./0000-0001-5862-106X
CR Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Ho ESL, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P427, DOI 10.1109/PG.2007.54
   Ho ESL, 2009, COMPUT GRAPH FORUM, V28, P299, DOI 10.1111/j.1467-8659.2009.01369.x
   Ho ESL, 2009, IEEE T VIS COMPUT GR, V15, P481, DOI 10.1109/TVCG.2008.199
   *ILOG INC, 2005, ILOG CPLEX 9 1 US RE
   JAKOBSEN T, 2001, GAM DEV C, P383
   Kagami S, 2001, ALGORITHMIC AND COMPUTATIONAL ROBOTICS: NEW DIRECTIONS, P329
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Kulpa R, 2005, COMPUT GRAPH FORUM, V24, P343, DOI 10.1111/j.1467-8659.2005.00859.x
   Lee J, 1999, COMP GRAPH, P39
   Lee Jehee., 2004, SCA 2004: Proceedings of the 2004 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P79
   Liu Karen, 2006, P 2006 ACM SIGGRAPHE, P215
   NAKAMURA Y, 1986, J DYN SYST-T ASME, V108, P163, DOI 10.1115/1.3143764
   *NINT CO LTD, 1986, PROWR
   Phillips C. B., 1990, Computer Graphics, V24, P245, DOI 10.1145/91394.91452
   POHL WF, 1968, J MATH MECH, V17, P975
   Rose CF, 2001, COMPUT GRAPH FORUM, V20, pC239
   *SCULPT SOFTW INC, 1992, WWF SUP WRESTLEMANIA
   Shin HJ, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P194
   SHUM HPH, 2007, P ACM VIRT REAL SOFT, P65
   SHUM HPH, 2008, ACM SIGGRAPH S INT 3, P131
   *THQ INC, WWE SMACKD RAW
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
   WHITNEY DE, 1969, IEEE T MAN MACHINE, VMM10, P47, DOI 10.1109/TMMS.1969.299896
   Yamane K, 2003, IEEE T VIS COMPUT GR, V9, P352, DOI 10.1109/TVCG.2003.1207443
   Yamane K., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P688, DOI 10.1109/ROBOT.2000.844132
   ZHAO JM, 1994, ACM T GRAPHIC, V13, P313, DOI 10.1145/195826.195827
NR 27
TC 9
Z9 10
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2011
VL 22
IS 5
BP 435
EP 443
DI 10.1002/cav.376
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856HY
UT WOS:000297631000004
DA 2024-07-18
ER

PT J
AU Zhao, C
   Sun, HQ
   Qin, KH
AF Zhao, Chong
   Sun, Hanqiu
   Qin, Kaihuai
TI Efficient wavelet-based geometry compression
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE matrix-valued subdivision; wavelets; lifting scheme; geometry
   compression
ID SUBDIVISION-SURFACE WAVELETS; SCHEME; CONSTRUCTION
AB In recent years, some wavelets constructed via local lifting have been proposed to accelerate the compression of geometric models. Unlike the traditional wavelet-based compression with global optimisation, their compression ratios are still not sufficient, particularly at low-bit rates. In this paper, we present a novel efficient wavelet-based compression approach using the matrix-valued Loop subdivision on triangular meshes. Based on the local lifting scheme, the computation of the wavelet transform is highly efficient and requires low memory usage. With the shape controls introduced by the matrix-valued subdivision, our approach can greatly improve the fitting quality of surfaces while keeping the efficient data compression. The experimental results showed that our wavelet transform had better performance on balancing the efficiency and compression ratios. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Zhao, Chong; Sun, Hanqiu] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   [Qin, Kaihuai] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 Chinese University of Hong Kong; Tsinghua University
RP Zhao, C (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
EM czhao@cse.cuhk.edu.hk; hanqiu@cse.cuhk.edu.hk
CR Bertram M, 2004, COMPUTING, V72, P29, DOI 10.1007/s00607-003-0044-0
   Bertram M, 2004, IEEE T VIS COMPUT GR, V10, P326, DOI 10.1109/TVCG.2004.1272731
   Bertram M, 2000, IEEE VISUAL, P389, DOI 10.1109/VISUAL.2000.885720
   Chui CK, 2008, COMPUT AIDED GEOM D, V25, P96, DOI 10.1016/j.cagd.2007.05.004
   Chui CK, 2005, APPL COMPUT HARMON A, V19, P303, DOI 10.1016/j.acha.2005.03.004
   Chui CK, 2003, APPL COMPUT HARMON A, V15, P147, DOI 10.1016/S1063-5203(03)00062-9
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   Li DG, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P25
   Lounsbery M, 1997, ACM T GRAPHIC, V16, P34, DOI 10.1145/237748.237750
   Peyré G, 2005, ACM T GRAPHIC, V24, P601, DOI 10.1145/1073204.1073236
   Samavati FF, 2002, COMPUT GRAPH FORUM, V21, P121, DOI 10.1111/1467-8659.00572
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Valette S, 2004, IEEE T VIS COMPUT GR, V10, P123, DOI 10.1109/TVCG.2004.1260764
   Wang H, 2009, COMPUT GRAPH FORUM, V28, P1572, DOI 10.1111/j.1467-8659.2009.01349.x
   Wang HW, 2007, IEEE T VIS COMPUT GR, V13, P914, DOI 10.1109/TVCG.2007.1031
   Wang HW, 2006, VISUAL COMPUT, V22, P874, DOI 10.1007/s00371-006-0074-7
   Wang HW, 2008, COMPUT AIDED GEOM D, V25, P816, DOI 10.1016/j.cagd.2007.11.002
   Zhang H., 2009, Computer Graphics Forum, V27, P1815
NR 19
TC 5
Z9 7
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 307
EP 315
DI 10.1002/cav.410
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700027
DA 2024-07-18
ER

PT J
AU Schuerman, M
   Singh, S
   Kapadia, M
   Faloutsos, P
AF Schuerman, Matthew
   Singh, Shawn
   Kapadia, Mubbasir
   Faloutsos, Petros
TI Situation agents: agent-based externalized steering logic
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE crowd simulation; steering; group behaviors; situation agents
AB We present a simple and intuitive method for encapsulating part of agents' steering and coordinating abilities into a new class of agents, called situation agents. Situation agents have all the abilities of typical agents. In addition, they can influence the steering decisions of any agent, including other situation agents, within their sphere of influence. Encapsulating steering logic into moving agents is a powerful abstraction which provides more flexibility and efficiency than traditional informed environment approaches, and works with many of the current steering methodologies. We demonstrate our proposed approach in a number of challenging scenarios. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Schuerman, Matthew; Faloutsos, Petros] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.
   [Faloutsos, Petros] Univ Calif Los Angeles, Dept Comp Sci, Graph Lab, Los Angeles, CA 90024 USA.
C3 University of California System; University of California Los Angeles;
   University of California System; University of California Los Angeles
RP Schuerman, M (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.
EM mschuerm@cs.ucla.edu
CR [Anonymous], SCA 09 P 2009 ACM SI
   [Anonymous], SCA 05 P 2005 ACM SI
   Badler N, 2008, SYNTHESIS LECT COMPU
   FARENC N, 1998, P ECAI WORKSH INT US
   Fiorini P, 1998, INT J ROBOT RES, V17, P760, DOI 10.1177/027836499801700706
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   KAMPHUIS A, 2003, P IEEE ICRA, P3815
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   SHAO W, 2005, SCA 05, P19
   SINGH S, 2009, STEERSUITE 1 02
   Sung M, 2004, COMPUT GRAPH FORUM, V23, P519, DOI 10.1111/j.1467-8659.2004.00783.x
   Tecchia Franco., 2001, GTEC2001, P17
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   VANDENBERG J, 2009, RVO LIB 1 1
   YEH H, 2008, SCA, P39
NR 19
TC 21
Z9 26
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 267
EP 276
DI 10.1002/cav.367
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400014
DA 2024-07-18
ER

PT J
AU Zhang, J
   Ong, SK
   Nee, AYC
AF Zhang, J.
   Ong, S. K.
   Nee, A. Y. C.
TI Development of an AR system achieving <i>in situ</i> machining
   simulation on a 3-axis CNC machine
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Virtual-Reality Continuum and its
   Applications in Industry
CY DEC 08-09, 2008
CL Singapore, SINGAPORE
SP ACM SIGGRAPH
DE augmented reality; dexel structure; machining force estimation;
   machining simulation
AB This paper presents an implementation of machining simulation in a real machining environment applying Augmented Reality (AR) technology. This in situ machining simulation system allows a machinist to analyze the simulation process, adjust the machining parameters, and observe the results in real-time in a real machining environment. Such a system is useful for machinists and trainees during the trial and learning stages, allowing them to experiment with different machining parameters on a real machine without having to worry about possibilities of machine and tool breakages. Three research aspects, namely, the tracking and registration module, the physical simulation module, and the implementation and performance of these proposed methodologies are discussed in details in this paper. Experiments were conducted on a real 3-axis CNC machine to validate and evaluate the performance of the system and the feedback from a survey carried out with the experiments is very positive. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Ong, S. K.] Natl Univ Singapore, Fac Engn, Dept Mech Engn, Singapore 117576, Singapore.
C3 National University of Singapore
RP Ong, SK (corresponding author), Natl Univ Singapore, Fac Engn, Dept Mech Engn, 9 Engn Dr 1, Singapore 117576, Singapore.
EM mpeongsk@nus.edu.sg
RI Zhang, Jie/HGU-1168-2022; Nee, Andrew, Y.C./C-9974-2009; Ong,
   SK/AAP-2918-2021
OI Ong, SK/0000-0002-9569-3350; Zhang, Jie/0000-0001-5345-336X; Nee,
   Andrew/0000-0002-1029-9988
CR Altintas Y, 2005, CIRP ANN-MANUF TECHN, V54, P651
   Aron M, 2007, COMPUT ANIMAT VIRT W, V18, P57, DOI 10.1002/cav.161
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   CHAPPEL IT, 1983, COMPUT AIDED DESIGN, V15, P156, DOI 10.1016/0010-4485(83)90082-9
   Choi B.K., 1998, Sculptured Surface Machining
   CHONG JWS, 2007, INT J VIRTUAL REALIT, V6, P69, DOI DOI 10.1145/1174429.1174470
   HOOK TV, 1986, COMPUTER GRAPHICS, V20, P15
   Huang CP, 2004, VIRTUAL AND AUGMENTED REALITY APPLICATIONS IN MANUFACTURING, P257
   HUANG Y, 1994, P 21 ANN C COMP GRAP, P287, DOI DOI 10.1145/192161.192231
   Jerard R. B., 2001, P 2001 NSF DES MAN I
   KLINE WA, 1982, INT J MACH TOOL MANU, V22, P7, DOI 10.1016/0020-7357(82)90016-6
   Liu SQ, 2006, COMPUT AIDED DESIGN, V38, P378, DOI 10.1016/j.cad.2005.11.003
   Lu CY, 1999, CIRP ANNALS 1999: MANUFACTURING TECHNOLOGY, VOL 48 NO 2 1999, P471
   Olwal A, 2008, P SPIE 2008 EL IM EN, V6804
   Ong SK, 2007, CIRP ANN-MANUF TECHN, V56, P49, DOI 10.1016/j.cirp.2007.05.014
   PAPAGIANNAKIS P, 2008, COMPUTER ANIMATION V, V19, P3, DOI DOI 10.1002/CAV.V19:1
   Shen Y, 2008, COMPUT AIDED DESIGN, V40, P963, DOI 10.1016/j.cad.2008.07.003
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   SMITH S, 1991, J ENG IND-T ASME, V113, P169, DOI 10.1115/1.2899674
   Yuan ML, 2004, COMPUT ANIMAT VIRT W, V15, P425, DOI 10.1002/cav.46
   YUAN ML, 2005, 2005 SING MIT ALL S, DOI DOI 10.1002/CAV.161
   Zhang J, 2006, 2006 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P33, DOI 10.1109/CW.2006.11
NR 22
TC 11
Z9 12
U1 2
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2010
VL 21
IS 2
SI SI
BP 103
EP 115
DI 10.1002/cav.327
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 586CJ
UT WOS:000276878600005
DA 2024-07-18
ER

PT J
AU Burrell, T
   Arnold, D
   Brooks, S
AF Burrell, Tim
   Arnold, Dirk
   Brooks, Stephen
TI Advected river textures
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE water; texture advection; adaptive simulation; rivers; Navier-Stokes
   equations
ID SIMULATION; FLUID; WATER; BODIES
AB We present a new method for the realistic real-time simulation of rivers. Our solution includes a 2D fluid solver that simulates the flow of a river's surface, an efficient method for adaptively computing 3D flow information and an animated 3D procedural Wave texture that is advected through the fluid via advection particles in order to mimic the highly detailed fluid surfaces that are characteristic of rivers. Our technique that couples animated texture advection with a pseudo-3D fluid simulation produces stable results that are representative of large-scale real-world rivers and suitable for use in real-time applications. Our system surpasses Prior Work on real-time river rendering both with regards to efficiency and visual quality, Which We establish through the rendering of rivers tens of kilometers long. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Arnold, Dirk; Brooks, Stephen] Dalhousie Univ, Fac Comp Sci, Halifax, NS B3H 1W5, Canada.
C3 Dalhousie University
RP Brooks, S (corresponding author), Dalhousie Univ, Fac Comp Sci, 6050 Univ Ave, Halifax, NS B3H 1W5, Canada.
EM sbrooks@cs.dal.ca
OI Arnold, Dirk/0000-0001-5367-6862
CR [Anonymous], GAM DEV C
   BROWN S, 2006, ACM SIGGRAPH 2006 SK, P21
   Carlson M, 2004, ACM T GRAPHIC, V23, P377, DOI 10.1145/1015706.1015733
   CHEN JX, 1995, GRAPH MODEL IM PROC, V57, P107, DOI 10.1006/gmip.1995.1012
   Clavet S., 2005, SCA '05, P219, DOI DOI 10.1145/1073368.1073400
   CORDS H, 2008, INT C CENTR EUR COMP
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster Nick., 1997, P 24 ANN C COMP GRAP, P181
   Fournier A., 1986, Computer Graphics, V20, P75, DOI 10.1145/15886.15894
   GINGOLD R, 1997, SMOOTHED PARTICLE HY, P375
   HOLMBERG N, 2004, GRAPHITE 04, P15
   Irving G, 2006, ACM T GRAPHIC, V25, P805, DOI 10.1145/1141911.1141959
   Kass M., 1990, Computer Graphics, V24, P49, DOI 10.1145/97880.97884
   Kwatra V, 2007, IEEE T VIS COMPUT GR, V13, P939, DOI 10.1109/TVCG.2007.1044
   LEE TG, 1907, ANAT REC, V1, P51
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   LUCY LB, 1977, ASTRON J, V82, P1013, DOI 10.1086/112164
   MAES MM, 2006, GRAPHITE 06, P107
   MASTIN GA, 1987, IEEE COMPUT GRAPH, V7, P16, DOI 10.1109/MCG.1987.276961
   Mei X, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P47, DOI 10.1109/PG.2007.15
   Mitchell JasonL., 2004, REAL TIME SYNTHESIS
   Mould D, 1997, COMPUT GRAPH-UK, V21, P801, DOI 10.1016/S0097-8493(97)00059-9
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Neyret F, 2001, SPRING EUROGRAP, P53
   Neyret F., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P147
   OBRIEN JF, 1995, COMPUTER ANIMATION, V95, P198
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Perlin K.H., 1989, 16 ANN C COMP GRAPH, P253, DOI 10.1145/74333.74359
   Shi SX, 2007, SIMUL MODEL PRACT TH, V15, P635, DOI 10.1016/j.simpat.2007.01.004
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   STAVA O, 2008, ACM SIGGRAPH EUR S C, P30
   Takahashi T, 2003, COMPUT GRAPH FORUM, V22, P391, DOI 10.1111/1467-8659.00686
   TESSENDORF J, 2004, SIGGRAPH COURSE
   TESSENDORF J, 2001, SIGGRAPH COURSE
   THON S, 2001, COMPUT GRAPH FORUM P, V19, P53
   Yuksel C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239550
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 38
TC 3
Z9 5
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 163
EP 173
DI 10.1002/cav.288
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700010
DA 2024-07-18
ER

PT J
AU Sugisaki, E
   Seah, HS
   Tian, F
   Morishima, S
AF Sugisaki, Eiji
   Seah, Hock Soon
   Tian, Feng
   Morishima, Shigeo
TI Interactive shadowing for 2D Anime
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE shadowing; Anime; 2D animation; Shadow Map
AB In this paper, we propose all instant shadow generation technique for 2D animation, especially Japanese Anime. In traditional 2D Anime production, the entire animation including shadows is drawn by hand so that it takes long time to complete. Shadows play all important role in the creation of symbolic visual effects. However shadows are not always drawn due to time constraints and lack of animators especially When the production schedule is tight. To solve this problem, We develop all easy shadowing approach that enables animators to easily create a layer of shadow and its animation based on the character's shapes. Our approach is both instant and intuitive. The only inputs required tire character or object shapes in input animation sequence With alpha value generally used in the Anime production pipeline. First, shadows are automatically rendered on a virtual plane by using a Shadow Map(1) based oil these inputs. Then the rendered shadows call be edited by simple operations and simplified by the Gaussian Filter. Several special effects such as blurring call be applied to the rendered shadow at the same time. Compared to existing approaches, ours is more efficient and effective to handle automatic shadowing in real-time. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Sugisaki, Eiji; Seah, Hock Soon; Tian, Feng] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Sugisaki, E (corresponding author), Nanyang Technol Univ, Sch Comp Engn, 36 Nanyang Ave N4-B4b-09 GameLAB, Singapore 639798, Singapore.
EM seiji@ntu.edu.sg
RI Seah, Hock Soon/AAK-9900-2020
OI Seah, Hock Soon/0000-0003-2699-7147; Morishima,
   Shigeo/0000-0001-8859-6539
CR ANNEN T, 2008, P ACM SIGGRAPH 2008
   DECORO C, P S NONPH AN REND 20, P77
   GUAN Y, P EUR 2006, P567
   JOHNSON T, 1981, WALL DISNEY PRODUCTI
   LLOYD B, 2005, TR05024 U N CAR
   Lloyd DB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409628
   MARTIN T, P EUR S REND 2004, P153
   NAKAJIMA H, P WSCG 2007, P233
   NAKAJIMA H, POST AN P S NONPH AN, P5
   PELLACINE F, P ACM SIGGRAPH 2002, P563
   PETROVIC L, P ACM SIGGRAPH 2000, P511
   SEGAL M, P ACM SIGGRAPH 1992, P249
   STAIMMINGER M, P ACM SIGGRAPH 2002, P557
   SUGISAKI E, P IWAIT 2009, P92
   WILLIAMS L, P ACM SIGGRAPH 1978, P270
   WIMMER M, P EUR S REND 2004, P143
NR 16
TC 3
Z9 3
U1 1
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 395
EP 404
DI 10.1002/cav.306
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700032
DA 2024-07-18
ER

PT J
AU Zhuang, YT
   Yu, J
   Xiao, J
   Chen, C
AF Zhuang, Yueting
   Yu, Jun
   Xiao, Jun
   Chen, Cheng
TI Perspective-aware cartoon clips synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE synthesize; cartoon clips; perspective; vanishing line
ID MOTION
AB In this paper rue propose an approach, which allows the users to synthesize cartoon clips according to the perspective of the background image. In order to construct the cartoons smoothly, the character's edge distance and motion direction distance are demonstrated to be the factors affecting tire human perception ill similarity evaluation, and utilized in cartoon clips synthesis. When applying the generated cartoons to tire background image, in which tire perspective exists, the size of the character is coordinated according to the scaling factor calculated from tire vanishing lute. The experiment results demonstrate that our approach call synthesize the cartoon: clips more smoothly compared With other single frame reusing strategies. The generated cartoons, which are applied to tire background image, call be accepted by the human perception well. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Zhuang, Yueting] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhuang, YT (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
EM yzhuang@cs.zju.edu.cn
CR [Anonymous], P S COMP AN
   [Anonymous], 1995, P 22 ANN C COMP GRAP, DOI DOI 10.1145/218380.218417
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   CATMULL E, 1978, P SIGGRAPH 78, P348
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   GALVIN M, 1998, P BRIT MACH VIS C BM, P195
   Gleicher M, 1999, COMPUT GRAPHICS-US, V33, P51, DOI 10.1145/345370.345409
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   JUAN CD, 2006, P EUR ASM SIGGRAPH S, P223
   Kort A., 2002, NPAR 02, P125, DOI DOI 10.1145/508530.508552
   LALONDE JF, 2007, P INT C COMP GRAPH I
   MCDONNELL R, 2007, P EUR ACM SIGGRAPH S, P259
   REITSMA A, 2004, P EUR ACM SIGGRAPH S, P89
   SOON SH, 2000, VISUAL COMPUT, V16, P289
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Yu J, 2007, COMPUT ANIMAT VIRT W, V18, P571, DOI 10.1002/cav.189
NR 17
TC 9
Z9 10
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 355
EP 364
DI 10.1002/cav.258
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200018
DA 2024-07-18
ER

PT J
AU Wang, CB
   Wang, ZY
   Peng, QS
AF Wang, Changbo
   Wang, Zhangye
   Peng, Qunsheng
TI Real-time rendering of sky scene considering scattering and refraction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE real-time rendering; sky scene; atmospheric refraction; atmospheric
   scattering
AB Realistic rendering of sky scene is important in game development and virtual reality. Traditional methods did not consider both the affect of atmospheric scattering and refraction, thus failing to realistically simulate the change of shape, color, and light ring of sky scene. In this paper, a new sky light model considering atmospheric scattering and refraction is proposed. We first calculate the refractional track of light through the atmosphere according to the refraction index. Then we adopt the scattered volume model to simplify the calculation of scattering light intensity. By adapting a path tracing algorithm considering refraction, the intensity distribution of sky light is calculated. Finally, various sky scenes in sunny day, foggy day, and that with rainbow and mirage under different conditions are realistically rendered in real time. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Wang, ZY (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM zywang@cad.zju.edu.cn
RI Zhou, Hong/JKJ-1067-2023
CR Dobashi Y, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P31, DOI 10.1109/PCCGA.2000.883864
   HABER J, 2005, PO WSCG 05 JAN, P79
   HOOKE WH, 1975, WAVES ATMOSPHERE
   Jackel D, 1997, COMPUT GRAPH FORUM, V16, P201, DOI 10.1111/1467-8659.00180
   KANEDA K, 1996, P PAC GRAPH 96, P117
   KHULAR E, 1977, AM J PHYS, V45, P90, DOI 10.1119/1.10919
   Max N. L., 1986, Computer Graphics, V20, P117, DOI 10.1145/15886.15899
   MUSGRAVE FK, 1990, IEEE COMPUT GRAPH, V10, P10, DOI 10.1109/38.62692
   NARSINHAN S, 2005, COMPUTER GRAPHICS, V24, P1040
   NEDA Z, 2002, J PHYS, V1, P379
   NIELSEN RS, 2003, THESIS TECHNICAL U D
   NISHIKAWA T, 1986, B JPN SOC PREC ENG, V20, P125
   Nishita T., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P379, DOI 10.1145/237170.237277
   Preetham AJ, 1999, COMP GRAPH, P91, DOI 10.1145/311535.311545
   TADAMURA K, 1993, COMPUTER GRAPHICS, V27, P175
   U. S. Government Printing Office, 1976, US STAND ATM 1976
   UMENHOFFER T, 2005, P EUR S REND, P277
   YAMASHITA H, 1991, P SIGGRAPH 2000 ACM, P19
NR 18
TC 3
Z9 3
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 539
EP 548
DI 10.1002/cav.213
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000032
DA 2024-07-18
ER

PT J
AU Adabala, N
   Varma, M
   Toyama, K
AF Adabala, Neeharika
   Varma, Manik
   Toyama, Kentaro
TI Computer aided generation of stylized maps
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cartography; geographic maps; vector data; computer vision; stylized
   rendering
ID EXTRACTION; TEXTURE; CLASSIFICATION; CITY
AB Geographic maps have existed from early stages of human civilization. Various styles of visualizing the geographic information have evolved depending on the nature of information and the technology available for visualization. This has led to innumerable map styles. In this work we develop a technique to create maps by combining two-dimensional and three-dimensional information such that the resulting maps are both functional and aesthetically appealing. Our technique requires geographical information in vector form and aerial images as inputs. We use computer vision based approaches and user defined inputs to augment the vector data with information that is required to create stylized maps. We define procedural graphics methods to generate a range of geographic elements that can be composed together into a stylized map. We demonstrate our technique by generating example maps of a region in Las Vegas. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Microsoft Res India, Bangalore 560080, Karnataka, India.
C3 Microsoft
RP Adabala, N (corresponding author), Microsoft Res India, 196-36 2nd Main, Bangalore 560080, Karnataka, India.
EM neeha@microsoft.com
OI Toyama, Kentaro/0000-0002-9128-2255
CR Agrawala M, 2001, COMP GRAPH, P241, DOI 10.1145/383259.383286
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berg AC, 2005, PROC CVPR IEEE, P26
   DECARLO D, 2002, P SIGGRAPH 2002
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Gooch B., 2001, Non-photorealistic rendering
   Haala N, 1999, ISPRS J PHOTOGRAMM, V54, P130, DOI 10.1016/S0924-2716(99)00010-6
   Konishi S, 2000, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.2000.855809
   Lazebnik S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P649
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Lorette A, 2000, INT J COMPUT VISION, V36, P221, DOI 10.1023/A:1008129103384
   MacEachren AlanM., 1995, HOW MAPS WORK
   Mena JB, 2003, PATTERN RECOGN LETT, V24, P3037, DOI 10.1016/S0167-8655(03)00164-8
   MONMONIER M, 1995, MAPPING OUT
   Rakkolainen I, 2001, COMPUT GRAPH-UK, V25, P619, DOI 10.1016/S0097-8493(01)00090-5
   Rellier G, 2004, IEEE T GEOSCI REMOTE, V42, P1543, DOI 10.1109/TGRS.2004.830170
   RUSINKIEWICZ S, 2006, ACM T GRAPHICS P SIG, P25
   Schmid C, 2004, INT J COMPUT VISION, V56, P7, DOI 10.1023/B:VISI.0000004829.38247.b0
   Sharon E, 2006, INT J COMPUT VISION, V70, P55, DOI 10.1007/s11263-006-6121-z
   Sidiropoulos G, 2006, COMPUT GRAPH-UK, V30, P299, DOI 10.1016/j.cag.2006.01.034
   Simard M, 2000, IEEE T GEOSCI REMOTE, V38, P2310, DOI 10.1109/36.868888
   Slocum T.A., 2003, Thematic Cartography and Geographic Visualization
   Varma M, 2003, PROC CVPR IEEE, P691
   Varma M., 2004, STAT APPROACHES TEXT
NR 24
TC 2
Z9 3
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2007
VL 18
IS 2
BP 133
EP 140
DI 10.1002/cav.168
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 181AO
UT WOS:000247409300006
DA 2024-07-18
ER

PT J
AU Arya, A
   Jefferies, LN
   Enns, JT
   DiPaola, S
AF Arya, Ali
   Jefferies, Lisa N.
   Enns, James T.
   DiPaola, Steve
TI Facial actions as visual cues for personality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE facial animation; social agent; personality; facial actions
ID EMOTION; EXPRESSIONS; PERCEPTION
AB What visual cites do human viewers rise to assign personality characteristics to animated characters? While most facial animation systems associate facial actions to limited emotional states or speech content, the present paper explores tire above question by relating the perception of personality to a Wide variety of facial actions (e.g., head tilting/turning, and eyebrow raising) and emotional expressions (e.g., smiles and frowns). Animated characters exhibiting these actions and expressions were presented to human viewers in brief videos. Human viewers rated the personalities of these characters using a well-standardized adjective rating system borrowed front the psychological literature. These personality descriptors are organized in a multidimensional space that is based on the orthogonal dimensions of desire for affiliation and displays of social dominance. The main result of the personality rating data was that human Viewers associated individual facial actions and emotional expressions With specific personality characteristics very reliably. In particular, dynamic facial actions such as head tilting and gaze aversion tended to spread ratings along the dominance dimension, whereas facial expressions of contempt and striding tended to spread ratings along the affiliation dimension. Furthermore, increasing tire frequency and intensity of the head actions increased tire perceived social dominance of the characters. We interpret these results as pointing to a reliable link between animated facial actions/expressions and tire personality attributions they evoke in human viewers. The paper shows how these findings are used in our facial animation system to create perceptually valid personality profiles based oil dominance and affiliation as two parameters that control tire facial actions of autonomous animated characters. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 iMedia Tek Interact Media Technol Inc, Vancouver, BC V6K 1L3, Canada.
RP Arya, A (corresponding author), iMedia Tek Interact Media Technol Inc, 308,2131 W 3rd Ave, Vancouver, BC V6K 1L3, Canada.
EM arya@imediatek.com
RI DiPaola, Stephen/M-5861-2013; Enns, James/O-7583-2017
OI DiPaola, Stephen/0000-0001-7549-9545; Enns, James/0000-0002-3676-8316;
   Jefferies, Lisa/0000-0003-1600-7170
CR Adams RB, 2005, EMOTION, V5, P3, DOI 10.1037/1528-3542.5.1.3
   [Anonymous], P 2 INT S SMART GRAP
   ARYA A, 2006, P WSCG 2006 PLZEN CZ
   BADLER N, 2002, P COMP AN C GEN SWIT
   BADLER NI, 1997, CREATING PERSONALITI
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   BATES J, 1992, J TELEOPRATORS VIRTU
   Battista S, 1999, IEEE MULTIMEDIA, V6, P74, DOI 10.1109/93.809236
   BERRY DS, 1991, J PERS SOC PSYCHOL, V61, P298, DOI 10.1037/0022-3514.61.2.298
   BORKENAU P, 1992, J PERS SOC PSYCHOL, V62, P645, DOI 10.1037/0022-3514.62.4.645
   Borkenau P, 2004, J PERS SOC PSYCHOL, V86, P599, DOI 10.1037/0022-3514.86.4.599
   BUSSO C, 2005, P COMP AN SOC AG
   CASSELL J, 1994, P ACM SIGGRAPH
   CASSELL J, 2001, P ACM SIGGRAPH LOS A
   EGGES A, 2003, P KNOWL BAS INT INF
   Ekman Paul., 2003, EMOTIONS REVEALED
   FUNGE J, 1999, P ACM SIGGRAPH LOS A
   GILBERT DT, 1995, PSYCHOL BULL, V117, P21, DOI 10.1037/0033-2909.117.1.21
   HOFSTEE WKB, 1992, J PERS SOC PSYCHOL, V63, P146, DOI 10.1037/0022-3514.63.1.146
   KING SA, 2003, P COMP AN SOC AG
   Knutson B, 1996, J NONVERBAL BEHAV, V20, P165, DOI 10.1007/BF02281954
   LOYALL AB, 1997, P AG C MAR REY CA US
   Marsh AA, 2005, EMOTION, V5, P119, DOI 10.1037/1528-3542.5.1.119
   McCrae RobertR., 1996, The Five-Factor Model of Personality: Theoretical Perspectives, P21
   Montepare JM, 2003, J NONVERBAL BEHAV, V27, P237, DOI 10.1023/A:1027332800296
   PELACHAUD C, 2003, COMMUNICATION MAS
   REILLY WS, 1995, CMUCS95164
   ROUSSEAU D, 1997, 9706 KSL STANF U
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   SMID K, 2004, P COMP AN SOC AG GEN
   WATSON D, 1989, J PERS SOC PSYCHOL, V57, P120, DOI 10.1037/0022-3514.57.1.120
   WIGGINS JS, 1988, MULTIVAR BEHAV RES, V23, P517, DOI 10.1207/s15327906mbr2304_8
NR 32
TC 24
Z9 28
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 371
EP 382
DI 10.1002/cav.140
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400023
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lee, J
   Yoon, SH
   Kim, MS
AF Lee, Jieun
   Yoon, Seung-Hyun
   Kim, Myung-Soo
TI Realistic human hand deformation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human hand modeling; hand deformation; palm deformation; palm lines;
   sweep surfaces; freeform surface; displacement map; self-intersection;
   collision detection
AB We present a new approach to realistic hand modeling and deformation with real-time performance. We model the underlying shape of a human hand by means of sweeps which follow a simplified skeleton. The resulting swept surfaces are blended, and an auxiliary surface is then bound to the swept representation in the palm region. In the areas of this palm-control surface Where bidges occur in certain poses of a real hand, the vertices are given their own trajectories, so that the palm forms realistic shapes as the joints bend. Palm lines can also be modeled as valleys in the skin by sketching them on a displacement map on the palm-control surface, and activitating them when appropriate joint movements take place. Self-intersections and collisions are detected using geometric primitives that are automatically generated from, and deform With, the Sweeps and palm surface. Our algorithm runs in real time, and tire naturalism of its results are demonstrated by comparative images of modeled and real hands, including several challenging poses. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151744, South Korea.
C3 Seoul National University (SNU)
RP Kim, MS (corresponding author), Seoul Natl Univ, Sch Comp Sci & Engn, San 56-1,Sillim Dong, Seoul 151744, South Korea.
EM mskim@cse.snu.ac.kr
RI Lee, Eun-ju/JAN-8749-2023; LEE, JIEUN/HTN-1777-2023; LEE,
   YU/JXY-2338-2024; Lee, Jieun/J-3909-2016
OI Lee, Jieun/0000-0001-5692-9263
CR Albrecht Irene., 2003, P 2003 ACM SIGGRAPHE, P98
   [Anonymous], 2001, P 2001 S INTERACTIVE
   [Anonymous], 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'02
   [Anonymous], 2005, P 2005 ACM SIGGRAPHE, DOI DOI 10.1145/1073368.1073414
   Bando Y, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P166, DOI 10.1109/PCCGA.2002.1167852
   Chang TI, 1998, VISUAL COMPUT, V14, P228, DOI 10.1007/s003710050137
   COQUILLART S, 1987, IEEE COMPUT GRAPH, V7, P36, DOI 10.1109/MCG.1987.277068
   ElKoura G., 2003, Proc. of ACM SIGGRAPH/Eurographics SCA, P110
   Huang Zhiyong, 1995, COMPUT GRAPHICS-US, P235
   Hyun DE, 2005, VISUAL COMPUT, V21, P542, DOI 10.1007/s00371-005-0343-x
   Kurihara Tsuneya, 2004, P 2004 ACM SIGGRAPHE, P355
   LAZARUS F, 1994, COMPUT AIDED DESIGN, V26, P607, DOI 10.1016/0010-4485(94)90103-1
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Magnenat-Thalmann Nadia, 1988, P GRAPHICS INTERFACE
   Moccozet L, 1997, COMP ANIM CONF PROC, P93, DOI 10.1109/CA.1997.601047
   SANSO RM, 1994, COMPUT GRAPH FORUM, V13, pC167, DOI 10.1111/1467-8659.1330167
NR 16
TC 17
Z9 17
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 479
EP 489
DI 10.1002/cav.150
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400033
DA 2024-07-18
ER

PT J
AU Lemos, RR
   Rokne, O
   Baranoski, GVG
   Kawakami, Y
   Kurihara, T
AF Lemos, RR
   Rokne, O
   Baranoski, GVG
   Kawakami, Y
   Kurihara, T
TI Modeling and simulating the deformation of human skeletal muscle based
   on anatomy and physiology
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE physically-based muscle modeling; medical three-dimensional simulation
ID FORCE
AB This paper describes the modeling and simulation of the deformation of human skeletal muscle at different structural levels based on sound scientific principles, experimental evidence, and state-of-art muscle anatomy and physiology. The equations of a continuum model of a muscle with realistic architecture, including internal arrangement Of muscle fibers and passive structures, and deformation, including activation relations, was developed and solved with the finite element method. The continuum model is used as the basis of a strategy for controlling muscle deformation using activation relations. In order to demonstrate the functionality of the model, it was used to investigate force production and structural changes during contraction of the human tibialis anterior for maximally and submaximally activated muscle behavior. From a comparison with experimental data obtained from ultrasound imaging, we concluded that the modeling and simulation of the continuum based on physiologically meaningful parameters as described in the paper is both an excellent predictor of force production observations and of changes in internal geometry under various test conditions. It is therefore a valuable tool for controlling muscle deformation during movement. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
   Univ Caixas do Sul, Dept Comp Sci, BR-95070560 Caxias Do Sul, RS, Brazil.
C3 University of Calgary
RP Univ Caixas do Sul, Dept Comp Sci, Rua Francisco,Getulio Vargas 1130, BR-95070560 Caxias Do Sul, RS, Brazil.
EM rlemos@ucs.br
RI Kawakami, Yasuo/AAH-3075-2022; Baranoski, Gladimir/A-1944-2008;
   Kurihara, Toshiyuki/JEF-8146-2023; Kawakami, Yasuo/AFM-0651-2022
OI Kawakami, Yasuo/0000-0003-0588-4039; Kurihara,
   Toshiyuki/0000-0001-9726-1255; Kawakami, Yasuo/0000-0003-0588-4039;
   Lemos, Robson/0000-0003-0750-6859
CR Blemker SS, 2005, J BIOMECH, V38, P657, DOI 10.1016/j.jbiomech.2004.04.009
   CHEN DT, 1992, COMP GRAPH, V26, P89, DOI 10.1145/142920.134016
   Epstein M, 1998, THEORETICAL MODELS S
   Fernandez JW, 2004, BIOMECH MODEL MECHAN, V2, P139, DOI [10.1007/s10237-003-0036-1, 10.1007/S10237-003-0036-1]
   Gielen A. W. J., 2000, Comput Methods Biomech Biomed Engin, V3, P231, DOI 10.1080/10255840008915267
   Herzog W, 2002, J EXP BIOL, V205, P1275
   HOUBOLT JC, 1950, J AERONAUT SCI, V17, P540, DOI 10.2514/8.1722
   Hunter P, 2002, PFLUG ARCH EUR J PHY, V445, P1, DOI 10.1007/s00424-002-0890-1
   Ito L, 1998, J APPL PHYSIOL, V85, P1230, DOI 10.1152/jappl.1998.85.4.1230
   Lemos R. R., 2004, Computer Methods in Biomechanics and Biomedical Engineering, V7, P305, DOI 10.1080/10255840412331317398
   LEMOS RR, 2004, THESIS U CALGARY CAN
   Maganaris CN, 2001, J ANAT, V199, P449, DOI 10.1046/j.1469-7580.2001.19940449.x
   Marieb E. N., 1995, HUMAN ANATOMY PHYSL
   Maurel W., 1998, BIOMECHANICAL MODELS
   Ng-Thow-Hing V, 2002, PROC GRAPH INTERF, P107
   Oomens CWJ, 2003, PHILOS T ROY SOC B, V358, P1453, DOI 10.1098/rstb.2003.1345
   Press W. H., 1988, Numerical Recipes
   Sandercock TG, 2000, J APPL PHYSIOL, V89, P2206, DOI 10.1152/jappl.2000.89.6.2206
   SCHEEPERS C, 1997, COMPUTER GRAPHICS, P163
   Teran J, 2005, IEEE T VIS COMPUT GR, V11, P317, DOI 10.1109/TVCG.2005.42
   Wilhelms J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P173, DOI 10.1145/258734.258833
   Wolf SL, 1997, ACTA ANAT, V158, P287, DOI 10.1159/000147942
NR 22
TC 18
Z9 22
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 319
EP 330
DI 10.1002/cav.83
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000017
DA 2024-07-18
ER

PT J
AU Lin, CH
   Lee, TY
   Chu, HK
   Yao, CY
AF Lin, CH
   Lee, TY
   Chu, HK
   Yao, CY
TI Progressive mesh metamorphosis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE metamorphosis; connectivity transformation; spherical parameterization;
   warping; semi-overlay; geomorph
AB This paper describes a new integrated scheme for metamorphosis between two closed manifold genus-0 polyhedral models. Spherical parameterizations of the source and target models are created first. To control the morphing, any number of feature vertex pairs is specified and a fold-over free warping method is used to align two spherical embeddings. Our method does not create a merged meta-mesh or execute re-meshing to construct a common connectivity for morphs. Alternatively, a scheme for the progressive connectivity transformation of two spherical parameterizations is employed to generate the intermediate meshes. A novel semi-overlay with a geomorph scheme is proposed to reduce the popping effects caused by the connectivity transformation. We demonstrate several examples of aesthetically pleasing morphing sequences using the proposed scheme. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Comp Graph Grp, Visual Syst Lab, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Comp Graph Grp, Visual Syst Lab, 1 Ta Hsueh Rd, Tainan 701, Taiwan.
EM tonylee@mail.ncku.edu.tw
CR Alexa M, 2000, VISUAL COMPUT, V16, P26, DOI 10.1007/PL00007211
   CHI MT, 2006, IN PRESS IEEE T VISU
   Fujimura K, 1998, GRAPH MODEL IM PROC, V60, P100, DOI 10.1006/gmip.1998.0454
   Gregory A, 1999, VISUAL COMPUT, V15, P453, DOI 10.1007/s003710050192
   HOPPE P, 1996, SIGGRAPH 96 P 23 ANN, P99
   Kanai T, 2000, IEEE COMPUT GRAPH, V20, P62, DOI 10.1109/38.824544
   Lee AWF, 1999, COMP GRAPH, P343, DOI 10.1145/311535.311586
   Lee TY, 2003, IEEE T VIS COMPUT GR, V9, P85, DOI 10.1109/TVCG.2003.1175099
   LEE TY, 2005, IEICE T INF SYST, V88, P645
   Lin CH, 2005, IEEE T VIS COMPUT GR, V11, P2
   Michikawa T, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P60, DOI 10.1109/PCCGA.2001.962858
   Praun E, 2001, COMP GRAPH, P179, DOI 10.1145/383259.383277
   SHLAFMAN S, 2002, EUROGRAPHICS, P219
   Zöckler M, 2000, VISUAL COMPUT, V16, P241, DOI 10.1007/PL00013396
NR 14
TC 7
Z9 9
U1 0
U2 3
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 487
EP 498
DI 10.1002/cav.85
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000031
DA 2024-07-18
ER

PT J
AU So, CKF
   Baciu, G
AF So, CKF
   Baciu, G
TI Entropy-based motion extraction for motion capture animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE motion capture; animation; entropy; mutual information; motion database
AB In this paper, we present a new segmentation solution for extracting motion patterns from motion capture data by searching for critical keyposes in the motion sequence. A rank is established for critical keyposes that identifies the significance of the directional change in motion data. The method is based on entropy metrics, specifically the mutual information measure. Displacement histograms between frames are evaluated and the mutual information metric is employed in order to calculate the inter-frame dependency. The most significant keypose identifies the largest directional change in the motion data. This will have the lowest mutual information level from all the candidate keyposes. Less significant keyposes are then listed with higher mutual information levels. The results show that the method has higher sensitivity in the directional change than methods based on the magnitude of the velocity alone. This method is intended to provide a summary of a motion clip by ranked keyposes, which is highly useful in motion browsing and motion retrieve database system. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
   Hong Kong Polytech Univ, Mulimedia Innovat Ctr, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; Hong Kong Polytechnic University
RP Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
EM csgeorge@comp.polyu.edu.hk
RI Baciu, George/AAU-7143-2021
OI BACIU, George/0000-0002-1766-6357
CR Ahanger G, 1996, J VIS COMMUN IMAGE R, V7, P28, DOI 10.1006/jvci.1996.0004
   [Anonymous], 2002, P SPRING C COMP GRAP
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Bevilacqua F., 2002, P WORKSH S SENS INP
   BEVILACQUA F, 2001, P IEEE MULT TECHN AP
   Bruderlin A, 1996, PROC GRAPH INTERF, P213
   Dailianas A., 1995, Proceedings of the SPIE Conference on Integration Issues in Large Commercial Media Delivery Systems, V2615, P2
   DREW MS, 2000, P IEEE INT C IM PROC, V3, P909
   Gleicher M, 2001, GRAPH MODELS, V63, P107, DOI 10.1006/gmod.2001.0549
   Gleicher Michael., 2003, I3D 2003: Proceedings of the 2003 Symposium on Interactive 3D Graphics, P181
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kurihara K, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1241, DOI 10.1109/ROBOT.2002.1014713
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   Lienhart R, 2001, PROC SPIE, V4315, P219, DOI 10.1117/12.410931
   LIENHART R, 2001, P IEEE INT C IM PROC
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   MOLINATANCO L, 2000, WORKSH HUM MOT HUMO, P137
   Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8
   Pullen K, 2002, ACM T GRAPHIC, V21, P501
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Tsekeridou S, 2001, IEEE T CIRC SYST VID, V11, P522, DOI 10.1109/76.915358
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
NR 26
TC 14
Z9 16
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 225
EP 235
DI 10.1002/cav.107
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000009
DA 2024-07-18
ER

PT J
AU Wilke, L
   Calvert, T
   Ryman, R
   Fox, I
AF Wilke, L
   Calvert, T
   Ryman, R
   Fox, I
TI From dance notation to human animation: The LabanDancer project
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE computer graphics; human figure animation; dance; notation
AB Symbolic systems such as Labanotation for notating dance and choreography provide a critical tool for the preservation of cultural heritage in what once was considered an 'illiterate' art form. While the goals of such notation systems are laudable, the unfortunate reality is that most dancers and choreographers cannot read or write the notation; that is, they are loath to take the considerable effort to learn a rich, but complex methodology. To make Labanotation scores more accessible the LabanDancer system has been developed to translate Labanotation scores recorded in the LabanWriter editor into 3-d human figure animations. A major challenge in the development of this translator has been to find approaches that are general enough to create reasonable animations for a wide variety of different movements. Any translator must also take account of the context of a movement since this can affect the interpretation of the Labanotation scores. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Credo Interact Inc, Vancouver, BC, Canada.
   Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
   Simon Fraser Univ, Sch Interact Arts & Technol, Surrey, BC V3T 5X3, Canada.
C3 University of Waterloo; Simon Fraser University
RP Simon Fraser Univ, Sch Interact Arts & Technol, 14th Floor,Cent City Tower,13450 102nd Ave, Surrey, BC V3T 5X3, Canada.
EM tom@sfu.ca
CR BADLER NI, 1979, COMPUT SURV, V11, P19, DOI 10.1145/356757.356760
   BAERLOCHER P, 2004, VISUAL COMPUTER, V20
   BROWN MD, 1978, COMPUT GRAPH, V3, P1, DOI 10.1016/0097-8493(78)90018-3
   Calvert T, 2005, IEEE COMPUT GRAPH, V25, P6, DOI 10.1109/MCG.2005.33
   Calvert T. W., 1991, Visual Computer, V7, P114, DOI 10.1007/BF01901182
   CALVERT TW, 1978, P 1978 ACM C, P731
   Cunningham Merce., 1968, CHANGES NOTES CHOREO
   GIRARD M, 1987, IEEE COMPUT GRAPH, V7, P39, DOI 10.1109/MCG.1987.276895
   GLEICHER M, 2003, S INT 3D GRAPH APR
   GRAY JA, 1984, INTERCHANGE, V15, P15, DOI 10.1007/BF01808249
   HUNT FES, 2003, 343 U SYDN BASS DEP
   HUTCHINSONGUEST A, 1970, LABANOTATION KINETOG
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   MIZUGUCHI M, P EUR 2001 MANCH UK
   NOLL A, 1967, DANCE MAG, P43
   RYMAN R, 1986, DANCE NOTATION J, V4, P16
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   vandePanne M, 1997, COMPUT GRAPH FORUM, V16, P211, DOI 10.1111/1467-8659.00181
   Venable L., 1989, LABANWRITER 2 0
   WOLOFSKY Z, 1974, THESIS S FRASER U
NR 20
TC 34
Z9 37
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 201
EP 211
DI 10.1002/cav.90
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000007
DA 2024-07-18
ER

PT J
AU Ma, JY
   Cole, R
   Pellom, B
   Ward, W
   Wise, B
AF Ma, JY
   Cole, R
   Pellom, B
   Ward, W
   Wise, B
TI Accurate automatic visible speech synthesis of arbitrary 3D models based
   on concatenation of diviseme motion capture data
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE visible speech; visual speech synthesis; animated speech; coarticulation
   modelling; speech animation; face animation
ID PERCEPTION; FACES
AB We present a technique for accurate automatic visible speech synthesis from textual input. When provided with a speech waveform and the text of a spoken sentence, the system produces accurate visible speech synchronized with the audio signal. To develop the system, we collected motion capture data from a speaker's face during production of a set of words containing all diviseme sequences in English. The motion capture points from the speaker's face are retargeted to the vertices of the polygons of a 31) face model. When synthesizing a new utterance, the system locates the required sequence of divisemes, shrinks or expands each diviseme based on the desired phoneme segment durations in the target utterance, then moves the polygons in the regions of the lips and lower face to correspond to the spatial coordinates of the motion capture data. The motion mapping is realized by a key-shape mapping function learned by a set of viseme examples in the source and target faces. A well-posed numerical algorithm estimates the shape blending coefficients. Time warping and motion vector blending at the juncture of two divisemes and the algorithm to search the optimal concatenated visible speech are also developed to provide the final concatenative motion sequence. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Colorado, Ctr Spoken Language Res, Boulder, CO 80309 USA.
C3 University of Colorado System; University of Colorado Boulder
RP Univ Colorado, Ctr Spoken Language Res, Campus Box 594, Boulder, CO 80309 USA.
EM jiyong@cslr.colorado.edu
CR [Anonymous], 1999, Coarticulation: Theory, Data and Techniques
   [Anonymous], 2003, PROCEEDINGS OF IEEE
   Bai Z., 2000, SIAM, DOI DOI 10.1137/1.9780898719581
   Bellman R., 1957, Dynamic programming
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Bregler C., 1997, P 24 ANN C COMP GRAP, V31, P353, DOI DOI 10.1145/258734.258880
   Chuang ES, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P68, DOI 10.1109/PCCGA.2002.1167840
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   Cole R, 2003, P IEEE, V91, P1391, DOI 10.1109/JPROC.2003.817143
   COLE R, 1999, P ESCA SOCRRATES WOR
   Cosatto E, 1998, COMP ANIM CONF PROC, P103, DOI 10.1109/CA.1998.681914
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Ezzat T, 1998, COMP ANIM CONF PROC, P96, DOI 10.1109/CA.1998.681913
   Feng G, 1998, IEEE T SIGNAL PROCES, V46, P2790, DOI 10.1109/78.720380
   Gertz EM, 2003, ACM T MATH SOFTWARE, V29, P58, DOI 10.1145/641876.641880
   GRAF, 2000, P FAC GEST REC, P189
   Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387
   Hartmann E, 2001, VISUAL COMPUT, V17, P1, DOI 10.1007/PL00013398
   JACKSON PL, 1988, VOLTA REV, V90, P99
   Kalberer GA, 2001, COMP ANIM CONF PROC, P20, DOI 10.1109/CA.2001.982373
   Kent, 1977, Journal of Phonetics, V5, P115, DOI [DOI 10.1006/JPHO.2000.0118, DOI 10.1016/S0095-4470(19)31123-4]
   KLEISER J, 1989, STATE ART FACIAL ANI, V22, P37
   Kshirsagar S, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P38, DOI 10.1109/CGI.2001.934656
   LOFQVIST A, 1990, NATO ADV SCI I D-BEH, V55, P289
   MA JY, 2004, IN PRESS VISUAL COMP
   Magnenat-Thalmann N., 1988, Visual Computer, V3, P290, DOI 10.1007/BF01914864
   NIELSON GM, 1993, IEEE COMPUT GRAPH, V13, P60, DOI 10.1109/38.180119
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   Pighin F, 2002, INT J COMPUT VISION, V50, P143, DOI 10.1023/A:1020393915769
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   *U ED, 2003, FEST SPEECH SYNTH SY
   Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
   WOODWARD MF, 1960, J SPEECH HEAR RES, V3, P212, DOI 10.1044/jshr.0303.212
NR 37
TC 17
Z9 19
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2004
VL 15
IS 5
BP 485
EP 500
DI 10.1002/cav.11
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 880TP
UT WOS:000225812600003
DA 2024-07-18
ER

PT J
AU DeCarlo, D
   Stone, M
   Revilla, C
   Venditti, JJ
AF DeCarlo, D
   Stone, M
   Revilla, C
   Venditti, JJ
TI Specifying and animating facial signals for discourse in embodied
   conversational agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE facial animation; embodied conversational agents
ID COMMUNICATION; EXPRESSIONS; INTONATION; MOVEMENT; LANGUAGE; SPEECH
AB People highlight the intended interpretation of their utterances within a larger discourse by a diverse set of non-verbal signals. These signals represent a key challenge for animated conversational agents because they are pervasive, variable, and need to be coordinated judiciously in an effective contribution to conversation. In this paper, we describe a freely available cross-platform real-time facial animation system, RUTH, that animates such high-level signals in synchrony with speech and lip movements. RUTH adopts an open, layered architecture in which fine-grained features of the animation can be derived by rule from inferred linguistic structure, allowing us to use RUTH, in conjunction with annotation of observed discourse, to investigate the meaningful high-level elements of conversational facial movement for American English speakers. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
   Rutgers State Univ, Ctr Cognit Sci, Piscataway, NJ 08854 USA.
C3 Rutgers University System; Rutgers University New Brunswick; Rutgers
   University System; Rutgers University New Brunswick
RP DeCarlo, D (corresponding author), Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
EM decarlo@cs.rutgers.edu
OI Stone, Matthew/0000-0003-3629-2941
CR André E, 2000, EMBODIED CONVERSATIONAL AGENTS, P220
   [Anonymous], 1998, Perceiving talking faces: From speech perception to a behavioral principle
   [Anonymous], 1999, Proceedings of the SIGCHI conference on human factors in computing systems, DOI [10.1145/302979.303150, DOI 10.1145/302979.303150]
   Badler N, 2002, COMP ANIM CONF PROC, P133, DOI 10.1109/CA.2002.1017521
   Ball G, 2000, EMBODIED CONVERSATIONAL AGENTS, P189
   Bavelas JB, 2000, J LANG SOC PSYCHOL, V19, P163, DOI 10.1177/0261927X00019002001
   BECKMAN M, 1997, GUIDELINSE TOBI LABE
   BLACK A, 1997, HCRCTR83
   Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537
   BULL P, 1985, J NONVERBAL BEHAV, V9, P169, DOI 10.1007/BF01000738
   BYUN M, 2002, ACM SIGGRAPH S COMP, P65
   Cahn J., 2000, Journal of the American Voice I/O Society, V8, P1
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   CASSELL J, 2000, 1 INT C NAT LANG GEN, P171
   CASSELL J, 1994, P COGN SCI SOC
   CASSELL J, 1999, APPL ARTIFICIAL INTE, V13
   Cassell J., 2000, Embodied Conversational Agents
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   DECAROLIS B, 2001, P IJCAI
   Ekman P., 1979, Human Ethology, P169
   Engle R. A., 2000, THESIS STANFORD U
   HADAR U, 1983, LANG SPEECH, V26, P117, DOI 10.1177/002383098302600202
   HIRSCHBERG J, 1993, ARTIF INTELL, V63, P305, DOI 10.1016/0004-3702(93)90020-C
   Hirschberg J., 1996, P ACL
   Jilka M, 1999, SPEECH COMMUN, V28, P83, DOI 10.1016/S0167-6393(99)00008-4
   KING SA, 2001, THESIS OHIO STATE U
   KRAHMER E, 2002, S SPEECH PROS
   KRAHMER E, 2002, INT C SPOK LAN PROC
   LADD DR, 1985, J ACOUST SOC AM, V78, P435, DOI 10.1121/1.392466
   Lester JC, 2000, EMBODIED CONVERSATIONAL AGENTS, P123
   LOFQVIST A, 1990, NATO ADV SCI I D-BEH, V55, P289
   MACON M, 1997, CSE97007 OR GRAD I
   MARSELLA SC, 2000, P AGENTS
   McNeil D., 1992, Hand and mind: What gesture reveals about thought
   MOHLER G, 2001, P 4 ISCA TUT RES WOR
   MOHLER G, 1999, P 6 EUR C SPEECH COM
   NAGAO K, 1994, P 32 ANN M ASS COMP, P102
   Nass C, 2000, EMBODIED CONVERSATIONAL AGENTS, P374
   Norvig P, 1992, Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp
   Pelachaud C, 1996, COGNITIVE SCI, V20, P1, DOI 10.1207/s15516709cog2001_1
   Pelachaud C, 2002, J VISUAL COMP ANIMAT, V13, P301, DOI 10.1002/vis.299
   PERLIN K, 1998, TEXTURING MODELING P, P209
   PERLIN K, 1997, SIGGRAPH 1997
   PIERREHUMBERT J, 1990, SYS DEV FDN, P271
   PLATT SM, 1985, THESIS U PENNSYLVANI
   Poggi I, 2000, AI COMMUN, V13, P169
   Poggi I, 2000, EMBODIED CONVERSATIONAL AGENTS, P155
   Silverman K.E. A., 1992, P 1992 INT C SPOKEN, V2, P867, DOI [10.21437/ICSLP.1992-260, DOI 10.21437/ICSLP.1992-260]
   Smid K, 2002, COMP ANIM CONF PROC, P240, DOI 10.1109/CA.2002.1017543
   STONE M, 2003, COMPUTER ANIMATION S
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Waters K., 1987, ACM SIGGRAPH Comput. Graph., V21, P17
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
NR 54
TC 14
Z9 15
U1 0
U2 3
PU WILEY-BLACKWELL
PI MALDEN
PA COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2004
VL 15
IS 1
BP 27
EP 38
DI 10.1002/cav.5
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 832EF
UT WOS:000222249300004
OA Bronze
DA 2024-07-18
ER

PT J
AU Li, XX
   Huang, YF
   Jiang, ZY
   Liu, Y
   Hou, YR
AF Li, Xunxiang
   Huang, Yufang
   Jiang, Ziyan
   Liu, Yi
   Hou, Yiru
TI Rendering and presentation of 3D digital ink landscape painting
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Chinese ink landscape painting; freehand brushwork; rendering and
   presentation
AB Explore the digital rendering mode with texturing brush and ink effect, analyze and simulate the brush and ink characteristics of traditional Chinese ink painting, especially the art of landscape painting, and try to integrate the texture of wrinkle method synthesis map and modeling technology based on particle deposition and stacking (overlapping) to render, thus realizing the computer simulation of small freehand brushwork and large freehand brushwork (splash ink) ink effects in traditional landscape painting. This research inherits and develops the esthetic theory and thought of traditional ink painting art, and makes some beneficial exploration in the field of digital freehand ink painting, which has positive reference value and promotion significance for the development of Chinese ink painting.
C1 [Li, Xunxiang; Huang, Yufang; Jiang, Ziyan; Liu, Yi; Hou, Yiru] Wenzhou Univ, Coll Fine Arts & Design, Wenzhou 325035, Peoples R China.
C3 Wenzhou University
RP Li, XX (corresponding author), Wenzhou Univ, Coll Fine Arts & Design, Wenzhou 325035, Peoples R China.
EM lixunxiang@163.com
RI Liu, Xinru/KEH-2341-2024; li, feiyang/KHW-5210-2024; yan,
   xu/KCY-8174-2024; Zhu, Mengzhao/KFT-2345-2024; Huang,
   Yufang/AAI-2648-2019; liu, yang/KFA-8402-2024; li, yf/KHX-1148-2024;
   Wang, Xinyi/KHV-4909-2024; liu, miao/KGL-7043-2024; Liu,
   Donghua/KEJ-1974-2024; Liu, Zhen/KFS-2748-2024; zhang,
   xiaoyu/KEJ-0657-2024; li, qing/KHU-6871-2024; chen, chen/KHW-7024-2024;
   wang, yifang/KEI-3766-2024; Wang, Zichao/KHX-4954-2024; Lu,
   Xin/KHW-8570-2024; Li, Yuanyuan/KEH-6935-2024; Shen, Yan/KEJ-4617-2024;
   liu, zhen/KFS-0275-2024; liu, qi/KFA-4047-2024; Zhang,
   Yulin/KEI-1610-2024; Lin, Wei/KFQ-5381-2024; Sun, Yue/KHU-8159-2024;
   wang, jiaqi/KHC-5900-2024; Zhang, Yi/KHW-2039-2024
OI Liu, Donghua/0000-0002-5830-9540; Lu, Xin/0000-0001-9885-6031; Li,
   Yuanyuan/0000-0002-4955-1159; 
FU National Social Science Fund of China [19BC030]
FX National Social Science Fund of China, Grant/Award Number: 19BC030
CR Ashikhmin M., SYNTHESIZING NATURAL
   Barabasi A. L., 1995, FRACTAL CONCEPTS SUR, DOI 10.1017/CBO9780511599798
   Baxter B, 2001, COMP GRAPH, P461, DOI 10.1145/383259.383313
   Chan C, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P403, DOI 10.1109/PCCGA.2002.1167884
   Lee J, 1999, IEEE COMPUT GRAPH, V19, P74, DOI 10.1109/38.761553
   Meijun S., 2004, J SYST SIMUL, V16, P2317
   Miller G. S. P., 1986, Computer Graphics, V20, P39, DOI 10.1145/15886.15890
   Shuli W., 2003, ESSENCE GAME PROGRAM, P451
   Strassmann S., 1986, Computer Graphics, V20, P225, DOI 10.1145/15886.15911
   Voss R., 1988, SCI FRACTAL IMAGES, P21, DOI DOI 10.1007/978-1-4612-3784-6_1
   Way DL, 2001, COMPUT GRAPH FORUM, V20, pC123
NR 11
TC 1
Z9 1
U1 12
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2215
EA SEP 2023
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OO0T8
UT WOS:001068574800001
DA 2024-07-18
ER

PT J
AU Aiman, U
   Ahmad, T
AF Aiman, Umme
   Ahmad, Tanvir
TI Angle based hand gesture recognition using graph convolutional network
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE convolutional neural network (CNN); deep learning; graph convolutional
   network (GCN); hand gesture recognition
AB Hand gesture recognition has attracted huge interest in the areas of autonomous driving, human computer systems, gaming and many others. Skeleton based techniques along with graph convolutional networks (GCNs) are being popularly used in this field due to the easy estimation of joint coordinates and better representation capability of graphs. Simple hand skeleton graphs are unable to capture the finer details and complex spatial features of hand gestures. To address these challenges, this work proposes an "angle-based hand gesture graph convolutional network" (AHG-GCN). This model introduces two additional types of novel edges in the graph to connect the wrist with each fingertip and finger's base, explicitly capturing their relationship, which plays an important role in differentiating gestures. Besides, novel features for each skeleton joint are designed using the angles formed with fingertip/finger-base joints and the distance among them to extract semantic correlation and tackle the overfitting problem. Thus, an enhanced set of 25 features for each joint is obtained using these novel techniques. The proposed model achieves 90% and 88% accuracy for 14 and 28 gesture configurations for the DHG 14/28 dataset and, 94.05% and 89.4% accuracy for 14 and 28 gesture configurations for the SHREC 2017 dataset, respectively.
C1 [Aiman, Umme; Ahmad, Tanvir] Fac Engn & Technol, Dept Comp Engn, New Delhi, India.
   [Aiman, Umme] Jamia Millia Islamia, Fac Engn & Technol, Dept Comp Engn, New Delhi 110025, India.
C3 Jamia Millia Islamia
RP Aiman, U (corresponding author), Jamia Millia Islamia, Fac Engn & Technol, Dept Comp Engn, New Delhi 110025, India.
EM aimanraza16@gmail.com; tahmad2@jmi.ac.in
OI AIMAN, UMME/0000-0002-4562-7486
FU Maulana Azad National Fellowship;  [201819-MANF-2018-19-DEL-100030]
FX Maulana Azad National Fellowship, Grant/Award
   Number:201819-MANF-2018-19-DEL-100030
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Althoff F., 2005, VDI B ERICHTE, V1919, P187
   Avola D, 2019, IEEE T MULTIMEDIA, V21, P234, DOI 10.1109/TMM.2018.2856094
   Boulahia SY., INT C IM PROC
   Cao CQ, 2019, IEEE T CIRC SYST VID, V29, P3247, DOI 10.1109/TCSVT.2018.2879913
   Chen XH, 2017, IEEE IMAGE PROC, P2881, DOI 10.1109/ICIP.2017.8296809
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Cheng L., 2019, IEEE T COGN DEV SYST, V13, P1, DOI DOI 10.1109/TCST.2019.2913534
   Cho K., 2014, ARXIV14061078
   Cires DC., INT JOINT C ART INT
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   De Smedt Q., 2017, 3DOR 10 EUR WORKSH 3, P1, DOI DOI 10.2312/3DOR.20171049
   De Smedt Q, 2016, IEEE COMPUT SOC CONF, P1206, DOI 10.1109/CVPRW.2016.153
   Devineau G, 2018, IEEE INT CONF AUTOMA, P106, DOI 10.1109/FG.2018.00025
   Du Yong., Hierarchical recurrent neural network for skeleton based action recognition
   Gao X., P ACM INT C MULT
   Han F., SPACETIME REPRESENTA
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hou JX, 2019, LECT NOTES COMPUT SC, V11134, P273, DOI 10.1007/978-3-030-11024-6_18
   Kim TS., IEEE CVPR WORKSH
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuznetsova A, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P83, DOI 10.1109/ICCVW.2013.18
   Lea C., 2016, Temporal Convolutional Networks: A Unified Approach to Action Segmentation
   Lecun Y., GRADIENT BASED LEARN
   Li C., 2018, PROCEDINGS 32 AAAI, DOI [10.48550/arxiv.1802.09834, DOI 10.48550/ARXIV.1802.09834]
   Li C, 2019, IEEE T IMAGE PROCESS, V28, P4646, DOI 10.1109/TIP.2019.2912357
   Li Y, 2019, EVID-BASED COMPL ALT, V2019, DOI 10.1155/2019/1635837
   Liu J., SPATIO TEMPORAL LSTM
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Ma CY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113680
   Marin G., IEEE INT C IM PROC I
   Molchanov P., 2016, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, P4207, DOI DOI 10.1109/CVPR.2016.456
   Neverova N, 2016, IEEE T PATTERN ANAL, V38, P1692, DOI 10.1109/TPAMI.2015.2461544
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Parada-Loira F., IEEE INT VEH S
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ramirez A, 2014, IEEE INT VEH SYM, P96, DOI 10.1109/IVS.2014.6856598
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Simard PY., BEST PRACTICES CONVO
   Smedt QD., 2017, EUROGRAPHICS WORK 3D, P86
   Smedt QD., IEEE C COMP VIS PATT
   Song S., P 31 AAAI C ART INT
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Wang SB., IEEE COMP SOC C COMP
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Weng J., EUR C COMP VIS ECCV
   Xue YX, 2019, IEEE T COGN DEV SYST, V11, P162, DOI 10.1109/TCDS.2018.2800167
   Yan S., SPATIAL TEMPORAL GRA
   Yang YK, 2021, IEEE T COGN DEV SYST, V13, P141, DOI 10.1109/TCDS.2020.2969297
   Zhang P., VIEW ADAPTIVE RECURR
   Zhang P., ADDING ATTENTIVENESS
   Zhang P., SEMANTICS GUIDED NEU, DOI DOI 10.48550/ARXIV.1904.01189
   Zhang PF, 2020, IEEE T IMAGE PROCESS, V29, P1061, DOI 10.1109/TIP.2019.2937724
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zobl M, 2003, LECT NOTES ARTIF INT, V2915, P448
NR 58
TC 0
Z9 0
U1 2
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2207
EA AUG 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001159239800001
DA 2024-07-18
ER

PT J
AU Liang, H
   Xu, HM
   Wang, Y
   Pan, JJ
   Fu, JL
   Pang, XW
AF Liang, Hui
   Xu, Haoming
   Wang, Yi
   Pan, Junjun
   Fu, Jialin
   Pang, Xiangwen
TI Virtual emotional gestures to assist in the examination of the mental
   health of the deaf-mutes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deaf-mutes; EEG; gesture library; mental health
ID SERVICES; HEARING
AB The particular characteristics of deaf-mutes make them more likely to have mental health problems. Due to their particular way of communication, it is more difficult for them to deal with mental health problems than ordinary people. Nowadays, those psychologists who are good at sign language are in short supply, and remote assistance cannot achieve satisfactory results. Therefore, a library of virtual emotional gestures based on electroencephalogram (EEG) was established and a prototype system for mental health examination of deaf-mutes was proposed, which help deaf-mutes identify their psychological problems in time and assist medical staff to examine the psychological problems encountered by deaf-mutes. In addition, the virtual library of emotional gestures is established with the assistance of the chief physician from a 3A hospital in Henan Province. More importantly, the later experiments demonstrate the applicability of this virtual system.
C1 [Liang, Hui; Xu, Haoming; Pang, Xiangwen] Zhengzhou Univ Light Ind, Coll Software Engn, Zhengzhou, Peoples R China.
   [Wang, Yi] Pingmei Shenma Grp, Gen Hosp, Dept Geriatr, Pingdingshan, Peoples R China.
   [Pan, Junjun] Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
   [Fu, Jialin] Zhengzhou Univ Light Ind, Coll Econ & Management, Zhengzhou, Peoples R China.
C3 Zhengzhou University of Light Industry; Beihang University; Zhengzhou
   University of Light Industry
RP Liang, H (corresponding author), Zhengzhou Univ Light Ind, Coll Software Engn, Zhengzhou, Peoples R China.
EM hliang@zzuli.edu.cn
RI Pan, Junjun/A-1316-2013
OI Xu, Haoming/0009-0001-7276-8460
FU Scientific and Technological Project in Henan Province, China
   [222102210030]; National Natural Science Foundation of China [62072414]
FX ACKNOWLEDGMENTS The research leading to these results has received
   funding from the Scientific and Technological Project in Henan Province,
   China (No. 222102210030). This research was supported by the National
   Natural Science Foundation of China (No. 62072414).
CR Abrams Z, 2022, IEEE PULSE, V13, P16, DOI 10.1109/MPULS.2022.3208824
   Austen S, 2006, AM ANN DEAF, V151, P311, DOI 10.1353/aad.2006.0033
   Best Paul, 2022, J Technol Behav Sci, V7, P100, DOI 10.1007/s41347-021-00214-6
   Costello EJ, 2016, J CLIN CHILD ADOLESC, V45, P710, DOI 10.1080/15374416.2016.1236728
   Crowe TV, 2017, COMMUNITY MENT HLT J, V53, P154, DOI 10.1007/s10597-016-0025-3
   Derogatis L. R., 2011, Symptom Checklist-90-Revised
   Dreyzehner J, 2019, CHILD ADOL PSYCH CL, V28, P411, DOI 10.1016/j.chc.2019.02.011
   Garg S, 2021, INDIAN J COMMUN MED, V46, P11, DOI 10.4103/ijcm.IJCM_581_20
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hatami H, 2022, INT J METH PSYCH RES, V31, DOI 10.1002/mpr.1924
   Kim MK, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/573734
   Kyuseva MV, 2019, VOPR YAZYKOZNANIYA, P120, DOI 10.31857/S0373658X0006288-5
   Lake James, 2017, Perm J, V21, P17, DOI 10.7812/TPP/17-024
   McCloskey R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P857, DOI 10.1109/VRW55335.2022.00284
   McDonnall MC, 2017, J SOC WORK DISABIL R, V16, P1, DOI 10.1080/1536710X.2017.1260515
   Morris JD, 1995, J ADVERTISING RES, V35, P63
   Ng R., 2021, ACM IEEE INT C HUM R
   Nolan BAD, 2015, SOC WORK PUBLIC HLTH, V30, P462, DOI 10.1080/19371918.2015.1051261
   Ohrnberger J, 2017, SOC SCI MED, V195, P42, DOI 10.1016/j.socscimed.2017.11.008
   Papastratis I, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175843
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Ranjan R, 2022, IEEE INT SYM MED MEA, DOI 10.1109/MEMEA54994.2022.9856586
   Ren S Q., 2015, 29 ANN C NEURAL INFO
   Sakalle A, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/8362091
   Schioppo J., 2020, 15 IEEE INT C AUT FA
   Swanepoel B, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2020-038431
   Wen F, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25637-w
   Wu B, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.895196
   Zeng F., 2021, 2021 3 INT C MACH LE, P621
   Zhang SJ, 2020, J ELECTRON INF TECHN, V42, P1021, DOI 10.11999/JEIT190416
NR 31
TC 1
Z9 1
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2165
EA MAY 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000987237900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sahoo, SR
   Dash, R
   Mohapatra, RK
AF Sahoo, Sandhya Rani
   Dash, Ratnakar
   Mohapatra, Ramesh Kumar
TI A customized deep learning framework for skin lesion classification
   using dermoscopic images
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE complexity; convolutional neural network; dermoscopic image; skin lesion
   classification; transfer learning
ID FEATURES; CANCER; MODEL
AB Automated analysis of skin lesions in dermoscopy images has gained much attention due to its medical importance in the early detection of melanoma. Detection of lesions has become a challenge due to the strong visual similarity between benign and malignant skin lesions. In this research, a customized deep convolutional neural network (CNN) architecture has been designed to discriminate between benign and malignant lesions. The model is designed carefully with lesser convolution layers, fewer filters, and parameters to achieve better classification performance compared to pretrained VGG16, ResNet50, InceptionV3 models and, ensures state-of-the-art performance. The proposed model is composed of nine trainable layers: eight convolution layers and one fully connected layer. The suggested framework is extensively evaluated on the benchmark ISIC 2016 challenge dataset. The effect of different input transformations over the dataset has been studied. For fair comparison, standard deep learning models such as VGG16, ResNet50, and InceptionV3 have been used for lesion classification using transfer learning approach. The memory requirement of the proposed model is reduced by 388, 68, and 63 times and FLOPs needed are lowered by 95%, 85%, and 84% compared to VGG16-TrL, ResNet50-TrL, and InceptionV3-TrL, respectively. Results show that class balancing with external images improves classification performance.
C1 [Sahoo, Sandhya Rani; Dash, Ratnakar; Mohapatra, Ramesh Kumar] NIT Rourkela, Dept Comp Sci & Engn, Rourkela, Odisha, India.
   [Sahoo, Sandhya Rani] NIT Rourkela, CSE Dept, Pattern Recognit Lab, Rourkela, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; National Institute of Technology (NIT System);
   National Institute of Technology Rourkela
RP Sahoo, SR (corresponding author), NIT Rourkela, CSE Dept, Pattern Recognit Lab, Rourkela, Odisha, India.
EM sandhyasahoo137@gmail.com
RI Dash, Ratnakar/F-1498-2018
OI Sahoo, Sandhya/0000-0002-8421-3147
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Adegun A, 2021, ARTIF INTELL REV, V54, P811, DOI 10.1007/s10462-020-09865-y
   Ahn E., 2020, IEEE T MED IMAGING, V39, P1
   Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Amin J, 2020, PATTERN RECOGN LETT, V131, P63, DOI 10.1016/j.patrec.2019.11.042
   Araújo RL, 2022, MULTIMEDIA SYST, V28, P1239, DOI 10.1007/s00530-021-00840-3
   Byrd AL, 2018, NAT REV MICROBIOL, V16, P143, DOI 10.1038/nrmicro.2017.157
   Chatterjee S, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101581
   Chollet F., 2017, SIMON SCHUSTER
   Diepgen TL, 2012, J DTSCH DERMATOL GES, V10, P297, DOI 10.1111/j.1610-0387.2012.07890.x
   Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ghalejoogh GS, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113127
   Gutman D, 2016, ARXIV
   Hagerty JR, 2019, IEEE J BIOMED HEALTH, V23, P1385, DOI 10.1109/JBHI.2019.2891049
   Hameed N, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112961
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu K, 2019, BIOMED SIGNAL PROCES, V51, P200, DOI 10.1016/j.bspc.2019.02.018
   Iqbal I, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101843
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu SP, 2019, NEUROCOMPUTING, V338, P191, DOI 10.1016/j.neucom.2019.01.090
   Mahajan K, 2020, IEEE COMPUT SOC CONF, P3142, DOI 10.1109/CVPRW50498.2020.00373
   Mahbod A, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105725
   Mahbod A, 2019, COMPUT MED IMAG GRAP, V71, P19, DOI 10.1016/j.compmedimag.2018.10.007
   Mrázek J, 2019, FOLIA MICROBIOL, V64, P435, DOI 10.1007/s12223-018-00670-3
   Nayak DR, 2020, PATTERN RECOGN LETT, V138, P385, DOI 10.1016/j.patrec.2020.04.018
   Olimov Bekhzod, 2020, 2020 8th International Conference on Orange Technology (ICOT), DOI 10.1109/ICOT51877.2020.9468748
   Olimov B., 2021, P KOR SOC INF SCI, P576
   Olimov B, 2021, IEEE ACCESS, V9, P154194, DOI 10.1109/ACCESS.2021.3128607
   Olimov Bekhzod, 2020, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V23, P1349
   Olimov B, 2021, MULTIMEDIA SYST, V27, P637, DOI 10.1007/s00530-020-00726-w
   Pérez E, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101858
   Polyak BT., 1964, USSR Computational Mathematics and Mathematical Physics, V4, P1
   Putra TA, 2020, IEEE ACCESS, V8, P40536, DOI 10.1109/ACCESS.2020.2976045
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Sanjar K, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103658
   Satheesha TY, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2648797
   Serte S, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103423
   Shimizu K, 2015, IEEE T BIO-MED ENG, V62, P274, DOI 10.1109/TBME.2014.2348323
   Shorfuzzaman M, 2022, MULTIMEDIA SYST, V28, P1309, DOI 10.1007/s00530-021-00787-5
   Silveira M, 2009, IEEE J-STSP, V3, P35, DOI 10.1109/JSTSP.2008.2011119
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tschandl P, 2019, COMPUT BIOL MED, V104, P111, DOI 10.1016/j.compbiomed.2018.11.010
   Wahba MA, 2018, COMPUT METH PROG BIO, V165, P163, DOI 10.1016/j.cmpb.2018.08.009
   Xiao F, 2020, IET IMAGE PROCESS, V14, P2140, DOI 10.1049/iet-ipr.2019.1018
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
NR 47
TC 1
Z9 1
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2132
EA DEC 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000897576000001
DA 2024-07-18
ER

PT J
AU Alonso, GE
   Jin, XG
AF Elias Alonso, Guillermo
   Jin, Xiaogang
TI Skeleton-level control for multi-agent simulation through deep
   reinforcement learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; deep reinforcement learning; multi-agent simulation;
   skeletal motion
AB Multi-agent simulation has attracted much attention in the field of computer animation in the last decades for its ability to model interaction between autonomous micro level entities. It widely uses deep reinforcement learning (DRL), which allows us to model environments and its agents approaching real-world and human-level complexity, with applications in robotics and computer animation, among others. However, DRL multi-agent simulation faces additional challenges: they have to be able to generalize high-dimensional observations and relate them with a high-dimensional action space, maximizing long-term cumulated reward. Due to this, DRL systems with numerous interacting agents seldom consider skeleton-level action spaces. To this end, we present skeleton-level control for multi-agent simulation with DRL. With our method, we are able to procedurally generate real-time collision-free simulations directly on individual agents with a high-dimensional skeleton-level action space. The state in our DRL system includes the velocity of the agent, its destination, and the status of its joints, as well as visual-based information about the environment and other agents. Our reward function encourages motion into the target destinations, and enalizes collision. We provide extensive experimentation to show the ability of agents to reach their goal through its skeleton motion while successfully avoiding inter-collisions.
C1 [Elias Alonso, Guillermo; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
EM jin@cad.zju.edu.cn
OI Jin, Xiaogang/0000-0001-7339-2920
FU National Natural Science Foundation of China [62036010]; Ningbo Major
   Special Projects of the "Science and Technology Innovation 2025
   [2020Z007]
FX National Natural Science Foundation of China, Grant/Award Number:
   62036010; Ningbo Major Special Projects of the "Science and Technology
   Innovation 2025", Grant/Award Number: 2020Z007
CR Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Baker B., 2019, Emergent tool use from multi-agent autocurricula
   Busoniu L, 2010, STUD COMPUT INTELL, V310, P183
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Jiang MX, 2019, IEEE ACCESS, V7, P32400, DOI 10.1109/ACCESS.2019.2901300
   Jiang YF, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322966
   Juliani A., 2018, ARXIV180902627
   Junling Hu, 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P242
   Kakade Sham, 2002, ICML, P267, DOI DOI 10.5555/645531.656005
   Kwiatkowski A, 2022, COMPUT GRAPH FORUM, V41, P613, DOI 10.1111/cgf.14504
   Lee J., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508221
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Ling HY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392422
   Lopez A., 2019, MOTION INTERACTION G, P1
   Mordatch I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185539
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Peng XB, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3197517.3201311, 10.1145/3450626.3459670]
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Pérez-Dattari R, 2019, IEEE INT CONF ROBOT, P7611, DOI [10.1109/icra.2019.8793675, 10.1109/ICRA.2019.8793675]
   Raffin A, 2021, J MACH LEARN RES, V22, P1
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Schulman J., 2017, ARXIV
   Schulman J, 2015, ADV NEUR IN, V28
   Wang JM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618514
   Wang JH, 2012, ADV DIFFER EQU-NY, P1, DOI 10.1186/1687-1847-2012-96
   Wang L, 2021, IEEE T COGN COMMUN, V7, P73, DOI 10.1109/TCCN.2020.3027695
   Wei YY, 2021, IEEE INFOCOM SER, DOI 10.1109/INFOCOM42981.2021.9488669
   Won J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392381
   Yao ZZ, 2019, NEUROCOMPUTING, V366, P314, DOI 10.1016/j.neucom.2019.08.021
   Yin ZQ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459817
   Yu WH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201397
   Zhou W., 2022, Auton. Intell. Syst.., V2, P5
NR 33
TC 0
Z9 0
U1 5
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2079
DI 10.1002/cav.2079
EA JUN 2022
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000805670600001
DA 2024-07-18
ER

PT J
AU Wu, YH
   Wang, CX
AF Wu, Yuanhao
   Wang, Chenxing
TI Parallel-branch network for 3D human pose and shape estimation in video
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human pose estimation; parallel networks; transformer
AB Human pose and shape estimation have developed rapidly, where a skinned multi-person linear (SMPL) approach performs excellent recently. However, the prior template of the human body in the SMPL model is fixed, thus a deviation may be resulted in the reconstructed body shape if a human body acts sharp movements such as sporting or dancing. To address this problem, we propose a parallel-branch network including a designed spatial-temporal (ST) branch and a SMPL branch. The ST branch essentially performs the 2D-to-3D lifting for more accurate joint prediction, by the designed spatial transformer and temporal transformer. The 3D joints from the ST branch are used to supervise the 3D joints from the SMPL branch and further correct the deviation of the SMPL model. Experiments on some popular benchmarks like 3DPW and MPI-INF-3DHP show that our method has better performance than other methods with video input. Our code is available at
C1 [Wu, Yuanhao] Southeast Univ, Suzhou Res Inst, Nanjing, Peoples R China.
   [Wang, Chenxing] Southeast Univ, Nanjing, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Wang, CX (corresponding author), Southeast Univ, Nanjing, Peoples R China.
EM cxwang@seu.edu.cn
OI Wang, Chenxing/0000-0002-2906-1929; Wu, yuanhao/0000-0002-1556-7283
FU National Natural Science Foundation of P.R. China [61828501]
FX This work is supported by the National Natural Science Foundation of
   P.R. China (61828501).
CR Andriluka M, 2018, PROC CVPR IEEE, P5167, DOI 10.1109/CVPR.2018.00542
   Brau E, 2016, INT CONF 3D VISION, P582, DOI 10.1109/3DV.2016.84
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Ching-Hang Chen, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P5759, DOI 10.1109/CVPR.2017.610
   Choi H., 2020, COMPUTER VISION ECCV, P769
   Choi H, 2021, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR46437.2021.00200
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jiang H., 2010, ICPR, P1674, DOI DOI 10.1109/ICPR.2010.414
   Kanazawa A, 2019, PROC CVPR IEEE, P5597, DOI 10.1109/CVPR.2019.00576
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kocabas M, 2019, PROC CVPR IEEE, P1077, DOI 10.1109/CVPR.2019.00117
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Luan Tom H, 2021, ARXIV PREPRINT ARXIV
   Luo Z., 2020, ACCV
   Martinez Julieta, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2659, DOI 10.1109/ICCV.2017.288
   Moon G., 2020, COMPUTER VISION ECCV
   Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11159, DOI 10.1109/ICCV48922.2021.01099
   Sun Y, 2019, IEEE I CONF COMP VIS, P5348, DOI 10.1109/ICCV.2019.00545
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan ZN, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13013, DOI 10.1109/ICCV48922.2021.01279
   Yang S., 2020, arXiv preprint arXiv:2012.14214, 2
   Zhang WY, 2013, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2013.280
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
NR 36
TC 3
Z9 3
U1 2
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2078
DI 10.1002/cav.2078
EA JUN 2022
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000805659000001
DA 2024-07-18
ER

PT J
AU Deng, NC
   He, ZY
   Yang, XB
AF Deng, Nianchen
   He, Zhenyi
   Yang, Xubo
TI Render-based factorization for additive light field display
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE additive light field displays; light field factorization; real-time
ID NEAR-EYE DISPLAY; ACCOMMODATION; SYSTEM
AB Augmented Reality (AR) and Virtual Reality (VR) applications enable viewers to experience 3D graphics immersively. However, current hardware either fails to provide multiple viewpoints like projectors or cause conflicts between vergence and accommodation like consumable headsets. Prior researchers have designed multi-view displays to solve the problem by enabling view-dependent images and focus cues. Nevertheless, it requires minutes to calculate one frame, which is critical for real-time AR/VR applications. In this paper, we propose a new render-based factorization for additive light field display and further improve the performance by optimizing the initialization of layers. We next compare our work with the state of the art and the results show that our solution has competitive results while the calculation takes less than 20 ms for each frame.
C1 [Deng, Nianchen; Yang, Xubo] Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.
   [He, Zhenyi] NYU, New York, NY USA.
C3 Shanghai Jiao Tong University; New York University
RP Yang, XB (corresponding author), Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.
EM yangxubo@sjtu.edu.cn
RI He, Zhenyi/IXD-6881-2023; Deng, Nianchen/GXZ-4749-2022
OI Deng, Nianchen/0000-0002-5292-266X
FU National Key Research and Development Program of China [2018YFB1004902]
FX This work was partially supported by the National Key Research and
   Development Program of China (2018YFB1004902).
CR Akeley K, 2004, ACM T GRAPHIC, V23, P804, DOI 10.1145/1015706.1015804
   [Anonymous], 1991, COMPUTATIONAL MODELS
   Bos P.J., 2016, SID Digest, P354
   Downing E, 1996, SCIENCE, V273, P1185, DOI 10.1126/science.273.5279.1185
   Dunn D, 2017, IEEE T VIS COMPUT GR, V23, P1275, DOI 10.1109/TVCG.2017.2657058
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Heide F., 2013, ACM Trans. Graph. (Proc. SIGGRAPH), V32, P1
   Hu XD, 2014, OPT EXPRESS, V22, P13896, DOI 10.1364/OE.22.013896
   Huang F.-C., 2015, SIGGRAPH EMERGING TE, P24
   Huang FC, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601122
   Kim D, 2018, OPT EXPRESS, V26, P17170, DOI 10.1364/OE.26.017170
   Koulieris GA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073622
   Lanman D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508366
   Lawton G, 2011, COMPUTER, V44, P17, DOI 10.1109/MC.2011.3
   Lee CK, 2016, OPT EXPRESS, V24, P19531, DOI 10.1364/OE.24.019531
   Lee S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925971
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Liao H., 2006, P VIRT REAL C MAR, P314
   MacKenzie KJ, 2010, J VISION, V10, DOI 10.1167/10.8.22
   Maimone A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073624
   Maruyama K, 2020, IEEE ACCESS, V8, P38767, DOI 10.1109/ACCESS.2020.2975209
   Meng XH, 2020, INT J NEUROSCI, V130, P1267, DOI 10.1080/00207454.2020.1731504
   Mori S, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P292, DOI [10.1109/ISMAR-Adjunct.2016.0098, 10.1109/ISMAR-Adjunct.2016.89]
   Neil MAA, 1997, P SOC PHOTO-OPT INS, V3012, P337, DOI 10.1117/12.274495
   Park HS, 2015, OPT EXPRESS, V23, P30618, DOI 10.1364/OE.23.030618
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Sun Q, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130807
   Wang Z, 2020, OPT LETT, V45, P615, DOI 10.1364/OL.383508
   Wetzstein G, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185576
   Yeom HJ, 2015, OPT EXPRESS, V23, P32025, DOI 10.1364/OE.23.032025
   Yoshida S., 2011, DIGITAL HOLOGRAPHY 3
   Yu H, 2019, IEEE T VIS COMPUT GR, V25, P1940, DOI 10.1109/TVCG.2019.2898821
   Zhan T, 2018, OPT EXPRESS, V26, P4863, DOI 10.1364/OE.26.004863
NR 33
TC 2
Z9 2
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2010
DI 10.1002/cav.2010
EA JUN 2021
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000662160600001
DA 2024-07-18
ER

PT J
AU Zhou, C
   Lai, ZJ
   Wang, SZ
   Li, LC
   Sun, XH
   Ding, Y
AF Zhou, Chi
   Lai, Zhangjiong
   Wang, Suzhen
   Li, Lincheng
   Sun, Xiaohan
   Ding, Yu
TI Learning a deep motion interpolation network for human skeleton
   animations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE image inpainting; motion control; motion interpolation; animation; deep
   learning
AB Motion interpolation technology produces transition motion frames between two discrete movements. It is wildly used in video games, virtual reality and augmented reality. In the fields of computer graphics and animations, our data-driven method generates transition motions of two arbitrary animations without additional control signals. In this work, we propose a novel carefully designed deep learning framework, named deep motion interpolation network (DMIN), to learn human movement habits from a real dataset and then to perform the interpolation function specific for human motions. It is a data-driven approach to capture overall rhythm of two given discrete movements and generate natural in-between motion frames. The sequence-by-sequence architecture allows completing all missing frames within single forward inference, which reduces computation time for interpolation. Experiments on human motion datasets show that our network achieves promising interpolation performance. The ablation study demonstrates the effectiveness of the carefully designed DMIN.(1)
C1 [Zhou, Chi; Li, Lincheng; Sun, Xiaohan; Ding, Yu] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
   [Zhou, Chi; Lai, Zhangjiong; Wang, Suzhen; Li, Lincheng; Ding, Yu] Netease Fuxi AI Lab, Virtual Human Grp, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Ding, Y (corresponding author), Netease Fuxi AI Lab, Virtual Human Grp, Hangzhou, Zhejiang, Peoples R China.
EM elonzhou@zju.edu.cn; dingyu01@corp.netease.com
RI li, lincheng/AAR-3978-2020
CR Casas D., 2012, P ACM SIGGRAPH S INT, P103, DOI DOI 10.1145/2159616.2159633
   Dam Erik B., 1998, Quaternions, Interpolation and Animation, P42, DOI DOI 10.1145/3422622
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Harvey FG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392480
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Henter GE, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417836
   Hong X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2033, DOI 10.1145/3343031.3351002
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Kovar L, 2008, ACM SIGGRAPH 2008 CL, DOI [DOI 10.1145/1401132.1401202, 10.1145/1401132.1401202]
   Pavllo Dario, 2018, BRIT MACH VIS C, DOI [10.1109/HUMANOIDS.2018.8624922, DOI 10.1109/HUMANOIDS.2018.8624922]
   Ramachandran P., 2017, Searching for activation functions
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruiz AH, 2019, IEEE I CONF COMP VIS, P7133, DOI 10.1109/ICCV.2019.00723
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Zhao H, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4069
NR 18
TC 0
Z9 1
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2003
DI 10.1002/cav.2003
EA MAY 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000653746400001
DA 2024-07-18
ER

PT J
AU Hou, Y
   Luo, HZ
   Zhao, WQ
   Zhang, X
   Wang, J
   Peng, JY
AF Hou, Yong
   Luo, Hangzai
   Zhao, Wanqing
   Zhang, Xiang
   Wang, Jun
   Peng, Jinye
TI Multilayer feature descriptors fusion CNN models for fine-grained visual
   recognition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE convolutional neural network; deep learning; dimensionality reduction;
   fine-grained image classification; multilayer feature descriptors
AB Fine-grained image classification is a challenging topic in the field of computer vision. General models based on first-order local features cannot achieve acceptable performance because the features are not so efficient in capturing fine-grained difference. A bilinear convolutional neural network (CNN) model exhibits that a second-order statistical feature is more efficient in capturing fine-grained difference than a first-order local feature. However, this framework only considers the extraction of a second-order feature descriptor, using a single convolutional layer. The potential effective classification features of other convolutional layers are ignored, resulting in loss of recognition accuracy. In this paper, a multilayer feature descriptors fusion CNN model is proposed. It fully considers the second-order feature descriptors and the first-order local feature descriptor generated by different layers. Experimental verification was carried out on fine-grained classification benchmark data sets, CUB-200-2011, Stanford Cars, and FGVC-aircraft. Compared with the bilinear CNN model, the proposed method has improved accuracy by 0.8%, 1.1%, and 5.5%. Compared with the compact bilinear pooling model, there is an accuracy increase of 0.64%, 1.63%, and 1.45%, respectively. In addition, the proposed model effectively uses multiple 1x1 convolution kernels to reduce dimension. The experimental results show that the multilayer low-dimensional second-order feature descriptors fusion model has comparable recognition accuracy of the original model.
C1 [Hou, Yong; Luo, Hangzai; Zhao, Wanqing; Zhang, Xiang; Wang, Jun; Peng, Jinye] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
C3 Northwest University Xi'an
RP Luo, HZ (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
EM hzluo@nwu.edu.cn
RI Peng, Jin/HZH-6965-2023; Zhao, Wanqing/ADL-9932-2022
OI Zhang, Xiang/0000-0001-8521-569X; Zhao, Wanqing/0000-0001-7622-0665;
   Hou, yong/0000-0001-8608-8960
FU National Key Technology Research and Development Program of China
   [2018YFB0204100]
FX The National Key Technology Research and Development Program of China,
   Grant/Award Number: 2018YFB0204100
CR [Anonymous], 2013, Tech. rep.
   [Anonymous], 2011, Technical Report CNS-TR-2011-001
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P EUR C COMP VIS 201
   [Anonymous], P 19 ACM SIGKDD INT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2014, BRIT C MACH VIS
   [Anonymous], 2017, 2017 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2017.106
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], P 2012 IEEE C COMP V
   [Anonymous], 2014, ABS14053531 CORR
   [Anonymous], P 15 INT C ART INT S
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], P EUR C COMP VIS 201
   [Anonymous], 2009, P 2009 IEEE C COMP V
   [Anonymous], 2015, P IEEE INT C COMP VI
   [Anonymous], 2013, P IEEE INT C COMP VI
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   He K, 2017, IEEE INT WORKSH MULT
   Hu J., 2020, P IEEE C COMP VIS PA
   Huang GL, 2017, IEEE ICC
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
NR 27
TC 5
Z9 5
U1 1
U2 32
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1897
DI 10.1002/cav.1897
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400016
DA 2024-07-18
ER

PT J
AU Chen, KY
   Liang, HN
   Yue, Y
   Craig, P
AF Chen, Keyu
   Liang, Hai-Ning
   Yue, Yong
   Craig, Paul
TI Infrared motion detection and electromyographic gesture recognition for
   navigating 3D environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE 3D environments; input devices; Leap Motion; mid-air interaction; Myo
   Armband; navigation; user studies
ID 2ND LIFE
AB This research explores the suitability and effectiveness of two relatively new types of input device for navigating 3D virtual environments. These are infrared motion detection, like the Leap Motion tracker, and electromyographic gesture recognition, like the Myo Armband. Despite the introduction of a variety of new input devices intended to provide a more natural interaction experience, navigation within 3D virtual environments is still normally done on more traditional control devices such as game controllers or the keyboard-mouse combination. This study investigates the potential of new devices to support navigation in 3D environments through an experiment conducted with 27 participants using three different types of input devices to play a ball-balancing maze-like game. The input devices tested are a standard game controller, a Leap Motion tracker for infrared motion detection, and the Myo Armband for electromyographic gesture recognition. Results demonstrated the real potential of both types of device to support navigation interaction within 3D environments.
C1 [Chen, Keyu; Liang, Hai-Ning; Yue, Yong; Craig, Paul] Xian Jiaotong Liverpool Univ, Dept Comp Sci & Software Engn, Suzhou, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Dept Comp Sci & Software Engn, Suzhou, Peoples R China.
EM haining.liang@xjtlu.edu.cn
OI Craig, Paul/0000-0002-9991-8238; Yue, Yong/0000-0001-7695-4538; Liang,
   Hai-Ning/0000-0003-3600-8955
FU XJTLU Key Program Special Fund [KSF-A-03]
FX XJTLU Key Program Special Fund, Grant/Award Number: KSF-A-03
CR Bachmann D, 2015, SENSORS-BASEL, V15, P214, DOI 10.3390/s150100214
   Boulos MNK, 2007, HEALTH INFO LIBR J, V24, P233, DOI 10.1111/J.1471-1842.2007.00733.x
   Bruder G, 2013, P 1 S SPAT US INT 20
   Cabreira AT, 2015, P 2015 BRIT HCI C 20
   Cheng G, 2014, COMPUT EDUC, V70, P105, DOI 10.1016/j.compedu.2013.08.011
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Ebert LC, 2014, J FORENSIC RADIOL IM, V2, P126, DOI 10.1016/j.jofri.2014.05.006
   Falcao C, 2015, PROCEDIA MANUF, V3, P5490, DOI 10.1016/j.promfg.2015.07.697
   Fernandes F, 2016, P 2016 IEEE 17 S VIR
   Guna J, 2014, SENSORS-BASEL, V14, P3702, DOI 10.3390/s140203702
   Hincapie-Ramos JD, 2014, P 2014 COMP PUBL DES
   Kamaishi S, 2016, P 10 ACM INT C UB IN
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Liang HN, 2009, INTERACT LEARN ENVIR, V17, P53, DOI 10.1080/10494820701610605
   Luh GC, 2015, P INT C MACH LEARN C
   McLeod PL, 2014, COMPUT HUM BEHAV, V39, P59, DOI 10.1016/j.chb.2014.06.025
   Moser C, 2015, P 14 INT C INT DES C
   Nancel M, 2011, P SIGCHI C HUM FACT
   Nestorov N, 2016, P 29 IEEE S COMP BAS
   Sathiyanarayanan M, 2015, PROCEDIA COMPUT SCI, V58, P50, DOI 10.1016/j.procs.2015.08.008
   Silva ECP, 2015, P 14 BRAZ S COMP GAM
   Simos M, 2016, 9TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2016), DOI 10.1145/2903220.2903249
   Sreejith M, 2015, P 5 NAT C COMP VIS P
   Yang C, 2016, P IEEE INT C INT ROB
NR 24
TC 2
Z9 2
U1 1
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1829
DI 10.1002/cav.1829
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100020
DA 2024-07-18
ER

PT J
AU Jiang, M
   Southern, R
   Zhang, JJ
AF Jiang, Min
   Southern, Richard
   Zhang, Jiang J.
TI Energy-based dissolution simulation using SPH sampling
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dissolution; fluid simulation; sampling; smoothed particle hydrodynamics
ID FLUID
AB A novel unified particle-based method is proposed for real-time dissolution simulation that is fast, predictable, independent of sampling resolution, and visually plausible. The dissolution model is derived from collision theory and integrated into a smoothed particle hydrodynamics fluid solver. Dissolution occurs when a solute is submerged in solvent. Physical laws govern the local excitation of solute particles based on kinetic energy: when the local excitation energy exceeds a user-specified threshold (activation energy), the particle will be dislodged from the solid. Solute separation during dissolution is handled using a new Graphics Processing Unit (GPU)-based region growing method. The use of smoothed particle hydrodynamics sampling for both solute and solvent guarantees a predictable and smooth dissolution process and provides user control of the volume change during the phase transition. A mathematical relationship between the activation energy and dissolution time allows for intuitive artistic control over the global dissolution rate. We demonstrate this method using a number of practical examples, including antacid pills dissolving in water, hydraulic erosion of nonhomogeneous terrains, and melting.
C1 [Jiang, Min] Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
   [Southern, Richard] Bournemouth Univ, Natl Ctr Comp Animat, Res, Poole, Dorset, England.
   [Zhang, Jiang J.] Bournemouth Univ, Natl Ctr Comp Animat, Comp Graph, Poole, Dorset, England.
C3 Bournemouth University; Bournemouth University; Bournemouth University
RP Southern, R (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
EM rsouthern@bournemouth.ac.uk
RI JIANG, MIN/KSM-4856-2024
OI Southern, Richard/0000-0002-1933-3951; Zhang, Jian/0000-0002-7069-5771
CR Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Alliez P, 2015, CGAL 3D FAST INTERSE
   AMADA T, 2006, GAME GEMS, V6, P189
   [Anonymous], 2014, RIGID BODY DYNAMICS
   [Anonymous], 2007, P SIGGRAPH SKETCH SA
   Baatz M., 2000, Multiresolution Segmentation: an optimization approach for high quality multi-scale image segmentation, DOI DOI 10.1016/J.ISPRSJPRS.2003.10.002
   Batty C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276502
   Becker M, 2009, IEEE T VIS COMPUT GR, V15, P493, DOI 10.1109/TVCG.2008.107
   Benes B, 2006, COMPUT ANIMAT VIRT W, V17, P99, DOI 10.1002/cav.77
   Bærentzen JA, 2005, IEEE T VIS COMPUT GR, V11, P243, DOI 10.1109/TVCG.2005.49
   Busaryev O, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185559
   Carlson M, 2004, ACM T GRAPHIC, V23, P377, DOI 10.1145/1015706.1015733
   Charypar D., 2003, P 2003 ACM SIGGRAPH
   Clark JohnO.E., 2004, ESSENTIAL DICT SCI
   Cleary PW, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239548, 10.1145/1276377.1276499]
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Genevaux O, 2003, P GRAPH INT 2003 C C, P1
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Happ PN, 2013, IEEE GEOSCI REMOTE S, V10, P1612, DOI 10.1109/LGRS.2013.2272665
   Harada T, 2007, P APCOM
   Hoetzlein R. C., 2014, GPU TECHN C GTC
   Hojjatoleslami SA, 1998, IEEE T IMAGE PROCESS, V7, P1079, DOI 10.1109/83.701170
   Ihmsen M., 2014, Eurographics 2014-State of the Art Reports
   Ihmsen M, 2012, VISUAL COMPUT, V28, P669, DOI 10.1007/s00371-012-0697-9
   Jiang M, 2015, PARTICLE BASED DISSO, P285
   Jiang M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818102
   Jones MW, 2006, IEEE T VIS COMPUT GR, V12, P581, DOI 10.1109/TVCG.2006.56
   Kim D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778807
   Kravtchenko TP, 1999, FOOD HYDROCOLLOID, V13, P219, DOI 10.1016/S0268-005X(99)00002-8
   Kristof P, 2009, COMPUT GRAPH FORUM, V28, P219, DOI 10.1111/j.1467-8659.2009.01361.x
   LUCY LB, 1977, ASTRON J, V82, P1013, DOI 10.1086/112164
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   McNaught A. D., 1997, IUPAC Compendium of Chemical Terminology: Gold Book
   PAYNE BA, 1992, IEEE COMPUT GRAPH, V12, P65, DOI 10.1109/38.135885
   Robinson-Mosher A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360645
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Shin SH, 2010, COMPUT GRAPH FORUM, V29, P675, DOI 10.1111/j.1467-8659.2009.01637.x
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Stomakhin A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601176
   Trautz M, 1916, Z ANORG ALLG CHEM, V96, P1, DOI 10.1002/zaac.19160960102
   Wojtan C, 2007, P 3 EUR CNAT PHEN AI
NR 42
TC 2
Z9 2
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2018
VL 29
IS 2
AR e1798
DI 10.1002/cav.1798
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GD0DX
UT WOS:000430170900001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Ruiz, ALC
   Pontonnier, C
   Levy, J
   Dumont, G
AF Ruiz, Ana Lucia Cruz
   Pontonnier, Charles
   Levy, Jonathan
   Dumont, Georges
TI A synergy-based control solution for overactuated characters:
   Application to throwing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion synthesis; muscles; musculoskeletal model; optimization;
   physics-based animation
ID POSITIVE FORCE FEEDBACK; MUSCLE SYNERGIES; UPPER EXTREMITY;
   MUSCULOSKELETAL; MOVEMENTS; SYSTEMS; MOTION; MODEL
AB In the current paper, we present a bio-inspired solution for the control of overactuated models in animation, such as musculoskeletal models. This solution consists in the extraction of muscle synergies from human experiments, followed by a control method consisting of a series of optimizations to adapt muscle parameters and synergies to match experimental data. We apply the framework on throwing motions, and the results show that these motions can be accurately reproduced on a character with a simplified muscular structure, while preserving important characteristics in the original synergies or control signals.
C1 [Pontonnier, Charles] Ecoles St Cyr Coetquidan, Guer, France.
   [Ruiz, Ana Lucia Cruz] INRIA IRISA, MimeTic Res Team, Rennes, France.
   [Pontonnier, Charles; Dumont, Georges] INRIA IRISA, Rennes, France.
   [Ruiz, Ana Lucia Cruz; Pontonnier, Charles] Ecole Normale Super Rennes, Bruz, France.
   [Levy, Jonathan] Ecole Normale Super Rennes, Dept Mechatron, Bruz, France.
   [Dumont, Georges] Ecole Normale Super Rennes, Mech Sci, Bruz, France.
C3 Universite de Rennes; Universite de Rennes; Ecole Normale Superieure de
   Rennes (ENS Rennes); Ecole Normale Superieure de Rennes (ENS Rennes);
   Ecole Normale Superieure de Rennes (ENS Rennes)
RP Ruiz, ALC (corresponding author), INRIA, Rennes, France.
EM ana-lucia.cruz-ruiz@inria.fr
RI DUMONT, Georges/K-8173-2013
OI DUMONT, Georges/0000-0002-0709-0921; Pontonnier,
   Charles/0000-0003-1140-3772
FU ANR project ENTRACTE [ANR 13-CORD-002-0]
FX ANR project ENTRACTE, Grant/Award Number: ANR 13-CORD-002-0
CR Alessandro C, 2013, FRONT COMPUT NEUROSC, V7, DOI 10.3389/fncom.2013.00043
   Bernshtein N.A., 1967, The co-ordination and regulation of movements
   Buchanan TS, 2004, J APPL BIOMECH, V20, P367, DOI 10.1123/jab.20.4.367
   Cruz Ruiz A. L., 2015, P 8 ACM SIGGRAPH C M, P65
   CruzRuiz AL, 2016, COMPUT GRAPH FORUM
   d'Avella A, 2013, FRONT COMPUT NEUROSC, V7, DOI 10.3389/fncom.2013.00042
   Damsgaard M, 2006, SIMUL MODEL PRACT TH, V14, P1100, DOI 10.1016/j.simpat.2006.09.001
   de Zee M, 2007, J BIOMECH, V40, P1219, DOI 10.1016/j.jbiomech.2006.05.030
   Dumas R, 2007, J BIOMECH, V40, P543, DOI 10.1016/j.jbiomech.2006.02.013
   Erdemir A, 2007, CLIN BIOMECH, V22, P131, DOI 10.1016/j.clinbiomech.2006.09.005
   Geijtenbeek T, 2012, COMPUT GRAPH FORUM, V31, P2492, DOI 10.1111/j.1467-8659.2012.03189.x
   Geijtenbeek T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508399
   Gerritsen K G, 1998, Motor Control, V2, P206
   Geyer H, 2003, P ROY SOC B-BIOL SCI, V270, P2173, DOI 10.1098/rspb.2003.2454
   Geyer H, 2010, IEEE T NEUR SYS REH, V18, P263, DOI 10.1109/TNSRE.2010.2047592
   Hermens H J., 1999, Roessingh Res Dev, V8, P13
   Hill AV, 1938, PROC R SOC SER B-BIO, V126, P136, DOI 10.1098/rspb.1938.0050
   Hirashima M, 2002, J SPORT SCI, V20, P301, DOI 10.1080/026404102753576071
   Hodgins J. K., 1998, Robotics Research. Eighth International Symposium, P356
   Holzbaur KRS, 2005, ANN BIOMED ENG, V33, P829, DOI 10.1007/s10439-005-3320-7
   Horsman MDK, 2007, CLIN BIOMECH, V22, P239, DOI 10.1016/j.clinbiomech.2006.10.003
   Houk JC, 2011, NEURAL CONTROL MUSCL
   Jain S, 2011, ACM T GRAPHIC, V30
   Kim H, 2008, SIAM J MATRIX ANAL A, V30, P713, DOI 10.1137/07069239X
   Kim JH, 2010, MULTIBODY SYST DYN, V24, P1, DOI 10.1007/s11044-010-9193-z
   Komura T, 2000, VISUAL COMPUT, V16, P254, DOI 10.1007/s003719900065
   Konrad P., 2005, ABC EMG PRACTICAL IN, DOI DOI 10.1016/J.JACC.2008.05.066
   Lee JB, 1999, INT J SPORTS MED, V20, P7, DOI 10.1055/s-2007-971083
   Lee Y, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661233
   Mordatch I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508365
   Muller A, 2015, COMPUT METHOD BIOMEC, V18, P2008, DOI 10.1080/10255842.2015.1069599
   Muller A, 2015, 33 INT C BIOM SPORTS
   Prochazka A, 1997, J NEUROPHYSIOL, V77, P3226, DOI 10.1152/jn.1997.77.6.3226
   Rengifo C, 2010, J BIOMECH ENG-T ASME, V132, DOI 10.1115/1.4001116
   Ruiz ALC, 2015, COMPUT METHOD BIOMEC, V18, P1918, DOI 10.1080/10255842.2015.1070581
   Ruiz ALC, 2014, COMPUT METHOD BIOMEC, V17, P174, DOI 10.1080/10255842.2014.931658
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Sakurai S, 2000, J SPORT SCI, V18, P901, DOI 10.1080/026404100750017832
   Si WG, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2626346
   Ting LH, 2007, PROG BRAIN RES, V165, P299, DOI 10.1016/S0079-6123(06)65019-X
   Tresch MC, 2006, J NEUROPHYSIOL, V95, P2199, DOI 10.1152/jn.00222.2005
   van der Krogt MM, 2009, J APPL PHYSIOL, V107, P801, DOI 10.1152/japplphysiol.91189.2008
   VANSOEST AJ, 1993, BIOL CYBERN, V69, P195, DOI 10.1007/BF00198959
   Venture G, 2005, IEEE-RAS INT C HUMAN, P351
   VENTURE G, 2006, IFAC INT C SYST ID, P1168
   Wangs JM, 2012, ACM T GRAPHIC, V31
   Willigenburg NW, 2012, J ELECTROMYOGR KINES, V22, P485, DOI 10.1016/j.jelekin.2012.01.001
   Ye YT, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409065
   Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556
NR 49
TC 1
Z9 1
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2017
VL 28
IS 6
AR e1743
DI 10.1002/cav.1743
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9YH
UT WOS:000417254100003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Balint, JT
   Allbeck, J
AF Balint, J. Timothy
   Allbeck, Jan
TI ALET: Agents Learning their Environment through Text
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE autonomous actors; intelligent virtual humans; semantic virtual
   environments
AB For intelligent virtual humans to interact in a rich environment, connections between the usable actions and objects must be defined. For scenarios consisting of hundreds of object types and many actions, having a simulation author create these connections by hand becomes and difficult. This limitation causes the simulation to have only a few object connections, whereas the rest of the objects are static and cannot be acted upon. Automated methods to connect objects to actions are promising but incomplete as they still miss key interactions and are unable to determine important characteristics of each action such as the manner of the action. We present Agents Learning their Environment through Text (ALET) to connect graphical objects to actions and provide an understanding of the actions. Observing that text contains descriptions of actions and connections to objects, ALET leverages large text corpora, and knowledge bases to provide candidate connections and descriptions for the actions and objects available in a simulation. The candidate connections and descriptions populate a representation that describes the graphical models and animations. We test ALET against other semantic generation methods, and find it more accurately determines object roles in actions, as well as determines semantic information about the action.
C1 [Balint, J. Timothy; Allbeck, Jan] George Mason Univ, Comp Sci, Fairfax, VA 22030 USA.
C3 George Mason University
RP Balint, JT (corresponding author), George Mason Univ, Fairfax, VA 22030 USA.
EM jbalint2@gmu.edu
OI Balint, J. Timothy/0000-0002-5940-8495
CR [Anonymous], 2000, Reasoning About Rational Agents
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2004, Workshop on Generative Model Based Vision
   Baker C.F., 1998, P 36 ANN M ASS COMP, P86, DOI [DOI 10.3115/980845.980860, DOI 10.3115/980451.980860]
   Balint JT, 2015, INT IND TRAIN SIM ED, P15227
   Balint JT, 2016, WORKSH VIRT HUM CROW, P5
   Bindiganavale R., 2000, Proceedings of the Fourth International Conference on Autonomous Agents, P293, DOI 10.1145/336595.337503
   Bureau of LS, 2010, TECHNICAL REPORT
   de Marneffe MC, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4585
   Donikian S, 2008, LECT NOTES COMPUT SC, V5277, P51
   Farenc N, 2000, APPL ARTIF INTELL, V14, P69, DOI 10.1080/088395100117160
   Fast E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P237, DOI 10.1145/2858036.2858528
   FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5
   Guerra-Filho G, 2012, IMAGE VISION COMPUT, V30, P251, DOI 10.1016/j.imavis.2011.12.002
   Guzdial M., 2015, International Conference on the Foundations of Digital Games, P9
   Kallmann M., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P124, DOI 10.1145/323663.323683
   Kessing J, 2009, LECT NOTES COMPUT SC, V5709, P276, DOI 10.1007/978-3-642-04052-8_33
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lugrin JL, 2007, 2007 INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P225
   Pelkey CD, 2014, COMPUT ANIMAT VIRT W, V25, P405, DOI 10.1002/cav.1587
   Pellens B, 2005, VIRTUAL CONCEPT, P69
   Peters C., 2003, Proceedings of 11th International Conference in Central Europe on Computer Graphics, P11
   Quinn AJ, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1403
   Rouhizadeh M., 2011, Ninth International Conference on Computational Semantics, P380
   Sequeira P, 2007, AAMAS
   Shoulson A, 2013, EVENT CENTRIC PLANNI, P121
   Shoulson A., 2013, Intelligent Narrative Technologies, V6, P216
   Slater M, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00003
   TheUniversity of Tokyo, 2003, ICS ACT DAT
   Thiebaux Marcus., 2008, P AAMAS 08, P151
   TUTENEL T., 2008, Computers in Entertainment CIE, V6, P57
   Tutenel T., 2009, Proceedings of the CASA Workshop on 3D Advanced Media In Gaming And Simulation, P10
   van Kaick O, 2011, COMPUT GRAPH FORUM, P553
   van Oijen J., 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P46, DOI 10.1109/WI-IAT.2011.176
NR 34
TC 0
Z9 1
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1759
DI 10.1002/cav.1759
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200006
DA 2024-07-18
ER

PT J
AU Xing, WW
   Wang, WQ
   Bao, P
   Sun, LY
   Tong, LM
AF Xing Weiwei
   Wang Weiqiang
   Bao Peng
   Sun Liya
   Tong Leiming
TI A novel method for automated human behavior segmentation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion capture; human behavior segmentation; posture histogram; sliding
   window; posture features; outlier detection
ID MOTION CAPTURE DATA; REHABILITATION; SYSTEM
AB In order to conveniently classify, retrieve, and synthesize human motion, motion capture (MoCap) data need to be properly segmented into distinct behaviors. In this paper, we propose a novel automated segmentation method based on posture histograms in sliding window. Firstly, a set of new posture features are proposed and defined to construct the posture histogram, which is a new compact representation of behavioral features. Then, by executing the sliding window, especially in this paper, the behavior features are analyzed in subsequence level to reduce noise sensitivity. We open up a novel way to tune sliding window by studying steady states of human behaviors, so that conspicuous and stable behavioral features can be obtained. Finally, by analyzing the clustering property of posture histograms of the subsequences, the behavior segmentation problem is tactfully simplified to the detection of outlier subsequence. In particular, the local outlier factor algorithm is adopted to solve outlier subsequence detection, and good results are achieved. Extensive experiments are conducted on 14 pieces of multi-behavior MoCap data from the CMU database,(dagger) and the experimental results demonstrate that our proposed method outperforms other state-of-the-art ones. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Xing Weiwei; Wang Weiqiang; Bao Peng; Sun Liya; Tong Leiming] Beijing Jiaotong Univ, Sch Software Engn, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Xing, WW (corresponding author), Beijing Jiaotong Univ, Sch Software Engn, Beijing, Peoples R China.
EM wwxing@bjtu.edu.cn
RI bao, peng/C-5665-2008
FU National Natural Science Foundation of China [61100143, 61272353,
   61370128]; Program for New Century Excellent Talents in University
   [NCET-13-0659]; Beijing Higher Education Young Elite Teacher Project
   [YETP0583]; Fundamental Research Funds for the Central Universities
   [2014JBZ004, 2015RC031]
FX This work is supported in part by the National Natural Science
   Foundation of China (nos. 61100143, 61272353, and 61370128), Program for
   New Century Excellent Talents in University (NCET-13-0659), Beijing
   Higher Education Young Elite Teacher Project (YETP0583), and Fundamental
   Research Funds for the Central Universities (2014JBZ004 and 2015RC031).
CR [Anonymous], 2009, P 2009 ACM SIGGRAPH
   [Anonymous], 2007, COMPUTER GRAPHICS TE
   [Anonymous], ACM T GRAPHICS
   [Anonymous], 2014, P 2014 ACM SIGGRAPHE
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Balazia Michal, 2014, Database and Expert Systems Applications 25th International Conference (DEXA 2014). Proceedings. LNCS 8644, P423, DOI 10.1007/978-3-319-10073-9_36
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Beaudoin P., 2008, P 2008 ACM SIGGRAPHE, P117
   Bernard J, 2013, IEEE T VIS COMPUT GR, V19, P2257, DOI 10.1109/TVCG.2013.178
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Fern'ndez-Baena A., 2012, 2012 4th International Conference on Intelligent Networking and Collaborative Systems (INCoS 2012), P656, DOI 10.1109/iNCoS.2012.66
   Fitzgerald D, 2007, P ANN INT IEEE EMBS, P4870, DOI 10.1109/IEMBS.2007.4353431
   Fod A, 2002, AUTON ROBOT, V12, P39, DOI 10.1023/A:1013254724861
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Goh A, 2007, IEEE C COMPUTER VISI, P1
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lan RY, 2015, VISUAL COMPUT, V31, P35, DOI 10.1007/s00371-013-0902-5
   Lau N, 2009, J BIOMECH, V42, P436, DOI 10.1016/j.jbiomech.2008.11.038
   Lin CD, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, VOLS 1 AND 2, P1
   López-Méndez A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.49
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Park W, 2008, IEEE T SYST MAN CY A, V38, P513, DOI 10.1109/TSMCA.2008.918588
   Pasciuto I, 2014, MULTIBODY SYST DYN, V32, P27, DOI 10.1007/s11044-013-9395-2
   Person JG, 2001, SURG ENDOSC-ULTRAS, V15, P997, DOI 10.1007/s004640080155
   Sousa P, 2011, LECT NOTES ARTIF INT, V7026, P392, DOI 10.1007/978-3-642-24769-9_29
   Souvenir R, 2005, IEEE I CONF COMP VIS, P648
   Xiao J, 2010, MULTIMED TOOLS APPL, V47, P379, DOI 10.1007/s11042-009-0329-1
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
NR 31
TC 1
Z9 2
U1 0
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2016
VL 27
IS 5
BP 501
EP 514
DI 10.1002/cav.1690
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DZ1QS
UT WOS:000385614100004
DA 2024-07-18
ER

PT J
AU Choi, MG
   Lee, KH
AF Choi, Myung Geol
   Lee, Kang Hoon
TI Interactive control of big-object manipulation animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE character animation; human body posture; physically based approach;
   big-object; interactive control
ID MOTION SYNTHESIS
AB We present a method for the interactive control of big-object manipulation animation. When a human character holds a big arbitrarily shaped object, it should use the whole upper body, including both arms and the torso in a limited range such that the holding postures can be physically as well as visually believable to users. In our method, we first sample various postures that satisfy our feasibility conditions: collision free and physically stable. The concept of the wrench space is used to evaluate the physical stability of holding postures. Then, we build a graph structure in which the nodes are the sampled postures and the links are collision-free motion interpolating between two-sampled postures. This manipulation motion graph allows us to use a general pathfinding method, such as Dijkstra's algorithm, to achieve real-time controllability. In our experiments, we build the manipulation motion graphs for differently shaped objects, and we demonstrate the usability of our method via several examples in which users interactively control the animation through the target positions or desired trajectories of the objects. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Choi, Myung Geol] Catholic Univ Korea, Dept Media Technol & Contents Technol, Bucheon, South Korea.
   [Lee, Kang Hoon] Kwangwoon Univ, Dept Comp Sci, Seoul, South Korea.
C3 Catholic University of Korea; Kwangwoon University
RP Lee, KH (corresponding author), Kwangwoon Univ, 447-1 Wolgye Dong, Seoul, South Korea.
EM kang@kw.ac.kr
CR [Anonymous], 2014, ACM Transactions on Graphics, DOI DOI 10.1145/2601097.2601117
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Borst C, 2004, IEEE INT CONF ROBOT, P319, DOI 10.1109/ROBOT.2004.1307170
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Choi MG, 2011, COMPUT GRAPH FORUM, V30, P445, DOI 10.1111/j.1467-8659.2011.01889.x
   Harada K, 2005, IEEE INT CONF ROBOT, P1712
   Jörg S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366208
   Kaneko K, 2004, IEEE INT CONF ROBOT, P1083, DOI 10.1109/ROBOT.2004.1307969
   Kang CG, 2014, COMPUT GRAPH FORUM, V33, P1, DOI 10.1111/cgf.12468
   Kim J, 2013, IEEE T ROBOT, V29, P1424, DOI 10.1109/TRO.2013.2273846
   Koga Y., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P395, DOI 10.1145/192161.192266
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lee J, 1999, COMP GRAPH, P39
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   LIU CK, 2009, ACM T GRAPHIC, V28
   Mordatch I., 2012, P ACM SIGGRAPH EUR S, P137
   Rodriguez I, 2008, COMPUT GRAPH-UK, V32, P474, DOI 10.1016/j.cag.2008.06.001
   Suarez Raul., 2006, GRASP QUALITY MEASUR
   Wang H, 2015, IEEE T VIS COMPUT GR, V21, P18, DOI 10.1109/TVCG.2014.2327976
   Yamane K, 2004, ACM T GRAPHIC, V23, P532, DOI 10.1145/1015706.1015756
   YE YT, 2012, ACM T GRAPHIC, V31, DOI DOI 10.1145/2185520.2185537
NR 22
TC 0
Z9 0
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 435
EP 442
DI 10.1002/cav.1696
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300028
DA 2024-07-18
ER

PT J
AU Li, GQ
   Ouyang, YB
   Wei, GD
   Zhang, ZB
   Mao, AH
AF Li, Guiqing
   Ouyang, Yaobin
   Wei, Guodong
   Zhang, Zhibang
   Mao, Aihua
TI Enhanced rig-space simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE computer animation; physically based modeling; rigging; parametric
   space; secondary motion
AB Rig-space physics a finite element method(FEM) based simulation technique that aims at adding secondary motion on a character while maintaining seamless cooperation with traditional animation pipelines. We enhance the rig-space physics by introducing several techniques, including general field interaction, proportional-derivative control, and improved material control. This allows an animator to perform various interferences to the simulation process and create more abundant animation effects. Moreover, we also improve the numerical stability of the simulation algorithm by prepending a conjugate gradient procedure. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Li, Guiqing; Ouyang, Yaobin; Wei, Guodong; Zhang, Zhibang; Mao, Aihua] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology
RP Li, GQ (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
EM ligq@scut.edu.cn
CR [Anonymous], 2010, ACM SIGGRAPH 2010 Papers. SIGGRAPH'10, DOI [DOI 10.1145/1833349.1778769, DOI 10.1145/1778765.1778769]
   [Anonymous], 2001, P 2001 S INTERACTIVE
   [Anonymous], 2009, P 2009 ACM SIGGRAPH
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Barbic J, 2005, ACM T GRAPHIC, V24, P982, DOI 10.1145/1073204.1073300
   Barbic J, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531359
   Barbic J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409116
   Barr A. H., 1984, Computers & Graphics, V18, P21
   Capell S, 2002, ACM T GRAPHIC, V21, P586, DOI 10.1145/566570.566622
   Hahn F., 2013, Proceedings of the 12th ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'13, P165, DOI DOI 10.1145/2485895.2485918
   Hahn F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185568
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Jeon H, 2007, IEEE INT CONF ROBOT, P2582, DOI 10.1109/ROBOT.2007.363854
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409075
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Kondo R., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation - SCA '05, P127, DOI [10.1145/1073368.1073385, DOI 10.1145/1073368.1073385]
   Le BH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366218
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Li SW, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601217
   Liu LB, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508427
   Magnenat-Thalmann, 1988, Proceedings of Graphics Interface '88, P26
   Martin S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964967
   Müller M, 2004, PROC GRAPH INTERF, P239
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Orvalho Veronica., 2012, Eurographics (State of the Art Reports), P183
   Parent R., 2012, Computer animation: algorithms and techniques
   Savoye Y, 2010, LECT NOTES COMPUT SC, V6169, P280, DOI 10.1007/978-3-642-14061-7_27
   Schumacher C., 2012, P 11 ACM SIGGRAPHEUR, P1
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Singh K., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P405, DOI 10.1145/280814.280946
   Sumner RW, 2005, ACM T GRAPHIC, V24, P488, DOI 10.1145/1073204.1073218
   Tan J, 2011, IEEE COMPUT GRAPH, V31, P34, DOI 10.1109/MCG.2011.30
NR 33
TC 0
Z9 0
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 250
EP 261
DI 10.1002/cav.1705
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300009
DA 2024-07-18
ER

PT J
AU Zhang, L
   Brunnett, G
AF Zhang, Liang
   Brunnett, Guido
TI Combining inverse blending and Jacobian-based inverse kinematics to
   improve accuracy in human motion generation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE data-driven motion synthesis; motion blending; inverse kinematics
AB We present in the paper a hybrid method for motion editing combining motion blending and Jacobian-based inverse kinematics (IK). When the original constraints are changed, a blending-based IK solver is first employed to find an adequate joint configuration coarsely. Using linear motion blending, this search corresponds to a gradient-based minimization in the weight space. The found solution is then improved by a Jacobian-based IK solver by further minimizing the distance between the end effectors and constraints. To accelerate the searching in the weight space, we introduce a weight map, which pre-computes the good starting positions for the gradient-based minimization. The advantages of our approach are threefold: first, more realistic motions can be generated by utilizing motion blending techniques, compared with pure Jacobian-based IK. The blended results also increase the rate of convergence of the Jacobian-based IK solver. Second, the Jacobian-based IK solver modifies poses in the pose configuration space and the computational cost does not scale with the number of examples. Third, it is possible to extrapolate the given example motions with a Jacobian-based IK solver, while it is generally difficult with pure blending-based techniques. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Zhang, Liang; Brunnett, Guido] Chemnitz Univ Technol 62, Dept Comp Sci Professorship Comp Graph & Visualiz, D-09107 Chemnitz, Germany.
RP Zhang, L (corresponding author), Chemnitz Univ Technol 62, Dept Comp Sci Professorship Comp Graph & Visualiz, D-09107 Chemnitz, Germany.
EM lizh@informatik.tu-chemnitz.de
CR [Anonymous], 2005, P 2005 S INTERACTIVE, DOI [DOI 10.1145/1053427.10534294, DOI 10.1145/1053427.1053429]
   [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   Boulic R, 1994, TECHNICAL REPORTS WO
   Boulic R., 1996, INTERACTIVE COMPUTER, P40
   Bruderlin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P97, DOI 10.1145/218380.218421
   Buss S. R., 2005, Journal of Graphics Tools, V10, P37
   Carvalho SR, 2013, VISUAL COMPUT, V29, P171, DOI 10.1007/s00371-012-0678-z
   Gleicher M., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P139, DOI 10.1145/253284.253321
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Huang YZ, 2010, LECT NOTES COMPUT SC, V6459, P242
   Kronfeld Thomas, 2014, Mathematical Methods for Curves and Surfaces. 8th International Conference, MMCS 2012. Revised Selected Papers: LNCS 8177, P265, DOI 10.1007/978-3-642-54382-1_16
   Lee J, 1999, COMP GRAPH, P39
   Min JY, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640452
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   Park SI., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. SCA2, P105, DOI DOI 10.1145/545261.545279
   Raunhardt D, VISUAL COMPUTER, V25, P509
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Rose CF, 2001, COMPUT GRAPH FORUM, V20, pC239
   Snyman JA, 2005, APPL OPTIM, V97, P1, DOI 10.1007/b105200
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   Witkin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P105, DOI 10.1145/218380.218422
   Zhang L, J VIRTUAL REALITY BR, V8
   Zhang LA, 2010, LECT NOTES COMPUT SC, V6169, P250, DOI 10.1007/978-3-642-14061-7_24
NR 23
TC 2
Z9 2
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2016
VL 27
IS 1
BP 3
EP 13
DI 10.1002/cav.1615
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4BX
UT WOS:000369868600001
DA 2024-07-18
ER

PT J
AU Çimen, G
   Kavafoglu, Z
   Kavafoglu, E
   Çapin, T
   Gürcay, H
AF Cimen, Goekcen
   Kavafoglu, Zumra
   Kavafoglu, Ersan
   Capin, Tolga
   Gurcay, Hasmet
TI Skill learning based catching motion control
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE ball catching simulation; physics-based character animation;
   reinforcement learning
AB Learned biomechanical strategies prepare the human body in kinematics and kinetics terms during interception tasks, such as throwing and catching, in real world. Based on this, we present a real-time physics-based approach that generates natural and physically plausible motions for a highly complex task ball catching. We showed that ball catching behavior could be achieved with the proper combination of rather simple motor skills, such as standing, walking, and reaching. The character learns some policies to know how and when to react by using reinforcement learning in order to use time accurately. We demonstrate the effectiveness of our method with some of the catching animation results in different catching strategies. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Cimen, Goekcen] Ecole Polytech Fed Lausanne, Comp Sci, Lausanne, Switzerland.
   [Kavafoglu, Zumra] Hacettepe Univ, Dept Math, Ankara, Turkey.
   [Kavafoglu, Ersan] Hacettepe Univ, Dept Comp Animat & Game Technol, Ankara, Turkey.
   [Capin, Tolga] TED Univ, Dept Comp Engn, Ankara, Turkey.
   [Gurcay, Hasmet] Hacettepe Univ, Comp Graph Dept, Ankara, Turkey.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Hacettepe University; Hacettepe University; Ted
   University; Hacettepe University
RP Çimen, G (corresponding author), Ecole Polytech Fed Lausanne, Comp Sci, Lausanne, Switzerland.
EM gokcen.cimen@epfl.ch
RI Çapın, Tolga Kurtuluş/G-6172-2018; Gürçay, Haşmet/G-9125-2013
OI Gürçay, Haşmet/0000-0002-9797-4666
FU Scientific and Technical Research Council of Turkey (TUBITAK) [112E105]
FX This work is supported by the Scientific and Technical Research Council
   of Turkey (TUBITAK, project number 112E105).
CR Bartletts R, 2007, INTRO SPORTS BIOMECH
   Brown David F., 2013, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P55, DOI 10.1145/2485895
   Coros S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964954
   Coros S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1781156
   Coros S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618516
   Feng AndrewW., 2012, I3D, P95, DOI [DOI 10.1145/2159616.2159632, 10.1145/2159616.2159632]
   Has S, 2012, ACM T GRAPHIC, V31
   Ikemotos L, 2005, ACM SIGGRAPH 2005 SK
   Kenwrights B, 2012, P 3 WORKSH PROC CONT
   Nguyens NH, 2012, SIGGRAPH AS 2012 TEC
   Shum H. P. H., 2012, P ACM S VIRT REAL SO, P17
   Tans J, 2014, ACM T GRAPHIC, V33
   Tans J, 2011, ACM T GRAPHIC, V30
   Tsai YY, 2010, IEEE T VIS COMPUT GR, V16, P325, DOI 10.1109/TVCG.2009.76
   Wang JM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618514
   Wangs JM, 2012, ACM T GRAPHIC, V31
   Yeos SH, 2012, ACM T GRAPHIC, V31
   Yins K, 2007, ACM T GRAPHICS, V26
NR 18
TC 0
Z9 0
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 217
EP 225
DI 10.1002/cav.1659
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700004
DA 2024-07-18
ER

PT J
AU Jones, B
   Popovic, J
   McCann, J
   Li, W
   Bargteil, A
AF Jones, Ben
   Popovic, Jovan
   McCann, James
   Li, Wilmot
   Bargteil, Adam
TI Dynamic sprites: artistic authoring of interactive animations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE physics-based animation; computer animation; computer graphics
ID MOTION; DEFORMATIONS
AB Traditional methods for creating dynamic objects and characters from static drawings involve careful tweaking of animation curves and/or simulation parameters. Sprite sheets offer a more drawing-centric solution, but they do not encode timing information or the logic that determines how objects should transition between poses and cannot generalize outside the given drawings. We present an approach for creating dynamic sprites that leverages sprite sheets while addressing these limitations. In our system, artists create a drawing, deform it to specify a small number of example poses, and indicate which poses can be interpolated. To make the object move, we design a procedural simulation to navigate the pose manifold in response to external or user-controlled forces. Powerful artistic control is achieved by allowing the artist to specify both the pose manifold and how it is navigated, while physics is leveraged to provide timing and generality. We used our method to create sprites with a range of different dynamic properties. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Jones, Ben; Bargteil, Adam] Univ Utah, Salt Lake City, UT 84112 USA.
   [Popovic, Jovan; McCann, James; Li, Wilmot] Adobe Syst Inc, Seattle, WA USA.
C3 Utah System of Higher Education; University of Utah; Adobe Systems Inc.
RP Jones, B (corresponding author), Univ Utah, 50 S Cent Campus Dr,Room 3190, Salt Lake City, UT 84112 USA.
EM benjones@cs.utah.edu
RI Jones, Ben/GXG-7037-2022; McCann, James/JBS-2149-2023
OI McCann, James/0000-0001-5656-177X
FU Direct For Computer & Info Scie & Enginr; Div Of Information &
   Intelligent Systems [1314896, 1314813] Funding Source: National Science
   Foundation; Div Of Information & Intelligent Systems; Direct For
   Computer & Info Scie & Enginr [1314757, 1654221] Funding Source:
   National Science Foundation
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   [Anonymous], 2012, ACM T GRAPHIC, DOI DOI 10.1145/2185520.2185573
   [Anonymous], 2011, ACM T GRAPHICS
   [Anonymous], 2004, P 2004 ACM SIGGRAPH, DOI DOI 10.1145/1028523.1028541
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Barzel R., 1996, COMPUTER ANIMATION S, V96, P184
   Beaudoin P., 2008, P 2008 ACM SIGGRAPHE, P117
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Bergous M, 2007, ACM T GRAPHIC, V26
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Chenney S, 2000, COMP GRAPH, P219, DOI 10.1145/344779.344882
   Coros S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185565
   Coros S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964954
   Coros S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1781156
   Faloutsos P, 1997, IEEE T VIS COMPUT GR, V3, P201, DOI 10.1109/2945.620488
   Fike JA, 2011, 49 AIAA AER M 2011, DOI [10.2514/6.2011-886, DOI 10.2514/6.2011-886]
   Hahn F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185568
   Hodgins J. K., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P71, DOI 10.1145/218380.218414
   Horry Y., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P225, DOI 10.1145/258734.258854
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Koyama Y., 2012, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P19, DOI DOI 10.2312/SCA/SCA12/019-024
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Martin S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964967
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Müller M, 2004, PROC GRAPH INTERF, P239
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   Ngo T, 2000, COMP GRAPH, P403, DOI 10.1145/344779.344964
   O'BRIEN J., 2010, ACM T GRAPHIC, V29, p[156, 1, 10]
   O'Brien J.F., 1999, Proc. ofACM SIGGRAPH, V99, P111
   Oh BM, 2001, COMP GRAPH, P433
   Parker E.G., 2009, P ACM SIGGRAPHEUROGR, P156
   Popovic J, 2000, COMP GRAPH, P209, DOI 10.1145/344779.344880
   Reitsma PSA, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289609
   Rivers A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778796
   Rivers AR, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239533
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Schumacher C., 2012, P 11 ACM SIGGRAPHEUR, P1
   Sorkine O, 2007, S GEOM PROC, V4, P109, DOI [10.1145/1073204.1073323, DOI 10.1145/1073204.1073323]
   Stam J, 2009, INT C COMP AID DES C, P1, DOI 10.1109/CADCG.2009.5246818
   Sykora Daniel, 2009, P 7 INT S NONPHOTORE, P25, DOI DOI 10.1145/1572614.1572619.3,7
   Terzopoulos D., 1988, Computer Graphics, V22, P269, DOI 10.1145/378456.378522
   Terzopoulos D., 1988, Visual Computer, V4, P306, DOI 10.1007/BF01908877
   Thomaszewski B, 2009, COMPUT GRAPH FORUM, V28, P569, DOI 10.1111/j.1467-8659.2009.01397.x
   Yins K, 2007, ACM T GRAPHIC, V26
NR 46
TC 7
Z9 9
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2015
VL 26
IS 2
BP 97
EP 108
DI 10.1002/cav.1608
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CG3GB
UT WOS:000353165400002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Castillo, S
   Wallraven, C
   Cunningham, DW
AF Castillo, Susana
   Wallraven, Christian
   Cunningham, Douglas W.
TI The semantic space for facial communication
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE facial expressions; emotional models; cognitive-based behavioural
   modelling
ID EMOTION; MODEL
AB We can learn a lot about someone by watching their facial expressions and body language. Harnessing these aspects of non-verbal communication can lend artificial communication agents greater depth and realism but requires a sound understanding of the relationship between cognition and expressive behaviour. Here, we extend traditional word-based methodology to use actual videos and then extract the semantic/cognitive space of facial expressions. We find that depending on the specific expressions used, either a four-dimensional or a two-dimensional space is needed to describe the variance in the stimuli. The shape and structure of the 4D and 2D spaces are related to each other and very stable to methodological changes. The results show that there is considerable variance between how different people express the same emotion. The recovered space can well capture the full range of facial communication and is very suitable for semantic-driven facial animation. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Castillo, Susana; Cunningham, Douglas W.] Brandenburg Tech Univ Cottbus Senftenberg, Cottbus, Germany.
   [Wallraven, Christian] Korea Univ, Cognit Syst Lab, Seoul, South Korea.
C3 Brandenburg University of Technology Cottbus; Korea University
RP Castillo, S (corresponding author), Brandenburg Tech Univ Cottbus Senftenberg, Cottbus, Germany.
EM castillo@tu-cottbus.de
RI Castillo, Susana/U-6432-2019
OI Castillo, Susana/0000-0003-1245-4758; Wallraven,
   Christian/0000-0002-2604-9115
FU German research council
FX This work was sponsored in part by a grant from the German research
   council.
CR Ahn J, 2010, P ENGAGE 2010 ZERM S
   Allbeck J., 2002, EMBODIED CONVERSATIO, V2, P15
   ARCHER D, 1977, J PERS SOC PSYCHOL, V35, P443, DOI 10.1037/0022-3514.35.6.443
   Barrett LF, 1999, CURR DIR PSYCHOL SCI, V8, P10, DOI 10.1111/1467-8721.00003
   Bettadapura V, ABS12036722 CORR
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   CARRERALEVILLAIN P, 1994, J NONVERBAL BEHAV, V18, P281, DOI 10.1007/BF02172290
   Chen HS, 2012, COMM COM INF SC, V288, P310
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   CONDON WS, 1966, J NERV MENT DIS, V143, P338, DOI 10.1097/00005053-196610000-00005
   Cunningham D. W., 2005, ACM T APPL PERCEPT, V2, P251, DOI DOI 10.1145/1077399.1077404
   Cunningham DW, 2009, J VISION, V9, DOI 10.1167/9.13.7
   Cunningham Douglas W, 2011, EXPT DESIGN USER STU
   De Ruiter JP, 2003, BEHAV RES METH INS C, V35, P408, DOI 10.3758/BF03195518
   DIGMAN JM, 1990, ANNU REV PSYCHOL, V41, P417, DOI 10.1146/annurev.psych.41.1.417
   Ekman P., 1971, Nebraska symposium on motivation, V19, P207
   FERNANDEZ-DOLS JM, 1991, J NONVERBAL BEHAV, V15, P107, DOI 10.1007/BF00998266
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   FORD JK, 1986, PERS PSYCHOL, V39, P291, DOI 10.1111/j.1744-6570.1986.tb00583.x
   Funge J, 1999, COMP GRAPH, P29, DOI 10.1145/311535.311538
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Hurley AE, 1997, J ORGAN BEHAV, V18, P667, DOI 10.1002/(SICI)1099-1379(199711)18:6<667::AID-JOB874>3.0.CO;2-T
   Kapadia M, 2013, MODELING SIMULATION, P15
   Kaulard K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032321
   Kleiner M, 2007, PERCEPTION, V36, P14
   Krahmer E., 2002, Proceedings of the 1st International Conference on Speech Prosody (SP2002), P443
   MEHRABIAN A, 1967, J CONSULT PSYCHOL, V31, P248, DOI 10.1037/h0024648
   Osgood C. E., 1957, The measurement of meaning
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Peres-Neto PR, 2001, OECOLOGIA, V129, P169, DOI 10.1007/s004420100720
   Rosch E., 1978, COGNITION CATEGORIZA, P27, DOI DOI 10.1016/B978-1-4832-1446-7.50028-5
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sokolov EN, 2000, INTEGR PHYS BEH SCI, V35, P81, DOI 10.1007/BF02688770
   Yik MSM, 1999, J PERS SOC PSYCHOL, V77, P600, DOI 10.1037/0022-3514.77.3.600
   Yngve VictorH., 1970, PAPERS 6 REGIONAL M, V6, P567
NR 35
TC 7
Z9 9
U1 0
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 225
EP 233
DI 10.1002/cav.1593
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA AJ2WD
UT WOS:000337524300004
DA 2024-07-18
ER

PT J
AU Luo, LB
   Yin, HY
   Cai, WT
   Lees, M
   Zhou, SP
AF Luo, Linbo
   Yin, Haiyan
   Cai, Wentong
   Lees, Michael
   Zhou, Suiping
TI Interactive scenario generation for mission-based virtual training
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE scenario generation; virtual worlds; training; serious games
AB For a virtual training system, how to effectively and quickly generate training scenarios has become a challenging issue. A scenario generation system is needed to produce scenarios that can meet different objectives and at the same time be customized for individuals. In this paper, we introduce a scenario generation framework for mission-based virtual training, which aims to generate scenarios from both trainer and trainee's perspective. The framework allows a trainer to direct the scenario generation process, so that the generated scenarios reflect the trainer's preferences over different mission objectives. It also considers how the scenarios could adapt to different trainees' skill levels. The representation of scenario beat is proposed, and the scenario generation process adopts a combinatorial optimization approach generating the sequence of scenario beats. The efficacy of the proposed framework is demonstrated through an empirical study of human players in a simple food distribution mission game. The results show that a trainee can achieve better performance improvement when playing the customized scenarios tailored to the trainee's skill level as compared with the uncustomized scenarios. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Luo, Linbo; Yin, Haiyan; Cai, Wentong; Lees, Michael] Nanyang Technol Univ, Sch Comp Engn, Parallel & Distributed Comp Ctr, Singapore 639798, Singapore.
   [Zhou, Suiping] Univ Teesside, Sch Comp, Middlesbrough, Cleveland, England.
C3 Nanyang Technological University; University of Teesside
RP Luo, LB (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Parallel & Distributed Comp Ctr, Singapore 639798, Singapore.
EM lbluo@ntu.edu.sg
RI Yin, Haiyan/JRY-1400-2023; Cai, Wentong/A-3720-2011; Lees, Michael
   H/A-3714-2011
OI Yin, Haiyan/0009-0007-9576-9398; Cai, Wentong/0000-0002-0183-3835; Lees,
   Michael/0000-0002-5457-9180
CR AlexanderZook StephenLee-Urban, 2012, P INT C FDN DIG GAM, P164, DOI DOI 10.1145/2282338.2282371
   Brenner M, 2010, AAAI CONF ARTIF INTE, P1517
   Ha EY, 2012, P 26 AAAI C ART INT, P2113
   Hill R., 2003, Kunstliche Intelligenz (KI Journal), V17, P5, DOI DOI 10.1002/J.2162-6057.20041B01234.X
   Magerko B., 2005, INT IND TRAIN SIM ED
   Magerko B, 2006, P 25 ARM SCI C ORL U
   Mateas M, 2005, P 1 ART INT INT DIG, P93
   Porteous J., 2010, Proceedings of the Ninth International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2010), P1297
   Porteous J., 2011, P 10 INT C AUT AG MU, V2, P449
   Riedl M., 2012, Proc. AAAI Conf. Artif. Intell, V26, P2160, DOI [10.1609/aaai.v26i1.8447, DOI 10.1609/AAAI.V26I1.8447]
   Riedl MO, 2010, J ARTIF INTELL RES, V39, P217, DOI 10.1613/jair.2989
   Rowe Jonathan P., 2010, Proceedings of the Intelligent Narrative Technologies III Workshop on - INT3 '10, P1
   Shaker N., 2010, Proceedings of AIIDE, P63
   Thue David., 2011, Proceedings of the Seventh AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, P91
   Yannakakis G. N., 2012, P 9 C COMP FRONT, P285, DOI 10.1145/2212908.2212954
   YuandMarkORiedl Hong, 2012, P 11 INT C AUT AG MU, V12, P71
NR 16
TC 16
Z9 19
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 345
EP 354
DI 10.1002/cav.1525
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500022
DA 2024-07-18
ER

PT J
AU Park, JH
   Rojas, FA
   Yang, HS
AF Park, Jin Hyoung
   Rojas, Francisco Arturo
   Yang, Hyun Seung
TI A collision avoidance behavior model for crowd simulation based on
   psychological findings
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents Conference (CASA)
CY 2013
CL Istanbul, TURKEY
DE collision avoidance; crowd simulation; speed-variant information process
   space (IPS); gaze movement angle (GMA); personal reaction bubble (PRB);
   gait motion
ID VIRTUAL HUMANS
AB This paper proposes a collision avoidance behavior model for crowd simulation based on psychological findings of human behaviors such as gaze movement angle (GMA), side stepping, gait motion, and personal reaction bubble to have better results in crowd simulation. By calculating the GMA between agents, collision can be predicted and avoided without knowing the exact trajectories of the agents. The proposed model consists of four phases: (1) GMA-based collision prediction for mid/long range by using speed-variant information process space, (2) collision avoidance steering, (3) gait-based locomotion generation, and (4) space keeping based on personal reaction bubble. The effectiveness of the proposed speed-variant information process space was tested on various types of agent flows with different densities. The total loss of kinetic energy accumulated during an agent's movement and the ratio of the length of the path actually traveled to the length of the original path are used as key metrics to figure out the features between the different types of flows. Finally, examples of tuning the parameters with well-known fundamental diagrams are presented. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Park, Jin Hyoung; Rojas, Francisco Arturo; Yang, Hyun Seung] Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.
   [Park, Jin Hyoung] KIOST, Maritime Safety Res Div, Taejon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea
   Institute of Ocean Science & Technology (KIOST)
RP Yang, HS (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, 291 Daehak Ro, Taejon 305701, South Korea.
EM hsyang@kaist.ac.kr
RI Yang, Hyun Seung/C-1984-2011
FU MKE/KEIT [10039165]; KIOST [PES160C]
FX This research was supported by the IT R&D program of MKE/KEIT,
   (10039165, Development of learner-participatory and interactive 3D
   virtual learning contents technology) and the research project of KIOST
   (The Development of Human Factors Experimental Evaluation Techniques for
   Maritime Traffic Safety Assessment-PES160C).
CR [Anonymous], 2000, THESIS U TOKYO
   [Anonymous], 1997, COMPUTER ANIMATION S, DOI DOI 10.1007/978-3-7091-6874-5_3
   [Anonymous], 1999, P GAM DEV C
   Badler NI, 1999, COMP ANIM CONF PROC, P128, DOI 10.1109/CA.1999.781206
   CUTTING JE, 1995, PSYCHOL REV, V102, P627, DOI 10.1037/0033-295X.102.4.627
   Galea ER., 1996, P 7 INT FIRE SCI ENG, P711
   Gérin-Lajoie M, 2008, GAIT POSTURE, V27, P239, DOI 10.1016/j.gaitpost.2007.03.015
   Goffman E., 2009, Relations in public
   Hall Edward Twitchell, 1966, HIDDEN DIMENSION
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Kholshevnikov VV, 2008, P PED EV DYN, P157
   Kitazawa K, 2010, PEDESTRIAN AND EVACUATION DYNAMICS 2008, P95, DOI 10.1007/978-3-642-04504-2_7
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Metoyer RA, 2003, COMP ANIM CONF PROC, P149, DOI 10.1109/CASA.2003.1199318
   Musse SR, 1999, SPRING COMP SCI, P23
   Older S, 1968, TRAFFIC ENG CONTROL, V10, P160
   Ondej J, 2010, ACM T GRAPHICS, V29
   Orendurff MS, 2008, GAIT POSTURE, V27, P603, DOI 10.1016/j.gaitpost.2007.08.004
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Predtechenskii V.M., 1978, Planning for Foot Traffic Flow in Buildings
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rymill S.J., 2005, THEORY PRACTICE COMP, P35
   Steffen B., 2008, C P PED2008, P677
   Strassner J, 2005, COMPUT ANIMAT VIRT W, V16, P331, DOI 10.1002/cav.96
   Thalmann Daniel., 2007, CROWD SIMULATION
NR 27
TC 25
Z9 29
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 173
EP 183
DI 10.1002/cav.1504
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 145GP
UT WOS:000319003500005
DA 2024-07-18
ER

PT J
AU Kumar, A
   Ojha, A
AF Kumar, Amit
   Ojha, Aparajita
TI Natural path planning using wavelet noise in static environment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Corridor Map Method; subdivision curves; Perlin noise; wavelet noise
AB In a constrained virtual environment, motion of a character has to be controlled with precision to avoid collisions. For modeling motion of a character representing some real-life object, it is important to generate paths that look natural. A number of path planning algorithms have been introduced to solve real-time path queries in an environment. However, in all such algorithms, a fixed path is returned always for the same start and goal positions in the environment. Recently, Perlin noise has been used to add variations to a path so that it appears more natural. However, because of pure random nature of Perlin noise function, often unnatural path occurs. In this paper, we present a new approach to natural path planning by adding wavelet noise to a path generated using subdivision-based Corridor Map Method. Because wavelet noise is almost perfectly band limited and provides good details with minimal aliasing effects, the resulting path becomes smoother and more natural. Moreover, by appropriately choosing the levels of down/up sampling in the wavelet noise generation algorithm, frequency of wavelet noise can be adjusted. This serves as an effective tool in bringing variations in path as per the requirement. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Kumar, Amit; Ojha, Aparajita] PDPM Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn Discipline, Jabalpur, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Kumar, A (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn Discipline, Jabalpur, India.
EM amitku@iiitdmj.ac.in
RI Ojha, Aparajita/Q-3902-2016
OI Ojha, Aparajita/0000-0003-1567-8378
CR [Anonymous], 2009, P 4 INT C FDN DIGITA, DOI DOI 10.1145/1536513.1536540
   [Anonymous], 1999, P GAM DEV C
   [Anonymous], 2000, Computational Geometry Algorithms and Applications
   Burgard W., 2005, Principles of Robot Motion: Theory, Algorithms, and Implementations
   Chui C. K., 1992, An Introduction to Wavelets, DOI 10.2307/2153134
   Cook RL, 2005, ACM T GRAPHIC, V24, P803, DOI 10.1145/1073204.1073264
   Geraerts R, 2007, COMPUT ANIMAT VIRT W, V18, P107, DOI 10.1002/cav.166
   Karamouzas I, 2008, COMPUT ANIMAT VIRT W, V19, P283, DOI 10.1002/cav.242
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Khosla P., 1988, Proceedings of IEEE International Conference on Robotics and Automation, P1778, DOI DOI 10.1109/ROBOT.1988.12323
   LaValle S. M., 2006, Planning algorithms
   Lewis J. P., 1989, Computer Graphics, V23, P263, DOI 10.1145/74334.74360
   ODUNLAING C, 1985, J ALGORITHMS, V6, P104, DOI 10.1016/0196-6774(85)90021-5
   Patil S, 2011, IEEE T VIS COMPUT GR, V17, P244, DOI 10.1109/TVCG.2010.33
   Peachey D, 1998, TEXTURING MODELING P
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Perlin K., MAKING NOISE
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Russell S.J., 2006, Artificial Intelligence A Modern Approach
   Yang K., 2009, Selected papers from the 2nd International Symposium on UAVs, Reno, Nevada, U.S.A. June 810, P101
NR 21
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2013
VL 24
IS 1
BP 17
EP 24
DI 10.1002/cav.1476
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 089PU
UT WOS:000314923300004
DA 2024-07-18
ER

PT J
AU Lee, SW
   Lee, KH
AF Lee, Sang Won
   Lee, Kang Hoon
TI Interactive buildup of animation sequences with captured motion data
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE computer animation; motion capture; interactive editing
AB We present a new approach to interactive resequencing of captured motion data that allows the user to progressively extend his or her animations such that each extension can best fit user requirements with respect to space, time, and pose. In the preprocessing phase, captured frames are clustered into pose groups and interconnected into a transition graph. For each step in building an animation sequence at runtime, the user is allowed to browse through motion paths in the graph that are connectable to the existing sequence by specifying the desired locations and poses at path ends and to select one of those paths to extend the animation. Instead of using graph search algorithms, our path browser unrolls the graph locally into spatial search trees and employs an efficient nearest-neighbor search method to quickly find the optimal paths that satisfy user inputs. We demonstrate the usefulness of our approach by creating animation examples in scenarios involving spatial, temporal, and postural requirements simultaneously. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Lee, Sang Won; Lee, Kang Hoon] Kwangwoon Univ, Seoul 139701, South Korea.
C3 Kwangwoon University
RP Lee, KH (corresponding author), Kwangwoon Univ, 603 Cham Bit Bldg, Seoul 139701, South Korea.
EM kang@kw.ac.kr
FU National Research Foundation of Korea (NRF); Ministry of Education,
   Science and Technology [2012-0002241]; Kwangwoon University
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education, Science and Technology (no. 2012-0002241). This
   research also has been conducted by the Research Grant of Kwangwoon
   University in 2010.
CR Beaudoin P., 2008, P 2008 ACM SIGGRAPHE, P117
   Beygelzimer A., 2006, P 23 INT C MACH LEAR, P97, DOI DOI 10.1145/1143844.1143857
   Davis J, 2003, P 2007 S COMP AN SAN, P320
   Igarashi T., 2005, Proceedings of the 2005 acm siggraph/eurographics symposium on computer animation, P107, DOI DOI 10.1145/1073368.1073383
   Ikemoto L, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P145
   Kim M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531385
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lau Manfred., 2006, P ACM SIGGRAPHEUROGR, P299
   Lee J, 1999, COMP GRAPH, P39
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Reitsma PSA, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289609
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Shin H.J., 2006, Proceedings of ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P291
   Shum HPH, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409067
   Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Wampler K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805970
   Zhao L., 2009, Proceedings of ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P27
NR 19
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 245
EP 251
DI 10.1002/cav.1454
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100012
DA 2024-07-18
ER

PT J
AU Oh, S
   Shin, S
   Jun, H
AF Oh, Seungtaik
   Shin, Seunghyup
   Jun, Hyeryeong
TI Practical simulation of hierarchical brittle fracture
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE fracture; fluid; rigid body
AB A novel practical method for brittle fracture simulation is presented. Our fracture model is represented by a tree structure, and all elementary fracture pieces are hierarchically connected. Each node in a fracture tree has a glue table to define connections and strengths among its child nodes. With our hierarchical fracture method, one can control the whole process of fracture formulation and simulation in a more direct way. Given an input object, a hierarchical fracture pattern is constructed by a series of recursive decompositions where the variation of fragment sizes can be intuitively controlled through a drawing interface. A noise pattern is applied on the interfaces of fragments for adding a natural look. A new simple and practical fracture criterion is also introduced, and we capture the difference of virtual and inherited velocities of fracture nodes to break the connection. Our fracture criterion is fast and robust because it does not involve any matrix solves or finite element analysis that is essential in the prior fracturing algorithms. We implement the proposed method on a fluid solver by extending a rigid body interaction unit, and as a result, we achieve that the fracture objects can interact with fluid and ordinary rigid bodies in a fully two-way manner. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Oh, Seungtaik] ETRI, Digital Content Res Div, Taejon 305700, South Korea.
   [Jun, Hyeryeong] ETRI, Comp Graph Team, Taejon 305700, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Oh, S (corresponding author), ETRI, Digital Content Res Div, 218 Gajeong No Yusong, Taejon 305700, South Korea.
EM stoh@etri.re.kr
FU Ministry of Culture, Sports and Tourism (MCST) of the Republic of Korea;
   Korea Creative Content Agency (KOCCA) in the Culture Technology (CT) and
   Research Development Program
FX The authors would like to thank to the anonymous reviewers for their
   useful comments and suggestions. This work was supported by the Ministry
   of Culture, Sports and Tourism (MCST) of the Republic of Korea and Korea
   Creative Content Agency (KOCCA) in the Culture Technology (CT) and
   Research Development Program 2011.
CR Addision PS, 1999, ASCE J ENG MECH, V125, P622
   Bao ZS, 2007, IEEE T VIS COMPUT GR, V13, P370, DOI 10.1109/TVCG.2007.39
   Bohn S, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.046215
   Cleary PW, 2008, IUTAM BOOKSER, V11, P287, DOI 10.1007/978-1-4020-9090-5_26
   Hellrung J, 2009, SIGGR 09 TALKS NEW O, P71
   Kaufmann P, 2009, SIGGR 09 NEW ORL, P50
   Molino N, 2004, ACM T GRAPHIC, V23, P385, DOI 10.1145/1015706.1015734
   MONAGHAN JJ, 1994, J COMPUT PHYS, V110, P399, DOI 10.1006/jcph.1994.1034
   Mould David., 2005, P GRAPHICS INTERFACE, P219
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M, 2004, SCA 04 GREN, P00
   Norton A., 1991, Visual Computer, V7, P210, DOI 10.1007/BF01900837
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   Oh S, 2009, COMPUT ANIMAT VIRT W, V20, P215, DOI 10.1002/cav.290
   Parker E.G., 2009, PROC S COMP ANIM, P165, DOI DOI 10.1145/1599470.1599492.
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Raghavachary S., 2002, ACM SIGGRAPH 2002 C, P187
   Smith J, 2000, PROC GRAPH INTERF, P27
   Su J., 2009, P 2009 ACM SIGGRAPH, P155
   Terzopoulos D., 1988, Computer Graphics, V22, P269, DOI 10.1145/378456.378522
   Weinstein R, 2008, SIGGR 08 TALKS LOS A, P71
   Zheng C, 2010, SIGGR 10 LSO ANG, P69
NR 23
TC 6
Z9 7
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 291
EP 300
DI 10.1002/cav.1443
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100016
DA 2024-07-18
ER

PT J
AU Zhao, X
   Zhou, Z
   Duan, Y
   Wu, W
AF Zhao, Xu
   Zhou, Zhong
   Duan, Ye
   Wu, Wei
TI Detail-feature-preserving surface reconstruction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE surface reconstruction; computational geometry; computer graphics
AB In this paper, we propose a feature-preserving surface reconstruction method from sparse noisy 3D measurements such as range scanning or passive multiview stereo. In contrast to earlier methods, we define a novel type of explicit 3D filterregularized weighted least squares filterto characterize the detail features such as surface wrinkles and sharp features. To account for noise, we rasterize input-oriented points into a probabilistic volume (base volume) and then create a guidance volume by Gaussian filtering. Both the base volume and the guidance volume are further filtered by regularized weighted least squares filter to detect and recover detail features. After the two-stage filtering, a global minimal surface is computed by graph cut and meshed as a geometric model. Experimental results on various datasets show that our method is robust to noise, outliers, and missing parts, which makes it more suitable to fit indoor/outdoor multiview stereo data. Unlike other methods, our method can completely recover scene structures and preserve detail features from noisy point samples. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Zhao, Xu; Zhou, Zhong; Wu, Wei] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Duan, Ye] Univ Missouri, Dept Comp Sci, Comp Graph & Image Understanding Lab, Columbia, MO USA.
C3 Beihang University; University of Missouri System; University of
   Missouri Columbia
RP Zhou, Z (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM zz@vrlab.buaa.edu.cn
FU National 863 Program of China [2012AA011803]; Natural Science Foundation
   of China [61170188]; National 973 Program of China [2009CB320805];
   Fundamental Research Funds for the Central Universities of China; Div Of
   Civil, Mechanical, & Manufact Inn; Directorate For Engineering [1039433]
   Funding Source: National Science Foundation
FX This work is supported by the National 863 Program of China under grant
   no. 2012AA011803, the Natural Science Foundation of China under grant
   no. 61170188, the National 973 Program of China under grant no.
   2009CB320805, and the Fundamental Research Funds for the Central
   Universities of China.
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947
   BOISSONNAT JD, 1984, ACM T GRAPHIC, V3, P266, DOI 10.1145/357346.357349
   Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Chauve AL, 2010, PROC CVPR IEEE, P1261, DOI 10.1109/CVPR.2010.5539824
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Desbrun, 2007, P 5 EUROGRAPHICS S G, V7, P39
   EDELSBRUNNER H, 1994, ACM T GRAPHIC, V13, P43, DOI 10.1145/174462.156635
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Gross M., 2007, POINT BASED GRAPHICS
   Guennebaud G, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239474
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hornung Alexander, 2006, ACM INT C PROCEED IN, P41, DOI DOI 10.2312/SGP/SGP06
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kolluri R., 2004, ser. SGP '04, P11, DOI DOI 10.1145/1057432.1057434
   Labatut P, 2009, COMPUT GRAPH FORUM, V28, P2275, DOI 10.1111/j.1467-8659.2009.01530.x
   Lafarge F, 2010, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.2010.5540193
   Lempitsky V., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI [10.1109/CVPR.2007.383293, DOI 10.1109/CVPR.2007.383293]
   Lempitsky V, 2010, PROC CVPR IEEE, P1197, DOI 10.1109/CVPR.2010.5539832
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Salman N, 2010, COMPUT GRAPH FORUM, V29, P1623, DOI 10.1111/j.1467-8659.2010.01771.x
   Seitz S.M., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI https://doi.org/10.1109/CVPR.2006.19
   Strecha C., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587706
NR 26
TC 5
Z9 5
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 407
EP 416
DI 10.1002/cav.1464
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100027
DA 2024-07-18
ER

PT J
AU Raunhardt, D
   Boulic, R
AF Raunhardt, Daniel
   Boulic, Ronan
TI Immersive singularity-free full-body interactions with reduced marker
   set
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE inverse kinematics; limb singularity; postural control; synergy;
   extrapolation
ID INVERSE KINEMATICS; ARTICULATED FIGURES; POSTURAL CONTROL; MOTION
   CAPTURE; REAL-TIME; ARCHITECTURE; ANIMATION; MOVEMENT; DESIGN
AB Despite the large success of games grounded on movement-based interactions the current state of full-body motion capture technologies still prevents the exploitation of precise interactions with complex environments. The first key requirement in the line of work we present here is to ensure a precise spatial correspondence between the user and the Avatar. For that purpose, we build upon our past effort in human postural control with a prioritized inverse kinematics (PIK) framework. One of its key advantages is to ease the dynamic-and priority-based combination of multiple conflicting constraints such as ensuring the balance and reaching a goal. However, its reliance on a linearized approximation of the problem makes it vulnerable to the well-known full extension singularity of the limbs. We address this issue by presenting a new type of 1D analytic constraint that smoothly integrates within the PIK framework under the name of FLEXT constraint (for FLexion-EXTension constraint). We further ease the full-body interaction by combining this new constraint with a recently introduced motion constraint to exploit the data-based synergy of full-body reach motions. The combination of both techniques allows immersive full-body interactions with a small set of active optical marker. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Boulic, Ronan] EPFL IC ISIM VRLAB, Ecole Polytech Fed Lausanne, VRLab, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Boulic, R (corresponding author), EPFL IC ISIM VRLAB, Ecole Polytech Fed Lausanne, VRLab, Stn 14, CH-1015 Lausanne, Switzerland.
EM ronan.boulic@epfl.ch
FU Swiss Scientific National Foundation [200020_117706/1]; Swiss National
   Science Foundation (SNF) [200020_117706] Funding Source: Swiss National
   Science Foundation (SNF)
FX The authors would like to thank Damien Maupu and Achille Peternier for
   their support for the CAVE graphics library, and Mireille Clavien for
   the video editing and the character design. The research was partially
   supported by the Swiss Scientific National Foundation under grant No.
   200020_117706/1.
CR *ASC TECHN CORP, 1996, FLOCK BIRDS INST OP
   BADLER NI, 1987, IEEE COMPUT GRAPH, V7, P28, DOI 10.1109/MCG.1987.276894
   Baerlocher P, 2004, VISUAL COMPUT, V20, P402, DOI 10.1007/s00371-004-0244-4
   Barzel R., 1988, Computer Graphics, V22, P179, DOI 10.1145/378456.378509
   Boulic R, 2006, LECT NOTES ARTIF INT, V3881, P176
   Boulic R, 2009, INTERACT COMPUT, V21, P11, DOI 10.1016/j.intcom.2008.10.002
   Gascuel J.-D., 1994, Visual Computer, V10, P191, DOI 10.1007/BF01901286
   Grassia F. S., 1998, J. Graph. Tools, V6, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]
   HECKER C, ACM SIGGRAPH 200, P1
   Jakobsen Thomas, 2001, GAM DEV C
   Kallmann M, 2008, COMPUT ANIMAT VIRT W, V19, P79, DOI 10.1002/cav.176
   Korein JamesU., 1985, GEOMETRIC INVESTIGAT
   Kulpa R, 2005, COMPUT GRAPH FORUM, V24, P343, DOI 10.1111/j.1467-8659.2005.00859.x
   LIEGEOIS A, 1977, IEEE T SYST MAN CYB, V7, P868
   Loke L, 2007, PERS UBIQUIT COMPUT, V11, P691, DOI 10.1007/s00779-006-0132-1
   MACIEJEWSKI AA, 1990, IEEE COMPUT GRAPH, V10, P63, DOI 10.1109/38.55154
   MAUPU D, 2008, VIRTUAL REALITY BROA, V5, P1
   MEREDITH M, 5 INT C COMP GAM ART, P81
   Michoud B, 2007, LECT NOTES COMPUT SC, V4843, P678
   Molet T, 1999, IEEE T ROBOTIC AUTOM, V15, P475, DOI 10.1109/70.768180
   Molet T, 1999, PRESENCE-TELEOP VIRT, V8, P140, DOI 10.1162/105474699566134
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   Nijholt A, 2008, LECT NOTES COMPUT SC, V5277, P166
   Peinado M, 2009, IEEE COMPUT GRAPH, V29, P62, DOI 10.1109/MCG.2009.42
   PHILLIPS CB, 1991, COMP GRAPH, V25, P359, DOI 10.1145/127719.122756
   Raunhardt D, 2009, VISUAL COMPUT, V25, P509, DOI 10.1007/s00371-009-0336-2
   SICILIANO B, ICAR 91, V2, P1211
   Sturman DJ, 1998, IEEE COMPUT GRAPH, V18, P38, DOI 10.1109/38.637269
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   Unzueta L, 2008, GRAPH MODELS, V70, P87, DOI 10.1016/j.gmod.2008.03.002
   ZHAO JM, 1994, ACM T GRAPHIC, V13, P313, DOI 10.1145/195826.195827
   2010, CINEFEX, V120, P68
NR 32
TC 7
Z9 7
U1 0
U2 3
PU WILEY-BLACKWELL
PI MALDEN
PA COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2011
VL 22
IS 5
BP 407
EP 419
DI 10.1002/cav.378
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856HY
UT WOS:000297631000002
DA 2024-07-18
ER

PT J
AU Gourret, JP
   Hariri, A
   Liverneaux, P
AF Gourret, Jean-Paul
   Hariri, Amir
   Liverneaux, Philippe
TI Explicit and implicit animation with fuzzy constraints of a versatile
   multi-body system for virtual hand surgery
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE explicit command and implicit control of animation; physics-based
   simulation and deformation; fuzzy constraints of position and
   orientation; versatile multi-body notation; structural agents in virtual
   hand surgery
ID FIXATION; PLACEMENT
AB This work is designed to control the movement of hand structural agents under external action, using the implicit animation driven by explicit animation technique (AI-CAE technique). Starting from the configuration of a hand at rest obtained by a 3D scanner and after meshing of the structural agents, we seek the configuration of the rigid agents under orthopaedic surgeon external action and interacting reliance of deformable and rigid agents. We have developed a model and software tools to answer this interactive application with adaptive execution. The first contribution comes from notations and definition of a versatile multi-body system dedicated to the explicit and implicit animation. The second contribution comes from the implicit animation driven by explicit animation itself, and from its ability to mimic the role of cartilages and ligaments. The resulting technique is applied to the bone structure consistency of a specific human hand in the context of virtual hand orthopaedic surgery. The versatile specific multi-body is made up of hierarchical interacting agents conceivable as a construction set of rigid bones with cartilages-ligaments and underlying links. The explicit animation produces a desired configuration from geometric command parameters of torsion, flexion, pivot and axis shifting, given in a scenario subdivided into temporal sequences. The implicit animation controls the movement by implementing a physics-based model and fuzzy constraints of position and orientation. It gives better configuration than the explicit animation because it takes into account the interactions between agents, and it gives a neat solution without the problems of complexity due to geometric modelling. A methodology based on the AI-CAE technique is discussed, medical expertise and validation tests are presented. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Gourret, Jean-Paul] Univ La Rochelle, Lab Informat Image & Interact, IUT, F-17026 La Rochelle 01, France.
   [Hariri, Amir; Liverneaux, Philippe] Strasbourg Univ Hosp, Dept Hand Surg, Illkirch Graffenstaden, France.
C3 La Rochelle Universite; CHU Strasbourg
RP Gourret, JP (corresponding author), Univ La Rochelle, Lab Informat Image & Interact, IUT, 15 Rue Francois de Vaux de Foletier, F-17026 La Rochelle 01, France.
EM jean-paul.gourret@univ-lr.fr
FU CPER [10]
FX This work is supported by the CPER Poitou-Charentes (Project 10: Image
   and interactivity). We are grateful to Dr Mickael Ohana Radiographer,
   hospital Raymond Poincare (service of Pr C. Vallee) Garches, for the
   CT-scans.
CR ACKERMAN MJ, D LIB MAG
   Albrecht I., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P98
   Asada Haruhiko, 1986, Robot analysis and control
   Barzel R., 1988, Computer Graphics, V22, P179, DOI 10.1145/378456.378509
   Chan KW, 2004, J HAND SURG-AM, V29A, P74, DOI 10.1016/j.jhsa.2003.09.002
   Gourret J., 1989, ACM SIGGRAPH COMPUTE, V23, P21, DOI DOI 10.1145/74333.74335
   Gourret J P, 2006, Chir Main, V25, P81, DOI 10.1016/j.main.2006.03.006
   GUILLOT O, 2007, P INT C COMP GRAPH T, P180
   HOLLERBACH JM, 1980, IEEE T SYST MAN CYB, V10, P730, DOI 10.1109/TSMC.1980.4308393
   ISAACS PM, 1987, COMPUT GRAPH, V21, P215
   Kurihara Tsuneya, 2004, P 2004 ACM SIGGRAPHE, P355
   Lee SH, 2006, ACM T GRAPHIC, V25, P1188, DOI 10.1145/1141911.1142013
   Lee SH, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559756
   Lee SH, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360621
   LIM CT, 1995, ACM SIGGRAPH S SOLID, P393
   Liverneaux P, 2005, Chir Main, V24, P169, DOI 10.1016/j.main.2005.06.004
   Liverneaux PA, 2008, INT J MED ROBOT COMP, V4, P165, DOI 10.1002/rcs.194
   Maciel A, 2007, IEEE T VIS COMPUT GR, V13, P518, DOI 10.1109/TVCG.2007.1016
   Magnenat-Thalmann Nadia, 1988, P GRAPHICS INTERFACE
   Marai GE, 2007, IEEE T VIS COMPUT GR, V13, P1095, DOI 10.1109/TVCG.2007.1063
   Maurel WALTER, 1999, Comput Methods Biomech Biomed Engin, V2, P65, DOI 10.1080/10255849908907979
   Rettig ME, 1999, J HAND SURG-AM, V24A, P1206
   RIJPKEMA H, 1991, ACM COMP GRAPH P SIG, P339
   Rohling R. N., 1993, PRESENCE-TELEOP VIRT, V2, P203
   Rohling RN., 1993, Presence, V2, P281, DOI DOI 10.1162/PRES.1993.2.4.281
   RUIZ MC, 2001, HUM MOD C UIMM PAR
   SCHWARTZ N, 1981, UNFALLHEILKUNDE, V84, P614
   SIBILLE L, 2000, COMPUTER ASSISTED RA, P7
   Slade JF, 2001, ORTHOP CLIN N AM, V32, P247, DOI 10.1016/S0030-5898(05)70247-9
   SUEDA S, 2008, ACM T GRAPHICS, V27
   Teran J, 2005, IEEE T VIS COMPUT GR, V11, P317, DOI 10.1109/TVCG.2005.42
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   THOMPSON DE, 1988, P ACM SIGGRAPH 88 AT, V22, P335
   Tolani D, 1996, PRESENCE-TELEOP VIRT, V5, P393, DOI 10.1162/pres.1996.5.4.393
   TSANG W, 2005, EUR ACM SIGGR S COMP
   Weghe MV, 2004, IEEE INT CONF ROBOT, P3375
   Wilkinson DD, 2003, IEEE INT CONF ROBOT, P238
   Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507
   WITKIN A, 1987, COMPUT GRAPH, V21, P225
   Zordan V. B., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P245
NR 40
TC 0
Z9 0
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL-AUG
PY 2011
VL 22
IS 4
BP 371
EP 392
DI 10.1002/cav.390
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 825OW
UT WOS:000295290400006
DA 2024-07-18
ER

PT J
AU Halit, C
   Capin, T
AF Halit, Cihan
   Capin, Tolga
TI Multiscale motion saliency for keyframe extraction from motion capture
   sequences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion saliency; motion capture; keyframe extraction; PCA
AB Motion capture is an increasingly popular animation technique; however data acquired by motion capture can become substantial. This makes it difficult to use motion capture data in a number of applications, such as motion editing, motion understanding, automatic motion summarization, motion thumbnail generation, or motion database search and retrieval. To overcome this limitation, we propose an automatic approach to extract keyframes from a motion capture sequence. We treat the input sequence as motion curves, and obtain the most salient parts of these curves using a new proposed metric, called 'motion saliency'. We select the curves to be analysed by a dimension reduction technique, Principal Component Analysis (PCA). We then apply frame reduction techniques to extract the most important frames as keyframes of the motion. With this approach, around 8% of the frames are selected to be keyframes for motion capture sequences. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Halit, Cihan; Capin, Tolga] Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Çapin, T (corresponding author), Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
EM halit@cs.bilkent.edu.tr; tcapin@cs.bilkent.edu.tr
RI Capin, Tolga K/K-2683-2012; Çapın, Tolga Kurtuluş/G-6172-2018
FU NSF [EIA-0196217]
FX The data used in this project was obtained from mocap.cs.cmu.edu. The
   database was created with funding from NSF EIA-0196217. The authors
   thank Eyuphan Bulut for his help in initial implementation of curve
   saliency.
CR Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   [Anonymous], 1981, Human Walking
   ARIKAN O, 2006, COMPUTER GRAPHICS P
   Barbic J., 2004, SEGMENTING MOTION CA
   BOULIC R, 1999, INT C MULT MOD
   BULUT E, 2007, CASA, P63
   COLEMAN P, 2008, S COMP AN JUL
   Cooper M, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P25
   Glardon P, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P292, DOI 10.1109/CGI.2004.1309224
   Gong YH, 2000, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2000.854772
   Gu Q, 2009, COMPUT GRAPH FORUM, V28, P1, DOI 10.1111/j.1467-8659.2008.01309.x
   HAUNG K, 2005, VISUAL COMPUT, V21, P532
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kondo K., 2004, Journal for Geometry and Graphics, V8, P81
   KWON J, 2007, 15 PAC C COMP GRAPH
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   LI S, 2005, P IEEE INT C MULT EX
   Lim IS, 2001, P ANN INT IEEE EMBS, V23, P1167
   LIM S, 2002, P IEEE C MULT EXP
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Parent Rick., 2001, Computer animation: algorithms and techniques
   Park MJ, 2004, COMPUT ANIMAT VIRT W, V15, P245, DOI 10.1002/cav.27
   PULLEN K, 2002, SIGGRAPH02
   SATTLER M, 2005, EUR ACM SIGGRAPH S C
   Togawa H, 2005, 11TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS WORKSHOPS, VOL II, PROCEEDINGS,, P182
   WITKIN A, 1995, SIGGRAPH 95, P105
   ZHAO J, 1989, MSCIS8909 U PENNS
NR 28
TC 30
Z9 36
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2011
VL 22
IS 1
BP 3
EP 14
DI 10.1002/cav.380
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 727SD
UT WOS:000287820600002
DA 2024-07-18
ER

PT J
AU Kim, SJ
   Gil, KJ
   Kim, H
   Lim, SB
   Kim, JI
AF Kim, Soo Jeong
   Gil, Kyung Jun
   Kim, HyungSeok
   Lim, Sang Boem
   Kim, Jee-in
TI Adaptive interactions in shared virtual environments for heterogeneous
   devices
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE adaptive interface; interaction adaptation; ubiquitous; service
AB In this research, we propose a method to adapt the interfaces and interaction processes of heterogeneous devices. The proposed method models the interaction capability of the devices. The interaction is modeled by categorizing elementary actions and measuring its effect in semantic behaviors. With this model, an interaction process can be modified to a given device by changing sequence of elementary actions for each behavior. In the pilot test, we showed the possibility of interaction adaptation for different situations. With the proposed adaptation mechanism, interface and interaction can be modeled for the device independently and can be transferred over different interaction environments. Copyright 0 (C) 2010 John Wiley & Sons, Ltd.
C1 [Kim, Soo Jeong; Kim, HyungSeok] Konkuk Univ, Dept Internet & Multimedia Engn, Seoul, South Korea.
   [Gil, Kyung Jun] Konkuk Univ, Dept Adv Technol, Seoul, South Korea.
   [Kim, HyungSeok] Univ Geneva, MIRALab, CH-1211 Geneva 4, Switzerland.
C3 Konkuk University; Konkuk University; University of Geneva
RP Kim, H (corresponding author), Konkuk Univ, Dept Internet & Multimedia Engn, Seoul, South Korea.
EM hyuskim@konkuk.ac.kr
RI SEOK, KIM HYUNG/C-2742-2009
OI SEOK, KIM HYUNG/0000-0003-4816-2992
FU Ministry of Land, Transport, and Maritime Affairs of Korea; Ministry of
   Land, Transport and Maritime Affairs (MLTM)
FX This research is supported by the project "Development of u-Eco City
   Business Service Platform" funded by the Ministry of Land, Transport,
   and Maritime Affairs of Korea. This work is financially supported by
   Korea Minister of Ministry of Land, Transport and Maritime Affairs
   (MLTM) as [U-City Master and Doctor Course Grant Program)
CR Arafa Y., 2000, IUI 2000. 2000 International Conference on Intelligent User Interfaces, P9, DOI 10.1145/325737.325748
   DEY AK, 1999, ISWC 99, P21
   GAJOS KZ, 2008, P CHI 08, P1257
   GIACOMO TD, 2004, WORKSH MOD MOT CAPT
   HARADA S, 2007, P ASSETS 07
   Hornof A., 2004, ASSETS 2004. The Sixth International ACM SIGACCESS Conference on Computers and Accessibility, P86
   Roman M., 2002, IEEE Pervasive Computing, V1, P74, DOI 10.1109/MPRV.2002.1158281
   Yoon SY, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P249
NR 8
TC 1
Z9 1
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2010
VL 21
IS 5
BP 531
EP 543
DI 10.1002/cav.338
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 672VP
UT WOS:000283615300006
DA 2024-07-18
ER

PT J
AU Bao, K
   Wu, XL
   Zhang, H
   Wu, EH
AF Bao, Kai
   Wu, Xiaolong
   Zhang, Hui
   Wu, Enhua
TI Volume fraction based miscible and immiscible fluid animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE multiple fluids; miscible flow; volume fraction; VOF; finite volume
   method
ID ADAPTIVE SOLVER; ALGORITHMS; SIMULATION; DYNAMICS; SURFACE
AB We propose a volume fraction based approach to effectively simulate the miscible and immiscible flows simultaneously. In this method, a volume fraction is introduced for each fluid component and the mutual interactions between different fluids are simulated by tracking the evolution of the volume fractions. Different techniques are employed to handle the miscible and immiscible interactions and special treatments are introduced to handle flows involving multiple fluids and different kinds of interactions at the same time. With this method, second-order accuracy is preserved in both space and time. The experiment results show that the proposed method can well handle both immiscible and miscible interactions between fluids and much richer mixing detail can be generated. Also, the method shows good controllability. Different mixing effects can be obtained by adjusting the dynamic viscosities and diffusion coefficients. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Bao, Kai] Chinese Acad Sci, State Key Lab Comp Sci, Inst Software, Beijing 100190, Peoples R China.
   [Zhang, Hui] Tsinghua Univ, Dept Engn Phys, Beijing, Peoples R China.
   [Zhang, Hui] Tsinghua Univ, Ctr Publ Safety Res, Beijing, Peoples R China.
   [Wu, Enhua] Univ Macau, Macau, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Tsinghua
   University; Tsinghua University; University of Macau
RP Bao, K (corresponding author), Chinese Acad Sci, State Key Lab Comp Sci, Inst Software, POB 8718, Beijing 100190, Peoples R China.
EM baokai@ios.ac.cn
CR BELL JB, 1989, J COMPUT PHYS, V85, P257, DOI 10.1016/0021-9991(89)90151-4
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   HIRT CW, 1981, J COMPUT PHYS, V39, P201, DOI 10.1016/0021-9991(81)90145-5
   Hong JM, 2005, ACM T GRAPHIC, V24, P915, DOI 10.1145/1073204.1073283
   Hong JM, 2003, COMPUT GRAPH FORUM, V22, P253, DOI 10.1111/1467-8659.00672
   Khokhlov AM, 1998, J COMPUT PHYS, V143, P519, DOI 10.1006/jcph.1998.9998
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   Mihalef Viorel., 2006, S COMPUTER ANIMATION, P317
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Park J, 2008, COMPUT ANIMAT VIRT W, V19, P455, DOI 10.1002/cav.256
   Popinet S, 2003, J COMPUT PHYS, V190, P572, DOI 10.1016/S0021-9991(03)00298-5
   Popinet S, 2009, J COMPUT PHYS, V228, P5838, DOI 10.1016/j.jcp.2009.04.042
   Scardovelli R, 1999, ANNU REV FLUID MECH, V31, P567, DOI 10.1146/annurev.fluid.31.1.567
   Stam J., 1999, The Proceedings of SIGGRAPH, P121, DOI DOI 10.1145/311535.311548
   Youngs D.L., 1982, NUMERICAL METHODS FL, P273
   ZHU H, 2007, P 2007 ACM S VIRT RE, P55
   Zhu HB, 2006, COMPUT ANIMAT VIRT W, V17, P403, DOI 10.1002/cav.143
NR 18
TC 18
Z9 23
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 401
EP 410
DI 10.1002/cav.356
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400026
DA 2024-07-18
ER

PT J
AU Manders, C
   Farbiz, F
   Yin, TK
   Yuan, ML
   Guan, CG
AF Manders, Corey
   Farbiz, Farzam
   Yin, Tang Ka
   Yuan Miaolong
   Guan, Chua Gim
TI A gesture control system for intuitive 3D interaction with virtual
   objects
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Virtual-Reality Continuum and its
   Applications in Industry
CY DEC 08-09, 2008
CL Singapore, SINGAPORE
SP ACM SIGGRAPH
DE virtual reality; augmented reality; virtual object manipulation;
   computer vision; hand tracking; interaction techniques
AB We present a system for interacting with 3D objects in a 3D virtual environment. Using the notion that a typical head-mounted display (HMD) does not cover the user's entire face, we use a fiducial marker placed on the HMD to locate the user's exposed facial skin. Using this information, a skin model is built and combined with the depth information obtained from a stereo camera. The information when used in tandem allows the position of the user's hands to be detected and tracked in real time. Once both hands are located, our system allows the user to manipulate the object with five degrees of freedom (translation in x-, y-, and z- axis with roll and yaw rotations) in virtual three-dimensional space using a series of intuitive hand gestures. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Farbiz, Farzam; Yin, Tang Ka; Yuan Miaolong] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R)
RP Farbiz, F (corresponding author), ASTAR, Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis, Singapore 138632, Singapore.
EM farbizf@i2r.a-star.edu.sg
RI Farbiz, Farzam/AAC-4088-2020
OI Farbiz, Farzam/0000-0001-8387-6507
CR Baecker R.M., 1987, Readings in Human-Computer Interaction: A Multidisciplinary Approach
   Billinghurst M, 2002, COMMUN ACM, V45, P64, DOI 10.1145/514236.514265
   Bradski G.R., 1998, INTEL TECHNOLOGY J, P15
   CANDOCIA FM, 2002, IEEE ICASSP, V4
   CANDOCIA FM, 2002, SYNTHESIZING PANORAM
   Ford A., COLOR SPACE CONVERSI
   GROSSBERG MD, 2002, P EUR C COMP VIS ECC
   *INT, INT OP SOURC COMP VI
   Kato H., 1999, P 2 INT WORKSH AUGM
   Larson G. W., 1998, Journal of Graphics Tools, V3, P15, DOI 10.1080/10867651.1998.10487485
   Manders CE, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P418, DOI 10.1109/ISIMP.2004.1434089
   Mann S., 2001, INTELLIGENT IMAGE PR
   McMenemy Karen., 2007, HITCHHIKERS GUIDE VI
   Poynton CharlesA., 1996, TECHNICAL INTRO DIGI
   REKIMOTO J, 1995, ACM S US INT SOFTW T, P29
   Shin MC, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P275, DOI 10.1109/ACV.2002.1182194
   Vezhnevets V., 2003, GRAPHICON
NR 17
TC 1
Z9 1
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2010
VL 21
IS 2
SI SI
BP 117
EP 129
DI 10.1002/cav.324
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 586CJ
UT WOS:000276878600006
DA 2024-07-18
ER

PT J
AU Grillon, H
   Thalmann, D
AF Grillon, Helena
   Thalmann, Daniel
TI Simulating gaze attention behaviors for crowds
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE crowd animation; crowd realism; attention behaviors; crowd motion
   editing
ID MODEL; EYE
AB Crowd animation is a topic of high interest which offers many challenges. One of the most important is the trade-off between rich, realistic behaviors, and computational costs. To this end, much effort has been put into creating variety in character representation and animation. Nevertheless, one aspect still lacking realism in virtual crowd characters resides in their attention behaviors. In this paper, we propose a framework to add gaze attention behaviors to crowd animations. First, We automatically extract interest points from character or object trajectories in pre-existing animations. For a given character, We assign a set of elementary scores based on parameters such as distance or speed to all other characters or objects in the scene. We then combine these subscores in all overall scoring function. The scores obtained from this function form a set of gaze constraints that determine where and when each character should look. We finally enforce these constraints With all optimized dedicated gaze Inverse Kinematics (IK) solver. It first computes Me displacement maps for the constraints to be satisfied. It then smoothly propagates these displacements over all automatically defined number of frames. We demonstrate the efficiency of our method and our visually convincing results through various examples. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Grillon, Helena] Ecole Polytech Fed Lausanne, IC ISIM VRLAB, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Grillon, H (corresponding author), Ecole Polytech Fed Lausanne, IC ISIM VRLAB, Stn 14, CH-1015 Lausanne, Switzerland.
EM helena.grillon@epfl.ch
RI Thalmann, Daniel/AAL-1097-2020; Thalmann, Daniel/A-4347-2008
OI Thalmann, Daniel/0000-0002-0451-7491; 
CR ARIKAN O, 2002, P 29 ANN C COMP GRAP, P483
   Badler N., 1985, VISUAL COMPUT, V1, P212
   Boulic R., 2004, J. Game Develop., V1, P29
   CALLENNEC BL, 2004, P 2004 ACM SIGGRAPH, P163
   Choi KJ, 2000, J VISUAL COMP ANIMAT, V11, P223, DOI 10.1002/1099-1778(200012)11:5<223::AID-VIS236>3.0.CO;2-5
   GILLIES M, 2001, THESIS U CAMBRIDGE
   GROSSMAN GE, 1988, EXP BRAIN RES, V70, P470
   Gu E, 2006, LECT NOTES ARTIF INT, V4133, P193
   HILL R, 1999, P COMP GEN FORC BEH
   Itti L, 2003, PROC SPIE, V5200, P64, DOI 10.1117/12.512618
   Khullar SC, 2001, AUTON AGENT MULTI-AG, V4, P9, DOI 10.1023/A:1010010528443
   KIM Y, 2005, P BEH REPR MOD SIM
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   KOVAR L, 2003, P ACM SIGGRAPH EUR S, P214
   Kuffner JJ, 1999, COMP ANIM CONF PROC, P118, DOI 10.1109/CA.1999.781205
   Kulpa R, 2005, COMPUT GRAPH FORUM, V24, P343, DOI 10.1111/j.1467-8659.2005.00859.x
   Lee J, 1999, COMP GRAPH, P39
   Lee Jehee., 2002, Proceedings of the 29th annual conference on Computer graphics and interactive techniques, P491, DOI DOI 10.1145/566570.566607
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Lee SH, 2006, ACM T GRAPHIC, V25, P1188, DOI 10.1145/1141911.1142013
   MAIM J, 2009, IEEE COMPUTER GRAPHI, V29
   Marchand É, 2002, VISUAL COMPUT, V18, P1, DOI 10.1007/s003710100122
   Neisser U, 1967, COGNITIVE PSYCHOL
   PEINADO M, 2007, P ACM S VIRT REAL SO, P89
   Peters C, 2005, LECT NOTES ARTIF INT, V3661, P229
   Peters C, 2003, COMP ANIM CONF PROC, P111, DOI 10.1109/CASA.2003.1199311
   Peters C, 2002, COMPUT GRAPH FORUM, V21, P743, DOI 10.1111/1467-8659.00632
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Sung M, 2004, COMPUT GRAPH FORUM, V23, P519, DOI 10.1111/j.1467-8659.2004.00783.x
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   YANTIS S, 1990, J EXP PSYCHOL HUMAN, V16, P121, DOI 10.1037/0096-1523.16.1.121
   Yu QX, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P119
NR 33
TC 22
Z9 26
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 111
EP 119
DI 10.1002/cav.293
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Matsumoto, T
   Hashimoto, S
   Okude, N
AF Matsumoto, Takashi
   Hashimoto, Sho
   Okude, Noohito
TI The embodied Web: embodied Web-services interaction with an umbrella for
   augmented city experiences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE embodied Web; ubiquitous computing; embodied interaction design;
   tangible interface; human-in formation interaction; social computing
AB This paper introduces the embodied Web, a new design paradigm for mobile devices. The embodied Web aims to provide an interface using real-world embodied interaction to provide a computer-augmented reality that accesses web services. This platform regards embodied interaction at three levels: operational level, activity level and social level; and is implemented with a combination of sensor, actuator and network connectivities. The platform is developed as a complex of hardware, software and network services. The implementation takes an approach of modularization of hardware, software and web services. As a practical prototype of the embodied Web, the Internet Umbrella Pileus was developed and tested. In contrast to the small screens of mobile devices, Pileus has a big screen on the underside of the umbrella, and it is operated by embodied interaction, including motion sensing of the device and location sensing of walking activities. Photo-sharing and 3D map navigation is provided on the umbrella to expand the user's activity area. These services are provided by API hookups with Flickr and Google Earth. Pileus has been iteratively developed from user observations, design observations and intuitions and prototype evaluations. The umbrella was tested in a large urban environment (the city of Tokyo). Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Matsumoto, Takashi; Okude, Noohito] Keio Univ, Okude Lab, Kanagawa 2528520, Japan.
C3 Keio University
RP Matsumoto, T (corresponding author), Keio Univ, Okude Lab, 5322 Endo, Kanagawa 2528520, Japan.
EM ma22n@sfc.keio.ac.jp
RI Matsumoto, Takashi/JQI-3451-2023
OI Matsumoto, Takashi/0000-0003-0105-0061
CR AHERN S, 2005, P ACM MULT, P790, DOI DOI 10.1145/1101149.1101317
   [Anonymous], 2002, CSCW '02, DOI DOI 10.1145/587078.587102
   [Anonymous], 2007, You Tube
   [Anonymous], 2007, Facebook
   Ballagas R., 2003, CHI, P537, DOI DOI 10.1145/642611.642705
   Beehaxee A.K., 2006, MOBILEHCI 06, P81, DOI DOI 10.1145/1152215.1152233
   BUNSELMEYER L, FLICKR LOVES YOU FAC
   Davies MCR, 2005, Proceedings of the 16th International Conference on Soil Mechanics and Geotechnical Engineering, Vols 1-5, P1335
   DOURISH P, 2001, WHERE ACTION IS FDN
   HASHIMOTO S, 2006, UBICOMP 2006 DEMO
   HASHIMOTO S, 2007, ACM ACE 2007 SALZ AU
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   JONES S, 2006, CHI 06 HUM FACT COMP, P63, DOI DOI 10.1145/1125451.1125469
   Kaye D., 2003, Loosely coupled: the missing pieces of Web services
   MATSUMOTO T, 2007, P MOB C SING, P595
   OREILLY T, WHAT WEB 2 0
   TSUKADA K, 2006, ADJUNCT P PERVASIVE, V207, P97
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   2007, DELICIOUS
   2007, FLICKR
   2007, MYSPACE
   2006, CHI2006 PAN MONTR CA
NR 22
TC 5
Z9 5
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2008
VL 19
IS 1
BP 49
EP 66
DI 10.1002/cav.222
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 283ZM
UT WOS:000254675000006
DA 2024-07-18
ER

PT J
AU Zhang, JJ
   Yang, XS
   Zhao, YF
AF Zhang, Jian J.
   Yang, Xiaosong
   Zhao, Yunfeng
TI Bar-net driven skinning for character animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE character animation; skin deformation; physically based animation;
   barnetwork form finding
AB In this paper we present a physically motivated technique for the deformation of animated characters, called the bar-net driven skinning. We use a bar-network (bar-net) as a deforming mechanism. This technique can be used similarly to a conventional skinning tool, but can also make a skin surface behave in a physically plausible manner due to the inherent physical properties of the network. A bar-net is a structure commonly used in structural engineering. Its shape depends on the structural and material properties and the forces acting upon it. Computing the rest shape of an arbitrary bar-net is a time-consuming non-linear problem. In order to speed up the computation and also for such a bar-net to be used intuitively to help computer animation, we have defined a set of properties that a desirable bar-net should satisfy. This allows a bar-net shape finding problem to be solved using linear equations. We adopt a two-layer structure for the representation of a skin surface, including a coarse mesh and a fine mesh. To deform a skin surface, we couple a bar-net to its coarse mesh, which in turn deforms the fine mesh when the coupled bar-net is deformed. The fine surface mesh can be of different forms, including Nurbs, subdivision surfaces and polygons. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Bournemouth Univ, Sch Media, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University
RP Yang, XS (corresponding author), Bournemouth Univ, Sch Media, Poole BH12 5BB, Dorset, England.
EM xyzng@bournemouth.ac.uk
OI Yang, Xiaosong/0000-0003-3815-0584
CR Albrecht Irene., 2003, P 2003 ACM SIGGRAPHE, P98
   Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626
   [Anonymous], 2001, P 2001 S INTERACTIVE
   [Anonymous], 2002, P 2002 ACM SIGGRAPHE
   Catmull Edwin, 1972, P ACM ANNU C, P422
   Chadwick J. E., 1989, Computer Graphics, V23, P243, DOI 10.1145/74334.74358
   Coquillart S., 1990, J. Computer Graphics, V24, P187, DOI DOI 10.1145/97880.97900
   Debunne G, 2000, COMP ANIM CONF PROC, P15, DOI 10.1109/CA.2000.889022
   DEBUNNE G, 1910, P 28 ANN C COMP GRAP, P31
   Der KG, 2006, ACM T GRAPHIC, V25, P1174, DOI 10.1145/1141911.1142011
   HSU WM, 1992, COMP GRAPH, V26, P177, DOI 10.1145/142920.134036
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Lee SH, 2006, ACM T GRAPHIC, V25, P1188, DOI 10.1145/1141911.1142013
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   MacCracken Ron., 1996, SIGGRAPH, P181, DOI DOI 10.1145/237170.237247
   Magnenat-Thalmann Nadia, 1988, P GRAPHICS INTERFACE
   Miller M., 2002, P 2002 ACM SIGGR EUR, P49
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Nedel LP, 1998, COMP ANIM CONF PROC, P34, DOI 10.1109/CA.1998.681905
   Pratscher Michael., 2005, SCA 05, P329
   SCHEEPERS CF, 1996, THESIS OHIO STATE U
   SCHEEPERS F, 1997, P 24 ANN C COMP GRAP, P163, DOI DOI 10.1145/258734.258827
   Schek H.-J., 1974, Computer Methods in Applied Mechanics and Engineering, V3, P115, DOI 10.1016/0045-7825(74)90045-0
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Shen Jianhua, 1993, Proceedings of the Third International Conference on CAD and Computer Graphics, P95
   SIMMONS M, 2002, P 2002 ACM SIGGRAPH, P139, DOI DOI 10.1145/545261.545284
   Singh K, 2000, PROC GRAPH INTERF, P35
   SINGH K, 1995, REALISTIC HUMAN FIGU
   WILHELMS J, 1995, MODELING ANIMALS BON
   WILHELMS J, 1997, P SIGGRAPH 97, P173
   Yang X, 2006, COMPUT ANIMAT VIRT W, V17, P293, DOI 10.1002/cav.133
NR 31
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 437
EP 446
DI 10.1002/cav.211
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000022
DA 2024-07-18
ER

PT J
AU Polys, NF
   Kim, S
   Bowman, DA
AF Polys, Nicholas F.
   Kim, Seonho
   Bowman, Doug A.
TI Effects of information layout, screen size, and field of view on user
   performance in Information-Rich Virtual Environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D interaction; visual design; usability testing and evaluation;
   Information-Rich Virtual Environments (IRVE); multimedia information
   systems; human factors
AB This paper describes our recent experimental evaluation of Information-Rich Virtual Environment (IRVE) interfaces. To explore the depth cue/visibility tradeoff between annotation schemes, we design and evaluate two information layout techniques to support search and comparison tasks. The techniques provide different depth and association cues between objects and their labels: labels were displayed either in the virtual world relative to their referent (Object Space) or on an image plane workspace (Viewport Space). The Software Field of View (SFOV) was controlled to 60 degrees or 100 degrees of vertical angle and two groups were tested: those running on a single monitor and those on a tiled nine-panel display. Users were timed, tracked for correctness, and gave ratings for both difficulty and satisfaction on each task. Significant advantages were found for the Viewport interface, and for high SFOV. The interactions between these variables suggest special design considerations to effectively support search and comparison performance across monitor configurations and projection distortions. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Virginia Tech, Dept Comp Sci, Blacksburg, VA 24061 USA.
   Virginia Tech, Ctr Human Comp Interact, Blacksburg, VA 24061 USA.
C3 Virginia Polytechnic Institute & State University; Virginia Polytechnic
   Institute & State University
RP Polys, NF (corresponding author), Virginia Tech, Dept Comp Sci, 660 McBryde Hall, Blacksburg, VA 24061 USA.
EM npolys@vt.edu
OI Polys, Nicholas/0000-0002-8503-970X
CR [Anonymous], P CHI 97
   BARRILLEUX J, 2001, 3D USER INTERFACES J
   Bell Blaine., 2001, Proceedings of the ACM Symposium on User Interface Software and Technology (UIST'01), P101, DOI DOI 10.1145/502360.502363
   BOLTER J, 1995, IEEE COMPUT GRAPH, V15, P8, DOI 10.1109/38.391481
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman D.A., 2004, 3D USER INTERFACES
   Bowman D. A., 2003, P ACM S VIRT REAL SO, DOI DOI 10.1145/1008653.1008669
   BRUTZMAN D, 2002, P WEB3D, P93
   Card S. K., 1999, USING VISION THINK
   CHANDLER P, 1991, COGNITION INSTRUCT, V8, P293, DOI 10.1207/s1532690xci0804_2
   Chen J, 2004, P IEEE VIRT REAL ANN, P181, DOI 10.1109/VR.2004.1310072
   Czerwinski M., 2003, P INT, V3, P9
   Draper MH, 2001, HUM FACTORS, V43, P129, DOI 10.1518/001872001775992552
   Ekstrom R.B., 1976, KIT FACTORREFERENCED
   Faraday P., 1998, Proceedings ACM Multimedia 98, P29, DOI 10.1145/290747.290752
   Feiner Steven., 1993, Proceedings of the 6th ACM Symposium on User Interface Software and Technology (UIST '93), P145
   Furnas G. W., 1986, ACM Sigchi Bull., V17, P16, DOI DOI 10.1145/22339.22342
   GOGUEN J, 1999, INFORMATION VISUALIZ
   Goldstein E. B., 2021, Sensation and Perception
   GUTWIN C, 2003, P CHI, V5, P201
   MACKINLAY JD, 2004, P CHI 04 VIENN AUST, P1521
   McClean P, 2001, SELECTED PAPERS FROM THE 12TH INTERNATIONAL CONFERENCE ON COLLEGE TEACHING AND LEARNING, P111
   Murray-Rust P, 2001, NEW J CHEM, V25, P618, DOI 10.1039/b008780g
   Polys N., 2004, Proceedings of the ninth international conference on 3D Web technology, P7
   Polys N. F., 2004, Virtual Reality, V8, P41, DOI 10.1007/s10055-004-0134-0
   Polys N.F., 2003, P 8 INT C 3D WEB TEC
   POLYS NF, 2004, NASA VIRTUAL IRON BI
   POUPYREV I, 1996, P UIST
   Shneiderman Ben., 1996, P IEEE VISUAL LANGUA
   SWAMINATHAN K, 1997, ACM INTERACTIONS
   Tan Desney S, 2003, Proceedings of the SIGCHI conference on Human factors in computing systems, CHI'03, P217, DOI DOI 10.1145/642611.642650
   Thomas JJ, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.5
   Ware C., 2003, HCI MODELS THEORIES
   Wei B, 2000, IEEE COMPUT GRAPH, V20, P50, DOI 10.1109/38.851750
NR 34
TC 22
Z9 27
U1 0
U2 23
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2007
VL 18
IS 1
BP 19
EP 38
DI 10.1002/cav.159
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 149ML
UT WOS:000245150900004
DA 2024-07-18
ER

PT J
AU Komura, T
   Lam, WC
AF Komura, Taku
   Lam, Wai-Chun
TI Real-time locomotion control by sensing gloves
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE sensing glove; computer puppetry; 3D user interface; 3D game
ID HUMAN MOTION
AB Sensing gloves are often used as an input device for virtual 3D games. We propose a new method to control characters such as humans or animals in real-time by using sensing gloves. Based on existing motion data of the body, a new method to map the hand motion of the user to the locomotion of 3D characters in real-time is proposed. The method was applied to control locomotion of characters such as humans or dogs. Various motions such as trotting, running, hopping, and turning could be produced. As the computational cost needed for our method is low, the response of the system is short enough to satisfy the real-time requirements that are essential to be used for games. Using our method, users can directly control their characters intuitively and precisely than previous controlling devices such as mouse, keyboards or joysticks. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Komura, T (corresponding author), City Univ Hong Kong, Dept Comp Sci, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
EM taku@ieee.org
CR [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], P 22 ANN C COMP GRAP
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   *ASC TECHN CO, 1998, FLOCK BIRDS REAL TIM
   BURDEA G, 1983, EL 93 INT C ED NJ
   Fang AC, 2003, ACM T GRAPHIC, V22, P417, DOI 10.1145/882262.882286
   Gleicher M, 1998, J VISUAL COMP ANIMAT, V9, P65, DOI 10.1002/(SICI)1099-1778(199804/06)9:2<65::AID-VIS176>3.0.CO;2-Z
   Gleicher M., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P139, DOI 10.1145/253284.253321
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Igarashi T., 2005, Proceedings of the 2005 acm siggraph/eurographics symposium on computer animation, P107, DOI DOI 10.1145/1073368.1073383
   *IMM CO, 2001, CYBERGLOVE
   Komura T, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P266, DOI 10.1109/CGI.2003.1214480
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Laszlo J, 2000, COMP GRAPH, P201, DOI 10.1145/344779.344876
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Sturman DJ, 1998, IEEE COMPUT GRAPH, V18, P38, DOI 10.1109/38.637269
   ESSENTIAL REALITY P5
NR 21
TC 5
Z9 6
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2006
VL 17
IS 5
BP 513
EP 525
DI 10.1002/cav.114
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 111UX
UT WOS:000242481700002
DA 2024-07-18
ER

PT J
AU Chao, SP
   Yang, SN
   Lin, TG
AF Chao, Shih-Pin
   Yang, Shi-Nine
   Lin, Tsang-Gang
TI An LMA-<i>Effort</i> simulator with dynamics parameters for motion
   capture animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation techniques; dynamics-based animation; motion capture and human
   body simulation; motion control; procedural modeling
AB This paper presents a dynamics-based Effort simulator so that a given motion can be modified according to specified Effort qualities. The basic idea of our approach is to establish relations between Effort factors such as Space, Weight, Time, and Flow, and their corresponding dynamics parameters such as force, stiffness, inertia, damping, gravity, and etc in the simulator. Then, a motion With specified Effort quality can be realized by mapping it to appropriate dynamics parameters of the simulator. The proposed simulator has two merits: it is motion capture-driven, therefore it is able to synthesize motion details and easily to be incorporated into popular motion capture applications. Besides, it is dynamics based and therefore it provides high-level control intuition of motion dynamics in specifying Effort qualities. To demonstrate the effectiveness of the proposed simulator, several experimental examples are presented and their results are discussed. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Tsing Hua University
RP Yang, SN (corresponding author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
EM snyang@cs.nthu.edu.tw
CR Amaya K, 1996, PROC GRAPH INTERF, P222
   [Anonymous], 2001, Doctoral thesis,
   Badler N, 2002, COMP ANIM CONF PROC, P133, DOI 10.1109/CA.2002.1017521
   Badler N.I., 1989, DANCE TECHNOLOGY, P23
   Bevacqua E, 2004, COMPUT ANIMAT VIRT W, V15, P297, DOI 10.1002/cav.32
   CHI D, 2000, P SIGGRAPH 00, P263
   Conde T, 2004, COMPUT ANIMAT VIRT W, V15, P311, DOI 10.1002/cav.34
   Egges A, 2004, COMPUT ANIMAT VIRT W, V15, P1, DOI 10.1002/cav.3
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Maletic Vera., 2005, Dance Dynamics: Effort and Phrasing
   Mataric M. J., 1999, Autonomous Agents and Multi-Agent Systems, V2, P23, DOI 10.1023/A:1010023022632
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Unuma M., 1995, P 22 ANN C COMPUTER, P91, DOI DOI 10.1145/218380.218419
   Zhao LW, 2005, GRAPH MODELS, V67, P1, DOI 10.1016/j.gmod.2004.08.002
   Zordan V. B., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P89
NR 15
TC 4
Z9 4
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 167
EP 177
DI 10.1002/cav.120
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400004
DA 2024-07-18
ER

PT J
AU Bao, YF
   Guo, XH
   Qin, H
AF Bao, YF
   Guo, XH
   Qin, H
TI Physically based morphing of point-sampled surfaces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE physically based animation; dynamic shape modeling; morphing; meshless
   method; point-based geometry
AB This paper presents an innovative method for naturally and smoothly morphing point-sampled surfaces via dynamic meshless simulation on point-sampled surfaces. While most existing literature on shape morphing emphasizes the issue of finding a good correspondence map between two object representations, this research primarily investigates the challenging problem of how to find a smooth, physically-meaningful transition path between two homeomorphic point-set surfaces. We analyze the deformation of surface involved in the morphing process using concepts in differential geometry and continuum mechanics. The morphing paths can be determined by optimizing an energy functional, which characterizes the intrinsic deformation of the surface away from its rest shape. As demonstrated in the examples, our method automatically produces a series of natural and physically-plausible in-between shapes, which greatly alleviates the shrinking, stretching, and self-intersection problems that often occur when linear interpolation is employed for the morphing of two objects. We envision that our new technique will continue to broaden the application scope of point-set surfaces and their dynamic animation. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM ybao@cs.sunysb.edu; xguo@cs.sunysb.edu; qin@cs.sunysb.edu
FU Direct For Computer & Info Scie & Enginr [0830183] Funding Source:
   National Science Foundation; Div Of Information & Intelligent Systems
   [0830183] Funding Source: National Science Foundation
CR Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575
   Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   BELYTSCHKO T, 1994, INT J NUMER METH ENG, V37, P229, DOI 10.1002/nme.1620370205
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Cirak F, 2000, INT J NUMER METH ENG, V47, P2039, DOI 10.1002/(SICI)1097-0207(20000430)47:12<2039::AID-NME872>3.0.CO;2-1
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Floater MS, 2001, COMPUT AIDED GEOM D, V18, P77, DOI 10.1016/S0167-8396(01)00013-9
   Grinspun E., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P62
   GUO X, 2004, POINT BASED DYNAMIC
   GUO X, 2005, COMPUTER ANIMATION V, V16
   Guo XH, 2004, IEEE COMPUT GRAPH, V24, P43, DOI 10.1109/MCG.2004.16
   KREYSZIG E, 1991, DIFFERENTIAL GEOMETR, P72
   Lazarus F, 1998, VISUAL COMPUT, V14, P373, DOI 10.1007/s003710050149
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Pauly M, 2003, ACM T GRAPHIC, V22, P641, DOI 10.1145/882262.882319
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Pauly Mark., 2002, Multiresolution modeling of pointsampled geometry
   Sederberg T.W., 1993, SIGGRAPH 93, P15
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Xiao CX, 2004, COMPUT ANIMAT VIRT W, V15, P201, DOI 10.1002/cav.22
   Yan HB, 2004, COMPUT ANIMAT VIRT W, V15, P443, DOI 10.1002/cav.48
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
NR 25
TC 15
Z9 22
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 509
EP 518
DI 10.1002/cav.100
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000033
DA 2024-07-18
ER

PT J
AU Guo, YW
   Wang, J
   Zeng, X
   Xie, ZY
   Sun, HQ
   Peng, QS
AF Guo, YW
   Wang, J
   Zeng, X
   Xie, ZY
   Sun, HQ
   Peng, QS
TI Image and video retexturing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE image/video retexturing; Poisson equation; graph cut
AB We propose a novel image/video retexturing approach that preserves the original shading effects without knowing the underlying surface and lighting conditions. For static images, we first introduce the Poisson equation-based algorithm to simulate the texture distortion on the projected interest region of the underlying surface, while preserving the shading effect of the original image. We further work on videos by retexturing the key frame as static image and then propagating the results onto the other frames. In video retexturing, we have introduced the mesh based optimization for object tracking to avoid texture drifting, and the graph cut algorithm to effectively deal with visibility shift between frames. The graph cut algorithm is applied on a trimap along the boundary of the object to extract the textured part inside the trimap. The proposed approach is developed in image/video retexturing at nearly interactive rate, and our experimental results have showed the satisfactory performance of our approach. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, Dept Math, State Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhejiang Univ, Dept Math, State Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM ywguo@cad.zju.edu.cn
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P584, DOI 10.1145/1015706.1015764
   Altunbasak Y, 1997, IEEE T IMAGE PROCESS, V6, P1255, DOI 10.1109/83.623189
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   BRADSHAW DB, 1999, THESIS U CAMBRIDGE
   Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Fang H, 2004, ACM T GRAPHIC, V23, P354, DOI 10.1145/1015706.1015728
   Jin HL, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P684, DOI 10.1109/ICCV.2001.937588
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Liu YX, 2004, ACM T GRAPHIC, V23, P368, DOI 10.1145/1015706.1015731
   LIU YX, 2003, CMURITR0326
   Oh BM, 2001, COMP GRAPH, P433
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Tsin YH, 2001, PROC CVPR IEEE, P539
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
NR 18
TC 6
Z9 9
U1 3
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 451
EP 461
DI 10.1002/cav.82
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000028
DA 2024-07-18
ER

PT J
AU Ihm, I
   Cha, DY
   Kang, BW
AF Ihm, I
   Cha, DY
   Kang, BW
TI Controllable local monotonic cubic interpolation in fluid animations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE interpolation; cubic polynomial; monotonicity; controllability; fluid
   animation
ID SPLINE
AB While linear interpolation has been used frequently in computer graphics, higher-order interpolation is often desirable in applications requiring higher-order accuracy. In this paper, we study how interpolation filters, employed to resample such data as velocity, density, and temperature in simulating the equations of fluid dynamics, affect the animation of fluids. For this purpose, we have designed a controllable local cubic interpolation scheme that offers G(1) (or C-1) continuity globally. It is based on monotonic splines so does not suffer from undue overshooting. Furthermore, it is possible to control the general behavior of the interpolation through a global tension parameter, providing a continuous spectrum of linear to cubic interpolation. We analyze how this controllable interpolation filter may be effectively used to enhance the visual reality for physically based fluid animation. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Sogang Univ, Dept Comp Sci, Seoul, South Korea.
C3 Sogang University
RP Ihm, I (corresponding author), Sogang Univ, Dept Comp Sci, 1 Shinsu Dong, Seoul, South Korea.
EM ihm@sogang.ac.kr
CR [Anonymous], 2017, Elementary Numerical Analysis: an Algorithmic Approach
   BUTLAND J, 1980, P COMPUTER GRAPHICS, P409
   FOLEY TA, 1987, ACM T MATH SOFTWARE, V13, P68, DOI 10.1145/23002.23004
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   FRITSCH F, 1980, UCRL85104 LAWR LIV L
   FRITSCH FN, 1980, SIAM J NUMER ANAL, V17, P238, DOI 10.1137/0717021
   FRITSCH FN, 1984, SIAM J SCI STAT COMP, V5, P300, DOI 10.1137/0905021
   HADWIGER M, 2001, P VIS MOD VIS 2001, P105
   Manni C, 1996, J COMPUT APPL MATH, V69, P143, DOI 10.1016/0377-0427(94)00026-3
   Marschner S. R., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P100, DOI 10.1109/VISUAL.1994.346331
   MITCHELL DP, 1988, P 15 ANN C COMP GRAP, P221
   Moller T, 1997, IEEE T VIS COMPUT GR, V3, P184, DOI 10.1109/2945.597800
   Möller T, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P143, DOI 10.1109/SVV.1998.729596
   SAPIDIS NS, 1988, NUMER MATH, V54, P179, DOI 10.1007/BF01396973
   SCHWEIKERT DG, 1966, J MATH PHYS CAMB, V45, P312, DOI 10.1002/sapm1966451312
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   THEUSSL T, 2000, P IEEE S VOL VIS, P101
   Wolberg G, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P188, DOI 10.1109/CGI.1999.777953
NR 18
TC 2
Z9 2
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 365
EP 375
DI 10.1002/cav.93
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000021
OA Bronze
DA 2024-07-18
ER

PT J
AU Duan, Y
   Hua, J
   Qin, H
AF Duan, Y
   Hua, J
   Qin, H
TI <i>HapticFlow</i>:: PDE-based mesh editing with haptics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE PDE; surface flow; distance field; sketching; haptics; interaction
   techniques
ID SURFACES
AB This paper presents HapticFlow, a haptics-based direct mesh editing system founded upon the concept of PDE-based geometric surface flow. The proposed flow-based approach for direct geometric manipulation offers a unified design paradigm that can seamlessly integrate implicit, distance-field based shape modeling with dynamic, physics-based shape design. HapticFlow provides an intuitive haptic interface and allows users to directly manipulate 3D polygonal objects with ease. To demonstrate the effectiveness of our new approach, we developed a variety of haptics-based mesh editing operations such as embossing, engraving, sketching as well as force-based shape manipulation operations. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Missouri, Dept Comp Sci, Columbus, MS USA.
C3 University of Missouri System; University of Missouri Columbia
RP Univ Missouri, Dept Comp Sci, Columbus, MS USA.
EM duanye@missouri.edu
FU Direct For Computer & Info Scie & Enginr [0830183] Funding Source:
   National Science Foundation; Div Of Information & Intelligent Systems
   [0830183] Funding Source: National Science Foundation
CR Balakrishnan R., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P111, DOI 10.1145/300523.300536
   Caselles V, 1997, IEEE T PATTERN ANAL, V19, P394, DOI 10.1109/34.588023
   COHEROR D, 1997, ACM T GRAPHICS
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Foskey M, 2002, P IEEE VIRT REAL ANN, P119, DOI 10.1109/VR.2002.996514
   Frisken SF, 2000, COMP GRAPH, P249, DOI 10.1145/344779.344899
   Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119
   KIM L, 2002, P IEEE RSJ INT C INT
   KIM L, 2003, P ASME 11 ANN S HAPT
   KOBBELT L, 2000, EUROGRAPHICS, P249
   Mandal C, 2000, IEEE T VIS COMPUT GR, V6, P265, DOI 10.1109/2945.879787
   Morgenbesser H. B., 1996, Proceedings of the ASME Dynamic Systems and Control Division, P407
   PAYNE BA, 1992, IEEE COMPUT GRAPH, V12, P65, DOI 10.1109/38.135885
   Perry RN, 2001, COMP GRAPH, P47, DOI 10.1145/383259.383264
   Salisbury K., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P123, DOI 10.1145/199404.199426
   Schroeder W. J., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P40, DOI 10.1109/VISUAL.1994.346339
NR 16
TC 5
Z9 6
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 193
EP 200
DI 10.1002/cav.21
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700008
DA 2024-07-18
ER

PT J
AU Zhang, B
   Shi, HP
   Wang, XY
AF Zhang, Bo
   Shi, Huiping
   Wang, Xinyu
TI An auxiliary development framework for lightweight RPG games based on
   Unity3D
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE entity-component-system; Unity3D; TRPGFramework
ID CO-SIMULATION
AB With the growing prevalence of virtual reality technology across industries like cinema, video animation, and gaming, game developers must cater to a wider range of players. Game engines serve as middleware, reducing the time spent on coding and improving productivity for creating video games. While mainstream game engines offer a plethora of customization options, certain developers may find themselves limited when it comes to controlling specific aspects of the game. Due to the lack of built-in functionality in current game engines like Unity and Unreal, the author developed TRPGFramework, a lightweight framework based on Unity3D, to address some of these problems. The game framework consists of two main parts: ZGamework (overall framework) and BGamework (game-specific framework). To enhance performance, scalability, and code reusability in the game development process, the entity-component-system structure is implemented. This approach increases maintainability and makes the code clearer, easier to expand, and debuggable. By creating a simple 2D RPG game for performance testing, we confirmed that the framework significantly improves code reusability and modularity, resulting in faster development time and increased efficiency for interactive applications and games. This framework is particularly useful for creating real-time combat role-playing games, which are some of the most complex games available today. Using entity-component-system principles, we developed a buff system and unit controller optimized to allow hundreds of intelligent units to fight on the same screen or thousands of non-intelligent units to fight simultaneously.
C1 [Zhang, Bo; Shi, Huiping; Wang, Xinyu] Jinling Inst Technol, Dept Comp Engn, Nanjing, Peoples R China.
   [Zhang, Bo] Jinling Inst Technol, Dept Comp Sci, 99 Hongjing Ave, Nanjing 211169, Jiangsu, Peoples R China.
C3 Jinling Institute of Technology; Jinling Institute of Technology
RP Zhang, B (corresponding author), Jinling Inst Technol, Dept Comp Sci, 99 Hongjing Ave, Nanjing 211169, Jiangsu, Peoples R China.
EM 30719547@qq.com
RI Wang, Xinyu/IQU-9172-2023
OI Wang, Xinyu/0000-0002-3568-2211
FU Jinling Institute of Science Technology Research Initiation Project
FX No Statement Available
CR Afnan, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11115277
   Ahmed S., P IEEE 66 VEH TECHN
   Amin Dhiraj, 2015, International Journal on Computational Science & Applications, V5, P11, DOI DOI 10.5121/IJCSA.2015.5102
   Anderson C., 2012, Pro Business Applications with Silverlight, V5, P461, DOI 10.1007/978-1-4302-3501-9_13
   Basile Davide, 2022, Leveraging Applications of Formal Methods, Verification and Validation. Adaptation and Learning: 11th International Symposium, ISoLA 2022, Proceedings. Lecture Notes in Computer Science (13703), P142, DOI 10.1007/978-3-031-19759-8_10
   Bhattacharya I., 2007, ACM T KNOWL DISCOV D, V1, P1, DOI [10.1145/1217299.1217304, DOI 10.1145/1217299.1217304]
   Callum KM., EXPLORING ARMOBILE E
   Cao XR, 2002, DISCRETE EVENT DYN S, V12, P253, DOI 10.1023/A:1015617431563
   Cieza E, 2018, PROCEDIA COMPUT SCI, V130, P352, DOI 10.1016/j.procs.2018.04.051
   Elvezio C., P 2018 CHI C HUM FAC
   Fischbach M., 2017, IEEE T VIS COMPUT GR, VPP(4), P1
   Gamma E., DESIGN PATTERNS ELEM
   Gu MX., COMP ANAL WEBFORMS M
   Harris S., IMPLEMENTATION ANAL
   Hatledal LI, 2020, MODEL IDENT CONTROL, V41, P297, DOI 10.4173/mic.2020.4.2
   Hatledal LI, 2021, SIMUL MODEL PRACT TH, V108, DOI 10.1016/j.simpat.2020.102243
   Jadon S., 2014, ARXIV
   Lange P., P IEEE 9 WORKSH SOFT
   Maleki S., UNDERSTANDING IMPACT
   Raffaillac Thibault, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3331150
   Romeo, ANAL ENTITY ENCODING
   Sadjina S, 2019, J OFFSHORE MECH ARCT, V141, DOI 10.1115/1.4040473
   Thule C, 2019, SIMUL MODEL PRACT TH, V92, P45, DOI 10.1016/j.simpat.2018.12.005
   Wang RX, 2020, ADV ENG SOFTW, V148, DOI 10.1016/j.advengsoft.2020.102838
   Wu CH, 2017, IEEE ACCESS, V5, P12895, DOI 10.1109/ACCESS.2017.2718559
   Zhao S, 2021, IEEE T COMPUT SOC SY, V8, P464, DOI 10.1109/TCSS.2021.3052261
NR 26
TC 0
Z9 0
U1 34
U2 37
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2206
EA AUG 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KA3U2
UT WOS:001153667500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sun, LB
   Tian, R
   Qin, WH
AF Sun, Libo
   Tian, Rui
   Qin, Wenhu
TI Physical based motion reconstruction from videos using musculoskeletal
   model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character animation; musculoskeletal model; physical simulation;
   reinforcement learning
AB We propose a novel method that combines human pose estimation and physical simulation of character animation. Our approach allows characters to learn from the actor's skills captured in videos and subsequently reconstruct the motions with high fidelity in a physically simulated environment. Firstly, we model the character based on the human musculoskeletal system and build a complete dynamics model of the proposed system using the Lagrange equations of motion. Next, we employ the pose estimation method to process the input video and generate human reference motion. Finally, we design a hierarchical control framework consisting of a trajectory tracking layer and a muscle control layer. The trajectory tracking layer aims to minimize the difference between the reference motion pose and the actual output pose, while the muscle control layer aims to minimize the difference between the target torque and the actual output muscle force. The two layers interact by passing parameters through a proportional differential controller until the desired learning objective is achieved. A series of complex experimental results demonstrate that our proposed method can learn to produce comparable high-quality motions with high similarity from videos of different complexity levels and remains stable in the presence of muscle contracture weakness perturbations.
C1 [Sun, Libo; Tian, Rui; Qin, Wenhu] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Sun, LB; Qin, WH (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
EM sunlibo@seu.edu.cn; qinwenhu@seu.edu.cn
OI Tian, Rui/0009-0008-3335-811X
FU Jiangsu Provincial Key Research and Development Program [BE2019311];
   National key Research and Development program [2020YFB160070301]
FX ACKNOWLEDGMENTS This work was supported by Jiangsu Provincial Key
   Research and Development Program under Grant No. BE2019311 and National
   key Research and Development program under Grant No. 2020YFB160070301.
CR Bin Peng X, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925881
   Choi H, 2021, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR46437.2021.00200
   Geijtenbeek T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508399
   Geyer H, 2010, IEEE T NEUR SYS REH, V18, P263, DOI 10.1109/TNSRE.2010.2047592
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hansen N, 2003, EVOL COMPUT, V11, P1, DOI 10.1162/106365603321828970
   Heess N., 2017, CoRR, abs/1707.02286.
   Ichim AE, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073664
   John CT, 2013, COMPUT METHOD BIOMEC, V16, P451, DOI 10.1080/10255842.2011.627560
   Kanazawa A, 2019, PROC CVPR IEEE, P5597, DOI 10.1109/CVPR.2019.00576
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kojic M, 1998, INT J NUMER METH ENG, V43, P941, DOI 10.1002/(SICI)1097-0207(19981115)43:5<941::AID-NME435>3.0.CO;2-3
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Komura T, 1997, COMPUT GRAPH FORUM, V16, pC165, DOI 10.1111/1467-8659.00153
   Lee S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3196492
   Lee Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818124
   Li W., 2022, Exploiting temporal contexts with strided transformer for 3d human pose estimation
   Lillicrap, 2015, ARXIV150902971, P1
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Marcard T., 2018, P INT C COMP VIS ECC
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Merel J., 2017, Learning human behaviors from motion capture by adversarial imitation
   Peng XB, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275014
   Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275014
   Qin WH, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2092
   Schulman J., 2017, ARXIV
   Schulman J., High-dimensional continuous control using generalized advantage estimation
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Singh T, 2010, J NEUROPHYSIOL, V103, P2990, DOI 10.1152/jn.00077.2010
   Su YB, 2022, ACTUATORS, V11, DOI 10.3390/act11030068
   Sun L., 2023, COMPUT ANIMAT VIRT W, V34
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JH, 2012, ADV DIFFER EQU-NY, P1, DOI 10.1186/1687-1847-2012-96
   Wang ZL, 2017, ACTA MECH SOLIDA SIN, V30, P1, DOI 10.1016/j.camss.2016.10.001
   Yu R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480504
   ZAJAC FE, 1989, EXERCISE SPORT SCI R, V17, P187
   Zheng C., 2021, P IEEE CVF INT C COM
   Zhu JY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601145
NR 40
TC 1
Z9 1
U1 3
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2209
EA AUG 2023
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001051699700001
DA 2024-07-18
ER

PT J
AU Lu, J
   Gong, YH
   Zhou, YR
   Ma, CX
   Huang, TT
AF Lu, Jian
   Gong, Yinghao
   Zhou, Yanran
   Ma, Chengxian
   Huang, Tingting
TI CHAN: Skeleton based action recognition by multi-level feature learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE action recognition; attention mechanism; multi-level features; skeleton
   joint coordinates
AB Skeleton-based action recognition has been continuously and intensively studied. However, dynamic 3D skeleton data are difficult to be popularized in practical applications due to the restricted data acquisition conditions. Although the action recognition method based on 2D pose information extracted from RGB video can effectively avoid the influence of complex background, it is susceptible to factors such as video jitter and joint overlap. To reduce the interference of the aforementioned factors, we use two-dimensional skeletal joint coordinate modal information to represent the changes in human body posture. First, we use a target detector and pose estimation algorithm to obtain the joint coordinates of each frame sample from RGB video. Then the feature extraction network is combined to perform multi-level feature learning to establish correspondence between actions and corresponding multi-level features. Finally, the hierarchical attention mechanism is introduced to design the model named CHAN. By calculating the association between elements, the weight of the action classification is redistributed. Extensive experiments on three datasets demonstrate the effectiveness of our proposed method.
C1 [Lu, Jian; Gong, Yinghao; Zhou, Yanran; Ma, Chengxian; Huang, Tingting] Xian Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
   [Lu, Jian] Xian Polytech Univ, Sch Elect & Informat, Xian 710006, Shaanxi, Peoples R China.
C3 Xi'an Polytechnic University; Xi'an Polytechnic University
RP Lu, J (corresponding author), Xian Polytech Univ, Sch Elect & Informat, Xian 710006, Shaanxi, Peoples R China.
EM lujian_studio@163.com
RI yang, xiao/KHT-9445-2024; Zhang, Zhipeng/KHY-2239-2024; Sun,
   Yang/KHY-5117-2024; WEI, ZHEN/KHU-7176-2024; feng, yue/KHV-4687-2024;
   Lu, Jian/C-6044-2013; Liu, Jiacheng/KHX-5326-2024; zhou,
   chen/KHW-8121-2024; zhao, wenqing/KEZ-9488-2024
OI Lu, Jian/0000-0001-5362-0316; Liu, Jiacheng/0000-0002-0518-3577; gong,
   yinghao/0009-0009-8817-7751
FU National Natural Science Foundation of China, China [61971339,
   62101419]; Applied Technology Research and Development Project in Beilin
   District, Xi'an City, China [GX2007]
FX ACKNOWLEDGMENTS This paper was funded in part by the National Natural
   Science Foundation of China, China (Nos. 61971339 and 62101419), in part
   by the Applied Technology Research and Development Project in Beilin
   District, Xi'an City, China (No. GX2007).
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Avola D, 2020, IEEE T MULTIMEDIA, V22, P2481, DOI 10.1109/TMM.2019.2960588
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Cao CQ, 2019, IEEE T CIRC SYST VID, V29, P3247, DOI 10.1109/TCSVT.2018.2879913
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen K., P 30 INT WORKSH QUAL
   Chen Y., P IEEE CVF INT C COM
   Chen Y., P IEEE C COMP VIS PA
   Chu X., P IEEE C COMP VIS PA
   Das Dawn D, 2016, VISUAL COMPUT, V32, P289, DOI 10.1007/s00371-015-1066-2
   Dedeoglu Y, 2006, LECT NOTES COMPUT SC, V3979, P64
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Gosciewska K, 2018, LECT NOTES COMPUT SC, V11114, P413, DOI 10.1007/978-3-030-00692-1_36
   Haque S., 2019, EXNET DEEP NEURAL NE
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Li C., IEEE INT C MULT EXP
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Megrhi S, 2016, J VIS COMMUN IMAGE R, V41, P375, DOI 10.1016/j.jvcir.2016.10.016
   Pappas N., 2017, Multilingual hierarchical attention networks for document classification
   Parisi GI, 2017, NEURAL NETWORKS, V96, P137, DOI 10.1016/j.neunet.2017.09.001
   Peng WT, 2020, IEEE INT C ELECTR TA, DOI 10.1109/icce-taiwan49838.2020.9258245
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Sargano AB., 2017 INT JOINT C NEU
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shi L., 2019, IEEE T CIRC SYST VID
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107511
   Simonyan K, 2014, ADV NEUR IN, V27
   Song YF, 2023, IEEE T PATTERN ANAL, V45, P1474, DOI 10.1109/TPAMI.2022.3157033
   Sun K., P IEEE CVF C COMP VI
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Taigman Y., P IEEE C COMP VIS PA
   Vemulapalli R., P IEEE C COMP VIS PA
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang HS, 2018, IEEE T IMAGE PROCESS, V27, P4382, DOI 10.1109/TIP.2018.2837386
   Xia L., 2012 IEEE COMP SOC C
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yang Z., HIERARCHICAL ATTENTI
   Zan G., 2010, 1 INT C HUM BEH UND
   Zhang P., P IEEE CVF C COMP VI
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 48
TC 0
Z9 0
U1 3
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2193
EA JUL 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HA0N7
UT WOS:001017674000001
DA 2024-07-18
ER

PT J
AU Joshi, Y
   Poullis, CC
AF Joshi, Yashas
   Poullis, Charalambos Charis
TI Enabling saccadic redirection through real-time saccade prediction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE perception; supervised learning; virtual reality
ID BLINDNESS; WALKING
AB Our proposed redirected walking technique improves on current solutions by leveraging temporary visual disruption caused by saccades for redirection without requiring additional eye-tracking hardware and enables saccadic redirection on widely used consumer-grade hardware, like mobile VR. Using a deep neural network trained on head rotation data, we predict saccades during an apparent head rotation and apply rigid transformations to the virtual environment for redirection. This allows users to infinitely walk in a perceived straight direction from within a physical tracked space of 3.5x3.5$$ 3.5\times 3.5 $$ m2$$ {}<^>2 $$. The three user studies illustrated in this article validate our approach and demonstrate its efficacy.
C1 [Joshi, Yashas; Poullis, Charalambos Charis] Concordia Univ, Gina Cody Sch Engn & Comp Sci, Montreal, PQ, Canada.
   [Joshi, Yashas] Concordia Univ, Immers & Creat Technol Lab, Montreal, PQ, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Joshi, Y (corresponding author), Concordia Univ, Gina Cody Sch Engn & Comp Sci, Montreal, PQ, Canada.
EM yashasjoshi1996@gmail.com
OI Joshi, Yashas/0000-0002-2993-0872
FU Natural Sciences and Engineering Research Council of Canada [N01670]
FX ACKNOWLEDGMENTS This work is supported by the Natural Sciences and
   Engineering Research Council of Canada Grants No. N01670 (Discovery
   Grant).
CR Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   BAHILL A T, 1975, Mathematical Biosciences, V24, P191, DOI 10.1016/0025-5564(75)90075-9
   BURR DC, 1994, NATURE, V371, P511, DOI 10.1038/371511a0
   Dichgans Johannes, 1978, Perception, P755, DOI [DOI 10.1007/978-3-642-46354-9253F, DOI 10.1007/978-3-642-46354-9_25, DOI 10.1007/978-3-642-46354-925]
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   Fang Y, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121035
   Gartner B., SMALLEST ENCLOSING E
   Glaholt MG., DRDCRDDC2016R032
   Joshi Y, 2020, IEEE ACCESS, V8, P39013, DOI 10.1109/ACCESS.2020.2975032
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kothari R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59251-5
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Langbehn E, 2019, ENCY COMPUTER GRAPHI, DOI [10.1007/978-3-319-08234-9_253-1, DOI 10.1007/978-3-319-08234-9_253-1]
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Langbehn E, 2017, P IEEE VIRT REAL ANN, P449, DOI 10.1109/VR.2017.7892373
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   O'Regan JK, 2000, VIS COGN, V7, P191, DOI 10.1080/135062800394766
   Peck TC, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P121
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Poullis C, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P199, DOI 10.1109/VR.2009.4811023
   Ramot Daniel., Average Duration of a Single Eye Blink - Human Homo Sapiens - BNID 100706
   Razzaque S., 2001, Proc. Eurogr, P289, DOI [10.2312/egs.20011036, DOI 10.2312/EGS.20011036]
   Razzaque S., Redirected Walking
   Rensink RA, 2002, ANNU REV PSYCHOL, V53, P245, DOI 10.1146/annurev.psych.53.100901.135125
   Rensink RA, 1997, PSYCHOL SCI, V8, P368, DOI 10.1111/j.1467-9280.1997.tb00427.x
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Stahl JS, 1999, EXP BRAIN RES, V126, P41, DOI 10.1007/s002210050715
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Usoh M., P 26 ANN C COMP GRAP
   VOLKMANN FC, 1986, VISION RES, V26, P1401, DOI 10.1016/0042-6989(86)90164-1
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Zank M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P49, DOI 10.1109/3DUI.2016.7460030
   Zank M, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P229, DOI 10.1109/CW.2015.20
NR 40
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2167
EA MAY 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000986961000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wong, SK
   Wei, XT
AF Wong, Sai-Keung
   Wei, Xu-Tao
TI Animation generation for object transportation with a rope using deep
   reinforcement learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation; collaboration; object transportation; reinforcement learning
AB This article presents a reinforcement learning-based approach to generate animation in which two agents use a rope to collaboratively transport a block. The challenge is that the agents need to master several skills, including approaching the block, using the rope to wrap around it, and then moving the block to a predefined goal position. We propose several reward terms to learn the transportation policy and the adjustment policy that govern the skills of the agents. Experiment results showed that the proposed approach was able to generate various animations in different settings, including rope lengths, block sizes, and block shapes. An ablation test revealed the effects of the reward terms. We also investigated factors that affected the performance of the two policies.
C1 [Wong, Sai-Keung; Wei, Xu-Tao] Natl Yang Ming Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Wong, SK (corresponding author), Natl Yang Ming Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
EM cswingo@nycu.edu.tw
FU Ministry of Science and Technology of the ROC
   [MOST109-2221-E-009-121-MY3]
FX This research was supported by the Ministry of Science and Technology of
   the ROC under Grant no. MOST109-2221-E-009-121-MY3.
CR Bin Peng X, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925881
   Chen H, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1826
   Chen SC, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2017
   Clegg A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275048
   Eoh G, 2021, IEEE ACCESS, V9, P137281, DOI 10.1109/ACCESS.2021.3118109
   Eoh G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144780
   Faloutsos P, 2001, COMP GRAPH, P251, DOI 10.1145/383259.383287
   Guo SH, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1779
   Heess N., EMERGENCE LOCOMOTION
   Hu K., 2021, IEEE T VIS COMPUT GR, V29, P2036
   Juliani A., 2018, ARXIV180902627
   Kim J, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2015
   Kwiatkowski A, 2022, COMPUT GRAPH FORUM, V41, P613, DOI 10.1111/cgf.14504
   Lee J., P 11 ACM SIGGRAPH C
   Lin GW, 2018, PHYS REV E, V97, DOI 10.1103/PhysRevE.97.062303
   Liu LB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201315
   Nair Ashvin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2146, DOI 10.1109/ICRA.2017.7989247
   Panayiotou A., ACM SIGGRAPH 2022 C
   Peng XB, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275014
   Riedmiller M, 2005, LECT NOTES ARTIF INT, V3720, P317, DOI 10.1007/11564096_32
   Rodriguez S, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4437, DOI 10.1109/IROS.2016.7759653
   Schulman J., 2017, ARXIV
   Sun LB, 2019, IEEE ACCESS, V7, P109544, DOI 10.1109/ACCESS.2019.2933492
   Wang K, 2020, AUTOMAT CONSTR, V116, DOI 10.1016/j.autcon.2020.103234
   Won J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130833
   Wong CC, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2081
   Wong SK., P ACM SIGGRAPH S INT
   Xu D, 2021, T GIS, V25, P1542, DOI 10.1111/tgis.12738
   Xu D, 2020, T GIS, V24, P756, DOI 10.1111/tgis.12620
   Yang HY, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3320283
   Yang HY, 2021, J INF SCI ENG, V37, P535, DOI 10.6688/JISE.202105_37(3).0003
   Zhang JW, 2023, COMPUT ANIMAT VIRT W, V34, DOI 10.1002/cav.2114
   Zhu KJ, 2016, SIMUL MODEL PRACT TH, V69, P31, DOI 10.1016/j.simpat.2016.09.002
NR 33
TC 1
Z9 1
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2168
EA MAY 2023
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000985989100001
DA 2024-07-18
ER

PT J
AU Mao, TL
   Fang, Z
   Yan, QY
   Meng, RY
   Liu, SH
   Wang, ZQ
AF Mao, Tianlu
   Fang, Zhong
   Yan, Qinyuan
   Meng, Ruoyu
   Liu, Shaohua
   Wang, Zhaoqi
TI Data-driven based double-layer bicycle simulation model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE bicycle simulation; data-driven; double-wheel kinematic
ID CELLULAR-AUTOMATA MODEL
AB Bicycle motion simulation is fundamental to urban transportation planning, virtual reality and other areas. This article proposes a data-driven based double-layer bicycle simulation model to consider the cyclist's decision-making process and the bicycle's kinematic structure. This proposed model consists of two layers, the decision-making layer and the motion layer. First, the decision-making layer using machine learning algorithms models the decision-making process as a regression problem to output the cyclist's decision. Then, the motion layer applies a bicycle kinematics model to output bicycle motion under physical constraints. In addition, a solution to calculate bicycles' dynamic information is proposed for the data-driven method. Quantitative and qualitative experiments have been conducted, and results show that the double-layer model and the parameter calculation solution can generate realistic bicycle motion simulations.
C1 [Mao, Tianlu; Fang, Zhong; Yan, Qinyuan; Wang, Zhaoqi] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Meng, Ruoyu; Liu, Shaohua] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Beijing University of Posts & Telecommunications
RP Mao, TL (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
EM ltm@ict.ac.cn
RI liu, shaohua/AAY-7553-2020
OI Yan, Qinyuan/0000-0001-5149-9559
FU Innovation Program of Institute of Computing Technology Chinese Academy
   of Sciences [E261070]; Major Program of National Natural Science
   Foundation of China [91938301]; National Key Research and Development
   Program of China [2020YFB1710400]; Youth Program of National Natural
   Science Foundation of China [62002345]
FX Innovation Program of Institute of Computing Technology Chinese Academy
   of Sciences, Grant/Award Number: E261070; Major Program of National
   Natural Science Foundation of China, Grant/Award Number: 91938301;
   National Key Research and Development Program of China, Grant/Award
   Number: 2020YFB1710400; Youth Program of National Natural Science
   Foundation of China, Grant/Award Number: 62002345
CR Alonso-Mora J, 2012, IEEE INT CONF ROBOT, P360, DOI 10.1109/ICRA.2012.6225166
   Bi HK, 2019, IEEE I CONF COMP VIS, P10382, DOI 10.1109/ICCV.2019.01048
   Carrignon D., 2009, Traffic Engineering and Control, VVol. 50, P323
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gould G, 2009, TRANSPORT RES REC, P157, DOI 10.3141/2140-17
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Jia B, 2007, EUR PHYS J B, V56, P247, DOI 10.1140/epjb/e2007-00116-5
   Jiang R, 2004, J PHYS A-MATH GEN, V37, P2063, DOI 10.1088/0305-4470/37/6/007
   Jin S, 2015, PHYS LETT A, V379, P2409, DOI 10.1016/j.physleta.2015.07.031
   Kingma D. P., 2014, arXiv
   Leutzbach W., 1988, Introduction to the theory of traffic flow
   Li M., 2011, P 3 INT C ROAD SAFET
   Li YX, 2021, SIMUL MODEL PRACT TH, V108, DOI 10.1016/j.simpat.2020.102265
   Li YX, 2020, PHYSICA A, V541, DOI 10.1016/j.physa.2019.123302
   [梁肖 Liang Xiao], 2012, [交通运输系统工程与信息, Journal of Transporation Systems Engineering & Information Technology], V12, P91
   Mallikarjuna C, 2009, J ADV TRANSPORT, V43, P321, DOI 10.1002/atr.5670430305
   Oketch TG, 2000, TRANSPORT RES REC, P61, DOI 10.3141/1705-10
   Rajamani R, 2012, MECH ENG SER, P1, DOI 10.1007/978-1-4614-1433-9
   Ramanayya T.V., 1988, TRAFFIC ENG CONTROL, V29, P284
   Ren G, 2016, PHYSICA A, V451, P70, DOI 10.1016/j.physa.2015.12.159
   Ren JP, 2021, IEEE T VIS COMPUT GR, V27, P1953, DOI 10.1109/TVCG.2019.2946769
   Schönauer R, 2012, TRANSPORT RES REC, P114, DOI 10.3141/2316-13
   Shamsul HM., 1997, MODELLING SIGNALIZED
   Sutomo H, 1992, APPROPRIATE SATURATI, V15, P885
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Vasic J, 2012, PHYSICA A, V391, P2720, DOI 10.1016/j.physa.2011.12.018
   [王华东 Wang Huadong], 2003, [中国公路学报, China Journal of Highway and Transport], V16, P99
   Wang P., 2018, UNDERSTANDING SOCIAL
   Wei Li-ying, 2011, Journal of Jilin University (Engineering and Technology Edition), V41, P51
   Wei X, 2018, NEUROCOMPUTING, V310, P125, DOI 10.1016/j.neucom.2018.05.022
   Yang XF, 2013, ACTA PHYS SIN-CH ED, V62, DOI 10.7498/aps.62.240511
   Yao DY, 2009, IEEE INTEL TRANSP SY, V1, P25, DOI 10.1109/MITS.2009.933863
   Zou Zhenyu, 2007, Computer Measurement & Control, V15, P763
NR 35
TC 0
Z9 0
U1 4
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2023
VL 34
IS 1
SI SI
AR e2121
DI 10.1002/cav.2121
EA AUG 2022
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Z2BA
UT WOS:000844420400001
DA 2024-07-18
ER

PT J
AU Yazli, NC
   Baka, E
   Magnenat-Thalmann, N
   Kaplanidi, D
   Partarakis, N
   Karuzaki, E
   Zidianakis, M
   Pattakos, A
   Zabulis, X
AF Yazli, Nedjma Cadi
   Baka, Evangelia
   Magnenat-Thalmann, Nadia
   Kaplanidi, Danae
   Partarakis, Nikolaos
   Karuzaki, Effie
   Zidianakis, Manos
   Pattakos, Andreas
   Zabulis, Xenophon
TI Modeling craftspeople for cultural heritage: A case study
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D animation; 3D modeling; cultural heritage; digital humans; heritage
   crafts; motion capture
AB Intangible heritage is often linked to human actions and performances. The use of digital humans (DHs) for its digital representation and therefore its preservation, allows reframing the way to transmit and deal with content that is difficult to visualize. To that end, the digital human becomes an important element establishing the connection between the action, the objects, the knowledge, and the environment. In this article, we describe the development of DHs acting as practitioners and storytellers for traditional craft processes within virtual environments. We present the process and the tasks involved in modeling, designing, and animating DHs, detailing the underlying technological background. Animations were completely based on real humans' motion extraction while working on the corresponding craft. As a result, we present the different DHs models created for three specific heritage crafts: mastic cultivation, glass blowing, and silk weaving as well as an AR application, built to augment exhibits of the Chios Mastic Museum. This article is a practical description of the steps to model and animate virtual humans. The work aims to bring a methodology for achieving DHs creation for CH applications.
C1 [Yazli, Nedjma Cadi] MIRALab Sarl, Geneva, Switzerland.
   [Baka, Evangelia; Magnenat-Thalmann, Nadia] Univ Geneva, MIRALab, Miralab, Switzerland.
   [Kaplanidi, Danae] Piraeus Bank Grp Cultural Fdn, Athens, Greece.
   [Partarakis, Nikolaos; Karuzaki, Effie; Zidianakis, Manos; Pattakos, Andreas; Zabulis, Xenophon] ICS FORTH, Iraklion, Greece.
C3 University of Geneva
RP Yazli, NC (corresponding author), MIRALab Sarl, Geneva, Switzerland.
EM cadi@miralab.ch
RI Zabulis, Xenophon/D-6186-2011; Partarakis, Nikolaos/GWZ-2219-2022
OI Zabulis, Xenophon/0000-0002-1520-4327; Partarakis,
   Nikolaos/0000-0003-0497-7348; Cadi Yazli, Nedjma/0000-0002-0548-2884;
   Kaplanidi, Danae/0000-0001-5991-7516; Thalmann,
   Nadia/0000-0002-1459-5960
FU Horizon 2020; European Union [822336]
FX Horizon 2020; This work has been conducted in the context of the Mingei
   project that has received funding from the European Union's Horizon 2020
   research and innovation program, Grant/Award Number: 822336
CR Andreoli R, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3064644
   Barreau JB, 2015, PRESENCE-TELEOP VIRT, V24, P201, DOI 10.1162/PRES_a_00231
   Blender, About us
   Bogdanovych A., 2009, LECT NOTES COMPUT SC, VVolume 6038, P140, DOI [10.1007/978-3-642-19208-1_10, DOI 10.1007/978-3-642-19208-1_10]
   Carrozzino M, 2018, LECT NOTES COMPUT SC, V10851, P292, DOI 10.1007/978-3-319-95282-6_22
   Carrozzino M, 2016, LECT NOTES COMPUT SC, V9769, P378, DOI 10.1007/978-3-319-40651-0_30
   Carrozzino M, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS & INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION & STANDARDS DIGITAL HERITAGE PROJECTS & APPLICATIONS, P187, DOI 10.1109/DigitalHeritage.2015.7419486
   Chittaro Luca., 2004, PSYCHNOLOGY J SPECIA, V2, P24
   De Paolis L. T., 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P169, DOI 10.1109/ICCSN.2011.6013802
   Dimitropoulos K, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P773
   Duguleana M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12176958
   Feng Andrew, 2015, P 8 ACM SIGGRAPH C M, P57
   Foni A., 2002, P UNESCO WORLD HERIT, V2
   iclusig, about Us
   Isa WMW, 2019, 2019 IEEE CONFERENCE ON GRAPHICS AND MEDIA (GAME), P13, DOI [10.1109/game47560.2019.8980774, 10.1109/GAME47560.2019.8980774]
   Jang S-A., 2016, P 2016 ACM C COMP PU, P173, DOI DOI 10.1145/2908805.2909417
   Kennedy S., 2013, 1318 DIGITAL HERITAG, P273
   Kim LC., 2016, INT J COMPUT ELECT A, V10, P1780
   Ma?m J., 2007, P 8 INT S VIRTUAL RE
   Machidon OM, 2018, J CULT HERIT, V33, P249, DOI 10.1016/j.culher.2018.01.007
   Martinez Bibiana, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2020033
   .mingei-project, MINGEI PROJECTS WEBS
   Mixamo, About us
   Papagiannakis George, 2007, International Journal of Architectural Computing, V5, P396, DOI 10.1260/1478-0771.5.2.396
   Papagiannakis G., 2003, P CIPA 19 INT S, P30
   Partarakis N., 2020, TRANSFORMING HERITAG
   Reallusion, CHAR CREAT
   Reallusion, About us
   Rodriguez-Echavarria K., 2007, P 8 INT C VIRT REAL, P93
   Rokoko, about us
   S?n?cal S., 2017, MIXED REALITY GAMIFI, P395, DOI [10.1007/978-3-319-49607-8_16, DOI 10.1007/978-3-319-49607-8_16]
   Stefanidi Evropi, 2020, P INT C HUMAN COMPUT
   Sylaiou S, 2020, PERS UBIQUIT COMPUT, V24, P829, DOI 10.1007/s00779-019-01358-2
   Tan Beng-Kiang., 2009, VIRTUAL HERITAGE REA, P143
   Test?n AM., 2021, DIGITAL AVATARS HUMA
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Vosinakis S, 2016, MEDITERR ARCHAEOL AR, V16, P29, DOI 10.5281/zenodo.204964
   Vourvopoulos A., 2012, 2012 18th International Conference on Virtual Systems and Multimedia (VSMM 2012). Proceedings, P291, DOI 10.1109/VSMM.2012.6365937
   Wyman B., 2011, CURATOR, V54, P461, DOI DOI 10.1111/J.2151-6952.2011.00110.X
   Zabulis X., 2019, Mem. Rev, V4, P1
   Zabulis X, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12041461
NR 41
TC 1
Z9 1
U1 8
U2 32
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2075
DI 10.1002/cav.2075
EA JUN 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000814973000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Xu, ZZ
   Xiao, SJ
AF Xu, Zezi
   Xiao, Shuangjiu
TI Spatial semantic graph enhanced monocular SLAM System
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; simultaneous localization and mapping; spatial
   relations
ID OBJECT
AB More and more applications require accurate estimation of objects' poses. For example, Augmented Reality (AR) needs that for interactions among virtual and real objects. However, recent object-level Simultaneous Localization and Mapping (SLAM) systems care more about trajectories than poses of objects. So, in this paper, we present SSG SLAM: a monocular SLAM system based on Spatial Semantic Graph (SSG), leveraging spatial relations to achieve good estimation of objects' poses. First, we put forward the design of SSG to organize objects and their spatial relations. Then, SSG is utilized in a monocular object SLAM and new constraints are proposed based on spatial relations. Finally, experimental evaluations performed on SSG-Dataset show that our approach outperforms the baseline object SLAM system, as well as providing visual consistency in an AR demo.
C1 [Xu, Zezi; Xiao, Shuangjiu] Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Xu, ZZ (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
EM xvzezi@163.com
FU National Natural Science Foundation of China [61972157]
FX National Natural Science Foundation of China, Grant/Award Number:
   61972157
CR Bao SY, 2011, IMAGE VISION COMPUT, V29, P569, DOI 10.1016/j.imavis.2011.08.001
   CLEMENTINI E, 1994, COMPUT GRAPH-UK, V18, P815, DOI 10.1016/0097-8493(94)90007-8
   Gálvez-López D, 2016, ROBOT AUTON SYST, V75, P435, DOI 10.1016/j.robot.2015.08.009
   Gawel Abel, 2018, IEEE Robotics and Automation Letters, V3, P1687, DOI 10.1109/LRA.2018.2801879
   Geiger A, 2015, LECT NOTES COMPUT SC, V9358, P183, DOI 10.1007/978-3-319-24947-6_15
   Hosseinzadeh M, 2019, LECT NOTES COMPUT SC, V11363, P410, DOI 10.1007/978-3-030-20893-6_26
   Matsakis P, 2010, STUD FUZZ SOFT COMP, V256, P49
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Pappas, 2017, P 2017 IEEE INT C RO
   Renzhong G.U.O., 1998, Geo-Spat. Inf. Sci., V1998, P38, DOI [10.1080/10095020.1998.10553282, DOI 10.1080/10095020.1998.10553282]
   Romero-Ramirez FJ, 2018, IMAGE VISION COMPUT, V76, P38, DOI 10.1016/j.imavis.2018.05.004
   Soatto, 2018, P EUR C COMP VIS ECC, P301
   Wang J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4193, DOI 10.1109/IROS.2016.7759617
   Wang S., 2019, P 2019 INT C ROB AUT
   Xiao LH, 2019, ROBOT AUTON SYST, V117, P1, DOI 10.1016/j.robot.2019.03.012
   Yang SA, 2019, INT CONF MACH LEARN, P1, DOI 10.1109/icmlc48188.2019.8949230
   Yang SC, 2019, IEEE ROBOT AUTOM LET, V4, P3145, DOI 10.1109/LRA.2019.2924848
   Yang SC, 2017, IEEE INT C INT ROBOT, P590, DOI 10.1109/IROS.2017.8202212
   Zhang JH, 2019, IEEE T VIS COMPUT GR, V25, P3052, DOI 10.1109/TVCG.2019.2932216
NR 19
TC 1
Z9 1
U1 1
U2 20
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2025
DI 10.1002/cav.2025
EA MAY 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000655580800001
DA 2024-07-18
ER

PT J
AU Liao, J
   Wei, MQ
   Fu, YP
   Yan, QG
   Xiao, CX
AF Liao, Jie
   Wei, Mengqiang
   Fu, Yanping
   Yan, Qingan
   Xiao, Chunxia
TI Dense multiview stereo based on image texture enhancement
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D reconstruction; multiview stereo; texture enhancement
ID PHOTOGRAPHY; FLASH
AB In this paper, we propose a novel Multiview Stereo (MVS) method which can effectively estimate geometry in low-textured regions. Conventional MVS algorithms predict geometry by performing dense correspondence estimation across multiple views under the constraint of epipolar geometry. As low-textured regions contain less feature information for reliable matching, estimating geometry for low-textured regions remains hard work for previous MVS methods. To address this issue, we propose an MVS method based on texture enhancement. By enhancing texture information for each input image via our multiscale bilateral decomposition and reconstruction algorithm, our method can estimate reliable geometry for low-textured regions that are intractable for previous MVS methods. To densify the final output point cloud, we further propose a novel selective joint bilateral propagation filter, which can effectively propagate reliable geometry estimation to neighboring unpredicted regions. We validate the effectiveness of our method on the ETH3D benchmark. Quantitative and qualitative comparisons demonstrate that our method can significantly improve the quality of reconstruction in low-textured regions.
C1 [Liao, Jie; Fu, Yanping; Xiao, Chunxia] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Wei, Mengqiang] Guangzhou Boguan Telecommun Technol Ltd, Game Dev Dept, Guangzhou, Peoples R China.
   [Yan, Qingan] JD Com, Silicon Valley Res Ctr Multimedia Software, Beijing, Peoples R China.
C3 Wuhan University
RP Xiao, CX (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
EM cxxiao@whu.edu.cn
RI Fu, Yanping/AAE-4921-2022
OI Fu, Yanping/0000-0002-4191-4779; Liao, Jie/0000-0002-4084-2427
FU Key Technological Innovation Projects of Hubei Province [2018AAA062];
   National Key Research and Development Program of China [2017YFB1002600];
   National Natural Science Foundation of China [61672390, 61972298]
FX Key Technological Innovation Projects of Hubei Province, Grant/Award
   Number: 2018AAA062; National Key Research and Development Program of
   China, Grant/Award Number: 2017YFB1002600; National Natural Science
   Foundation of China, Grant/Award Numbers: 61672390, 61972298
CR Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Cui ZP, 2017, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2017.47
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239502, 10.1145/1276377.1276441]
   Fu YP, 2020, PROC CVPR IEEE, P5949, DOI 10.1109/CVPR42600.2020.00599
   Fu YP, 2018, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2018.00488
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Galliani S, 2015, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2015.106
   Habbecke M, 2007, PROC CVPR IEEE, P1720
   HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965
   Heise P, 2013, IEEE I CONF COMP VIS, P2360, DOI 10.1109/ICCV.2013.293
   Hernández C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820
   Khanian Maryam, 2018, Computational Visual Media, V4, P83, DOI 10.1007/s41095-017-0101-9
   Langguth F, 2016, LECT NOTES COMPUT SC, V9907, P469, DOI 10.1007/978-3-319-46487-9_29
   Liao J, 2019, COMPUT GRAPH FORUM, V38, P335, DOI 10.1111/cgf.13841
   Ono T, 2019, COMPUT VIS MEDIA, V5, P325, DOI 10.1007/s41095-019-0150-3
   Oxholm G, 2014, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2014.277
   Paris S, 2006, LECT NOTES COMPUT SC, V3954, P568
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Schöps T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272
   Shen SH, 2013, IEEE T IMAGE PROCESS, V22, P1901, DOI 10.1109/TIP.2013.2237921
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Yan QA, 2017, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2017.24
   Yan QA, 2016, COMPUT GRAPH FORUM, V35, P1, DOI 10.1111/cgf.12998
   Yan QA, 2014, COMPUT GRAPH FORUM, V33, P339, DOI 10.1111/cgf.12502
   Zhang L, 2017, IEEE T IMAGE PROCESS, V26, P4114, DOI 10.1109/TIP.2017.2712283
   Zhao X, 2012, COMPUT ANIMAT VIRT W, V23, P407, DOI 10.1002/cav.1464
   Zheng EL, 2014, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2014.196
NR 33
TC 3
Z9 3
U1 0
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2021
VL 32
IS 2
AR e1979
DI 10.1002/cav.1979
EA NOV 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RK2HP
UT WOS:000592285000001
DA 2024-07-18
ER

PT J
AU Zhang, ZL
   Li, YF
   Yang, BL
   Li, FWB
   Liang, XH
AF Zhang, Zili
   Li, Yunfei
   Yang, Bailin
   Li, Frederick W. B.
   Liang, Xiaohui
TI Target-driven cloud evolution using position-based fluids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cloud evolution; fluid control; position-based fluids; target-driven
ID SIMULATION; ANIMATION
AB To effectively control particle-based cloud evolution without imposing strict position constraints, we propose a novel method integrating a control force field and a phase transition control into the position-based fluids (PBF) framework. To produce realistic cloud simulation, we incorporate both fluid dynamics and thermodynamics to govern cloud particle movement. The fluid dynamics is simulated through our novel driving and damping force terms. As these terms are only formulated based on cloud particle density and position, they simplify the inputs and make our method free from artificial positional constraints. The thermodynamics is implemented by our phase transition control, which can effectively simulate cloud evolution between discrepant initial and target shapes, producing plausible results. Uniquely, our method can also support target shape change during cloud simulation. Experiment results have demonstrated our method surpasses existing methods.
C1 [Zhang, Zili; Li, Yunfei; Liang, Xiaohui] Beihang Univ, State Key Lab Virtual Real Technol & Syst, 37 Xueyuan Rd, Beijing, Peoples R China.
   [Zhang, Zili] Shijiazhuang Univ, Dept Comp Sci & Engn, Shijiazhuang, Hebei, Peoples R China.
   [Yang, Bailin] Zhejiang Gongshang Univ, Dept Comp & Elect Engn, Hangzhou, Zhejiang, Peoples R China.
   [Li, Frederick W. B.] Univ Durham, Dept Comp Sci, Durham, England.
C3 Beihang University; Shijiazhuang University; Zhejiang Gongshang
   University; Durham University
RP Liang, XH (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, 37 Xueyuan Rd, Beijing, Peoples R China.
EM liang_xiaohui@buaa.edu.cn
RI Zhang, Zili/HKW-2171-2023; Li, Frederick W. B./AAM-6662-2021
OI Yang, Bailin/0000-0003-1754-5595; liang, xiaohui/0000-0001-6351-2538;
   Zhang, Zili/0000-0001-9351-135X; Li, Frederick W. B./0000-0002-4283-4228
FU National Key R&D Program of China [2017YFB1002702]; National Natural
   Science Foundation of China [61572058]
FX National Key R&D Program of China, Grant/Award Number: 2017YFB1002702;
   National Natural Science Foundation of China, Grant/Award Number:
   61572058
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   [Anonymous], 2016, ARXIV160801102
   Barbosa CWF, 2015, COMPUT ANIMAT VIRT W, V26, P367, DOI 10.1002/cav.1657
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bodin K, 2012, IEEE T VIS COMPUT GR, V18, P516, DOI 10.1109/TVCG.2011.29
   Bridson R., 2015, Fluid simulation for computer graphics
   Cornelis J, 2014, COMPUT GRAPH FORUM, V33, P255, DOI 10.1111/cgf.12324
   Cui Q, 2015, TARGET TEMPERATURE D, P45
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Dobashi Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360693
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Feng G, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1781
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P178, DOI 10.1109/CGI.1997.601299
   Gardner G. Y., 1985, Computer Graphics, V19, P297, DOI 10.1145/325165.325248
   Guruge KS, 2017, INT J ENVIRON SCI TE, V14, P1, DOI 10.1007/s13762-016-1129-6
   Harris M. J., 2003, THESIS
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   Horvath C. J., 2013, 1304 PIX AN STUD
   Ihmsen M., 2014, SPH FLUIDS COMPUTER
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Jakob Wenzel, 2010, Mitsuba renderer
   KESSLER E, 1995, ATMOS RES, V38, P109, DOI 10.1016/0169-8095(94)00090-Z
   Koschier D, 2017, IEEE T VIS COMPUT GR, V23, P2208, DOI 10.1109/TVCG.2017.2730202
   Ma PX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201334
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Madill J., 2013, PROC GRAPHICS INTERF, P125
   Man P., 2006, CENTRAL EUROPEAN SEM, P1
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Miyazaki R, 2002, EUROGRAPHICS SHORT P, P1
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Peer A, 2018, COMPUT GRAPH FORUM, V37, P135, DOI 10.1111/cgf.13317
   Raveendran Karthik., 2012, Controlling liquids using meshes, P255
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Thürey N, 2009, GRAPH MODELS, V71, P221, DOI 10.1016/j.gmod.2008.12.007
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Wither J., 2008, P 5 EUR C SKETCH BAS, P113
   Yang B, 2013, COMPUT GRAPH-UK, V37, P775, DOI 10.1016/j.cag.2013.05.001
   Yau M. K., 1996, A short course in cloud physics
   Yuan CQ, 2014, COMPUT GRAPH FORUM, V33, P288, DOI 10.1111/cgf.12350
   Zhang S, 2015, PROCEEDINGS - I3D 2015, P61, DOI 10.1145/2699276.2699287
   Zhou JH, 2005, HT2005: PROCEEDINGS OF THE ASME SUMMER HEAT TRANSFER CONFERENCE 2005, VOL 1, P221, DOI 10.1115/HT2005-72602
NR 44
TC 1
Z9 1
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2020
VL 31
IS 6
AR e1937
DI 10.1002/cav.1937
EA SEP 2020
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE8AF
UT WOS:000566492100001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Liao, J
   Fu, YP
   Yan, QA
   Xiao, CX
AF Liao, Jie
   Fu, Yanping
   Yan, Qingan
   Xiao, Chunxia
TI Folding patch correspondence for multiview stereo
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D reconstruction; multiview stereo; PatchMatch
AB In this article, we propose the novel folding patch model which can replace the traditional patch model utilized in patch-based multiview stereo (MVS) methods to significantly improve the reconstruction results. The patch model is applied as an approximation of the scene surface differential in the geometric estimation procedure. By minimizing the photometric discrepancy of the projection of the patch model on multiple source images, patch-based MVS algorithms optimize the position and normal values for the 3D hypothesis of the target pixel. The optimization is based on the assumption that the patch model can fit the target scene surface perfectly. However, when it comes to complex scenes crowded with sharp edges, splintery surfaces, or round surfaces, the patch model is inherently not suitable since even from the microscopic perspective these surfaces are not entirely flat. We construct the folding patch model by folding the traditional patch model from the middle line. By adjusting the folding angle and direction, the folding patch model can fit complex surfaces more flexibly. We apply our folding patch model to the representative open-source patch based multiview stereo (PMVS) and COLMAP, and validate the effectiveness on ETH3D benchmark and data sets captured in nature. The results demonstrate that utilizing the folding patch model can significantly improve the behavior of PMVS and COLMAP, especially on data sets mainly consist of complex surfaces from plants.
C1 [Liao, Jie; Fu, Yanping; Xiao, Chunxia] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Yan, Qingan] JD Com, Silicon Valley Res Ctr Multimedia Software, Mountain View, CA USA.
C3 Wuhan University
RP Xiao, CX (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
EM cxxiao@whu.edu.cn
RI Fu, Yanping/AAE-4921-2022
OI Fu, Yanping/0000-0002-4191-4779; Liao, Jie/0000-0002-4084-2427
FU Key Technological Innovation Projects of Hubei Province [2018AAA062];
   National Key Research and Development Program of China [2017YFB1002600];
   National Natural Science Foundation of China [61672390, 61972298]
FX Key Technological Innovation Projects of Hubei Province, Grant/Award
   Number: 2018AAA062; National Key Research and Development Program of
   China, Grant/Award Number: 2017YFB1002600; National Natural Science
   Foundation of China, Grant/Award Number: No. 61672390, 61972298
CR Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.445
   [Anonymous], 2017, PROC IEEE C COMPUT
   Bailer C, 2012, LECT NOTES COMPUT SC, V7574, P398, DOI 10.1007/978-3-642-33712-3_29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Chen YD, 2013, COMPUT ANIMAT VIRT W, V24, P387, DOI 10.1002/cav.1508
   Finn N, 2010, PROCEEDING OF THE THIRD WORLD CONFERENCE ON 3D FABRICS AND THEIR APPLICATIONS, P29
   Fu YP, 2020, PROC CVPR IEEE, P5949, DOI 10.1109/CVPR42600.2020.00599
   Fu YP, 2018, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2018.00488
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933
   HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965
   Heise P, 2015, IEEE I CONF COMP VIS, P882, DOI 10.1109/ICCV.2015.107
   Heise P, 2013, IEEE I CONF COMP VIS, P2360, DOI 10.1109/ICCV.2013.293
   Knapitsch Arno, 2017, ACM Transactions on Graphics, V36, DOI 10.1145/3072959.3073599
   Liao J, 2019, COMPUT GRAPH FORUM, V38, P335, DOI 10.1111/cgf.13841
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Powell MJD, 2009, NA200906 U CAMBR, P26
   Romanoni A, 2019, IEEE I CONF COMP VIS, P10412, DOI 10.1109/ICCV.2019.01051
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Wei M, 2019, VISUAL COMPUT, V35, P1
   Xu Q., 2019, P IEEE CVF C COMP VI, P5483
   Yan Q., 2017, P C COMP VIS PATT RE, P3836
   Yan QA, 2014, COMPUT GRAPH FORUM, V33, P339, DOI 10.1111/cgf.12502
   Yang HS, 2014, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2014.435
   Zhao X, 2012, COMPUT ANIMAT VIRT W, V23, P407, DOI 10.1002/cav.1464
   Zheng EL, 2015, IEEE I CONF COMP VIS, P2075, DOI 10.1109/ICCV.2015.240
   Zheng EL, 2014, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2014.196
NR 31
TC 1
Z9 1
U1 1
U2 20
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1938
DI 10.1002/cav.1938
EA SEP 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000564245200001
DA 2024-07-18
ER

PT J
AU Magnoux, V
   Ozell, B
AF Magnoux, Vincent
   Ozell, Benoit
TI Real-time visual and physical cutting of a meshless model deformed on a
   background grid
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cutting simulation; mesh generation; meshless methods; surgery
   simulation
ID SIMULATION; OBJECTS
AB Soft body deformation models are commonly used in surgery simulations. However, cutting those models can have a severe impact on computation times and affects the interactivity of the simulation. We propose a novel method for modeling topology and introducing cuts in a meshless soft body simulated on a background grid, as well a way to progressively update the visual aspect of the object by adding a small number of triangles to the surface mesh to cover the cut area. We determine that the accuracy of the deformation is preserved after cutting by comparing our method to a finite element method. Tests show that this new method achieves interactive simulation rates with more than 10,000 elements while cutting the model and reconstructing the mesh. Our separation of the visual and physical aspects of the simulation allows for more flexibility when tuning the performance of the simulation. Topology modifications have little impact on computation times for either physical or visual changes.
C1 [Magnoux, Vincent; Ozell, Benoit] Ecole Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
C3 Universite de Montreal; Polytechnique Montreal
RP Ozell, B (corresponding author), Ecole Polytech Montreal, Dept Comp & Software Engn, Stn Ctr Ville, POB 6079, Montreal, PQ H3C 3A7, Canada.
EM benoit.ozell@polymtl.ca
RI Ozell, Benoit/V-5032-2019
OI Ozell, Benoit/0000-0002-7157-7726; Magnoux, Vincent/0000-0002-5543-6536
FU Natural Sciences and Engineering Research Council of Canada [501444-16]
FX Natural Sciences and Engineering Research Council of Canada, Grant/Award
   Number: 501444-16
CR Aras R, 2016, ADV ENG SOFTW, V102, P40, DOI 10.1016/j.advengsoft.2016.08.011
   BELYTSCHKO T, 1994, INT J NUMER METH ENG, V37, P229, DOI 10.1002/nme.1620370205
   Bender J, 2014, COMPUT GRAPH-UK, V44, P1, DOI 10.1016/j.cag.2014.07.004
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Brunet J.N., 2019, INT C CENTR EUR COMP, P91, DOI [10.24132/CSRN.2019.2901.1.11, DOI 10.24132/CSRN.2019.2901.1.11]
   Cheng Q., 2018, Journal of Healthcare Engineering, V2018, P1
   Cotin S, 2000, VISUAL COMPUT, V16, P437, DOI 10.1007/PL00007215
   Courtecuisse H, 2014, MED IMAGE ANAL, V18, P394, DOI 10.1016/j.media.2013.11.001
   Dick C, 2011, IEEE T VIS COMPUT GR, V17, P1663, DOI 10.1109/TVCG.2010.268
   Faure F., 2012, Studies in Mechanobiology, Tissue Engineering and Biomaterials,, V11, P283, DOI [DOI 10.1007/8415_2012_125, DOI 10.1007/84152012125]
   Ghali B, 2009, IEEE TIC-STH 09: 2009 IEEE TORONTO INTERNATIONAL CONFERENCE: SCIENCE AND TECHNOLOGY FOR HUMANITY, P141, DOI 10.1109/TIC-STH.2009.5444518
   Gutiérrez LF, 2010, GRAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P275
   Horton A, 2010, INT J NUMER METH BIO, V26, P977, DOI 10.1002/cnm.1374
   Jerábková L, 2010, PROG BIOPHYS MOL BIO, V103, P217, DOI 10.1016/j.pbiomolbio.2010.09.012
   Jerabkova L, 2009, IEEE COMPUT GRAPH, V29, P61, DOI 10.1109/MCG.2009.32
   Jia SY, 2017, J COMPUT SCI TECH-CH, V32, P1198, DOI 10.1007/s11390-017-1794-z
   Jung H, 2012, COMPUT ANIMAT VIRT W, V23, P489, DOI 10.1002/cav.1485
   Li S, 2014, COMPUT ANIMAT VIRT W, V25, P155, DOI 10.1002/cav.1543
   Lim YJ, 2006, P 19 IEEE S COMP BAS, P635
   Lin S.Y., 2008, COMPUT AIDED DESIGN, V5, P877
   Molino Neil., 2005, ACM SIGGRAPH 2005 Courses, SIGGRAPH'05, DOI [10.1145/1198555.1198574, DOI 10.1145/1198555.1198574]
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Pan JJ, 2018, VISUAL COMPUT, V34, P105, DOI 10.1007/s00371-016-1317-x
   Pan JJ, 2015, COMPUT ANIMAT VIRT W, V26, P321, DOI 10.1002/cav.1655
   Qian K, 2016, COMPUT ANIMAT VIRT W, V27, P280, DOI 10.1002/cav.1691
   Quesada C, 2016, INT J NUMER METH ENG, V108, P1230, DOI 10.1002/nme.5252
   Seiler M, 2011, VISUAL COMPUT, V27, P519, DOI 10.1007/s00371-011-0561-3
   Shewchuk JR, 2002, P 11 INT MESH ROUNDT, P115
   Sifakis E, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P73
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Steinemann D., 2006, PROC ACM SIGGRAPHEUR, P63
   Steinemann D, 2006, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2006.74
   Turkiyyah GM, 2011, COMPUT AIDED DESIGN, V43, P809, DOI 10.1016/j.cad.2010.10.005
   Wu Jun, 2014, Stud Health Technol Inform, V196, P469
   Wu J, 2011, INT CONF ACOUST SPEE, P25
   Yeung YH, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2856317
   Zhu CY, 2013, INT CONF BIOMED, P283, DOI 10.1109/BMEI.2013.6746949
NR 38
TC 4
Z9 6
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2020
VL 31
IS 6
AR e1929
DI 10.1002/cav.1929
EA JUN 2020
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE8AF
UT WOS:000538697500001
DA 2024-07-18
ER

PT J
AU Netek, R
   Burian, T
   Macecek, M
AF Netek, Rostislav
   Burian, Tomas
   Macecek, Martin
TI From 360° camera toward to virtual map app: Designing low-cost pilot
   study
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE interactivity; low-cost; map; panorama; virtual reality
ID INFORMATION; WORLD; GIS
AB Currently, virtual reality (VR) is a trend both in general and in specific fields such as interactive maps. The article aims to test the possibilities of deployment of low-cost virtual reality environment for the 3D spatial panoramic application. It discusses and compares modern trends in hardware (panoramic cameras and glasses) and software in the field of virtual reality. Many panoramic map applications (e.g., the well-known "Google Street View") allow us to navigate through applications using VR headsets or on an ordinary 2D monitor. The main aim of the article is to design, develop, and deploy VR map application with different levels of user interaction. It presents two pilot studies with different user's interactivity and technical solutions: "simple" 2D-based map with 360 degrees panoramic photos and "true" 3D application for VR glasses. The article focuses on the possibilities of creating low-cost map applications. Therefore, the working process "from camera toward to virtual map application" is described as followed-up case studies.
C1 [Netek, Rostislav; Burian, Tomas; Macecek, Martin] Palacky Univ Olomouc, Dept Geoinformat, Olomouc, Czech Republic.
C3 Palacky University Olomouc
RP Netek, R (corresponding author), Palacky Univ Olomouc, Fac Sci, Dept Geoinformat, 17 Listopadu 50, Olomouc 77146, Czech Republic.
EM rostislav.netek@upol.cz
RI Netek, Rostislav/ABG-7252-2020
OI Netek, Rostislav/0000-0002-3923-7676
FU Internal Grant Agency of Palacky University Olomouc [IGA_PrF_2020_027]
FX Internal Grant Agency of Palacky University Olomouc, Grant/Award Number:
   IGA_PrF_2020_027
CR [Anonymous], 2018, OXFORD DICT
   Boulos MNK, 2011, INT J HEALTH GEOGR, V10, DOI 10.1186/1476-072X-10-45
   Bowman DA, 2008, IEEE COMPUT GRAPH, V28, P20, DOI 10.1109/MCG.2008.109
   Burian J, 2018, J MAPS, V14, P73, DOI 10.1080/17445647.2018.1493407
   Dobesova Z, 2013, INT MULTI SCI GEOCO, P653
   Frome A, 2009, IEEE I CONF COMP VIS, P2373, DOI 10.1109/ICCV.2009.5459413
   Hall S., 2017, TELEGRAPH
   Kim Y, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1814
   LaValle Steven., 2019, Virtual reality
   Liu SX, 2014, VISUAL COMPUT, V30, P1373, DOI 10.1007/s00371-013-0892-3
   Longley P.A., 2005, Geographic information systems and science, V17, P517
   Ma CY, 2010, COMPUT ANIMAT VIRT W, V21, P499, DOI 10.1002/cav.322
   MACEACHREN AM, 1992, PROF GEOGR, V44, P431, DOI 10.1111/j.0033-0124.1992.00431.x
   Meilinger T, 2013, COGNITION, V129, P24, DOI 10.1016/j.cognition.2013.05.013
   Netek R, 2016, INT ARCH PHOTOGRAMM, V41, P13, DOI 10.5194/isprsarchives-XLI-B6-13-2016
   Netek R, 2013, INT MULTI SCI GEOCO, P753
   Peli E, 1998, VISION RES, V38, P2053, DOI 10.1016/S0042-6989(97)00397-0
   Rigaux P., 2001, Spatial Databases With Application 10 GIS
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Verbree E, 1999, INT J GEOGR INF SCI, V13, P385, DOI 10.1080/136588199241265
NR 21
TC 2
Z9 2
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2020
VL 31
IS 6
AR e1924
DI 10.1002/cav.1924
EA MAR 2020
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE8AF
UT WOS:000519814800001
DA 2024-07-18
ER

PT J
AU Yang, BL
   Jiang, ZY
   Shangguan, J
   Li, FWB
   Song, C
   Guo, YB
   Xu, ML
AF Yang, Bailin
   Jiang, Zhaoyi
   Shangguan, Jiantao
   Li, Frederick W. B.
   Song, Chao
   Guo, Yibo
   Xu, Mingliang
TI Compressed dynamic mesh sequence for progressive streaming
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE PCA; progressive streaming; spectrum wavelet transform; 3D mesh coding;
   3D mesh sequence compression
ID PROTECTION
AB Dynamic mesh sequence (DMS) is a simple and accurate representation for precisely recording a 3D animation sequence. Despite its simplicity, this representation is typically large in data size, making storage and transmission expensive. This paper presents a novel framework that allows effective DMS compression and progressive streaming by eliminating spatial and temporal redundancy. To explore temporal redundancy, we propose a temporal frame-clustering algorithm to organize DMS frames by their motion trajectory changes, eliminating intracluster redundancy by principal component analysis dimensionality reduction. To eliminate spatial redundancy, we propose an algorithm to transform the coordinates of mesh vertex trajectory into a decorrelated trajectory space, generating a new spatially nonredundant trajectory representation. We finally apply a spectral graph wavelet transform with color set partitioning embedded block encoding to turn the resultant DMS into a multiresolution representation to support progressive streaming. Experiment results show that our method outperforms several existing methods in terms of storage requirement and reconstruction quality.
C1 [Yang, Bailin] Zhejiang Gongshang Univ, Hangzhou, Peoples R China.
   [Jiang, Zhaoyi; Shangguan, Jiantao; Song, Chao] Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, Hangzhou, Peoples R China.
   [Li, Frederick W. B.] Univ Durham, Dept Comp Sci, Durham, England.
   [Guo, Yibo; Xu, Mingliang] Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Peoples R China.
C3 Zhejiang Gongshang University; Zhejiang Gongshang University; Durham
   University; Zhengzhou University
RP Xu, ML (corresponding author), Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Peoples R China.
EM iexumingliang@zzu.edu.cn
RI Li, Frederick W. B./AAM-6662-2021
OI Yang, Bailin/0000-0003-1754-5595; Li, Frederick W.
   B./0000-0002-4283-4228
FU National Natural Science Foundation of China [61472363, 61572436];
   Zhejiang Province Natural Science Foundation [LY16F020001]
FX National Natural Science Foundation of China, Grant/Award Number:
   61472363 and 61572436; Zhejiang Province Natural Science Foundation,
   Grant/Award Number: LY16F020001
CR Ahmad S, 2009, IEEE T MULTIMEDIA, V11, P1381, DOI 10.1109/TMM.2009.2030546
   Ahn JK, 2013, IEEE T MULTIMEDIA, V15, P485, DOI 10.1109/TMM.2012.2235417
   Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   AlRegib G, 2005, IEEE T MULTIMEDIA, V7, P766, DOI 10.1109/TMM.2005.850981
   Amjoun R, 2007, JOURNAL WSCG, V15, P99
   [Anonymous], COMPUTER GRAPHICS FO
   [Anonymous], 2014, DICT GEOTECHNICAL EN, DOI [10.1007/978-3-642-41714-6_36134, DOI 10.1007/978-3-642-41714-6_36134]
   Boulfani-Cuisinaud Y, 2007, 2007 IEEE INT C IM P, P1
   Briceno HM, 2003, P 2003 ACM SIGGRAPH
   Chew BS, 2011, IEEE T MULTIMEDIA, V13, P40, DOI 10.1109/TMM.2010.2082512
   Cho J-W, 2006, 2006 INT C IM PROC 2
   Cho JW, 2010, APPL MATH COMPUT, V216, P410, DOI 10.1016/j.amc.2010.01.032
   Cho JW, 2007, LECT NOTES COMPUT SC, V4418, P389
   Firouzmanesh A, 2011, IEEE T MULTIMEDIA, V13, P829, DOI 10.1109/TMM.2011.2129497
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Guskov I, 2004, P 2004 ACM SIGGRAPH
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Ibarria L, 2003, P 2003 ACM SIGGRAPH
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Leandro JDJG, 2013, 2013 IEEE 9 INT C E
   Lengyel JE, 1999, P 1999 S INT 3D GRAP
   Li FWB, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000493
   Li SZ, 2015, NEUROCOMPUTING, V151, P565, DOI 10.1016/j.neucom.2014.06.086
   Lin SF, 2010, J INF SCI ENG, V26, P1011
   Luo GL, 2013, COMPUT ANIMAT VIRT W, V24, P365, DOI 10.1002/cav.1522
   Mekuria R, 2014, IEEE T MULTIMEDIA, V16, P1809, DOI 10.1109/TMM.2014.2331919
   Oja E, 1997, NEUROCOMPUTING, V17, P25, DOI 10.1016/S0925-2312(97)00045-3
   Payan F, 2005, 2 INT C MACH INT ACI
   Roeger LIW, 2007, J DIFFER EQU APPL, V13, P333, DOI 10.1080/10236190601079134
   Sattler M, 2005, P 2005 ACM SIGGRAPH
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Stefanoski N, 2010, COMPUT GRAPH FORUM, V29, P101, DOI 10.1111/j.1467-8659.2009.01547.x
   Tian DH, 2007, IEEE T MULTIMEDIA, V9, P736, DOI 10.1109/TMM.2007.893341
   Vaa L, 2007, 2007 3DTV C 2007 MAY
   Vása L, 2014, COMPUT GRAPH FORUM, V33, P145, DOI 10.1111/cgf.12304
   Vása L, 2011, GRAPH MODELS, V73, P218, DOI 10.1016/j.gmod.2011.03.005
   Xu M, 2017, IEEE T CIRCUITS SYST
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Yang BL, 2016, VISUAL COMPUT, V32, P1415, DOI 10.1007/s00371-015-1129-4
NR 42
TC 4
Z9 4
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2019
VL 30
IS 6
AR e1847
DI 10.1002/cav.1847
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KD5NX
UT WOS:000507913800006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Yang, X
   Wang, HR
   Chen, SZ
   Piao, XL
   Zhou, DS
   Zhang, Q
   Yin, BC
   Wei, XP
AF Yang, Xin
   Wang, Haoran
   Chen, Shaozhe
   Piao, Xinglin
   Zhou, Dongsheng
   Zhang, Qiang
   Yin, Baocai
   Wei, Xiaopeng
TI Cascaded network with deep intensity manipulation for scene
   understanding
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE cascaded network; DIMNet; intensity manipulation; low-light; scene
   understanding
AB Scene understanding is essential to robotic navigation and autonomous driving as it provides semantic information to their controlling system. However, it will fail when processing low-light images/videos captured under adverse weather or at night use state-of-the-art scene understanding methods. A naive way to directly infer semantics from low-light images is ill posed because the low-light condition distorts pixel intensities and buries details. In order to address this problem, we propose the Deep Intensity Manipulation Network (DIMNet), which could relight the input images and recover the details, and combine the DIMNet with a scene understanding network to get a cascaded network to learn the semantics from low-light images. Through learning pixel intensity manipulation, our method can generate images not only visually pleasing but also practical for scene understanding. Qualitative and quantitative experiments demonstrate that the proposed method is effective and robust for both synthetic and real-world images.
C1 [Yang, Xin; Wang, Haoran; Chen, Shaozhe; Piao, Xinglin; Zhou, Dongsheng; Zhang, Qiang; Yin, Baocai; Wei, Xiaopeng] Dalian Univ Technol, Dept Comp Sci, Dalian 116024, Peoples R China.
   Dalian Univ Technol, Dalian, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology
RP Piao, XL; Wei, XP (corresponding author), Dalian Univ Technol, Dept Comp Sci, Dalian 116024, Peoples R China.
EM piaoxinglin@dlut.edu.cn; xpwei@dlut.edu.cn
RI Jiang, Tao/IWM-7503-2023; Zhang, Qiang/IWU-5000-2023; Zhang,
   Qiang/GXF-3105-2022; Wang, Haoran/L-4320-2019; zhang,
   qiang/HZJ-9551-2023; jiang, lei/IWE-1124-2023; wei, xiao/ISB-6027-2023
OI Wang, Haoran/0000-0001-7831-5238; Zhang, Qiang/0000-0003-3776-9799; ,
   Xin/0000-0002-8046-722X
FU National Natural Science Foundation of China [91748104, U1811463,
   61632006, 61425002, 61751203]; National Key Research and Development
   Program of China [2018YFC0910506]; Open Project Program of the State Key
   Lab of CAD CG [A1901]; Open Research Fund of Beijing Key Laboratory of
   Big Data Technology for Food Safety [BTBD-2018KF]
FX National Natural Science Foundation of China, Grant/Award Number:
   91748104, U1811463, 61632006, 61425002, and 61751203; National Key
   Research and Development Program of China, Grant/Award Number:
   2018YFC0910506; Open Project Program of the State Key Lab of CAD C&G,
   Grant/Award Number: A1901; Open Research Fund of Beijing Key Laboratory
   of Big Data Technology for Food Safety, Grant/Award Number: BTBD-2018KF
CR [Anonymous], 2017, ARXIV170408545
   [Anonymous], 2015, 3 INT C LEARN REPR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ARXIV161201051
   [Anonymous], 2016, ARXIV161108583
   [Anonymous], 2017, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2016.2644615
   [Anonymous], IEEE INT C COMP VIS
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai DX, 2018, IEEE INT C INTELL TR, P3819, DOI 10.1109/ITSC.2018.8569387
   Dosovitskiy A, 2016, 30 C NEURAL INFORM P, V29
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee S, 2017, IEEE I CONF COMP VIS, P1965, DOI 10.1109/ICCV.2017.215
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Park S, 2017, IEEE T CONSUM ELECTR, V63, P178, DOI 10.1109/TCE.2017.014847
   Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ros G., 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, P3234, DOI DOI 10.1109/CVPR.2016.352
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang QX, 2016, PROC CVPR IEEE, P4517, DOI 10.1109/CVPR.2016.489
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 37
TC 1
Z9 1
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1888
DI 10.1002/cav.1888
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400023
DA 2024-07-18
ER

PT J
AU Kim, Y
   Kim, HJ
   Kim, YJ
AF Kim, Yaesol
   Kim, Hyun Jung
   Kim, Young J.
TI Encountered-type haptic display for large VR environment using per-plane
   reachability maps
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE encountered-type haptic; haptic interaction; human-robot interaction;
   virtual reality
AB We show a novel encountered-type haptic system, H-Wall, to enable haptic feedback using a manipulator of seven degrees of freedom suitable for simulating indoor virtual reality environments, which are characterized and confined by a set of vertical walls and revolving doors. At runtime, our system tracks hand motion using a red-green-blue depth sensor and locates its configuration. Then, the robotic manipulator plans a trajectory for the end effector, attached to a rectangular rigid board, to make contact with the hand to deliver a sense of touch as long as the perceived hand contact force is substantial. The force feedback is generated in a passive sense for static walls that the rigid board, corresponding to a vertical wall, holds its position as long as the perceived hand contact force is substantial. For a revolving door, the force feedback is generated in an active sense based on impedance control. In order to address the issue of limited workspace, we also propose a new reachability map, called per-plane reachability map, that is optimized to answer whether passive haptic feedback can be generated by a manipulator when the user touches a vertical wall at a given orientation. We successfully demonstrate our system to provide an illusion to the user in a virtual environment with touch sensation to the surrounding environment.
C1 [Kim, Yaesol; Kim, Hyun Jung; Kim, Young J.] Ewha Womans Univ, Dept Comp Sci & Engn, Seoul 03760, South Korea.
C3 Ewha Womans University
RP Kim, YJ (corresponding author), Ewha Womans Univ, Dept Comp Sci & Engn, Seoul 03760, South Korea.
EM kimy@ewha.ac.kr
OI Kim, Young J./0000-0003-2159-4832; Kim, Yaesol/0000-0003-0374-9570
FU National Research Foundation [2017R1A2B3012701]; Ministry of Culture,
   Sports and Tourism (MCST)/Korea Creative Content Agency (KOCCA) [CT RD
   2018]
FX National Research Foundation, Grant/Award Number: 2017R1A2B3012701;
   Ministry of Culture, Sports and Tourism (MCST)/Korea Creative Content
   Agency (KOCCA), Grant/Award Number: CT R&D 2018
CR [Anonymous], 1994, P ASME WINT ANN M S, DOI DOI 10.1145/1029632.1029682
   [Anonymous], 1996, FORCE TOUCH FEEDBACK
   [Anonymous], 2008, HAPTIC RENDERING FDN
   Araujo B, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P218, DOI 10.1145/2839462.2839484
   BERGAMASCO M, 1994, IEEE INT CONF ROBOT, P1449, DOI 10.1109/ROBOT.1994.351286
   COLGATE JE, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P202, DOI 10.1109/VRAIS.1993.380777
   Dong J, 2015, IEEE INT C INT ROBOT, P1488, DOI 10.1109/IROS.2015.7353564
   Guan YS, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1984, DOI 10.1109/IROS.2006.282406
   Hogan N., 1984, AM CONTR C, P304, DOI DOI 10.23919/ACC.1984.4788393
   Iwata H., 1993, Proceedings IEEE 1993 Symposium on Research Frontiers in Virtual Reality (Cat. No.93TH0585-0), P16, DOI 10.1109/VRAIS.1993.378268
   Iwata H., 1992, J ROBOTICS MECHATRON, V24, P39, DOI [10.20965/jrm.1992.p0039, DOI 10.20965/JRM.1992.P0039]
   Iwata H, 1994, SIGGRAPH 94 VIS P OR
   Marcus B, 1993, P VR SYST C OCT NEW
   MCNEELY WA, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P336, DOI 10.1109/VRAIS.1993.380761
   Razzaque S., 2001, Proc. Eurogr, P289, DOI [10.2312/egs.20011036, DOI 10.2312/EGS.20011036]
   Shigeta K, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P188
   Siciliano B., 2016, SPRINGER HDB ROBOTIC, DOI DOI 10.1007/978-3-540-30301-5
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Ugray Z, 2007, INFORMS J COMPUT, V19, P328, DOI 10.1287/ijoc.1060.0175
   Vahrenkamp N, 2013, IEEE INT CONF ROBOT, P1970, DOI 10.1109/ICRA.2013.6630839
   Vonach E, 2017, P IEEE VIRT REAL ANN, P74, DOI 10.1109/VR.2017.7892233
   Yokokohji Y, 2001, P IEEE VIRT REAL ANN, P271, DOI 10.1109/VR.2001.913796
   Yokokohji Y, 1999, PRESENCE-TELEOP VIRT, V8, P412, DOI 10.1162/105474699566314
   Zacharias Franziska, 2009, 2009 9th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2009), P55, DOI 10.1109/ICHR.2009.5379601
   Zacharias F, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3235
NR 25
TC 15
Z9 16
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1814
DI 10.1002/cav.1814
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100005
DA 2024-07-18
ER

PT J
AU Nie, YY
   Chang, J
   Chaudhry, E
   Guo, SH
   Smart, A
   Zhang, JJ
AF Nie, Yinyu
   Chang, Jian
   Chaudhry, Ehtzaz
   Guo, Shihui
   Smart, Andi
   Zhang, Jian Jun
TI Semantic modeling of indoor scenes with support inference from a single
   photograph
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE fully convolutional network; indoor scene reconstruction; semantic
   modeling; support inference
AB We present an automatic approach for the semantic modeling of indoor scenes based on a single photograph, instead of relying on depth sensors. Without using handcrafted features, we guide indoor scene modeling with feature maps extracted by fully convolutional networks. Three parallel fully convolutional networks are adopted to generate object instance masks, a depth map, and an edge map of the room layout. Based on these high-level features, support relationships between indoor objects can be efficiently inferred in a data-driven manner. Constrained by the support context, a global-to-local model matching strategy is followed to retrieve the whole indoor scene. We demonstrate that the proposed method can efficiently retrieve indoor objects including situations where the objects are badly occluded. This approach enables efficient semantic-based scene editing.
C1 [Nie, Yinyu; Chang, Jian; Chaudhry, Ehtzaz; Zhang, Jian Jun] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
   [Guo, Shihui] Xiamen Univ, Sch Software, Xiamen, Peoples R China.
   [Smart, Andi] Univ Exeter, Ctr Innovat & Serv Res, Sch Business, Exeter, Devon, England.
C3 Bournemouth University; Xiamen University; University of Exeter
RP Chang, J (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
EM JChang@bournemouth.ac.uk
RI Nie, Yinyu/AES-2766-2022
OI Nie, Yinyu/0000-0001-7023-6797
FU European Regional Development Funds - VISTA AR project (the Interreg
   France (Channel) England); National Natural Science Foundation of China
   [61702433, 61661146002]; 61702433 and 61661146002; Bournemouth
   University
FX European Regional Development Funds - VISTA AR project (the Interreg
   France (Channel) England); the National Natural Science Foundation of
   China, Grant/Award Number: 61702433 and 61661146002; the China
   Scholarship Council and Bournemouth University
CR [Anonymous], VISUAL COMPUT
   [Anonymous], 2017, ARXIV170602413
   Chao-Hui Shen, 2012, ACM Transactions on Graphics, V31, DOI 10.1145/2366145.2366199
   Chen K., 2015, COMPUT VIS MEDIA, V1, P267, DOI DOI 10.1007/S41095-015-0029-X
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Guo R., 2015, ARXIV150402437
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411
   Hua BS, 2016, INT CONF 3D VISION, P92, DOI 10.1109/3DV.2016.18
   Izadinia H, 2017, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2017.260
   JONES DR, 1993, J OPTIMIZ THEORY APP, V79, P157, DOI 10.1007/BF00941892
   Konolige K., 2011, Technical description of Kinect calibration
   Lai K, 2014, IEEE INT CONF ROBOT, P3050, DOI 10.1109/ICRA.2014.6907298
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Li Yi, 2016, ARXIV161107709
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mallya A, 2015, IEEE I CONF COMP VIS, P936, DOI 10.1109/ICCV.2015.113
   Powell M., 2009, TECHNICAL REPORT
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Xiong X., 2010, Proceedings of the British Machine Vision Conference 2010, British Machine Vision Association, P1, DOI DOI 10.5244/C.24.45
   Xu K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461968
   Yang Sheng, 2017, [Computational Visual Media, 计算可视媒体], V3, P131
   Zhang Y, 2015, COMPUT GRAPH-UK, V53, P210, DOI 10.1016/j.cag.2015.10.004
NR 27
TC 2
Z9 2
U1 3
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1825
DI 10.1002/cav.1825
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100016
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Jung, S
   Hong, S
   Cho, K
   Eom, H
   Choi, B
   Noh, J
AF Jung, Sunjin
   Hong, Seokpyo
   Cho, Kyungmin
   Eom, Haegwang
   Choi, Byungkuk
   Noh, Junyong
TI Age-related gait motion transformation based on biomechanical
   observations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE aging simulation; character animation; motion transformation
ID WALKING; SPEED
AB We present a novel approach for synthesizing human gait motions according to a range of input ages by transforming a given motion based on biomechanical observations. Given an original motion, our method first extracts gait cycles that are periodically defined by foot contact on the ground and then transforms the original motion to achieve a desirable posture and motions that respectively correspond to the input age. Among many biomechanical features that gradually change with aging, we mainly focus on spatiotemporal and kinematic features as well as postural changes. Exploiting these features, we formulate the biomechanical changes as continuous functions that reflect visually significant features corresponding to the input age. Finally, we demonstrate that our system can automatically generate plausible gait motions given a wide range of input ages.
C1 [Jung, Sunjin; Hong, Seokpyo; Cho, Kyungmin; Eom, Haegwang; Noh, Junyong] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon, South Korea.
   [Choi, Byungkuk] Weta Digital, Wellington, New Zealand.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Noh, J (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon, South Korea.
EM junyongnoh@kaist.ac.kr
RI Noh, Junyong/C-1663-2011
FU National Research Foundation of Korea (NRF); the Korea government (MSIP)
   [2014R1A2A1A01002871]
FX National Research Foundation of Korea (NRF); the Korea government
   (MSIP), Grant/Award Number: 2014R1A2A1A01002871
CR [Anonymous], P 22 ANN C COMP GRAP
   Boyle JJW, 2002, CLIN BIOMECH, V17, P361, DOI 10.1016/S0268-0033(02)00030-X
   Cofré Lizama LE, 2011, GAIT POSTURE, V33, P484, DOI 10.1016/j.gaitpost.2010.12.030
   FON GT, 1980, AM J ROENTGENOL, V134, P979, DOI 10.2214/ajr.134.5.979
   Gunaratne C, 2013, COMP GRAPH IMAG VIS, P17
   Han D, 2016, COMPUT ANIMAT VIRT W, V27, P378, DOI 10.1002/cav.1708
   HIMANN JE, 1988, MED SCI SPORT EXER, V20, P161, DOI 10.1249/00005768-198820020-00010
   Imms F J, 1981, Age Ageing, V10, P147, DOI 10.1093/ageing/10.3.147
   Judge JO, 1996, J GERONTOL A-BIOL, V51, pM303, DOI 10.1093/gerona/51A.6.M303
   Kerrigan DC, 1998, ARCH PHYS MED REHAB, V79, P317, DOI 10.1016/S0003-9993(98)90013-2
   Kron Taesoo., 2005, EUROGRAPHICSACM SIGG, P29, DOI DOI 10.1145/1073368.1073373
   Kuo YL, 2009, J MANIP PHYSIOL THER, V32, P210, DOI 10.1016/j.jmpt.2009.02.002
   Le D, 2003, INT ARCH PHOTOGRAM R, V34, P5
   Lee J, 1999, COMP GRAPH, P39
   Liu CK, 2002, ACM T GRAPHIC, V21, P408, DOI 10.1145/566570.566596
   Lockwood N, 2011, P 2011 ACM SIGGRAPH, P267
   MURRAY MP, 1969, J GERONTOL, V24, P169, DOI 10.1093/geronj/24.2.169
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   OBERG T, 1993, J REHABIL RES DEV, V30, P210
   Prince F, 1997, GAIT POSTURE, V5, P128, DOI 10.1016/S0966-6362(97)01118-1
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Viaud M-L, 1992, THESIS
   Wangs JM, 2012, ACM T GRAPHIC, V31
   WINTER DA, 1990, PHYS THER, V70, P340, DOI 10.1093/ptj/70.6.340
   Wu Y, 1999, VISUAL COMPUT, V15, P183, DOI 10.1007/s003710050171
NR 26
TC 2
Z9 2
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1774
DI 10.1002/cav.1774
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200020
DA 2024-07-18
ER

PT J
AU Liu, N
   Zhu, DM
   Wang, ZQ
   Qin, H
   Zhan, JF
   Gao, JZ
AF Liu, Ning
   Zhu, Dengming
   Wang, Zhaoqi
   Qin, Hong
   Zhan, Jianfeng
   Gao, Jinzhu
TI Pipelining image compositing in heterogeneous networking environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE pipeline; image compositing; heterogeneous networking environment;
   optimization algorithm
AB Because of intensive inter-node communications, image compositing has always been a bottleneck in parallel visualization systems. In a heterogeneous networking environment, the variation of link bandwidth and latency adds more uncertainty to the system performance. In this paper, we present a pipelining image compositing algorithm in heterogeneous networking environments, which is able to rearrange the direction of data flow of a compositing pipeline under strict ordering constraint. We introduce a novel directional image compositing operator that specifies not only the color and. channels of the output but also the direction of data flow when performing compositing. Based on this new operator, we thoroughly study the properties of image compositing pipelines in heterogeneous environments. We develop an optimization algorithm that could find the optimal pipeline from an exponentially large searching space in polynomial time. We conducted a comprehensive evaluation on the ns-3 network simulator. Experimental results demonstrate the efficiency of our method. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Liu, Ning; Zhu, Dengming; Wang, Zhaoqi; Zhan, Jianfeng] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Liu, Ning] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
   [Gao, Jinzhu] Univ Pacific, Dept Comp Sci, Stockton, CA 95211 USA.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; State University of New York (SUNY) System; State University of New
   York (SUNY) Stony Brook; University of the Pacific
RP Liu, N (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
EM liuning01@ict.ac.cn
RI Gao, Jinzhu/B-4716-2011
CR Bentes C, 2014, CLUSTER COMPUT, V17, P423, DOI 10.1007/s10586-013-0244-0
   Kendall W., 2010, Proceedings of the 10th Eurographics Conference on Parallel Graphics and Visualization, EG PGV'10, P101, DOI DOI 10.2312/EGPGV/EGPGV10/101-110
   MA KL, 1994, IEEE COMPUT GRAPH, V14, P59, DOI 10.1109/38.291532
   MOLNAR S, 1994, IEEE COMPUT GRAPH, V14, P23, DOI 10.1109/38.291528
   Moreland K., 2011, P INT C HIGH PERFORM
   Neumann U., 1993, Proceedings. 1993 Parallel Rendering Symposium (IEEE Cat. No.93TH0592-6), P97, DOI 10.1109/PRS.1993.586093
   Peterka T, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Peterka Tom., 2012, European MPI Users' Group Meeting, P275
   Porter T., 1984, Computers & Graphics, V18, P253
   Wu QS, 2009, J PARALLEL DISTR COM, V69, P230, DOI 10.1016/j.jpdc.2008.11.004
   Yu Hongfeng., 2008, P SUPERCOMPUTING C, P1
NR 11
TC 0
Z9 0
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 385
EP 393
DI 10.1002/cav.1711
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300023
DA 2024-07-18
ER

PT J
AU Liang, H
   Chang, J
   Yang, XS
   You, LH
   Bian, SJ
   Zhang, JJ
AF Liang, Hui
   Chang, Jian
   Yang, Xiaosong
   You, Lihua
   Bian, Shaojun
   Zhang, Jian Jun
TI Advanced ordinary differential equation based head modelling for Chinese
   marionette art preservation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE ODE-based swept surface; marionette head modelling; culture heritage
   preservation
ID SWEPT SURFACES; ANIMATION
AB Puppetry has been a popular art form for many centuries in different cultures, which becomes a valuable and fascinating heritage assert. Traditional Chinese marionette art with over 2000years history is one of the most representative forms offering a mixture of stage performance of singing, dancing, music, poetry, opera, story narrative and action. Apart from a set of string rules, which controls the dynamics, head carving skill is another important pillar in this art form. This paper addresses the heritage preservation of the marionette head carving by digitalizing the head models with a novel modelling technique using ordinary differential equations (ODEs). The technique has been specially tailored to suit the modelling complexity and the need of accurate description of shapes. It offers smoothly sewing ODE swept patches to represent the distinct features of a marionette head with sharp variance of local geometry. Such features otherwise are difficult to model and capture accurately, which may require a great effort and tedious handcrafting of an experienced modeller, when using other representation forms like polygons. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Liang, Hui; Chang, Jian; Yang, Xiaosong; You, Lihua; Bian, Shaojun; Zhang, Jian Jun] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
   [Liang, Hui] Commun Univ China, Beijing 100024, Peoples R China.
C3 Bournemouth University; Communication University of China
RP Chang, J (corresponding author), Bournemouth Univ, Media Sch, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
EM JChang@bournemouth.ac.uk
OI Yang, Xiaosong/0000-0003-3815-0584; Bian, Shaojun/0000-0003-1108-744X;
   Chang, Jian/0000-0003-4118-147X; Zhang, Jian/0000-0002-7069-5771
FU European Union under REA [623883]; project Dr Inventor [FP7-ICT-2013.8.1
   611383]
FX The research leading to these results has received funding from the
   People Programme (Marie Curie Actions) of the European Union's Seventh
   Framework Programme FP7/2007-2013/ under REA grant agreement no.
   [623883]-'AniM'. The authors acknowledge partial support from project Dr
   Inventor (FP7-ICT-2013.8.1 611383). We would like to thank Ismail Kazmi
   for proof reading the draft of the paper.
CR [Anonymous], 2010, ACM SIGGRAPH 2010 Papers. SIGGRAPH'10, DOI [DOI 10.1145/1833349.1778769, DOI 10.1145/1778765.1778769]
   [Anonymous], ACM SIGGRAPH P
   [Anonymous], 2009, P 2009 ACM SIGGRAPHE, DOI [DOI 10.1145/1599470.1599472, 10.1145/1599470.1599472]
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Blanz V., 1999, P SIGGRAPH, P87
   BLOOR MIG, 1990, COMPUT AIDED DESIGN, V22, P202, DOI 10.1016/0010-4485(90)90049-I
   BLOOR MIG, 1989, COMPUT AIDED DESIGN, V21, P165, DOI 10.1016/0010-4485(89)90071-7
   Lin C, 2013, J FUJIAN ARTS, V1, P63
   Parke Frederic, 1991, COMPUTER ANIMATION 9, V91, P3
   Parke Frederick Ira, 1974, UTECCSC75047
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   Seol Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024196
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   SIFAKIS E, 2006, P 2006 ACM SIGGRAPH, P261
   Weise T, 1981, ACM T GRAPHIC, V30, P77
   Williams L., 1990, ACM SIGGRAPH COMPUTE, V24, P235
   You LH, 2007, COMPUT GRAPH FORUM, V26, P313, DOI 10.1111/j.1467-8659.2007.01053.x
   You LH, 2014, VISUAL COMPUT, V30, P625, DOI 10.1007/s00371-014-0950-5
   You LH, 2010, COMPUT ANIMAT VIRT W, V21, P297, DOI 10.1002/cav.352
NR 19
TC 2
Z9 2
U1 0
U2 13
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 207
EP 216
DI 10.1002/cav.1651
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700003
DA 2024-07-18
ER

PT J
AU Bonaventura, X
   Guo, JW
   Meng, WL
   Feixas, M
   Zhang, XP
   Sbert, M
AF Bonaventura, Xavier
   Guo, Jianwei
   Meng, Weiliang
   Feixas, Miquel
   Zhang, Xiaopeng
   Sbert, Mateu
TI 3D shape retrieval using viewpoint information-theoretic measures
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE shape similarity; information theory; mutual information
ID TOPOLOGICAL SIMILARITY; DATABASE SYSTEM
AB In this paper, we present an information-theoretic framework to compute the shape similarity between 3D polygonal models. Given a 3D model, an information channel between a sphere of viewpoints around the model and its polygonal mesh is defined to compute the specific information associated with each viewpoint. The obtained information sphere can be seen as a shape descriptor of the model. Then, given two models, their similarity is obtained by performing a registration process between the corresponding information spheres. The distance between the information histograms is also defined as a coarse measure of similarity, as well as the scalar value given by the mutual information of the channel. The performance of all these measures is tested using the Princeton Shape Benchmark database. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Bonaventura, Xavier; Feixas, Miquel; Sbert, Mateu] Univ Girona, Graph & Imaging Lab, Girona, Spain.
   [Guo, Jianwei; Meng, Weiliang; Zhang, Xiaopeng; Sbert, Mateu] Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing, Peoples R China.
C3 Universitat de Girona; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Bonaventura, X (corresponding author), Univ Girona, Graph & Imaging Lab, Girona, Spain.
EM xavierb@ima.udg.edu
RI Bonaventura, Xavier/C-6258-2014; Sbert, Mateu/G-6711-2011; Feixas,
   Miquel/F-6762-2016
OI Sbert, Mateu/0000-0003-2164-6858; Feixas, Miquel/0000-0001-6512-7588
FU Spanish Government [TIN2010-21089-C03-01, BES-2011-045252]; Generalitat
   de Catalunya (Catalan Government) [2009-SGR-643]; National Natural
   Science Foundation of China [61331018, 61372190]
FX This work has been founded in part by grant number TIN2010-21089-C03-01
   and BES-2011-045252 of Spanish Government, grant number 2009-SGR-643 of
   Generalitat de Catalunya (Catalan Government), and National Natural
   Science Foundation of China (Nos. 61331018, 61372190).
CR [Anonymous], 1981, Attention and Performance
   Blanz V, 1999, PERCEPTION, V28, P575, DOI 10.1068/p2897
   Bonaventura X, 2013, SIGNAL IMAGE VIDEO P, V7, P467, DOI 10.1007/s11760-013-0449-y
   Bonaventuras X, 2011, P 21 GRAPHICON INT C, P16
   Bordoloi UD, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P487
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Covers TM, 1991, WILEY SERIES TELECOM
   DeWeese MR, 1999, NETWORK-COMP NEURAL, V10, P325, DOI 10.1088/0954-898X/10/4/303
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   El-Mehalawi M, 2003, COMPUT AIDED DESIGN, V35, P83, DOI 10.1016/S0010-4485(01)00177-4
   El-Mehalawi M, 2003, COMPUT AIDED DESIGN, V35, P95, DOI 10.1016/S0010-4485(01)00178-6
   Fang R, 2008, LECT NOTES COMPUT SC, V5358, P381, DOI 10.1007/978-3-540-89639-5_37
   Feixas M, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1462055.1462056
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gonzalez F., 2007, EG SHORT PAPERS, P21
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   Kazhdan Michael., 2004, COMPUT GRAPH FORUM, P115, DOI DOI 10.1145/1057432.1057448
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Liu YJ, 2013, IEEE T AUTOM SCI ENG, V10, P783, DOI 10.1109/TASE.2012.2228481
   Löffler J, 2000, IEEE INFOR VIS, P82, DOI 10.1109/IV.2000.859741
   Novotni M., 2003, P 8 ACM S SOL MOD AP, P216, DOI DOI 10.1145/781606.781639
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   POWELL MJD, 1964, COMPUT J, V7, P155, DOI 10.1093/comjnl/7.2.155
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Shao TJ, 2011, COMPUT GRAPH FORUM, V30, P2011, DOI 10.1111/j.1467-8659.2011.02050.x
   Shilane P., 2004, P INT C SHAPE MODELI, DOI DOI 10.1109/SMI.2004.1314504
   Sokolov D, 2006, VISUAL COMPUT, V22, P506, DOI 10.1007/s00371-006-0025-3
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Sundars H, 2003, SHAPE MODELING INT
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Tarr MJ, 1997, PSYCHOL SCI, V8, P282, DOI 10.1111/j.1467-9280.1997.tb00439.x
   Tung T., 2005, International Journal of Shape Modeling, V11, P91, DOI 10.1142/S0218654305000748
   Vazquez P.-P., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P273
   Viola I, 2006, IEEE T VIS COMPUT GR, V12, P933, DOI 10.1109/TVCG.2006.152
   YOON S.M., 2010, Proceedings of the international conference on Multimedia, P193
   Zhang C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P935, DOI 10.1109/ICIP.2001.958278
NR 40
TC 3
Z9 3
U1 1
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2015
VL 26
IS 2
BP 147
EP 159
DI 10.1002/cav.1566
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CG3GB
UT WOS:000353165400006
DA 2024-07-18
ER

PT J
AU Choi, MG
AF Choi, Min Gyu
TI Real-time simulation of ductile fracture with oriented particles
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deformation; plasticity; ductile fracture; shape matching; oriented
   particles
ID ANIMATION
AB This paper proposes a practical approach for real-time simulation of large deformation and ductile fracture. We adopt the oriented particles approach for robust and efficient simulation of large deformation and develop a practical model for plastic flow and fracture. The proposed method finds the optimal rotation and the optimal stretch in shape matching. The newly introduced optimal stretch leads to a material strain that can be employed in the plastic flow and fracture criteria. We also propose a graphics processing unit skinning method for real-time rendering of a deformed, fractured visual mesh. Experimental results show that the proposed method can robustly simulate large, elastoplastic deformation and ductile fracture of large visual meshes in real time. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 Kwangwoon Univ, Dept Comp Sci, Seoul 139701, South Korea.
C3 Kwangwoon University
RP Choi, MG (corresponding author), Kwangwoon Univ, Dept Comp Sci, Seoul 139701, South Korea.
EM mgchoi@kw.ac.kr
FU National Research Foundation of Korea (NRF) - Korean Government
   [NRF-2011-0012878]; Kwangwoon University
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean Government (NRF-2011-0012878) and the
   Research Grant of Kwangwoon University in 2013.
CR [Anonymous], 2009, P 3 INT C BIOINF BIO
   [Anonymous], 2004, P 2004 ACM SIGGRAPH, DOI DOI 10.1145/1028523.1028541
   Antsaklis P., 2007, A Linear Systems Primer
   Baker M., 2011, ACM SIGGRAPH 2011 CO
   Bao ZS, 2007, IEEE T VIS COMPUT GR, V13, P370, DOI 10.1109/TVCG.2007.39
   Bargteil AW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239467
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Gross D, 2011, MECH ENG SER, P1, DOI 10.1007/978-3-642-19240-1
   Lien JM, 2008, COMPUT AIDED GEOM D, V25, P503, DOI 10.1016/j.cagd.2008.05.003
   Molino N, 2004, ACM T GRAPHIC, V23, P385, DOI 10.1145/1015706.1015734
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Müller M, 2004, PROC GRAPH INTERF, P239
   MULLER M., 2006, P VIRTUAL REALITY IN, P71, DOI [10.1007/978-3-319-08234-9_92-1, DOI 10.1007/978-3-319-08234-9_92-1]
   Muller M., 2013, ACM T GRAPHIC, V32, P4
   Muller M, 2011, ACM T GRAPHIC, V30, P92
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   Parker E.G., 2009, PROC S COMP ANIM, P165, DOI DOI 10.1145/1599470.1599492.
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Rivers AR, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239533
   Steinemann D., 2008, P 2008 ACM SIGGRAPHE, P87
   Terzopoulos D., 1988, Computer Graphics, V22, P269, DOI 10.1145/378456.378522
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Zheng CX, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778806
NR 25
TC 6
Z9 9
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 457
EP 465
DI 10.1002/cav.1601
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300026
DA 2024-07-18
ER

PT J
AU Zhang, CX
   Dubois, E
   Zhao, Y
AF Zhang, Chunxiao
   Dubois, Eric
   Zhao, Yan
TI Virtual cubic panorama synthesis based on triangular reprojection
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cubic panorama; view synthesis; triangular meshes; matching lines
ID PROPAGATION; STEREO
AB Cubic panoramas provide an efficient solution to the implementation of immersive and omnidirectional displays for image-based virtual navigation. To allow unrestricted navigation through the environment, a system must be capable of constructing novel views given the reference images, typically, cubic panoramas. This paper proposes a processing pipeline for cubic panorama synthesis based on 2D/3D triangular reprojection. This pipeline uses matching features to implement the triangular meshing on cubic panoramas, and introduces the matching line constraint, which significantly reduces the artifacts of straight-line features in the rendered image and accelerates the division process. The modules of this pipeline take the geometrical characteristics of cubic panorama into account. Thus, it can handle the discontinuities of the cube edges when the triangular mesh covers different faces. Furthermore, these modules could be reconfigured to compose customized pipelines and generate virtual cubic panoramas of different quality based on the amount of features. The performance and efficiency of the proposed pipeline is demonstrated with comparison experiments. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Zhang, Chunxiao] Beijing Inst Space Mech & Elect, Beijing, Peoples R China.
   [Dubois, Eric] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
   [Zhao, Yan] Beihang Univ, Sch Instrumentat Sci & Optoelect Engn, Beijing, Peoples R China.
C3 University of Ottawa; Beihang University
RP Zhang, CX (corresponding author), Beijing Inst Space Mech & Elect, Beijing, Peoples R China.
EM cxzhang84@gmail.com
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX This work was partly supported by the Natural Sciences and Engineering
   Research Council of Canada (NSERC Strategic project). The authors thank
   Mr. Feng Shi, Prof. Falin Wu, and Dr. Zheng Liu for valuable comments
   and help.
CR Beermann Markus, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P217
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932
   Chan SC, 2007, IEEE SIGNAL PROC MAG, V24, P22, DOI 10.1109/MSP.2007.905702
   Chang CF, 1999, COMP GRAPH, P291, DOI 10.1145/311535.311571
   Chaurasia G, 2011, COMPUT GRAPH FORUM, V30, P1223, DOI 10.1111/j.1467-8659.2011.01981.x
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Fleck S, 2009, IMAGE VISION COMPUT, V27, P141, DOI 10.1016/j.imavis.2008.05.009
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Ince S, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/803231
   Klaus A, 2006, INT C PATT RECOG, P15
   Kopf J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778833
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810
   McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398
   Schmid C, 2000, INT J COMPUT VISION, V40, P199, DOI 10.1023/A:1008135310502
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Shi F, 2009, 2009 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, P200, DOI 10.1109/CRV.2009.34
   Shum H.-Y., 2006, IMAGE BASED RENDERIN
   Shum HY, 2003, IEEE T CIRC SYST VID, V13, P1020, DOI 10.1109/TCSVT.2003.817360
   Sin AMK, 2005, IEEE T IMAGE PROCESS, V14, P241, DOI 10.1109/TIP.2004.840690
   Siu A.M. K., 2004, VRST'04: Proceedings of the ACM symposium on Virtual reality software and technology, P114
   Stegmaier S, 2005, VOLUME GRAPHICS 2005, P187
   Tam W. J., 2005, P SOC PHOTO-OPT INS, V6016, P75
   Velho L, 1999, VISUAL COMPUT, V15, P21, DOI 10.1007/s003710050160
   Vincent L, 2007, COMPUTER, V40, P118, DOI 10.1109/MC.2007.442
   Wang ZH, 2009, PATTERN RECOGN, V42, P941, DOI 10.1016/j.patcog.2008.08.035
   Zhang CX, 2011, APPL OPTICS, V50, P4286, DOI 10.1364/AO.50.004286
   Zhang CX, 2010, IEEE IMAGE PROC, P3985, DOI 10.1109/ICIP.2010.5650944
   Zitnick CL, 2007, INT J COMPUT VISION, V75, P49, DOI 10.1007/s11263-006-0018-8
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 31
TC 2
Z9 3
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2014
VL 25
IS 2
BP 143
EP 154
DI 10.1002/cav.1541
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AE8SY
UT WOS:000334273500005
DA 2024-07-18
ER

PT J
AU Perriollat, M
   Bartoli, A
AF Perriollat, Mathieu
   Bartoli, Adrien
TI A computational model of bounded developable surfaces with application
   to image-based three-dimensional reconstruction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE developable; surface; structure-from-motion; 3D reconstruction; capture
ID APPROXIMATION
AB Developable surfaces have been extensively studied in computer graphics because they are involved in a large body of applications. This type of surfaces has also been used in computer vision and document processing in the context of three-dimensional (3D) reconstruction for book digitization and augmented reality. Indeed, the shape of a smoothly deformed piece of paper can be very well modeled by a developable surface. Most of the existing developable surface parameterizations do not handle boundaries or are driven by overly large parameter sets. These two characteristics become issues in the context of developable surface reconstruction from real observations. Our main contribution is a generative model of bounded developable surfaces that solves these two issues. Our model is governed by intuitive parameters whose number depends on the actual deformation and including the flat shape boundary. A vast majority of the existing image-based paper 3D reconstruction methods either require a tightly controlled environment or restricts the set of possible deformations. We propose an algorithm for reconstructing our model's parameters from a general smooth 3D surface interpolating a sparse cloud of 3D points. The latter is assumed to be reconstructed from images of a static piece of paper or any other developable surface. Our 3D reconstruction method is well adapted to the use of keypoint matches over multiple images. In this context, the initial 3D point cloud is reconstructed by structure-from-motion for which mature and reliable algorithms now exist and the thin-plate spline is used as a general smooth surface model. After initialization, our model's parameters are refined with model-based bundle adjustment. We experimentally validated our model and 3D reconstruction algorithm for shape capture and augmented reality on seven real datasets. The first six datasets consist of multiple images or videos and a sparse set of 3D points obtained by structure-from-motion. The last dataset is a dense 3D point cloud acquired by structured light. Our implementation has been made publicly available on the authors' web home pages. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Perriollat, Mathieu] VI Technol, Res & Dev Team, Grenoble, France.
   [Bartoli, Adrien] Univ Auvergne, Clermont Ferrand, France.
C3 Universite Clermont Auvergne (UCA)
RP Bartoli, A (corresponding author), Univ Auvergne, Clermont Ferrand, France.
EM Adrien.Bartoli@gmail.com
CR [Anonymous], 2001, A Practical Guide to Splines
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 1952, Geometry and the Imagination
   Aumann G, 2004, COMPUT AIDED GEOM D, V21, P661, DOI 10.1016/j.cagd.2004.04.007
   Aumann G, 2003, COMPUT AIDED GEOM D, V20, P601, DOI 10.1016/j.cagd.2003.07.001
   Aumann G., 1991, Computer-Aided Geometric Design, V8, P409, DOI 10.1016/0167-8396(91)90014-3
   Billinghurst M, 2001, COMPUT GRAPH-UK, V25, P745, DOI 10.1016/S0097-8493(01)00117-0
   BO P, 2007, P EUR PRAG CZECH REP
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Brown MS, 2007, IEEE T PATTERN ANAL, V29, P1904, DOI 10.1109/TPAMI.2007.1118
   Chen HY, 1999, GRAPH MODEL IM PROC, V61, P110, DOI 10.1006/gmip.1999.0487
   Chu CH, 2002, COMPUT AIDED DESIGN, V34, P511, DOI 10.1016/S0010-4485(01)00122-1
   COURTEILLE F, 2004, P INT C PATT REC CAM
   Demartines P, 1997, IEEE T NEURAL NETWOR, V8, P148, DOI 10.1109/72.554199
   Do Carmo M., 1976, Differential Geometry of Curves and Surfaces
   DUCHON J, 1976, REV FR AUTOMAT INFOR, V10, P5
   Fernández-Jambrina L, 2007, COMPUT AIDED GEOM D, V24, P189, DOI 10.1016/j.cagd.2007.03.001
   Glaeser G, 2007, J MATH ARTS, V1, P59, DOI 10.1080/17513470701230004
   Gumerov N, 2004, LECT NOTES COMPUT SC, V3023, P482
   Houle PA, 1996, PHYS REV E, V54, P278, DOI 10.1103/PhysRevE.54.278
   KERGOSIEN YL, 1994, IEEE COMPUT GRAPH, V14, P40, DOI 10.1109/38.250917
   Lang J., 1992, Computer-Aided Geometric Design, V9, P291, DOI 10.1016/0167-8396(92)90036-O
   Leopoldseder S, 1998, COMPUT AIDED DESIGN, V30, P571, DOI 10.1016/S0010-4485(98)00015-3
   Liang J, 2005, PROC CVPR IEEE, P338
   LIU Y, 2006, P SIGGRAPH BOST US
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LU F, 1994, SIGNAL PROCESS, V37, P129, DOI 10.1016/0165-1684(94)90171-6
   MAMIC G, 2001, P IEEE INT C IM PROC
   PARK J, 2004, INT S 3D DAT PROC VI
   PERRIOLLAT M, 2007, IEEE BENCHMARKING AU
   Peternell M, 2004, COMPUT AIDED GEOM D, V21, P785, DOI 10.1016/j.cagd.2004.07.008
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   Pottmann H, 1999, COMPUT AIDED GEOM D, V16, P539, DOI 10.1016/S0167-8396(99)00012-6
   Pottmann H, 2002, P 10 PAC C COMP GRAP
   Pressley A., 2005, ELEMENTARY DIFFERENT
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002
   Struik D.J., 1961, Lectures on Classical Differential Geometry
   Sun M, 1996, PROC GRAPH INTERF, P176
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Wallner J., 2001, MATH VISUAL
   Wang C. C. L., 2005, Computer-Aided Design and Applications, V2, P233
   Weinberger KQ, 2006, INT J COMPUT VISION, V70, P77, DOI 10.1007/s11263-005-4939-z
   Yang HP, 2004, COMPUT AIDED DESIGN, V36, P639, DOI 10.1016/S0010-4485(03)00140-4
NR 45
TC 18
Z9 19
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2013
VL 24
IS 5
BP 457
EP 475
DI 10.1002/cav.1478
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 238UL
UT WOS:000325976300003
DA 2024-07-18
ER

PT J
AU Tence, F
   Gaubert, L
   Soler, J
   De Loor, P
   Buche, C
AF Tence, F.
   Gaubert, L.
   Soler, J.
   De Loor, P.
   Buche, C.
TI CHAMELEON: online learning for believable behaviors based on humans
   imitation in computer games
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE believable agent; decision making; video games
ID AGENTS
AB In some video games, humans and computer programs can play together, each one controlling a virtual humanoid. These computer programs usually aim at replacing missing human players; however, they partially miss their goal, as they can be easily spotted by players as being artificial. Our objective is to find a method to create programs whose behaviors cannot be told apart from players when observed playing the game. We call this kind of behavior a believable behavior. To achieve this goal, we choose models using Markov chains to generate the behaviors by imitation. Such models use probability distributions to find which decision to choose depending on the perceptions of the virtual humanoid. Then, actions are chosen depending on the perceptions and the decision. We propose a new model, called Chameleon, to enhance expressiveness and the associated imitation learning algorithm. We first organize the sensors and motors by semantic refinement and add a focus mechanism in order to improve the believability. Then, we integrate an algorithm to learn the topology of the environment that tries to best represent the use of the environment by the players. Finally, we propose an algorithm to learn parameters of the decision model. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Gaubert, L.; Soler, J.; De Loor, P.; Buche, C.] UEB ENIB LAB STICC, CERV, F-29280 Plouzane, France.
   [Tence, F.; Soler, J.] VIRTUALYS, CERV, F-29280 Plouzane, France.
C3 Ecole Nationale d'Ingenieurs de Brest (ENIB)
RP Buche, C (corresponding author), UEB ENIB LAB STICC, CERV, 25 Rue Claude Chappe, F-29280 Plouzane, France.
EM buche@enib.fr
RI De Loor, Pierre/AAP-7967-2020
OI Gaubert, Laurent/0000-0001-6808-2645
CR [Anonymous], 1950, MIND, DOI 10.1093/mind/LIX.236.433
   Bates J., 1992, CMUCS92200 SCH COMP
   Bauckhage C, 2007, MMI INTERAKTIV, V12, P3
   Bossard C., 2009, P 11 VIRT REAL INT C, P171
   Bryant B D., 2006, Proceedings of the 2006 Congress on Evolutionary Computation (CEC 2006), P3752
   Cass S, 2002, IEEE SPECTRUM, V39, P40, DOI 10.1109/MSPEC.2002.1088444
   Cavazza Marc., 2003, INT C ENTERTAINMENT, P1
   DelBimbo A, 1995, IEEE T VIS COMPUT GR, V1, P350, DOI 10.1109/2945.485622
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fritzke B., 1995, Advances in Neural Information Processing Systems 7, P625
   Gorman B, 2006, LECT NOTES COMPUT SC, V4095, P655
   Hayes P, 1995, INT JOINT CONF ARTIF, P972
   Held R., 1991, Pictorial communication in virtual and real environments, P232
   Humphrys M., 2007, P 10 INT C COMPUTER
   Isla Damian., 2005, Game Developers Conference, P12
   Laird J. E., 2000, Simulating Human Agents. Papers from the 2000 AAAI Fall Symposium, P75
   Le Hy R, 2004, ROBOT AUTON SYST, V47, P177, DOI 10.1016/j.robot.2004.03.012
   LeHy R., 2007, THESIS I NATL POLYTE
   LIVINGSTONE D, 2006, COMPUTER ENTERTAINME, V4, DOI DOI 10.1145/1111293.1111303
   LOYALL AB, 1997, THESIS CARNEGIE MELL
   Mac Namee B., 2004, THESIS TRINITY COLL
   Mac Namee B., 2004, THESIS U DUBLIN
   Pinchbeck D., 2008, P PHIL COMP GAM 2008 P PHIL COMP GAM 2008, P242
   Riedl MO, 2005, LECT NOTES ARTIF INT, V3661, P278
   Searle J.R., 1980, MINDS, P353
   Silverman BG, 2006, PRESENCE-TELEOP VIRT, V15, P163, DOI 10.1162/pres.2006.15.2.163
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Tence F., 2011, THESIS UBO BREAST
   Tencé F, 2008, GAME-ON 2008: 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT GAMES AND SIMULATION, P39
   Thomas F., 1981, The Illusion of Life: Disney Animation
   Thurau C, 2005, GAMEON-NA 2005: 1ST INTERNATIONAL NORTH-AMERICAN CONFERENCE ON INTELLIGENT GAMES AND SIMULATION, P3
   Thurau C, 2004, FROM ANIMALS TO ANIMATS 8, P315
   WETZEL B, 2004, CHALLENGES GAME ARTI, P11
NR 34
TC 2
Z9 2
U1 0
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2013
VL 24
IS 5
BP 477
EP 496
DI 10.1002/cav.1524
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 238UL
UT WOS:000325976300004
DA 2024-07-18
ER

PT J
AU Liu, CX
   Li, H
   Peng, QS
   Wang, X
   Wu, EH
AF Liu, Chunxiao
   Li, Hong
   Peng, Qunsheng
   Wang, Xun
   Wu, Enhua
TI Relighting abstracted image via salient edge-guided luminance field
   optimization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE image abstraction; image relighting; salient edge; energy optimization;
   illumination decomposition
ID VIDEO ABSTRACTION
AB Because existing image abstraction systems can hardly incorporate with the changing light, we present an integrated image abstraction and relighting rendering system, which is based on a salient edge-guided luminance field optimization approach. For an input image, we first adopt a sparsity prior-based illumination decomposition method to remove its original illumination and have an intrinsic image. Meanwhile, we iteratively extract the salient edge inside by employing a message-passing strategy. Then, we simplify this image with a proposed salient edge-guided image abstraction optimization algorithm in the luminance field. Finally, we put forward a salient edge-guided image relighting optimization method to simulate the effect of dynamic lighting along different directions. Experiment results show that our system can artistically adjust the illumination of the abstracted image and makes it more vivid. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Liu, Chunxiao; Wang, Xun] Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, Hangzhou, Zhejiang, Peoples R China.
   [Li, Hong; Wu, Enhua] Univ Macau, FST, Dept Comp & Informat Sci, Macau, Peoples R China.
   [Peng, Qunsheng] Zhejiang Univ, Dept Math, State Key Lab CAD&CG, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University; University of Macau; Zhejiang University
RP Liu, CX (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, Hangzhou, Zhejiang, Peoples R China.
EM cxliu@mail.zjgsu.edu.cn
FU National Natural Science Foundation of China [61003188]; State Key Lab
   of Virtual Reality Technology and Systems at Beihang University
   [BUAA-VR-13KF-2013]; Technology Innovation Team Building Program of
   Zhejiang Province [2012R10041-15]; Education Department of Zhejiang
   Province [Y201018011]; Zhejiang Provincial Key Laboratory of Electronic
   Commerce and Logistics Information Technology [2011E10005]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61003188, the open funding project of State Key
   Lab of Virtual Reality Technology and Systems at Beihang University
   under Grant No. BUAA-VR-13KF-2013, the Key Technology Innovation Team
   Building Program of Zhejiang Province under Grant No. 2012R10041-15, the
   Education Department of Zhejiang Province under Grant No. Y201018011,
   and the Zhejiang Provincial Key Laboratory of Electronic Commerce and
   Logistics Information Technology under Grant No. 2011E10005.
CR Bhat P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731048
   Bousseau A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618476
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carroll R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964938
   Cong L, 2011, VISUAL COMPUT, V27, P187, DOI 10.1007/s00371-010-0522-2
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Huang H, 2011, VISUAL COMPUT, V27, P861, DOI 10.1007/s00371-011-0596-5
   Huang H, 2010, COMPUT GRAPH FORUM, V29, P2055, DOI 10.1111/j.1467-8659.2010.01792.x
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kyprianidis JE, 2011, COMPUT GRAPH FORUM, V30, P593, DOI 10.1111/j.1467-8659.2011.01882.x
   Kyprianidis JE, 2009, COMPUT GRAPH FORUM, V28, P1955, DOI 10.1111/j.1467-8659.2009.01574.x
   Levin A, 2007, IEEE T PATTERN ANAL, V29, P1647, DOI 10.1109/TPAMI.2007.1106
   Madsen C., 2004, 13 DANISH C PATTERN, P13
   Olsen S., 2011, ACM SIGGRAPH, P65
   Orzan A, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P103
   Peers P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239503
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Shen L, 2011, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2011.5995738
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Zhang SH, 2009, SCI CHINA SER F, V52, P162, DOI 10.1007/s11432-009-0035-7
   Zhao HL, 2008, VISUAL COMPUT, V24, P727, DOI 10.1007/s00371-008-0254-8
NR 26
TC 0
Z9 0
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 265
EP 274
DI 10.1002/cav.1516
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500014
DA 2024-07-18
ER

PT J
AU Hegde, S
   Gatzidis, C
   Tian, F
AF Hegde, Siddharth
   Gatzidis, Christos
   Tian, Feng
TI Painterly rendering techniques: a state-of-the-art review of current
   approaches
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE graphics; non-photorealistic rendering; NPR; survey; painterly
ID IMAGE; ABSTRACTION; ANIMATION
AB In this publication we will look at the different methods presented over the past few decades which attempt to recreate digital paintings. While previous surveys concentrate on the broader subject of non-photorealistic rendering, the focus of this paper is firmly placed on painterly rendering techniques. We compare different methods used to produce different output painting styles such as abstract, colour pencil, watercolour, oriental, oil and pastel. Whereas some methods demand a high level of interaction using a skilled artist, others require simple parameters provided by a user with little or no artistic experience. Many methods attempt to provide more automation with the use of varying forms of reference data. This reference data can range from still photographs, video, 3D polygonal meshes or even 3D point clouds. The techniques presented here endeavour to provide tools and styles that are not traditionally available to an artist. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Hegde, Siddharth; Gatzidis, Christos; Tian, Feng] Bournemouth Univ, Sch Design Engn & Comp, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University
RP Hegde, S (corresponding author), Bournemouth Univ, Sch Design Engn & Comp, Talbot Campus,Poole House, Poole BH12 5BB, Dorset, England.
EM shegde@bournemouth.ac.uk
RI Li, Mengqi/AAG-6804-2021
CR Adams B, 2004, EUR S POINT BAS GRAP, P59
   [Anonymous], 1986, P 13 ANN C COMP GRAP, DOI DOI 10.1145/15922.15911
   Baxter B, 2001, COMP GRAPH, P461, DOI 10.1145/383259.383313
   Bousseau A., 2006, P NPAR, P141, DOI [DOI 10.1145/1124728.1124751, 10.1145/1124728.1124751]
   Bousseau A, 2007, ACM SIGGRAPH 2007 PA
   Bratkova M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559759
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Chen J., 2008, Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST 2008, Bordeaux, France, October 27-29, 2008, P231
   Chi MT, 2006, IEEE T VIS COMPUT GR, V12, P61, DOI 10.1109/TVCG.2006.14
   Christoudias CM, 2005, PATT REC 2002 P 16 I, V4, P150
   Chu Nelson., 2010, P 8 INT S NONPHOTORE, P27, DOI 10.1145/1809939.1809943
   Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   Collomosse JP, 2005, IEEE T VIS COMPUT GR, V11, P540, DOI 10.1109/TVCG.2005.85
   Collomosse JP, 2002, 20TH EUROGRAPHICS UK CONFERENCE, PROCEEDINGS, P122, DOI 10.1109/EGUK.2002.1011281
   Curtis C. J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P421, DOI 10.1145/258734.258896
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Durand F, P 2 INT S NONPH AN R, P111
   Gooch A., 1998, P 25 ANN C COMP GRAP
   Gooch A.A., 2010, NPAR 10 P 8 INT S NO, P165
   Gooch B., 2002, 2 INT S NONPHOTOREAL, P83
   Guo C, 2007, COMPUTER VISION IMAG, V106, P5
   Haeberli P., 1990, Computer Graphics, V24, P207, DOI 10.1145/97880.97902
   Hays J., 2004, PROC NPAR 01, P113
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Hertzmann A, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P47, DOI 10.1109/CGI.2001.934657
   Hertzmann A., 2000, NPAR, P7
   Hsu S. C., 1993, Sixth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P197, DOI 10.1145/168642.168662
   Kalnins RD, 2002, ACM T GRAPHIC, V21, P755, DOI 10.1145/566570.566648
   Kaplan M., 2000, NPAR, P67, DOI 10.1145/340916.340925
   Kowalski MA, 1999, COMP GRAPH, P433, DOI 10.1145/311535.311607
   Kulla CD, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P477, DOI 10.1109/PCCGA.2003.1238298
   Kuwahara M., 1976, Digital Processing of Biomedical Images, P187, DOI [DOI 10.1007/978-1-4684-0769-3_13, 10.1007/978-1-4684-0769-313, DOI 10.1007/978-1-4684-0769-313, 10.1007/978-1-4684-0769-3_13]
   Kyprianidis JE, 2011, COMPUT GRAPH FORUM, V30, P593, DOI 10.1111/j.1467-8659.2011.01882.x
   LANSDOWN J, 1995, IEEE COMPUT GRAPH, V15, P29, DOI 10.1109/38.376610
   Lee H, 2009, COMPUT GRAPH FORUM, V28, P1207, DOI 10.1111/j.1467-8659.2009.01498.x
   Lee H., 2010, Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering, P43
   Lee J, 1999, IEEE COMPUT GRAPH, V19, P74, DOI 10.1109/38.761553
   Lee J, 2001, COMPUT GRAPH-UK, V25, P295, DOI 10.1016/S0097-8493(00)00132-1
   Lee S., 2006, Proc. NPAR '06, P97, DOI DOI 10.1145/1124728.1124745
   Lin L., 2010, Proc. NPAR '10, P73, DOI DOI 10.1145/1809939.1809948
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   Lu J., 2010, PROC ACM SIGGRAPH S, P127
   Luft T., 2006, Proceedings of the 4th International Symposium on Non-Photorealistic Animation and Rendering, NPAR'06, P11, DOI [10.1145/1124728.1124732, DOI 10.1145/1124728.1124732]
   Mao XY, 2001, CAD/GRAPHICS '2001: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN AND COMPUTER GRAPHICS, VOLS 1 AND 2, P240
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Meier B. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P477, DOI 10.1145/237170.237288
   Olsen SvenC., 2005, P GRAPHICS INTERFACE, P241
   Papari G, 2007, IEEE T IMAGE PROCESS, V16, P2449, DOI 10.1109/TIP.2007.903912
   Park Y, 2008, GRAPH MODELS, V70, P1, DOI 10.1016/j.gmod.2007.06.001
   Petrov Alexander., 1999, OLD MAN SEA
   Santella A, P 2 INT S NONPH AN R, P75
   Schlechtweg S, 2005, COMPUT GRAPH FORUM, V24, P137, DOI 10.1111/j.1467-8659.2005.00838.x
   Schmid J, 2011, ACM SIGGRAPH 2011 PA, P28
   Schwarz M, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P15
   SHIRAISHI M, 2000, P 1 INT S NONPH AN R, P53, DOI DOI 10.1145/340916.340923
   Solso R., 1996, COGNITION VISUAL ART
   Sousa MC, 1999, PROC GRAPH INTERF, P157
   Sousa MC, 2000, COMPUT GRAPH FORUM, V19, P27, DOI 10.1111/1467-8659.00386
   Takgi S., 1999, Proceedings. Seventh Pacific Conference on Computer Graphics and Applications (Cat. No.PR00293), P250, DOI 10.1109/PCCGA.1999.803369
   Te W, 1988, SHAN SHUI QING
   Velho Luiz, 1991, P 18 ANN C COMP GRAP, P81, DOI 10.1145/122718.122727
   Way DL, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P499
   Xie N., 2010, Proc. NPAR '10, P63
   XU H., 2004, Proceedings of the 3rd International Symposium on Non-Photorealistic Animation and Rendering (NPAR 2006), P25, DOI DOI 10.22633/RPGE.V25I3.15840
   XU H, 2004, P 7 INT S REC ADV IN, P21
   Yamamoto S, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P329
   Yao B, 2007, LECT NOTES COMPUT SC, V4679, P169
   Yen CR, 2007, IEEE T VISUALIZATION, V14, P468
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhang SH, 2009, SCI CHINA SER F, V52, P162, DOI 10.1007/s11432-009-0035-7
   Zhao M., 2010, PROC INT S NONPHOTOR, P99, DOI DOI 10.1145/1809939.1809951
   Zwicker M, ACM T GRAPHICS TOG, P322
NR 74
TC 20
Z9 24
U1 1
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2013
VL 24
IS 1
BP 43
EP 64
DI 10.1002/cav.1435
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 089PU
UT WOS:000314923300006
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Alvarez, H
   Leizea, I
   Borro, D
AF Alvarez, Hugo
   Leizea, Ibai
   Borro, Diego
TI A new marker design for a robust marker tracking system against
   occlusions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; marker; tracking; occlusion
AB Marker systems are a widely used optical tracking method that does not support occlusions. Thus, this paper proposes a new marker design to overcome the problem of marker occlusions. It is highly adaptable, because it can be used by any marker tracking system that uses its central area to codify the digital identification. Our proposal takes advantage of an untapped frame to place some textures that will be tracked during marker occlusion. In addition, these textures are customizable, which lets users make their own designs. Two tracking methods are combined to offer a robust tracking, updating the six degrees of freedom of the camera in real time. The first one is a fast technique based on temporal coherence, whereas the second one is a robust technique based on appearance, which is used as a recovery mode. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Alvarez, Hugo] Univ Navarra, Ceit, San Sebastian 20018, Spain.
   [Alvarez, Hugo] Univ Navarra, Tecnun, San Sebastian 20018, Spain.
C3 University of Navarra; University of Navarra
RP Alvarez, H (corresponding author), Univ Navarra, Ceit, Manuel de Lardizabal 15, San Sebastian 20018, Spain.
EM halvarez@ceit.es
RI Borro, Diego/J-5433-2019
OI Borro, Diego/0000-0002-8789-4777; LEIZEA, IBAI/0000-0002-8141-2626
FU Government of the Basque Country within the Formacion de Personal
   Investigador program; Beca Universidad de Navarra of the University of
   Navarra
FX The contract of Hugo Alvarez is funded by the Government of the Basque
   Country within the Formacion de Personal Investigador program that
   belongs to the Education, University and Research department. We are
   thankful to the Beca Universidad de Navarra of the University of Navarra
   for funding the contract of Ibai Leizea.
CR ALVAREZ H, 2009, INT C COMP VIS THEOR, P478
   [Anonymous], 2007, Proc. CVWW '07
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Fiala M, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P148
   Fiala M, 2005, PROC CVPR IEEE, P590
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gall J, 2006, LECT NOTES COMPUT SC, V4319, P84
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Lee Gun A, 2004, PROC 2004 ACM SIGGRA, P419
   López-De-Ipiña D, 2002, PERS UBIQUIT COMPUT, V6, P206, DOI 10.1007/s007790200020
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maidi M, 2010, J IMAGE VIDEO PROCES, V2010, P1
   Malik S, 2002, P C VIS INT VI 02 CA, P399
   Marimon D, 2007, P 1S T SPIE EL IM C
   Mcdonald C, 2003, P VIS INT VI 03 HAL
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Möhring M, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P252, DOI 10.1109/ISMAR.2004.63
   Nakai T, 2006, LECT NOTES COMPUT SC, V3872, P541
   Pressigout M, 2006, IEEE INT CONF ROBOT, P2726, DOI 10.1109/ROBOT.2006.1642113
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Sanchez Jairo R., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P185, DOI 10.1109/ISMAR.2010.5643568
   Tateno K, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P259
   Uchiyama H, 2011, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2011.5759433
   Vacchetti L, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P48, DOI 10.1109/ISMAR.2004.24
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Wagner D, 2008, INT SYM MIX AUGMENT, P121, DOI 10.1109/ISMAR.2008.4637337
   Xu K, 2008, IMAGE VISION COMPUT, V26, P673, DOI 10.1016/j.imavis.2007.08.015
   Zhang X, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P97, DOI 10.1109/ISMAR.2002.1115078
NR 29
TC 5
Z9 6
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2012
VL 23
IS 5
BP 503
EP 518
DI 10.1002/cav.1487
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 021ZW
UT WOS:000309925700006
DA 2024-07-18
ER

PT J
AU Yoshiyasu, Y
   Yamazaki, N
AF Yoshiyasu, Yusuke
   Yamazaki, Nobutoshi
TI Detail-aware spatial deformation transfer
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE space deformation; deformation transfer
ID MESH
AB In this paper, we propose a deformation transfer method that is applicable to multi-component objects and is able to transfer fine-scale deformations. To accomplish our goal, we combine surface-based and space-based deformation transfers. Our system enhances the result of space deformation transfer, which is applicable to multi-component objects but loses details, by using surface-based deformation transfer to add fine-scale deformations. Self-collisions are handled by approximating spatial relationships between surfaces, from the result of space deformation. Experimental results show that our method can transfer fine-scale deformations such as motions of a skirt and muscle bulging. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Yamazaki, Nobutoshi] Keio Univ, Dept Mech Engn, Tokyo 108, Japan.
C3 Keio University
RP Yoshiyasu, Y (corresponding author), 3-14-1 Hiyoshi,Kohoku Ku, Yokohama, Kanagawa 2238522, Japan.
EM yusuke_2_ax_es@z6.keio.jp
RI Yoshiyasu, Yusuke/M-4386-2016
CR [Anonymous], 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'02
   [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Baran I, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531342
   Ben-Chen Mirela, 2009, P 2009 ACM SIGGRAPH, P67
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Chen L, 2010, COMPUT GRAPH-UK, V34, P107, DOI 10.1016/j.cag.2010.01.003
   Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Lee TY, 2006, VISUAL COMPUT, V22, P729, DOI 10.1007/s00371-006-0059-6
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Yong Zhao, 2011, 2011 12th International Conference on Computer-Aided Design and Computer Graphics, P302, DOI 10.1109/CAD/Graphics.2011.60
   Yoshiyasu Y, 2012, P C COMP AN SOC AG C
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zhao Y, 2009, COMPUT ANIMAT VIRT W, V20, P301, DOI 10.1002/cav.302
   Zhou K, 2010, COMPUT GRAPH FORUM, V29, P319, DOI 10.1111/j.1467-8659.2009.01601.x
NR 20
TC 2
Z9 2
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 225
EP 233
DI 10.1002/cav.1442
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100010
OA Bronze
DA 2024-07-18
ER

PT J
AU Beacco, A
   Andujar, C
   Pelechano, N
   Spanlang, B
AF Beacco, A.
   Andujar, C.
   Pelechano, N.
   Spanlang, B.
TI Efficient rendering of animated characters through optimized per-joint
   impostors
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd rendering; image-based rendering; impostors; level of detail
ID HUMANS
AB In this paper, we present a new impostor-based representation for 3D animated characters supporting real-time rendering of thousands of agents. We maximize rendering performance by using a collection of pre-computed impostors sampled from a discrete set of view directions. Our approach differs from previous work on view-dependent impostors in that we use per-joint rather than per-character impostors. Our characters are animated by applying the joint rotations directly to the impostors, instead of choosing a single impostor for the whole character from a set of pre-defined poses. This offers more flexibility in terms of animation clips, as our representation supports any arbitrary pose, and thus, the agent behavior is not constrained to a small collection of pre-defined clips. Because our impostors are intended to be valid for any pose, a key issue is to define a proper boundary for each impostor to minimize image artifacts while animating the agents. We pose this problem as a variational optimization problem and provide an efficient algorithm for computing a discrete solution as a pre-process. To the best of our knowledge, this is the first time a crowd rendering algorithm encompassing image-based performance, small graphics processing unit footprint, and animation independence is proposed. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Beacco, A.; Andujar, C.; Pelechano, N.] Univ Politecn Cataluna, MOVING Res Grp, Barcelona, Spain.
   [Spanlang, B.] BodyMetrics, London, England.
   [Spanlang, B.] Univ Barcelona, EventLab, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya; University of Barcelona
RP Beacco, A (corresponding author), Univ Politecn Cataluna, MOVING Res Grp, Barcelona, Spain.
EM abeacco@lsi.upc.edu
RI Beacco, Alejandro/AAD-7459-2020; Pelechano, Nuria/K-4288-2014; Andujar,
   Carlos/K-3692-2014
OI Beacco, Alejandro/0000-0001-8192-1431; Pelechano,
   Nuria/0000-0002-1437-245X; Spanlang, Bernhard/0000-0002-9659-635X;
   Andujar, Carlos/0000-0002-8480-4713
FU Spanish Government [TIN2010-20590-C01-01]; TRAVERSE ERC [227985]
FX This research has been partially funded by the Spanish Government grant
   TIN2010-20590-C01-01 and the TRAVERSE ERC advanced grant 227985.
CR [Anonymous], VIRTUAL SYST MULTIME
   Aubel A, 2000, IEEE T CIRC SYST VID, V10, P207, DOI 10.1109/76.825720
   Aubel A., 1998, Virtual Worlds. First International Conference, VW'98. Proceedings, P14
   Baboud L, 2006, PROC GRAPH INTERF, P195
   Beacco A, 2011, COMPUT GRAPH FORUM, V30, P2328, DOI 10.1111/j.1467-8659.2011.02065.x
   Coic J, 2007, RN0620 LIRIS U CLAUD
   Dobbyn S., 2005, ACM SIGGRAPH 2005 S, P95, DOI DOI 10.1145/1053427.1053443
   Dudash B., 2007, GPU GEMS, V3, P39
   Dudash B, 2007, NVIDIA SDK, V10
   Gillies M, 2010, PRESENCE-VIRTUAL AUG, V19, P95, DOI 10.1162/pres.19.2.95
   Kavan L, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P149
   Maïm J, 2009, IEEE COMPUT GRAPH, V29, P82, DOI 10.1109/MCG.2009.129
   McDonnell R, 2009, ACM T GRAPHIC, V28, P55
   McDonnell R, 2005, INT WORKSH CROWD SIM, P101
   Millan E., 2006, P 4 INT C COMPUTER G, P49, DOI DOI 10.1145/1174429.1174436
   Pettre J, 2006, COMPUTER ANIMATION V, P445
   Policarpo F., 2005, Proceedings of the 2005 symposium on Interactive 3D graphics and games, P155, DOI DOI 10.1145/1053427.1053453
   Policarpo F., 2007, GPU gems, V3, P409
   Pratt DR, 1997, PRESENCE-TELEOP VIRT, V6, P547, DOI 10.1162/pres.1997.6.5.547
   Schaufler G., 1997, Rendering Techniques '97. Proceedings of the Eurographics Workshop. Eurographics, P151
   Schroders M., 2006, Proceedings of the 21st ACM SIGGRAPH EUROGRAPHICS symposium on Graphics hardware, P61
   SPANLANG B, 2009, HALCA HARDWARE ACCEL
   Tatarchuk N., 2006, Proceedings of the 2006 symposium on Interactive 3D graphics and games, P63
   Tecchia F, 2002, IEEE COMPUT GRAPH, V22, P36, DOI 10.1109/38.988745
   Tecchia F, 2000, SPRING COMP SCI, P83
   Wand M, 2002, COMPUT GRAPH FORUM, V21, P483, DOI 10.1111/1467-8659.t01-1-00608
NR 26
TC 4
Z9 4
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2012
VL 23
IS 1
BP 33
EP 47
DI 10.1002/cav.1422
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 897SH
UT WOS:000300675800005
DA 2024-07-18
ER

PT J
AU Hwang, J
   Kim, GJ
AF Hwang, Jane
   Kim, Gerard J.
TI Provision and maintenance of presence and immersion in hand-held virtual
   reality through motion based interaction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion based interaction; presence; immersion; hand-held virtual
   reality; proprioception; perceived field of view
ID ENVIRONMENTS; PERCEPTION; PERFORMANCE
AB Hand-held devices are also becoming computationally more powerful and being equipped with special sensors and non-traditional displays for diverse applications aside from just making phone calls. As such, it raises the question of whether realizing virtual reality, providing a minimum level of immersion and presence, might be possible on a hand-held device capable of only relatively "small'' display. In this paper, we propose that motion based interaction can widen the perceived field of view (FOV) more than the actual physical FOV, and in turn, increase the sense of presence and immersion up to a level comparable to that of a desktop or projection display based VR systems. We have implemented a prototype hand-held VR platform and conducted two experiments to verify our hypothesis. Our experimental study has revealed that when a motion based interaction was used, the FOV perceived by the user for the small hand held device was significantly greater than (around 50%) the actual. Other larger display platforms using the conventional button or mouse/keyboard interface did not exhibit such a phenomenon. In addition, the level of user felt presence in the hand-held platform was higher than or comparable to those in VR platforms with larger displays. We hypothesize that this phenomenon is related to and analogous to the way the human vision system compensates for differences in acuity resolution in the eye/retina through the saccadic activity. The paper demonstrates the distinct possibility of realizing reasonable virtual reality even with devices with a small visual FOV and limited processing power. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Kim, Gerard J.] Korea Univ, Dept Comp Sci & Engn, Digital Experience Lab, Seoul, South Korea.
   [Hwang, Jane] Korea Inst Sci & Technol, Image Media Res Ctr, Seoul, South Korea.
C3 Korea University; Korea Institute of Science & Technology (KIST)
RP Kim, GJ (corresponding author), Korea Univ, Dept Comp Sci & Engn, Digital Experience Lab, Seoul, South Korea.
EM gjkim@korea.ac.kr
FU Korea Ministry of Knowledge Economy (MKE); Korea Institute of Science
   and Technology under KOCCA; Korea University [K0619461]
FX This research was supported in part by the Strategic Technology
   Laboratory Program (Multimodal Entertainment Platform area) of Korea
   Ministry of Knowledge Economy (MKE), Korea Institute of Science and
   Technology (under the KOCCA Mobile Augmented Reality Tour project), and
   a grant from Korea University (K0619461).
CR ALFANO PL, 1990, PERCEPT MOTOR SKILL, V70, P35, DOI 10.2466/PMS.70.1.35-45
   [Anonymous], 1994, COMPUTER VISION PATT
   [Anonymous], 2009, NINT WII
   [Anonymous], 2009, DANC DANC REV
   [Anonymous], 2009, OPEN SOURCE COMPUTER
   [Anonymous], 2009, DIRECTSOUND
   ARTHUR K, 1996, P C HUM FACT COMP SY, P29
   Ballagas R, 2005, P CHI 2005 C HUM FAC
   Bayon V, 2003, P HCI INT
   Berthoz A., 2000, The brain's sense of movement
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Bowman DA, 2002, PRESENCE-TELEOP VIRT, V11, P404, DOI 10.1162/105474602760204309
   Clifford M., 2005, Measuring tilt with low-g accelerometers
   Creem-Regehr S, 2003, UUCS03016
   Duh H, 2001, P IEEE VIRT REAL C
   FITZMAURICE GW, 1993, ACM T INFORM SYST, V11, P197, DOI 10.1145/159161.159160
   Gutiérrez M, 2004, P IEEE VIRT REAL ANN, P125, DOI 10.1109/VR.2004.1310065
   Hachet M, 2005, P IEEE VR 2005 WORKS
   Hacket M, 2005, P ACM SIGGRAPH S INT
   Henry D, 1993, P IEEE VIRT REAL ANN, P33, DOI DOI 10.1109/VRAIS.1993.380801
   Hinckley K, 2000, P ACM S US INT SOFTW
   Hinkley K, 1997, P ACM C HUM FACT COM
   Hwang J, 2006, P ACM VIRT REAL SOFT
   ISPR, 2004, PRES WHAT IS PRES
   James KR, 1995, P HUM FACT ERG SOC 3, P275
   Knapp J, 2003, PRESENCE TELEOPERATO, V13
   Knapp J. M., 1999, ProQuest Diss. Theses,, P125
   Kukimoto N, 2003, P 3 IASTED INT C VIS
   Lampton DR, 2003, P HUM FACT ERG SOC 3, V39, P1268
   Lee S, 2004, P 7 ANN INT PRES WOR
   Lin J, 2002, P IEEE VIRT REAL C
   Lindeman RobertW., 1999, Proceedings of the SIGCHI conference on Human factors in computing systems the CHI is the limit - CHI '99, P64, DOI [10.1145/302979.302995, DOI 10.1145/302979.302995]
   Lourakis M, 2005, COMPUTER VISION IMAG, P99
   MacKay D.M., 1973, Handbook of Sensory Physiology, V8, P307, DOI DOI 10.1007/978-3-642-65352-0_5
   Mine M, 1997, P ACM SIGGRAPH
   Ni T, 2006, PROC GRAPH INTERF, P139
   NVIDIA, 2009, VIS COMP MOB DEV
   OREGAN JK, 1992, CAN J PSYCHOL, V46, P461, DOI 10.1037/h0084327
   Paelke V, 2004, P ACM INT C ADV COMP
   PARADISO MA, 1991, VISION RES, V31, P1221, DOI 10.1016/0042-6989(91)90047-9
   Polys N, 2005, P ACM VIRT REAL SOFT
   Poupyrev I, 2002, P C HUM FACT COMP SY
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   Seay AF, 2001, P IEEE VIRT REAL ANN, P299, DOI 10.1109/VR.2001.913806
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, pIII
   Slater M, 1995, ACM T COMPUTER HUMAN
   Usoh M, 1999, P ACM SIGGRAPH
   VOLKMANN FC, 1968, J OPT SOC AM, V58, P562, DOI 10.1364/JOSA.58.000562
   Wagner D, 2003, P INT C WEAR COMP
   Waller D, 1999, PRESENCE-TELEOP VIRT, V8, P657, DOI 10.1162/105474699566549
   Watsen K, 1999, P INT PROJ TECHN WOR
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Witmer BG, 1998, HUM FACTORS, V40, P478, DOI 10.1518/001872098779591340
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P144, DOI 10.1162/105474698565640
   Yang U, 2004, P IEEE INT C VIRT RE
   Yee K.P., 2003, Proc. CHI'03, P571, DOI DOI 10.1145/642611.642613
NR 57
TC 0
Z9 0
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2010
VL 21
IS 6
BP 547
EP 559
DI 10.1002/cav.336
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 696EB
UT WOS:000285423600002
DA 2024-07-18
ER

PT J
AU Chen, H
   Sun, HQ
   Jin, XG
AF Chen, Hui
   Sun, Hanqiu
   Jin, Xiaogang
TI Haptic-constraint modeling based on interactive metaballs
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE haptics interface; constrained deformation; metaballs
ID DEFORMATIONS; OBJECTS; FORCE
AB Adding interactive haptic-constraint sensations is important in interactive computer gaming and 3D shape design. Usually constraints are set on vertices of the object to drive the deformation. How to simulate dynamic force constraints in interactive design is still a challenging task. In this paper, we propose a novel haptic-constraint modeling method based on interactive metaballs, during which the haptic-constraint tools are attracted to the target location and then control the touch-enabled deformation within the constrained areas. The interactive force feedbacks facilitate designers to accurately deform the target regions and fine carve the details as their intention on the objects. Our work studies how to apply touch sensation in such constrained deformations using interactive metaballs, thus users can truly feel and control the soft-touch objects during the deforming interactions. Experimental results show that the dynamic sense of touch during the haptic manipulation is intuitively simulated to users, via the interacting interface we have developed. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Chen, Hui] Chinese Univ Hong Kong, Chinese Acad Sci, Shenzhen Inst Adv Integrat Technol, Shenzhen, Peoples R China.
   [Sun, Hanqiu] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shenzhen, Peoples R China.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
C3 The Chinese University of Hong Kong, Shenzhen; Chinese Academy of
   Sciences; Shenzhen Institute of Advanced Technology, CAS; The Chinese
   University of Hong Kong, Shenzhen; Zhejiang University
RP Chen, H (corresponding author), Chinese Univ Hong Kong, Chinese Acad Sci, Shenzhen Inst Adv Integrat Technol, Shenzhen, Peoples R China.
EM hui.chen@siat.ac.cn
CR [Anonymous], 1997, Introduction to Implicit Surfaces
   [Anonymous], 2001, P 2001 S INT 3D GRAP
   [Anonymous], P EUR REAL TIM 3D DE
   Basdogan C, 2001, STUD HEALTH TECHNOL, V81, P46
   Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290
   Bloomenthal J., 1990, Computer Graphics, V24, P109, DOI 10.1145/91394.91427
   BLOOMENTHAL J, 1991, COMP GRAPH, V25, P251, DOI 10.1145/127719.122757
   BORREL P, 1994, ACM T GRAPHIC, V13, P137, DOI 10.1145/176579.176581
   Botsch M, 2005, COMPUT GRAPH FORUM, V24, P611, DOI 10.1111/j.1467-8659.2005.00886.x
   Chen H, 2006, PRESENCE-VIRTUAL AUG, V15, P186, DOI 10.1162/pres.2006.15.2.186
   CHEN H, 2002, ACM VIRTUAL REALITY, P81
   Chen H, 2007, COMPUT ANIMAT VIRT W, V18, P153, DOI 10.1002/cav.171
   Clapés M, 2008, LECT NOTES COMPUT SC, V5098, P359, DOI 10.1007/978-3-540-70517-8_35
   COLGATE JE, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P140, DOI 10.1109/IROS.1995.525875
   Dachille F, 2001, COMPUT AIDED DESIGN, V33, P403, DOI 10.1016/S0010-4485(00)00131-7
   Duriez C, 2006, IEEE T VIS COMPUT GR, V12, P36, DOI 10.1109/TVCG.2006.13
   Feygin D, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P40, DOI 10.1109/HAPTIC.2002.998939
   Forsyth BAC, 2006, IEEE T VIS COMPUT GR, V12, P103, DOI 10.1109/TVCG.2006.11
   FOSKEY M, 2005, INT C COMP GRAPH INT, P188
   GARRE C, 2009, HAPTIC RENDERING COM
   GLENCROSS M, 2006, SIGGRAPH 2006 COURS
   Gregory A, 2000, IEEE VISUAL, P139, DOI 10.1109/VISUAL.2000.885687
   HIGASHI M, 2002, J COMPUTING INFORM S, V2, P265
   Ho CH, 2000, INT J ROBOT RES, V19, P668, DOI 10.1177/027836490001900704
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   Jin XG, 2000, COMPUT GRAPH-UK, V24, P219, DOI 10.1016/S0097-8493(99)00156-9
   Kim YJ, 2003, PRESENCE-VIRTUAL AUG, V12, P277, DOI 10.1162/105474603765879530
   Komerska R, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P270, DOI 10.1109/HAPTIC.2003.1191295
   LANQUETIN S, 2006, LNCS, P132
   Liu X, 2005, COMPUT AIDED DESIGN, V37, P1447, DOI 10.1016/j.cad.2005.02.015
   Magnenat-Thalmann N, 2007, 2007 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P3, DOI 10.1109/CW.2007.18
   McNeely WA, 1999, COMP GRAPH, P401, DOI 10.1145/311535.311600
   Miller T., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P97, DOI 10.1145/300523.300534
   Nishimura H., 1985, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ68D, P718
   NISHITA T, 1994, COMPUT GRAPH FORUM, V13, pC271, DOI 10.1111/1467-8659.1330271
   NOH JY, 2000, P ACM S VIRT REAL SO, P166
   Otaduy MA, 2003, ACM T GRAPHIC, V22, P543, DOI 10.1145/882262.882305
   OTADUY MA, 2005, P WORLD HAPT C JOINT
   Otaduy MA, 2006, IEEE T ROBOT, V22, P751, DOI 10.1109/tro.2006.876897
   Puangmali P, 2008, IEEE SENS J, V8, P371, DOI 10.1109/JSEN.2008.917481
   ROSENBERG LB, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P76, DOI 10.1109/VRAIS.1993.380795
   Ruspini D. C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P345, DOI 10.1145/258734.258878
   SEO Y, 2007, HAVE 2007 IEEE INT W, P136
   SNIBBE S, 1998, P 3 PHANT US GROUP
   Volino P, 2007, VISUAL COMPUT, V23, P133, DOI 10.1007/s00371-006-0034-2
   WITKIN A., 2001, SIGGRAPH 2001 COURS
   YOSHIHIRO K, 2005, COMPUTER METHODS PRO, V80, P216
   ZILLES CB, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P146, DOI 10.1109/IROS.1995.525876
NR 48
TC 0
Z9 0
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2010
VL 21
IS 5
BP 485
EP 497
DI 10.1002/cav.333
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 672VP
UT WOS:000283615300002
DA 2024-07-18
ER

PT J
AU Vanhala, T
   Surakka, V
   Siirtola, H
   Räihä, KJ
   Morel, B
   Ach, L
AF Vanhala, Toni
   Surakka, Veikko
   Siirtola, Harri
   Raiha, Kari-Jouko
   Morel, Benoit
   Ach, Laurent
TI Virtual proximity and facial expressions of computer agents regulate
   human emotions and attention
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE embodied agents; proximity; facial expressions; heart rate; emotion;
   attention
ID COMPONENTS
AB Emotion- and attention-related subjective and physiological responses to virtual proximity and facial expressions of embodied computer agents (ECA) were studied. Thirty participants viewed female and male characters with a neutral, unpleasant, or pleasant facial expression. Agents' size was used to simulate three levels of proximity. Participants' electrical facial muscle and heart activity were registered, and subjective ratings of emotional and attentional experiences collected. Unpleasant and large (i.e., closer) agents were more alerting (i.e., unpleasant, arousing, and dominating) and attracted more stimulus-driven attention than neutral, pleasant, and smaller (i.e., further away) agents. Pleasant agents attracted more voluntary attention than neutral and unpleasant agents. Heart rate (HR) responded to agent proximity, while the valence of the agent affected electrical facial muscle activity. Thus, the imitation of human social emotional cues in embodied computer agents (ECAs) could be used to regulate human-computer interaction. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Vanhala, Toni] Univ Tampere, Dept Comp Sci, Tampere Unit Comp Human Interact TAUCHI, Tampere 33014, Finland.
C3 Tampere University
RP Vanhala, T (corresponding author), Univ Tampere, Dept Comp Sci, Tampere Unit Comp Human Interact TAUCHI, Tampere 33014, Finland.
EM toni.vanhala@cs.uta.fi
OI Raiha, Kari-Jouko/0000-0001-5639-975X; Surakka,
   Veikko/0000-0003-3986-0713
CR Amodio DM, 2008, PSYCHOPHYSIOLOGY, V45, P11, DOI 10.1111/j.1469-8986.2007.00609.x
   [Anonymous], 2007, STAT METHODS PSYCHOL
   Arvidson P. S., 2003, Phenomenology and the Cognitive Sciences, V2, P99, DOI 10.1023/A:1024895827774
   Beale R, 2009, INT J HUM-COMPUT ST, V67, P755, DOI 10.1016/j.ijhcs.2009.05.001
   Bourgeois P, 2008, BIOL PSYCHOL, V77, P343, DOI 10.1016/j.biopsycho.2007.11.008
   Bradley MM, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P581, DOI 10.1017/CBO9780511546396.025
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Codispoti M, 2007, PSYCHOPHYSIOLOGY, V44, P680, DOI 10.1111/j.1469-8986.2007.00545.x
   *COMP NEUR, 2003, 2202 COMP NEUR
   FRIDLUND AJ, 1986, PSYCHOPHYSIOLOGY, V23, P567, DOI 10.1111/j.1469-8986.1986.tb00676.x
   Gratton G., 2000, Handbook of psychophysiology, V2nd, P900
   Hall EdwardT., 1996, HIDDEN DIMENSION
   HAYDUK LA, 1983, PSYCHOL BULL, V94, P293, DOI 10.1037/0033-2909.94.2.293
   Hess U, 2001, INT J PSYCHOPHYSIOL, V40, P129, DOI 10.1016/S0167-8760(00)00161-6
   Koda T, 2009, AI SOC, V24, P237, DOI 10.1007/s00146-009-0214-5
   Larsen JT, 2003, PSYCHOPHYSIOLOGY, V40, P776, DOI 10.1111/1469-8986.00078
   LEHTINEN M, 2004, MOT KIELITOIMISTON S
   Loftus GR, 2005, PSYCHON B REV, V12, P43, DOI 10.3758/BF03196348
   Martin JC, 2006, INT J HUM ROBOT, V3, P269, DOI 10.1142/S0219843606000825
   Mauss IB, 2005, EMOTION, V5, P175, DOI 10.1037/1528-3542.5.2.175
   MEHLMAN DW, 1995, ECOLOGY, V76, P640, DOI 10.2307/1941219
   Moundridou M, 2002, J COMPUT ASSIST LEAR, V18, P253, DOI 10.1046/j.0266-4909.2001.00237.x
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72, DOI 10.1145/191666.191703
   Partala T, 2004, INTERACT COMPUT, V16, P295, DOI 10.1016/j.intcom.2003.12.001
   Partala T., 2004, Proceedings of the third nordic conference on human-computer interaction, P353, DOI DOI 10.1145/1028014.1028070DOI.ORG/10.1145/1028014.1028070
   *PHYSIONET, PHYS
   POSNER MI, 1982, AM PSYCHOL, V37, P168, DOI 10.1037/0003-066X.37.2.168
   Schneider W., 2002, E-Prime User's Guide
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Sternberg R., 2006, COGNITIVE PSYCHOL, VFourth
   Surakka V, 1998, COGNITIVE BRAIN RES, V7, P159, DOI 10.1016/S0926-6410(98)00021-4
   Weyers P, 2006, PSYCHOPHYSIOLOGY, V43, P450, DOI 10.1111/j.1469-8986.2006.00451.x
NR 32
TC 5
Z9 6
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 215
EP 224
DI 10.1002/cav.366
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400009
DA 2024-07-18
ER

PT J
AU Karamouzas, I
   Overmars, MH
AF Karamouzas, Ioannis
   Overmars, Mark H.
TI Adding variation to path planning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE path planning; Corridor Map Method; variation; Perlin noise
ID MODEL
AB Path planning in computer games, whether these are serious or entertainment games, plays an important role in the immersion of a player. Recently, the concept of path planning inside corridors has been introduced and a novel approach tinder the name Corridor Map Method (CMM) has beers proposed. In this paper; We extend the original CMM by creating alternative paths that a character can follow within a corridor. This not only presents a more challenging and less predictable opponent for the player; but also enhances the realism of the gaining and/or training experience. We also discuss how variation in the speed of the animated characters can be integrated into our extended framework, leading to convincing characters that exhibit human like path planning. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Karamouzas, Ioannis] Univ Utrecht, Dept Informat & Comp Sci, Ctr Games & Virtual Worlds, NL-3584 CH Utrecht, Netherlands.
C3 Utrecht University
RP Karamouzas, I (corresponding author), Univ Utrecht, Dept Informat & Comp Sci, Ctr Games & Virtual Worlds, Padualaan 14, NL-3584 CH Utrecht, Netherlands.
EM ioannis@cs.uu.nl
CR [Anonymous], 2000, P WORKSH ALG FDN ROB
   Cluss M., 2006, American Society of Biomechanics
   DELOURA M, 2000, GAME PROGRAMMING GEM, V1
   Fritz S., 1998, GISRUK 98
   Geraerts R, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4355, DOI 10.1109/IROS.2006.282009
   Geraerts R, 2007, COMPUT ANIMAT VIRT W, V18, P107, DOI 10.1002/cav.166
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   HELBING D, 1994, J MATH SOCIOL, V19, P189, DOI 10.1080/0022250X.1994.9990143
   Kamphuis A., 2004, SCA '04: Proceedings of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P19
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Kuffner J. J.  Jr., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P995, DOI 10.1109/ROBOT.2000.844730
   LaValle SM, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P473, DOI 10.1109/ROBOT.1999.770022
   *MET VR INC, MET REAL TIM PC BAS
   MONTEPARE JM, 1987, J NONVERBAL BEHAV, V11, P33, DOI 10.1007/BF00999605
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Poole S., 2000, TRIGGER HAPPY VIDEOG
   Reif J., 1995, INT WORKSHOP ALGORIT, P431
   Reynolds C. W., 1999, P GAM DEV C, P763
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Russell S., 1995, Prentice Hall series in artificial intelligence, V25, P27
   *TRANSP ASS CAN, 2002, MAN UN TRAFF CONTR D
   *US DEP TRANSP, 2003, US FHWA MAN UN TRAFF
NR 22
TC 7
Z9 8
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 283
EP 293
DI 10.1002/cav.242
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200012
DA 2024-07-18
ER

PT J
AU Yu, JH
   Liao, J
   Patterson, J
AF Yu, Jinhui
   Liao, Jing
   Patterson, John
TI Modeling the interaction between objects and cartoon water
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE cartoon animation; effects; water; model
AB In this paper, we describe a method for modeling the interaction between objects and the cartoon water which does not involve physics simulations. Our method involves the definition of flow path lines in the presence of obstacles, modeling of different types of water forms, and combinations of them in space and tune. There are several notable features with our method: easy setting with little user intervention, modeling of complex water forms that represent more energetic water behavior than has been encompassed by semi-automatic means so far, and the adaptive change of animated Water forms to the variation of obstacle object in number, size, and shape in the water path. A number of formulae for managing shape and time variance in these animations are given. We tested our method with both still and moving objects that have different shape and size in the Water and relevant examples are given in the paper. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Yu, Jinhui] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Liao, J (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
EM liaojing@cad.zju.edu.cn
OI LIAO, Jing/0000-0001-7014-5377
CR Adabala N, 2002, COMPUT GRAPH FORUM, V21, P65, DOI 10.1111/1467-8659.00566
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   CHENNEY S, 2004, P 3 INT S NON PHOT A, P57
   DIFIORE F, 2004, P COMP AN SOC AG CAS, P171
   Eden Ashley M., 2007, Proceedings Graphics Interface 2007, P51, DOI 10.1145/1268517.1268528
   FEIN A, 2006, P 4 INT S NON PHOT A, P21
   HARTNETT C, 2004, SIGGRAPH, P171
   He HT, 2005, COMPUT ANIMAT VIRT W, V16, P441, DOI 10.1002/cav.103
   Iglesias A, 2004, FUTURE GENER COMP SY, V20, P1355, DOI 10.1016/j.future.2004.05.026
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   THORNTON JD, 2006, SKETCHES APPL SIGGRA
   WHITTAKER H, 1981, TIMING ANIMATION
   YU JH, 1996, P COMP AN SIM, P49
   Yu JH, 2007, COMPUT ANIMAT VIRT W, V18, P405, DOI 10.1002/cav.207
NR 14
TC 2
Z9 4
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 375
EP 385
DI 10.1002/cav.239
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200020
DA 2024-07-18
ER

PT J
AU Yu, J
   Zhuang, YT
   Xiao, J
   Chen, C
AF Yu, Jun
   Zhuang, Yueting
   Xiao, Jun
   Chen, Cheng
TI Adaptive control in cartoon data reusing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE reusing; animation; image processing; computer vision; machine learning;
   fusion
ID MOTION
AB In this paper, we propose a novel approach, which reuses Traditional Chinese Cartoon to create new animations. In order to extract the cartoon character precisely, a segmentation method based on edge detection is implemented. Before reusing the data, a lower-dimensional space of the cartoon data is constructed by ISOmap. The character's gesture difference calculated by optical flow is combined with character's edge difference through a novel distance function, which is controlled by a weight parameter. The animation is created by reordering the existing data into a sequence, which is the shortest path between two designated data in the space. Our approach utilizes image processing, computer vision, and machine learning in cartoon creation and the experiment results demonstrate that the animation's quality can be effectively improved by the fusion of these techniques. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Yu, J (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
EM yujun116@yahoo.com.cn
CR [Anonymous], P S COMP AN
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 1995, P 22 ANN C COMP GRAP, DOI DOI 10.1145/218380.218417
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P2071, DOI 10.1109/83.887975
   Correa W.T., 1998, INT C COMPUTER GRAPH, P435
   Galvin B., 1998, PROC 9 BRIT MACHINE, V1, P195
   Gleicher M, 1999, COMPUT GRAPHICS-US, V33, P51, DOI 10.1145/345370.345409
   HAEVRE WV, 2005, P INT C COMP GRAPH I, P24
   He XC, 2004, INT C PATT RECOG, P791, DOI 10.1109/ICPR.2004.1334377
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   JUAN CD, 2006, P EUR ASM SIGGRAPH S, P223
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Park MJ, 2004, COMPUT ANIMAT VIRT W, V15, P245, DOI 10.1002/cav.27
   Petrovic L, 2000, COMP GRAPH, P511, DOI 10.1145/344779.345073
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
NR 19
TC 8
Z9 9
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 571
EP 582
DI 10.1002/cav.189
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000035
DA 2024-07-18
ER

PT J
AU Green, M
   Lee, WL
AF Green, Mark
   Lee, Wai Leng
TI Automatic design and layout of 3D user interfaces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Virtual Reality Continuum and Its
   Applications (VRCIA)
CY 2006
CL Hong Kong, PEOPLES R CHINA
SP ACM SIGGRAPH, Eurgograph Assoc, Chinese Soc Image & Graph, INI GraphicsNet
DE 3D user interfaces; user interface layout techniques; virtual reality;
   user interface construction
AB The production of 3D user interfaces is complicated by the wide range of input and output devices used in 3D applications and the lack of software tools for their production. A 3D user interface that works well with one particular set of input and output devices could fail when another set of devices is used. To solve this problem the Grappl system automatically generates 3D user interfaces at run time. This paper presents the programmer interface to Grappl and some of the techniques used in its implementation. An important part of this process is placing user interface and application objects in 3D space. This is achieved by using policy techniques to automate the layout process. This paper presents some of the features and techniques that have been used in policy implementation, including relative position policy and grouping policy, with a few example applications. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Univ Ontario, Inst Technol, Oshawa, ON, Canada.
C3 Ontario Tech University
RP Green, M (corresponding author), Univ Ontario, Inst Technol, Oshawa, ON, Canada.
EM Mark.Green@uoit.ca
RI Lee, Wai-Leng/F-5895-2014
OI Lee, Wai-Leng/0000-0002-0036-2859
CR Barrilleaux J., 2001, 3D USER INTERFACES J, V1st
   BELL B, 2001, ACM S US INT SOFTW T, P101
   BELL B, 2000, ACM P UIST 00 SAN DI, P239
   BOWAN DA, 2005, 3D USER INTERFACES T
   ECKSTEIN R, 1998, JAWA SWING
   GREEN M, 1986, ACM T GRAPHIC, V5, P244, DOI 10.1145/24054.24057
   GREEN M, 2004, P ICAT, P548
   GREEN M, 2004, GRAPPL 3D INTERACTIO, P16
   JACOB RJK, 1999, T COMPUTER HUMAN INT, V6, P1
   Lee Wai Leng, 2005, P ACM S VIRTUAL REAL, P96
   MCCORMACK J, 1985, X TOOLKIT INTRINSICS
   *OMNET, OMNET DISC EV SIM SY
   Ousterhout J.K., 1994, TCL TK TOOLKIT
   SHAW C, 1993, ACM T INFORM SYST, V11, P287, DOI 10.1145/159161.173948
   SINGH G, 1991, ACM T GRAPHIC, V10, P213, DOI 10.1145/108541.108543
   STEVANOVIC MM, 1994, ADV CERAMICS GLASS S, P59
   Szekely P., 1996, RETROSPECTIVE CHALLE, P1
   ZELEZNIK R, 1993, ACM COMPUTER GRAPHIC, P81
NR 18
TC 0
Z9 0
U1 1
U2 5
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2007
VL 18
IS 3
BP 211
EP 224
DI 10.1002/cav.174
PG 14
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 185HG
UT WOS:000247701400006
OA Bronze
DA 2024-07-18
ER

PT J
AU Fan, ZW
   Jin, XG
   Feng, JQ
   Sun, HQ
AF Fan, ZW
   Jin, XG
   Feng, JQ
   Sun, HQ
TI Mesh morphing using polycube-based cross-parameterization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE mesh morphing; cross-parameterization; polycube maps; texture transfer
AB In this paper, we propose a novel mesh morphing approach based on polycubic cross-parameterization. We compose parameterizations over the surfaces of the polycubes whose shape is similar to that of the given meshes. Because the polycubes capture the large-scale features, we can easily preserve the shape of the models, mapping legs to legs, head to head, and so on. For the finer features that are not reflected by the shape of the polycubes, we split the polycubes into matching patches and optimize them to get a low-distortion bijection that satisfies user-prescribed constraints. Our approach works well for meshes with arbitrary genus as long as the polycubes capture this feature and transfers texture seamlessly. We can also build maps with singularities between models with different genus. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM jin@cad.zju.edu.cn
CR Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575
   Alexa M, 2000, VISUAL COMPUT, V16, P26, DOI 10.1007/PL00007211
   Biermann H, 2002, ACM T GRAPHIC, V21, P312, DOI 10.1145/566570.566583
   Breen DE, 2001, IEEE T VIS COMPUT GR, V7, P173, DOI 10.1109/2945.928169
   Cohen-Or D, 1998, ACM T GRAPHIC, V17, P116, DOI 10.1145/274363.274366
   Degener P., 2003, P 12 INT MESH ROUNDT, P201
   DESBRUN M, 2002, COMPUT GRAPH FORUM, V17, P167
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Gotsman C, 2003, ACM T GRAPHIC, V22, P358, DOI 10.1145/882262.882276
   Guskov I, 2000, COMP GRAPH, P95, DOI 10.1145/344779.344831
   Khodakovsky A, 2003, ACM T GRAPHIC, V22, P350, DOI 10.1145/882262.882275
   Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811
   Kraevoy V, 2003, ACM T GRAPHIC, V22, P326, DOI 10.1145/882262.882271
   Lee AWF, 1999, COMP GRAPH, P343, DOI 10.1145/311535.311586
   LERIOS A, 1995, P ACM SIGGRAPH 1995, P6
   Lévy B, 2001, COMP GRAPH, P417, DOI 10.1145/383259.383308
   Michikawa T, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P60, DOI 10.1109/PCCGA.2001.962858
   Praun E, 2001, COMP GRAPH, P179, DOI 10.1145/383259.383277
   Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274
   Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307
   Schreiner J, 2004, ACM T GRAPHIC, V23, P870, DOI 10.1145/1015706.1015812
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tarini M, 2004, ACM T GRAPHIC, V23, P853, DOI 10.1145/1015706.1015810
NR 23
TC 12
Z9 20
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 499
EP 508
DI 10.1002/cav.92
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000032
DA 2024-07-18
ER

PT J
AU Strassner, J
   Langer, M
AF Strassner, J
   Langer, M
TI Virtual humans with personalized perception and dynamic levels of
   knowledge
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE virtual humans; perception; memory
ID SYNTHETIC VISION; MEMORY
AB Not everything is perceived as it is provided by the environment. Depending on focus and attention perception can vary and therefore also the knowledge about the world. Virtual humans are sensing the virtual world, storing knowledge and using it to perform tasks. This paper describes our approach to model perceiving, storing and forgetting knowledge as the main regulation of tasks. We use different forms and levels of knowledge which can be independently adapted to different personalities and situations by combining computer graphics methods with psychological models. Copyright (c) 2005 John Wiley & Sons, Ltd.
RP Rhonstr 7, D-64354 Reinheim, Germany.
EM johannes.strassner@gmail.com
CR [Anonymous], 1968, PSYCHOL LEARN MOTIVA
   BORDEUX C, 1999, COMPUT GRAPH FORUM, V18, P23
   CAVAZZA M, 2002, INTERACTIVE STORYTEL
   Chopra-Khullar S., 1999, Proceedings of the Third International Conference on Autonomous Agents, P16, DOI 10.1145/301136.301152
   Doyle Patrick., 2002, Proceedings of the first international joint conference on Autonomous agents and multiagent systems: part 1, P342
   Gibson J., 1979, The ecological approach to visual perception
   Goldstein E.B., 2002, Sensation and perception, V6ieme
   HILL JR, 1999, 8 C COMP GEN FORC BE
   KUFFNER JJ, 1999, P CA 99 IEEE INT C C
   Levesque HJ, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1139
   NOSER H, 1995, COMPUT GRAPH, V19, P7, DOI 10.1016/0097-8493(94)00117-H
   O'Sullivan C, 2002, COMPUT GRAPH FORUM, V21, P733, DOI 10.1111/1467-8659.00631
   Peters C, 2002, COMPUT GRAPH FORUM, V21, P743, DOI 10.1111/1467-8659.00632
   Rickel J, 2002, IEEE INTELL SYST, V17, P32, DOI 10.1109/MIS.2002.1024750
   RIEGER C, 1976, ARTIF INTELL, V7, P89, DOI 10.1016/0004-3702(76)90001-1
   Sloman A., 1997, Creating Personalities for Synthetic Actors. Towards Autonomous Personality Agents, P166, DOI 10.1007/BFb0030576
   Torres D., 2003, P ACM S VIRT REAL SO, P91
NR 17
TC 7
Z9 7
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 331
EP 342
DI 10.1002/cav.96
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000018
DA 2024-07-18
ER

PT J
AU King, SA
   Parent, RE
AF King, SA
   Parent, RE
TI Animating song
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE facial animation; lip synchronization
AB We describe techniques used to create animations of song. Modifications to a text-to-audiovisual-speech system have been made to take the extra information of timing and frequency of the lyrics from a MIDI file. Lip-synchronized animations of song are then produced. We discuss differences between the production of speech and the production of song. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Otago, Dept Comp Sci, Dunedin, New Zealand.
C3 University of Otago
RP Univ Otago, Dept Comp Sci, POB 56, Dunedin, New Zealand.
EM ScottKing@ACM.org
OI King, Scott/0000-0002-4022-0388
CR [Anonymous], 1987, From text to speech: The MITalk system
   Black A.W., 1999, The Festival Speech Synthesis System: system documentation
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   DEGRAF B, 1989, SIGGRAPH 89 COURSE N, P8
   Ezzat T, 1998, COMP ANIM CONF PROC, P96, DOI 10.1109/CA.1998.681913
   EZZAT T, 1997, P ESCA WORKSH AUD SP, P141
   FLINGER, 2001, FESTIVAL SINGER
   FROMKIN V, 1964, LANG SPEECH, V7, P215, DOI 10.1177/002383096400700402
   King SA, 2001, INT FED INFO PROC, V68, P12
   King SA, 2001, J VISUAL COMP ANIMAT, V12, P107, DOI 10.1002/vis.249
   KING SA, 2001, THESIS OHIO STATE U
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   LEWIS PJ, 1987, P HUM FACT COMP SYST, P143
   LOOFQVIST A, 1990, SPEECH PRODUCTION SP, P289
   *LUC TECHN, 2001, BELL LABS TEXT SPEEC
   MACON M, 2001, LYRICOS
   MADSEN RP, 1969, ANIMATED FILM CONCEP
   MORISHIMA S, 1990, SPIE VISUAL COMMUNIC, V1360, P1151
   Nahas M., 1988, Visual Computer, V3, P272, DOI 10.1007/BF01914862
   NTICHIE EB, 1930, LIP READING PRINCIPL
   PARKE FI, 1975, COMPUTERS GRAPHICS J, V1, P1
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   PATTERSON EC, 1991, COMPUTER ANIMATION 9
   Pearce A., 1986, Proceedings of Graphics Interface '86 and Vision Interface '86, P136
   PELACHAUD C, 1993, IJCAI-93, VOLS 1 AND 2, P1610
   PELACHAUD C, 1991, THESIS U PENNSYLVANI
   PROVINE JA, 1995, IEEE INT SYMP CIRC S, P453, DOI 10.1109/ISCAS.1995.521548
   SAULNIER A, 1995, INT WORKSH AUT FAC G
   SIMONS AD, 1990, P I AC AUT C, V12, P483
   Sturman DJ, 1998, IEEE COMPUT GRAPH, V18, P38, DOI 10.1109/38.637269
   WALTHER EF, 1982, LIPREADING
   WATERS K, 1993, 934 CRL DIG EQ CORP
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
NR 34
TC 1
Z9 2
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2004
VL 15
IS 1
BP 53
EP 61
DI 10.1002/cav.7
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 832EF
UT WOS:000222249300006
DA 2024-07-18
ER

PT J
AU Bao, XY
   Bian, YL
   Qi, M
   Liu, R
   Gai, W
   Liu, J
   Luan, HQ
   Yang, CL
   Wang, Y
AF Bao, Xiyu
   Bian, Yulong
   Qi, Meng
   Liu, Ran
   Gai, Wei
   Liu, Juan
   Luan, Hongqiu
   Yang, Chenglei
   Wang, Yu
TI A toolkit for automatically generating and modifying VR hierarchy tile
   menus
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE tile menu; toolkit; user interface; virtual reality/augmented reality
ID SYSTEM
AB Current VR/AR system development studios lack a toolkit that can automatically generate hierarchical tile menu layouts and menu prototypes for VR/AR devices without the need for user programming. This paper proposes a solution in the form of a toolkit that automatically generates a hierarchy tile menu layout using a modified circular treemap algorithm. Users can interactively arrange and resize tiles to create various layouts according to their preferences or needs, utilizing a circle packer method. The toolkit further automatically generates a VR/AR menu prototype based on the resulting layout. Notably, reprogramming is not necessary each time the hierarchy is modified or the menu layout is redesigned. The user test results demonstrate that the proposed toolkit simplifies the creation of hierarchical tile menu layouts, enhances user efficiency in the design process, and enables users to flexibly create hierarchical tile menu prototypes according to their design ideas.
C1 [Bao, Xiyu; Gai, Wei; Luan, Hongqiu; Yang, Chenglei; Wang, Yu] Shandong Univ, Sch Software, Jinan, Shandong, Peoples R China.
   [Bian, Yulong; Liu, Juan] Shandong Univ, Sch Mechatron & Informat Engn, Jinan, Shandong, Peoples R China.
   [Qi, Meng] Shandong Normal Univ, Jinan, Shandong, Peoples R China.
C3 Shandong University; Shandong University; Shandong Normal University
RP Gai, W; Yang, CL (corresponding author), Shandong Univ, Sch Software, Jinan, Shandong, Peoples R China.
EM gw@sdu.edu.com; chl_yang@sdu.edu.com
OI bao, xiyu/0009-0002-5847-0876
FU This work is supported by National Key Ramp;D Program of China
   (2022ZD0118002), and the National Natural Science Foundation of China
   under Grant (61972233, 62007021, 62277035). [2022ZD0118002]; National
   Key Ramp;D Program of China [61972233, 62007021, 62277035]; National
   Natural Science Foundation of China
FX This work is supported by National Key R&D Program of China
   (2022ZD0118002), and the National Natural Science Foundation of China
   under Grant (61972233, 62007021, 62277035).
CR Akkersdijk SM., 2011, IMAGEPILE ALTERNATIV
   [Anonymous], 2004, Designing the User Interface: Strategies for Eff ective Human-Computer Interaction
   [Anonymous], 2005, Proceedings of the SIGCHI conference on Human factors in computing systems
   [Anonymous], 2022, LIV TIL AN
   Auber D, 2013, IEEE T VIS COMPUT GR, V19, P1820, DOI 10.1109/TVCG.2013.91
   Belkacem I., 2016, SMART GLASSES SEMANT, P1405
   Bly S., 1986, Proceedings of CHI'86, P101
   Bowman D., 2001, USING PINCH GLOVES T
   Bowman DA, 2001, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2001.913781
   BRYSON S, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P20, DOI 10.1109/VRAIS.1993.380803
   Butz A., 2004, TUISTER TANGIBLE UI, P223
   COHEN ES, 1986, IEEE COMPUT GRAPH, V6, P35, DOI 10.1109/MCG.1986.276790
   Dachselt R, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P79, DOI 10.1109/INFVIS.2001.963284
   Dachselt R, 2007, COMPUT GRAPH-UK, V31, P53, DOI 10.1016/j.cag.2006.09.006
   Dayama NR., 2020, GRIDS INTERACTIVE LA, P1, DOI [10.1145/3313831.3376553, DOI 10.1145/3313831.3376553]
   Deering M.F., 1995, ACM Trans. Comput.-Hum. Interact., V2, P220
   Dunk A, 2009, LECT NOTES COMPUT SC, V5545, P746, DOI 10.1007/978-3-642-01973-9_83
   Fekete JD, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P167, DOI 10.1109/INFVIS.2004.64
   Gerber D, 2005, P IEEE VIRT REAL ANN, P271
   HART SM, 1995, APPL MATH MODEL, V19, P244, DOI 10.1016/0307-904X(94)00033-3
   Horn MS, 2009, 2009 6TH INTERNATIONAL SYMPOSIUM ON VORONOI DIAGRAMS (ISVD 2009), P265, DOI 10.1109/ISVD.2009.22
   Hou S., 2021, VRMENUDESIGNER TOOLK, P154
   Kacem I., 2021, ALGORITHMS VARIABLE, P1
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Mario G., CIRCLEPACKER
   Niyazov A., 2021, PROCE ACM HUMAN COMP, V5, P1
   Piekarski W., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P19, DOI 10.1145/769953.769956
   Riemann J., 2018, PROC ACM INTERACT MO, V2, P1
   Rios-Berrios M, 2012, GOV INFORM Q, V29, P212, DOI 10.1016/j.giq.2011.07.004
   ROBERTSON G.G., 1991, CHI 91, P189, DOI DOI 10.1145/108844.108883
   Robertson GG., 1993, DOCUMENT LENS, P101
   Scheibel W., 2020, SURVEY TREEMAP LAYOU, P1
   Scheibel W., 2018, P 13 INT JOINT C COM, P273, DOI DOI 10.5220/0006617102730280
   Scheibel W, 2020, IVAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 3: IVAPP, P273, DOI 10.5220/0009153902730280
   Wang C.Y., 2015, MOBILEHCI 2015 P 17, P153, DOI DOI 10.1145/2785830.27858862
   Wattenberg M, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P181, DOI 10.1109/INFVIS.2005.1532145
   Wettel R, 2007, 4TH IEEE INTERNATIONAL WORKSHOP ON VISUALIZING SOFTWARE FOR UNDERSTANDING AND ANALYSIS, PROCEEDINGS, P92, DOI 10.1109/VISSOF.2007.4290706
   Xiao S, 2018, PROCEDIA COMPUT SCI, V129, P103, DOI 10.1016/j.procs.2018.03.056
   Zhao HS, 2015, IEEE PAC VIS SYMP, P81, DOI 10.1109/PACIFICVIS.2015.7156360
NR 39
TC 0
Z9 0
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2208
EA OCT 2023
PG 25
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001076171400001
DA 2024-07-18
ER

PT J
AU Takahashi, H
   Kanamori, Y
   Endo, Y
AF Takahashi, Haruka
   Kanamori, Yoshihiro
   Endo, Yuki
TI 3D terrain estimation from a single landscape image
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D reconstruction; deep learning; terrain
AB This article presents the first technique to estimate a 3D terrain model from a single landscape image. Although monocular depth estimation also offers single-image 3D reconstruction, it assigns depth only to pixels visible in the input image, resulting in an incomplete 3D terrain output. Our method generates a complete 3D terrain model as a textured height map via a three-stage framework using deep neural networks. First, to exploit the performance of pixel-aligned estimation, we estimate terrain's per-pixel depth and color free from shadows or lights in the perspective view. Second, we triangulate the RGB-D data generated in the first stage and rasterize the triangular mesh from the top view to obtain an incomplete textured height map. Finally, we inpaint the depth and color in the missing regions. Because there are many possible ways to complete the missing regions, we synthesize diverse shapes and textures during inpainting using a variational autoencoder. Qualitative and quantitative experiments reveal that our method outperforms existing methods applying a direct perspective-to-top view transform as image-to-image translation.
C1 [Takahashi, Haruka; Kanamori, Yoshihiro; Endo, Yuki] Univ Tsukuba, Grad Sch Sci & Technol, Tennoudai 1-1-1, Tsukuba, Ibaraki 3058573, Japan.
C3 University of Tsukuba
RP Kanamori, Y (corresponding author), Univ Tsukuba, Grad Sch Sci & Technol, Tennoudai 1-1-1, Tsukuba, Ibaraki 3058573, Japan.
EM kanamori@cs.tsukuba.ac.jp
FU Grants-in-Aid for Scientific Research [22H03606] Funding Source: KAKEN
CR [Anonymous], 2014, Proceedings of Graphics Interface
   Argudo O, 2018, COMPUT GRAPH FORUM, V37, P101, DOI 10.1111/cgf.13345
   Bhat SF., ADABINS DEPTH ESTIMA
   Chen XT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P694
   Guérin E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130804
   Kingma D.P., 2014, P C P PAP ACC 2 INT, P2014
   Kristof P, 2009, COMPUT GRAPH FORUM, V28, P219, DOI 10.1111/j.1467-8659.2009.01361.x
   LEWIS JP, 1987, ACM T GRAPHIC, V6, P167, DOI 10.1145/35068.35069
   Miller G. S. P., 1986, Computer Graphics, V20, P39, DOI 10.1145/15886.15890
   Musgrave F. K., 1989, Computer Graphics, V23, P41, DOI 10.1145/74334.74337
   Neidhold B., 2005, Natural Phenomena, P25
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Ramamonjisoa M, 2019, IEEE INT CONF COMP V, P2109, DOI 10.1109/ICCVW.2019.00266
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Regmi K, 2018, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2018.00369
   Roudier P., 1993, Computer Graphics Forum, V12, P375, DOI 10.1111/1467-8659.1230375
   Tang H, 2019, PROC CVPR IEEE, P2412, DOI 10.1109/CVPR.2019.00252
   Wu Y, 2020, PSYCHOL MED, V50, P1368, DOI [10.1017/S0033291719001314, 10.1145/3290605.3300666]
   Xie YH, 2022, COMPUT GRAPH FORUM, V41, P641, DOI 10.1111/cgf.14505
   Yin W., 2019, P IEEE C COMPUTER VI
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao YW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356553
   Zhou H, 2007, IEEE T VIS COMPUT GR, V13, P834, DOI 10.1109/TVCG.2007.1027
NR 23
TC 1
Z9 1
U1 2
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2022
VL 33
IS 6
AR e2119
DI 10.1002/cav.2119
EA SEP 2022
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6Z9LE
UT WOS:000849519900001
DA 2024-07-18
ER

PT J
AU Qin, WH
   Tao, R
   Sun, LB
   Dong, KY
AF Qin, Wenhu
   Tao, Ran
   Sun, Libo
   Dong, Kaiyue
TI Muscle-driven virtual human motion generation approach based on deep
   reinforcement learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE curriculum learning; deep reinforcement learning; motion generation;
   musculoskeletal model
ID SIMULATIONS
AB We propose a muscle-driven motion generation approach to realize virtual human motion with user interaction and higher fidelity, which can address the problem that the joint-driven fails to reflect the motion process of the human body. First, a simplified virtual human musculoskeletal model is built based on human biomechanics. Then, a hierarchical policy learning framework is constructed including motion tracking layer, SPD controller and muscle control layer. The motion tracking layer is responsible for mimicking reference motion and completing control command, using proximal policy optimization to train the policy; the muscle control layer is aimed to minimize muscle energy consumption and train the policy based on supervised learning; the SPD controller acts as a link between the two layers. At the same time, we integrate the curriculum learning to improve the efficiency and success rate of policy training. Simulation experiments show that the proposed approach can use motion capture data and pose estimation data as reference motions to generate better and more adaptable motions. Furthermore, the virtual human has the ability to respond to the user control command during the motion, and can complete the target task successfully.
C1 [Qin, Wenhu; Tao, Ran; Sun, Libo; Dong, Kaiyue] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Qin, WH; Sun, LB (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
EM qinwenhu@seu.edu.cn; sunlibo@seu.edu.cn
OI dong, kaiyue/0000-0003-1407-5591
FU Key R&D Program of Jiangsu Province [BE2019311]; Jiangsu Modern
   Agricultural Industry Key Technology Innovation Project [CX(20)2013];
   National Key Research and Development Program [2020YFB160070301]
FX This work was supported by the Key R&D Program of Jiangsu Province under
   Grant BE2019311, Jiangsu Modern Agricultural Industry Key Technology
   Innovation Project under Grant CX(20)2013, and National Key Research and
   Development Program under Grant 2020YFB160070301.
CR Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   de Vree L, 2021, IEEE T NEUR SYS REH, V29, P607, DOI 10.1109/TNSRE.2021.3063015
   Delp SL, 2007, IEEE T BIO-MED ENG, V54, P1940, DOI 10.1109/TBME.2007.901024
   Haeufle DFB, 2014, J BIOMECH, V47, P1531, DOI 10.1016/j.jbiomech.2014.02.009
   HILL AV, 1953, PROC R SOC SER B-BIO, V141, P104, DOI 10.1098/rspb.1953.0027
   Lee J., 2018, J OPEN SOURCE SOFTWA, V3, P500, DOI DOI 10.21105/JOSS.00500
   Lee S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322972
   Lencioni T, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0323-z
   Liu LB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083723
   Liu LB, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2893476
   Peng XB, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3197517.3201311, 10.1145/3450626.3459670]
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Ruiz AL, 2017, COMPUT GRAPH FORUM, V36, P122, DOI 10.1111/cgf.12863
   Schulman J., 2017, ARXIV
   Tan J, 2011, IEEE COMPUT GRAPH, V31, P34, DOI 10.1109/MCG.2011.30
   Weng JC, 2021, IEEE ROBOT AUTOM LET, V6, P4156, DOI 10.1109/LRA.2021.3067617
   Xu HH, 2021, PLATELETS, V32, P950, DOI 10.1080/09537104.2020.1810221
   Xue Bin Peng, 2021, ACM Transactions on Graphics, V40, DOI 10.1145/3476576.3476723
   Yin ZQ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459817
NR 19
TC 5
Z9 5
U1 2
U2 32
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2092
DI 10.1002/cav.2092
EA JUN 2022
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000812000500001
DA 2024-07-18
ER

PT J
AU Noah, N
   Das, S
AF Noah, Naheem
   Das, Sanchari
TI Exploring evolution of augmented and virtual reality education space in
   2020 through systematic literature review
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Review
DE augmented reality; literature review; online education; virtual reality
AB Research is increasingly being conducted to identify the benefits provided by the latest developments in the AR/VR domain, which has seen an increase in interest as a result of the stay-at-home phenomena in 2020. Of particular interest is the application of AR/VR to education, a discipline that has seen a rapid shift to online modules in 2020. To better understand the advancements in AR/VR enabled education, we conducted a systematic literature review consisting of N=61 papers published in the year 2020 that focused on AR/VR in the education sector. We particularly focused on papers where studies have evaluated user perceptions in different countries, academic fields, and at varied educational levels. We found that while most papers conducted user studies and evaluated the technical applications of AR/VR, user perceptions, impact, and awareness were not explored in detail. Our findings highlight trends that can drive critically needed innovations through AR/VR especially to help a globalized digital evolution in the education sector.
C1 [Noah, Naheem] Africa Prudential, Lagos, Nigeria.
   [Das, Sanchari] Univ Denver, Dept Comp Sci, Denver, CO USA.
C3 University of Denver
RP Noah, N (corresponding author), Africa Prudential, Lagos, Nigeria.
EM noahnaheem@gmail.com
OI Das, Sanchari/0000-0003-1299-7867
CR Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Al-Amri A, 2020, INT J EMERG TECHNOL, V15, P4, DOI 10.3991/ijet.v15i05.11890
   Altmeyer K, 2020, BRIT J EDUC TECHNOL, V51, P611, DOI 10.1111/bjet.12900
   Bishop G., 1992, ACM SIGGRAPH Computer Graphics, V26, P153, DOI DOI 10.1145/142413.142416
   Chang SC, 2020, BRIT J EDUC TECHNOL, V51, P148, DOI 10.1111/bjet.12790
   Chen CH, 2020, BRIT J EDUC TECHNOL, V51, P657, DOI 10.1111/bjet.12902
   Chen CH, 2020, J COMPUT ASSIST LEAR, V36, P1052, DOI 10.1111/jcal.12469
   Chen JC, 2020, J COMPUT ASSIST LEAR, V36, P46, DOI 10.1111/jcal.12389
   Chen P, 2017, LECT N EDUC TECHNOL, P13, DOI 10.1007/978-981-10-2419-1_2
   Das Sanchari, 2019, P 13 INT S HUM ASP I
   Das Souvik, 2019, 13 INT S HUMAN ASPEC
   Duezguen R., 2020, ARXIV PREPRINT ARXIV
   Ferrari V, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/9321535
   Francis ER, 2020, J SURG EDUC, V77, P947, DOI 10.1016/j.jsurg.2020.02.013
   Garzón J, 2019, VIRTUAL REAL-LONDON, V23, P447, DOI 10.1007/s10055-019-00379-9
   Gigante MA, 1993, VIRTUAL REALITY SYST, P3, DOI [10.1016/B978-0-12-227748-1.50009-3, DOI 10.1016/B978-0-12-227748-1.50009-3]
   Glass G. V., 1976, ED RES, V5, P3, DOI [DOI 10.3102/0013189X005010003, 10.2307/1174772ISSN0536-1036, 10.3102/0013189x005010003]
   Huang XL, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P46, DOI 10.23919/iLRN47897.2020.9155159
   Ibili E, 2020, INT J MATH EDUC SCI, V51, P224, DOI 10.1080/0020739X.2019.1583382
   Johnson-Glenberg MC., 2020, IMMERS LEARN RES NET
   Joshi S, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3418029
   Kandi VR, 2020, J ARCHIT ENG, V26, DOI 10.1061/(ASCE)AE.1943-5568.0000434
   Makransky G, 2021, J EDUC PSYCHOL, V113, P719, DOI 10.1037/edu0000473
   McNeal KS, 2020, J GEOGR HIGHER EDUC, V44, P85, DOI 10.1080/03098265.2019.1694875
   Morris SB, 2008, ORGAN RES METHODS, V11, P364, DOI 10.1177/1094428106291059
   Netland TH, 2020, J MANAG EDUC, V44, P313, DOI 10.1177/1052562919892028
   Ostrander JK, 2020, J MECH DESIGN, V142, DOI 10.1115/1.4044006
   Pittman C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P761, DOI [10.1109/VRW50115.2020.00-44, 10.1109/VRW50115.2020.00231]
   Sawilowsky SS, 2009, J MOD APPL STAT METH, V8, P597, DOI 10.22237/jmasm/1257035100
   Stowell E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173589
   Sukhmani S, 2019, IEEE MULTIMEDIA, V26, P21, DOI 10.1109/MMUL.2018.2879591
   Yuen S.C.Y., 2011, J. Educ. Technol. Dev. Exch. (JETDE), V4, P11, DOI [10.18785/jetde.0401.10, DOI 10.18785/JETDE.0401.10]
NR 32
TC 11
Z9 12
U1 5
U2 70
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2020
DI 10.1002/cav.2020
EA JUN 2021
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA TH1NG
UT WOS:000661876700001
DA 2024-07-18
ER

PT J
AU Zhuo, L
   Liu, Z
   Liu, TT
   Hung, CC
   Chai, YJ
AF Zhuo, Lin
   Liu, Zhen
   Liu, Tingting
   Hung, Chih-Chieh
   Chai, Yanjie
TI Modeling crowd emotion from emergent event video
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; differential evolution; emotion; emotion contagion;
   parameter optimization
ID EVACUATION; PERCEPTION; SIMULATION; CONTAGION
AB In emergency situation, mass panic often causes more causalities than the disaster itself. The crowd emotional model could be used to simulate how crowd behavior in emergency scenarios and be helpful for developing crowd evacuation plans in emergency situations. However, existing crowd emotional models usually set model parameters in an empirical manner and are not validated by real cases. In this paper, a crowd emotional model is proposed to simulate the crowd movement in outdoor emergency situations. First of all, the crowd entropy and the movement difference are proposed to describe the emotional impact of the crowd scene on the agents. The perception of vision and hearing are considered, and the calculation formulas of the agent's emotional intensity and crowd emotional contagion are proposed. By calculating individual trajectories in the real video, the cumulative differences between the movements of the real crowd and the corresponding virtual crowd are analyzed. At last, a multi-parameter optimization method is implemented by the differential evolution algorithm. To verify the parameters in models, three videos which are generated from three real cases, including explosion attack, shooting incident, and crowd disturbance are selected for experimental verification. The results showed that the proposed model could be a feasible method for optimizing parameters to simulate the emergency scenario.
C1 [Zhuo, Lin; Liu, Zhen; Chai, Yanjie] Ningbo Univ, Fac Informat Sci & Technol, Ningbo 315211, Peoples R China.
   [Liu, Tingting] Ningbo Univ, Coll Sci & Technol, Cixi, Peoples R China.
   [Hung, Chih-Chieh] Natl Chung Hsing Univ, Taichung, Taiwan.
C3 Ningbo University; Ningbo University; National Chung Hsing University
RP Zhuo, L (corresponding author), Ningbo Univ, Fac Informat Sci & Technol, Ningbo 315211, Peoples R China.
RI Hung, Chih-Chieh/AAA-1158-2019; liu, zhen/AHE-0113-2022
OI Hung, Chih-Chieh/0000-0002-6972-6577; liu, tingting/0000-0002-3469-275X
FU National Natural Science Foundation of China [61761166005]; Ministry of
   Science and Technology, Taiwan [MOST 106-2218-E-032-003-MY3]; National
   Natural Science Foundation of Zhejiang [LY20F020007]; Ningbo Science
   Technology Plan projects [2019B10032]; K.C. Wong Magna Fund in Ningbo
   University
FX This work was sponsored by the National Natural Science Foundation of
   China (Grants 61761166005), Ministry of Science and Technology, Taiwan
   (MOST 106-2218-E-032-003-MY3) and National Natural Science Foundation of
   Zhejiang (Grant LY20F020007) and the Ningbo Science Technology Plan
   projects (Grants 2019B10032), and the K.C. Wong Magna Fund in Ningbo
   University.
CR [Anonymous], 1988, CONTEMP SOCIOL
   Basak AE, 2018, COMPUT GRAPH-UK, V72, P70, DOI 10.1016/j.cag.2018.02.004
   Bera A, 2016, IEEE COMPUT GRAPH, V36, P37, DOI 10.1109/MCG.2016.113
   Bosse T, 2013, AUTON AGENT MULTI-AG, V27, P52, DOI 10.1007/s10458-012-9201-1
   Cao MX, 2017, PHYSICA A, V483, P250, DOI 10.1016/j.physa.2017.04.137
   Charalambous P, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12472
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Festinger L, 1954, HUM RELAT, V7, P117, DOI 10.1177/001872675400700202
   Fridman N, 2010, COMPUT MATH ORGAN TH, V16, P348, DOI 10.1007/s10588-010-9082-2
   Guy SJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366209
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Jin XG, 2008, IEEE COMPUT GRAPH, V28, P37, DOI 10.1109/MCG.2008.117
   Kim S, 2016, P IEEE VIRT REAL ANN, P29, DOI 10.1109/VR.2016.7504685
   Liu BQ, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/5397071
   Liu Z, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1817
   [刘箴 Liu Zhen], 2013, [计算机研究与发展, Journal of Computer Research and Development], V50, P2578
   Mao Y, 2019, VISUAL COMPUT, V35, P1725, DOI 10.1007/s00371-018-1568-9
   Oguz O, 2010, COMPUT GRAPH-UK, V34, P136, DOI 10.1016/j.cag.2009.12.004
   Price Kenneth, 2006, NAT COMP SER, DOI 10.1007/3-540-31306-0
   Sobol IM, 2001, MATH COMPUT SIMULAT, V55, P271, DOI 10.1016/S0378-4754(00)00270-6
   Thalmann Daniel., 2013, Crowd Simulation, VSecond
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Tsai J., 2011, 10 INT C AUT AG MULT, P425
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Wei X, 2018, NEUROCOMPUTING, V310, P125, DOI 10.1016/j.neucom.2018.05.022
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu TF, 2020, PHYS LETT A, V384, DOI 10.1016/j.physleta.2019.126080
   Yao ZZ, 2019, NEUROCOMPUTING, V366, P314, DOI 10.1016/j.neucom.2019.08.021
   Zhang XG, 2019, PHYSICA A, V525, P935, DOI 10.1016/j.physa.2019.04.033
   Zhao Y, 2015, PHYSICA A, V431, P84, DOI 10.1016/j.physa.2015.02.068
   Zhuo L., 2021, CHINESE J AGR RES RE, P1
NR 32
TC 3
Z9 3
U1 4
U2 59
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2021
VL 32
IS 5
DI 10.1002/cav.1988
EA FEB 2021
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WJ5HR
UT WOS:000614701000001
DA 2024-07-18
ER

PT J
AU Yoon, JC
   Kang, H
AF Yoon, Jong-Chul
   Kang, HyeongYeop
TI Interactive learning in the classroom: A mobile augmented reality
   assistance application for learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; human-computer interaction; interactive learning;
   amartphone application
AB The rapid evolution of augmented reality (AR) technology has presented new opportunities in the domain of education. Acting as a bridge between the virtual and real worlds, AR technology overcomes the physical limitations of our classrooms at a low cost and provides an interactive learning experience. In this study, we present a smartphone AR application, named the AR-E-Helper, which assists the learning of students in higher education lectures. Our goal is to provide an AR-enhanced learning experience for students. To validate the effectiveness of the AR-E-Helper, we conducted an experiment that compares three classes: AR-enhanced, smartphone-enhanced, and nontechnology-enhanced classes. Through the experiment, we observed that our application was helpful in maintaining student's focus in class, promoting their interest, and increasing their satisfaction. Furthermore, we also found how to improve our application based on the observations that the application brought some downsides to the learning activities. We expect that this study will be helpful to design AR learning tools in the future.
C1 [Yoon, Jong-Chul] Kangwon Natl Univ Samcheok, Dept Soft & Media Engn, Samcheok, South Korea.
   [Kang, HyeongYeop] Kyung Hee Univ, Dept Software Convergence, Coll Software Convergence, Yongin, South Korea.
C3 Kangwon National University; Kyung Hee University
RP Kang, H (corresponding author), Kyung Hee Univ, Dept Software Convergence, Coll Software Convergence, Yongin, South Korea.
EM siamiz@khu.ac.kr
RI Kang, HyeongYeop/AAJ-2471-2020
OI Kang, HyeongYeop/0000-0001-5292-4342
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2019R1I1A3A01061157,
   NRF-2020R1F1A1076528]
FX This study is supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2019R1I1A3A01061157 and NRF-2020R1F1A1076528).
CR Alkhamisi A.O., 2013, International Journal of Internet and Distributed Systems, V1, P25, DOI [DOI 10.4236/IJIDS.2013.14005, 10.4236/ijids.2013.14005]
   [Anonymous], 2018, GOOGLE ARCORE GOOGLE
   [Anonymous], 2007, Journal of Science Education and Technology, DOI [DOI 10.1007/S10956-006-9037-Z, 10.1007/s10956-006-9037-z]
   Antoniou PE, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P1561, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.360
   Arvanitis TN, 2009, PERS UBIQUIT COMPUT, V13, P243, DOI 10.1007/s00779-007-0187-7
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Billinghurst M, 2012, COMPUTER, V45, P56, DOI 10.1109/MC.2012.111
   Ibáñez MB, 2014, COMPUT EDUC, V71, P1, DOI 10.1016/j.compedu.2013.09.004
   Carmigniani J, 2011, HANDBOOK OF AUGMENTED REALITY, P3, DOI 10.1007/978-1-4614-0064-6_1
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chang G., 2010, P SOC INFORM TECHNOL, P1380
   Chang KE, 2014, COMPUT EDUC, V71, P185, DOI 10.1016/j.compedu.2013.09.022
   Chen CM, 2012, COMPUT EDUC, V59, P638, DOI 10.1016/j.compedu.2012.03.001
   Chen R., 2008, Tsinghua Science Technology, V13, P13, DOI DOI 10.1016/S1007-0214(08)70120-2
   Chen SSC, 2018, IEEE INT CONF ADV LE, P367, DOI 10.1109/ICALT.2018.00092
   Cheng KH, 2013, J SCI EDUC TECHNOL, V22, P449, DOI 10.1007/s10956-012-9405-9
   Chowriappa A, 2015, BJU INT, V115, P336, DOI 10.1111/bju.12704
   Chu K., 2018, INT C ART REAL TEL E, P175
   Cooper K., 2019, P SOC INFORM TECHNOL, P2623
   da Silva Manoela M. O., 2019, Journal of the Brazilian Computer Society, V25, DOI 10.1186/s13173-019-0084-8
   Dave A, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P942, DOI [10.1109/ccwc47524.2020.9031145, 10.1109/CCWC47524.2020.9031145]
   Diegmann P., 2015, Benefits, V3, P1542
   Dunleavy M., 2014, Handbook of Research on Educational Communications and Technology, P735, DOI [DOI 10.1007/978-1-4614-3185-5_59, 10.1007/978-1-4614-3185-5_59]
   Dunleavy M, 2009, J SCI EDUC TECHNOL, V18, P7, DOI 10.1007/s10956-008-9119-1
   Dunser A., 2012, Proceedings of the 24th Australian Computer-Human Interaction Conference, P107, DOI [10.1145/2414536.2414554, DOI 10.1145/2414536.2414554]
   Iwata T, 2011, IEEE INT CONF EMBED, P105, DOI 10.1109/RTCSA.2011.43
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Juanes JA, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0495-4
   Kamarainen AM, 2013, COMPUT EDUC, V68, P545, DOI 10.1016/j.compedu.2013.02.018
   Kaufmann H, 2007, LECT NOTES COMPUT SC, V4563, P660
   Kerawalla L., 2006, Virtual Real, V10, P163, DOI [10.1007/s10055-006-0036-4, DOI 10.1007/S10055-006-0036-4]
   Klopfer E, 2008, ETR&D-EDUC TECH RES, V56, P203, DOI 10.1007/s11423-007-9037-6
   Klopfer Eric, 2010, New Dir Youth Dev, V2010, P85, DOI 10.1002/yd.378
   Leblanc F, 2010, J AM COLL SURGEONS, V211, P250, DOI 10.1016/j.jamcollsurg.2010.04.002
   Liu DF, 2015, PROCEDIA COMPUT SCI, V75, P95, DOI 10.1016/j.procs.2015.12.224
   Andújar JM, 2011, IEEE T EDUC, V54, P492, DOI 10.1109/TE.2010.2085047
   Martin-Gutierrez Jorge, 2013, 2013 IEEE Frontiers in Education Conference (FIE), P362, DOI 10.1109/FIE.2013.6684848
   Martín-Gutiérrez J, 2011, PROC FRONT EDUC CONF
   Matsutomo S, 2017, IEEE T MAGN, V53, DOI 10.1109/TMAG.2017.2665563
   Mitchell R., 2011, Journal of Computers in Mathematics and Science Teaching, V30, P271
   O'Brien H.L., 2009, P AM SOC INFORM SCI, V45, P1
   Okamoto T, 2015, DIGEST SURG, V32, P117, DOI 10.1159/000371860
   Pelargos PE, 2017, J CLIN NEUROSCI, V35, P1, DOI 10.1016/j.jocn.2016.09.002
   Potkonjak V, 2016, COMPUT EDUC, V95, P309, DOI 10.1016/j.compedu.2016.02.002
   Radu I, 2019, P 2019 CHI C HUM FAC, P1, DOI [10.1145/3290605.3300774, DOI 10.1145/3290605.3300774]
   Redondo E, 2013, PROCEDIA COMPUT SCI, V25, P52, DOI 10.1016/j.procs.2013.11.007
   Samat Charuni, 2019, Innovative Technologies and Learning. Second International Conference, ICITL 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11937), P175, DOI 10.1007/978-3-030-35343-8_19
   Shelton BE., 2002, AUGMENTED REALITY ED, V9
   Tamim RM, 2011, REV EDUC RES, V81, P4, DOI 10.3102/0034654310393361
   Tutwiler, 2012, J IMMERS ED, P14
   Unfried A, 2015, J PSYCHOEDUC ASSESS, V33, P622, DOI 10.1177/0734282915571160
   Valimont R. B., 2007, Journal of Aviation/Aerospace Education & Research., DOI [10.15394/jaaer.2007.1478, DOI 10.15394/JAAER.2007.1478]
   Wijdenes P., 2018, P 2018 CHI C HUM FAC, P1
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yoon JC, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1989
   Yuen S.C.Y., 2011, J. Educ. Technol. Dev. Exch. (JETDE), V4, P11, DOI [10.18785/jetde.0401.10, DOI 10.18785/JETDE.0401.10]
NR 57
TC 5
Z9 5
U1 5
U2 30
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2021
VL 32
IS 5
DI 10.1002/cav.1989
EA JAN 2021
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WJ5HR
UT WOS:000612687000001
DA 2024-07-18
ER

PT J
AU Grabowski, A
   Jach, K
AF Grabowski, Andrzej
   Jach, Kamil
TI The use of virtual reality in the training of professionals: with the
   example of firefighters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE firefighters; professionals; training; virtual reality
AB The article presents a brief history of the development of virtual reality (VR), followed by a comprehensive literature overview on the matter as well as an example of the application of VR in the training of professionals on the example of firefighters. The history, starting in 1965 with the ideas, concepts, and solutions presented by the VR's "forefather"-Ivan Sutherland, delves into multiple projects. The literature review presents various examples of the use of VR in the training of professionals coming from multiple fields, such as medicine, psychology, forestry, iron casting, or construction. The case study shows it can be used to recreate even the most complex scenarios and surroundings, even those of the firefight in confined spaces where enclosed fires tend to appear and have been considered vastly hazardous for not only civilians or equipment but also to firefighters dispatched to contain them.
C1 [Grabowski, Andrzej; Jach, Kamil] Cent Inst Ochrony Pracy, Panstwowy Inst Badawczy, Warsaw, Poland.
C3 Central Institute for Labour Protection - National Research Institute
RP Grabowski, A (corresponding author), Cent Inst Ochrony Pracy, Panstwowy Inst Badawczy, Warsaw, Poland.
EM angra@ciop.pl
RI Grabowski, Andrzej/AEM-7429-2022
OI Grabowski, Andrzej/0000-0002-0924-2140
FU National Center for Research and Development
FX National Center for Research and Development
CR [Anonymous], 2011, USING VIRTUAL REALIT
   Choi Ja-Young, 2015, [Journal of Institute of Control, Robotics and Systems, 제어.로봇.시스템학회 논문지], V21, P709, DOI 10.5302/J.ICROS.2015.15.0081
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Eijlers R, 2019, ANESTH ANALG, V129, P1344, DOI 10.1213/ANE.0000000000004165
   Fang Y, 2016, 16 INT C CONSTR APPL
   Fisher S, 1986, VIRTUAL ENV DISPLAY, P77
   Gerschutz B, 2019, INT C ENG DES ICED19
   Hui Z, 2017, INT J MIN SCI TECHNO, V27, P717, DOI 10.1016/j.ijmst.2017.05.005
   Lapoinmte J.-F., 2000, Education and Information Technologies, V5, P237, DOI 10.1023/A:1012045305968
   Lee H.Y., 2014, INT J MULTIMEDIA UBI, V9, P431
   Lin FH, 2002, INFORM SCIENCES, V140, P153, DOI 10.1016/S0020-0255(01)00185-2
   Lucas J, 2008, J INF TECHNOL CONSTR, V13, P637
   Mazuryk T., 2014, VIRTUAL REALITY HIST
   Oliva D., 2019, GAMIFIN C 2019, P241
   Stone R, 2001, INT J HUM-COMPUT ST, V55, P699, DOI 10.1006/ijhc.2001.0497
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Vackova M, 2018, SECUR DIMEN, V27, P126, DOI [10.5604/01.3001.0013.0294, DOI 10.5604/01.3001.0013.0294]
NR 18
TC 7
Z9 8
U1 3
U2 26
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2021
VL 32
IS 2
DI 10.1002/cav.1981
EA DEC 2020
PG 6
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RK2HP
UT WOS:000599199800001
DA 2024-07-18
ER

PT J
AU Xu, CX
   Yu, WJ
   Li, YR
   Lu, XQ
   Wang, ML
   Yang, XS
AF Xu, Chenxu
   Yu, Wenjie
   Li, Yanran
   Lu, Xuequan
   Wang, Meili
   Yang, Xiaosong
TI KeyFrame extraction for human motion capture data via multiple binomial
   fitting
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; curve simplification; keyframe extraction; motion
   capture
AB In this paper, we make two contributions. The first is to propose a new keyframe extraction algorithm, which reduces the keyframe redundancy and reduces the motion sequence reconstruction error. Secondly, a new motion sequence reconstruction method is proposed, which further reduces the error of motion sequence reconstruction. Specifically, we treated the input motion sequence as curves, then the binomial fitting was extended to obtain the points where the slope changes dramatically in the vicinity. Then we took these points as inputs to obtain keyframes by density clustering. Finally, the motion curves were segmented by keyframes and the segmented curves were fitted by binomial formula again to obtain the binomial parameters for motion reconstruction. Experiments show that our methods outperform existing techniques, in terms of reconstruction error.
C1 [Xu, Chenxu; Yu, Wenjie; Wang, Meili] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Wang, Meili] Bournemouth Univ, NCCA, Poole, Dorset, England.
   [Wang, Meili] Deakin Univ, Sch Informat Technol, Waurn Ponds Campus, Waurn Ponds, Vic, Australia.
   [Li, Yanran; Yang, Xiaosong] Minist Agr, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
   [Lu, Xuequan] Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China; Bournemouth University; Deakin
   University; Ministry of Agriculture & Rural Affairs
RP Wang, ML (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
EM wml@nwsuaf.edu.cn
RI zhang, luyu/JJC-4227-2023
OI Lu, Xuequan/0000-0003-0959-408X; Li, Yanran/0000-0003-1385-7604
FU Key Laboratory of Agricultural Internet of Things, Ministry of
   Agriculture and Rural Affairs, China [2018AIOT-09]; Key Research and
   Development Program of Shaanxi Province [2018NY-127]; Shaanx-i Key
   Industrial Innovation Chain Project in Agricultural Domain
   [2019ZDLNY02-05]
FX Key Laboratory of Agricultural Internet of Things, Ministry of
   Agriculture and Rural Affairs, China, Grant/Award Number: (2018AIOT-09);
   Key Research and Development Program of Shaanxi Province, Grant/Award
   Number: (2018NY-127); Shaanx-i Key Industrial Innovation Chain Project
   in Agricultural Domain, Grant/Award Number: (2019ZDLNY02-05)
CR Chang XJ, 2016, STUD COMPUT INTELL, V642, P335, DOI 10.1007/978-3-319-31277-4_29
   Gong YH, 2003, MULTIMEDIA SYST, V9, P157, DOI 10.1007/s00530-003-0086-3
   Halit C, 2011, COMPUT ANIMAT VIRT W, V22, P3, DOI 10.1002/cav.380
   Huang KS, 2005, VISUAL COMPUT, V21, P532, DOI 10.1007/s00371-005-0316-0
   Jun X, 2006, P INT C ADV COM GRAP
   Li YR, 2019, VISUAL COMPUT, V35, P1143, DOI 10.1007/s00371-019-01692-9
   Li ZJ, 2015, IEEE T IND ELECTRON, V62, P5763, DOI 10.1109/TIE.2015.2447498
   Liu XM, 2013, VISUAL COMPUT, V29, P85, DOI 10.1007/s00371-012-0676-1
   Miura T, 2014, IEEJ T ELECTR ELECTR, V9, P697, DOI 10.1002/tee.22029
   Qi Z, 2019, P 2019 INT C ART INT, P482
   Sasaki T, 2010, IEEE T IND ELECTRON, V57, P1401, DOI 10.1109/TIE.2009.2030825
   Shin SY, 2015, IEEE T IND ELECTRON, V62, P2265, DOI 10.1109/TIE.2014.2353017
   Sun B, 2018, P 2018 IEEE 9 ANN IN
   Xia GY, 2017, IEEE T IND ELECTRON, V64, P1589, DOI 10.1109/TIE.2016.2610946
   Zhang Q, 2014, SYMMETRY-BASEL, V6, P926, DOI 10.3390/sym6040926
   Zhang Q, 2013, J HUM KINET, V39, P5, DOI 10.2478/hukin-2013-0063
   Zhang Y, 2018, P MATEC WEB C, P232
NR 17
TC 2
Z9 2
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2021
VL 32
IS 1
AR e1976
DI 10.1002/cav.1976
EA DEC 2020
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QP5QT
UT WOS:000598277800001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Chan, JCP
   Shum, HPH
   Wang, H
   Yi, L
   Wei, W
   Ho, ESL
AF Chan, Jacky C. P.
   Shum, Hubert P. H.
   Wang, He
   Yi, Li
   Wei, Wei
   Ho, Edmond S. L.
TI A generic framework for editing and synthesizing multimodal data with
   relative emotion strength
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE data-driven; emotion motion; facial expression; image editing; motion
   capture; motion synthesis; relative attribute
ID MOTION; CLASSIFICATION
AB Emotion is considered to be a core element in performances. In computer animation, both body motions and facial expressions are two popular mediums for a character to express the emotion. However, there has been limited research in studying how to effectively synthesize these two types of character movements using different levels of emotion strength with intuitive control, which is difficult to be modeled effectively. In this work, we explore a common model that can be used to represent the emotion for the applications of body motions and facial expressions synthesis. Unlike previous work that encode emotions into discrete motion style descriptors, we propose a continuous control indicator called emotion strength by controlling which a data-driven approach is presented to synthesize motions with fine control over emotions. Rather than interpolating motion features to synthesize new motion as in existing work, our method explicitly learns a model mapping low-level motion features to the emotion strength. Because the motion synthesis model is learned in the training stage, the computation time required for synthesizing motions at run time is very low. We further demonstrate the generality of our proposed framework by editing 2D face images using relative emotion strength. As a result, our method can be applied to interactive applications such as computer games, image editing tools, and virtual reality applications, as well as offline applications such as animation and movie production.
C1 [Chan, Jacky C. P.] Caritas Inst Higher Educ, Tseung Kwan O, Hong Kong, Peoples R China.
   [Shum, Hubert P. H.; Ho, Edmond S. L.] Northumbria Univ, Fac Engn & Environm, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
   [Wang, He] Univ Leeds, Sch Comp, Leeds, W Yorkshire, England.
   [Yi, Li] Yilifilm, Shenzhen, Peoples R China.
   [Wei, Wei] Xian Univ Technol, Sch Comp Sci & Engn, Xian, Peoples R China.
C3 Saint Francis University Hong Kong; Northumbria University; University
   of Leeds; Xi'an University of Technology
RP Ho, ESL (corresponding author), Northumbria Univ, Fac Engn & Environm, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
EM e.ho@northumbria.ac.uk
RI Wang, He/ABD-8303-2021; wei, wei/HHR-8613-2022; chan,
   jacky/JVP-2299-2024; Ho, Edmond S. L./JDW-1835-2023; Wei,
   Wei/ABB-8665-2021; wei, wei/IQW-1347-2023; Shum, Hubert P.
   H./E-8060-2015
OI Wang, He/0000-0002-2281-5679; Ho, Edmond S. L./0000-0001-5862-106X; Wei,
   Wei/0000-0002-8751-9205; Shum, Hubert P. H./0000-0001-5651-6039; Chan,
   Chun Pong/0000-0002-6180-9853
FU Engineering and Physical Sciences Research Council [EP/M002632/1];
   Office of the Royal Society [IE160609]; EPSRC [EP/M002632/1] Funding
   Source: UKRI
FX Engineering and Physical Sciences Research Council, Grant/Award Number:
   EP/M002632/1; Office of the Royal Society, Grant/Award Number: IE160609
CR [Anonymous], 2007, P ADV NEUR INF PROC
   [Anonymous], 2001 C P 23 ANN INT
   [Anonymous], SIGGRAPH AS 2013 TEC
   [Anonymous], 2017 IEEE C COMP VIS
   [Anonymous], P 5 S APPL PERC GRAP
   [Anonymous], AAAI 18 32 AAAI C AR
   [Anonymous], 2011 INT C COMP VIS
   [Anonymous], SPORT EX PSYCHOL
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Brand Matthew, 2000, P 27 ANN C COMP GRAP
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155
   Chen L., 2014, 2014 IEEE C COMP VIS
   Ennis C., 2013, Proceedings of Motion on Games, p31:53
   Ho ESL, 2016, COMPUT VIS IMAGE UND, V148, P97, DOI 10.1016/j.cviu.2015.12.011
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Ikemoto L, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477927
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Laffont PY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601101
   Ma YL, 2006, BEHAV RES METHODS, V38, P134, DOI 10.3758/BF03192758
   MATLAB, 2015, MATLAB VERS 8 5 0 R2
   Normoyle Aline, 2013, P ACM S APPL PERC, P91, DOI [DOI 10.1145/2492494.2492500, 10.1145/2492494.2492500]
   Portenier T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201393
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Sigal L, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766971
   Song F, 2008, SMART MATER STRUCT, V17, DOI 10.1088/0964-1726/17/5/055024
   Urtasun R, 2004, COMPUT GRAPH FORUM, V23, P799, DOI 10.1111/j.1467-8659.2004.00809.x
   Van Der Maaten Laurens, 2009, Journal of Machine Learning Research, V10, P13
   Xia SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766999
   Yang YM, 2005, LECT NOTES ARTIF INT, V3809, P133
   Yumer ME, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925955
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 33
TC 2
Z9 2
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2019
VL 30
IS 6
AR e1871
DI 10.1002/cav.1871
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KD5NX
UT WOS:000507913800005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Le Naour, T
   Courty, N
   Gibet, S
AF Le Naour, T.
   Courty, N.
   Gibet, S.
TI Skeletal mesh animation driven by few positional constraints
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE animation from a limited set of positional constraints; data-driven
   character animation; mesh animation
ID DEFORMATION
AB In this paper, we propose a whole animation pipeline for data-driven character animation. Considering that the traditional animation pipeline, including skeleton reconstruction from markers, rigging, and retargeting, is subject to potential loss of information and precision, our objective is to control in real time articulated meshes from a low number of positional constraints. Our method is based on an efficient deformation technique that integrates into a volumetric control structure the high-resolution mesh, the skeleton, and relevant marker locations. An iterative optimization method, which preserves both geometric characteristics, segment lengths and joint limits, is applied to this structure. We show the ability of our system to interactively animate and deform high-resolution models from few positional constraints while keeping all the details of the movement.
C1 [Le Naour, T.; Courty, N.; Gibet, S.] Univ Bretagne Sud, IRISA, Vannes Campus, Bretagne, France.
   [Le Naour, T.] Univ Fribourg, Neurosci, CH-1700 Fribourg, Switzerland.
C3 University of Fribourg
RP Le Naour, T (corresponding author), Univ Bretagne Sud, IRISA, Vannes Campus, Bretagne, France.; Le Naour, T (corresponding author), Univ Fribourg, Neurosci, CH-1700 Fribourg, Switzerland.
EM thibaut.lenaour@unifr.ch
OI Le Naour, Thibaut/0000-0003-4476-6617
CR [Anonymous], 2007, MPII20074004
   Aristidou A, 2011, GRAPH MODELS, V73, P243, DOI 10.1016/j.gmod.2011.05.003
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Blow J, 2002, TECHNICAL REPORT
   Borosan P., 2010, Proceedings of Eurographics 2010 - Short papers, P41
   Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995
   Jacobson A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185573
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Krayevoy V, 2005, SIGGRAPH 05 ACM SIGG
   Levi Z, 2015, IEEE T VIS COMPUT GR, V21, P264, DOI 10.1109/TVCG.2014.2359463
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Liu Z, 2018, P 11 ANN INT C MOT I
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Park SI, 2006, ACM T GRAPHIC, V25, P881, DOI 10.1145/1141911.1141970
   Shi XH, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239532
   Sorkine O, 2007, S GEOM PROC, V4, P109, DOI [10.1145/1073204.1073323, DOI 10.1145/1073204.1073323]
   Sumner RW, 2005, ACM T GRAPHIC, V24, P488, DOI 10.1145/1073204.1073218
   Vaillant R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461960
   Wang, 1996, P 5 INT MESH ROUNDT, P47
   Wheatland N., 2013, P MOTION GAMES, P197, DOI DOI 10.1145/2522628.2522656
   Xian CH, 2012, VISUAL COMPUT, V28, P21, DOI 10.1007/s00371-011-0595-6
   Zhao Y, 2012, COMPUT ANIMAT VIRT W, V23, P519, DOI 10.1002/cav.1488
   Zollhofer M, 2012, P EUR SHORT PAP, P85, DOI 10.2312/conf/EG2012/short/085-088
   Zordan V. B., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P245
NR 24
TC 3
Z9 3
U1 2
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1900
DI 10.1002/cav.1900
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400021
DA 2024-07-18
ER

PT J
AU Zhu, XQ
   Song, L
   Wang, N
   Zhang, RH
   Chen, SS
   Wang, XY
   Zhu, MY
   You, LH
   Deng, ZG
   Jin, XG
AF Zhu, Xiaoqiang
   Song, Lei
   Wang, Nan
   Zhang, Ruiheng
   Chen, Shenshuai
   Wang, Xiangyang
   Zhu, Mengyao
   You, Lihua
   Deng, Zhigang
   Jin, Xiaogang
TI Screwing assembly oriented interactive model segmentation in HMD VR
   environment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE HCI; virtual reality; 3D segmentation; 3D printing
ID 3D MODELS
AB Although different approaches of segmenting and assembling geometric models for 3D printing have been proposed, it is difficult to find any research studies, which investigate model segmentation and assembly in head-mounted display (HMD) virtual reality (VR) environments for 3D printing. In this work, we propose a novel and interactive segmentation method for screwing assembly in the environments to tackle this problem. Our approach divides a large model into semantic parts with a screwing interface for repeated tight assembly. Specifically, after a user places the cutting interface, our algorithm computes the bounding box of the current part automatically for subsequent multicomponent semantic Boolean segmentations. Afterwards, the bolt is positioned with an improved K3M image thinning algorithm and is used for merging paired components with union and subtraction Boolean operations respectively. Moreover, we introduce a swept Boolean-based rotation collision detection and location method to guarantee a collision-free screwing assembly. Experiments show that our approach provides a new interactive multicomponent semantic segmentation tool that supports not only repeated installation and disassembly but also tight and aligned assembly.
C1 [Zhu, Xiaoqiang; Song, Lei; Wang, Nan; Zhang, Ruiheng; Chen, Shenshuai; Wang, Xiangyang; Zhu, Mengyao] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [You, Lihua] Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
C3 Shanghai University; Bournemouth University; University of Houston
   System; University of Houston; Zhejiang University
RP Zhu, MY (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM zhumengyao@shu.edu.cn
OI Deng, Zhigang/0000-0003-2571-5865; Deng, Zhigang/0000-0002-0452-8676;
   Jin, Xiaogang/0000-0001-7339-2920
FU National Natural Science Foundation of China [61402277, 61831019,
   61671011, 61801255]; Key Support Projects of Shanghai Science and
   Technology Committee [16010500100]; Key Research and Development Program
   of Zhejiang Province [2018C01090]
FX National Natural Science Foundation of China, Grant/Award Number:
   61402277, 61831019, 61671011, and 61801255; Key Support Projects of
   Shanghai Science and Technology Committee, Grant/Award Number:
   16010500100; Key Research and Development Program of Zhejiang Province,
   Grant/Award Number: 2018C01090
CR [Anonymous], 2001, P 2001 S INT 3D GRAP
   [Anonymous], 2008, MESHLAB OPEN SOURCE, DOI DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136
   Arora R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5643, DOI 10.1145/3025453.3025474
   Bærentzen JA, 2005, IEEE T VIS COMPUT GR, V11, P243, DOI 10.1109/TVCG.2005.49
   Butterworth J., 1992, Proceeding of the Symposium on Interactive 3D Graphics, P135, DOI DOI 10.1145/147156.147182
   Garg A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925900
   George D, 2018, GRAPH MODELS, V96, P1, DOI 10.1016/j.gmod.2018.01.001
   Hu RZ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661244
   Jackson B, 2016, IEEE T VIS COMPUT GR, V22, P1442, DOI 10.1109/TVCG.2016.2518099
   Jacobson A., 2017, LIBIGL SIMPLE C PLUS
   Jadoon AK, 2018, IEEE COMPUT GRAPH, V38, P38, DOI [10.1109/MCG.2018.042731658, 10.1109/MCG.2018.182130719]
   James Stuart, 2018, P JOINT S COMPUTATIO
   Keefe DF, 2007, IEEE T VIS COMPUT GR, V13, P1067, DOI 10.1109/TVCG.2007.1060
   Le T, 2017, COMPUT GRAPH-UK, V66, P103, DOI 10.1016/j.cag.2017.05.011
   Luo LJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366148
   Mcloughlin L, 2016, IEEE COMPUT GRAPH, V36, P22, DOI 10.1109/MCG.2016.1
   Mendes D, 2017, COMPUT GRAPH-UK, V67, P95, DOI 10.1016/j.cag.2017.06.003
   Mendes D, 2017, IEEE SYMP 3D USER, P154, DOI 10.1109/3DUI.2017.7893332
   Otsuki M, 2018, VIRTUAL REAL-LONDON, V22, P167, DOI 10.1007/s10055-017-0317-0
   Rodrigues RSV, 2018, COMPUT GRAPH FORUM, V37, P235, DOI 10.1111/cgf.13323
   Saeed K, 2010, INT J AP MAT COM-POL, V20, P317, DOI 10.2478/v10006-010-0024-4
   Shu ZY, 2016, COMPUT AIDED GEOM D, V43, P39, DOI 10.1016/j.cagd.2016.02.015
   Song P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925876
   Song P, 2015, COMPUT AIDED GEOM D, V35-36, P137, DOI 10.1016/j.cagd.2015.03.020
   Sun T, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766961
   Vanek J, 2014, COMPUT GRAPH FORUM, V33, P322, DOI 10.1111/cgf.12353
   Wesche G., 2001, P ACM S VIRTUAL REAL, P167
   Xian CH, 2009, SMI 2009: IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P21, DOI 10.1109/SMI.2009.5170159
   Yao MJ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818064
   Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238
   Zhao HL, 2011, VISUAL COMPUT, V27, P507, DOI 10.1007/s00371-011-0571-1
   Zhou QN, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925901
NR 32
TC 2
Z9 2
U1 0
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1880
DI 10.1002/cav.1880
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Vanakittistien, N
   Sudsang, A
   Chentanez, N
AF Vanakittistien, Nuttapon
   Sudsang, Attawith
   Chentanez, Nuttapong
TI Game-ready 3D hair model from a small set of images
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE hair modeling; hair simulation; physical simulation; physics-based
   animation; reconstruction
AB We present a system for creating a hair model that matches a user's hairstyle from images. The model consists of guide hair strands and can be used in a real-time hair simulator. Our goal differs from most previous works that aim to create realistic high-resolution hair for off-line applications or create a mesh of the exterior of the hair volume for image manipulation. Our primary aim is for a user to be able to put his/her hairstyle into game or other real-time applications. By taking photos in eight views of the user's head using a smartphone camera and segmenting the images with some easy-to-use tools, the player will obtain his/her own hair model in NVIDIA's HairWorks, which is a hair simulator used in many games. We show a number of results demonstrating the capabilities of our system in this paper.
C1 [Vanakittistien, Nuttapon; Sudsang, Attawith; Chentanez, Nuttapong] Chulalongkorn Univ, Fac Engn, Dept Comp Engn, 254 Pathum Wan Dist, Bangkok, Thailand.
   [Chentanez, Nuttapong] NVIDIA, Phys Res Grp, Santa Clara, CA USA.
C3 Chulalongkorn University; Nvidia Corporation
RP Chentanez, N (corresponding author), Chulalongkorn Univ, Fac Engn, Dept Comp Engn, 254 Pathum Wan Dist, Bangkok, Thailand.
EM nuttapong26@gmail.com
FU Development and Promotion of Science and Technology Talents Project
FX Development and Promotion of Science and Technology Talents Project
CR [Anonymous], 2015, ACM T GRAPHIC
   [Anonymous], WORKSH VIRT REAL INT
   [Anonymous], 2016, CMU-CS-16-118
   [Anonymous], NVID HAIRWORKS
   [Anonymous], WORKSH VIRT REAL INT
   [Anonymous], 2014, ACM T GRAPHIC, DOI DOI 10.1145/2661229.2661254
   [Anonymous], ACM T GRAPH
   [Anonymous], STAR P EUR 2013 GIR
   [Anonymous], ACM T GRAPH
   Chai ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925961
   Chai ML, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461990
   Chai ML, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185612
   Hu LW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766931
   Iben Hayley., 2013, Proceedings of the 12th ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P63, DOI DOI 10.1145/2485895.2485913
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   KIM T.-Y., 2012, P ACM SIGGRAPHEUROGR, P305, DOI DOI 10.5555/2422356.2422399
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Liwen Hu, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601194
   Luo LJ, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462026
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Paris S, 2004, ACM T GRAPHIC, V23, P712, DOI 10.1145/1015706.1015784
   Paris S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360629
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Umetani Nobuyuki, 2014, ACM SIGGRAPH 2014 TA, P21, DOI [DOI 10.1145/2614106.2614158, 10.1145/2614106.2614158]
   Vanakittistien Nuttapon., 2016, Proceedings of the 9th International Conference on Motion in Games, P85
   Wei YC, 2005, ACM T GRAPHIC, V24, P816, DOI 10.1145/1073204.1073267
   Zhang M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073627
NR 29
TC 0
Z9 0
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2019
VL 30
IS 2
AR e1855
DI 10.1002/cav.1855
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR7XB
UT WOS:000463367400007
DA 2024-07-18
ER

PT J
AU Krejtz, K
   Duchowski, A
   Zhou, H
   Jorg, S
   Niedzielska, A
AF Krejtz, Krzysztof
   Duchowski, Andrew
   Zhou, Heng
   Jorg, Sophie
   Niedzielska, Anna
TI Perceptual evaluation of synthetic gaze jitter
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character animation; eye movements; gaze synthesis; microsaccades; pupil
   unrest
ID PUPILLARY RESPONSES; NOISE
AB Eye movements are an essential part of non-verbal behavior. Non-player characters; as they occur in many games, communicate with the player through dialogue and non-verbal behavior and can have a strong influence on player experience or even on gameplay. In this paper, we evaluate a procedural model designed to synthesize the subtleties of eye motion. More specifically, our model adds microsaccadic jitter and pupil unrest both modeled by 1/f(alpha) or pink noise to the saccadic main sequence. In a series of perceptual two-alternative forced-choice experiments, we explore the perceived naturalness of different parameters of pink noise by comparing synthesized motions to rendered motion of recorded eye movements at extreme close shot and close shot distances. Our results show that, on average, animations based on a procedural model with pink noise were perceived and evaluated as highly natural, whereas data-driven motion without any jitter or with unfiltered jitter were consistently selected as the least natural in appearance.
C1 [Krejtz, Krzysztof] SWPS Univ Social Sci & Humanities, Psychol Dept, Warsaw, Poland.
   [Duchowski, Andrew; Jorg, Sophie] Clemson Univ, Sch Comp, Clemson, SC USA.
   [Zhou, Heng] Clemson Univ, Sch Comp, Comp Sci, Clemson, SC USA.
   [Niedzielska, Anna] Natl Informat Proc Inst, Interact Technol Lab, Warsaw, Poland.
C3 SWPS University of Social Sciences & Humanities; Clemson University;
   Clemson University; Information Processing Center - National Research
   Institute
RP Krejtz, K (corresponding author), SWPS Univ Social Sci & Humanities, Psychol Dept, Warsaw, Poland.
EM duchowski@clemson.edu
RI Krejtz, Krzysztof/AAP-6165-2021; Duchowski, Andrew/P-2068-2015
OI Krejtz, Krzysztof/0000-0002-9558-3039; Duchowski,
   Andrew/0000-0003-1681-7878
FU National Science Foundation [IIS-1423189]
FX National Science Foundation, Grant/Award Number: IIS-1423189
CR ABRAMS RA, 1989, J EXP PSYCHOL HUMAN, V15, P529, DOI 10.1037/0096-1523.15.3.529
   AHERN S, 1979, SCIENCE, V205, P1289, DOI 10.1126/science.472746
   Aks D.J., 2002, Nonlinear Dynamics, Psychology, and the Life Sciences, V6, P1, DOI DOI 10.1023/A:1012222601935
   [Anonymous], COMPUT ENTERTAIN
   [Anonymous], 1988, Eye, brain, and vision
   [Anonymous], 2014, Recursive Digital Filters: A Concise Guide
   [Anonymous], HDB BRAIN THEORY NEU
   [Anonymous], 2000, HDB PSYCHOPHYSIOLOGY
   [Anonymous], CREATING NOISE
   [Anonymous], LECT NOTES
   BAHILL A T, 1975, Mathematical Biosciences, V24, P191, DOI 10.1016/0025-5564(75)90075-9
   BEATTY J, 1982, PSYCHOL BULL, V91, P276, DOI 10.1037/0033-2909.91.2.276
   Bentivoglio AR, 1997, MOVEMENT DISORD, V12, P1028, DOI 10.1002/mds.870120629
   Bérard P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661285
   Deng ZG, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.35
   Duchowski Andrew., 2015, P 8 ACM SIGGRAPH C M, P47
   Duchowski AT, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P147, DOI 10.1145/2857491.2857528
   Duchowski AT, 2014, EYE TRACKING RES APP, P103
   Garau Maia, 2003, P SIGCHI C HUM FACT, P529, DOI DOI 10.1145/642611.642703
   Green D., 1966, SIGNAL DETECTION THE
   Hodgins J, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823740
   Jogan M, 2014, J VISION, V14, DOI 10.1167/14.3.20
   Krejtz K., 2014, P 2 INT WORKSH EYE T, P37
   Lance Brent J, 2008, P 7 INT JOINT C AUT, V1, P199
   Landy SD, 1999, SCI AM, V280, P38, DOI 10.1038/scientificamerican0699-38
   Le BH, 2012, IEEE T VIS COMPUT GR, V18, P1902, DOI 10.1109/TVCG.2012.74
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Ma XH, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P143, DOI 10.1109/VR.2009.4811014
   Martinez-Conde S, 2009, TRENDS NEUROSCI, V32, P463, DOI 10.1016/j.tins.2009.05.006
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   Newcombe RG, 1998, STAT MED, V17, P873, DOI 10.1002/(SICI)1097-0258(19980430)17:8<873::AID-SIM779>3.0.CO;2-I
   Normoyle Aline., 2013, Proceedings of motion on games, P141, DOI DOI 10.1145/2522628.25226301,2
   Ostling A, 2000, Science, V290, P671
   Otero-Millan J, 2011, ANN NY ACAD SCI, V1233, P107, DOI 10.1111/j.1749-6632.2011.06177.x
   Ouzts A.D., 2012, Proceedings of the Symposium on Eye Tracking Research and Applications, P321, DOI DOI 10.1145/2168556.2168626
   Oyekoya Oyewole., 2009, Proceedings of the 16th acm symposium on virtual reality software and technology, P199, DOI [10.1145/1643928.1643973, DOI 10.1145/1643928.1643973]
   Pamplona VF, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559763
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Peters C, 2010, COMPUT GRAPH-UK, V34, P677, DOI 10.1016/j.cag.2010.09.007
   Privitera CM, 2008, PROC SPIE, V6806, DOI 10.1117/12.772844
   R Development Core Team, 2011, R LANG ENV STAT COMP
   Ren L, 2005, ACM T GRAPHIC, V24, P1090, DOI 10.1145/1073204.1073316
   Robin X, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-77
   Ruhland K., 2014, EUROGRAPHICS STATE O, P69
   STARK L, 1958, NATURE, V182, P857, DOI 10.1038/182857a0
   Steptoe W, 2010, COMPUT ANIMAT VIRT W, V21, P161, DOI 10.1002/cav.354
   Swirski L, 2014, EYE TRACKING RES APP, V14, P219
   Szendro P, 2001, EUR BIOPHYS J BIOPHY, V30, P227, DOI 10.1007/s002490100143
   Team B. L. A. Noire, 2011, LA NOIR ROCKST GAM
   Thurstone LL, 1926, J ABNORM SOC PSYCH, V21, P384
   Trutoiu LC, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010327
   USHER M, 1995, PHYS REV LETT, V74, P326, DOI 10.1103/PhysRevLett.74.326
   Vertegaal R., 1999, P C COMPUTER HUMAN I, P294
   Yang Z, 2009, ADV NEURAL INFORM PR, V22, P2160
   Yeo SH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185538
NR 55
TC 5
Z9 5
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2018
VL 29
IS 6
AR e1745
DI 10.1002/cav.1745
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HH9VW
UT WOS:000456089800005
DA 2024-07-18
ER

PT J
AU Pan, Y
   Sinclair, D
   Mitchell, K
AF Pan, Ye
   Sinclair, David
   Mitchell, Kenny
TI Empowerment and embodiment for collaborative mixed reality systems
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE augmented reality and virtual reality; telecollaboration
AB We present several mixed-reality-based remote collaboration settings by using consumer head-mounted displays. We investigated how two people are able to work together in these settings. We found that the person in the AR system will be regarded as the leader (i.e., they provide a greater contribution to the collaboration), whereas no similar leader emerges in augmented reality (AR)-to-AR and AR-to-VRBody settings. We also found that these special patterns of leadership only emerged for 3D interactions and not for 2D interactions. Results about the participants' experience of leadership, collaboration, embodiment, presence, and copresence shed further light on these findings.
C1 [Pan, Ye; Sinclair, David; Mitchell, Kenny] Disney Res Los Angeles, 521 Circle 7 Dr, Glendale, CA 91201 USA.
RP Mitchell, K (corresponding author), Disney Res Los Angeles, 521 Circle 7 Dr, Glendale, CA 91201 USA.
EM kenny.mitchell@disneyresearch.com
RI Mitchell, Kenny/AAZ-3421-2020
OI Mitchell, Kenny/0000-0003-2420-7447; Pan, Ye/0000-0003-0355-989X
CR Axelsson AS, 2001, CYBERPSYCHOL BEHAV, V4, P279, DOI 10.1089/109493101300117956
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Bodenheimer B, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P115, DOI 10.1145/2804408.2804426
   Ebert D. S., 2003, TEXTURING MODELLING
   Fournier A., 1988, TUTORIAL COMPUTER GR, P114
   Hodgins J, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823740
   Katsyri J, 2015, FRONT PSYCHOL, P6
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P225, DOI 10.1109/VR.2015.7223377
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Olano M., 2005, HWWS 05, P105
   Piwek L, 2014, COGNITION, V130, P271, DOI 10.1016/j.cognition.2013.11.001
   Roth D., 2017, P 2017 CHI C HUM FAC, P2875
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Steed A, 1999, P IEEE VIRT REAL ANN, P112, DOI 10.1109/VR.1999.756941
   Ye P, 2017, PLOS ONE, V12
   Young MK, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P119, DOI 10.1145/2804408.2804410
   Zund F, 2014, MIG 14 P 7 INT C MOT, P125
NR 19
TC 11
Z9 12
U1 2
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1838
DI 10.1002/cav.1838
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100029
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wang, YT
   Wang, LY
   Deng, ZG
   Jin, XG
AF Wang, Yutong
   Wang, Luyuan
   Deng, Zhigang
   Jin, Xiaogang
TI Sketch-based shape-preserving tree animations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE shape preservation; sketch-based editing; special effects; tree
   animation
ID DESIGN
AB We present a novel and intuitive sketch-based tree animation technique, targeting on generating a new type of special effect of smoothly transforming leafy trees into morphologically different new shapes. Both topological consistencies of branches and meaningful in-between crown shapes are preserved during the transformation. Specifically, it takes a leafy tree and a user's sketch describing the silhouette of the desired crown shape under a certain viewpoint as the input. Based on a self-adaptive multiscale cage tree representation, branches are locally transformed through a series of topology-aware deformations, and the resulting tree conforms to the user-designed shape, demonstrating better aesthetics compared to global single-cage-based methods. By interpolating the transformations, we are able to create visually pleasing shape-preserving animations of trees transforming between two crown shapes. Our proposed framework also provides an efficient way to interactively edit leafy trees toward desired shapes, demonstrating its potential to leverage existing tree modeling frameworks by providing flexible and intuitive tree editing operations.
C1 [Wang, Yutong; Wang, Luyuan; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Deng, Zhigang] East China Jiaotong Univ, Virtual Real & Interact Tech Inst, Nanchang, Jiangxi, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 Zhejiang University; East China Jiaotong University; University of
   Houston System; University of Houston
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.; Deng, ZG (corresponding author), East China Jiaotong Univ, Virtual Real & Interact Tech Inst, Nanchang, Jiangxi, Peoples R China.; Deng, ZG (corresponding author), Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
EM zhigang.deng@gmail.com; jin@cad.zju.edu.cn
OI Deng, Zhigang/0000-0003-2571-5865; Deng, Zhigang/0000-0002-0452-8676;
   Jin, Xiaogang/0000-0001-7339-2920
FU National Key R&D Program of China [2017YFB1002600]; Key Research and
   Development Program of Zhejiang Province [2018C01090]; National Natural
   Science Foundation of China [61732015]
FX National Key R&D Program of China, Grant/Award Number: 2017YFB1002600;
   Key Research and Development Program of Zhejiang Province, Grant/Award
   Number: 2018C01090; National Natural Science Foundation of China,
   Grant/Award Number: 61732015
CR [Anonymous], 1994, COMPUTING DISCRETE F
   [Anonymous], ACM T GRAPH
   Din M.A., 1990, MANUAL WOODY LANDSCA
   Gkioulekas I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516972
   Hertzmann A, 1999, SIGGRAPH 99 NONPH RE
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Liu S, 2012, T EDUTAINMENT
   Longay S., 2012, The proceedings of the Eurographics Symposium on Sketch-Based Interfaces and Modeling, P107, DOI [DOI 10.2312/SBM/SBM12/107-120, 10.2312/SBM/SBM12/107-120]
   Nealen A, 2005, ACM T GRAPHIC, V24, P1142, DOI 10.1145/1073204.1073324
   Okabe M, 2005, COMPUT GRAPH FORUM, V24, P487, DOI 10.1111/j.1467-8659.2005.00874.x
   Palubicki W, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531364
   Pirk S., 2012, ACM Transactions on Graphics, V31, P1
   Pirk S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661252
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366188
   Pirk S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130814
   Prusinkiewicz P, 2004, CURR OPIN PLANT BIOL, V7, P79, DOI 10.1016/j.pbi.2003.11.007
   Prusinkiewicz P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P351, DOI 10.1145/192161.192254
   Runions A., 2007, NPH, P63
   Shek A, 2010, ACM SIGGRAPH 2010 TA, V53
   Stava O, 2014, COMPUT GRAPH FORUM, V33, P118, DOI 10.1111/cgf.12282
   VATTI BR, 1992, COMMUN ACM, V35, P56, DOI 10.1145/129902.129906
   Wang G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3144456
   Wang R, 2014, COMPUT GRAPH FORUM, V33, P82, DOI 10.1111/cgf.12402
   Wang Y., 2017, COMPUT ANIMAT VIRTUA, V28
   Wang YT, 2017, IEEE T VIS COMPUT GR, V23, P2521, DOI 10.1109/TVCG.2016.2636187
   Wither J, 2009, COMPUT GRAPH FORUM, V28, P541, DOI 10.1111/j.1467-8659.2009.01394.x
NR 27
TC 1
Z9 2
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1821
DI 10.1002/cav.1821
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100012
DA 2024-07-18
ER

PT J
AU Waszak, B
AF Waszak, Bartlomiej
TI Limbless movement simulation with a particle-based system
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE limbless movement; motion synthesis; position-based dynamics; snake
   locomotion; soft-body dynamics
ID LOCOMOTION
AB Snakes and other limbless animals continue to attract the close attention of scientists because of their unique locomotion abilities. This paper presents a novel approach to limbless movement simulation. We built our simulation framework using position-based dynamics. We describe the body configuration of snakes using different types of distance constraints. The limbless movement is based on the formulation of a friction constraint to model the behavior of a snake's scales. In our approach, it is easy to solve collisions between objects and self-collisions for simulated snakes. Our model includes a dynamic geometrical environment colliding with simulated animals. Detailed patterns are presented for four main types of limbless movement: serpentine, rectilinear, concertina, and sidewinding. Finally, we present the process of computing the final smooth visual mesh from the physical simulation data. This paper concludes with several simulation scenarios showing the high-quality results of our framework for limbless movement simulation.
C1 [Waszak, Bartlomiej] 464 Rue St Mathias,Apartment 209, Quebec City, PQ G1K 1B6, Canada.
   [Waszak, Bartlomiej] Ubisoft Quebec City Studio, Quebec City, PQ, Canada.
RP Waszak, B (corresponding author), 464 Rue St Mathias,Apartment 209, Quebec City, PQ G1K 1B6, Canada.
EM bartlomiej.waszak@gmail.com
CR [Anonymous], THESIS
   [Anonymous], 1997, INTRO PHYS BASED MOD
   [Anonymous], 2014, SNAK MOV VER SCAR
   Bender J., 2015, EUROGRAPHICS TUTORIA
   BEYNON M, 2007, WILDLIFE SPECIALS SE
   BIRTH Lab, 2015, SNAK MOT SID
   BRML-Technion channel, 2015, KIN SNAK LOC SNAK TU
   Chang J, 2004, COMPUT ANIMAT VIRT W, V15, P211, DOI 10.1002/cav.23
   Ericson C., 2005, Real-time collision detection
   Erleben Kenny., 2005, Physics-based animation
   Filippov AE, 2016, SCI REP-UK, V6, DOI 10.1038/srep23539
   GANS C, 1986, HERPETOLOGICA, V42, P33
   GRAY J, 1946, J EXP BIOL, V23, P101
   GRAY J, 1950, J EXP BIOL, V26, P354
   Grzeszczuk R., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P63, DOI 10.1145/218380.218411
   Hopkins J.K., 2012, Performance Metrics for Intelligent Systems (PerMIS'12) Workshop, College Park, MD, P136
   Hu DL, 2009, P NAT AC SCI US NEW, P106
   Jakobsen Thomas., 2003, Advanced Character Physics
   JAYNE BC, 1986, COPEIA, P915, DOI 10.2307/1445288
   Lengyel E., 2012, Mathematics for 3D Game Programming and Computer Graphics
   Macklin M., 2013, ACM T GRAPHIC, V32
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Mahadevan L, 2004, P NATL ACAD SCI USA, V101, P23, DOI 10.1073/pnas.2637051100
   Miller G, 2000, SNAKE ROBOTS
   Miller G. S. P., 1988, Computer Graphics, V22, P169, DOI 10.1145/378456.378508
   MULLER M., 2006, P VIRTUAL REALITY IN, P71, DOI [10.1007/978-3-319-08234-9_92-1, DOI 10.1007/978-3-319-08234-9_92-1]
   MULLER M., 2008, VIRTUAL REALITY INTE
   Panagiotakis C, 2006, VISUAL COMPUT, V22, P562, DOI 10.1007/s00371-006-0035-1
   Sanchez A, 2013, RECTILINEAR SNAKE MO
   Seol Y, 2008, LECT NOTES COMPUT SC, V5358, P646, DOI 10.1007/978-3-540-89639-5_62
   Stam J, 2009, IEEE INT C COMP AID
   Transeth AA, 2007, THESIS
   VAN VERTH J. M., 2008, ESSENTIAL MATH GAMES
   Waszak B, 2017, SUPPORTING VIDEO LIM
   Waszak B, 2015, PROCEEDINGS - I3D 2015, P136, DOI 10.1145/2699276.2721401
   Wolf A, 2005, ADV ROBOTICS, V19, P221, DOI 10.1163/1568553053583652
NR 36
TC 2
Z9 2
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2018
VL 29
IS 2
AR e1795
DI 10.1002/cav.1795
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GD0DX
UT WOS:000430170900006
DA 2024-07-18
ER

PT J
AU Herrmann, E
   Manns, M
   Du, H
   Hosseini, S
   Fischer, K
AF Herrmann, Erik
   Manns, Martin
   Du, Han
   Hosseini, Somayeh
   Fischer, Klaus
TI Accelerating statistical human motion synthesis using space partitioning
   data structures
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE character animation; human motion synthesis; motion retrieval;
   clustering
AB Statistical model-based motion synthesis enables the constrained generation of natural human motions. In this paper, we present a combination of statistical model-based motion synthesis with a motion retrieval method. We fit a statistical motion model to the low-dimensional latent space obtained by applying principal component analysis to a functional representation of example motion data. In order to accelerate the synthesis, we construct a space partitioning tree on a dense set of samples from the model projected into a feature space. At run-time, the tree is traversed based on an objective function to find the best sample fitting user-defined constraints. After finding a good initial guess, we apply numerical optimization to reach constraints exactly. We evaluated the accuracy and efficiency of the search in the tree using different space partitioning methods on synthetic and motion capture data. In our experiments, the most stable and accurate search results were achieved using the k-Means++ algorithm for the tree construction.
C1 [Herrmann, Erik; Du, Han; Hosseini, Somayeh; Fischer, Klaus] Deutsch Forschungszentrum Kunstliche Intelligenz, Agents & Simulated Real, Saarbrucken, Germany.
   [Herrmann, Erik; Du, Han; Hosseini, Somayeh; Fischer, Klaus] Univ Saarland, Dept Comp Sci, Saarbrucken, Germany.
   [Manns, Martin] Univ Siegen, Siegen, Germany.
C3 Saarland University; Universitat Siegen
RP Herrmann, E (corresponding author), Deutsch Forschungszentrum Kunstliche Intelligenz, Agents & Simulated Real, Saarbrucken, Germany.
EM erik.herrmann@dfki.de
FU European Union in FP7 [611007]; Horizon 2020 under the Marie
   Sklodowska-Curie [642841]
FX European Union in FP7, Grant/Award Number: 611007; Horizon 2020 under
   the Marie Sklodowska-Curie, Grant/Award Number: 642841
CR [Anonymous], 2009, Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games, I3D'09, DOI DOI 10.1145/1507149.1507181
   [Anonymous], 2010, SCA'10: proceedings of the 2010 ACM SIGGRAPH/Eurographics symposium on computer animation, DOI [10.2312/SCA/SCA10/001-010, DOI 10.2312/SCA/SCA10/001-010]
   [Anonymous], 2013, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'13
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bernard J, 2013, IEEE T VIS COMPUT GR, V19, P2257, DOI 10.1109/TVCG.2013.178
   Busemann S, 2016, PROC CIRP, V41, P224, DOI 10.1016/j.procir.2015.12.106
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Guo SH, 2015, VISUAL COMPUT, V31, P497, DOI 10.1007/s00371-014-0943-4
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L., 2004, THESIS
   Lee Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866160
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Min JY, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640452
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Ren C, 2010, COMPUT GRAPH FORUM, V29, P545, DOI 10.1111/j.1467-8659.2009.01624.x
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Yoo I, 2014, VISUAL COMPUT, V30, P213, DOI 10.1007/s00371-013-0797-1
   Zhou LY, 2014, VISUAL COMPUT, V30, P845, DOI 10.1007/s00371-014-0957-y
NR 22
TC 5
Z9 5
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1780
DI 10.1002/cav.1780
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200026
OA hybrid
DA 2024-07-18
ER

PT J
AU Lee, J
   Jeong, K
   Kim, J
AF Lee, Jiwon
   Jeong, Kisung
   Kim, Jinmo
TI MAVE: Maze-based immersive virtual environment for new presence and
   experience
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE immersion; immersive virtual reality; interaction; maze generation
   algorithm; portable walking simulator; VR sickness
ID REALISM
AB To provide users with a sense of presence and experience, this study presents a maze-based immersive virtual environment (MAVE). MAVE consists of a new immersive virtual scene and immersive interaction optimized for such maze. The algorithm for calculating a finite maze is defined to automatically generate diverse maze patterns; an interactive editing function and sketch-based maze retrieval make it easier to generate maze patterns intuitively. With the integration of these procedures, MAVE proposes a user-oriented maze terrain authoring system that can reconstruct two-dimensional maze patterns into three-dimensional maze terrains. It also provides an interaction system that enables users to be immersed in a broad virtual maze environment within a limited space. As an Arduino-based portable walking simulator, this system detects the user's steps as he or she walks in place and controls the user's motions in the virtual environment. This study confirms through various technical and statistical experiments that MAVE can lead to new research on immersion enhancement without virtual reality sickness via virtual reality content.
C1 [Lee, Jiwon; Kim, Jinmo] Catholic Univ Pusan, Dept Software, 57 Oryundae Ro, Busan, South Korea.
   [Jeong, Kisung] Korea Univ, Dept Visual Informat Proc, 145 Anam Ro, Seoul, South Korea.
C3 Catholic University Pusan; Korea University
RP Kim, J (corresponding author), Catholic Univ Pusan, 57 Oryundae Ro, Busan, South Korea.
EM jmkim11@cup.ac.kr
RI Kim, Jinmo/AAG-2822-2020
OI Kim, Jinmo/0000-0002-1663-9306
FU National Research Foundation of Korea; Ministry of Education
   [NRF-2014R1A1A2055834]
FX National Research Foundation of Korea; Ministry of Education,
   Grant/Award Number: NRF-2014R1A1A2055834
CR Bouchard S., 2009, Journal of CyberTherapy Rehabilitation, V2, P127, DOI DOI 10.3233/SHTI210961
   Carvalheiro C, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1146, DOI 10.1145/2964284.2964293
   Cheng LP, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P417
   Cheng LP, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3463, DOI 10.1145/2556288.2557101
   Dylla K., 2010, Computer Graphics World, Vol, V37, P62
   Hayward V., 2004, Sensor Review, V24, P16, DOI 10.1108/02602280410515770
   Hoffman HG, 1998, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VRAIS.1998.658423
   Jeong K, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8110120
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim J., 2016, SYMMETRY, V8
   Nordahl R, 2010, LECT NOTES COMPUT SC, V6192, P123, DOI 10.1007/978-3-642-14075-4_18
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schissler C, 2016, IEEE T VIS COMPUT GR, V22, P1356, DOI 10.1109/TVCG.2016.2518134
   Sivak M, 2012, ICDVRAT 2012, P279
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Tan P, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409061
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vanegas CA, 2012, THESIS
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Visell Y, 2008, LECT NOTES COMPUT SC, V5024, P420, DOI 10.1007/978-3-540-69057-3_55
   Wonka P, 2003, ACM T GRAPHIC, V22, P669, DOI 10.1145/882262.882324
NR 22
TC 14
Z9 14
U1 1
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1756
DI 10.1002/cav.1756
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200003
DA 2024-07-18
ER

PT J
AU Zhu, XQ
   Song, L
   You, LH
   Zhu, MY
   Wang, XY
   Jin, XG
AF Zhu, Xiaoqiang
   Song, Lei
   You, Lihua
   Zhu, Mengyao
   Wang, Xiangyang
   Jin, Xiaogang
TI Brush2Model: Convolution surface-based brushes for 3D modelling in
   head-mounted display-based virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE brush-based 3D modelling; convolution surfaces; closed-form analytical
   solutions; HMD-based virtual environments
ID IMPLICIT; KERNELS; CURVES; TREE
AB Easy and efficient 3D modelling in virtual environments is an important and unsolved topic. This paper proposes a new modelling approach to tackle this issue. It invents convolution surface-based brushes to directly draw 3D models in head-mounted display-based virtual environments. In order to maximize the efficiency, flexibility, and capacity of our proposed modelling approach, we propose three different skeleton-based convolution surfaces to tackle different modelling tasks: point skeleton-based convolution surfaces for metaball shapes, line skeleton-based convolution surfaces for cylindrical shapes, and polygon skeleton-based convolution surfaces for planar surfaces. Their combination makes 3D modelling more flexible and powerful. The high efficiency is further raised by our developed closed-form solutions for point skeletons, ends of line skeletons, and edges of polygonal skeletons. Different user-friendly sweeping schemes are provided to facilitate intuitive inputs for various complex shape generation. Unlike Google's Tilt Brush, which is used to create disconnected sheet-like surfaces only, our proposed convolution surface-based brushes can produce smoothly blended manifold surfaces, and novice users can easily learn and use them to create various interesting 3D models efficiently.
C1 [Zhu, Xiaoqiang; Song, Lei; Zhu, Mengyao; Wang, Xiangyang] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [You, Lihua] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Shanghai University; Bournemouth University; Zhejiang University
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM jin@cad.zju.edu.cn
FU National Natural Science Foundation of China [61402277, 61373084,
   61472351]; Shanghai Municipal Education Commission [15ZZ044]; State Key
   Lab of CADCG [1507]
FX National Natural Science Foundation of China, Grant/Award Number:
   61402277, 61373084; Innovation Program of Shanghai Municipal Education
   Commission, Grant/Award Number: 15ZZ044; Open Project Program of the
   State Key Lab of CAD&CG, Grant/Award Number: 1507; the National Natural
   Science Foundation of China, Grant/Award Number: 61472351
CR Alexe IA, 2007, INT C COMP GRAPH INT, P39
   ALEXE IA, 2004, P AFRIGRAPH, P25
   [Anonymous], J GRAPH TOOLS
   [Anonymous], SBIM
   [Anonymous], 2001, P 2001 S INT 3D GRAP
   BERNHARDT A, 2008, EUROGRAPHICS WORKSH, P57
   Bloomenthal J, 1991, P SIGGRAPH 91, P251
   Butterworth J., 1992, Proceeding of the Symposium on Interactive 3D Graphics, P135, DOI DOI 10.1145/147156.147182
   Canezin F, 2013, COMPUT GRAPH-UK, V37, P565, DOI 10.1016/j.cag.2013.05.024
   Crespin B, 1996, COMPUT GRAPH FORUM, V15, pC165, DOI 10.1111/1467-8659.1530165
   Eyiyurekli M, 2009, SKETCH BASED INTERFA, P45
   Ferley E, 2001, GRAPH MODELS, V63, P459, DOI 10.1006/gmod.2001.0558
   Gourmel O, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451238
   Hornus S, 2003, VISUAL COMPUT, V19, P94, DOI 10.1007/s00371-002-0179-6
   Hubert E, 2012, GRAPH MODELS, V74, P1, DOI 10.1016/j.gmod.2011.07.001
   Hubert E, 2012, J SYMB COMPUT, V47, P680, DOI 10.1016/j.jsc.2011.12.026
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Jackson B, 2016, IEEE T VIS COMPUT GR, V22, P1442, DOI 10.1109/TVCG.2016.2518099
   Jin XG, 2002, VISUAL COMPUT, V18, P530, DOI 10.1007/s00371-002-0161-3
   Jin XG, 2002, COMPUT GRAPH-UK, V26, P437, DOI 10.1016/S0097-8493(02)00087-0
   Jin XG, 2009, VISUAL COMPUT, V25, P279, DOI 10.1007/s00371-008-0267-3
   Karpenko O, 2002, COMPUT GRAPH FORUM, V21, P585, DOI 10.1111/1467-8659.t01-1-00709
   Keefe DF, 2007, IEEE T VIS COMPUT GR, V13, P1067, DOI 10.1109/TVCG.2007.1060
   McCormack J, 1998, COMPUT GRAPH FORUM, V17, P113, DOI 10.1111/1467-8659.00232
   Sanchez M, 2015, COMPUT GRAPH FORUM, V34, P277, DOI 10.1111/cgf.12599
   Sherstyuk A, 1999, VISUAL COMPUT, V15, P171, DOI 10.1007/s003710050170
   Tai CL, 2004, COMPUT GRAPH FORUM, V23, P71, DOI 10.1111/j.1467-8659.2004.00006.x
   Wesche G., 2001, P ACM S VIRTUAL REAL, P167
   Wyvill B, 1999, COMPUT GRAPH FORUM, V18, P149, DOI 10.1111/1467-8659.00365
   Zanni C, 2013, COMPUT GRAPH FORUM, V32, P219, DOI 10.1111/cgf.12199
   Zhu XQ, 2015, VISUAL COMPUT, V31, P69, DOI 10.1007/s00371-013-0905-2
   Zhu XQ, 2012, VISUAL COMPUT, V28, P1115, DOI 10.1007/s00371-011-0662-z
NR 32
TC 7
Z9 8
U1 1
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1764
DI 10.1002/cav.1764
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200011
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Gao, TH
   Wang, WC
   Han, HL
AF Gao, Tianhao
   Wang, Wencheng
   Han, Honglei
TI Efficient view selection by measuring proxy information
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE viewing algorithm; view selection; view evaluation; proxy information
ID IMAGE
AB View selection aims at finding good views that can watch model information as much as possible. However, existing view evaluation methods used to measure model properties are generally complex and very time-consuming. In this paper, we address this challenge by generating succinct proxy information to measure the view quality. The proxy information is generated by principal component analysis of the model to obtain its six principal viewing directions and consists of the representative information computed by the principal viewing directions. We discuss and validate the effectiveness of the proxy information for view evaluation. Thus, measuring the proxy information for view evaluation, the time complexity can be reduced as it is independent of the facet number of the model. This is superior to existing methods by straight measurement of model properties and provides acceleration for view selection. Experimental results show that we can obtain good views as state-of-the-art methods and speed up view selection by at least two orders of magnitudes and achieve more acceleration when the models have more facets. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Gao, Tianhao; Wang, Wencheng] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Gao, Tianhao; Wang, Wencheng] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Han, Honglei] Commun Univ China, Fac Art, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS;
   Communication University of China
RP Wang, WC (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
EM whn@ios.ac.cn
RI Wang, Wencheng/A-3828-2009
CR [Anonymous], 2010, P 3 EUR WORKSH 3D OB
   Au C, 2010, CMES-COMP MODEL ENG, V68, P221
   Biedl TC, 2011, COMP GEOM-THEOR APPL, V44, P399, DOI 10.1016/j.comgeo.2011.04.001
   Blanz V, 1999, PERCEPTION, V28, P575, DOI 10.1068/p2897
   Chen X., 2012, ACM T GRAPHIC, V31
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Feixas M, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1462055.1462056
   Fu HB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360641
   Gonzalez F, 2008, IEEE COMPUT GRAPH, V28, P44, DOI 10.1109/MCG.2008.41
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   KAMADA T, 1988, COMPUT VISION GRAPH, V41, P43, DOI 10.1016/0734-189X(88)90116-8
   Kucerova J., 2013, INT S INF COMM AUT T, P1
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Leifman G, 2012, PROC CVPR IEEE, P414, DOI 10.1109/CVPR.2012.6247703
   Lienhard S, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12317
   Liu H, 2012, VISUAL COMPUT, V28, P279, DOI 10.1007/s00371-011-0638-z
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Mortara M, 2009, COMPUT GRAPH-UK, V33, P280, DOI 10.1016/j.cag.2009.03.003
   Plemenos D., 1996, P INT C COMP GRAPH V
   Polonsky O, 2005, VISUAL COMPUT, V21, P840, DOI 10.1007/s00371-005-0326-y
   Sbert M., 2005, P COMPAESTH EG, P185, DOI [10.2312/COMPAESTH/COMPAESTH05/185-192, DOI 10.2312/COMPAESTH/COMPAESTH05/185-192]
   Secord A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019628
   Serin E, 2013, VISUAL COMPUT, V29, P675, DOI 10.1007/s00371-013-0805-5
   Shilane P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243981
   Sokolov D., 2006, J VIRTUAL REALITY BR, V3, P1860
   Vazquez P.-P., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P273
   Vázquez PP, 2009, VISUAL COMPUT, V25, P441, DOI 10.1007/s00371-009-0326-4
   Vieira T, 2009, COMPUT GRAPH FORUM, V28, P717, DOI 10.1111/j.1467-8659.2009.01412.x
NR 28
TC 3
Z9 4
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 351
EP 357
DI 10.1002/cav.1698
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300019
DA 2024-07-18
ER

PT J
AU Kim, JH
   Im, J
   Kim, CH
   Lee, J
AF Kim, Jong-Hyun
   Im, Jaeho
   Kim, Chang-Hun
   Lee, Jung
TI Subtle features of ice with cloudy effects and scratches from collision
   damage
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE cloudy effects; scratches; collision damage; subtle features of ice
ID VISUAL SIMULATION
AB We propose a simulation framework for expressing cloudy effects and scratches on ice caused by the collision of other objects. Cloudy effects are created and diffused in proportion to the collision on the ice surfaces calculated by a combination of a grid-projection technique and the boundary particle method. To prevent dissipation during the diffusion process, a geodesic distance is used as a constraint. Scratches are modeled directionally by analyzing the density gradient of cloudy effects and rendered using needle-shaped ellipsoids. Experiments provide detailed expression of cloudy effects and scratches from collision damage. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Kim, Jong-Hyun; Im, Jaeho] Korea Univ, Seoul, South Korea.
   [Kim, Chang-Hun] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Lee, Jung] Hallym Univ, Dept Convergence Software, Chunchon, South Korea.
C3 Korea University; Korea University; Hallym University
RP Lee, J (corresponding author), Hallym Univ, Chunchon, South Korea.
EM airjung@hallym.ac.kr
CR [Anonymous], ACM SIGGRAPH ASIA
   [Anonymous], J COMPUTER ANIMATION
   [Anonymous], ACM T GRAPHICS
   Bosch C, 2004, COMPUT GRAPH FORUM, V23, P361, DOI 10.1111/j.1467-8659.2004.00767.x
   Carlson M., 2002, ACM SIGGRAPH/Eurographics Symp. Comp. Anim, P167
   Cohen J.M., 2010, Proceedings of the 2010 ACM SIGGRAPH symposium on Interactive 3D Graphics and Games (New York, NY, USA, 2010), P15
   Dobashi Y, 2008, COMPUT GRAPH FORUM, V27, P477, DOI 10.1111/j.1467-8659.2008.01145.x
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Frisken SF, 2000, COMP GRAPH, P249, DOI 10.1145/344779.344899
   Fujisawa M, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P249
   Gagnon J, 2011, VISUAL COMPUT, V27, P451, DOI 10.1007/s00371-011-0584-9
   Guendelman E, 2003, ACM T GRAPHIC, V22, P871, DOI 10.1145/882262.882358
   Hong JM, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239498
   Im J, 2013, COMPUT GRAPH FORUM, V32, P371, DOI 10.1111/cgf.12057
   Iwasaki K, 2010, COMPUT GRAPH FORUM, V29, P2215, DOI 10.1111/j.1467-8659.2010.01810.x
   Jeong S, 2011, VISUAL COMPUT, V27, P417, DOI 10.1007/s00371-011-0575-x
   Kim D, 2012, IEEE T VIS COMPUT GR, V18, P1488, DOI 10.1109/TVCG.2011.264
   Kim T., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P86
   KIM T, 2004, P 2004 ACM SIGGRAPH, P305, DOI DOI 10.1145/1028523.1028564
   Kim T., 2006, Proc 2006 ACM SIGGRAPH/Eurographics Symp Comp Anim, P167
   Lii SY, 2014, VISUAL COMPUT, V30, P531, DOI 10.1007/s00371-013-0878-1
   Liu SG, 2009, VISUAL COMPUT, V25, P687, DOI 10.1007/s00371-009-0344-2
   Madrazo C., 2009, The Journal of the Society for Art and Science, V8, P35
   Melek Zeki., 2007, SPM '07: Proceedings of the 2007 ACM symposium on Solid and physical modeling, P51
   Merillou S, 2001, VISUAL COMPUT, V17, P30, DOI 10.1007/s003710000093
   Miao YB, 2015, 14TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, VRCAI 2015, P17, DOI 10.1145/2817675.2817676
   Nishino T, 2012, ACM SIGGRAPH ASIA 20
   Schwarzler M, 2007, RENDERING IMPERFECTI
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Stomakhin A, 2014, ACM SIGGRAPH 2014
   Sumner RW, 1999, COMPUT GRAPH FORUM, V18, P17, DOI 10.1111/1467-8659.00299
   Yoon JC, 2009, COMPUT GRAPH FORUM, V28, P1853, DOI 10.1111/j.1467-8659.2009.01563.x
   Zhu B, 2010, COMPUT GRAPH FORUM, V29, P2207, DOI 10.1111/j.1467-8659.2010.01809.x
NR 33
TC 4
Z9 4
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 271
EP 279
DI 10.1002/cav.1699
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300011
DA 2024-07-18
ER

PT J
AU Wang, YZ
   Serracino-Inglott, F
   Yi, XD
   Yuan, XF
   Yang, XJ
AF Wang, Yanzhen
   Serracino-Inglott, Ferdinand
   Yi, Xiaodong
   Yuan, Xue-Feng
   Yang, Xue-Jun
TI Real-time Simulation of Catheterization in Endovascular Surgeries
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE deformable modeling; surgery simulation; catheterization; contact
   handling
AB This paper proposes an efficient and stable numerical method for modeling catheterization during endovascular surgeries. The guidewire-catheter combination is treated as an elastic rod, which has very large resistance against twisting about its medial axis. A torsion free assumption is made, and the physical behavior of the rod is predominately governed by stretching and bending energies. This simplification greatly reduces the computational complexity and makes the model more stable, while the simulation results are still realistic enough for its application in endovascular surgeries. A contact handling algorithm that directly makes use of the volume data of the relevant tissues is proposed to simulate the interaction between the guidewire-catheter combination and the aortic wall. During each simulation step, the penetration depth of each vertex in contact with the aortic wall is calculated using moving least squares surfaces, and the contact is then resolved in a position-based manner. A comprehensive quantitative evaluation of the rod model is performed to validate its accuracy. Finally, the proposed approach is applied in a prototype system for simulation of endovascular aneurysm repair surgeries. Its efficiency and effectiveness are demonstrated in a real-time interactive catheterization simulation. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Wang, Yanzhen; Yi, Xiaodong; Yang, Xue-Jun] Natl Univ Def Technol, Coll Comp, HPCL, Changsha, Hunan, Peoples R China.
   [Serracino-Inglott, Ferdinand] Manchester Royal Infirm, Manchester Acad Hlth Sci Ctr, Manchester, Lancs, England.
   [Yuan, Xue-Feng] Sun Yat Sen Univ, Natl Supercomp Ctr Guangzhou, Guangzhou, Guangdong, Peoples R China.
C3 National University of Defense Technology - China; University of
   Manchester; Sun Yat Sen University
RP Wang, YZ (corresponding author), Natl Univ Def Technol, Coll Comp, HPCL, Changsha, Hunan, Peoples R China.
EM yzwang@nudt.edu.cn
RI YANG, Xue/HPI-0953-2023
CR Alterovitz R, 2008, SPRINGER TRAC ADV RO, V50, P1
   [Anonymous], 1999, LEVEL SET METHODS FA
   [Anonymous], 2011, ACM T GRAPHICS
   [Anonymous], 1983, History of strength of materials
   Benedetti F., 2002, POSTGRADUATE COURSE
   Bergou M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360662
   Caselles V, 1997, IEEE T PATTERN ANAL, V19, P394, DOI 10.1109/34.588023
   Chen X, 2008, PROCEEDINGS OF 2008 INTERNATIONAL PRE-OLYMPIC CONGRESS ON COMPUTER SCIENCE, VOL II, P81
   Cheng Z.Q., 2008, VGPBG SIGGRAPH, P9
   Cotin S, 2005, LECT NOTES COMPUT SC, V3750, P534, DOI 10.1007/11566489_66
   Cotin S, 2000, Stud Health Technol Inform, V70, P59
   Heidelberger B., 2004, P VISION MODELING VI, P339
   Hirota G, 2003, VISUAL COMPUT, V19, P291, DOI 10.1007/s00371-002-0188-5
   Hong F, 2014, IEEE T VIS COMPUT GR, V20, P2545, DOI 10.1109/TVCG.2014.2346416
   Lenoir J, 2006, COMPUT GRAPH-UK, V30, P416, DOI 10.1016/j.cag.2006.02.013
   Lin Z., 2001, Selected papers from the Pan-Sydney workshop on Visualisation - Volume 2, VIP '00, V2, P31
   Martin S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778776
   Nowinski WL, 2001, INTERNATIONAL WORKSHOP ON MEDICAL IMAGING AND AUGMENTED REALITY, PROCEEDINGS, P87, DOI 10.1109/MIAR.2001.930269
   Satava RM, 2005, MINIM INVASIV THER, V14, P257, DOI 10.1080/13645700500274112
   Spillmann J, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P63
   Spillmann J, 2008, THESIS
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Wang WP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330513
NR 23
TC 4
Z9 4
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 185
EP 194
DI 10.1002/cav.1702
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300002
DA 2024-07-18
ER

PT J
AU Lee, J
   Lim, M
   Park, S
   Kim, H
   Ko, H
   Kim, JI
AF Lee, Jun
   Lim, Mingyu
   Park, SungJun
   Kim, HyungSeok
   Ko, Heedong
   Kim, Jee-In
TI Approximate resolution of asynchronous conflicts among sequential
   collaborations in dynamic virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE asynchronous collaboration; networked virtual environment;
   computer-aided design
AB Asynchronous collaboration for a networked virtual environment (NVE) has emerged as a promising area in collaborative computer-aided design applications. The concept of asynchronous collaboration is a sequential collaboration of temporal processes in an NVE where the participants are not required to be present at the time of the collaboration. Conflicts in asynchronous collaboration occur because the preceding task of a participant can influence the output of the ensuing task of another participant. The conflicted tasks must be modified manually. However, it requires considerable time and effort to resolve conflicts in a sequential collaboration. In this paper, we present an asynchronous collaborative framework that converts the conflict states of the shared objects into approximately resolved states. We develop a novel approximate resolution algorithm using a task-based modeling mechanism to resolve the asynchronous conflicts with their corresponding tasks. Moreover, we propose a visual relation editor for convenient management. The participants can set flexible relations among shared objects using the proposed visual editor. The proposed approximate resolution approach can significantly reduce the average resolution time and the number of required manual task resolutions in a virtual environment compared to a manual resolution approach. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Lee, Jun] Korea Inst Sci & Technol, Ctr Robot Res, Seoul, South Korea.
   [Lim, Mingyu; Kim, HyungSeok; Kim, Jee-In] Konkuk Univ, Dept Internet & Multimedia, Seoul, South Korea.
   [Park, SungJun] Hoseo Univ, Dept Game Engn, Seoul, South Korea.
   [Ko, Heedong] Korea Inst Sci & Technol, Imaging Media Res Ctr, Seoul, South Korea.
C3 Korea Institute of Science & Technology (KIST); Konkuk University; Hoseo
   University; Korea Institute of Science & Technology (KIST)
RP Kim, JI (corresponding author), Konkuk Univ, Dept Internet & Multimedia, Seoul, South Korea.
EM jnkm@konkuk.ac.kr
RI Lim, Mingyu/D-3819-2011
OI Lim, Mingyu/0000-0002-3749-1902; Kim, HyungSeok/0000-0003-4816-2992
FU Konkuk University
FX This paper was supported by Konkuk University in 2014.
CR [Anonymous], P COMP AN SOC AG 201
   [Anonymous], 2012, THESIS U GEORGIA ATH
   Co P, 2006, LEVEL DESIGN GAMES, P353
   Collins-Sussman B., 2004, VERSION CONTROL SUBV, P8
   Dodds TJ, 2009, COMPUT GRAPH-UK, V33, P130, DOI 10.1016/j.cag.2009.01.001
   ELNOZAHY EN, 1992, IEEE T COMPUT, V41, P526, DOI 10.1109/12.142678
   Greenhalgh C, 1997, PROCEEDINGS OF THE FIFTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P313
   Greenhalgh C, 2002, P IEEE VIRT REAL ANN, P101, DOI 10.1109/VR.2002.996512
   Greenhalgh C, 1997, BT TECHNOL J, V15, P101, DOI 10.1023/A:1018635613702
   Greenhalgh C, 2001, TNC 98 P TER NETW C, V198, P1677
   Joslin C, 2004, IEEE COMMUN MAG, V42, P28, DOI 10.1109/MCOM.2004.1284925
   Lee J, 2009, 2009 INTERNATIONAL SYMPOSIUM ON UBIQUITOUS VIRTUAL REALITY (ISUVR 2009), P68, DOI 10.1109/ISUVR.2009.14
   Lim M, 2012, ADV SCI LETT, V9, P677
   Lopez T, 2014, COMPUT ANIMAT VIRT W, V25, P487, DOI 10.1002/cav.1583
   Ogasawara H, 2008, 2008 22ND INTERNATIONAL WORKSHOPS ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOLS 1-3, P1040, DOI 10.1109/WAINA.2008.215
   Pardo R, 2010, GAM DEV C
   Perry L., 2002, GAME DEV, P30
   Ruddle R. A., 2002, ACM Transactions on Computer-Human Interaction, V9, P285, DOI 10.1145/586081.586084
   Steed A, 2010, NETWORKED GRAPHICS: BUILDING NETWORKED GAMES AND VIRTUAL ENVIRONMENTS, P1
NR 19
TC 1
Z9 1
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2016
VL 27
IS 2
BP 163
EP 180
DI 10.1002/cav.1669
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ2BZ
UT WOS:000374010000007
DA 2024-07-18
ER

PT J
AU Gutierrez-Garcia, JO
   Rodríguez, LF
AF Octavio Gutierrez-Garcia, J.
   Rodriguez, Luis-Felipe
TI Corruptible social agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE social agents; corruption; belief-desire-intention model; agent-based
   simulation; fuzzy logic
ID MODEL
AB Agent-based virtual simulations of social systems susceptible to corruption (e.g., police agencies) require agents capable of exhibiting corruptible behaviors to achieve realistic simulations and enable the analysis of corruption as a social problem. This paper proposes a formal belief-desire-intention framework supported by the functional event calculus and fuzzy logic for modeling corruption based on the integrity level of social agents and the influence of corrupters on them. Corruptible social agents are endowed with beliefs, desires, intentions, and corrupt-prone plans to achieve their desires. This paper also proposes a fuzzy logic system to define the level of impact of corruption-related events on the degree of belief in the truth of anti-corruption factors (e.g., the integrity of the leader of an organization). Moreover, an agent-based model of corruption supported by the proposed belief-desire-intention framework and the fuzzy logic system was devised and implemented. Results obtained from agent-based simulations are consistent with actual macro-level patterns of corruption reported in the literature. The simulation results show that (i) the bribery rate increases as more external entities attempt to bribe agents and (ii) the more anti-corruption factors agents believe to be true, the less prone to perpetrate acts of corruption. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Octavio Gutierrez-Garcia, J.] Inst Tecnol Autonomo Mexico, Dept Comp Sci, 1 Rio Hondo St, Mexico City 01080, DF, Mexico.
   [Rodriguez, Luis-Felipe] Inst Tecnol Sonora, Dept Comp Sci, Obregon 85000, Sonora, Mexico.
C3 Instituto Tecnologico Autonomo de Mexico
RP Gutierrez-Garcia, JO (corresponding author), Inst Tecnol Autonomo Mexico, Dept Comp Sci, 1 Rio Hondo St, Mexico City 01080, DF, Mexico.
EM octavio.gutierrez@itam.mx
RI Gutierrez-Garcia, J. Octavio/F-3983-2011; Gutierrez-Garcia, J.
   Octavio/R-4843-2019; Rodriguez, Luis-Felipe/AAI-5587-2020
OI Gutierrez-Garcia, J. Octavio/0000-0002-6252-6169; Gutierrez-Garcia, J.
   Octavio/0000-0002-6252-6169; Rodriguez, Luis-Felipe/0000-0001-8114-0299
FU Asociacion Mexicana de Cultura, A.C.; Mexican Council for Science and
   Technology (CONACYT) [216101]
FX The authors would like to thank the editors-in-chief and the anonymous
   referees for their comments and suggestions. This work has been
   supported by Asociacion Mexicana de Cultura, A.C. and by the Mexican
   Council for Science and Technology (CONACYT) through grant number
   216101.
CR [Anonymous], COMPUTATIONAL EC
   [Anonymous], WHY ARE SOME PUBLIC
   [Anonymous], 2013, EUROPEAN Q POLITICAL
   [Anonymous], SOCIAL SCI RES NETWO
   [Anonymous], P 9 JOINT INT C INF
   [Anonymous], 19 CTR SOC EC DYN
   Bac M, 2001, PUBLIC CHOICE, V107, P87, DOI 10.1023/A:1010349907813
   Baumeister R. F., 2001, Review of General Psychology, V5, P323, DOI [10.1037/1089-2680.5.4.323, DOI 10.1037/1089-2680.5.4.323]
   Cingolani P, 2012, IEEE INT CONF FUZZY
   Dignum Virginia., 2001, PROG ARTIF INTELL, P191
   Georgeff M, 1999, LECT NOTES ARTIF INT, V1555, P1
   Gilbert N., 2008, Agent-Based Models, DOI [10.4135/9781412983259, DOI 10.4135/9781412983259]
   Groenendijk N, 1997, CRIME LAW SOCIAL CH, V27, P207, DOI 10.1023/A:1008267601329
   Johnson KarlE., 2004, J AFR AMER HIST, V89, P118, DOI DOI 10.2307/4134096
   Lucas P, 2011, AI SOC, V26, P355, DOI 10.1007/s00146-010-0315-1
   Ma J, 2013, IEEE T SUSTAIN ENERG, V4, P200, DOI 10.1109/TSTE.2012.2212471
   Mueller ET, 2004, J LOGIC COMPUT, V14, P703, DOI 10.1093/logcom/14.5.703
   Novak Peter., 2006, AAMAS 06, P1009
   PEDRYCZ W, 1994, FUZZY SET SYST, V64, P21, DOI 10.1016/0165-0114(94)90003-5
   Porter LE, 2009, POLIC SOC, V19, P79, DOI 10.1080/10439460802457719
   Punch M., 2000, European Journal on Criminal Policy and Research, V8, P301
   Sah M., 2011, P 22 ACM C HYP HYP, P37, DOI [10.1145/1995966.1995975, DOI 10.1145/1995966.1995975]
   Vogt W., 1999, DICT STAT METHODOLOG
NR 23
TC 2
Z9 2
U1 0
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2016
VL 27
IS 2
BP 89
EP 102
DI 10.1002/cav.1613
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ2BZ
UT WOS:000374010000001
DA 2024-07-18
ER

PT J
AU Huang, ZP
   Gong, GH
   Han, L
AF Huang, Zhanpeng
   Gong, Guanghong
   Han, Liang
TI Vortex particle smoke simulation with an octree data structure
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE physically based method; fluid simulation; smoke animation; vortex
   particle method; octree structure
AB We propose an octree-based presentation of vortex particles to simulate smoke and gaseous phenomena in a physical way. Vortex particle method prevails over grid-based method in terms of less numerical dissipation and more detail features, but it suffers from heavy computational overhead due to per-particle Biot-Savart integration over the entire simulation space. To alleviate this problem, we employ an octree background grid to separate the vortex particles into individual groups. Particles in groups are aggregated as a single super vortex particle to reduce computational cost. The proposed method produces comparable visual result as previous methods with much less computational overhead. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Huang, Zhanpeng; Gong, Guanghong; Han, Liang] Beihang Univ, Adv Simulat Technol Lab, Haidian Dist Beijing 100191, Peoples R China.
   [Huang, Zhanpeng; Gong, Guanghong; Han, Liang] Beihang Univ, Adv Simulat Technol Lab, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Huang, ZP (corresponding author), Beihang Univ, Adv Simulat Technol Lab, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM soaroc@asee.buaa.edu.cn
RI Han, Liang/KFR-6745-2024
CR [Anonymous], P SIGGRAPH LOS ANG
   [Anonymous], P 20 ANN C COMP GRAP
   [Anonymous], P ACM SIGGRAPH EUR S
   [Anonymous], 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, DOI DOI 10.1145/1073368.1073380
   Ebert D. S., 1990, Computer Graphics, V24, P357, DOI 10.1145/97880.97918
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Foster N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P181, DOI 10.1145/258734.258838
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Gamito MN, 1995, P 6 EUR WORKSH COMP, P3
   Gardner G. Y., 1985, Computer Graphics, V19, P297, DOI 10.1145/325165.325248
   He S, 2011, COMPUTER ANIMATION V, V22
   Huang ZP, 2015, MULTIMED TOOLS APPL, V74, P7569, DOI 10.1007/s11042-014-1992-4
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Kawada G, 2011, P 2011 ACM SIGGRAPH
   Kwatra N, 2010, P 2010 ACM SIGGRAPH
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Park S. I., 2005, Computer Animation, Conference Proceedings, P261, DOI [DOI 10.1145/1073368.1073406, 10.1145/1073368.1073406]
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Pfaff T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185608
   Pfaff T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866196
   Pfaff T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618467
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   SAKAS G, 1990, EUROGRAPHICS 90, P519
   Schechter H., 2008, Symposium on Computer animation, P1
   Selle A, 2005, P SIGGRAPH 05 LOS AN
   Sewall J, 2008, GRAPHICAL MODELS, V71
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam Jos., 1995, Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, SIGGRAPH '95, P129
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Vines M, 2014, IEEE T VIS COMPUT GR, V20, P303, DOI 10.1109/TVCG.2013.95
   Weissmann S., 2010, ACM SIGGRAPH 2010 papers on-SIGGRAPH '10, P1, DOI DOI 10.1145/1833349.1778852
   WINCKELMANS GS, 1993, J COMPUT PHYS, V109, P247, DOI 10.1006/jcph.1993.1216
   Yaeger L, 1986, P SIGGRAPH 86 C P 19, P85
   Yuan Z, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024170
   [No title captured]
   [No title captured]
NR 36
TC 3
Z9 3
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2016
VL 27
IS 1
BP 14
EP 23
DI 10.1002/cav.1625
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4BX
UT WOS:000369868600002
OA Bronze
DA 2024-07-18
ER

PT J
AU Saito, S
   Umetani, N
   Morishima, S
AF Saito, Shunsuke
   Umetani, Nobuyuki
   Morishima, Shigeo
TI Macroscopic and microscopic deformation coupling in up-sampled cloth
   simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE homogenization; cloth simulation; model reduction; up-sampling
ID REAL-TIME SIMULATION
AB Various methods of predicting the deformation of fine-scale cloth from coarser resolutions have been explored. However, the influence of fine-scale deformation has not been considered in coarse-scale simulations. Thus, the simulation of highly nonhomogeneous detailed cloth is prone to large errors. We introduce an effective method to simulate cloth made of nonhomogeneous, anisotropic materials. We precompute a macroscopic stiffness that incorporates anisotropy from the microscopic structure, using the deformation computed for each unit strain. At every time step of the simulation, we compute the deformation of coarse meshes using the coarsened stiffness, which saves computational time and add higher-level details constructed by the characteristic displacement of simulated meshes. We demonstrate that anisotropic and inhomogeneous cloth models can be simulated efficiently using our method. (c) 2014 The Authors. Computer Animation and Virtual Worlds published by John Wiley & Sons, Ltd.
C1 [Saito, Shunsuke] Waseda Univ, Dept Appl Phys, Shinjuku Ku, Tokyo, Japan.
   [Umetani, Nobuyuki] Univ Tokyo, Bunkyo Ku, Tokyo 113, Japan.
   [Morishima, Shigeo] Waseda Univ, Res Inst Sci & Engn, Shinjuku Ku, Tokyo, Japan.
C3 Waseda University; University of Tokyo; Waseda University
RP Saito, S (corresponding author), Waseda Univ, Shinjuku Ku, 3-4-1 Okubo, Tokyo, Japan.
EM shun-1616@moegi.waseda.jp
OI Morishima, Shigeo/0000-0001-8859-6539
FU JST CREST
FX The authors thank Tiantina Liu and Craig Schroeder for their helpful
   suggestions. This research is supported by JST CREST.
CR [Anonymous], ACM T GRAPH
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bender J, 2013, COMPUT GRAPH-UK, V37, P945, DOI 10.1016/j.cag.2013.08.003
   Bergou M, 2007, ACM T GRAPHIC, P50
   Bonet J., 1997, Nonlinear continuum mechanics for finite element analysis
   Bridson R., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P28
   Chen L, 2011, IEIT J ADAPTIVE DYNA, V2012, P28
   Choi KJ, 2005, COMPUT AIDED DESIGN, V37, P585, DOI 10.1016/j.cad.2004.11.002
   Choi MG, 2005, IEEE T VIS COMPUT GR, V11, P91
   Choi MG, 2007, COMPUT GRAPH FORUM, V26, P349, DOI 10.1111/j.1467-8659.2007.01057.x
   Etzmuss O, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P244, DOI 10.1109/PCCGA.2003.1238266
   Farmer CL, 2002, INT J NUMER METH FL, V40, P63, DOI 10.1002/fld.267
   Faure F, 2011, ACM T GRAPHIC, V30, P73
   Feng W, 2010, ACM T GRAPHIC, V29, P108
   Goldenthal R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239500
   Grinspun E., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P62
   Jeon I, 2013, COMPUT GRAPH FORUM, V32, P31, DOI 10.1111/cgf.12209
   Kaldor JM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778842
   Kang YM, 2001, VISUAL COMPUT, V17, P147, DOI 10.1007/s003710100103
   Kavan L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964988
   Kelager M, 2010, P WORKSH VIRT REAL I, P31, DOI [10.2312/PE/vriphys/vriphys10/031-037, DOI 10.2312/PE/VRIPHYS/VRIPHYS10/031-037]
   Kharevych L, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1531326.1531357, 10.1145/15313261531357]
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muller M., 2011, WORKSH VIRT REAL INT, P83
   Muller M, 2011, ACM T GRAPHIC, V30, P92
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   Muller Matthias, 2010, Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P85, DOI [10.5555/1921427.19214412, DOI 10.5555/1921427.19214412]
   Nesme M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531358
   Oh S, 2008, COMPUT ANIMAT VIRT W, V19, P479, DOI 10.1002/cav.255
   Selle A, 2009, IEEE T VIS COMPUT GR, V15, P339, DOI 10.1109/TVCG.2008.79
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Thomaszewski B., 2006, Proceedings of the 2006 ACM SIGGRAPH/Eurographics symposium on Computer animation, P107
   Wang H, 2010, ACM T GRAPHICS TOG, V29, P107
   Yuksel C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185533
   Zurdo Javier S, 2012, IEEE T VISUALIZATION, V19, P149
NR 35
TC 2
Z9 2
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 437
EP 446
DI 10.1002/cav.1589
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300024
DA 2024-07-18
ER

PT J
AU Shapiro, A
   Feng, A
   Wang, RZ
   Li, H
   Bolas, M
   Medioni, G
   Suma, E
AF Shapiro, Ari
   Feng, Andrew
   Wang, Ruizhe
   Li, Hao
   Bolas, Mark
   Medioni, Gerard
   Suma, Evan
TI Rapid avatar capture and simulation using commodity depth sensors
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE image capture; animation; avatar
ID IMAGE
AB We demonstrate a method of acquiring a 3D model of a human using commodity scanning hardware and then controlling that 3D figure in a simulated environment in only a few minutes. The model acquisition requires four static poses taken at 90 degrees angles relative to each other. The 3D model is then given a skeleton and smooth binding information necessary for control and simulation. The 3D models that are captured are suitable for use in applications where recognition and distinction among characters by shape, form, or clothing is important, such as small group or crowd simulations or other socially oriented applications. Because of the speed at which a human figure can be captured and the low hardware requirements, this method can be used to capture, track, and model human figures as their appearances change over time. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Shapiro, Ari; Feng, Andrew; Bolas, Mark; Suma, Evan] Univ So Calif, Inst Creat Technol, Playa Vista, CA 90094 USA.
   [Wang, Ruizhe; Li, Hao; Medioni, Gerard] Univ So Calif, Los Angeles, CA 90089 USA.
C3 University of Southern California; University of Southern California
RP Shapiro, A (corresponding author), Univ So Calif, Inst Creat Technol, Playa Vista, CA 90094 USA.
EM shapiro@ict.usc.edu
RI Wang, Ruizhe/Q-5642-2017
OI Li, Hao/0000-0002-4019-3420; Suma Rosenberg, Evan/0000-0002-4826-4561
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Bharaj G., 2011, COMPUT GRAPH FORUM, V30, P755
   Buss S. R., 2004, TECHNICAL REPORT IEE
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Chuang M, 2009, COMPUTER GRAPHICS FO, V28
   Dionne O, 2013, P 12 ACM SIGGRAPH EU
   Feng A, 2013, COMPUTER ANIMATION V, V25, P3
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Jain A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866174
   Kazhdan M., 2006, P 4 EUROGRAPHICS S G
   Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508407
   McDonnell R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360625
   McDonnell R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531361
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Rusinkiewicz S, 2001, 2001 P 3 INT C 3 D D
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Vlasic Daniel, 2009, ACM T GRAPHICS
   Wang RZ, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P432, DOI 10.1109/3DIMPVT.2012.57
   Wang X, 2014, 2014 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY
   Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465
   Wu C, 2013, ACM T GRAPHICS, V32
   Yan Cui, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P133, DOI 10.1007/978-3-642-37484-5_12
   Zeng M, 2013, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2013.26
NR 25
TC 47
Z9 52
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 201
EP 211
DI 10.1002/cav.1579
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ben Moussa, M
   Magnenat-Thalmann, N
AF Ben Moussa, Maher
   Magnenat-Thalmann, Nadia
TI Toward socially responsible agents: integrating attachment and learning
   in emotional decision-making
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE emotional decision-making; affective computing; virtual humans; robots;
   interaction
ID MEMORY; MODEL
AB Our goal is to create socially responsible agents, either robots or virtual humans. In this paper, we present an integration of emotions, attachment, and learning in emotional decision-making to achieve this goal. Based on emerging psychological theories, we aim at building human-like emotional decision-making, where emotions play a central role in selecting the next action to be performed by the agent. Here, we present our own approach for emotion appraisal where we use emotional attachment as an important impulse for determining the intensities of emotions. Emotions in their turn are used to calculate the emotional attachment toward the users and for learning to predict future consequences. We report on the results of a simulation evaluation where we assess the influence of emotions, attachment, and learning on decision-making. It is our strong belief that by giving an agent the ability to have emotions and to feel empathy and emotional attachment toward others, we will ultimately give this agent the ability to learn and improve its social behavior skills through interactions with the users and through user feedback. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Ben Moussa, Maher; Magnenat-Thalmann, Nadia] Univ Geneva, MIRALab, CH-1227 Carouge, Switzerland.
C3 University of Geneva
RP Ben Moussa, M (corresponding author), Univ Geneva, MIRALab, 7 Route Drize, CH-1227 Carouge, Switzerland.
EM benmoussa@miralab.ch
RI Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Nadia/0000-0002-1459-5960
FU European research project 3DLife NoE [IST-FP7 247688]; Swiss National
   Science Foundation project AerialCrowds [CRSI20-122696]
FX The research has been funded by the European research project 3DLife NoE
   (IST-FP7 247688) and the Swiss National Science Foundation project
   AerialCrowds (CRSI20-122696). Furthermore, we would like to thank
   Ulysses Bernardet for his scientific support.
CR [Anonymous], 2007, The emotional construction of morals
   Bui T, 2002, ADV ARTIFICIAL INTEL, V2479, p1 9
   El-Nasr MS, 2000, AUTON AGENT MULTI-AG, V3, P219, DOI 10.1023/A:1010030809960
   Gadanho SC, 2001, CYBERNET SYST, V32, P531, DOI 10.1080/019697201750257766
   Gebhard P, 2005, ARTIFICIAL INTELLIGE
   Hudlicka E., 2007, INTEGRATED MODELS CO, P263
   Kasap Z, 2009, IEEE COMPUT GRAPH, V29, P20, DOI 10.1109/MCG.2009.26
   Levy David., 2007, LOVE SEX ROBOTS
   Loewenstein G, 2003, SER AFFECTIVE SCI, P619
   Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005
   Moussa MB, 2010, P SUMM SCH ENG ZERM
   Moussa MB, 2012, P 6 INT S E HLTH SER, P64
   Ortony A, 1992, COGNITIVE STRUCTURE
   Peters E, 2006, CONSTRUCTION OF PREFERENCE, P454, DOI 10.1017/CBO9780511618031.025
   Pfister HR, 2008, JUDGM DECIS MAK, V3, P5
   Pontier M, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P279
   Russell S., 2010, ARTIF INTELL, V3rd
   Suddendorf T, 2007, BEHAV BRAIN SCI, V30, P299, DOI 10.1017/S0140525X07001975
   TULVING E, 1985, CAN PSYCHOL, V26, P1, DOI 10.1037/h0080017
   Watkins C. J. C. H., 1989, LEARNING DELAYED REW
NR 20
TC 9
Z9 9
U1 3
U2 18
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 327
EP 334
DI 10.1002/cav.1515
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500020
DA 2024-07-18
ER

PT J
AU Le Naour, T
   Courty, N
   Gibet, S
AF Le Naour, T.
   Courty, N.
   Gibet, S.
TI Spatiotemporal coupling with the 3D+t motion Laplacian
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character animation; spatial relationship; motion editing; motion
   retargeting
ID DEFORMATION
AB Motion editing requires the preservation of spatial and temporal information of the motion. During editing, this information should be preserved at best. We propose a new representation of the motion based on the Laplacian expression of a 3D+t graph: the set of connected graphs given by the skeleton over time. Through this Laplacian representation of the motion, we propose an application that allows an easy and interactive editing, correction, or retargeting of a motion. The new created motion is the result of the combination of two minimizations, linear and non-linear: the first penalizes the difference of energy between the Laplacian coordinates from an animation to the desired one. The other one preserves the length of segments. Using several examples, we demonstrate the benefits of our method and in particularly the preservation of the spatiotemporal properties of the motion in an interactive context. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Le Naour, T.; Courty, N.; Gibet, S.] IRISA UBS, Vannes, Bretagne, France.
RP Le Naour, T (corresponding author), Univ Bretagne Sud, IRISA UBS, Rennes, France.
EM thibaut.le-naour@univ-ubs.fr
OI Le Naour, Thibaut/0000-0003-4476-6617
CR Alexa M, 2003, VISUAL COMPUT, V19, P105, DOI 10.1007/s00371-002-0180-0
   [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Belyaev A, 2006, MPII20064005
   Budd C, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P61, DOI 10.1109/CVMP.2009.27
   Chai JX, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239459
   Courty N, 2010, COMPUTER ANIMATION V, V21, P1
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Henry Joseph., 2012, Proceedings of the 11th ACM SIGGRAPH / Eurographics conference on Computer Animation, EUROSCA'12, P193
   Hetroy F., 2012, RR8003 INRIA
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Ikemoto L, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477927
   Kim M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531385
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   Le Callennec B, 2006, GRAPH MODELS, V68, P175, DOI 10.1016/j.gmod.2005.03.001
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Meyer Mark., 2002, Discrete differential-geometry operators for triangulated 2-manifolds
   Sorkine O, 2006, COMPUT GRAPH FORUM, V25, P789, DOI 10.1111/j.1467-8659.2006.00999.x
   Tak S, 2005, ACM T GRAPHIC, V24, P98, DOI 10.1145/1037957.1037963
   Takahashi S, 2009, COMPUT GRAPH FORUM, V28, P639, DOI 10.1111/j.1467-8659.2009.01404.x
   Weng YL, 2006, VISUAL COMPUT, V22, P653, DOI 10.1007/s00371-006-0054-y
NR 21
TC 7
Z9 8
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 419
EP 428
DI 10.1002/cav.1518
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500029
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Buche, C
   Jeannin-Girardon, A
   De Loor, P
AF Buche, Cedric
   Jeannin-Girardon, Anne
   De Loor, Pierre
TI Simulation theory and anticipation for interactive virtual character in
   an uncertain world
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE anticipation; real-time interaction; decision making; behavioral model;
   virtual juggler; virtual character; computer animation
AB This paper deals with simulations of real-time interactive character behavior. The underlying idea is to take into account principles from cognitive science, in particular, the human ability to anticipate and simulate the world behavior. For that purpose, we propose a conceptual framework where the entity possesses an autonomous world of simulation within simulation, in which it can simulate itself (with its own model of behavior) and the environment (with an abstract representation, which can be learnt, of the other entities behaviors). This principle is illustrated by the development of an artificial juggler, which predicts the motion of balls in the air and uses its predictions to coordinate its own behavior while juggling. Thanks to this model it is possible to add a human user to launch balls that the virtual juggler can catch whilst juggling. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Buche, Cedric; Jeannin-Girardon, Anne; De Loor, Pierre] ENIB UEB CERV, Dept Comp Sci, Plouzane, France.
C3 Ecole Nationale d'Ingenieurs de Brest (ENIB)
RP Buche, C (corresponding author), ENIB UEB CERV, Dept Comp Sci, Plouzane, France.
EM buche@enib.fr
RI De Loor, Pierre/AAP-7967-2020
CR [Anonymous], 1999, Proceedings of the SIGCHI conference on human factors in computing systems, DOI [10.1145/302979.303150, DOI 10.1145/302979.303150]
   AUBRY M, 2010, CASA 2010
   BADLER NI, 1995, PACIFIC GRAPHICS 95
   Bergson H., 1896, Matiere et memoire.
   Berthoz Alain, 1997, Le sens du mouvement
   Brunia CHM, 1999, ACTA PSYCHOL, V101, P213, DOI 10.1016/S0001-6918(99)00006-2
   Buche C, 2010, COMPUT ANIMAT VIRT W, V21, P573, DOI 10.1002/cav.363
   Cassell J., 1994, P 21 ANN C COMP GRAP, P413, DOI DOI 10.1145/192161.192272
   Hesslow G, 2002, TRENDS COGN SCI, V6, P242, DOI 10.1016/S1364-6613(02)01913-7
   Julliard F, 1999, LECT NOTES ARTIF INT, V1739, P265
   Kipp M, 2007, LECT NOTES ARTIF INT, V4722, P15
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S, 2010, SPEECH COMMUN, V52, P587, DOI 10.1016/j.specom.2010.02.007
   LAIRD JE, 2008, P 1 C ART GEN INT, P224
   Lamarche F., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P1309
   LOYALL AB, 2004, SCA 04, P59
   Multon F, 2001, VISUAL COMPUT, V17, P91, DOI 10.1007/s003710000086
   NIEWIADOMSKI R, 2009, INT JOINT C AUT AG M, P1399
   Prepin K, 2007, ADV ROBOTICS, V21, P1709, DOI 10.1163/156855307782506192
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0
   Rosen R., 1985, Anticipatory systems: Philosophical, mathematical, and methodological foundations (ifsr international series on systems science and engineering)
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   VANWELBERGEN H, 2009, EUROGRAPHICS STATE A, P45
   VANWELBERGEN H, 2010, MOG 2010, V1002
NR 24
TC 2
Z9 2
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 133
EP 139
DI 10.1002/cav.401
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hu, N
   Zhou, SP
   Wu, ZK
   Zhou, MQ
   Cho, BEK
AF Hu, Nan
   Zhou, Suiping
   Wu, Zhongke
   Zhou, Mingquan
   Cho, Benjamin Eng Keong
TI Spatial-temporal patterns and pedestrian simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE navigational behavior; pedestrian simulation; spatial-temporal patterns
ID CROWD; NAVIGATION; MODEL
AB In this paper, we propose a framework for modeling lower-level pedestrian navigational behaviors. We aim not only to generate realistic simulation results but also to make our framework flexible and extendible, and easy to use for model developers. A divide-and-conquer methodology is first adopted to divide the complex navigational behaviors into three levels, which allows us to focus on the intermediate level. We then propose a pattern-based framework for modeling pedestrian navigational behavior at this level. In our framework, spatial-temporal patterns are used to represent the situational perception, and a pattern-matching mechanism is proposed to model the navigational choices of individual pedestrians. To demonstrate the effectiveness of our framework, a computational model is constructed to simulate pedestrian behaviors in a corridor with medium to relatively high density of pedestrians. Simulation results with this model are summarized in this paper. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Hu, Nan] Nanyang Technol Univ, Sch Comp Engn, Parallel & Distributed Comp Ctr, Singapore, Singapore.
   [Zhou, Suiping] China Aerosp Corp, Beijing Simulat Ctr, Beijing, Peoples R China.
   [Zhou, Suiping] Weizmann Inst Sci, IL-76100 Rehovot, Israel.
   [Wu, Zhongke; Zhou, Mingquan] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
C3 Nanyang Technological University; Weizmann Institute of Science; Beijing
   Normal University
RP Hu, N (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Parallel & Distributed Comp Ctr, Singapore, Singapore.
EM HUNA0002@ntu.edu.sg
RI ha, na/KHE-4563-2024
CR [Anonymous], P 1 INT WORKSH CROWD
   [Anonymous], 1997, Naturalistic decision making
   [Anonymous], 1981, NONVERBAL COMMUNICAT
   Dalton RC, 2003, ENVIRON BEHAV, V35, P107, DOI 10.1177/0013916502238867
   ENDSLEY MR, 1995, HUM FACTORS, V37, P65, DOI 10.1518/001872095779049499
   Feurtey F., 2000, SIMULATING COLLISION
   Goffman E., 1971, Relations in Public, DOI 10.1038/229103a0 16059101
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kapadia M, 2009, I3D 09 P 2009 S INT
   Klein G. A., 2017, SOURCES POWER PEOPLE
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   Lee KC, 2007, 2007 MOBILE NETWORKING FOR VEHICULAR ENVIRONMENTS, P109, DOI 10.1109/MOVE.2007.4300814
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   LOSCOS C, 2003, P THEOR PRACT COMP G
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Paris S, 2006, COMPUT ANIMAT VIRT W, V17, P325, DOI 10.1002/cav.136
   Pelechano N., 2007, P 2007 ACM SIGGRAPH
   Pettré J, 2006, COMPUT ANIMAT VIRT W, V17, P445, DOI 10.1002/cav.147
   Reynolds C. W., 1999, P GAM DEV C, P763
   Ronald Nicole, 2007, International Journal of Simulation: Systems, Science & Technology, V8, P25
   Shao W., 2005, P 2005 ACM SIGGRAPH
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Ulicny B, 2002, COMPUT GRAPH FORUM, V21, P767, DOI 10.1111/1467-8659.00634
   ULICNY B, 2001, P EUR WORKSH COMP AN
   Wolff M., 1973, PEOPLE PLACES, P35
NR 26
TC 1
Z9 1
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 387
EP 399
DI 10.1002/cav.341
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400025
DA 2024-07-18
ER

PT J
AU Jeon, J
   Jang, H
   Lim, SB
   Choy, YC
AF Jeon, Jaewoong
   Jang, Hyunho
   Lim, Soon-Bum
   Choy, Yoon-Chul
TI A sketch interface to empower novices to create 3D animations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE sketch interface; multiple-pass sketching; computer animation
AB We introduce a multiple-pass sketch-based user interface, designed for novice users, which avoids spatial ambiguities and hence allows considerable freedom in creating 3D animations. The user first draws the path along which a character or object is to move. A vertical motion window is then erected along this path, on which the user specifies the character's gestures or the object's vertical movements. A further cross-motion window can be used to add detail to the movements of the object. Window-specific camera modules present the user with appropriate views, extending the fluidity of pencil and paper to 3D. A usability study involving 60 users, who were previously unfamiliar with 3D animation tools, demonstrated that the proposed interface is easy to learn and effective in use. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Jeon, Jaewoong] Yonsei Univ, Multimedia Graph Lab, Dept Comp Sci, Seoul 120749, South Korea.
   [Choy, Yoon-Chul] Korea Multimedia Soc, Seoul, South Korea.
C3 Yonsei University
RP Jeon, J (corresponding author), Yonsei Univ, Multimedia Graph Lab, Dept Comp Sci, 134 Shinchon Dong Sudaemoon ku, Seoul 120749, South Korea.
EM demiblue@gmail.com
CR [Anonymous], AUTODESK 3DS MAX 200
   ARIKAN O, 2002, P 29 ANN C COMP GRAP, P483
   BALAGUER JF, 1995, COMPUT GRAPH FORUM, V14, pC241, DOI 10.1111/j.1467-8659.1995.cgf143_0241.x
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Callahan J., 1988, P ACM CHI C HUMAN FA, P95, DOI DOI 10.1145/57167.57182
   Chaudhuri P, 2004, COMPUT GRAPH FORUM, V23, P411, DOI 10.1111/j.1467-8659.2004.00772.x
   Chetverikov D, 2003, LECT NOTES COMPUT SC, V2756, P746
   Dontcheva M, 2003, ACM T GRAPHIC, V22, P409, DOI 10.1145/882262.882285
   FEI G, 2008, P VRCAI 2008, P1
   Fitzmaurice G, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1361
   Hachet M, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P83
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   IGARASHI T, 1998, P 11 ANN ACM S US IN, P173, DOI DOI 10.1145/288392.288599
   Igarashi T., 2005, Proceedings of the 2005 acm siggraph/eurographics symposium on computer animation, P107, DOI DOI 10.1145/1073368.1073383
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee Jehee., 2002, Proceedings of the 29th annual conference on Computer graphics and interactive techniques, P491, DOI DOI 10.1145/566570.566607
   McCann J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276385, 10.1145/1239451.1239457]
   Park S, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P105, DOI 10.1109/MOTION.2002.1182221
   Popovic J, 2003, ACM T GRAPHIC, V22, P1034, DOI 10.1145/944020.944025
   SUTHERLAND IE, 1964, DAC 64
   Terra S.C. L., 2004, Proceedings of ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P253, DOI DOI 10.1145/1028523.1028556
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   vandePanne M, 1997, COMPUT GRAPH FORUM, V16, P211, DOI 10.1111/1467-8659.00181
   Xin M., 2008, P 2008 ACM S VIRT RE, P223, DOI [DOI 10.1145/1450579.1450627, 10.1145/1450579.1450627]
   Zeleznik R. C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P163, DOI 10.1145/237170.237238
NR 25
TC 9
Z9 11
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 423
EP 432
DI 10.1002/cav.353
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400028
OA Bronze
DA 2024-07-18
ER

PT J
AU Kang, SH
   Gratch, J
AF Kang, Sin-Hwa
   Gratch, Jonathan
TI Virtual humans elicit socially anxious interactants' verbal
   self-disclosure
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE virtual humans; social anxiety; self-disclosure; contingent non-verbal
   feedback; rapport; virtual agents; anonymity; evaluation
ID PUBLIC SPEAKING; ANXIETY; CONSCIOUSNESS
AB We explored the relationship between interactants' social anxiety and the interactional fidelity of virtual humans. We specifically addressed whether the contingent non-verbal feedback of virtual humans affects the association between interactants' social anxiety and their verbal self-disclosure. This subject was investigated across three experimental conditions where participants interacted with real human videos and virtual humans in computer-mediated interview interactions. The results demonstrated that socially anxious people revealed more information and greater intimate information about themselves when interacting with a virtual human when compared with real human video interaction, whereas less socially anxious people did not show this difference. We discuss the implication of this association between the interactional fidelity of virtual humans and social anxiety in a human interactant on the design of an embodied virtual agent for social skills' training and psychotherapy. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Kang, Sin-Hwa; Gratch, Jonathan] Univ So Calif, Inst Creat Technol, Dept Comp Sci, USCs Computat Emot Grp, Marina Del Rey, CA 90292 USA.
C3 University of Southern California
RP Kang, SH (corresponding author), Univ So Calif, Inst Creat Technol, Dept Comp Sci, USCs Computat Emot Grp, 13274 Fiji Way, Marina Del Rey, CA 90292 USA.
EM kang@ict.usc.edu
CR Altman I., 1973, Social penetration: The development of interpersonal relationships
   [Anonymous], CONTENT ANAL INTRO I
   [Anonymous], 1983, REVISED CHEEK BUSS S
   Antheunis M. L., 2009, INT COMM ASS C
   Bailenson JN, 2006, PRESENCE-VIRTUAL AUG, V15, P359, DOI 10.1162/pres.15.4.359
   BICKMORE T, 2006, P CHI, P550
   COZBY PC, 1973, PSYCHOL BULL, V79, P73, DOI 10.1037/h0033950
   Gratch J, 2007, LECT NOTES ARTIF INT, V4722, P125
   Gratch J, 2006, LECT NOTES ARTIF INT, V4133, P14
   Herbelin B., 2005, THESIS I SYSTEMES IN
   Hopko DR, 2005, J PERS ASSESS, V84, P185, DOI 10.1207/s15327752jpa8402_08
   James LK, 2003, CYBERPSYCHOL BEHAV, V6, P237, DOI 10.1089/109493103322011515
   Joinson A.N., 2007, SELF DISCLOSURE PRIV
   KALLMANN M, 2005, P IVA, P253
   KANG S, 2008, P CHI, P1535
   KANG SH, 2008, P 7 INT JOINT C AUT, P120
   MACRORIE M, 2009, P IVA, P27
   Moon Y, 2000, J CONSUM RES, V26, P323, DOI 10.1086/209566
   Myers D.G., 2015, EXPLORING SOCIAL PSY, V7th
   Nowak KL, 2005, J COMPUT-MEDIAT COMM, V11
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   RENO RR, 1992, J PERS, V60, P79, DOI 10.1111/j.1467-6494.1992.tb00266.x
   Rickenberg Raoul, 2000, P SIGCHI C HUM FACT, P49
   Roberson-Nay R, 2007, PSYCHOL ASSESSMENT, V19, P133, DOI 10.1037/1040-3590.19.1.133
   Robins B., 2005, Universal Access in the Information Society, V4, P105, DOI 10.1007/s10209-005-0116-3
   SCHEIER MF, 1985, J APPL SOC PSYCHOL, V15, P687, DOI 10.1111/j.1559-1816.1985.tb02268.x
   Schouten AP, 2007, MEDIA PSYCHOL, V10, P292, DOI 10.1080/15213260701375686
   Slater M, 1999, IEEE COMPUT GRAPH, V19, P6, DOI 10.1109/38.749116
   Stricker G., 1990, Self-disclosure in the therapeutic relationship
   Tartaro A, 2007, P CHI, P1677
   ter Wat M, 2009, LECT NOTES ARTIF INT, V5773, P467, DOI 10.1007/978-3-642-04380-2_51
   Tickle-Degnen Linda, 1990, Psychological Inquiry, V1, P285, DOI DOI 10.1207/S15327965PLI01041
   Tidwell LC, 2002, HUM COMMUN RES, V28, P317, DOI 10.1093/hcr/28.3.317
   ZANBAKA C, 2007, P CHI, P561
NR 34
TC 73
Z9 81
U1 6
U2 44
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 473
EP 482
DI 10.1002/cav.345
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400033
DA 2024-07-18
ER

PT J
AU Yu, J
   Liu, DQ
   Seah, HS
AF Yu, Jun
   Liu, Dongquan
   Seah, Hock Soon
TI Transductive graph based cartoon synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE cartoon; computer-assisted; inbetweening; reusing; correspondence;
   transductive graph
AB To reduce tedious works in cartoon animation, some computer-assisted systems including automatic inbetweening and cartoon reusing systems have been proposed. In existing automatic inbetweening systems, accurate correspondence construction, which is a prerequisite for inbetweening, cannot be achieved. For cartoon reusing systems, the lack of efficient similarity estimation method and reusing mechanism makes it impractical for the users. The Transductive Graph based Cartoon Synthesis (TGCS) approach proposed in this paper aims at synthesizing smooth cartoons from the existing data. In this approach, the similarity between cartoon frames can be accurately evaluated by calculating the distance based on local shape context, which is rotation, and scaling invariant. According to the similarity, the label propagation based graph transduction method is adopted to generate cartoon clips, which is smoother than the clips generated by the shortest path method used in previous cartoon reusing approaches. Besides, the synthesized cartoon clips can be applied in accurate correspondence building, based on which the inbetweening method can be used to refine the results. Experimental results on our cartoon dataset suggest the effectiveness of the proposed approach for cartoon synthesis. Additional experiments on correspondence show our approach's performance on accurate correspondence building. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Yu, Jun; Seah, Hock Soon] Nanyang Technol Univ, Sch Comp Engn, GameLAB, Singapore 636798, Singapore.
C3 Nanyang Technological University
RP Yu, J (corresponding author), Nanyang Technol Univ, Sch Comp Engn, GameLAB, Singapore 636798, Singapore.
EM yujun@ntu.edu.sg
RI Seah, Hock Soon/AAK-9900-2020
OI Seah, Hock Soon/0000-0003-2699-7147
CR [Anonymous], P S COMP AN
   [Anonymous], 1995, P 22 ANN C COMP GRAP, DOI DOI 10.1145/218380.218417
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   CATMULL E, 1978, P SIGGRAPH 78, P348
   CHANG C, 1998, VISUALIZATION COMPUT, V8, P165
   Chen Q, 2006, COMPUT ANIMAT VIRT W, V17, P189, DOI 10.1002/cav.122
   DURAND CX, 1991, COMPUT GRAPH, V15, P285, DOI 10.1016/0097-8493(91)90081-R
   Kort A., 2002, NPAR 02, P125, DOI DOI 10.1145/508530.508552
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Papadimitriou C., 1992, COMBINATORIAL OPTIMI
   Seah HS, 2001, CAD/GRAPHICS '2001: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN AND COMPUTER GRAPHICS, VOLS 1 AND 2, P193
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TVERSKY A, 1970, J MATH PSYCHOL, V7, P572, DOI 10.1016/0022-2496(70)90041-6
   WALLACH MA, 1958, PSYCHOL REV, V65, P103, DOI 10.1037/h0042908
   WILLIAM H, 2005, P INT C COMP GRAPH I, P245
   Yang Y, 2009, PR ELECTROMAGN RES S, P311, DOI 10.1145/1631272.1631316
   Yang YS, 2009, PROCEEDINGS OF 2009 CONFERENCE ON SYSTEMS SCIENCE, MANAGEMENT SCIENCE & SYSTEM DYNAMICS, VOL 8, P175, DOI 10.1145/1631272.1631298
   Yu J, 2007, COMPUT ANIMAT VIRT W, V18, P571, DOI 10.1002/cav.189
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhuang YT, 2008, COMPUT ANIMAT VIRT W, V19, P355, DOI 10.1002/cav.258
NR 21
TC 3
Z9 3
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 277
EP 288
DI 10.1002/cav.355
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400015
DA 2024-07-18
ER

PT J
AU Yan, H
   Wang, ZY
   He, JA
   Chen, X
   Wang, CB
   Peng, QS
AF Yan, He
   Wang, Zhangye
   He, Jian
   Chen, Xi
   Wang, Changbo
   Peng, Qunsheng
TI Real-time fluid simulation with adaptive SPH
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE physically based fluid simulation; adaptive SPH; adaptive surface
   tension model; GPU
AB We present a new adaptive model for real-time fluid simulation based on Smoothed Particle Hydrodynamics (SPH) framework. Unlike traditional time-consuming SPH methods, our model can simulate fluid at a considerably faster speed without losing realism. In our model, we first introduce the non-uniform particle system and propose a generalized distance field function Which considers not only geometrical complexity but also physical complexity of fluid body. And the new sampling rules for splitting and merging of particles are also presented. This can greatly reduce the computation time of the dynamic fluid simulation. Then, a new pressure state equation and an adaptive surface tension model are proposed to enhance the stability of the system and to make the free surface more realistic. To further accelerate the computation, a special fluid solver is designed and implemented using GPU. Various fluid phenomena like breaking Wave and flood are simulated at real-time. Experiments demonstrate that our new adaptive model can greatly enhance the computation efficiency of fluid simulation compared With previous adaptive methods. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Yan, He; Wang, Zhangye; He, Jian; Chen, Xi; Peng, Qunsheng] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
   [Wang, Changbo] E China Normal Univ, Inst Software Engn, Shanghai, Peoples R China.
C3 Zhejiang University; East China Normal University
RP Wang, ZY (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
EM zywang@cad.zju.edu.cn
RI Zhou, Hong/JKJ-1067-2023
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Desbrun M., 1999, 3829 INRIA
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   JESCHKE S, 2003, WSCG POST P
   Kass M., 1990, P SIGGRAPH, P49
   Keiser R., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P125, DOI 10.1109/PBG.2005.194073
   LOSASSO F, 2008, IEEE T VISUALIZATION, P797
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   NGUYEN H, 2007, GRAPHIC GEMS
   PHARR M, 2005, GRAPHIC GEMS
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   Sethian J., 1999, LEVEL SET METHODS FA
   STAM J, 1995, INT C COMP GRAPH INT, P129
   Takeshita D, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P482, DOI 10.1109/PCCGA.2003.1238299
   Thürey N, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P39, DOI 10.1109/PG.2007.33
   Yuksel C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239550
NR 21
TC 26
Z9 36
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 417
EP 426
DI 10.1002/cav.300
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700034
DA 2024-07-18
ER

PT J
AU Choi, B
   You, M
   Noh, J
AF Choi, Byungkuk
   You, Mi
   Noh, Junyong
TI Extended spatial keyframing for complex character animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE performance-driven animation; character articulation; keyframing
ID MOTION
AB As 3D computer animation becomes snore accessible to novice users, it snakes it possible for these users to create high-quality animations. This paper introduces a more powerful system to create highly articulated character animations With an intuitive setup then the previous research, Spatial Keyframing (SK). As the main purpose of SK Was tire rapid generation of primitive animation over quality animation, we propose Extended Spatial Keyframing (ESK) that exploits a global control structure coupled With multiple sets of spatial keyframes, and hierarchical relationship between controllers. The generated structure can be flexibly embedded into the given rigged character, and the system enables tire given character to be animated delicately by user performance. During the performance, the movement of the highest ranking controllers' across the control hierarchy is recorded in layered style to increase tire level of detail for final motions. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Noh, Junyong] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Visual Media Lab, Taejon 305701, South Korea.
   [Noh, Junyong] Hollywood Visual Effects Co, Rhythm & Hues Studios, Venice, CA 90291 USA.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Noh, J (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Visual Media Lab, 335 Gwahangno, Taejon 305701, South Korea.
EM junyongnoh@kaist.ac.kr
RI Noh, Junyong/C-1663-2011
CR [Anonymous], 2000, Introduction to Time Series Analysis and Forecasting: with Application in SAS and SPSS
   *AUT INC, 2007, LEARN AUT MAYA 2008
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   BRUDERLIN A, AN INT AG WORKSH P I
   Terra SCL, 2007, GRAPH MODELS, V69, P89, DOI 10.1016/j.gmod.2006.09.002
   CLARK B, 2005, INSPIRED 3D ADV RIGG
   Dontcheva M, 2003, ACM T GRAPHIC, V22, P409, DOI 10.1145/882262.882285
   Eck M., 1991, CAD COMPUTERGRAPHIK, V13, P109
   Forsey D. R., 1988, Computer Graphics, V22, P205, DOI 10.1145/378456.378512
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   IGARASHI T, 2005, SCA 05, P107
   Lee J, 1999, COMP GRAPH, P39
   LIU Z, 1994, SIGGRAPH 94 C P, P35
   MORDATCH I, 2007, SIGGRAPH 07, P84
   Neff M, 2007, COMPUT GRAPH FORUM, V26, P675, DOI 10.1111/j.1467-8659.2007.01091.x
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Orr M J L, 1996, Introduction to radial basis function networksJ
   Popovic J, 2003, ACM T GRAPHIC, V22, P1034, DOI 10.1145/944020.944025
   TERRA SCL, 2004, SCA 04 P 2004 ACM SI, P253
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Turk G, 2002, ACM T GRAPHIC, V21, P855, DOI 10.1145/571647.571650
   WILLIAMS R, 2001, ANIMATORS SURVIVAL K, P5
   2008, AUTODESK MAYA 2008
NR 23
TC 3
Z9 3
U1 0
U2 0
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 175
EP 188
DI 10.1002/cav.247
PG 14
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 354GZ
UT WOS:000259628200003
DA 2024-07-18
ER

PT J
AU Papagiannakis, G
   Singh, G
   Magnenot-Thalmann, N
AF Papagiannakis, George
   Singh, Gurminder
   Magnenot-Thalmann, Nadia
TI A survey of mobile and wireless technologies for augmented reality
   systems
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented-mixed reality; mobile systems; wireless networking
ID MIXED REALITY; ENVIRONMENTS; COMPUTER
AB Recent advances in hardware and software for mobile computing have enabled anew breed of mobile augmented reality (AR) systems and applications. A new breed of computing called 'augmented ubiquitous computing' has resulted from the convergence of wearable computing, wireless networking, and mobile AR interfaces. In this paper, we provide a survey of different mobile and wireless technologies and how they have impact AR. Our goal is to place them into different categories so that it becomes easier to understand the state Of art and to help identify new directions of research. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Papagiannakis, George] Univ Geneva, MIRALab, CH-1227 Carouge, Switzerland.
C3 University of Geneva
RP Papagiannakis, G (corresponding author), Univ Geneva, MIRALab, 7 Route Drize, CH-1227 Carouge, Switzerland.
EM george.papagianiiakis@miralab.unige.cl
RI papagiannakis, george/AAI-7973-2020
OI papagiannakis, george/0000-0002-2977-9850
CR [Anonymous], P 1992 IEEE HAW INT
   [Anonymous], 2007, COMP VIS WINT WORKSH
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma R., 2004, ACM SIGGRAPH 2004 CO
   AZUMA R, 2006, P ISMAR 2006 IEEE AC, P119
   BALCISOY S, 2000, P CGI00
   Banâtre M, 2004, LECT NOTES COMPUT SC, V3160, P310
   BARAKONYI I, 2006, P ISMAR 2006 IEEE AC
   Bell B, 2002, IEEE COMPUT GRAPH, V22, P6, DOI 10.1109/MCG.2002.1016691
   Bierbaum A., 2000, THESIS IOWA STATE U
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   CHEOK A, 2003, LECT NOTES COMPUTER
   CHEOK AD, 2004, P MOB HCI 2004 6 INT, P209
   CYBORG CM, 1995, CYBORG HDB, P35
   DAS T, 1997, P 6 IEEE WORKSH EN T, P148
   DIVERDI S, 2007, IEEE VIRTUAL REA MAR
   Egges A, 2007, VISUAL COMPUT, V23, P317, DOI 10.1007/s00371-007-0113-z
   ELMQVIST N, 2006, 200612 CHALM U TECHN
   FERGUSON T, 2007, 3G WIFI GO HEAD HEAD
   GAUSEMEIER J, 2003, P ACM SIGGRAPH AFRIG
   Goose S., 2004, P IEEE DMS 2004 INT, P75
   GOSETA M, 2004, P IEEE MELECON DUBR, P661
   HARTLING PL, 2002, 6 WORLD MULT SYST CY
   HENRYSSON A, 2005, P INT S MIX AUGM REA, P80
   Hollerer Tobias Hans, 2004, THESIS COLUMBIA U
   HUGHES CE, 2005, IEEE COMPUT GRAPH, V26, P24
   *INTERMEDIA NOE, 2007, D31A INTERMEDIA NOE
   JONIETZA E, 2007, 10 EMERGING TECHNOLO
   KLEIN G, 2004, P 3 IEEE ACM INT S M
   Klein G., 2006, THESIS U CAMBRIDGE
   Kölsch M, 2006, IEEE COMPUT GRAPH, V26, P62, DOI 10.1109/MCG.2006.66
   LIU AL, 2006, ACM ASSETS06
   Magerkurth C., 2005, Computer in Entertainment (CIE), V3, P4
   MAKRI A, 2005, 11 INT C VIRT SYST M
   Mann S, 1997, COMPUTER, V30, P25, DOI 10.1109/2.566147
   McCaffery D. J., 2004, P 2004 ACM SIGCHI IN, P203
   Milgram P, 1999, MIXED REALITY, P5
   Mitchell Keith., 2003, P 2 WORKSHOP NETWORK, P91
   NEWMAN J, 2006, ADV PERVASIVE COMPUT
   Ohlenburg J., 2004, P ACM S VIRTUAL REAL, P166, DOI DOI 10.1145/1077534.1077568
   OLWAL A, 2006, P ISMAR 2006 IEEE AC, P119, DOI DOI 10.1109/ISMAR.2006.297802
   Pantel Lothar., 2002, NOSSDAV 02 P 12 INT, P23
   Papagiannakis G, 2005, COMPUT ANIMAT VIRT W, V16, P11, DOI 10.1002/cav.53
   Papagiannakis G., 2004, Real-time virtual humans in ar sites, P273
   Papagiannakis G, 2007, INT J ARCHIT COMPUT, V5, P395, DOI 10.1260/1478-0771.5.2.396
   PEROVIC I, 2003, P 7 INT C TEL CONTEL
   PETERNIER A, 2006, EUR S VIRT ENV 06
   PIEKARSKI W, 2004, P 3 IEEE ACM INT S M
   PIEKARSKI W, 2003, 2 INT S MIX AUGM REA
   Ponder M., 2003, Proceedings Computer Graphics International 2003, P96, DOI 10.1109/CGI.2003.1214453
   Rashid O., 2006, ACM Computers in Entertainment, V4
   RAUHALA M, 2006, ACM MOBILEHCI06
   Reitmayr G., 2006, P ISMAR 2006 IEEE AC, P119
   RENEVIER P, 2004, 5 INT C COMP AID DES, P307
   SCHMALSTIEG D, 2002, PRESENCE TELEOPERATO
   SCHMEIL A, 2006, ACM SIGGRAPH 2006 SK
   Singhal Aneesh B, 2004, Top Stroke Rehabil, V11, P1
   SMED J, 2001, P INT C APPL DEV GAM
   Steggles P., 2005, The Ubisense Smart Space Platform Electronic version]
   STORK A, 2006, P VIRT CONC 06
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Tamura H, 2001, IEEE COMPUT GRAPH, V21, P64, DOI 10.1109/38.963462
   VACCHETTI L, 2004, VIRTUAL REALITY AUGM, P11
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Wagner D, 2006, C ADV COMP ENT TECHN, pp57
   Wagner D, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P235
   WATSEN K, 1999, 3 INT IMM PROJ TECHN
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   WELLNER P, 1993, COMMUN ACM, V36, P24, DOI 10.1145/159544.159555
   ZAUNER J, 2004, 10 EUR S VIRT ENV EG, P87
   [No title captured]
NR 71
TC 132
Z9 161
U1 1
U2 51
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2008
VL 19
IS 1
BP 3
EP 22
DI 10.1002/cav.221
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 283ZM
UT WOS:000254675000003
OA Bronze
DA 2024-07-18
ER

PT J
AU Ueki, A
   Inakage, M
AF Ueki, Atsuro
   Inakage, Masa
TI Facilitating public awareness - the design of information distribution
   for communication in future workplaces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE work environment; communication; awareness; emotional information;
   message system
AB We present Emo System that extends e-mail communication system in a workspace environment. In this system, the emotional information included in e-mail message is extracted and shared in the public space, while reserving the private exchange of messages. As a result, people in the public space become aware of the 'emotional' information. This paper discusses how we extract and segment the information to share the emotional information. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Ueki, Atsuro; Inakage, Masa] Keio Univ, SFC, Kanagawa, Japan.
C3 Keio University
RP Ueki, A (corresponding author), Keio Univ, SFC, Delta S110,5322 Endo, Kanagawa, Japan.
EM atsurou@sfc.keio.ac.jp
CR Gaver W., 1999, Proceedings of the SIGCHI conference on Human Factors in Computing Systems, P600
   Kaye J.J., 2004, P 2004 C DESIGNING I, DOI [10.1145/1013115.1013175, DOI 10.1145/1013115.1013175]
   Prante T., 2003, ADJUNCT P UBICOMP, P277, DOI DOI 10.1.1.58.3459
   *SONY, SONY FEL
   TOKUDA H, 2004, P 4 ACM INT C EMB SO, P2
   Tollmar K., 2002, P 2 NORDIC C HUMAN C, P41
   Vogel Daniel., 2004, Proc. of the 17th Annual ACM Sypm. on User Interface Software and Technology (UIST), P137, DOI [DOI 10.1145/1029632.1029656, https://doi.org/10.1145/1029632.1029656]
   Wisneski C, 1998, LECT NOTES COMPUT SC, V1370, P22
NR 8
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2008
VL 19
IS 1
BP 37
EP 47
DI 10.1002/cav.219
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 283ZM
UT WOS:000254675000005
DA 2024-07-18
ER

PT J
AU Seo, H
   Cordier, F
   Hong, K
AF Seo, Hyewon
   Cordier, Frederic
   Hong, Kyunghi
TI A breast modeler based on analysis of breast scans
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE nude breast; 3D scanning; breast volume; statistical estimation;
   interpolation
AB The advent of 3D scanning technology has allowed effective measurement and analysis of breast size and shape, attracting interests by plastic surgeons, brassier designers, etc. Much work remains, however, before 3D scanning systems can be successfully used in automated analysis and synthesis of the breast-filtering noise, filling holes, and, in case a statistical analysis is desired, finding correspondence among each scan data. Moreover, analysis of a sagged breast is difficult to obtain, due to occlusions. In this paper, we address the problems and specific issues of using 3D scan data for the analysis and synthesis of breast models. The goal of our work is to build a breast modeler which can help both surgeons and garment designers in analyzing breast volume and surface measurements. Given enough samples of scanned breasts, our modeler can generate highly realistic breast shape, with some expected and consistent variability. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Chungnam Natl Univ, Dept Comp Sci & Engn, Taejon, South Korea.
C3 Chungnam National University
RP Seo, H (corresponding author), Chungnam Natl Univ, Dept Comp Sci & Engn, 220 Kung Dong, Taejon, South Korea.
EM hseo@cnu.ac.kr
CR Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   HUDSON TC, 1997, VRML 97 2 S VIRT REA
   Lee HY, 2004, APPL ERGON, V35, P353, DOI 10.1016/j.apergo.2004.03.004
   Losken A, 2005, ANN PLAS SURG, V54, P471, DOI 10.1097/01.sap.0000155278.87790.a1
   LOUGHRY W, 1997, PLASTIC RECONSTRUCTI, V80, P553
   PRESS WH, 1929, NUMERICAL RECIPES C
   Seo Hyewon., 2003, Proceedings of the 2003 Symposium on Interactive 3D Graphics, P19, DOI [10.1145/641480.641487, DOI 10.1145/641480.641487]
   Tezel E, 2000, PLAST RECONSTR SURG, V105, P1019, DOI 10.1097/00006534-200003000-00028
NR 11
TC 11
Z9 14
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2007
VL 18
IS 2
BP 141
EP 151
DI 10.1002/cav.169
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 181AO
UT WOS:000247409300007
DA 2024-07-18
ER

PT J
AU Busso, C
   Deng, ZG
   Neumann, U
AF Busso, C
   Deng, ZG
   Neumann, U
TI Natural head motion synthesis driven by acoustic prosodic features
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE head motion synthesis; prosody; HMM; facial animation; data-driven;
   spherical cubic interpolation
AB Natural head motion is important to realistic facial animation and engaging human-computer interactions. In this paper, we present a novel data-driven approach to synthesize appropriate head motion by sampling from trained hidden markov models (HMMs). First, while an actress recited a corpus specifically designed to elicit various emotions, her 3D head motion was captured and further processed to construct a head motion database that included synchronized speech information. Then, an HMM for each discrete head motion representation (derived directly from data using vector quantization) was created by using acoustic prosodic features derived from speech. Finally, first-order Markov models and interpolation techniques were used to smooth the synthesized sequence. Our comparison experiments and novel synthesis results show that synthesized head motions follow the temporal dynamic behavior of real human subjects. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Univ So Calif, Dept Elect Engn, Integrated Media Syst Ctr, Viterbi Sch Engn, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Univ So Calif, Dept Elect Engn, Integrated Media Syst Ctr, Viterbi Sch Engn, 3740 McClintock Ave,Room 400, Los Angeles, CA 90089 USA.
EM busso@usc.edu
RI Narayanan, Shrikanth S/D-5676-2012
OI Deng, Zhigang/0000-0002-0452-8676; Deng, Zhigang/0000-0003-2571-5865;
   Busso, Carlos/0000-0002-4075-4072
CR [Anonymous], P 2004 ACM SIGMM WOR
   [Anonymous], 2002, CAMBRIDGE U ENG DEP
   [Anonymous], 2000, 3D GAME ENGINE DESIG
   [Anonymous], P IEEE INT C AUT FAC
   Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537
   Bregler C., 1997, P 24 ANN C COMP GRAP, V31, P353, DOI DOI 10.1145/258734.258880
   Cassell J., 1994, P 21 ANN C COMP GRAP, P413, DOI DOI 10.1145/192161.192272
   CHUANG E, 2003, CSTR200302 STANF U C
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   COSTA M, 2001, INT C AUGM VIRT ENV
   Dehon C, 2000, STUD CLASS DATA ANAL, P321
   Delgado D., 2002, INFORM MATH MODELLIN
   Deng Z, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P19
   DENG Z, 2004, IEEE 17 INT C COMP A, P267
   Deng ZG, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.35
   Ekman P., 2003, UNMASKING FACE GUIDE
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Kshirsagar S, 2003, COMPUT GRAPH FORUM, V22, P631, DOI 10.1111/1467-8659.t01-2-00711
   Kuratate T., 1999, Eurospeech'99, V3, P1279
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu WT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P885
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Pelachaud C, 1996, COGNITIVE SCI, V20, P1, DOI 10.1207/s15516709cog2001_1
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
   Yehia H., 2000, 5 SEM SPEECH PROD MO, P265
NR 27
TC 52
Z9 60
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 283
EP 290
DI 10.1002/cav.80
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000014
DA 2024-07-18
ER

PT J
AU Chittaro, L
   Serra, M
AF Chittaro, L
   Serra, M
TI Behavioral programming of autonomous characters based on probabilistic
   automata and personality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE virtual characters; personality; behavioral autonomy; probabilistic
   automata
ID AVATARS
AB This paper presents a system for realistic behavioral programming of virtual characters, based on personality and probabilistic automata. We describe personality by using the Five-Factor Model and achieve autonomy through a goal-oriented approach. Each character perceives the surrounding world, decides how to behave and acts on the environment according to its personality and to its goals. The chief idea explored by the proposed approach is that personality has a probabilistic influence on behavior selection instead of a deterministic one. Different behavior sequences available to achieve a goal are modeled using probabilistic automata and making probability dependent on character personality. This leads to non-repetitive behaviors, whose evolution is not foreseeable. The paper first motivates the approach in the context of cybertherapy. Then, it summarizes related work and illustrates in detail the proposed approach. Finally, it presents obtained results and discusses the main limitations of the implemented system. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Udine, Dept Math & Comp Sci, HCI Lab, I-33100 Udine, Italy.
C3 University of Udine
RP Univ Udine, Dept Math & Comp Sci, HCI Lab, Via Sci 206, I-33100 Udine, Italy.
EM chittaro@dimi.uniud.it
OI CHITTARO, Luca/0000-0001-5975-4294
CR ANASTASSAKIS G, 2001, LECT NOTES ARTIF INT, P112
   ANDRE E, 2002, VIRT HUM WORKSH MARC
   Arafa Y., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P313, DOI 10.1145/604045.604109
   Badler N, 2002, COMP ANIM CONF PROC, P133, DOI 10.1109/CA.2002.1017521
   BECHEIRAZ P, 1998, P 1 WORKSH EMB CONV, P57
   Bouchard S, 2002, HAVE 2002 - IEEE INTERNATIONAL WORKSHOP ON HAPTIC VIRTUAL ENVIRONMENTS AND THEIR APPLICATIONS, P7, DOI 10.1109/HAVE.2002.1106906
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   EGGERS A, 2003, LECT NOTES AI
   Funge J, 1999, COMP GRAPH, P29, DOI 10.1145/311535.311538
   Gaggioli A, 2003, CYBERPSYCHOL BEHAV, V6, P117, DOI 10.1089/109493103321640301
   Howard P. J., 1995, The big five quickstart: An introduction to the five-factor model of personality for human resource professionals
   NOSER H, 1993, P FRENCH JAP WORKSH
   Ortony Andrew., 1998, COGNITIVE STRUCTURE
   Perlin Ken., 1996, SIGGRAPH 96, P205
   Pina A, 2000, COMPUT GRAPH-UK, V24, P297, DOI 10.1016/S0097-8493(99)00165-X
   Schuemie M.J., 2003, THESIS DELFT U TECHN
   Wiederhold BK, 1999, COMPUT GRAPHICS-US, V33, P25
NR 18
TC 21
Z9 24
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 319
EP 326
DI 10.1002/cav.35
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700022
DA 2024-07-18
ER

PT J
AU Wagg, DK
   Nixon, MS
AF Wagg, DK
   Nixon, MS
TI Automated markerless extraction of walking people using deformable
   contour models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE motion capture; gait; walking; snakes
ID MOTION; TRACKING
AB We develop a new automated markerless motion capture system for the analysis of walking people. We employ global evidence gathering techniques guided by biomechanical analysis to robustly extract articulated motion. This forms a basis for new deformable contour models, using local image cues to capture shape and motion at a more detailed level. We extend the greedy snake formulation to include temporal constraints and occlusion modelling, increasing the capability of this technique when dealing with cluttered and self-occluding extraction targets.
   This approach is evaluated on a large database of indoor and outdoor video data, demonstrating fast and autonomous motion capture for walking people, Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
C3 University of Southampton
RP Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
EM dkw02r@ecs.soton.ac.uk
RI Nixon, Mark S/F-7406-2014
OI Nixon, Mark/0000-0002-9174-5934
CR [Anonymous], P WORKSH MULT US AUT
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P372, DOI 10.1109/AFGR.2002.1004182
   Cheung GKM, 2003, PROC CVPR IEEE, P77
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Davison AJ, 2001, SPRING EUROGRAP, P3
   Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Ning HZ, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P383, DOI 10.1109/ICMI.2002.1167025
   PLANKERS R, 2003, P INT C COMP VIS, P394
   SHUTLER JD, 2000, P REC ADV SOFT COMP, P66
   Wachter S, 1999, COMPUT VIS IMAGE UND, V74, P174, DOI 10.1006/cviu.1999.0758
   WAGG DK, 2004, UNPUB P FACE GESTURE
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Whittle MW, 1999, HUM MOVEMENT SCI, V18, P681, DOI 10.1016/S0167-9457(99)00032-9
   WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L
   Winter D., 1990, BIOMECHANICS HUMAN M
   WINTER DA, 1991, BIOMECHNANICS MOTOR
   Yam CY, 2002, INT C PATT RECOG, P287, DOI 10.1109/ICPR.2002.1044691
NR 19
TC 24
Z9 30
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 399
EP 406
DI 10.1002/cav.43
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700030
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Dinerstein, J
   Egbert, PK
   de Garis, H
   Dinerstein, N
AF Dinerstein, Jonathan
   Egbert, Parris K.
   de Garis, Hugo
   Dinerstein, Nelson
TI Fast and learnable behavioral and cognitive modeling for virtual
   character animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; synthetic characters; behavioral modeling; cognitive
   modeling; machine learning; reinforcement learning
AB Behavioral and cognitive modeling for virtual characters is a promising field. It significantly reduces the workload on the animator, allowing characters to act autonomously in a believable fashion. It also makes interactivity between humans and virtual characters more practical than ever before. In this paper we present a novel technique where an artificial neural network is used to approximate a cognitive model. This allows Its to execute the model much more quickly, making cognitively empowered characters more practical for interactive applications. Through this approach, we can animate several thousand intelligent characters in real time on a PC. We also present a novel technique for how a virtual character, instead Of using an explicit model supplied by the user, can automatically learn an unknown behavioral/cognitive model by itself through reinforcement learning. The ability to learn without an explicit model appears promising for helping behavioral and cognitive modeling become more broadly accepted and used in the computer graphics community, as it call further reduce the workload on the animator. Further, it provides solutions for problems that cannot easily be modeled explicitly. Copyright (C) 2004 John Wiley & Sons, Ltd.
C1 [Dinerstein, Jonathan; Egbert, Parris K.] Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.
   [de Garis, Hugo; Dinerstein, Nelson] Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
C3 Brigham Young University; Utah System of Higher Education; Utah State
   University
RP Dinerstein, J (corresponding author), Brigham Young Univ, Dept Comp Sci, 3366 TMCB, Provo, UT 84602 USA.
EM jondinerstein@yahoo.com
CR [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], 1999, OpenGL programming guide: the official guide to learning OpenGL
   Bertsekas D. P., 1996, NEURODYNAMIC PROGRAM
   BLUMBERG B, 2002, P 29 ANN C COMP GRAP, P417
   BLUMBERG B, 1996, P ACM SIGGRAPH, P47
   BURKE R, 2001, P COMP GAM DEV C
   FALOUTSOS P, 2001, P ACM SIGGRAPH, P39
   Funge J, 1999, COMP GRAPH, P29, DOI 10.1145/311535.311538
   Funge J, 2000, COMMUN ACM, V43, P40, DOI 10.1145/341852.341862
   FUNGE J, 1999, AI GAMES ANIMATION C
   GRZESZCZUK R, 1997, P ACM SIGGRAPH, P9
   GRZESZCZUK R, 1995, P SIGGRAPH 95, P63
   Haykin S., 1994, NEURAL NETWORKS, V2
   HODGINS JK, 1997, P SIGGRAPH 97, P153
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417
   Perlin Ken., 1996, SIGGRAPH 96, P205
   REYNOLDS CW, 1994, P ARTIFICIAL LIFE, V4, P59
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Russell S., 1995, Prentice Hall series in artificial intelligence, V25, P27
   Sims K., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P15, DOI 10.1145/192161.192167
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Terzopoulos D., 1999, Communications of the ACM, V42, P32, DOI 10.1145/310930.310966
   TOMLINSON B, 2002, P 1 GSFC JPL WORKSH
   TU X., 1994, P ACM SIGGRAPH 94, P43, DOI DOI 10.1145/192161.192170
   VANDEPANNE M, 1994, P 5 EUR WORKSH SIM A
   VANDEPANNE M, 1993, P ACM SIGGRAPH
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Yoon SY, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P249
NR 30
TC 10
Z9 14
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2004
VL 15
IS 2
BP 95
EP 108
DI 10.1002/cav.8
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA V10FD
UT WOS:000207449000004
DA 2024-07-18
ER

PT J
AU Guerroudji, MA
   Amara, K
   Lichouri, M
   Zenati, N
   Masmoudi, M
AF Guerroudji, Mohamed Amine
   Amara, Kahina
   Lichouri, Mohamed
   Zenati, Nadia
   Masmoudi, Mostefa
TI A 3D visualization-based augmented reality application for brain tumor
   segmentation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D reconstruction; 3D visualization; active contour; augmented reality;
   brain tumor; interaction; MRI; segmentation
ID MRI; ALGORITHM
AB Every year on June 8th, the globe observes World Brain Tumor Day to raise awareness and educate people about brain cancer, encompassing both noncancerous (benign) and cancerous (malignant) growths. Research in the field of brain cancer plays a vital role in supporting medical professionals. In this context, augmented reality (AR) technology has emerged as a valuable tool, enabling surgeons to visualize underlying structures and offering a cost-effective and time-efficient alternative. Our study focuses on the efficient segmentation of brain tumor classes using Magnetic Resonance Imaging (MRI) and incorporates a three-stage approach: preprocessing, segmentation, and 3D reconstruction & AR display. In the preprocessing stage, a Gaussian filter is applied to mitigate intensity heterogeneity. Segmentation and detection are achieved using active geometric contour models, complemented by morphological operations. To establish 3D brain tumor reconstruction, a genuine scene is virtually integrated using 3D Slicer software. The proposed methodology was validated using a genuine patient dataset comprising 496 MRI scans obtained from the local Bab El Oued university hospital center. The results demonstrate the effectiveness of our approach in achieving accurate 3D brain tumor reconstruction, efficient tumor extraction, and augmented reality visualization. The obtained segmentation results showcased an impressive accuracy of 98.61%, outperforming existing state-of-the-art methods and affirming the efficacy of our proposed strategy.
   AR-assisted 3D brain tumor neurovisualisation.image
C1 [Guerroudji, Mohamed Amine; Amara, Kahina; Zenati, Nadia; Masmoudi, Mostefa] Ctr Dev Adv Technol CDTA, Div Robot & Ind Automat, Baba Hassen, Algeria.
   [Lichouri, Mohamed] Univ Sci & Technol Houari Boumediene USTHB, Dept Telecommun, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Guerroudji, MA (corresponding author), Ctr Dev Adv Technol CDTA, Div Robot & Ind Automat, Baba Hassen, Algeria.
EM mguerroudji@cdta.dz
RI Lichouri, Mohamed/AAI-1833-2019; Amara, Kahina/IRZ-3469-2023
OI Lichouri, Mohamed/0000-0003-0584-1389; Amara,
   Kahina/0000-0001-6673-0143; guerroudji, mohamed
   amine/0000-0002-8847-9778
CR Al-Rei M., 2017, THESIS
   Amara K., 2023, IEEE SENSORS J
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Aslam A, 2015, PROCEDIA COMPUT SCI, V58, P430, DOI 10.1016/j.procs.2015.08.057
   Bian YN, 2023, VIEW-CHINA, V4, DOI 10.1002/VIW.20220069
   Chen XL, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9456008
   Douglas David B., 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040029
   Dunne JR, 2010, MIL MED, V175, P25, DOI 10.7205/MILMED-D-10-00158
   Frantz T, 2018, HEALTHC TECHNOL LETT, V5, P221, DOI 10.1049/htl.2018.5079
   Gerard IJ, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.2.021210
   Görgel P, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4170
   Guerreiro Marco, 2023, IECON 2023- 49th Annual Conference of the IEEE Industrial Electronics Society, P1, DOI 10.1109/IECON51785.2023.10312423
   Guerroudji MA., 2021, INT ENTREPRENEURSHIP, P1
   Guerroudji MA., 2022, 2022 7 INT C IM SIGN
   Guerroudji MA., 2021, INT C ART INT ITS AP, P447
   Ireland RH, 2016, CLIN ONCOL-UK, V28, P695, DOI 10.1016/j.clon.2016.08.005
   Khosravanian A, 2023, INT J IMAG SYST TECH, V33, P323, DOI 10.1002/ima.22792
   Khosravanian A, 2022, MULTIMED TOOLS APPL, V81, P21719, DOI 10.1007/s11042-022-12445-7
   Kikinis R, 2011, IEEE ENG MED BIO, P6982, DOI 10.1109/IEMBS.2011.6091765
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Moiyadi AV., 2016, INTRAOPERATIVE ULTRA, P135
   Montemurro N, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18199955
   Munir K, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218201
   Naik Gunjan, 2022, International Journal of Computer Vision and Image Processing, DOI 10.4018/IJCVIP.314947
   Neumann-Podczaska A., 2021, HEALTHCARE
   Parveen, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P98, DOI 10.1109/SPIN.2015.7095308
   Qian ZL, 2022, EMERG MED INT, V2022, DOI 10.1155/2022/5356069
   Reddy MG, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102618
   Rodríguez-Hernández M, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11050555
   Senthilkumaran N., 2014, INT J COMPUTER SCI I, V5, P5336
   Shan Q, 2017, PROCEDIA COMPUT SCI, V113, P400, DOI 10.1016/j.procs.2017.08.356
   Shankar BJ, 2021, J MED IMAG HEALTH IN, V11, P661, DOI 10.1166/jmihi.2021.3365
   Sheela CJJ, 2022, J KING SAUD UNIV-COM, V34, P557, DOI 10.1016/j.jksuci.2019.04.006
   Shen S, 2005, IEEE T INF TECHNOL B, V9, P459, DOI 10.1109/TITB.2005.847500
   Shivhare SN, 2019, MULTIMED TOOLS APPL, V78, P34207, DOI 10.1007/s11042-019-08048-4
   Tabrizi LB, 2015, J NEUROSURG, V123, P206, DOI 10.3171/2014.9.JNS141001
   Tailor J, 2021, PEDIATR CLIN N AM, V68, P811, DOI 10.1016/j.pcl.2021.04.007
   Tavakoli-Zaniani M, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102615
   Tomikawa M, 2010, J AM COLL SURGEONS, V210, P927, DOI 10.1016/j.jamcollsurg.2010.01.032
   Tongbram S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02762-w
   WHO, 2019, BRAIN CANC WHO
   Yoon JW, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1914
NR 42
TC 1
Z9 1
U1 8
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2223
EA NOV 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001093413400001
DA 2024-07-18
ER

PT J
AU So, CH
   Khvan, A
   Choi, W
AF So, Chaehan
   Khvan, Anel
   Choi, Wonjun
TI Natural conversations with a virtual being: How user experience with a
   current conversational AI model compares to expectations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE approachable; conversational AI; empathetic; engaging; fine-tuning;
   virtual agents
ID MEASURING SERVICE QUALITY; UNCANNY VALLEY; COMPARISON STANDARD; EFFECT
   SIZE; AGENTS; HUMANS; PERCEPTION; REALISM; ANTHROPOMORPHISM; CREDIBILITY
AB The present work investigates the effect of natural conversations with virtual beings on user perceptions with a current conversational AI model (Meta's BlenderBot). To this aim, we designed a virtual being from a deep learning-generated face and a conversational AI model acting as a virtual conversation partner in an online conferencing software and evaluated it in 11 perceptions of social attributes. Compared to prior expectations, participants perceived the virtual being as distinctly higher in warmth (engaging, empathic, and approachable) but lower in realism and credibility after 5 days of 10 min daily conversations (Study 1). Further, we explored the idea of simplifying the technical setup to reduce the technical entry barrier for such AI applications (Study 2). To this aim, we conducted several trials of fine-tuning a small conversational model of 90 million parameters until its performance metrics improved. Testing this fine-tuned model with users revealed that this model was not perceived differently from a large conversational model (1.4 billion parameters). In summary, our findings show that recent progress in conversational AI has added warmth-related aspects to the user experience with virtual beings, and that fine-tuning a conversational AI model can be effective to reduce technical complexity.
C1 [So, Chaehan] Virtual Friend, Los Angeles, CA 90033 USA.
   [So, Chaehan; Choi, Wonjun] Yonsei Univ, Informat & Interact Design, Seoul, South Korea.
   [Khvan, Anel] Yonsei Univ, Creat Technol Management, Seoul, South Korea.
C3 Yonsei University; Yonsei University
RP So, CH (corresponding author), Virtual Friend, Los Angeles, CA 90033 USA.
EM chaehan.so@gmail.com
RI So, Chaehan/D-8007-2016
OI So, Chaehan/0000-0002-0546-2947; Choi, Wonjun/0000-0001-7672-4521
CR Aburumman N, 2022, INT J HUM-COMPUT ST, V164, DOI 10.1016/j.ijhcs.2022.102819
   Adamopoulou E, 2020, IFIP Advances in Information and Communication Technology, P373, DOI [10.1007/978-3-030-49186-4_31, DOI 10.1007/978-3-030-49186-4_31]
   Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006
   Alkawaz MH, 2014, SCI WORLD J, DOI 10.1155/2014/367013
   Anderson Keith, 2013, Advances in Computer Entertainment. 10th International Conference, ACE 2013. Proceedings: LNCS 8253, P476, DOI 10.1007/978-3-319-03161-3_35
   Archibald MM, 2019, INT J QUAL METH, V18, DOI 10.1177/1609406919874596
   Arora K., 2022, ARXIV
   Barikeri S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1941
   Bartneck Christoph, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P269, DOI 10.1109/ROMAN.2009.5326351
   Bartneck C., 2009, INT J SOC ROBOT
   Bartneck C, 2009, INT J SOC ROBOT, V1, P71, DOI 10.1007/s12369-008-0001-3
   Baumgartner Jason, 2020, Technical report
   Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922
   Benyon D, 2013, IEEE T AFFECT COMPUT, V4, P299, DOI 10.1109/T-AFFC.2013.15
   Bolukbasi T, 2016, ADV NEUR IN, V29
   Brave S, 2005, INT J HUM-COMPUT ST, V62, P161, DOI 10.1016/j.ijhcs.2004.11.002
   Brown Gillian, 1983, DISCOURSE ANAL
   Bunt H., 1998, Multimodal Human-Computer Communication: Systems, Techniques, and Experiments
   Burleigh TJ, 2013, COMPUT HUM BEHAV, V29, P759, DOI 10.1016/j.chb.2012.11.021
   Cafaro A, 2016, ACM T COMPUT-HUM INT, V23, DOI 10.1145/2940325
   Cao WJ, 2020, PSYCHIAT RES, V287, DOI 10.1016/j.psychres.2020.112934
   Cassell J., 2000, Embodied Conversational Agents
   Chattaraman V, 2012, COMPUT HUM BEHAV, V28, P2055, DOI 10.1016/j.chb.2012.06.009
   Chattopadhyay D, 2016, J VISION, V16, DOI 10.1167/16.11.7
   Cheetham M, 2013, JOVE-J VIS EXP, DOI 10.3791/4375
   Choi Y, 2020, INT J CONTEMP HOSP M, V32, P977, DOI 10.1108/IJCHM-03-2019-0265
   Chou WP, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17218039
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cohen J., 1988, STAT POWER ANAL BEHA, VSecond, P1, DOI DOI 10.1016/B978-0-12-179060-8.50006-2
   Corrigan P, 2004, AM PSYCHOL, V59, P614, DOI 10.1037/0003-066X.59.7.614
   Corti K, 2016, COMPUT HUM BEHAV, V58, P431, DOI 10.1016/j.chb.2015.12.039
   Cribari-Neto F, 2010, J STAT SOFTW, V34, P1
   Croes EAJ, 2021, J SOC PERS RELAT, V38, P279, DOI 10.1177/0265407520959463
   CRONBACH LJ, 1951, PSYCHOMETRIKA, V16, P297, DOI [10.1007/BF02310555, DOI 10.1007/BF02310555]
   Cumming G, 2005, AM PSYCHOL, V60, P170, DOI 10.1037/0003-066X.60.2.170
   Dahlberg L, 2021, AGING MENT HEALTH, V25, P1161, DOI 10.1080/13607863.2021.1875195
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Diel A, 2022, ACM T HUM-ROBOT INTE, V11, DOI 10.1145/3470742
   Diener E, 1999, PSYCHOL BULL, V125, P276, DOI 10.1037//0033-2909.125.2.276
   Dinan E, 2020, SPRING SER CHALLENGE, P187, DOI 10.1007/978-3-030-29135-8_7
   Dinan Emily, 2019, ICLR
   Fiedel Noah, 2020, CoRR
   Fiske ST, 2007, TRENDS COGN SCI, V11, P77, DOI 10.1016/j.tics.2006.11.005
   Fitrianie S, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P159, DOI 10.1145/3308532.3329421
   Fong K, 2015, PERS SOC PSYCHOL B, V41, P237, DOI 10.1177/0146167214562761
   Gehman Samuel, 2020, EMNLP Findings, P3356
   GIBBONS RD, 1993, J EDUC STAT, V18, P271, DOI 10.2307/1165136
   Gratch J, 2007, LECT NOTES COMPUT SC, V4552, P286
   Gu XD, 2021, AAAI CONF ARTIF INTE, V35, P12911
   Gürerk Ö, 2019, J BEHAV EXP ECON, V78, P17, DOI 10.1016/j.socec.2018.11.003
   Hedges LV., 1982, HDB RES SYNTHESIS ME, V7, P245
   Ho A, 2018, J COMMUN, V68, P712, DOI 10.1093/joc/jqy026
   Ho CC, 2010, COMPUT HUM BEHAV, V26, P1508, DOI 10.1016/j.chb.2010.05.015
   Holzwarth M, 2006, J MARKETING, V70, P19, DOI 10.1509/jmkg.70.4.19
   Hovland C. I., 1953, Communication and persuasion
   Jin SAA, 2010, COMPUT HUM BEHAV, V26, P443, DOI 10.1016/j.chb.2009.12.003
   Judd CM, 2005, J PERS SOC PSYCHOL, V89, P899, DOI 10.1037/0022-3514.89.6.899
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   Kang SH, 2014, COMPUT HUM BEHAV, V34, P120, DOI 10.1016/j.chb.2014.01.006
   Kang SH, 2012, STUD HEALTH TECHNOL, V181, P202, DOI 10.3233/978-1-61499-121-2-202
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Komeili M., 2021, INTERNET AUGMENTED D
   Kuzminykh A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376665
   Kwon JH, 2013, INT J HUM-COMPUT ST, V71, P978, DOI 10.1016/j.ijhcs.2013.07.003
   Lakens Daniel, 2013, Front Psychol, V4, P863, DOI 10.3389/fpsyg.2013.00863
   Lance B, 2010, AUTON AGENT MULTI-AG, V20, P50, DOI 10.1007/s10458-009-9097-6
   Last JM., 2001, DICT EPIDEMIOLOGY
   LEVINGER G, 1980, J EXP SOC PSYCHOL, V16, P510, DOI 10.1016/0022-1031(80)90056-6
   Li LZ, 2020, PSYCHIAT RES, V291, DOI 10.1016/j.psychres.2020.113267
   Li Margaret, 2019, Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons
   Li Z, 2021, INT J COMPUT ASS RAD, V16, P619, DOI 10.1007/s11548-021-02328-x
   Liang H., 2021, ARXIV
   Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043
   Luk STK, 2002, SERV IND J, V22, P109, DOI 10.1080/714005073
   MacDorman KF, 2016, COGNITION, V146, P190, DOI 10.1016/j.cognition.2015.09.019
   Madotto A., 2020, PLUG AND PLAY CONVER, V2, P2422, DOI [10.18653/v1/2020.findings-emnlp.219, DOI 10.18653/V1/2020.FINDINGS-EMNLP.219]
   Maya BM, 2020, COMPUT HUM BEHAV, V103, P21, DOI 10.1016/j.chb.2019.08.029
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   McRorie M, 2012, IEEE T AFFECT COMPUT, V3, P311, DOI 10.1109/T-AFFC.2011.38
   MEYER P, 1988, JOURNALISM QUART, V65, P567, DOI 10.1177/107769908806500301
   Miller A, 2017, System Demonstrations, P79, DOI 10.18653/v1/D17-2014
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Morris SB, 2002, PSYCHOL METHODS, V7, P105, DOI 10.1037//1082-989X.7.1.105
   Niewiadomski R, 2010, LECT NOTES ARTIF INT, V6356, P272, DOI 10.1007/978-3-642-15892-6_29
   Nowak KL, 2008, COMPUT HUM BEHAV, V24, P1473, DOI 10.1016/j.chb.2007.05.005
   Nunnally JC, 1978, PSYCHOMETRIC THEORY, V2nd
   Oh SY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161794
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   Palgi Y, 2020, J AFFECT DISORDERS, V275, P109, DOI 10.1016/j.jad.2020.06.036
   Pan XN, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032931
   PARASURAMAN A, 1988, J RETAILING, V64, P12
   PARASURAMAN A, 1994, J MARKETING, V58, P111, DOI 10.1177/002224299405800109
   PARASURAMAN A, 1985, J MARKETING, V49, P41, DOI 10.2307/1251430
   Parasuraman A., 2002, Journal of retailing, V67, P114
   Park S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167214
   Pelachaud C., 2016, P 9 INT C MOT GAM, P175, DOI DOI 10.1145/2994258.2994280
   Pfeifer Vardoulakis Laura, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P289, DOI 10.1007/978-3-642-33197-8_30
   Philip P, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-019-0213-y
   Powers MB, 2013, J ANXIETY DISORD, V27, P398, DOI 10.1016/j.janxdis.2013.03.003
   Qu C, 2014, COMPUT HUM BEHAV, V34, P58, DOI 10.1016/j.chb.2014.01.033
   Quickchat, 2022, EM AI PERS THAT TALK
   Ranjbartabar H, 2021, IEEE T AFFECT COMPUT, V12, P788, DOI 10.1109/TAFFC.2019.2899305
   Ranjbartabar H, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4030055
   Rashkin H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5370
   Reidsma D, 2011, J MULTIMODAL USER IN, V4, P97, DOI 10.1007/s12193-011-0060-x
   Ren JJ, 2014, LECT NOTES ARTIF INT, V8637, P350, DOI 10.1007/978-3-319-09767-1_46
   Richards D, 2014, INT J HUM-COMPUT ST, V72, P460, DOI 10.1016/j.ijhcs.2014.01.005
   Roller S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P300
   Rosenthal-von der Pütten AM, 2019, COMPUT HUM BEHAV, V90, P397, DOI 10.1016/j.chb.2018.08.047
   Sasaki K, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01792
   Schroeder NL, 2018, COMPUT EDUC, V126, P170, DOI 10.1016/j.compedu.2018.07.005
   Seyama J, 2007, PRESENCE-TELEOP VIRT, V16, P337, DOI 10.1162/pres.16.4.337
   Shuster K, 2022, ARXIV
   Shuster K., 2020, MULTIMODAL OPEN DOMA
   Siarohin A, 2019, ADV NEUR IN, V32
   Skjuve M, 2021, INT J HUM-COMPUT ST, V149, DOI 10.1016/j.ijhcs.2021.102601
   Smith EM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2021
   Soderlund M, 2021, J RETAIL CONSUM SERV, V59, DOI 10.1016/j.jretconser.2020.102401
   Ta V, 2020, J MED INTERNET RES, V22, DOI 10.2196/16235
   TEAS RK, 1994, J MARKETING, V58, P132, DOI 10.2307/1252257
   Thoppilan R., 2022, Lamda: Language models for dialog applications
   Tinwell A, 2011, COMPUT HUM BEHAV, V27, P741, DOI 10.1016/j.chb.2010.10.018
   Trinh H., 2015, DYNAMICDUO, P1739
   Vaswani A, 2017, ADV NEUR IN, V30
   Warren M, 2006, PRAG BEYOND NEW SER, V152, P1
   Weston J., 2018, P 2018 EMNLP WORKSHO
   Wojciszke B, 1998, PERS SOC PSYCHOL B, V24, P1251, DOI 10.1177/01461672982412001
   Xu Jing, 2021, Beyond goldfish memory: Long-term open-domain conversation
   Yokotani K, 2018, COMPUT HUM BEHAV, V85, P135, DOI 10.1016/j.chb.2018.03.045
   Zaib M, 2020, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2020), DOI 10.1145/3373017.3373028
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270
   Zlotowski JA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00883
NR 133
TC 0
Z9 0
U1 4
U2 23
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2149
EA MAR 2023
PG 25
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HA0S4
UT WOS:000946882900001
DA 2024-07-18
ER

PT J
AU Cui, XL
   Khan, D
   He, ZB
   Cheng, ZL
AF Cui, Xiaoliang
   Khan, Dawar
   He, Zhenbang
   Cheng, Zhanglin
TI Fusing surveillance videos and three-dimensional scene: A mixed reality
   system
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented virtual environments; video fusion; video surveillance;
   virtual environments; virtual-reality fusion
ID TIME VIDEO; SMART
AB Augmented Virtual Environments (AVE) or Virtual-Reality Fusion systems fuse dynamic videos with static three-dimensional (3D) models of a virtual environment to provide an optimal solution for visualizing and understanding multichannel surveillance systems. However, texture distortion caused by viewpoint changes in such systems is a critical issue that needs to be addressed. To minimize texture fusion distortion, this paper presents a novel virtual environment system in two phases, offline and online phases, to dynamically fuse multiple surveillance videos with a virtual 3D scene. In the offline phase, a static virtual environment is obtained by performing a 3D photogrammetric reconstruction from the input images of the scene. In the online phase, the virtual environment is augmented by fusing multiple videos through two optional strategies. One strategy is to dynamically map images of different videos onto a 3D model of the virtual environment, and the other is to extract moving objects and represent them as billboards. The system can be used to visualize a 3D environment from any viewpoint augmented by real-time videos. Experiments and user studies in different scenarios demonstrate the superiority of our system.
C1 [Cui, Xiaoliang; Khan, Dawar; He, Zhenbang; Cheng, Zhanglin] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Cui, Xiaoliang; He, Zhenbang] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing, Peoples R China.
   [Khan, Dawar] Univ Haripur, Dept Informat Technol, Haripur, Pakistan.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS
RP Cheng, ZL (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM zl.cheng@siat.ac.cn
OI Khan, Dawar/0000-0001-5864-1888; Cheng, Zhanglin/0000-0002-3360-2679
FU NSFC; Shenzhen Science and Technology Program;  [U21A20515]; 
   [61972388];  [JCYJ20180507182222355];  [GJHZ20210705141402008]
FX ACKNOWLEDGMENTS This work is supported in part by NSFC (U21A20515 and
   61972388) and Shenzhen Science and Technology Program
   (JCYJ20180507182222355 and GJHZ20210705141402008).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.445
   Chen ZH, 2020, IEEE T CIRC SYST VID, V30, P1410, DOI 10.1109/TCSVT.2019.2902937
   de Haan G, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P103
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Gao RH, 2020, PROC CVPR IEEE, P10454, DOI 10.1109/CVPR42600.2020.01047
   Garland M., 1997, P 24 ANN C COMP GRAP, V1997, P209, DOI DOI 10.1145/258734.258849
   Hubner M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI), DOI 10.1109/MFI52462.2021.9591185
   Jian HD, 2017, INT J DIGIT EARTH, V10, P1177, DOI 10.1080/17538947.2017.1306126
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Katkere A, 1997, MULTIMEDIA SYST, V5, P69, DOI 10.1007/s005300050043
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kim K, 2009, INT SYM MIX AUGMENT, P35, DOI 10.1109/ISMAR.2009.5336505
   Kumar SHSSR., 2000, P IEEE INT C COMPUTE
   Lau BPL, 2019, INFORM FUSION, V52, P357, DOI 10.1016/j.inffus.2019.05.004
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo T, 2020, J REAL-TIME IMAGE PR, V17, P773, DOI 10.1007/s11554-018-0817-5
   Maqsood R., 2021, ANOMALY RECOGNITION
   Neumann U, 2003, P IEEE VIRT REAL ANN, P61, DOI 10.1109/VR.2003.1191122
   Pan CW, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P65, DOI 10.1109/CW.2016.17
   Philip D., 2010, P ACM INT C MULT, P371, DOI [10.1145/1873951.1874002, DOI 10.1145/1873951.1874002]
   Rathore MM, 2018, SOFT COMPUT, V22, P1533, DOI 10.1007/s00500-017-2942-7
   Ripolles O, 2014, MULTIMED TOOLS APPL, V73, P977, DOI 10.1007/s11042-012-1184-z
   Sawhney H. S., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P157
   Shao ZF, 2018, IEEE T BIG DATA, V4, P105, DOI 10.1109/TBDATA.2017.2715815
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Tian L, 2018, FUTURE GENER COMP SY, V86, P1371, DOI 10.1016/j.future.2017.12.065
   Wu TH, 2017, LECT NOTES COMPUT SC, V10393, P652, DOI 10.1007/978-3-319-65482-9_50
   Wu Z., 2022, ELECTRONICS, V11, P1
   Wu ZH, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091413
   Wu ZX, 2021, INT J COMPUT VISION, V129, P2965, DOI 10.1007/s11263-021-01508-1
   Wu ZX, 2022, IEEE T PATTERN ANAL, V44, P1699, DOI 10.1109/TPAMI.2020.3029425
   Yuan-Kai Wang, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P178, DOI 10.1109/IIH-MSP.2012.49
   Yue Meng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P86, DOI 10.1007/978-3-030-58571-6_6
   Zhou Y, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI [10.1145/3281505.3281513, 10.1109/TSMC.2018.2858843]
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 35
TC 3
Z9 3
U1 8
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2023
VL 34
IS 1
SI SI
DI 10.1002/cav.2129
EA DEC 2022
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Z2BA
UT WOS:000895716400001
DA 2024-07-18
ER

PT J
AU Dou, WH
   Gao, SS
   Mao, DQ
   Dai, HH
   Zhang, CH
   Zhou, YF
AF Dou, Wenhan
   Gao, Shanshan
   Mao, Deqian
   Dai, Honghao
   Zhang, Chenhao
   Zhou, Yuanfeng
TI Tooth instance segmentation based on capturing dependencies and
   receptive field adjustment in cone beam computed tomography
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE CBCT; centroid prediction; dependency; receptive field; tooth instance
   segmentation
ID TEETH
AB Automatic and accurate instance segmentation of teeth can provide important support for computer-aided orthodontic work. Traditional methods for tooth segmentation studies often ignore the rich structural features of teeth. Capturing the complete and accurate geometry as well as morphological details of a single tooth remains a challenge for current tooth segmentation studies. In this article, a new tooth segmentation deeplearning network based on capturing dependencies and receptive field adjustment in cone beam computed tomography (CBCT) is proposed to achieve automatic and accurate instance segmentation of dental CBCT data. The method acquires coarse-level features of tooth and accurate tooth centroids in the first stage, and acquires the instance information and spatial position localization of the tooth. The encoding process in the second stage of the network introduces a guidance module for obtaining tooth geometry information based on a 3D self-attention mechanism to capture dependencies in CBCT. The proposed tooth feature integration module is based on multiscale fusion of dilated convolutions to capture tooth detailed information at multiple scales, and the network receptive field was adjusted. Extensive evaluation, ablation, and comparison experiments demonstrate that our method exhibits state-of-the-art segmentation performance and accurate instance segmentation results, reflecting their potential applicability in clinical medicine.
C1 [Dou, Wenhan; Gao, Shanshan; Mao, Deqian; Dai, Honghao; Zhang, Chenhao] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
   [Gao, Shanshan] Shandong China US Digital Media Int Cooperat Res, Jinan, Peoples R China.
   [Gao, Shanshan] Shandong Prov Key Lab Digital Media Technol, Jinan, Peoples R China.
   [Zhou, Yuanfeng] Shandong Univ, Sch Software, Jinan, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University
RP Gao, SS (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
EM gsszxy@aliyun.com
RI zhang, chenhao/KMY-0335-2024; Zhou, Yuanfeng/AAT-4670-2020
FU National Key R&D Plan on Strategic International Scientific and
   Technological Innovation Cooperation Special Project [2021YFE0203800];
   National Natural Science Foundation of China [U1909210, 62172257,
   61902217]; Natural Science Foundation & Key Research and Development
   Program of Shandong Province [ZR2020MF037, ZR2019BF043, ZR2019MF016];
   Introduction and Education Plan of Young Creative Talents in Colleges,
   Jinan Scientific Research Leader Studio [Z2020025]
FX The National Key R&D Plan on Strategic International Scientific and
   Technological Innovation Cooperation Special Project, Grant/Award
   Number: 2021YFE0203800; National Natural Science Foundation of China,
   Grant/Award Numbers: U1909210, 62172257, 61902217; Natural Science
   Foundation & Key Research and Development Program of Shandong Province,
   Grant/Award Numbers: ZR2020MF037, ZR2019BF043, ZR2019MF016; The
   Introduction and Education Plan of Young Creative Talents in Colleges,
   Jinan Scientific Research Leader Studio, Grant/Award Number: Z2020025
CR Chen L.-C., DEEPLAB SEMANTIC IMA
   Chen YL, 2020, IEEE ACCESS, V8, P97296, DOI 10.1109/ACCESS.2020.2991799
   Cui ZM, 2021, LECT NOTES COMPUT SC, V12729, P150, DOI 10.1007/978-3-030-78191-0_12
   Cui ZM, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2020.101949
   Cui ZM, 2019, PROC CVPR IEEE, P6361, DOI 10.1109/CVPR.2019.00653
   Evain T, 2017, I S BIOMED IMAGING, P1197, DOI 10.1109/ISBI.2017.7950731
   Ezhov M, 2019, I S BIOMED IMAGING, P52, DOI 10.1109/ISBI.2019.8759310
   Gan YZ, 2018, IEEE J BIOMED HEALTH, V22, P196, DOI 10.1109/JBHI.2017.2709406
   Gan YZ, 2015, MED PHYS, V42, P14, DOI 10.1118/1.4901521
   Gao H, 2010, PATTERN RECOGN, V43, P2406, DOI 10.1016/j.patcog.2010.01.010
   Hosntalab M, 2008, INT J COMPUT ASS RAD, V3, P257, DOI 10.1007/s11548-008-0230-9
   Ji DX, 2014, COMPUT BIOL MED, V50, P116, DOI 10.1016/j.compbiomed.2014.04.006
   [姜晓通 Jiang Xiaotong], 2020, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V32, P820
   Lessmann N, 2019, MED IMAGE ANAL, V53, P142, DOI 10.1016/j.media.2019.02.005
   Li M, 2020, IEEE T MED IMAGING, V39, P2289, DOI 10.1109/TMI.2020.2968472
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Miki Y, 2017, COMPUT BIOL MED, V80, P24, DOI 10.1016/j.compbiomed.2016.11.003
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Suzani A, 2015, PROC SPIE, V9415, DOI 10.1117/12.2081542
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang L, 2016, MED PHYS, V43, P336, DOI 10.1118/1.4938267
   Wang Y., 2021, THESIS U ELECT SCI T
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
NR 26
TC 6
Z9 6
U1 3
U2 27
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2022
VL 33
IS 5
AR e2100
DI 10.1002/cav.2100
EA JUL 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5E9FV
UT WOS:000834008900001
DA 2024-07-18
ER

PT J
AU Endo, Y
   Kanamori, Y
AF Endo, Yuki
   Kanamori, Yoshihiro
TI Controlling StyleGANs using rough scribbles via one-shot learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE GAN inversion; generative adversarial networks; image editing
AB This paper tackles the challenging problem of one-shot semantic image synthesis from rough sparse annotations, which we call "semantic scribbles." Namely, from only a single training pair annotated with semantic scribbles, we generate realistic and diverse images with layout control over, for example, facial part layouts and body poses. We present a training strategy that performs pseudo labeling for semantic scribbles using the StyleGAN prior. Our key idea is to construct a simple mapping between StyleGAN features and each semantic class from a single example of semantic scribbles. With such mappings, we can generate an unlimited number of pseudo semantic scribbles from random noise to train an encoder for controlling a pretrained StyleGAN generator. Even with our rough pseudo semantic scribbles obtained via one-shot supervision, our method can synthesize high-quality images thanks to our GAN inversion framework. We further offer optimization-based postprocessing to refine the pixel alignment of synthesized images. Qualitative and quantitative results on various datasets demonstrate improvement over previous approaches in one-shot settings.
C1 [Endo, Yuki; Kanamori, Yoshihiro] Univ Tsukuba, Tsukuba, Ibaraki, Japan.
C3 University of Tsukuba
RP Endo, Y (corresponding author), Univ Tsukuba, Tsukuba, Ibaraki, Japan.
EM endo@cs.tsukuba.ac.jp
FU JSPS KAKENHI Grant [20K19816]
FX JSPS KAKENHI Grant Number, Grant/Award Number: 20K19816
CR Abdal R., 2020, P IEEECVF C COMPUTER, P8296
   Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Alaluf Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6691, DOI 10.1109/ICCV48922.2021.00664
   Branwen G., 2019, ANONYMOUS COMMUNITY
   Brock AM, 2018, PROCEEDINGS PERVASIVE DISPLAYS 2018: THE 7TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, DOI 10.1145/3205873.3205877
   Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168
   Chen WL, 2018, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR.2018.00981
   Chiu CH, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392409
   Collins E, 2020, PROC CVPR IEEE, P5770, DOI 10.1109/CVPR42600.2020.00581
   Endo Y, 2020, COMPUT GRAPH FORUM, V39, P519, DOI 10.1111/cgf.14164
   Gao CY, 2020, PROC CVPR IEEE, P5173, DOI 10.1109/CVPR42600.2020.00522
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Harkonen E., 2020, Advances in Neural Information Processing Systems, V33, P9841
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jahanian Ali, 2020, STEERABILITY GENERAT
   Jo Y, 2019, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2019.00183
   Kang K., ICCV 2021, P13941
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T., 2021, NEURIPS 2021
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Li DQ, 2021, PROC CVPR IEEE, P8296, DOI 10.1109/CVPR46437.2021.00820
   Li K, 2019, IEEE I CONF COMP VIS, P4219, DOI 10.1109/ICCV.2019.00432
   Li Y., 2020, P IEEECVF C COMPUTER, P8365
   Liu X., 2019, Advances in Neural Information Processing Systems, P570
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Pinkney Justin., 2020, Awesome pretrained StyleGAN2
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Roich D., 2021, ABS210605744 CORR
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Shen YJ, 2021, PROC CVPR IEEE, P1532, DOI 10.1109/CVPR46437.2021.00158
   Shen Yujun, 2020, P IEEE CVF C COMP VI, P9243, DOI DOI 10.1109/CVPR42600.2020.00926
   Sun W, 2019, IEEE I CONF COMP VIS, P10530, DOI 10.1109/ICCV.2019.01063
   Tang H., 2020, P IEEE CVPR, P7870
   Tang Hao, 2020, ACM MM, P1994
   Tov O, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459838
   Tritrong N, 2021, PROC CVPR IEEE, P4473, DOI 10.1109/CVPR46437.2021.00445
   Wang Sheng-Yu, 2021, 2021 IEEECVF INT C C, P14050
   Wu ZZ, 2021, PROC CVPR IEEE, P12858, DOI 10.1109/CVPR46437.2021.01267
   Xia W., 2021, CORR ABS210105278
   Xue Y, 2022, COMPUT VIS MEDIA, V8, P3, DOI 10.1007/s41095-021-0234-8
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YX, 2021, PROC CVPR IEEE, P10140, DOI 10.1109/CVPR46437.2021.01001
   Zhao B., CVPR 2019, P8584
   Zhu Z, 2020, PROC CVPR IEEE, P5466, DOI 10.1109/CVPR42600.2020.00551
NR 45
TC 1
Z9 1
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2022
VL 33
IS 5
AR e2102
DI 10.1002/cav.2102
EA JUL 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5E9FV
UT WOS:000822333900001
DA 2024-07-18
ER

PT J
AU Shi, JG
   Xiu, Y
   Tang, GY
AF Shi, Jianguo
   Xiu, Yu
   Tang, Ganyi
TI Research on occlusion block face recognition based on feature point
   location
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 35th International Conference on Computer Animation and Social Agents
   (CASA)
CY JUL 05-07, 2022
CL Nanjing, PEOPLES R CHINA
SP Nanjing Univ
DE block; face recognition; feature point location; multipose; occlusion
AB Aiming at improving the poor face recognition accuracy under occlusion, a multipose block occlusion face recognition method based on feature point location is proposed. Face segmentation is carried out according to the location results of face feature points and occlusion areas. The local features of each face block are extracted by deep convolution neural network. The dynamic adaptive weighting method is used to give different weights to the face block information, and the occluded face recognition is completed according to the results of face segmentation, which effectively reduces the impact of pose change and occlusion on face recognition. The experiment is analyzed from two aspects: frontal occlusion and multipose face occlusion. The results show that fewer blocks in the frontal occlusion experiment are conducive to maintaining good local integrity and relatively good recognition performance; When the proportion of frontal occlusion reaches 50%, the recognition rate of our algorithm can still be up to 92.68%, which is significantly better than other algorithms.
C1 [Shi, Jianguo; Xiu, Yu; Tang, Ganyi] Anhui Polytech Univ, Sch Comp & Informat, Wuhu, Anhui, Peoples R China.
C3 Anhui Polytechnic University
RP Shi, JG (corresponding author), Anhui Polytech Univ, Sch Comp & Informat, Wuhu, Anhui, Peoples R China.
EM shijianguo@ahpu.edu.cn
FU Anhui Polytechnic University [2019jyxm72, Xjky072019C03]
FX Anhui Polytechnic University, Grant/Award Numbers: 2019jyxm72,
   Xjky072019C03
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   Baraniuk RG, 2017, IEEE T INFORM THEORY, V63, P3368, DOI 10.1109/TIT.2017.2688381
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Tang JL, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105622
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
   Wang J, 2014, IEEE T CYBERNETICS, V44, P2368, DOI 10.1109/TCYB.2014.2307067
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Zeng D., 2020, ARXIV PREPRINT ARXIV
   Zhou ZH, 2009, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2009.5459383
NR 11
TC 3
Z9 3
U1 3
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2094
DI 10.1002/cav.2094
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 2S4AL
UT WOS:000821735900018
DA 2024-07-18
ER

PT J
AU Liu, XJ
   He, CY
   Zhao, HT
   Jia, JY
   Liu, C
AF Liu, Xiaojun
   He, Changyan
   Zhao, Hantao
   Jia, Jinyuan
   Liu, Chang
TI Building information modeling indoor path planning: A lightweight
   approach for complex BIM building
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE A star; BIM; IFC; environment modeling; indoor path planning; path
   searching
ID NAVIGATION; VISUALIZATION; FLOOR
AB The increased growth of building complexity confronts the limited device resources, especially for lightweight personal digital devices. The research of handling these complex buildings with limited resources has become a pivotal research topic. This paper explores the task of lightweight indoor path planning in complex building information modeling (BIM) buildings. Both the environment modeling and path searching are important addressed through indoor path planning with a lightweight web-based approach. A lightweight framework is designed in which the complex indoor path planning of a whole BIM building can be simplified into many local path searching of the building's interior spaces and all the online computation is decreased within no more than two simpler ones. In addition, an automatically indoor environment modeling method is proposed to partition the BIM building into many local interior spaces, constructing their spatial relationship and local grid map in a multilayered network. In the end, a heuristics optimized A star algorithm is implemented to speed up the shortest local path searching for the case of the path ends in a narrow corner. The final experiment shows that the online computational cost can be reduced greatly and dynamically to an average of 2 s when searching for the shortest path in a complex BIM building.
C1 [Liu, Xiaojun] Jiaxing Univ, Nanhu Coll, Jiaxing, Peoples R China.
   [He, Changyan] Jiaxing Univ, Normal Coll, Jiaxing, Peoples R China.
   [Zhao, Hantao] Southeast Univ, Sch Cyber Sci & Engn, Nanjing, Peoples R China.
   [Jia, Jinyuan] Tongji Univ, Sch Software Engn, Shanghai, Peoples R China.
   [Liu, Chang] Nanchang Hangkong Univ, Sch Informat Engn, Nanchang, Jiangxi, Peoples R China.
C3 Jiaxing University; Jiaxing University; Southeast University - China;
   Tongji University; Nanchang Hangkong University
RP Jia, JY (corresponding author), Tongji Univ, Sch Software Engn, Shanghai, Peoples R China.; Liu, C (corresponding author), Nanchang Hangkong Univ, Sch Informat Engn, Nanchang, Jiangxi, Peoples R China.
EM jyjia@tongji.edu.cn; lcsszz@163.com
RI zhao, hantao/GXN-1105-2022
OI Liu, Xiaojun/0000-0002-3653-9871
FU National Natural Science Foundation of China [6207071897, U19A2063];
   Science and Technology Research Fund of Jiangxi Provincial Education
   Department [GJJ200907]; Scientific Research Fund of Zhejiang Provincial
   Education Department [Y202044717]; Public Welfare Plan Research Project
   of Jiaxing City [2021AD10015]
FX The authors appreciate the comments and suggestions of all anonymous
   reviewers. This work and project were partly supported by the National
   Natural Science Foundation of China (6207071897 and U19A2063), the grant
   from the Science and Technology Research Fund of Jiangxi Provincial
   Education Department (GJJ200907), the Scientific Research Fund of
   Zhejiang Provincial Education Department (Y202044717), and the Public
   Welfare Plan Research Project of Jiaxing City (2021AD10015).
CR Aggarwal S, 2020, COMPUT COMMUN, V149, P270, DOI 10.1016/j.comcom.2019.10.014
   Amor R., 2010, Proc. CIB, VW78, P1, DOI [10.13140/2.1.1905.7609, DOI 10.13140/2.1.1905.7609]
   Hamieh A, 2020, AUTOMAT CONSTR, V113, DOI 10.1016/j.autcon.2020.103120
   Isikdag U, 2013, COMPUT ENVIRON URBAN, V41, P112, DOI 10.1016/j.compenvurbsys.2013.05.001
   Johansson M, 2015, AUTOMAT CONSTR, V54, P69, DOI 10.1016/j.autcon.2015.03.018
   Kim JS, 2019, ISPRS J PHOTOGRAMM, V147, P146, DOI 10.1016/j.isprsjprs.2018.11.017
   Lamarche F, 2009, COMPUT GRAPH FORUM, V28, P649, DOI 10.1111/j.1467-8659.2009.01405.x
   Lee J, 2004, GEOINFORMATICA, V8, P237, DOI 10.1023/B:GEIN.0000034820.93914.d0
   Lee JK, 2010, ENVIRON PLANN B, V37, P628, DOI 10.1068/b35124
   Li Jing, 2011, Journal of Software, V22, P2488, DOI 10.3724/SP.J.1001.2011.03927
   Lin YH, 2013, ADV ENG INFORM, V27, P189, DOI 10.1016/j.aei.2012.10.001
   Liu XJ, 2016, GRAPH MODELS, V88, P40, DOI 10.1016/j.gmod.2016.06.001
   Log T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19225050
   Lu P, 2019, APPL PHYS REV, V6, DOI 10.1063/1.5113955
   Stentz Anthony, 1997, INTELLIGENT UNMANNED
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Taneja S, 2016, AUTOMAT CONSTR, V61, P24, DOI 10.1016/j.autcon.2015.09.010
   Tsardoulias EG, 2016, J INTELL ROBOT SYST, V84, P829, DOI 10.1007/s10846-016-0362-z
   Xiong Q, 2017, EARTH SCI INFORM, V10, P69, DOI 10.1007/s12145-016-0279-x
   Yoon JinYi, 2018, [The Journal of Korean Institute of Communications and Information Sciences, 한국통신학회논문지], V43, P161, DOI 10.7840/kics.2018.43.1.161
   Yuan WJ, 2010, LECT NOTES GEOINF CA, P299, DOI 10.1007/978-3-642-12326-9_16
   Zafar MN, 2018, PROCEDIA COMPUT SCI, V133, P141, DOI 10.1016/j.procs.2018.07.018
   Zhang SP, 2018, J DISCRET MATH SCI C, V21, P393, DOI 10.1080/09720529.2018.1453624
   Zhou XP, 2020, IEEE T IND INFORM, V16, P7459, DOI 10.1109/TII.2020.2974252
   Zhu X., 2020, J GEOM, V45, P44
NR 25
TC 9
Z9 9
U1 6
U2 53
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2014
DI 10.1002/cav.2014
EA JUN 2021
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000659729800001
DA 2024-07-18
ER

PT J
AU Chen, QR
   Zhang, S
   Zheng, Y
AF Chen, Qiaorui
   Zhang, Shuai
   Zheng, Yao
TI Learning a deep motion interpolation network for human skeleton
   animations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA)
CY 2021
CL ELECTR NETWORK
SP Univ Ottawa
DE image inpainting; motion control; motion interpolation; animation; deep
   learning
AB Motion interpolation technology produces transition motion frames between two discrete movements. It is wildly used in video games, virtual reality and augmented reality. In the fields of computer graphics and animations, our data-driven method generates transition motions of two arbitrary animations without additional control signals. In this work, we propose a novel carefully designed deep learning framework, named deep motion interpolation network (DMIN), to learn human movement habits from a real dataset and then to perform the interpolation function specific for human motions. It is a data-driven approach to capture overall rhythm of two given discrete movements and generate natural in-between motion frames. The sequence-by-sequence architecture allows completing all missing frames within single forward inference, which reduces computation time for interpolation. Experiments on human motion datasets show that our network achieves promising interpolation performance. The ablation study demonstrates the effectiveness of the carefully designed DMIN.(1)
C1 [Chen, Qiaorui; Zhang, Shuai; Zheng, Yao] Zhejiang Univ, Ctr Engn & Sci Computat, Hangzhou 310027, Zhejiang, Peoples R China.
   [Chen, Qiaorui; Zhang, Shuai; Zheng, Yao] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Zhang, S (corresponding author), Zhejiang Univ, Ctr Engn & Sci Computat, Hangzhou 310027, Zhejiang, Peoples R China.; Zhang, S (corresponding author), Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Zhejiang, Peoples R China.
EM shuaizhang@zju.edu.cn
CR Casas D., 2012, P ACM SIGGRAPH S INT, P103, DOI DOI 10.1145/2159616.2159633
   Dam Erik B., 1998, Quaternions, Interpolation and Animation, P42, DOI DOI 10.1145/3422622
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Harvey FG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392480
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Henter GE, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417836
   Hernandez Alejandro, 2019, IEEE INT C COMP VIS
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Hong X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2033, DOI 10.1145/3343031.3351002
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Pavllo Dario, 2018, BRIT MACH VIS C, DOI [10.1109/HUMANOIDS.2018.8624922, DOI 10.1109/HUMANOIDS.2018.8624922]
   Pighin F., 2008, ACM SIGGRAPH CLASSES, P1
   Ramachandran P., 2017, CoRR
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Zhao H., 2015, arXiv 2015 1511.08861, DOI [10.48550/ARXIV.1511.08861, DOI 10.48550/ARXIV.1511.08861]
NR 20
TC 3
Z9 3
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
DI 10.1002/cav.2019
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA TH1NG
UT WOS:000671860800023
DA 2024-07-18
ER

PT J
AU Zha, HF
   Liu, R
   Yang, X
   Zhou, DS
   Zhang, Q
   Wei, XP
AF Zha, Hengfeng
   Liu, Rui
   Yang, Xin
   Zhou, Dongsheng
   Zhang, Qiang
   Wei, Xiaopeng
TI ASFNet: Adaptive multiscale segmentation fusion network for real-time
   semantic segmentation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer vision; multiscale fusion; real-time semantic segmentation;
   segmentation fusion
AB Recently, the development of deep learning has facilitated continuous progress in the field of computer vision. Pixel-level semantic segmentation serves as a fundamental task in computer vision. It achieves significant results by connecting wider and deeper backbone networks and building fine-grained segmentation heads. However, applications such as self-driving cars are more critical to the computational speed of the algorithms. The trade-off between accuracy and real-time performance of existing algorithms is still a challenging task. To address this challenge, this article proposes an adaptive multiscale segmentation fusion network to fuse multiscale contextual, which designs an adaptive multiscale segmentation fusion module based on an attention mechanism. Using segmentation fusion instead of feature fusion, the multiscale segmentation results are aggregated to obtain more precise segmentation results. The final results achieved 70.9% mIoU of accuracy in the Cityspace test set, processing images at 61 FPS when the input is 1024 x 2048. In addition, when adjusting the input size to 512 x 1024, the images are processed at 185 FPS.
C1 [Zha, Hengfeng; Liu, Rui; Zhou, Dongsheng; Zhang, Qiang] Dalian Univ, Sch Software Engn, Natl & Local Joint Engn Lab Comp Aided Design, Dalian 116622, Peoples R China.
   [Yang, Xin; Zhou, Dongsheng; Zhang, Qiang; Wei, Xiaopeng] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
C3 Dalian University; Dalian University of Technology
RP Zhou, DS (corresponding author), Dalian Univ, Sch Software Engn, Natl & Local Joint Engn Lab Comp Aided Design, Dalian 116622, Peoples R China.
EM zhouds@dlu.edu.cn
RI zhang, lin/IZQ-4870-2023; Zhang, Qiang/IWU-5000-2023; Zhang,
   Qiang/GXF-3105-2022; jiang, lei/IWE-1124-2023; Jiang, Tao/IWM-7503-2023;
   wei, xiao/ISB-6027-2023; zhang, qiang/HZJ-9551-2023
OI Zhang, Qiang/0000-0003-3776-9799; Zhou, Dongsheng/0000-0003-3414-9623;
   Zha, Hengfeng/0000-0002-9092-9467; , Xin/0000-0002-8046-722X
FU Key Program of NSFC [U1908214]; Special Project of Central Government
   Guiding Local Science and Technology Development [2021JH6/10500140];
   Program for the Liaoning Distinguished Professor; Program for Innovative
   Research Team in University of Liaoning Province and Dalian University;
   Science and Technology Innovation Fund of Dalian [2020JJ25CY001]
FX Key Program of NSFC, Grant/Award Number: U1908214); Special Project of
   Central Government Guiding Local Science and Technology Development,
   Grant/Award Number: 2021JH6/10500140; Program for the Liaoning
   Distinguished Professor, Program for Innovative Research Team in
   University of Liaoning Province and Dalian University, and in part by
   the Science and Technology Innovation Fund of Dalian, Grant/Award
   Number: 2020JJ25CY001
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen XY, 2020, IEEE T INTELL TRANSP, V21, P2990, DOI 10.1109/TITS.2019.2922252
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Hao SJ, 2020, IEEE ACCESS, V8, P55230, DOI 10.1109/ACCESS.2020.2981842
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kim J., 2019, P BRIT MACH VIS C MA
   Li H., 2019, P IEEE CVF C COMP VI, P9522, DOI [DOI 10.1109/CVPR.2019.00975, 10.1109/CVPR.2019.00975]
   Li H., 2018, P BRIT MACH VIS C
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lo S.-Y., 2019, ACM MULTIMEDIA ASIA, DOI [DOI 10.1145/3338533.3366558, 10.1145/3338533.3366558]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Paszke A., 2016, ARXIV160602147
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Tao A., 2020, Arxiv
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xiangtai Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P775, DOI 10.1007/978-3-030-58452-8_45
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zha H., 2020, P 12 AS C MACH LEARN
   Zhang Y., 2018, ABS181108201 ARXIV
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 30
TC 6
Z9 6
U1 1
U2 54
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2022
DI 10.1002/cav.2022
EA MAY 2021
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000654863600001
DA 2024-07-18
ER

PT J
AU Bai, JX
   Dai, R
   Dai, J
   Pan, JJ
AF Bai, Junxuan
   Dai, Rong
   Dai, Ju
   Pan, Junjun
TI EmoDescriptor: A hybrid feature for emotional classification in dance
   movements
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dance performances; emotional classification; feature fusion; hybrid
   feature
AB Similar to language and music, dance performances provide an effective way to express human emotions. With the abundance of the motion capture data, content-based motion retrieval and classification have been fiercely investigated. Although researchers attempt to interpret body language in terms of human emotions, the progress is limited by the scarce 3D motion database annotated with emotion labels. This article proposes a hybrid feature for emotional classification in dance performances. The hybrid feature is composed of an explicit feature and a deep feature. The explicit feature is calculated based on the Laban movement analysis, which considers the body, effort, shape, and space properties. The deep feature is obtained from latent representation through a 1D convolutional autoencoder. Eventually, we present an elaborate feature fusion network to attain the hybrid feature that is almost linearly separable. The abundant experiments demonstrate that our hybrid feature is superior to the separate features for the emotional classification in dance performances.
C1 [Bai, Junxuan; Dai, Rong; Pan, Junjun] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Bai, Junxuan; Dai, Ju; Pan, Junjun] Peng Cheng Lab, Shenzhen, Peoples R China.
C3 Beihang University; Peng Cheng Laboratory
RP Pan, JJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM pan_junjun@buaa.edu.cn
RI Bai, Junxuan/P-7282-2018; Pan, Junjun/A-1316-2013
OI Bai, Junxuan/0000-0002-7941-0584; Dai, Ju/0000-0002-9397-8539
FU Baidu academic collaboration program; Beijing Natural Science Foundation
   Haidian Primitive Innovation Joint Fund [L182016]; China Postdoctoral
   Science Foundation [2020M682827]; National Key R&D Program of China
   [2018YFC0115102]; National Natural Science Foundation of China
   [61872020, U20A20195]; Shenzhen Research Institute of Big Data; Global
   Visiting Fellowship of Bournemouth University
FX Baidu academic collaboration program; Beijing Natural Science Foundation
   Haidian Primitive Innovation Joint Fund, Grant/Award Number: L182016;
   China Postdoctoral Science Foundation, Grant/Award Number: 2020M682827;
   National Key R&D Program of China, Grant/Award Number: 2018YFC0115102;
   National Natural Science Foundation of China, Grant/Award Numbers:
   61872020, U20A20195; Shenzhen Research Institute of Big Data; Global
   Visiting Fellowship of Bournemouth University
CR Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392469
   [Anonymous], 2016, P IEEE C COMPUTER VI
   [Anonymous], 2020, DANCE MOCAP DATABASE
   Aristidou A, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099566
   Aristidou A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275038
   Aristidou A, 2015, COMPUT GRAPH FORUM, V34, P262, DOI 10.1111/cgf.12598
   Bortone I, 2018, IEEE T NEUR SYS REH, V26, P1469, DOI 10.1109/TNSRE.2018.2846814
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Chen ZM, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1952
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   Cimen G, 2013, COMPUT ANIMAT VIRT W, V24, P355, DOI 10.1002/cav.1509
   Durupinar F, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983620
   Faloutsos C, 2012, MOR KAUF D, P83
   GOODFELLOW I, 2016, DEEP LEARNING, P524
   Gupta K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P756, DOI [10.1109/VR46266.2020.000-5, 10.1109/VR46266.2020.1581313729558]
   Holden D, 2017, IEEE COMPUT GRAPH, V37, P42, DOI 10.1109/MCG.2017.3271464
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Kleinsmith A, 2011, IEEE T SYST MAN CY B, V41, P1027, DOI 10.1109/TSMCB.2010.2103557
   Laban/Bartenieff + somatic studies international, 2020, MOV AN
   Laraba S, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1782
   Lv Na, 2018, IEEE Trans Vis Comput Graph, V24, P1969, DOI 10.1109/TVCG.2017.2702620
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Men QH, 2019, VISUAL COMPUT, V35, P973, DOI 10.1007/s00371-019-01690-x
   Noroozi F, 2021, IEEE T AFFECT COMPUT, V12, P505, DOI 10.1109/TAFFC.2018.2874986
   Qi T, 2013, COMPUT ANIMAT VIRT W, V24, P399, DOI 10.1002/cav.1505
   Senecal S, 2016, COMPUT ANIMAT VIRT W, V27, P311, DOI 10.1002/cav.1714
   Shepstone SE, 2018, IEEE T AFFECT COMPUT, V9, P176, DOI 10.1109/TAFFC.2016.2598741
   Smith HJ, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340254
   Tian Y, 2019, IEEE SIGNAL PROC LET, V26, P1753, DOI 10.1109/LSP.2019.2942138
   Valcik J, 2016, COMPUT ANIMAT VIRT W, V27, P484, DOI 10.1002/cav.1674
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   Wen WH, 2010, SCI CHINA INFORM SCI, V53, P1774, DOI 10.1007/s11432-010-4001-1
   Xia SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766999
   Xue JX, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9654-6
   Yiannakides A, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1887
   Yong H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1251, DOI [10.1109/vr.2019.8797736, 10.1109/VR.2019.8797736]
   Yumer ME, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925955
   Zao L, 2014, IEEE SIGNAL PROC LET, V21, P620, DOI 10.1109/LSP.2014.2311435
   Zhang HM, 2018, IEEE T MULTIMEDIA, V20, P2824, DOI 10.1109/TMM.2018.2808760
NR 41
TC 0
Z9 0
U1 0
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2021
VL 32
IS 6
AR e1996
DI 10.1002/cav.1996
EA APR 2021
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XW9UC
UT WOS:000638518200001
DA 2024-07-18
ER

PT J
AU Kim, JH
   Lee, J
AF Kim, Jong-Hyun
   Lee, Jung
TI Synthesizing Large-Scale Fluid Simulations with Surface and Wave Foams
   via Sharp Wave Pattern and Cloudy Foam
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fluid simulation; foam effects; surface foam; wave foam
ID ANIMATION
AB This paper presents a unified framework to simulate surface and wave foams efficiently and realistically. The framework is designed first to project thee-dimensional (3D) water particles from an underlying water solver onto two-dimensional screen space to reduce the computational complexity of determining where foam particles should be generated. Because foam effects are often created primarily in fast and complicated water flows, we analyze the acceleration and curvature values to identify the areas exhibiting such flow patterns. Foam particles are emitted from the identified areas in 3D space, and each foam particle is advected according to its type, which is classified on the basis of velocity, thereby capturing the essential characteristics of foam wave motions. We improve the realism of the resulting foam by classifying it into two types: surface foam and wave foam. Wave foam is characterized by the sharp wave patterns of torrential flows, and surface foam is characterized by a cloudy foam shape, even in water with reduced motion. Based on these features, we propose a technique to correct the velocity and position of a foam particle. In addition, we propose a kernel technique using the screen space density to reduce redundant foam particles efficiently, resulting in improved overall memory efficiency without loss of visual detail in terms of foam effects. Experiments convincingly demonstrate that the proposed approach is efficient and easy to use while delivering high-quality results.
C1 [Kim, Jong-Hyun] Kangnam Univ, Sch Software Applicat, Yongin, Gyeonggi, South Korea.
   [Lee, Jung] Hallym Univ, Sch Software, Chunchon, Gangwon, South Korea.
C3 Kangnam University; Hallym University
RP Lee, J (corresponding author), Hallym Univ, Sch Software, Chunchon, Gangwon, South Korea.
EM airjung@hallym.ac.kr
OI Kim, Jong-Hyun/0000-0003-1603-2675
FU Hallym University Research Fund [HRF-202011-009]; National Research
   Foundation of Korea - Ministry of Science, ICT & Future Planning
   [2017R1C1B5074984]
FX Hallym University Research Fund, Grant/Award Number: HRF-202011-009;
   National Research Foundation of Korea funded by Ministry of Science, ICT
   & Future Planning, Grant/Award Number: 2017R1C1B5074984
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   [Anonymous], 2010, P ACM SIGGRAPH AS 20
   [Anonymous], 2009, THESIS
   [Anonymous], 2006, ACM SIGGRAPH
   Bagar F, 2010, COMPUT GRAPH FORUM, V29, P1383, DOI 10.1111/j.1467-8659.2010.01734.x
   Batty C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276502
   Bender J, 2019, IEEE T VIS COMPUT GR, V25, P2284, DOI 10.1109/TVCG.2018.2832080
   Botsch Mario, 2005, P EUROGRAPHICSIEEE V, P17, DOI [DOI 10.2312/SPBG/SPBG05/017-024, 10.1109/PBG.2005.194059.6]
   Cleary PW, 2007, P ACM SIGGRAPH 2007
   Crespo AJC, 2015, COMPUT PHYS COMMUN, V187, P204, DOI 10.1016/j.cpc.2014.10.004
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Garcia-Feal O, P 11 INT SPHERIC WOR
   Greenwood S., 2004, Proceedings of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P287
   Harlow F.H., 1964, Methods Comput. Phys., V3, P319, DOI DOI 10.1007/BF00230516
   Hong JM, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239498
   Hong W, 2008, VISUAL COMPUT, V24, P535, DOI 10.1007/s00371-008-0234-z
   Ihmsen M, 2012, VISUAL COMPUT, V28, P669, DOI 10.1007/s00371-012-0697-9
   Johanson C., 2004, REAL TIME WATER REND
   Kim J., 2006, Proc ACM SIGGRAPH/Eurograph Symp Comp Anim, SCA '06, P335
   Kim T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360649
   Lee Ang., 2012, Life of Pi
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   MA C., 2009, ACM Trans. Graph, V28, P1
   Mihalef V, 2009, COMPUT GRAPH FORUM, V28, P229, DOI 10.1111/j.1467-8659.2009.01362.x
   Müller M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P9
   Nielsen MB, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461918
   Peterson W, 2006, POSEDION FEATURED SO
   Pfaff T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185608
   Pfaff T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618467
   Qiu YX, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1741
   Sirignano W.A., 1999, FLUID DYNAMICS TRANS, DOI 10.1017/CBO9780511529566
   Takahashi T, 2003, COMPUT GRAPH FORUM, V22, P391, DOI 10.1111/1467-8659.00686
   Thürey N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P191
   Van der Laan W.J., 2009, P 2009 S INT 3D GRAP, P91, DOI [DOI 10.1145/1507149.1507164, 10.1145/1507149.1507164]
   Vaughn Matthew, 2011, X-Men: First Class
   Wang CB, 2013, VISUAL COMPUT, V29, P937, DOI 10.1007/s00371-013-0849-6
   Wang CB, 2019, COMPUT GRAPH-UK, V78, P87, DOI 10.1016/j.cag.2018.12.001
   Yan H, 2009, COMPUT ANIMAT VIRT W, V20, P417, DOI 10.1002/cav.300
   Yang LP, 2014, COMPUT GRAPH FORUM, V33, P199, DOI 10.1111/cgf.12488
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 41
TC 4
Z9 4
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2021
VL 32
IS 2
AR e1984
DI 10.1002/cav.1984
EA DEC 2020
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RK2HP
UT WOS:000595455900001
DA 2024-07-18
ER

PT J
AU Zhang, D
   Lv, CL
   Liu, N
   Wu, ZK
   Wang, XC
AF Zhang, Dan
   Lv, Chenglei
   Liu, Na
   Wu, Zhongke
   Wang, Xingce
TI 3D face modeling from single image based on discrete shape space
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D face modeling; discrete shape space; facial landmarks; geodesic path
ID VIEWS
AB In this article, we propose a novel 3D face modeling method which constructs a new 3D face model from a low-dimensional feature space consisted of a large set of blend shapes based on the discrete shape space theory. The details of original face features are completely retained during the modeling process and a large number of new natural faces are constructed by several face samples. The optimization process of our method is independently decoupled for different facial attributes (identity, expression, and head pose), which improves the application flexibility and reduces the probability of it falling into a local optimal situation. The new facial data with new attributes are constructed based on the geodesic path search in discrete shape space with sufficient freedom and accuracy. In experiments and applications based on public databases (Helen, LFW, and CUFS), the modeling results show our method can provide high-quality 3D face model, with enough freedom for face expression editing and natural facial expression animation from a small facial sample set.
C1 [Zhang, Dan; Lv, Chenglei; Liu, Na; Wu, Zhongke; Wang, Xingce] Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.
C3 Beijing Normal University
RP Wang, XC (corresponding author), Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.
EM wangxingce@bnu.edu.cn
RI Zhang, Dan/AFA-2608-2022
OI Zhang, Dan/0000-0002-7295-4837; liu, daisy/0000-0002-4572-4155; Dan,
   Zhang/0000-0001-5676-0656
FU Beijing Natural Science Foundation of China [4172033]; National Key R&D
   Program of China [2017YFB1002604]; BRICS of China [2017YFE0100500]
FX Beijing Natural Science Foundation of China, Grant/Award Number:
   No.4172033; National Key R&D Program of China, Grant/Award Number: No.
   2017YFB1002604; the National Key Cooperation between the BRICS of China,
   Grant/Award Number: No.2017YFE0100500
CR Alashkar T, 2016, PATTERN RECOGN, V57, P21, DOI 10.1016/j.patcog.2016.03.013
   [Anonymous], 2016, AS C COMP VIS WORKSH
   Ansari AN, 2005, PATTERN RECOGN, V38, P2549, DOI 10.1016/j.patcog.2005.04.016
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   DeCarlo D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P67, DOI 10.1145/280814.280823
   Guo YD, 2019, IEEE T PATTERN ANAL, V41, P1294, DOI 10.1109/TPAMI.2018.2837742
   Han XG, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073629
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jin H, 2017, COMPUT AIDED GEOM D, V50, P1, DOI 10.1016/j.cagd.2016.11.001
   Joshi P., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P187
   Kahler M, 2012, THESIS
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81
   Kurtek S, 2015, COMPUT GRAPH-UK, V51, P52, DOI 10.1016/j.cag.2015.05.027
   Lee J. M., 2006, RIEMANNIAN MANIFOLDS
   Lee KS, 2001, REAL-TIME IMAGING, V7, P173, DOI 10.1006/rtim.2000.0241
   Longbo Jiang X.-z. Y, 2017, ACS Sustain. Chem. Eng., V5, P1
   Lu X., 2006, Proc. IEEE Conf. Computer Vision and Pattern Recognition, V2, P1377
   Lüthi M, 2018, IEEE T PATTERN ANAL, V40, P1860, DOI 10.1109/TPAMI.2017.2739743
   NEUMANN T., 2013, ACM T GRAPHIC, V32, P6
   Patel A, 2009, PROC CVPR IEEE, P1327, DOI 10.1109/CVPRW.2009.5206522
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Pighin F., 2005, ACM SIGGRAPH, P9
   Schönborn S, 2017, INT J COMPUT VISION, V123, P160, DOI 10.1007/s11263-016-0967-5
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Wu CL, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925882
   ZHU X, 2015, PROC CVPR IEEE, V1, P787
NR 28
TC 2
Z9 2
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1943
DI 10.1002/cav.1943
EA SEP 2020
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000568621400001
DA 2024-07-18
ER

PT J
AU Ye, ZH
   Li, GQ
   Yao, BY
   Xian, CH
AF Ye, Zehao
   Li, Guiqing
   Yao, Biyuan
   Xian, Chuhua
TI HAO-CNN: Filament-aware hair reconstruction based on volumetric vector
   fields
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE adaptive O-CNN; hair modeling; single-view reconstruction
AB Hair modeling plays an important role in computer animation, virtual reality, and other applications. This paper proposes an encoder-decoder network, named HAO-CNN, to recover 3D hair strand models from a single image. Specifically, HAO-CNN generates a volumetric vector field (VVF) from the oriented map of hairstyles. However, instead of directly working on the full resolution VVFs, we introduce the adapted O-CNN to predict the adaptive representation of VVFs in order to greatly reduce the memory cost. In addition, we fuse the features from different layers of the encoding stage for both capturing the global structure and being aware of hair filaments. Considering the difficulty of acquiring true three-dimensional (3D) hair models, we augment the dataset with 340 3D hair models by 1,800 hair models via interactive editing using the software and render their oriented maps as training data. Then given a hair photo associated with human head, we segment out the hair region, compute its two-dimensional oriented map using Gabor filter, and feed it into the network to produce a hair volumetric vector field which is then converted into hairline models using an improved VVF-to-strands algorithm. This greatly decreases the time cost of approaches based on volumetric vector fields.
C1 [Ye, Zehao; Li, Guiqing; Yao, Biyuan; Xian, Chuhua] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
C3 South China University of Technology
RP Li, GQ (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
EM ligq@scut.edu.cn
RI Yao, Biyuan/KHE-3266-2024
FU National Natural Science Foundation of China [61572202, 61972160];
   Natural Science Funding of Guangdong Province [2019A1515011793]
FX National Natural Science Foundation of China, Grant/Award Numbers:
   61572202, 61972160; Natural Science Funding of Guangdong Province,
   Grant/Award Number: 2019A1515011793
CR Beeler T, 2015, ACM T GRAPHIC, V31, P1
   Chai ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925961
   Chai ML, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461990
   Chai ML, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185612
   Echevarria JI, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601133
   Herrera TL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366165
   Hu LW, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661254
   Hu LW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766931
   Hu LW, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601194
   Kingma D. P., 2014, arXiv
   Kingma DP, 2013, ARXIV
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Saito S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275019
   Shen Y, 2020, IEEE T VIS COMPUT GR, V99, P1
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Wang P., 2017, INT J ROBUST NONLIN, V4, P1
   Wang P-S, 2018, ACM Transactions on Graphics (TOG), V37, P1
   Xu ZX, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661284
   Zhang M, 2019, VIS INFORM, V3, P102, DOI 10.1016/j.visinf.2019.06.001
   Zhou Y, 2018, LECT NOTES COMPUT SC, V11215, P249, DOI 10.1007/978-3-030-01252-6_15
NR 22
TC 2
Z9 2
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1945
DI 10.1002/cav.1945
EA SEP 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000566770800001
DA 2024-07-18
ER

PT J
AU Koilias, A
   Mousas, C
   Anagnostopoulos, CN
AF Koilias, Alexandros
   Mousas, Christos
   Anagnostopoulos, Christos-Nikolaos
TI I feel a moving crowd surrounds me: Exploring tactile feedback during
   immersive walking in a virtual crowd
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human-crowd interaction; human movement; self-reported ratings; tactile
   feedback; virtual crowd
ID ENVIRONMENTS; PEDESTRIANS; DISTANCE; BEHAVIOR; MOTION
AB The aim of our study was to investigate whether different tactile feedback conditions could affect the behavior of participants who were instructed to walk within a virtual reality environment surrounded by a virtual crowd of people. A road crossing scenario that takes place in a virtual metropolitan city was developed for this study. Participants were asked to walk toward the opposite sidewalk while wearing a tactile vest. At each road crossing, one of several tactile feedback conditions was generated, including No Tactile, Side Tactile, Back Tactile, Front Tactile, Accurate Tactile, and Random Tactile. During the virtual road crossing, the movement of the participants was captured, and movement-related measurements were extracted and analyzed to evaluate the effects of tactile feedback on the participant's movement behavior. Additional data were collected through the distribution of a questionnaire to consider self-reported ratings of the experimental conditions. The results revealed that tactile feedback conditions had significant effects on movement behavior, while the participants' ratings also indicated that they were affected by the tactile feedback conditions. We found that when the participants were immersed in a high-density crowd simulation, they became sensitive to tactile feedback. However, they were not able to distinguish between the accurate feedback and the random feedback.
C1 [Koilias, Alexandros; Anagnostopoulos, Christos-Nikolaos] Univ Aegean, Dept Cultural Technol & Commun, Mitilini, Greece.
   [Mousas, Christos] Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
C3 University of Aegean; Purdue University System; Purdue University
RP Mousas, C (corresponding author), Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
EM cmousas@purdue.edu
RI Anagnostopoulos, Christos-Nikolaos/AAR-2988-2021; Mousas,
   Christos/AGV-3533-2022
OI Anagnostopoulos, Christos-Nikolaos/0000-0002-4496-275X; Mousas,
   Christos/0000-0003-0955-7959
CR Babu SV, 2011, IEEE T VIS COMPUT GR, V17, P14, DOI 10.1109/TVCG.2009.211
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Borges M, 2018, IEEE INT C INT ROBOT, P2610, DOI 10.1109/IROS.2018.8593707
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   Chihak BJ, 2010, J EXP PSYCHOL HUMAN, V36, P1535, DOI 10.1037/a0020560
   Cohen J., 1988, STAT POWER ANAL BEHA
   Crucianelli Laura, 2013, Front Psychol, V4, P703, DOI 10.3389/fpsyg.2013.00703
   Dickinson P, 2019, VIRTUAL REAL-LONDON, V23, P19, DOI 10.1007/s10055-018-0365-0
   Dim NK, 2017, INT J HUM-COMPUT ST, V97, P34, DOI 10.1016/j.ijhcs.2016.08.002
   DiSalvo C, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P403
   Ducourant T, 2005, NEUROSCI LETT, V389, P6, DOI 10.1016/j.neulet.2005.06.052
   Faria JJ, 2010, BEHAV ECOL, V21, P1236, DOI 10.1093/beheco/arq141
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Foottit J, 2016, ARXIV160408322
   Fröhner J, 2019, IEEE T HAPTICS, V12, P339, DOI 10.1109/TOH.2018.2889497
   García-Valle G, 2018, IEEE ACCESS, V6, P7224, DOI 10.1109/ACCESS.2017.2782254
   Gehrke L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300657
   Ghasemi A, 2012, INT J ENDOCRINOL MET, V10, P486, DOI 10.5812/ijem.3505
   Giannopoulos E, 2011, BRAIN RES BULL, V85, P276, DOI 10.1016/j.brainresbull.2010.11.012
   Gobron SC, 2015, LECT NOTES COMPUT SC, V9254, P199, DOI 10.1007/978-3-319-22888-4_15
   Gonzalez-Franco M, 2019, IEEE T HAPTICS, V12, P319, DOI 10.1109/TOH.2019.2925038
   Grechkin TY, 2013, J EXP PSYCHOL HUMAN, V39, P23, DOI 10.1037/a0029716
   Gronau N, 2011, PROCEEDINGS OF THE 12TH EUROPEAN CONFERENCE ON KNOWLEDGE MANAGEMENT, VOLS 1 AND 2, P349
   Guéguen N, 2001, J SOC PSYCHOL, V141, P413, DOI 10.1080/00224540109600562
   Haans A., 2007, P AC M C HUMAN FACTO, P2405
   Hou XY, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P39, DOI 10.1109/CW.2014.14
   Israr A, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2641570
   Jiang Y., 2016, P ACM S APPL PERCEPT, P57, DOI [DOI 10.1145/2931002.2931003, 10.1145/2931002.2931003, DOI 10.1145/2931002]
   Jiang YY, 2016, P IEEE VIRT REAL ANN, P193, DOI 10.1109/VR.2016.7504719
   Kappers AML, 2011, PHILOS T R SOC B, V366, P3106, DOI 10.1098/rstb.2011.0171
   Kapur Pulkit, 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P519, DOI 10.1109/HAPTIC.2010.5444606
   Karamouzas I., 2010, Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology, VRST '10, P183, DOI DOI 10.1145/1889863
   Keedwell AD, 2015, LATIN SQUARES AND THEIR APPLICATIONS, 2ND EDITION, P1
   Koilias A, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1928
   Koilias A, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6020018
   KROGMEIER C, 2019, COMPUT ANIMAT VIRT W, V30, P3
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   Lee J, 2016, IEEE T HUM-MACH SYST, V47, P112
   Lee S, 2004, P INT C ART TEL
   LEFKOWITZ M, 1955, J Abnorm Psychol, V51, P704, DOI 10.1037/h0042000
   Lemercier S, 2012, COMPUT GRAPH FORUM, V31, P489, DOI 10.1111/j.1467-8659.2012.03028.x
   Li-Te Cheng, 1996, Proceedings ACM Multimedia 96, P243, DOI 10.1145/244130.244220
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Mousas C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P626, DOI [10.1109/VR46266.2020.00-19, 10.1109/VR46266.2020.1581211592060]
   Mousas C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P726, DOI [10.1109/VR.2019.8798043, 10.1109/vr.2019.8798043]
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Nelson M, 2019, P INT C VIRT REAL CO
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Nordahl R, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P73, DOI 10.1109/VR.2012.6180888
   Olivier AH, 2018, IEEE T VIS COMPUT GR, V24, P2251, DOI 10.1109/TVCG.2017.2714665
   Pabon S., 2007, 10 ANN INT WORKSHOP, P345
   Pan XN, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032931
   Pelechano Nuria., 2008, P 7 INT JOINT C AUTO, V1, P136
   Perrinet J, 2013, P ACM S APPL PERC, P59
   Pfeiffer M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2505, DOI 10.1145/2702123.2702190
   Pham QC, 2007, EUR J NEUROSCI, V26, P2391, DOI 10.1111/j.1460-9568.2007.05835.x
   Popov A, 2016, AEROSP CONF PROC
   Richter H, 2011, P AUGM HUM INT C, P1
   Rio KW, 2018, P ROY SOC B-BIOL SCI, V285, DOI 10.1098/rspb.2018.0611
   Rio KW, 2014, J VISION, V14, DOI 10.1167/14.2.4
   ROS A, 2018, FOLLOWER BEHAV VIRTU
   Serafin G., 2004, SOUND DESIGN ENHANCE
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Stevens E, 2013, J PEDIATR PSYCHOL, V38, P285, DOI 10.1093/jpepsy/jss116
   Still GK, 2014, INTRODUCTION TO CROWD SCIENCE, P1, DOI 10.1201/b17097
   Tanaka K, 2002, IFAC P SER, P309
   Tsalamlal MY, 2015, J MULTIMODAL USER IN, V9, P69, DOI 10.1007/s12193-014-0162-3
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/TOH.2012.51, 10.1109/ToH.2012.51]
   van der Meulen E, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P102, DOI [10.1109/ISMAR-Adjunct.2016.0050, 10.1109/ISMAR-Adjunct.2016.43]
   Ware C., 1999, ACM Transactions on Computer-Human Interaction, V6, P162, DOI 10.1145/319091.319102
   Warren WH, 2018, CURR DIR PSYCHOL SCI, V27, P232, DOI 10.1177/0963721417746743
   Wilcox L. M., 2003, P HUMAN FACTORS ERGO, V47, P2097, DOI [10.1177/154193120304702004, DOI 10.1177/154193120304702004]
   Wilson Erin, 2018, Adv Simul (Lond), V3, P21, DOI 10.1186/s41077-018-0080-7
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yang U, 2004, P IEEE VIRT REAL ANN, P27, DOI 10.1109/VR.2004.1310052
   Zhao S, 2015, P INT C INT DES CHIL, P239, DOI 10.1145/2771839.2771886
NR 78
TC 16
Z9 18
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1963
DI 10.1002/cav.1963
EA SEP 2020
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA OG1RS
UT WOS:000566458200001
DA 2024-07-18
ER

PT J
AU Liao, J
   Fu, YP
   Yan, QA
   Xiao, CX
AF Liao, Jie
   Fu, Yanping
   Yan, Qingan
   Xiao, Chunxia
TI Transparent object segmentation from casually captured videos
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE object segmentation; saliency estimation; video processing
AB Segmentation of transparent objects from sequences can be very useful in computer vision applications. However, without additional auxiliary information it can be hard work for traditional segmentation methods, as light in the transparent area captured by RGB cameras mostly derive from the background and the appearance of transparent objects changes with surroundings. In this article, we present a from-coarse-to-fine transparent object segmentation method, which utilizes trajectory clustering to roughly distinguish the transparent from the background and refine the segmentation based on combination information of color and distortion. We further incorporate the transparency saliency with color and trajectory smoothness throughout the video to acquire a spatiotemporal segmentation based on graph-cut. We conduct our method on various datasets. The results demonstrate that our method can successfully segment transparent objects from the background.
C1 [Liao, Jie; Fu, Yanping; Xiao, Chunxia] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Yan, Qingan] JD Com, Silicon Valley Res Ctr Multimedia Software, Mountain View, CA USA.
C3 Wuhan University
RP Xiao, CX (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
EM cxxiao@whu.edu.cn
RI Fu, Yanping/AAE-4921-2022
OI Fu, Yanping/0000-0002-4191-4779; Liao, Jie/0000-0002-4084-2427
FU Key Technological Innovation Projects of Hubei Province [2018AAA062];
   National Key Research and Development Program of China [2017YFB1002600];
   National Natural Science Foundation of China [61672390, 61972298]
FX Key Technological Innovation Projects of Hubei Province, Grant/Award
   Number: 2018AAA062; National Key Research and Development Program of
   China, Grant/Award Number: 2017YFB1002600; National Natural Science
   Foundation of China, Grant/Award Number: No. 61672390, 61972298
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ben-Ezra M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1025
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Chen YD, 2013, COMPUT ANIMAT VIRT W, V24, P387, DOI 10.1002/cav.1508
   Guanying Chen, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P9233, DOI 10.1109/CVPR.2018.00962
   Hu B, 2017, PROT CONTR MOD POW, V2, DOI 10.1186/s41601-017-0037-1
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Liao J, 2019, COMPUT GRAPH FORUM, V38, P335, DOI 10.1111/cgf.13841
   McHenry K, 2005, PROC CVPR IEEE, P973
   McHenry K., 2006, CVPR, P1038, DOI DOI 10.1109/CVPR.2006.28
   Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Wang T, 2013, IEEE IMAGE PROC, P2944, DOI 10.1109/ICIP.2013.6738606
   Wang T, 2012, INT C PATT RECOG, P3783
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wei M, 2019, VISUAL COMPUT, V35, P1
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Xu YC, 2015, IEEE I CONF COMP VIS, P3442, DOI 10.1109/ICCV.2015.393
   Xu YC, 2015, COMPUT VIS IMAGE UND, V139, P122, DOI 10.1016/j.cviu.2015.02.009
   Yan Q., 2017, P C COMP VIS PATT RE, P3836
   Yan QA, 2016, COMPUT GRAPH FORUM, V35, P1, DOI 10.1111/cgf.12998
   Yan QA, 2014, COMPUT GRAPH FORUM, V33, P339, DOI 10.1111/cgf.12502
   Zhang L, 2017, IEEE T IMAGE PROCESS, V26, P4114, DOI 10.1109/TIP.2017.2712283
   Zhao X, 2012, COMPUT ANIMAT VIRT W, V23, P407, DOI 10.1002/cav.1464
NR 25
TC 2
Z9 2
U1 1
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1950
DI 10.1002/cav.1950
EA SEP 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000564349500001
DA 2024-07-18
ER

PT J
AU Xiang, W
   Yao, XR
   Wang, H
   Jin, XG
AF Xiang, Wei
   Yao, Xinran
   Wang, He
   Jin, Xiaogang
TI FASTSWARM: A data-driven framework for real-time flying insect swarm
   simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE collective behavior; data-driven; insect swarm simulation; optimization;
   real time
ID CROWD
AB Insect swarms are common phenomena in nature and therefore have been actively pursued in computer animation. Realistic insect swarm simulation is difficult due to two challenges: high-fidelity behaviors and large scales, which make the simulation practice subject to laborious manual work and excessive trial-and-error processes. To address both challenges, we present a novel data-driven framework, FASTSWARM, to model complex behaviors of flying insects based on real-world data and simulate plausible animations of flying insect swarms. FASTSWARM has a linear time complexity and achieves real-time performance for large swarms. The high-fidelity behavior model of FASTSWARM explicitly takes into consideration the most common behaviors of flying insects, including the interactions among insects such as repulsion and attraction, self-propelled behaviors such as target following and obstacle avoidance, and other characteristics such as random movements. To achieve scalability, an energy minimization problem is formed with different behaviors modeled as energy terms, where the minimizer is the desired behavior. The minimizer is computed from the real-world data, which ensures the plausibility of the simulation results. Extensive simulation results and evaluations show that FASTSWARM isversatilein simulating various swarm behaviors,high fidelitymeasured by various metrics, easilycontrollablein inducing user controls and highlyscalable.
C1 [Xiang, Wei; Yao, Xinran; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
   [Wang, He] Univ Leeds, Sch Comp, Leeds, W Yorkshire, England.
   [Jin, Xiaogang] ZJU Tencent Game & Intelligent Graph Innovat Tech, Hangzhou, Peoples R China.
C3 Zhejiang University; University of Leeds
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
EM jin@cad.zju.edu.cn
RI Wang, He/ABD-8303-2021
OI Wang, He/0000-0002-2281-5679; Xiang, Wei/0000-0002-0656-2851; Jin,
   Xiaogang/0000-0001-7339-2920
FU Key Research and Development Program of Zhejiang Province [2018C01090,
   2020C03096]; National Key R&D Program of China [2017YFB1002600];
   National Natural Science Foundation of China [61972344]; Research
   England Strategic Priorities Fund
FX Key Research and Development Program of Zhejiang Province, Grant/Award
   Numbers: 2018C01090, 2020C03096; National Key R&D Program of China,
   Grant/Award Number: 2017YFB1002600; National Natural Science Foundation
   of China, Grant/Award Number: 61972344; Research England Strategic
   Priorities Fund
CR [Anonymous], 1987, COMPUTER GRAPHICS
   Bandala AA, 2014, J ADV COMPUT INTELL, V18, P745, DOI 10.20965/jaciii.2014.p0745
   Bi HK, 2020, IEEE T VIS COMPUT GR, V26, P2335, DOI 10.1109/TVCG.2018.2889834
   Blum Christian, 2008, P43, DOI 10.1007/978-3-540-74089-6_2
   Bozkurt A, 2014, PROC SPIE, V9091, DOI 10.1117/12.2053906
   Bridson R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276435, 10.1145/1239451.1239497]
   Chao QW, 2018, IEEE T VIS COMPUT GR, V24, P1167, DOI 10.1109/TVCG.2017.2648790
   Chao QW, 2013, GRAPH MODELS, V75, P305, DOI 10.1016/j.gmod.2013.07.003
   Charalambous P, 2014, COMPUT GRAPH FORUM, V33, P95, DOI 10.1111/cgf.12403
   Colpan AM, 2020, ROUT INT STUD BUS HI, P3
   Ge H, 2019, ANN ONCOL, V30, P3
   Guo SH, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1779
   Halloy J, 2007, SCIENCE, V318, P1155, DOI 10.1126/science.1144259
   Ju Eunjung., 2010, ACM T GRAPHIC, V29, P1
   Kelley DH, 2013, SCI REP-UK, V3, DOI 10.1038/srep01073
   Khaluf Y, 2019, J COMPUT SCI-NETH, V31, P33, DOI 10.1016/j.jocs.2018.12.012
   Lee KC, 2007, 2007 MOBILE NETWORKING FOR VEHICULAR ENVIRONMENTS, P109, DOI 10.1109/MOVE.2007.4300814
   Li WZ, 2015, COMPUT GRAPH FORUM, V34, P425, DOI 10.1111/cgf.12572
   Li Y., 2012, Eurographics Symposium on Computer Animation, P201
   Lukeman R, 2010, P NATL ACAD SCI USA, V107, P12576, DOI 10.1073/pnas.1001763107
   Puckett JG, 2014, SCI REP-UK, V4, DOI 10.1038/srep04766
   Ren JP, 2021, IEEE T VIS COMPUT GR, V27, P1953, DOI 10.1109/TVCG.2019.2946769
   Ren JP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155698
   Sinhuber M, 2017, PHYS REV LETT, V119, DOI 10.1103/PhysRevLett.119.178003
   Wang XJ, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12277
   Wang Xinjie, 2015, P 14 ACM SIGGRAPHEUR, P111, DOI DOI 10.1145/2786784.2786790
   Wang YX, 2019, J ENG-JOE, V2019, P7365, DOI 10.1049/joe.2019.0599
   Wu HS, 2011, OPT EXPRESS, V19, P7646, DOI 10.1364/OE.19.007646
   Xiang W, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1867
   Zhao MB, 2013, IEEE ACM DIS SIM, P125, DOI 10.1109/DS-RT.2013.21
NR 30
TC 4
Z9 4
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1957
DI 10.1002/cav.1957
EA SEP 2020
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000564475900001
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Jiang, Q
   Chen, XL
AF Jiang, Quan
   Chen, Xiliang
TI Landslide-generated wave hazard prediction based on multiphase flow
   model of DualSPHysics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE DualSPHysics; fluid-solid coupling; landslide and tsunamis; multiphase
   flow; prediction
ID SMOOTHED PARTICLE HYDRODYNAMICS
AB Because involving a large number of discrete particles interacting with water, simulating the fluid-solid coupling problem of landslide-generated waves in a virtual environment is very difficult. This paper employs the DualSPHysics multiphase flow model to relatively easily simulate the dynamics of landslide-generated waves in large scales. In addition, the simulation results are well visualized by the marching cubes algorithm. It is found that, when the factors of the landslide scale, the water length, and water depth are fixed, the initial maximum wave height decreases as the water width increases. After the water is squeezed by the falling slider, one-way and two-way propagations of the surge are generated under 2D and 3D conditions, respectively. In addition, under the true-3D condition, although the initial swell generated is smaller than the 2D and quasi-2D conditions, it will generate a large wave height during the climbing and undulation of the near shore. In the 2D condition, the surge generated is almost the largest. Therefore, when using the DualSPHysics multiphase flow model to predict the maximum wave height generated by landslide surges, a 2D simulation can be used to improve work efficiency.
C1 [Jiang, Quan; Chen, Xiliang] Chinese Acad Sci, Inst Adv Mfg Technol, Ningbo Inst Mat Technol & Engn, Ningbo 315201, Peoples R China.
   [Jiang, Quan] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Chen, Xiliang] Taizhou Univ, Sch Aeronaut Engn, Taizhou 318000, Peoples R China.
C3 Chinese Academy of Sciences; Ningbo Institute of Materials Technology
   and Engineering, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS; Taizhou University
RP Chen, XL (corresponding author), Chinese Acad Sci, Inst Adv Mfg Technol, Ningbo Inst Mat Technol & Engn, Ningbo 315201, Peoples R China.; Chen, XL (corresponding author), Taizhou Univ, Sch Aeronaut Engn, Taizhou 318000, Peoples R China.
EM chenxl@nimte.ac.cn
FU National High Technology Research and Development Program of China
   [2015AA016403]
FX National High Technology Research and Development Program of China,
   Grant/Award Number: 2015AA016403
CR Aller AB, 2015, THESIS
   Altomare C, 2014, COMPUT STRUCT, V130, P34, DOI 10.1016/j.compstruc.2013.10.011
   Altomare C, 2015, COAST ENG, V96, P1, DOI 10.1016/j.coastaleng.2014.11.001
   Crespo AJC, 2007, CMC-COMPUT MATER CON, V5, P173
   Crespo AJC, 2015, COMPUT PHYS COMMUN, V187, P204, DOI 10.1016/j.cpc.2014.10.004
   Fourtakas G, 2016, ADV WATER RESOUR, V92, P186, DOI 10.1016/j.advwatres.2016.04.009
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   [黄波林 Huang Bolin], 2018, [岩石力学与工程学报, Chinese Journal of Rock Mechanics and Engineering], V37, P621
   Huang C, 2015, COMPUT ANIMAT VIRT W, V26, P43, DOI 10.1002/cav.1564
   Lind SJ, 2012, J COMPUT PHYS, V231, P1499, DOI 10.1016/j.jcp.2011.10.027
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Molteni D, 2009, COMPUT PHYS COMMUN, V180, P861, DOI 10.1016/j.cpc.2008.12.004
   Violeau D, 2012, FLUID MECHANICS AND THE SPH METHOD: THEORY AND APPLICATIONS, P1, DOI 10.1093/acprof:oso/9780199655526.001.0001
   Xenakis AM, 2017, P ROY SOC A-MATH PHY, V473, DOI 10.1098/rspa.2016.0674
   Yavari-Ramshe S, 2016, LANDSLIDES, V13, P1325, DOI 10.1007/s10346-016-0734-2
   Zhang F, 2018, J HYDRODYN, V30, P95, DOI 10.1007/s42241-018-0010-0
NR 16
TC 2
Z9 2
U1 7
U2 34
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2019
VL 30
IS 6
AR e1874
DI 10.1002/cav.1874
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KD5NX
UT WOS:000507913800002
DA 2024-07-18
ER

PT J
AU Hassaballah, M
   Aly, AM
   Abdelnaim, A
AF Hassaballah, M.
   Aly, Abdelraheem M.
   Abdelnaim, A.
TI Interactive fluid flow simulation in computer graphics using
   incompressible smoothed particle hydrodynamics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; computer graphics; fluid simulation; incompressible
   smoothed particle hydrodynamics (ISPH); object modeling; physically
   based simulation
ID 2-PHASE FLOW; SPH; MODEL; SOLVER; FORCE
AB Interactive simulations of fluids flow play an important role in several computer graphics-based applications such as computer games, computer animation, movie industry, and virtual realities. The incompressible smoothed particle hydrodynamics (ISPH) model is a promising numerical scheme for large-scale and large-deformation simulations, where the pressure can be determined precisely by solving pressure Poisson equation (PPE). The three main shortcomings of the ISPH scheme are oscillating pressure, particles disorders, and particles penetrations through rigid boundary. In this paper, the stable pressure is obtained from modifications in the source term of PPE, in which the divergence-free velocity condition plus density-invariance condition multiply by a relaxation coefficient are included. The particles disorders are solved via utilizing a shifting technique with the current treatment of source term in PPE. Additionally, the dummy boundary particles are used for the rigid boundary treatment. For getting enough pressure on the boundary, the Neumann boundary condition is satisfied during the implicit solving processes. The performance of the stabilized ISPH model is tested on various numerical simulations with largely distorted free surface including liquid sloshing problems, fluid-fluid and fluid-structure interactions, and dam-break flows. To extend the applicability of the stabilized ISPH model, the post process including visual realism with a highly rendering scheme is coupled. The coupled scheme introduces several simulations including free falling of a rigid body, water splashes, and dam break analysis. Furthermore, the proposed ISPH-based method enables efficient and viscous fluid simulations with large time steps, higher viscosities, and resolutions, and it is a robust scheme in long interval simulations of nonlinear free-surface flows.
C1 [Hassaballah, M.] South Valley Univ, Fac Comp & Informat, Dept Comp Sci, Qena 83523, Egypt.
   [Aly, Abdelraheem M.] King Khalid Univ, Fac Sci, Dept Math, Abha, Saudi Arabia.
   [Aly, Abdelraheem M.; Abdelnaim, A.] South Valley Univ, Fac Sci, Dept Math, Qena, Egypt.
C3 Egyptian Knowledge Bank (EKB); South Valley University Egypt; King
   Khalid University; Egyptian Knowledge Bank (EKB); South Valley
   University Egypt
RP Hassaballah, M (corresponding author), South Valley Univ, Fac Comp & Informat, Dept Comp Sci, Qena 83523, Egypt.
EM m.hassaballah@svu.edu.eg
RI Hassaballah, Mahmoud/A-5197-2018; Aly, Abdelraheem Mahmoud/Y-5649-2019
OI Hassaballah, Mahmoud/0000-0001-5655-8511; Aly, Abdelraheem
   Mahmoud/0000-0003-3369-8452; Aly, Abdelraheem/0000-0002-8524-9467
CR Abdelnaim A, 2019, J FLOW VIS IMAGE PRO, V26, P223, DOI 10.1615/JFlowVisImageProc.2019029921
   Aly AM, 2015, NUMER HEAT TR B-FUND, V67, P255, DOI 10.1080/10407790.2014.955772
   Aly AM, 2011, OCEAN SYST ENG, V1, P207, DOI 10.12989/ose.2011.1.3.207
   Aly AM, 2013, INT J NUMER METHOD H, V23, P479, DOI 10.1108/09615531311301263
   Andersen M, 2017, COMPUT GRAPH-UK, V69, P36, DOI 10.1016/j.cag.2017.09.006
   Asai M, 2012, J APPL MATH, DOI 10.1155/2012/139583
   Ban XJ, 2018, NEURAL COMPUT APPL, V29, P33, DOI 10.1007/s00521-016-2286-8
   Bao K, 2009, COMPUT ANIMAT VIRT W, V20, P311, DOI 10.1002/cav.299
   Bender J., 2015, P 14 ACM SIGGRAPH EU, P147, DOI DOI 10.1145/2786784.2786796
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   Brousset M, 2016, COMPUT GRAPH-UK, V57, P102, DOI 10.1016/j.cag.2016.03.003
   Cornelis J, 2019, VISUAL COMPUT, V35, P579, DOI 10.1007/s00371-018-1488-8
   Ellero M, 2007, J COMPUT PHYS, V226, P1731, DOI 10.1016/j.jcp.2007.06.019
   Feng G, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1781
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Goncalves E, 2017, INT J NUMER METHOD H, V27, P1487, DOI 10.1108/HFF-05-2016-0202
   GREENHOW M, 1987, APPL OCEAN RES, V9, P214, DOI 10.1016/0141-1187(87)90003-4
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Isshiki M, 2016, J EARTHQ TSUNAMI, V10, DOI 10.1142/S1793431116400200
   Jiang M, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1798
   Kang N, 2014, COMPUT GRAPH FORUM, V33, P219, DOI 10.1111/cgf.12490
   Kozakevicius AD, 2018, INT J NUMER METHOD H, V28, P2052, DOI 10.1108/HFF-05-2017-0215
   Lee ES, 2008, J COMPUT PHYS, V227, P8417, DOI 10.1016/j.jcp.2008.06.005
   Li C, 2013, IEEE T VIS COMPUT GR, V19, P1242, DOI 10.1109/TVCG.2012.302
   Mercier O, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818115
   Nguyen MT, 2018, INT J NUMER METHOD H, V28, P684, DOI 10.1108/HFF-02-2017-0058
   Minhajul, 2018, APPL MATH COMPUT, V327, P117, DOI 10.1016/j.amc.2018.01.021
   Morris JP, 1997, J COMPUT PHYS, V136, P214, DOI 10.1006/jcph.1997.5776
   Nair P, 2019, COMPUT FLUIDS, V179, P301, DOI 10.1016/j.compfluid.2018.11.015
   Ozgen O, 2013, COMPUT ANIMAT VIRT W, V24, P511, DOI 10.1002/cav.1527
   Peer A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766925
   Raveendran K., 2011, P 2011 ACM SIGGRAPHE, P33
   Ren B, 2016, VISUAL COMPUT, V32, P523, DOI 10.1007/s00371-015-1086-y
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   SCHOENBERG IJ, 1946, Q APPL MATH, V4, P45, DOI 10.1090/qam/15914
   Sun HQ, 2010, COMPUT ANIMAT VIRT W, V21, P589, DOI 10.1002/cav.379
   Takahashi T, 2018, COMPUT GRAPH FORUM, V37, P313, DOI 10.1111/cgf.13292
   Winchenbach R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073713
   Xu XY, 2018, COMPUT MECH, V62, P963, DOI 10.1007/s00466-018-1542-4
   Zadick Johanne, 2016, Computer Games Journal, V5, P55, DOI 10.1007/s40869-016-0020-5
   Zeidan D, 2007, INT J NUMER METH FL, V54, P393, DOI 10.1002/fld.1404
   Zeidan D, 2019, COMPUT FLUIDS, V181, P90, DOI 10.1016/j.compfluid.2018.12.013
   Zeidan D, 2016, APPL MATH COMPUT, V272, P707, DOI 10.1016/j.amc.2015.09.038
   Zeidan D, 2011, APPL MATH COMPUT, V217, P5023, DOI 10.1016/j.amc.2010.07.053
   Zhang XY, 2015, COMPUT ANIMAT VIRT W, V26, P357, DOI 10.1002/cav.1637
NR 45
TC 3
Z9 4
U1 1
U2 21
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2020
VL 31
IS 2
AR e1916
DI 10.1002/cav.1916
EA OCT 2019
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LC0VU
UT WOS:000491546700001
DA 2024-07-18
ER

PT J
AU Huang, JW
   Liu, SG
AF Huang, Jiawei
   Liu, Shiguang
TI Robust simultaneous localization and mapping in low-light environment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE feature; image preprocessing; low-light environment; visual SLAM
AB Complex and varied illumination makes computer vision research studies difficult. This research field pays much attention to scenes with weak illumination, especially in visual simultaneous localization and mapping (SLAM). Although the current feature-based algorithm is mature, the existing SLAM method often fails because it cannot extract enough feature information in the low-light environment. In this paper, we propose a new solution to this problem, which allows our system to work in environments with the majority of lighting. We propose a multifeature extraction algorithm to extract two kinds of image features simultaneously. With such a solution, our system can work when the single-feature algorithm fails to extract enough feature points. We also add an image preprocessing step before tracking thread to cope with extremely dark conditions. Finally, we fully evaluate our approach on existing public data sets. Experiments show that the method combining multiple features can improve the robustness of the state-of-the-art algorithm under weak illumination without affecting the real-time performance.
C1 [Huang, Jiawei; Liu, Shiguang] Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM lsg@tju.edu.cn
FU Natural Science Foundation of China [61672375, 61170118]; National Key
   Research and Development Program of China [2018YFC1407405]
FX Natural Science Foundation of China, Grant/Award Number: 61672375 and
   61170118; National Key Research and Development Program of China,
   Grant/Award Number: 2018YFC1407405
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chiu YS, 2011, IEEE SYS MAN CYBERN, P2946, DOI 10.1109/ICSMC.2011.6084119
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Ji Penglei, 2018, P 31 INT C COMPUTER, P59, DOI DOI 10.1145/3205326.3205358
   Jiao Linan, 2011, Computer Engineering and Applications, V47, P196, DOI 10.3778/j.issn.1002-8331.2011.09.057
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liu R., 2018, P 31 INT C COMP AN S, P66
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Milford M, 2012, IEEE INT C ROB AUT 2
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Nuske S, 2009, J FIELD ROBOT, V26, P728, DOI 10.1002/rob.20306
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pumarola A., 2017, P 2017 IEEE INT C RO, P4503, DOI DOI 10.1109/ICRA.2017.7989522
   Pyojin Kim, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5447, DOI 10.1109/ICRA.2017.7989640
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Ross P., 2014, AUSTR C ROB AUT ACRA
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Seonwook Park, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4523, DOI 10.1109/ICRA.2017.7989525
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010
   von Gioi RG, 2012, IMAGE PROCESS ON LIN, V2, P35, DOI 10.5201/ipol.2012.gjmr-lsd
   Zhu ZL, 2015, PROCEEDINGS OF THE 31ST INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2016), P53, DOI 10.1145/3205326.3205357
NR 24
TC 5
Z9 9
U1 6
U2 37
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1895
DI 10.1002/cav.1895
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400018
DA 2024-07-18
ER

PT J
AU Li, P
   Jin, YX
   Sheng, B
   Lin, D
   Nie, YW
   Wu, EH
AF Li, Ping
   Jin, Yuxi
   Sheng, Bin
   Lin, Di
   Nie, Yongwei
   Wu, Enhua
TI Multiview-coherent disocclusion synthesis using connected regions
   optimization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE coherent; connected regions; disocclusion synthesis; multiview
ID VIRTUAL VIEW SYNTHESIS; VIDEO; REMOVAL
AB Handling of missing areas is a key step for depth-based rendering to synthesize virtual views. Existing methods usually consider finding candidate pixels from only one reference view to fill missing areas. However, the information provided by one reference view is restricted by the position of the view. By utilizing two reference views located on both the left and right sides of the virtual view, we propose to synthesize the missing areas at hole level with connected regions optimization. To avoid the appearance of ghost boundary, we apply morphological operations to generate a boundary band map for the depth map, which restricts the warping of the virtual view. We use a binary map to mark unknown pixels in a hole, label the connected unknown regions, and count the area of each connected region, which decide the order in our enhanced inpainting synthesis. Besides, we separate the foreground and background regions of the depth map to constrain the searching of candidate pixels. Multiple experiments on virtual view synthesis have shown the effectiveness and high quality of our multiview-coherent disocclusion synthesis.
C1 [Li, Ping; Jin, Yuxi] Macau Univ Sci & Technol, Fac Informat Technol, Macau 999078, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Lin, Di] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Nie, Yongwei] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Wu, Enhua] Univ Macau, Fac Sci & Technol, Macau, Peoples R China.
C3 Macau University of Science & Technology; Hong Kong Polytechnic
   University; Shanghai Jiao Tong University; Shenzhen University; South
   China University of Technology; Chinese Academy of Sciences; Institute
   of Software, CAS; University of Macau
RP Li, P (corresponding author), Macau Univ Sci & Technol, Fac Informat Technol, Macau 999078, Peoples R China.; Li, P (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.; Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
EM lipingfire@ieee.org; shengbin@sjtu.edu.cn
RI Li, Ping/AAO-2019-2020; Yuxi, Jin/HPD-0563-2023
OI Li, Ping/0000-0002-1503-0240; 
FU Macau Science and Technology Development Fund [0027/2018/A1]; National
   Natural Science Foundation of China [61872241, 61632003, 61672502,
   61602183, 61572316]; Science and Technology Project of Guangzhou City
   [201707010140]
FX Macau Science and Technology Development Fund, Grant/Award Number:
   0027/2018/A1; National Natural Science Foundation of China, Grant/Award
   Number: 61872241, 61632003, 61672502, 61602183, and 61572316; Science
   and Technology Project of Guangzhou City, Grant/Award Number:
   201707010140
CR Ahn I, 2013, IEEE T BROADCAST, V59, P614, DOI 10.1109/TBC.2013.2281658
   [Anonymous], 2012, The Best of IET and IBC
   [Anonymous], 2011, 3DTV C TRUE VIS CAPT
   [Anonymous], INT C SIGN PROC COMM
   [Anonymous], 2016, IEEE INT CON MULTI
   [Anonymous], 2004, INT SOC OPTICS PHOTO, DOI DOI 10.1117/12.524762
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766934
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Burdea G., 2015, Digital Technology Application, V95, P663
   Buyssens P., 2015, P SIGGRAPH AS TECH B, P2
   Choi S, 2013, IEEE T IMAGE PROCESS, V22, P2429, DOI 10.1109/TIP.2013.2251646
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daribo Ismael, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P167, DOI 10.1109/MMSP.2010.5662013
   Daribo I, 2011, IEEE T BROADCAST, V57, P533, DOI 10.1109/TBC.2011.2125110
   Ganelin I, 2018, IEEE IMAGE PROC, P3898, DOI 10.1109/ICIP.2018.8451211
   Habigt J, 2013, IEEE IMAGE PROC, P2131, DOI 10.1109/ICIP.2013.6738439
   Lang M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778812
   Liu G, 2012, INT CONF SOFTW ENG, P1
   Luo GB, 2017, IEEE T CIRC SYST VID, V27, P2118, DOI 10.1109/TCSVT.2016.2583978
   Oh KJ, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P233
   Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855
   Rahaman DMM, 2018, IEEE T IMAGE PROCESS, V27, P1190, DOI 10.1109/TIP.2017.2772858
   Schmeing M, 2015, IEEE T MULTIMEDIA, V17, P2160, DOI 10.1109/TMM.2015.2476372
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Smolic A, 2011, PATTERN RECOGN, V44, P1958, DOI 10.1016/j.patcog.2010.09.005
   Stankiewicz O., 2013, ISO IEC JTC, V1, P533
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Zhou Tinghui, 2018, ARXIV180509817
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 31
TC 0
Z9 0
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1894
DI 10.1002/cav.1894
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400019
DA 2024-07-18
ER

PT J
AU Wang, L
   Kim, H
   Kim, I
   Han, S
AF Wang, Lin
   Kim, Hyuncheol
   Kim, Imgyu
   Han, Soonhung
TI A visual simulation of ocean floating wind power system
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE game engine; motion and sea environment; OFWP; 3D visualization
AB The development of ocean floating wind power has been burgeoning in recent years because of its low cost and high efficiency. To facilitate effectiveness, 3D visualization using virtual reality and augmented reality technologies has been applied to many operating systems. However, most of the existing 3D motion visualizations are "pseudo" visualization, and there are a few realistic visualization systems that base the motion of ocean floating wind power on simulation and experiment results. Therefore, in this paper, we conducted research related to the design for a realistic motion visualization system based on numerical simulation data using a commercial game engine (Unity 3D). In our system, the six-degree-of-freedom motion (Surge, Sway, Heave, Roll, Pitch, and Yaw) is simulated and visualized based on numerical analysis results of two hydrodynamics simulation softwares, which can illuminate the nuance between simulation results and experiment results and give us a "real-time" visual experience about motion in each direction. Meanwhile, comprehensive sea environment conditions, such as wind, rain, water, sound, and cloudiness, are also visualized in Unity 3D.
C1 [Wang, Lin; Kim, Hyuncheol; Kim, Imgyu; Han, Soonhung] Korea Adv Inst Sci & Technol, Grad Sch Ocean Syst Engn, Dept Mech Engn, Daejeon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Han, S (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Ocean Syst Engn, Dept Mech Engn, Daejeon 305701, South Korea.
EM shhan@kaist.ac.kr
RI wang, Lin/GQO-7901-2022; Kim, Imgyu/KHV-2362-2024; han,
   soonhung/AAA-5745-2021
OI wang, Lin/0000-0002-7485-4493; han, soonhung/0000-0001-5676-8121
FU Climate Change Research Hub of KAIST [N11180110]; Korea Institute of
   Energy Technology Evaluation and Planning (KETEP); Ministry of Trade,
   Industry & Energy (MOTIE) of the Republic of Korea [20168520021200]
FX Climate Change Research Hub of KAIST, Grant/Award Number: N11180110;
   Korea Institute of Energy Technology Evaluation and Planning (KETEP);
   Ministry of Trade, Industry & Energy (MOTIE) of the Republic of Korea,
   Grant/Award Number: 20168520021200
CR [Anonymous], 2014, AGX DYN US GUID VERS
   Choi G., 2002, International Journal of CAD/CAM, V2, P13
   Daglas H, VIRTUAL TRAINING REA
   Dekker G.W., 2013, P INT C MOD SIM VIS, P1
   Gueydon S, 2011, OCEANS 2011, P1
   Huynh T., 2015, INT J COMPUTATIONAL, V5, P50
   Hyungki Kim, 2014, Virtual, Augmented and Mixed Reality. Applications of Virtual and Augmented Reality. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8526, P390, DOI 10.1007/978-3-319-07464-1_36
   Jallouli J, 2009, RENEW ENERG, V34, P597, DOI 10.1016/j.renene.2008.05.036
   Jonkman B.J., 2006, TurbSim User's Guide
   Journee J.M.J., 2001, Offshore Hydromechanics
   Liu JX, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL III, P382, DOI 10.1109/ETCS.2009.613
   Lu GP, 2011, ADV MATER RES-SWITZ, V317-319, P2162, DOI 10.4028/www.scientific.net/AMR.317-319.2162
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Panigrahi S R, 2014, MODELING NUMERICAL S, V4, P79
   Fernandez RP, 2015, ADV ENG SOFTW, V81, P30, DOI 10.1016/j.advengsoft.2014.11.001
   Shyh-Kuang Ueng, 2008, Virtual Reality, V12, P65, DOI 10.1007/s10055-008-0088-8
   Tran TT, 2015, J WIND ENG IND AEROD, V142, P65, DOI 10.1016/j.jweia.2015.03.009
   Xiufeng Z., 2004, Source Proceedings of the 2004 ACM SIGGRAPH International Conference on Virtual Reality Continuum and its Applications in Industry, Singapore, V5, P282
NR 18
TC 1
Z9 1
U1 3
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2019
VL 30
IS 2
AR e1859
DI 10.1002/cav.1859
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR7XB
UT WOS:000463367400003
DA 2024-07-18
ER

PT J
AU Chen, JX
   Zhang, L
   Li, XX
   Zhang, B
   Ye, ZF
AF Chen, Jiaxu
   Zhang, Long
   Li, Xiaoxu
   Zhang, Bo
   Ye, Zhongfu
TI Locally controlled as-rigid-as-possible deformation for 2D characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE as-rigid-as-possible (ARAP); local control; shape deformation; 2D
   character animation
AB Due to its practical use in animation and image editing, two-dimensional shape deformation has received great attention during the past decades. The traditional paradigms, spreading local modifications over the whole shape, will cause a global deformation. For the simultaneous realization of the local control and preservation of the rigidity of the shape, a novel deformation method is proposed for point, skeleton, and cage handles. Our framework can be accomplished in terms of the minimization of the improved as-rigid-as-possible energy with local and smooth penalties, named locally controlled as-rigid-as-possible energy. The visually pleasing experiment results demonstrate the success of our method in two-dimensional character deformation.
C1 [Chen, Jiaxu; Zhang, Long; Li, Xiaoxu; Zhang, Bo; Ye, Zhongfu] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Natl Engn Lab Speech & Language Informat Proc, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Ye, ZF (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Natl Engn Lab Speech & Language Informat Proc, Hefei, Anhui, Peoples R China.
EM yezf@ustc.edu.cn
RI Zhang, Bo/AAG-2557-2020; chen, jia/JLM-4733-2023; chen,
   jia/JDW-7660-2023
OI Zhang, Bo/0000-0001-5751-8255; 
FU Fundamental Research Funds for the Central Universities
FX Fundamental Research Funds for the Central Universities.
CR ALEXA M, 2000, ANN C SERIES, P157
   [Anonymous], 2014, ACM T GRAPH
   [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Botsch M., 2010, POLYGON MESH PROCESS, P49
   Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016
   Deng BL, 2013, COMPUT GRAPH FORUM, V32, P11, DOI 10.1111/cgf.12021
   Deng W., 2011, TR1106 CAAM
   Eldar YC, 2010, IEEE T SIGNAL PROCES, V58, P3042, DOI 10.1109/TSP.2010.2044837
   Gao L, 2012, SCI CHINA INFORM SCI, V55, P983, DOI 10.1007/s11432-012-4574-y
   Golub GH, 2013, MATRIX COMPUTATIONS, P159
   He L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461965
   Jacobson A, 2014, COMMUN ACM, V57, P99, DOI 10.1145/2578850
   Jacobson A, 2010, COMPUT GRAPH FORUM, V29, P1565, DOI 10.1111/j.1467-8659.2010.01765.x
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Lipman Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805971
   Liu J., 2013, SLEP: Sparse Learning with Efficient Projections
   Liu LG, 2008, COMPUT GRAPH FORUM, V27, P1495, DOI 10.1111/j.1467-8659.2008.01290.x
   Pinkall U., 1993, Exp. Math., V2, P15, DOI 10.1080/10586458.1993.10504266
   Qin ZW, 2013, MATH PROGRAM COMPUT, V5, P143, DOI 10.1007/s12532-013-0051-x
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Shewchuk J. R., 1996, Applied Computational Geometry. Towards Geometric Engineering. FCRC'96 Workshop, WACG'96. Selected Papers, P203, DOI 10.1007/BFb0014497
   Solomon J, 2011, COMPUT GRAPH FORUM, V30, P1543, DOI 10.1111/j.1467-8659.2011.02028.x
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Tibshirani R., 1996, J R STAT SOC B, DOI DOI 10.1111/J.2517-6161.1996.TB02080.X
   Wang X, 2013, VISUAL COMPUT, V29, P545, DOI 10.1007/s00371-013-0817-1
   Wang Xun, 2015, COMPUT ANIM VIRTUAL
   Wang Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766952
   Weber O, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778815
   Weber O, 2009, COMPUT GRAPH FORUM, V28, P587, DOI 10.1111/j.1467-8659.2009.01399.x
   Xu LL, 2015, GRAPH MODELS, V82, P160, DOI 10.1016/j.gmod.2015.06.012
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zhang HY, 2015, IEEE T VIS COMPUT GR, V21, P873, DOI 10.1109/TVCG.2015.2398432
   Zhao Y, 2014, COMPUT ANIMAT VIRT W, V25, P413, DOI 10.1002/cav.1596
NR 38
TC 1
Z9 1
U1 2
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2017
VL 28
IS 6
DI 10.1002/cav.1750
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9YH
UT WOS:000417254100006
DA 2024-07-18
ER

PT J
AU Alsweis, M
   Deussenn, O
   Liu, J
AF Alsweis, Monssef
   Deussenn, Oliver
   Liu, Jia
TI Simulation and visualization of adapting venation patterns
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE leaf development; Auxin; curvature scale space; botanical simulation;
   RERG; centroidal Voronoi tessellations; minimum spanning tree
ID LEAF; GROWTH
AB This paper suggests a procedural biologically motivated method to simulate the development of leaf contours and the generation of different levels of leaf venation systems. Leaf tissue is regarded as a viscous, incompressible fluid whose 2D expansion is determined by a spatially varying growth rate. Visually realistic development is described by a growth function relative elementary growth rate that reacts to hormone (Auxin) sources embedded in the leaf blade. The shape of the leaf is determined by a set of feature points at the leaf contour. The contour is extracted from images utilizing the curvature scale space corner detection algorithm. Auxin transport is described by an initial Auxin flow from a source to a sink that is gradually channelized into cells with large amounts of highly polarized transporters. The proposed model simulates leaf forms ranging from simple shapes to lobed leaves. The third level of venation system is generated using centroidal Voronoi tessellations and minimum spanning trees, whereas the size of each cell within the Voronoi-diagram is related to the involved quantity of Auxin. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Alsweis, Monssef; Deussenn, Oliver] Univ Konstanz, Dept Comp Informat Sci, Univ Str 10, D-78464 Constance, Germany.
   [Deussenn, Oliver] Chinese Acad Sci, SIAT, Shenzhen, Peoples R China.
   [Liu, Jia] Beijing Informat Sci Technol Univ, Sch Automat, Beijing, Peoples R China.
C3 University of Konstanz; Chinese Academy of Sciences; Shenzhen Institute
   of Advanced Technology, CAS; Beijing Information Science & Technology
   University
RP Alsweis, M (corresponding author), Univ Konstanz, Dept Comp Informat Sci, Univ Str 10, D-78464 Constance, Germany.
EM monssef.alsweis@uni-konstanz.de
RI Liu, Jia/AAF-9537-2020
FU Institute of International Education and its Scholar Rescue Fund;
   National Foreign 1000 Talent Plan [WQ201344000169]; Leading Talents of
   Guangdong Program [00201509]; NSFC [61501464, 61331018]
FX The work reported here was supported in part by the Institute of
   International Education and its Scholar Rescue Fund, by National Foreign
   1000 Talent Plan (WQ201344000169) and Leading Talents of Guangdong
   Program (00201509), and by NSFC with Nos. 61501464 and 61331018.
CR [Anonymous], 1996, The Algorithmic Beauty of Plants
   Bilsborough GD, 2011, P NATL ACAD SCI USA, V108, P3424, DOI 10.1073/pnas.1015162108
   Castro-Díez P, 2000, OECOLOGIA, V124, P476, DOI 10.1007/PL00008873
   Coen E, 2004, P NATL ACAD SCI USA, V101, P4728, DOI 10.1073/pnas.0306308101
   Coley PD, 2006, OIKOS, V115, P219, DOI 10.1111/j.2006.0030-1299.14928.x
   Corson F, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.048703
   Hammel M, 1992, P COMP GRAPH INT 92, V92, P119
   HEJNOWICZ Z, 1984, J THEOR BIOL, V110, P93, DOI 10.1016/S0022-5193(84)80017-X
   Jeong S, 2013, COMPUT GRAPH FORUM, V32, P204, DOI 10.1111/cgf.12009
   Katifori E, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.048704
   Liang HY, 2011, P NATL ACAD SCI USA, V108, P5516, DOI 10.1073/pnas.1007808108
   Liang HY, 2009, P NATL ACAD SCI USA, V106, P22049, DOI 10.1073/pnas.0911954106
   Mündermann L, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P60, DOI 10.1109/CGI.2003.1214448
   Nakata Miyuki, 2013, Plants-Basel, V2, P174, DOI 10.3390/plants2020174
   Prusinkiewicz Przemyslaw, 1994, Artificial Life, V1, P61
   Quan L, 2006, ACM T GRAPHIC, V25, P599, DOI 10.1145/1141911.1141929
   Rodkaew Y., 2002, INT C NICOGRAPH 2002, P73
   Rodkaew Y, 2004, MODELING PLANT LEAVE
   Rolland-Lagan AG, 2005, PLANT J, V44, P854, DOI 10.1111/j.1365-313X.2005.02581.x
   Rong G., 2010, Proceedings of Symposium of Solid and Physical Modeling (SPM 2010), P117
   Roth-Nebelsick A, 2001, ANN BOT-LONDON, V87, P553, DOI 10.1006/anbo.2001.1391
   Runions A, 2005, ACM T GRAPHIC, V24, P702, DOI 10.1145/1073204.1073251
   Scarpella E, 2010, CONTROL LEAF VEIN DE, V2, P4728
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Stanko V, 2014, MOL PLANT, V7, P1637, DOI 10.1093/mp/ssu080
   Terraz O, 2009, VISUAL COMPUT, V25, P165, DOI 10.1007/s00371-008-0212-5
   ULICHNEY RA, 1988, P IEEE, V76, P56, DOI 10.1109/5.3288
   Wang IR, 2004, COMPUT ANIMAT VIRT W, V15, P237, DOI 10.1002/cav.26
   Xiao H, 2011, SOFT MATTER, V7, P10794, DOI 10.1039/c1sm05998j
   Xu H, 2012, ADV INFORM SCI SERVI, V4, P52
NR 30
TC 7
Z9 7
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2017
VL 28
IS 2
AR e1723
DI 10.1002/cav.1723
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ER2AB
UT WOS:000398595200003
OA Green Published
DA 2024-07-18
ER

PT J
AU Possani-Espinosa, A
   Gutierrez-Garcia, JO
   Gordillo, IV
AF Possani-Espinosa, Andre
   Octavio Gutierrez-Garcia, J.
   Vargas Gordillo, Isaac
TI Determining personality traits of racing game players using the open
   racing car simulator: toward believable virtual drivers
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE racing game players; personality traits; player modeling; driving
   behaviors; car racing simulation; virtual drivers
ID DRIVING BEHAVIOR; DECISION TREES
AB Believable artificial opponents, for example, believable virtual drivers, are fundamental to engage players and make (car racing) video games more entertaining. This paper lays the foundations for the design of believable virtual drivers by proposing a methodology for profiling players using the open racing car simulator. Data collected from 125 players about their driving behaviors and personality traits give insights into how personality traits should model the behavior of believable virtual drivers. The data analysis was conducted using a correlation analysis and the J48 decision tree algorithm. Empirical evidence shows that goal-oriented driving behaviors can be used to determine personality traits of players. In addition, this work also (i) gives preliminary insights into the relationship between the driving behavior and personality of racing game players and actual car drivers; and (ii) presents evidence of the relevance of gender as a predictor of personality traits of racing game players. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Possani-Espinosa, Andre; Vargas Gordillo, Isaac] Inst Tecnol Autonomo Mexico, Dept Digital Syst, Mexico City 01080, DF, Mexico.
   [Octavio Gutierrez-Garcia, J.] Inst Tecnol Autonomo Mexico, Dept Comp Sci, 1 Rio Hondo St, Mexico City 01080, DF, Mexico.
C3 Instituto Tecnologico Autonomo de Mexico; Instituto Tecnologico Autonomo
   de Mexico
RP Gutierrez-Garcia, JO (corresponding author), Inst Tecnol Autonomo Mexico, Dept Comp Sci, 1 Rio Hondo St, Mexico City 01080, DF, Mexico.
EM octavio.gutierrez@itam.mx
RI Gutierrez-Garcia, J. Octavio/F-3983-2011; Gutierrez-Garcia, J.
   Octavio/R-4843-2019
OI Gutierrez-Garcia, J. Octavio/0000-0002-6252-6169; Gutierrez-Garcia, J.
   Octavio/0000-0002-6252-6169
FU Asociacion Mexicana de Cultura, A.C
FX This work has been supported by the Asociacion Mexicana de Cultura, A.C.
   The authors would like to thank (i) the editors-in-chief and the
   anonymous referees for their comments and suggestions and (ii) Mayte
   Mendoza for assisting in the data collection process.
CR Cardamone L, 2011, IEEE CONF COMPU INTE, P227, DOI 10.1109/CIG.2011.6032011
   Cardamone L, 2010, IEEE T COMP INTEL AI, V2, P176, DOI 10.1109/TCIAIG.2010.2052102
   Emmons R.A., 1997, HDB PERSONALITY PSYC, P485, DOI DOI 10.1016/B978-012134645-4/50021-4
   Gallego F, 2005, INTELIGENCIA ARTIFIC, V9, P9
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hansen C.P., 1988, J BUS PSYCHOL, V2, P346, DOI DOI 10.1007/BF01013766
   Humanmetrics Inc, PERS TEST BAS C JUNG
   Karn JS, P IEEE INT S EMP SOF, P417, DOI [10.1109/ISESE.2005. 1541850., DOI 10.1109/ISESE.2005]
   Latham CL, 2011, J PROF NURS, V27, P344, DOI 10.1016/j.profnurs.2011.04.015
   Loyall AB, P 1 INT C AUT AG 199, P106, DOI [10.1145/267658, DOI 10.1145/267658]
   Lu XQ, 2014, COMPUT ANIMAT VIRT W, V25, P363, DOI 10.1002/cav.1575
   Machin MA, 2008, ACCIDENT ANAL PREV, V40, P541, DOI 10.1016/j.aap.2007.08.010
   MacInnes W.J., 2004, Proceedings of CHI extended abstracts, P1537
   Munoz J., 2012, Believable Bots, P289, DOI DOI 10.1007/978-3-642-32323-2_12
   Myers Isabel Briggs, 1998, MBTI Manual: A Guide to the Development and Use of the Myers-Briggs Type Indicator
   Oltedal S, 2006, SAFETY SCI, V44, P621, DOI 10.1016/j.ssci.2005.12.003
   Perner P, 2001, PATTERN RECOGN LETT, V22, P47, DOI 10.1016/S0167-8655(00)00098-2
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   SETTLES B, 2009, 1648 CS U WISC MAD
   TAYLOR R, 1990, J DIAGN MED SONOG, V6, P35, DOI 10.1177/875647939000600106
   Togelius J, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND GAMES, P252, DOI 10.1109/CIG.2007.368106
   Vorderer P, 2013, P 2 INT C ENT COMP 2, P1
   WALLACE CS, 1993, MACH LEARN, V11, P7, DOI 10.1023/A:1022646101185
   Williams L., 2006, Proceedings. 16th IEEE International Symposium on Software Reliability Engineering
   Wymann B., TORCS OPEN RACING CA
   Zammitto V, 2008, P INT C GAM RES DEV, P1
NR 26
TC 1
Z9 1
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2017
VL 28
IS 2
AR e1722
DI 10.1002/cav.1722
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ER2AB
UT WOS:000398595200002
DA 2024-07-18
ER

PT J
AU Wang, MF
   Jia, JY
   Xie, N
   Zhang, CX
AF Wang, Mingfei
   Jia, Jinyuan
   Xie, Ning
   Zhang, Chenxi
TI Interest-driven avatar neighbor-organizing for P2P transmission in
   distributed virtual worlds
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE DVE; P2P transmission; avatar behavior; neighbors mesh
AB The neighbor table/distributed hash table (DHT) is used to choose the data supplier for data-dispatching services in distributed virtual environments based on peer-to-peer networks. It is essential that a stable and efficient neighbor table/DHT be maintained. Because the avatar has much freedom to roam, the spatial distribution of nodes is not uniform, and the logical topology may change dramatically. Therefore, traditional construction mechanisms, such as the neighbor-discovery mechanism based on spatial distance or DHT, may involve fierce churn in the neighbor table and frequent message exchanges. In this paper, we proposed a dynamic node-organizing mechanism that aims to solve these challenging problems by applying the avatar's behavioral characteristics to the neighbor maintenance mechanism and scene data transmission. First, we have summarized the common social behaviors of avatars and extracted their characteristics. We then propose an interest-similarity measuring algorithm to divide the node into diverse clusters. Next, we measure the cluster stability in terms of interest entropy while constructing a stable neighbor mesh for each node in a cluster. We have conducted extensive simulation experiments that simulate avatar behaviors in a popular massively multiplayer online game. The results show that our proposed mechanism achieved a substantial alleviation of neighbor churn and reduced information exchange, which improves the transmission efficiency in distributed virtual environments. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Wang, Mingfei; Jia, Jinyuan; Xie, Ning; Zhang, Chenxi] Tongji Univ, Sch Software Engn, 4800 Caoan Rd, Shanghai 201804, Peoples R China.
C3 Tongji University
RP Xie, N (corresponding author), Tongji Univ, Sch Software Engn, 4800 Caoan Rd, Shanghai 201804, Peoples R China.
EM seanxiening@gmail.com
FU National Science Foundation of China [61272270]; National Twelfth
   Five-year Plan Major Science and Technology Project
   [2012BAC11B00-04-03]; Special Research Fund of Higher College's
   Doctorate [20130072110035]; Key Science and Technology Project of Jilin
   [20140204088GX]; Changbai Valley Talent Plan of Changchun National
   Hi-Tech Industrial Development Zone [3-2013006]
FX The work was supported by the National Science Foundation of China (No.
   61272270), National Twelfth Five-year Plan Major Science and Technology
   Project (No. 2012BAC11B00-04-03), Special Research Fund of Higher
   College's Doctorate (No. 20130072110035), Key Science and Technology
   Project of Jilin (No. 20140204088GX), and Changbai Valley Talent Plan of
   Changchun National Hi-Tech Industrial Development Zone (No. 3-2013006).
CR [Anonymous], 2015, OSG 2015
   Bharambe AR, 2004, ACM SIGCOMM COMP COM, V34, P353, DOI 10.1145/1030194.1015507
   Buyukkaya E., 2009, P 6 IEEE CONS COMM N, P1
   Buyukkaya E, 2015, PEER PEER NETW APPL, V8, P276, DOI 10.1007/s12083-013-0231-5
   Carlini E., 2011, P 4 INT ICST C SIM T, P328
   Cordasco G, 2009, IPDPS, P1
   Ginhung Wang, 2012, 2012 International Conference on Information Networking (ICOIN 2012), P199, DOI 10.1109/ICOIN.2012.6164377
   HU SY, 2008, INFOCOM 2008
   Knutsson B., 2004, INFOCOM 2004, V1
   La C.-A., 2008, Proceedings of the first workshop on Online social networks, WOSP '08, P79
   Legtchenko S, 2012, ACM T AUTON ADAP SYS, V7, DOI 10.1145/2240166.2240178
   Legtchenko S, 2010, I C DEPEND SYS NETWO, P171, DOI 10.1109/DSN.2010.5544919
   Li JL, 2005, Proceedings of 2005 IEEE International Workshop on VLSI Design and Video Technology, P87, DOI 10.1109/IWVDVT.2005.1504557
   Liang HG, 2009, MULTIMED TOOLS APPL, V45, P163, DOI 10.1007/s11042-009-0304-x
   Miller J., 2009, PROC HT2009, P1
   Park SI, 2013, COMPUT ANIMAT VIRT W, V24, P155, DOI 10.1002/cav.1512
   Pittman Daniel., 2007, NETGAMES 07 P 6 ACM, P25
   Schmieg A, 2008, IEEE INT CONF PEER, P247, DOI 10.1109/P2P.2008.20
   Shen S., 2014, P NETW OP SYST SUPP, P13
   Sripanidkulchai K, 2003, IEEE INFOCOM SER, P2166
   Suznjevic M, 2013, MULTIMEDIA SYST, V19, P199, DOI 10.1007/s00530-012-0270-4
   Tencent, 2015, ARCH AG
   The ADAPTIVECommunication Environment, 2015, AC 2015
   Varvello M., 2007, P 6 ACM SIGCOMM WORK, P105
   Varvello M, 2011, IEEE ACM T NETWORK, V19, P80, DOI 10.1109/TNET.2010.2060351
   Xiao L, 2005, IEEE T COMPUT, V54, P1091, DOI 10.1109/TC.2005.146
   Yahyavi A, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522977
   Yu A., 2005, Proceedings of the 15th International Workshop on Network and Operating Systems Support for Digital Audio and Video. NOSSDAV 2005, P99, DOI 10.1145/1065983.1066007
   Zhou SC, 2014, COMPUT ANIMAT VIRT W, V25, P245, DOI 10.1002/cav.1582
NR 29
TC 4
Z9 4
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2016
VL 27
IS 6
BP 519
EP 531
DI 10.1002/cav.1670
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EE1HQ
UT WOS:000389332200002
OA Bronze
DA 2024-07-18
ER

PT J
AU Way, DL
   Hsieh, CH
AF Way, Der-Lor
   Hsieh, Cheng-Han
TI 3D street art illusions: embedding chalk stylized rendering of 3D
   objects into a pavement photo
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D street art; non-photorealistic rendering (NPR); line integral
   convolution (LIC); illusion art; camera calibration
ID VANISHING POINTS; IMAGE
AB Three dimensional street art illusions have become more popular in recent years. Many of them are drawn on pavement such as streets, sidewalks, and town squares. It is often known as 3D chalk art, where a 2D artwork is drawn on the street, giving the viewer a 3D optical illusion from a certain perspective. This paper supplies chalk stylized renderings for 3D models and synthesizes 3D objects into a realistic photograph. Users can input one photo for the 3D model. First, a camera position is achieved by using a camera calibration algorithm. Second, a chalk stylized rendering was applied to create an artistic image of the 3D models using the same camera position. Then, the non-photorealistic rendering image is composited into a source photograph using a modified Poisson approach. All of the enhanced pavement texture details are also blended into the object's image. The major contribution of this paper is providing a user to create any interesting and attractive 3D illusionary art without physically drawing pictures on the pavement. Finally, the proposed method is demonstrated using various experimental 3D street art illusion images. Copyright (C) 2014 John Wiley & Sons, Ltd.
C1 [Way, Der-Lor] Taipei Natl Univ Arts, Dept New Media Art, Taipei 112, Taiwan.
   [Hsieh, Cheng-Han] Natl Chiao Tung Univ, Inst Multimedia Engn, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Way, DL (corresponding author), Taipei Natl Univ Arts, Dept New Media Art, 1 Hsueh Yuan Road, Taipei 112, Taiwan.
EM adlerway@gmail.com
RI WAY, Der-Lor/HLG-1230-2023
FU Ministry of Science and Technology of the Republic of China, Taiwan
   [MOST 103-2221-E-119 -001]
FX The authors would like to thank the Ministry of Science and Technology
   of the Republic of China, Taiwan, for financially supporting this
   research under Contract No. MOST 103-2221-E-119 -001.
CR [Anonymous], P BRIT MACH VIS C
   CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813
   Chi MT, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360661
   Chu HK, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778788
   Farbman Z, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531373
   Guillou E, 2000, VISUAL COMPUT, V16, P396, DOI 10.1007/PL00013394
   Hata M, 2012, VISUAL COMPUT, V28, P657, DOI 10.1007/s00371-012-0689-9
   Hays J., 2004, PROC NPAR 01, P113
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Jia JY, 2006, ACM T GRAPHIC, V25, P631, DOI 10.1145/1141911.1141934
   Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191
   Li N., 2003, GRAPHITE, P135, DOI DOI 10.1145/604471.604498
   Lopez-Moreno J, 2010, COMPUT GRAPH-UK, V34, P698, DOI 10.1016/j.cag.2010.08.004
   Lu Cewu., 2012, Proc. NPAR, P65
   Mao X, 2002, ACM SIGGRAPH 2002 C, P149, DOI DOI 10.1145/1242073.1242162
   Mitra NJ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618509
   Oliva A, 2006, ACM T GRAPHIC, V25, P527, DOI 10.1145/1141911.1141919
   Olsen SvenC., 2005, P GRAPHICS INTERFACE, P241
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Salvi J, 2002, PATTERN RECOGN, V35, P1617, DOI 10.1016/S0031-3203(01)00126-1
   Shen JB, 2007, COMPUT GRAPH-UK, V31, P119, DOI 10.1016/j.cag.2006.10.004
   Wang Q, 2010, CHIN CONT DECIS CONF, P3354, DOI 10.1109/CCDC.2010.5498574
   Way DL, 2014, INT J INNOV COMPUT I, V10, P233
   Wenner K., 2011, ASPHALT RENAISSANCE
   Yamamoto S, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P329
   Yoon JC, 2008, COMPUT GRAPH FORUM, V27, P1869, DOI 10.1111/j.1467-8659.2008.01334.x
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 29
TC 2
Z9 2
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2015
VL 26
IS 6
BP 563
EP 575
DI 10.1002/cav.1624
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science
GA DB2QO
UT WOS:000368354300003
DA 2024-07-18
ER

PT J
AU Chao, QW
   Deng, ZG
   Jin, XG
AF Chao, Qianwen
   Deng, Zhigang
   Jin, Xiaogang
TI Vehicle-pedestrian interaction for mixed traffic simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE microscopic simulation; vehicle-pedestrian interaction; traffic
   simulation; crowds
ID MODEL
AB Simulation of real-world traffic scenarios is widely needed in virtual environments. Different from many previous works on simulating vehicles or pedestrians separately, our approach aims to capture the realistic process of vehicle-pedestrian interaction for mixed traffic simulation. We model a decision-making process for their interaction based on a gap acceptance judging criterion and then design a novel environmental feedback mechanism for both vehicles' and pedestrians' behavior-control models to drive their motions. We demonstrate that our proposed method can soundly model vehicle-pedestrian interaction behaviors in a realistic and efficient manner and is convenient to be plugged into various traffic simulation systems. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Chao, Qianwen; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 Zhejiang University; University of Houston System; University of Houston
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM jin@cad.zju.edu.cn
OI Deng, Zhigang/0000-0002-0452-8676; Deng, Zhigang/0000-0003-2571-5865
FU National Natural Science Foundation of China [61272298, 61328204]; Joint
   Research Fund for Overseas Chinese, Hong Kong; State Key Lab of CAD&CG
   at Zhejiang University [A1423]
FX Xiaogang Jin was supported by the National Natural Science Foundation of
   China (Grant no. 61272298). Zhigang Deng was supported by the Joint
   Research Fund for Overseas Chinese, Hong Kong, and Macao Young
   Scientists of the National Natural Science Foundation of China (Grant
   No. 61328204) and the Open Project Program of the State Key Lab of
   CAD&CG at Zhejiang University (Grant No. A1423).
CR [Anonymous], ACM SIGGRAPH 2008 CO
   [Anonymous], 1999, P GAM DEV C
   Aw A, 2000, SIAM J APPL MATH, V60, P916, DOI 10.1137/S0036139997332099
   BANDO M, 1995, PHYS REV E, V51, P1035, DOI 10.1103/PhysRevE.51.1035
   Chao QW, 2013, GRAPH MODELS, V75, P305, DOI 10.1016/j.gmod.2013.07.003
   Durupinar F., 2008, P 7 INT JOINT C AUT, P1217
   Gerloughs DL, 1955, THESIS UCLA
   Guy S.J., 2011, P 2011 ACM SIGGRAPH, P43, DOI [10.1145/2019406.2019413, DOI 10.1145/2019406.2019413]
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Jin XG, 2008, IEEE COMPUT GRAPH, V28, P37, DOI 10.1109/MCG.2008.117
   Kim S., 2012, P ACM SIGGRAPH S INT, P55, DOI [DOI 10.1145/2159616.2159626, 10.1145/2159616.2159626]
   Lighthill J.M., 1955, Proceedings of the royal society of london. series a. mathematical and physical sciences, V229, P317, DOI [10.1098/rspa.1955.0089, DOI 10.1098/RSPA.1955.0089]
   Lus X, 2014, COMPUTER ANIMATION V, V25, P361
   Payne H.J., 1971, SIMULATION COUNCILS, V1, P51
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pelechano N., 2008, Synthesis Lectures on Computer Graphics and Animation, V3, P1, DOI DOI 10.2200/S00123ED1V01Y200808CGR008
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Schreckenbergs M, 2001, PEDESTRIAN EVACUATIO
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   Sewall J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024169
   Sewall J, 2011, IEEE T VIS COMPUT GR, V17, P26, DOI 10.1109/TVCG.2010.27
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Shen JJ, 2012, GRAPH MODELS, V74, P265, DOI 10.1016/j.gmod.2012.04.002
   Treiber M., 2001, Automatisierungstechnik, V49, P478, DOI 10.1524/auto.2001.49.11.478
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Wan BH, 2004, TRANSPORT RES REC, P58
   Whithams G, 1974, LINEAR NONLINEAR WAV
   Wilkie D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462021
   Zhang HM, 2002, TRANSPORT RES B-METH, V36, P275, DOI 10.1016/S0191-2615(00)00050-3
NR 29
TC 34
Z9 37
U1 0
U2 31
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 405
EP 412
DI 10.1002/cav.1654
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700022
DA 2024-07-18
ER

PT J
AU Xian, CH
   Li, GQ
   Xiong, YH
AF Xian, Chuhua
   Li, Guiqing
   Xiong, Yunhui
TI Efficient and effective cage generation by region decomposition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cage generation; voxelization; region decomposition; mesh deformation
AB Cage-based deformation has become a popular method for shape deformation in computer graphics and animation. To edit a shape first requires a cage to be built to envelop the target model which is a tedious work by manual approaches. In this paper, we develop an automatic method to generate the cage for a model using voxelization based decomposition. We first voxelize the input model, and then use the seed filling algorithm to group the inner voxels. By dilating the inner voxel groups, we decompose the model into broad regions and narrow regions. Then we construct partial cages using different strategies and unite them to get a cage. Experiment results demonstrate that our method is effective, efficient as well as robust to model transformation. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Xian, Chuhua; Li, Guiqing] S China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Xiong, Yunhui] S China Univ Technol, Coll Sci, Guangzhou 510006, Guangdong, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Xian, CH (corresponding author), S China Univ Technol, Coll Sci, Guangzhou 510006, Guangdong, Peoples R China.
EM chhxian@scut.edu.cn; yhxiong@scut.edu.cn
FU NSFC [61300136]; Fundamental Research Funds for the Central Universities
   [2013ZM087]; Ministry of Education of China [20130172120010]; NSF of
   Guangdong Province [S2013020012795]
FX This paper is supported by NSFC(61300136), the Fundamental Research
   Funds for the Central Universities (2013ZM087), the Doctoral Fund of
   Ministry of Education of China (20130172120010) and NSF of Guangdong
   Province (S2013020012795).
CR Ben-Chen M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531340
   Botsch M, 2007, COMPUT GRAPH FORUM, V26, P339, DOI 10.1111/j.1467-8659.2007.01056.x
   Burchard H, 1994, Designing fair curves and surfaces, P3
   Chen YF, 1997, COMPUT AIDED GEOM D, V14, P583, DOI 10.1016/S0167-8396(96)00048-9
   Chuhuas X, 2009, IEEE INT C SHAP MOD
   COHENOR D, 1995, GRAPH MODEL IM PROC, V57, P453, DOI 10.1006/gmip.1995.1039
   Coquillart S., 1990, J. Computer Graphics, V24, P187, DOI DOI 10.1145/97880.97900
   Deng ZJ, 2011, J COMPUT SCI TECH-CH, V26, P538, DOI 10.1007/s11390-011-1153-4
   Elad M, 2002, SPRING EUROGRAP, P107
   Fabri S., 2009, P 17 ACM SIGSPATIAL, P538, DOI 10.1145/1653771.1653865
   Floater MS, 2005, COMPUT AIDED GEOM D, V22, P623, DOI 10.1016/j.cagd.2005.06.004
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Gokul Varadhan, 2003, Symposium on Geometry Processing, P116
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   Huangs J, 2008, P ACM SOL PHYS MOD 2, V2008, P241
   Joshis P, 2007, ACM T GRAPHICS, V26
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Jus T, 2008, ACM T GRAPHICS TOG, V26
   Kós G, 2000, COMPUT AIDED GEOM D, V17, P127, DOI 10.1016/S0167-8396(99)00043-6
   Landreneaus E, 2009, COMPUTER GRAPHICS FO, V28
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Lipman Yaron., 2007, Proceedings of the fifth Eurographics symposium on Geometry processing, P117
   MacCracken R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P181, DOI 10.1145/237170.237247
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Wangs SW, 1993, P 4 C VIS 93, P84
   Weber O, 2009, COMPUT GRAPH FORUM, V28, P587, DOI 10.1111/j.1467-8659.2009.01399.x
   Xian CH, 2012, VISUAL COMPUT, V28, P21, DOI 10.1007/s00371-011-0595-6
NR 30
TC 6
Z9 7
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2015
VL 26
IS 2
BP 173
EP 184
DI 10.1002/cav.1571
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CG3GB
UT WOS:000353165400008
DA 2024-07-18
ER

PT J
AU Yang, B
   Jin, XG
AF Yang, Ben
   Jin, Xiaogang
TI Turbulence synthesis for shape-controllable smoke animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE smoke animation; turbulence; procedural synthesis
ID VORTEX PARTICLE METHOD; FLUID; SIMULATION
AB We present a novel procedural synthesis method to improve small-scale turbulence details for controllable smoke animation constrained by shapes and paths. In order to enhance fluid details without introducing unpleasing fluid control effects, we propose a spatial-temporal varying synthesis parameter to control turbulence behaviors and compute it from control force and the vorticity velocity. Our approach can control enhanced turbulence behaviors efficiently and produces visually plausible realistic fine-scale details while reducing artifacts of large-scale noises on fluid control. We compare our algorithm to existing procedural synthesis ones to validate its efficiency and controllability. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Yang, Ben; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Yang, B (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
EM jin@cad.zju.edu.cn
FU China 863 program [2012AA011503]; Research Fund for Overseas Chinese,
   Hong Kong and Macao Young Scientists of the National Natural Science
   Foundation of China [61328204]; National Natural Science Foundation of
   China [61272298]
FX This work was supported by the China 863 program (Grant no.
   2012AA011503), the Joint Research Fund for Overseas Chinese, Hong Kong
   and Macao Young Scientists of the National Natural Science Foundation of
   China (Grant No. 61328204), and the National Natural Science Foundation
   of China (Grant no. 61272298).
CR [Anonymous], 2008, Fluid Simulation for Computer Graphics
   [Anonymous], ACM T GRAPHICS
   Chen F, 2011, COMPUT GRAPH FORUM, V30, P435, DOI 10.1111/j.1467-8659.2011.01872.x
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P181, DOI 10.1145/258734.258838
   He S, 2013, COMPUT GRAPH FORUM, V32, P27, DOI 10.1111/j.1467-8659.2012.03228.x
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   Kim B, 2007, IEEE T VIS COMPUT GR, V13, P135, DOI 10.1109/TVCG.2007.3
   Kim D, 2008, COMPUT GRAPH FORUM, V27, P467, DOI 10.1111/j.1467-8659.2008.01144.x
   Kim Y., 2006, P 2006 ACM SIGGRAPHE, P33
   Lentine Michael., 2011, Proceedings of the 2011 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '11, P91, DOI [10.1145/2019406.2019419, DOI 10.1145/2019406.2019419]
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Narain R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409119
   Pfaff T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866196
   Pfaff T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618467
   Pharr M., 2010, PHYS BASED RENDERING
   Schechter H., 2008, Symposium on Computer animation, P1
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Shi Lin., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '05, P229, DOI DOI 10.1145/1073368.1073401
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Yang B, 2013, COMPUT GRAPH-UK, V37, P775, DOI 10.1016/j.cag.2013.05.001
   Yoon JC, 2009, COMPUT GRAPH FORUM, V28, P1853, DOI 10.1111/j.1467-8659.2009.01563.x
   Yuan Z, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024170
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 28
TC 4
Z9 5
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 467
EP 474
DI 10.1002/cav.1585
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300027
DA 2024-07-18
ER

PT J
AU Tripicchio, P
   Loconsole, C
   Piarulli, A
   Ruffaldi, E
   Tecchia, F
   Bergamasco, M
AF Tripicchio, Paolo
   Loconsole, Claudio
   Piarulli, Andrea
   Ruffaldi, Emanuele
   Tecchia, Franco
   Bergamasco, Massimo
TI On multiuser perspectives in passive stereographic virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE passive stereo vision; user study; virtual reality
ID PERCEIVED DEPTH; DISPLAYS; PARAMETERS; IMAGES
AB The use of stereographic systems is spreading out in modern society, from the revolution of cinematography to its adoption in high-tech products such as portable gaming devices or photo cameras. However, the fruition of immersive stereographic systems by more than one person at a time is still a research issue. In more detail, the class of passive stereo systems presents technological limitations of displaying correct multiuser perspectives. In fact, the stereo image projected onto the screen is usually rendered according to a unique point of view (PoV). Nevertheless, in multiuser systems, the selection of an appropriate PoV can minimize both optical discomfort and perspective distortion. This paper aims to evaluate which among existing PoV calculation methods provides the best performances in terms of projection realism, optical comfort and overall system usability in multiuser passive stereo systems. The performances have been evaluated in three different distance scenarios to take into account also the effects of binocular disparity in the PoV calculation. To accomplish this objective, we administered a questionnaire to nine couple subjects, evaluating each of the investigated PoV calculation methods for each of the three distance scenarios. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Tripicchio, Paolo; Loconsole, Claudio; Piarulli, Andrea; Ruffaldi, Emanuele; Tecchia, Franco; Bergamasco, Massimo] Scuola Super Sant Anna, TECIP Inst, Perceptual Robot Lab, Pisa, Italy.
C3 Scuola Superiore Sant'Anna
RP Loconsole, C (corresponding author), Scuola Super Sant Anna, TECIP Inst, Perceptual Robot Lab, Pisa, Italy.
EM c.loconsole@sssup.it
RI Loconsole, Claudio/IAP-4833-2023; Tripicchio, Paolo/I-1654-2019;
   Ruffaldi, Emanuele/A-2352-2009
OI Loconsole, Claudio/0000-0002-0662-6181; Tripicchio,
   Paolo/0000-0003-3225-2782; BERGAMASCO, Massimo/0000-0002-7418-2332;
   piarulli, andrea/0000-0003-4516-2671
CR Agrawala M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P327, DOI 10.1145/258734.258875
   [Anonymous], 1994, BIOMETRY PRINCIPLES
   Arthur K., 1998, TECHNICAL REPORT
   ARTHUR KW, 1993, ACM T INFORM SYST, V11, P239, DOI 10.1145/159161.155359
   Banks Martin S, 2009, Inf Disp (1975), V25, P12
   Bimber O., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P87, DOI 10.1145/769953.769964
   Blom K., 2002, IMM PROJ TECHN WORKS
   Bolas M, 2004, IEEE COMPUT GRAPH, V24, P18, DOI 10.1109/MCG.2004.1255802
   Bouguila L., 2000, WORLD MULT SYST CYB, P406
   Cakmakci O, 2006, J DISP TECHNOL, V2, P199, DOI 10.1109/JDT.2006.879846
   Carrozzino Marcello, 2008, P 3 INT C DIG INT ME, P100
   Chun K, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P53, DOI 10.1109/HAVE.2004.1391881
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   de Haan G, 2007, COMPUT GRAPH FORUM, V26, P695, DOI 10.1111/j.1467-8659.2007.01093.x
   Dodgson NA, 2005, COMPUTER, V38, P31, DOI 10.1109/MC.2005.252
   Frohlich B., 2005, WSCG FULL PAPERS, P139
   Heldal I, 2005, P IEEE VIRT REAL ANN, P171
   Holliman NS, 2011, IEEE T BROADCAST, V57, P362, DOI 10.1109/TBC.2011.2130930
   Ijsselsteijn W, 1998, DISPLAYS, V18, P207, DOI 10.1016/S0141-9382(98)00022-5
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Ijsselsteijn WA, 1998, P SOC PHOTO-OPT INS, V3299, P282, DOI 10.1117/12.320119
   IJsselsteijn WA, 2000, IEEE T CIRC SYST VID, V10, P225, DOI 10.1109/76.825722
   Jones G, 2001, P SOC PHOTO-OPT INS, V4297, P42, DOI 10.1117/12.430855
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   LILLIEFORS HW, 1967, J AM STAT ASSOC, V62, P399, DOI 10.2307/2283970
   Lo C H., 2003, Proceedings of the 19th spring conference on Computer graphics, P109
   Manly B.F.J., 2020, RANDOMIZATION BOOTST, DOI DOI 10.1201/9781315273075
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Marbach J, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P51, DOI 10.1109/VR.2009.4810998
   MARINO G, 2007, INTUITION 2007
   McGinity M, 2007, EDT 07
   Mynatt E.D., 1994, P C AUDITORY DISPLAY, P109
   Naemura T, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P903, DOI 10.1109/ICIP.1998.723666
   Ning QA, 1997, NEURON, V18, P359, DOI 10.1016/S0896-6273(00)81238-6
   Pala S, 2007, P SOC PHOTO-OPT INS, V649011-649012
   PATTERSON R, 1992, HUM FACTORS, V34, P655, DOI 10.1177/001872089203400602
   Rani N. S., 2006, Journal of Computer Sciences, V2, P634, DOI 10.3844/jcssp.2006.634.637
   Rule JT, 1941, J OPT SOC AM, V31, P325, DOI 10.1364/JOSA.31.000325
   Sandro B., 2005, Proceedings of the 2005 ACM SIGCHI International Con- ference on Advances in Computer Entertainment Technology, P270, DOI DOI 10.1145/1178477.1178524
   Simon A, 2007, IEEE T VIS COMPUT GR, V13, P26, DOI 10.1109/TVCG.2007.23
   Springer JR, 2006, P IEEE VIRT REAL ANN, P237, DOI 10.1109/VR.2006.33
   Steinicke F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019631
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   Urey H, 2011, P IEEE, V99, P540, DOI 10.1109/JPROC.2010.2098351
   Wall W., 2002, Proceedings of Eurohaptics 2002, P23
   WANN JP, 1995, VISION RES, V35, P2731, DOI 10.1016/0042-6989(95)00018-U
   Wartell Zachary Justin, 1999, TECHNICAL REPORT
   Wozelka R., 2006, CESCG 2006 WEB P WIE
   Yamanoue H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1701, DOI 10.1109/ICME.2006.262877
NR 49
TC 3
Z9 3
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2014
VL 25
IS 1
BP 69
EP 81
DI 10.1002/cav.1535
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AA4LQ
UT WOS:000331067500007
OA Bronze
DA 2024-07-18
ER

PT J
AU Sandilands, P
   Choi, MG
   Komura, T
AF Sandilands, Peter
   Choi, Myung Geol
   Komura, Taku
TI Interaction capture using magnetic sensors
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character animation; motion capture; environment interactions
AB Capturing a close interaction between an actor and an object can be difficult as a result of occlusion and having to recreate the geometry of the scene accurately. In this paper, we propose a technique that allows us to capture the object's motion and geometry alongside the actor's movements and optionally the local environment, using a magnetic motion capture system and an RGB-D sensor. This not only gives greater information when placing a character in a scene but enables us to digitally recreate the scene in motion without significant animator work after capture. The use of magnetic sensors prevents occlusion or marker confusion that is common in optical techniques when dealing with close interactions, as the magnetic sensors do not require direct line of sight to a camera. The geometry reconstruction ensures that the proportions of objects and surfaces the character interacts with are accurate and alleviates the need for an artist to model the object. We perform validation of the results by comparison with an optical system and show a variety of motions, such as using a screwdriver or removing a cap to drink from a bottle, that can be captured using our technique. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Sandilands, Peter; Choi, Myung Geol; Komura, Taku] Univ Edinburgh, Sch Informat, Inst Percept Act & Behav, Edinburgh EH8 9AB, Midlothian, Scotland.
C3 University of Edinburgh
RP Sandilands, P (corresponding author), Univ Edinburgh, Sch Informat, Inst Percept Act & Behav, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.
EM peter.sandilands@ed.ac.uk
FU EPSRC [EP/H012338/ 1]; EU FP7 TOMSY; EPSRC [EP/H012338/1] Funding
   Source: UKRI
FX We thank the anonymous reviewers for their constructive comments. This
   work is partially supported by grants from EPSRC (EP/H012338/ 1) and EU
   FP7 TOMSY.
CR [Anonymous], 2009, IEEE INT C ROB AUT
   [Anonymous], 2005, ACM SIGGRAPH EUR S C, DOI DOI 10.1145/1073368.1073413
   Ascension, 1998, FLOCK BIRDS REAL TIM
   Autodesk Inc, 2012, AUT FBX SDX
   Blood E., 1989, Pat, Patent No. [4849692 US, 4849692]
   BURDEA G, 1993, EL 93 INT C ED APR, P164
   ElKoura G., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P110
   Hamer H., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P360, DOI 10.1109/FG.2011.5771426
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Karen Liu C., 2009, ACM Trans. Graph, V28
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Krieg J., 1993, Virtual Reality Systems, V1, P32
   Kry PG, 2006, ACM T GRAPHIC, V25, P872, DOI 10.1145/1141911.1141969
   Mitobe K, 2006, ACM SIGGRAPH 2006 RE
   Munoz-Salinas Rafael, 2012, Aruco: a minimal library for augmented reality applications based on opencv
   Sandilands Peter, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P220, DOI 10.1007/978-3-642-34710-8_21
   Ye Y, 2012, ACM T GRAPHICS SIGGR, V31, P41
NR 17
TC 5
Z9 5
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2013
VL 24
IS 6
BP 527
EP 538
DI 10.1002/cav.1537
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 273QL
UT WOS:000328551100002
DA 2024-07-18
ER

PT J
AU Ozgen, O
   Sumengen, S
   Kallmann, M
   Coimbra, CFM
   Balcisoy, S
AF Ozgen, Oktar
   Sumengen, Selcuk
   Kallmann, Marcelo
   Coimbra, Carlos F. M.
   Balcisoy, Selim
TI Simulating colliding flows in smoothed particle hydrodynamics with
   fractional derivatives
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fluid simulation; physically based simulation; fractional derivatives
ID DYNAMICS
AB We propose a new method based on the use of fractional differentiation for improving the efficiency and realism of simulations based on smoothed particle hydrodynamics (SPH). SPH represents a popular particle-based approach for fluid simulation and a high number of particles is typically needed for achieving high quality results. However, as the number of simulated particles increase, the speed of computation degrades accordingly. The proposed method employs fractional differentiation to improve the results obtained with SPH in a given resolution. The approach is based on the observation that effects requiring a high number of particles are most often produced from colliding flows, and therefore, when the modeling of this behavior is improved, higher quality results can be achieved without changing the number of particles being simulated. Our method can be employed to reduce the resolution without significant loss of quality, or to improve the quality of the simulation in the current chosen resolution. The advantages of our method are demonstrated with several quantitative evaluations. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Ozgen, Oktar; Kallmann, Marcelo] Univ Calif Merced, Sch Engn, Merced, CA USA.
   [Sumengen, Selcuk; Balcisoy, Selim] Sabanci Univ, Comp Graph Lab, Istanbul, Turkey.
   [Coimbra, Carlos F. M.] Univ Calif San Diego, Dept Mech & Aerosp Engn, San Diego, CA 92103 USA.
C3 University of California System; University of California Merced;
   Sabanci University; University of California System; University of
   California San Diego
RP Ozgen, O (corresponding author), Univ Calif Merced, Sch Engn, Merced, CA USA.
EM oozgen@ucmerced.edu
RI Coimbra, Carlos F.M./A-3036-2008; , Selim/Y-3196-2019; Kallmann,
   Marcelo/HSC-7222-2023
OI Coimbra, Carlos F.M./0000-0002-9428-3931; Balcisoy,
   Selim/0000-0002-6495-7341
FU TUBITAK [BIDEB 2214]
FX Selcuk Sumengen was funded by TUBITAK (BIDEB 2214) during his visit to
   University of California, Merced between September 2009 and February
   2010.
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   [Anonymous], MEMOIRS AM MATH SOC
   [Anonymous], ACM T GRAPHICS
   Basset A.B., 1888, Philos. t. Roy. Soc A, V179A, P43, DOI DOI 10.1098/RSTA.1888.0003
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Boussinesq J., 1885, C. R. Math. Acad. Sci. Paris, V100, P935
   Coimbra CFM, 1998, J FLUID MECH, V370, P53, DOI 10.1017/S0022112098001967
   Coimbra CFM, 2004, J FLUID MECH, V504, P353, DOI 10.1017/S002211200400789X
   Coimbra CFM, 2003, ANN PHYS-BERLIN, V12, P692, DOI 10.1002/andp.200310032
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Elcott S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1189762.1189766
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Goktekin TG, 2004, ACM T GRAPHIC, V23, P463, DOI 10.1145/1015706.1015746
   Hifler R., 2000, APPL FRACTIONAL CALC
   Ihmsen M., 2010, P VRIPHYS, P79
   Ihmsen M, 2011, COMPUT GRAPH FORUM, V30, P99, DOI [10.1111/j.1467-8659.2010.01832.x, 10.1111/j.1467-8659.2010.01834.x]
   Kilbas A. A., 2006, THEORY APPL FRACTION
   L'Espérance D, 2005, EXP FLUIDS, V38, P112, DOI 10.1007/s00348-004-0905-0
   Lenaerts T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360648
   Liu GR., 2003, SMOOTHED PARTICLE HY, DOI 10.1142/5340
   Miller K., 1993, An Introduction to the Fractional Calculus and Fractional Differential Equations
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Narain R, 2008, SIGGRAPH ASIA 08 ACM, P1
   Oger G, 2007, J COMPUT PHYS, V225, P1472, DOI 10.1016/j.jcp.2007.01.039
   Oldham K., 1974, The Fractional Calculus, DOI DOI 10.1017/S0308210500019648
   Ozgen O, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805967
   Pedro HTC, 2008, J VIB CONTROL, V14, P1659, DOI 10.1177/1077546307087397
   Pfaff T, 2009, SIGGRAPH ASIA 09 ACM, P1
   Podlubny I., 1999, FRACTIONAL DIFFERENT
   Ramirez LES, 2007, ANN PHYS-BERLIN, V16, P543, DOI 10.1002/andp.200710246
   Ramirez LES, 2011, PHYSICA D, V240, P1111, DOI 10.1016/j.physd.2011.04.001
   Raveendran K., 2011, P 2011 ACM SIGGRAPHE, P33
   Solenthaler B, 2009, SIGGRAPH 09 ACM SIGG, P1
   Soon CM, 2005, ANN PHYS-BERLIN, V14, P378, DOI 10.1002/andp.200410140
   Treuille A, 2006, ACM T GRAPHIC, V25, P826, DOI 10.1145/1141911.1141962
   Zielinski BS, 2007, FISH PHYSIOL, V25, P1, DOI 10.1016/S1546-5098(06)25001-5
NR 37
TC 1
Z9 2
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2013
VL 24
IS 5
BP 511
EP 523
DI 10.1002/cav.1527
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 238UL
UT WOS:000325976300006
DA 2024-07-18
ER

PT J
AU Jeong, MH
   Ko, HS
AF Jeong, Moon-Hwan
   Ko, Hyeong-Seok
TI Draft-space warping: grading of clothes based on parametrized draft
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE garment grading; mean value coordinates; clothing simulation; clothing
   design retargeting
AB This paper presents a novel framework for garment grading. In CG, an extensive amount of study has been carried out to clothe human characters, but little attention has been taken to the grading problem itself. For the development of a grading technique, we obtained the insight from the process of drawing the patternmaking draft (sloper) in the clothing field. Noting that the draft can be completely determined by supplying the primary body sizes, we abstract the draft construction process as a computer procedure, which we call the parametrized draft. With the parametrized draft, we develop a grading method based on the draft-space warping, which takes three steps: (i) draft-space encoding, (ii) target draft construction, then (iii) draft-space decoding. The proposed grading method can be performed instantly for any given body without calling for the user's intervention. With experimental results, we show that the new grading framework can bring an improvement to garment grading. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Jeong, Moon-Hwan; Ko, Hyeong-Seok] Seoul Natl Univ, Graph & Media Lab, Dept Elect & Comp Engn, Seoul, South Korea.
C3 Seoul National University (SNU)
RP Jeong, MH (corresponding author), Seoul Natl Univ, Graph & Media Lab, Dept Elect & Comp Engn, 1 Gwanak Ro, Seoul, South Korea.
EM ansghkss@snu.ac.kr; ko@graphics.snu.ac.kr
FU Ministry of Culture, Sports and Tourism (MCST); Korea Culture Content
   Agency (KOCCA) in the Culture Technology (CT) Research Development
   Programs; Basic Science Research Program through the National Research
   Foundation of Korea (NRF); Ministry of Education, Science and Technology
   (MEST) [2012R1A2A1A01004891]; Brain Korea 21 Project; ASRI (Automation
   and Systems Research Institute at Seoul National University)
FX This work was supported by Ministry of Culture, Sports and Tourism
   (MCST) and Korea Culture Content Agency (KOCCA) in the Culture
   Technology (CT) Research Development Programs 2013, the Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Education, Science and Technology (MEST) (No.
   2012R1A2A1A01004891), the Brain Korea 21 Project in 2013, and ASRI
   (Automation and Systems Research Institute at Seoul National
   University). The authors thank Dr. Young-A Ko for the advice in the
   initial conception of this work.
CR Brouet R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185532
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119
   Horlamus T, 2008, THREADS, V101, P66
   Hormann K, 2006, ACM T GRAPHIC, V25, P1424, DOI 10.1145/1183287.1183295
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Lipman Yaron., 2007, Proceedings of the fifth Eurographics symposium on Geometry processing, P117
   Meng YW, 2012, COMPUT AIDED DESIGN, V44, P68, DOI 10.1016/j.cad.2010.11.008
   Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011
   Umetani N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964985
   Volino P, 2005, COMPUT AIDED DESIGN, V37, P593, DOI 10.1016/j.cad.2004.09.003
   Wang CCL, 2005, COMPUT AIDED DESIGN, V37, P675, DOI 10.1016/j.cad.2004.08.007
   Warren J, 2007, ADV COMPUT MATH, V27, P319, DOI 10.1007/s10444-005-9008-6
NR 14
TC 2
Z9 2
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 377
EP 386
DI 10.1002/cav.1503
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500025
DA 2024-07-18
ER

PT J
AU ap Cenydd, L
   Teahan, B
AF ap Cenydd, Llyr
   Teahan, Bill
TI An embodied approach to arthropod animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dynamic animation; procedural animation; real-time; arthropods; spiders;
   insects
ID DECENTRALIZED ARCHITECTURE; LEGGED LOCOMOTION; WALKING; INSECT;
   MOVEMENTS; WALKNET; NETWORK
AB We describe a system for dynamically animating the locomotive behaviour of arthropods (insects, spiders and numerous other species) in real-time, facilitating realistic and autonomous traversal across an arbitrary environment. By combining a decentralised reactive behavioural model with a hybrid approach to motion that utilises the comparative advantages of physical simulation and kinematic control, our system is capable of automatically generating complex organic motion over a wide range of surface features, independent of structural complexity. The reactive embodiment of the creature, combined with the physical simulation of the virtual world enables the formation of emergent behaviours that are entirely based on circumstance, including rigid-body interaction, grip recovery and adaptive wall climbing. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [ap Cenydd, Llyr; Teahan, Bill] Bangor Univ, Sch Comp Sci, Bangor, Gwynedd, Wales.
C3 Bangor University
RP ap Cenydd, L (corresponding author), Bangor Univ, Sch Comp Sci, Bangor, Gwynedd, Wales.
EM llyr.ap.cenydd@bangor.ac.uk
CR Alshurafa NI, 2006, P INT SOC OPTICAL EN, V6230
   [Anonymous], GAM DEV C SAN JOS CA
   [Anonymous], 2011, OGRE OBJ OR GRAPH RE
   [Anonymous], 1091 MIT AI LAB
   [Anonymous], 2011, REALTIME ARTHROPOD A
   ap Cenydd L, 2005, EGUK THEORY PRACTICE, P125
   ap Cenydd L, 2007, EGUK THEORY PRACTICE, P21
   Beer R.D., 1990, Intelligence as Adaptive Behavior: An Experiment in Computational Neuroethology
   Beer Randall D., 1992, Adaptive Behavior, V1, P91, DOI 10.1177/105971239200100105
   BEER RD, 1992, NEURAL COMPUT, V4, P356, DOI 10.1162/neco.1992.4.3.356
   Beer RD, 1989, ADV NEURAL INFORMATI, V1, P577
   Bowerman R.W., 1981, P73
   BOWERMAN RF, 1975, J COMP PHYSIOL, V100, P183, DOI 10.1007/BF00614529
   Coros S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1781156
   Cruse H, 2004, CISM COURSES LECT, P81
   Cruse H, 1998, NEURAL NETWORKS, V11, P1435, DOI 10.1016/S0893-6080(98)00067-7
   Cruse H, 2007, PHILOS T R SOC A, V365, P221, DOI 10.1098/rsta.2006.1913
   DELCOMYN F, 1973, J EXP BIOL, V59, P643
   Dürr V, 2001, J EXP BIOL, V204, P1589
   Espenscheid Kenneth S., 1993, Adaptive Behavior, V1, P455, DOI 10.1177/105971239300100404
   Espenschied KS, 1994, P 5 INT S ROB MAN MA, P14
   Fang AC, 2003, ACM T GRAPHIC, V22, P417, DOI 10.1145/882262.882286
   Frantsevich L, 1997, J INSECT PHYSIOL, V43, P447, DOI 10.1016/S0022-1910(96)00119-9
   Full RJ, 2002, INTEGR COMP BIOL, V42, P149, DOI 10.1093/icb/42.1.149
   Gibson DP, 2007, GRAPH MODELS, V69, P231, DOI 10.1016/j.gmod.2006.09.005
   Holmes P, 2006, SIAM REV, V48, P207, DOI 10.1137/S0036144504445133
   Koditschek DE, 2004, ARTHROPOD STRUCT DEV, V33, P251, DOI 10.1016/j.asd.2004.06.003
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866160
   MACMILLAN DL, 1975, PHILOS T R SOC B, V270, P1, DOI 10.1098/rstb.1975.0003
   McKenna M., 1990, Computer Graphics, V24, P29, DOI 10.1145/97880.97882
   Meredith M., 2004, TECHNICAL REPORT
   Murdock A, 2006, BORIS SPIDER AUTODES
   Natural Motion, 2011, DYN MOT SYNTH
   Newton Game Dynamics, 2011, NEWT GAM DYN PHYS EN
   Shapiro A, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P455, DOI 10.1109/PCCGA.2003.1238294
   Skrba L, 2008, EUROGRAPHICS 08 STAT, P7
   Sullivan C, 2006, THESIS BOURNEMOUTH U
   van Basten B.J. H., 2011, Graphics Interface, P9
   van Welbergen H, 2010, COMPUT GRAPH FORUM, V29, P2530, DOI 10.1111/j.1467-8659.2010.01822.x
   Xu WW, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531341
   Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556
NR 42
TC 8
Z9 8
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2013
VL 24
IS 1
BP 65
EP 83
DI 10.1002/cav.1436
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 089PU
UT WOS:000314923300007
OA Bronze
DA 2024-07-18
ER

PT J
AU Kim, J
   Cho, H
AF Kim, Jinmo
   Cho, Hyungje
TI Efficient modeling of numerous trees by introducing growth volume for
   real-time virtual ecosystems
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE generative tree modeling; growth model of numerous trees; growth volume;
   real-time virtual ecosystems
AB This study suggests a growth volume system for the efficient modeling of numerous trees for a real-time virtual ecosystem. To increase the efficiency of the real-time system and to allow natural tree generation, the basic tree modeling system obtains its growth rule by means of botany-based self-organizing under a recursive hierarchy structure. On the basis of this rule, growth volume was introduced and controlled to generate numerous trees in a virtual ecosystem more intuitively, which allows the generation of various trees. The reality of the expression was increased by including the effects of external factors, such as light, physical obstacles, and other trees. Finally, an instancing-based branch control procedure was added to enable an efficient rendering of the real-time ecosystem. Experiments were performed to verify whether various and natural trees could be generated and numerous trees in the virtual ecosystem can be easily modeled on the basis of the suggested growth volume, which shows the efficiency of the real-time ecosystem. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Kim, Jinmo; Cho, Hyungje] Dongguk Univ, Dept Multimedia, Seoul, South Korea.
C3 Dongguk University
RP Cho, H (corresponding author), Dongguk Univ, Dept Multimedia, Seoul, South Korea.
EM chohj@dongguk.edu
RI Kim, Jinmo/AAG-2822-2020
OI Kim, Jinmo/0000-0002-1663-9306
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA) in the Culture Technology (CT) Research and Development
   Program
FX This research is supported by Ministry of Culture, Sports and Tourism
   (MCST) and Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) Research and Development Program 2011.
CR [Anonymous], 1962, PROC S APPL MATH, DOI DOI 10.1090/PSAPM/014/9947
   [Anonymous], 1996, P 2 CSIRO S COMPUTAT
   Benes B, 2002, COMP ANIM CONF PROC, P33, DOI 10.1109/CA.2002.1017504
   Benes Bedrich., 2009, Eurographics Workshop on Natural Phenomena, P9
   Boulanger K, 2008, COMPUT GRAPH FORUM, V27, P1189, DOI 10.1111/j.1467-8659.2008.01257.x
   Candussi A, 2005, RENDERING REALISTIC
   Chen X, 2008, P SIGGRAPH AS 2008 S, P109
   Deussen O, 1997, PROC GRAPH INTERF, P189
   Deussen O., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P275, DOI 10.1145/280814.280898
   HONDA H, 1971, J THEOR BIOL, V31, P331, DOI 10.1016/0022-5193(71)90191-3
   Li C, 2011, P 2011 SIGGRAPH AS C, P127
   LINDENMAYER A, 1968, J THEOR BIOL, V18, P280, DOI 10.1016/0022-5193(68)90079-9
   Lintermann B, 1996, COMP AN SIM 96 POIT
   Livny Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964948
   Livny Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866177
   McCormack J, 1993, INTERACTIVE EVOLUTIO, P118
   Mech R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P397, DOI 10.1145/237170.237279
   Okabe M, 2005, COMPUT GRAPH FORUM, V24, P487, DOI 10.1111/j.1467-8659.2005.00874.x
   Palubicki W, 2009, P SIGGRAPH 2009 NEW, P58
   Runions A., 2007, NPH, P63
   Talton JO, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944851
   Tan P, 2008, P SIGGRAPH AS 2008 S, P108
NR 22
TC 10
Z9 13
U1 2
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 155
EP 165
DI 10.1002/cav.1438
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100004
DA 2024-07-18
ER

PT J
AU Yang, M
   Jiang, LS
   Li, XS
   Liu, YQ
   Liu, XH
   Wu, EH
AF Yang, Meng
   Jiang, Longsheng
   Li, Xiaosheng
   Liu, Youquan
   Liu, Xuehui
   Wu, Enhua
TI Interactive coupling between a tree and raindrops
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE two-resolution tree motion; drop motion; realistic effects; interactive
   coupling
ID ANIMATION; WATER; FLUID
AB This paper presents a novel approach for simulating the dynamic coupling between a tree and raindrops based on physical deformation and fluid simulation. By the approach, tree animation in the rain can be simulated in a two-resolution way: branch motion and leaf motion. The branch is represented by the EulerBernoulli beam model, and the leaf petiole is represented by the three-prism elastic model. Interaction coupling liquid motion on the hydrophilic surface with a flexible petiole is well implemented by a special design. To simplify the computation process, instead of the computation-intensive three-dimensional NavierStokes equations, shallow water equations are used to simulate the water dynamics together with the whole leaf deformation. Simulation has been also made to various phenomena incurred from the interactive coupling. These include, among others, part of impacting raindrops splashing into the air with the remaining flowing along the slant of the leaf and merging into larger ones or hanging on the blade boundary, with the leaf rebounding and vibrating after the drops fall off the leaf. A level-of-detail approach is exploited to accelerate rendering in views of different distances. The experimental results illustrate that the approach can be applied to efficiently generate realistic details of the interactive coupling between a tree and raindrops. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Yang, Meng; Jiang, Longsheng; Li, Xiaosheng; Liu, Xuehui; Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Yang, Meng; Wu, Enhua] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macau, Peoples R China.
   [Yang, Meng; Jiang, Longsheng; Li, Xiaosheng; Wu, Enhua] Chinese Acad Sci, Grad Univ, Beijing, Peoples R China.
   [Liu, Youquan] Changan Univ, Xian, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; University of
   Macau; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS; Chang'an University
RP Yang, M (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
EM yangm@ios.ac.cn
RI Liu, Youquan/C-1628-2012; Lin, Fan/JZT-1441-2024
OI Lin, Fan/0000-0002-7330-3833; YANG, Meng/0000-0001-6439-2873
FU National Natural Science Foundation of China [60833007, 60973066];
   National Grand Fundamental Research 973 Program of China [2009CB320802];
   University of Macau
FX The authors would like to thank anonymous reviewers for their
   constructive advices and Dr. Fang Liu, Mengcheng Huang, Ming Liu, and
   Xiaolong Wu for their kind help. This work has been supported by the
   National Natural Science Foundation of China (grant numbers 60833007 and
   60973066), the National Grand Fundamental Research 973 Program of China
   (grant number 2009CB320802), and the University of Macau Research Grant.
CR Akagi Y, 2006, COMPUT GRAPH-UK, V30, P529, DOI 10.1016/j.cag.2006.03.017
   Angst R, 2007, THESIS ETH ZURICH
   [Anonymous], 2008, Fluid Simulation for Computer Graphics
   [Anonymous], MORGAN KAUFMANN SERI
   Baraff D, 2001, ACM SIGGRAPH 2001 CO
   Batty C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276502
   Becker M, 2009, IEEE T VIS COMPUT GR, V15, P493, DOI 10.1109/TVCG.2008.107
   Carlson M, 2004, ACM T GRAPHIC, V23, P377, DOI 10.1145/1015706.1015733
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Garg K, 2007, P EUR S REND GREN FR
   Génevaux O, 2003, PROC GRAPH INTERF, P31
   Guendelman E, 2005, ACM T GRAPHIC, V24, P973, DOI 10.1145/1073204.1073299
   Habel R, 2009, COMPUT GRAPH FORUM, V28, P523, DOI 10.1111/j.1467-8659.2009.01391.x
   Kaneda K., 1996, 1996 Pacific Graphics Conference Proceedings, P50
   Kaneda K, 1999, J VISUAL COMP ANIMAT, V10, P15, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<15::AID-VIS192>3.0.CO;2-P
   Liu YQ, 2005, VISUAL COMPUT, V21, P727, DOI 10.1007/s00371-005-0314-2
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Ono Hiromi., 1997, Proceedings of the 8th Eurographics Workshop on Computer Animation and Simulation, P149
   Ota S, 2004, VISUAL COMPUT, V20, P613, DOI 10.1007/s00371-004-0266-y
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Thurey N., 2007, THESIS U ERLANGEN NU
   Wang HM, 2005, ACM T GRAPHIC, V24, P921, DOI 10.1145/1073204.1073284
   Yang M., 2009, P 8 INT C VIRT REAL, P47
   Yang M., 2010, 17 ACM S VIRTUAL REA, P83
   Yang Mengu, 2011, Journal of Software, V22, P1934, DOI 10.3724/SP.J.1001.2011.04022
   Yu YJ, 1999, COMPUT GRAPH-UK, V23, P213, DOI 10.1016/S0097-8493(99)00031-X
   Zhang Y, 2011, IEEE T VISUALIZATION, V99, DOI http://doi.ieeecomputersociety.org/10.1109/TVCG.2011.141
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
   Zioma R, 2007, GPU GEMS
NR 32
TC 3
Z9 4
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 267
EP 277
DI 10.1002/cav.1451
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100014
OA Bronze
DA 2024-07-18
ER

PT J
AU Liao, SH
   Liang, YX
   Li, LZ
   Zou, BJ
   Zhu, XH
   Ai, W
AF Liao, Sheng-Hui
   Liang, Yixiong
   Li, Ling-Zhi
   Zou, Bei-Ji
   Zhu, Xing-Hao
   Ai, Wei
TI Practical craniofacial surgery simulator based on GPU accelerated
   lattice shape matching
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE craniofacial surgery; soft tissue deformation; lattice shape matching;
   GPU acceleration
ID MAXILLOFACIAL SURGERY; MODEL
AB This paper presents an intuitive and practical craniofacial surgery simulation system, which is suitable for daily clinical practice. The key component of the system is a GPU accelerated lattice shape matching method, to estimate individual patient post-operative appearance interactively. The lattice model can be set up from individual CT data in an easy and robust way, incorporating CT mapping physical inhomogeneous material as well as orthotropic behavior of soft tissue. Instead of simulating dynamic behavior, an iterative optimization is used for direct computation of soft tissue deformation. In addition, a GPU acceleration framework for the lattice shape matching method is further exploited based on the lattice regularity, thus the simulation operations can be performed at interactive or real time. Finally, a craniofacial surgery simulation system is developed for daily clinical practice, which is capable of simulating a variety of surgeries including osteotomies, bone fragment repositioning, and insertion of implants. The treatment of more than 50 patients was found to provide a good correlation between simulation and post-operative outcome. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Liao, Sheng-Hui; Liang, Yixiong; Li, Ling-Zhi; Zou, Bei-Ji; Zhu, Xing-Hao; Ai, Wei] Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
C3 Central South University
RP Liao, SH (corresponding author), Cent S Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
EM shliao@zju.edu.cn
RI LIANG, YIXIONG/ABC-6068-2021; , Yixiong/AAQ-2023-2020
OI , Yixiong/0000-0002-2260-066X; Liang, Yixiong/0000-0003-0407-5838
CR [Anonymous], 2005, ACMEUROGRAPHICS S CO
   Chabanas M, 2003, MED IMAGE ANAL, V7, P131, DOI 10.1016/S1361-8415(02)00108-1
   Gibson S. F. F., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P149, DOI 10.1145/253284.253324
   GLADILIN E, 2003, THESIS FU BERLIN GER
   Keeve E, 1998, Comput Aided Surg, V3, P228
   Keeve E, 1996, INT CONGR SER, V1124, P757
   Li MF, 2011, COMPUT GRAPH-UK, V35, P92, DOI 10.1016/j.cag.2010.11.013
   Liang RH, 2008, J DISP TECHNOL, V4, P431, DOI 10.1109/JDT.2008.2002223
   MAKOTO O, 2009, COMPUTER ANIMATION V, V20, P365
   Meehan M, 2003, Orthod Craniofac Res, V6 Suppl 1, P102
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   PAULY M, 2005, P SIGGRAPH 05, P957
   RIVERS AR, 2007, P SIGGRAPH 07
   Sarti A, 1999, FUTURE GENER COMP SY, V15, P217, DOI 10.1016/S0167-739X(98)00065-X
   Steinemann D., 2008, P 2008 ACM SIGGRAPHE, P87
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Teschner M, 1999, LECT NOTES COMPUT SC, V1679, P1183
   Teschner M., 2000, VMV 00, P383
   WANG Q, 2007, IEEE COMPUTING SCI E, V9, P32
   Westermark A, 2005, J CRANIOFAC SURG, V16, P100, DOI 10.1097/00001665-200501000-00019
   Zachow S, 2000, INT CONGR SER, V1214, P23
   Zachow S., 2001, MEDICAL IMAGE COMPUT, P473
NR 23
TC 1
Z9 1
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 269
EP 276
DI 10.1002/cav.393
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700023
DA 2024-07-18
ER

PT J
AU Liu, YL
   Qin, XY
   Xing, GY
   Peng, QS
AF Liu, Yanli
   Qin, Xueying
   Xing, Guanyu
   Peng, Qunsheng
TI A new approach to outdoor illumination estimation based on statistical
   analysis for augmented reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE augmented reality; illumination estimation; image statistics; outdoor
   scenes
AB Illumination consistency plays an important role in realistic rendering of virtual characters which are integrated into a live video of real scene. This paper proposes a novel method for estimating the illumination conditions of outdoor videos captured by a fixed viewpoint. We first derive an analytical model which relates the statistics of an image to the lighting parameters of the scene adhering to the basic illumination model. Exploiting this model, we then develop a framework to estimate the lighting conditions of live videos. In order to apply the above approach to scenes containing dynamic objects such as intrusive pedestrians and swaying trees, we enforce two constraints, namely spatial and temporal illumination coherence, to refine the solution. Our approach requires no geometric information of the scenes and is sufficient for real-time performance. Experiments show that with the lighting parameters recovered by our method, virtual characters can be seamlessly integrated into the live video. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Qin, Xueying] Zhejiang Univ, State key Lab EAD & CG, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Qin, XY (corresponding author), Zhejiang Univ, State key Lab EAD & CG, Hangzhou, Zhejiang, Peoples R China.
EM xyqin@cad.zju.edu.cn
RI Qin, Xueying/AAM-8775-2021
OI Qin, Xueying/0000-0003-0057-295X
CR ANDERSEN MS, 2006, ICPR, V4, P91
   [Anonymous], SIGGRAPH
   [Anonymous], ICCV
   BUI T, 2006, 3 EUR C COL GRAPH IM
   CHANTLER MJ, 2002, ECCV 2002 EUR C COMP, V3, P289
   Choudhury B, 2006, GRAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P176
   DRBOHLAV O, 2004, DO JOINT IMAGE STAT
   GINNEKEN BV, 1999, INT J COMPUT VISION, V31, P169
   HENSLEY J, 2007, S INT 3D GRAPH GAM P
   Heymann S, 2005, P INT C VID IM PREC
   Jacobs K, 2006, COMPUT GRAPH FORUM, V25, P29, DOI 10.1111/j.1467-8659.2006.00816.x
   Liu YL, 2009, VISUAL COMPUT, V25, P637, DOI 10.1007/s00371-009-0342-4
   Nakamae E., 1986, Computer Graphics, V20, P207, DOI 10.1145/15886.15909
   Rees W.G., 1990, PHYS PRINCIPLES REMO
   Sato I., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P306, DOI 10.1109/CVPR.1999.786956
   Seitz SM, 2005, IEEE I CONF COMP VIS, P1440
   Sunkavalli K., 2008, Proc. CVPR, P1
   Sunkavalli K, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276504, 10.1145/1239451.1239552]
   Wang Y, 2003, GRAPH MODELS, V65, P185, DOI 10.1016/S1524-0703(03)00043-2
   WELCH G, 2001, SIGGRAPH COURS
NR 20
TC 12
Z9 16
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 321
EP 330
DI 10.1002/cav.357
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400019
DA 2024-07-18
ER

PT J
AU Hwang, SU
   Lee, BC
   Ryu, J
   Lee, KH
   Lee, YG
AF Hwang, Sun-Uk
   Lee, Beom-Chan
   Ryu, Jeha
   Lee, Kwan H.
   Lee, Yong-Gu
TI Adaptive haptic rendering for time-varying haptic and video frame rates
   in multi-modal interactions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE haptics; sensing gloves; virtual reality; multi-modal interactions
ID REAL
AB In multi-modal interactions including haptics, problems such as input sensor noise, temporal mismatch between graphics and haptics, and non-constant refresh rates may cause non-smooth force/torque display. This paper proposes temporal smoothing technique for haptic interaction using a sensing glove in multi-modal applications. The proposed technique employs two processes: (1) a noise reduction method is applied to reduce jitter noise at the sensors in the sensing glove and (2) an adaptive force extrapolation is applied for time-varying haptic and video frame rates. To demonstrate the performance of the proposed method, We developed a test platform to assess a simple box model and relatively complex models such as gamephone, portable media player (PMP) It was subsequently demonstrated that the proposed method can support smooth haptic interactions in multi-modal applications where a haptic device and a sensing glove are used. Copyright (D, 2009 John Wiley & Sons, Ltd.
C1 [Ryu, Jeha; Lee, Yong-Gu] GIST, Dept Mechatron, Kwangju 500712, South Korea.
   [Lee, Kwan H.] No Illinois Univ, De Kalb, IL 60115 USA.
   [Lee, Kwan H.] GIST, Sch Informat & Mechatron, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST); Northern Illinois
   University; Gwangju Institute of Science & Technology (GIST)
RP Lee, YG (corresponding author), GIST, Dept Mechatron, 1 Oryong Dong, Kwangju 500712, South Korea.
EM lygu@gist.ac.kr
OI Ryu, Jeha/0000-0003-4084-5684
FU Ministry of Education, Science and Technology, Korea
   [R0A-2007-000-20049-0]; institute of Medical System Engineering (iMSE)
   in the GIST, Korea; MIC (Ministry of Information and Communication),
   Korea; ITRC (Information Technology Research Center)
   [ITA-2008-C1090-0804-0002]
FX This research is supported by the Korea Science and Engineering
   Foundation (KOSEF) through the National Research Laboratory (NRL)
   Program funded by the Ministry of Education, Science and Technology,
   Korea (No. R0A-2007-000-20049-0), the institute of Medical System
   Engineering (iMSE) in the GIST, Korea, and by the MIC (Ministry of
   Information and Communication), Korea, under the ITRC (Information
   Technology Research Center) support program supervised by the IITA
   (Institute for Information Technology Advancement)
   (IITA-2008-C1090-0804-0002).
CR Benslimane A, 2000, EUROMICRO CONF PROC, P456, DOI 10.1109/EURMIC.2000.874667
   BOURGUET ML, 2003, P HCI 03, V2, P81
   Brewster S, 2002, DISABIL REHABIL, V24, P613, DOI 10.1080/09638280110111388
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   CAGATAY B, 2000, ACM T COMPUT-HUM INT, V7, P443
   CHA J, 2005, P 10 INT C HUM COMP, P1046
   Cha J, 2006, IEEE T CONSUM ELECTR, V52, P477, DOI 10.1109/TCE.2006.1649668
   CHEN HY, 1995, IEEE T CONSUM ELECTR, V41, P12, DOI 10.1109/30.370305
   Conti Francois., 2005, IEEE WORLD HAPT PIS
   ELHELALY M, 2007, P 2007 IEEE INT C IM, V6, P193
   *FORC DIM CO, 2004, DHD 6 DOF US MAN VER
   FRANS F, 2003, P 5 INT C MULT INT I, P1
   GEORGIOS N, 2004, P 9 C SPEECH COMP SP, P507
   Iddan GJ, 2001, P SOC PHOTO-OPT INS, V4298, P48, DOI 10.1117/12.424913
   *IMM CORP, 2001, VHS US GUID VERS 2 7
   PerezLuque MJ, 1996, IEEE J SEL AREA COMM, V14, P36, DOI 10.1109/49.481692
   Robles-De-La-Torre G, 2006, IEEE MULTIMEDIA, V13, P24, DOI 10.1109/MMUL.2006.69
   Salisbury K, 2004, IEEE COMPUT GRAPH, V24, P24, DOI 10.1109/MCG.2004.1274058
   Sharp HM, 1997, EUR PSYCHIAT, V12, P1, DOI 10.1016/S0924-9338(97)86371-7
   *VIRT TECHN INC, 2000, VIRT HAND SDK REF MA
   Wongwirat O, 2005, IEEE ASME INT C ADV, P1305
   XAVIER R, 2005, P 2005 INT C NEW INT, P109
   You YG, 2007, 6TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P834, DOI 10.1109/ICIS.2007.58
   Zhou J, 2007, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND ENGINEERING MANAGEMENT, VOLS A AND B, P201
   Zhou JL, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P99, DOI 10.1109/HAVE.2004.1391889
NR 25
TC 0
Z9 0
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2010
VL 21
IS 1
BP 25
EP 38
DI 10.1002/cav.328
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 560XD
UT WOS:000274937200003
DA 2024-07-18
ER

PT J
AU Jin, G
   Baek, N
   Hahn, JK
   Bielamowicz, S
   Mittal, R
   Walsh, R
AF Jin, Ge
   Baek, Nakhoon
   Hahn, James K.
   Bielamowicz, Steven
   Mittal, Rajat
   Walsh, Raymond
TI Image guided medialization laryngoplasty
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE image guided surgery; registration; partial shape matching
ID REGISTRATION
AB Techniques that originate in computer graphics and computer vision have found prominent applications in the medical domain. In this paper, we have seamlessly developed techniques from computer graphics and computer vision together with domain knowledge from medicine to develop an image guided surgical system for medialization laryngoplasty. The technical focus of this paper is to register the preoperative radiological data to the intraoperative anatomical structure of the patient. With careful analysis of the real-world surgical environment., we have developed an TCP-based partial shape matching algorithm to register the partially visible anatomical structure to the preoperative CT data. We extracted distinguishable features from the human thyroid cartilage surface and applied image space template matching to find the initial guess for the shape matching. The experimental result shows that our feature-based partial shape matching method has better performance and robustness compared with original ICP-based shape matching method. Although this paper concentrates on the medialization laryngoplasty procedure, its generality makes our methods ideal for future applications in other image guided surgical areas. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Jin, Ge] Purdue Univ Calumet, Dept Comp Informat Technol & Graph, Hammond, LA USA.
   [Jin, Ge] George Washington Univ, Dept Comp Sci, Washington, DC 20052 USA.
   [Baek, Nakhoon] Kyungpook Natl Univ, Sch Elect Engn & Comp Sci, Taegu, South Korea.
   [Hahn, James K.] Washington Univ, Dept Comp Sci, St Louis, MO 63130 USA.
   [Bielamowicz, Steven] George Washington Univ, Div Otolaryngol, Washington, DC 20052 USA.
   [Bielamowicz, Steven] George Washington Univ, Voice Treatment Ctr, Washington, DC 20052 USA.
   [Mittal, Rajat] George Washington Univ, Dept Mech & Aerosp Engn, Washington, DC 20052 USA.
   [Walsh, Raymond] George Washington Univ, Sch Med & Hlth Sci, Washington, DC 20052 USA.
C3 Purdue University System; Purdue University; George Washington
   University; Kyungpook National University; Washington University
   (WUSTL); George Washington University; George Washington University;
   George Washington University; George Washington University
RP Hahn, JK (corresponding author), 801 22nd ST NW,Suite 703, Washington, DC 20052 USA.
EM hahn@gwu.edu
RI Mittal, Rajat/A-3009-2010; Hahn, James/AAF-8272-2021
OI Baek, Nakhoon/0000-0003-2136-843X; Mittal, Rajat/0000-0002-8107-9499
FU National Institutes of Health [R01-DC007125-01B1]
FX This work was supported by the National Institutes of Health with a
   grant R01-DC007125-01B1 to develop computer-based tools for
   medialization laryngoplasty.
CR Anderson TD, 2003, J VOICE, V17, P442, DOI 10.1067/S0892-1997(03)00080-8
   [Anonymous], P 4 EUR S GEOM PROC
   [Anonymous], Matlab documentation for fmincon
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Cash DM, 2003, MED PHYS, V30, P1671, DOI 10.1118/1.1578911
   Darabi K, 1997, INT CONGR SER, V1134, P920
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Gelfand N., 2005, P 3 EUR S GEOM PROC, V2, P5
   Gilles B, 2006, LECT NOTES COMPUT SC, V4190, P289
   Greenspan M, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P442, DOI 10.1109/IM.2003.1240280
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Huang QX, 2006, ACM T GRAPHIC, V25, P569, DOI 10.1145/1141911.1141925
   *INT CORP, 2000, OP SOURC COMP VIS LI
   Jin G, 2007, PROC SPIE, V6509, DOI 10.1117/12.709612
   Jin G, 2006, LECT NOTES COMPUT SC, V4291, P761
   KELLY PJ, 1986, NEUROLOGY, V36, P535, DOI 10.1212/WNL.36.4.535
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Marmulla R, 2004, J ORAL MAXIL SURG, V62, P845, DOI 10.1016/j.joms.2004.01.014
   Masuda T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P879, DOI 10.1109/ICPR.1996.546150
   Maurer CR, 1997, IEEE T MED IMAGING, V16, P447, DOI 10.1109/42.611354
   Miga MI, 2003, IEEE T MED IMAGING, V22, P973, DOI 10.1109/TMI.2003.815868
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   SCHROEDER W, 2000, VISUALIZATION TOOLKI
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Simon DA, 1996, THESIS CARNEGIE MELL
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 28
TC 2
Z9 3
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2009
VL 20
IS 1
BP 67
EP 77
DI 10.1002/cav.271
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 407WD
UT WOS:000263394100007
PM 20664748
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Lim, S
   Kwon, K
   Shin, BS
AF Lim, Sukhyun
   Kwon, Koojoo
   Shin, Byeong-Seok
TI GPU-based interactive visualization framework for ultrasound datasets
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE interactive medical visualization; volume ray casting; GPU-based volume
   rendering; ultrasound rendering; filtering
ID TIME 3-DIMENSIONAL ULTRASOUND; VOLUMETRIC IMAGING-SYSTEM; OCTREE;
   QUANTIFICATION; SPECKLE
AB Ultrasound imaging is widely used in medical areas. By transmitting ultrasound signals into the human body, their echoed signals call be rendered to represent the shape of internal organs. Although its image quality is inferior to that of CT or MR, ultrasound is widely used for its speed and reasonable cost. Volume rendering techniques provide methods for rendering the 3D volume dataset intuitively. We present a visualization framework for ultrasound datasets that uses programmable graphics hardware. For this, we convert ultrasound coordinates into Cartesian form. In ultrasound datasets, however, since physical storage and representation space is different, we apply different sampling intervals adaptively for each ray. In addition, we exploit multiple filtered datasets in order to reduce noise. By our method, we can determine the adequate filter size without considering the filter size. As a result, our approach enables interactive volume rendering for ultrasound datasets, using a consumer-level PC. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Lim, Sukhyun] Inha Univ, Dept Comp & Informat Engn, Sch Comp Engn, Inchon 402751, South Korea.
C3 Inha University
RP Shin, BS (corresponding author), Inha Univ, Dept Comp & Informat Engn, Sch Comp Engn, 253 Yonghyundong, Inchon 402751, South Korea.
EM bsshin@inha.ac.kr
FU INHA University Research Grant
FX This work was supported by INHA University Research Grant.
CR Angelini ED, 2005, ULTRASOUND MED BIOL, V31, P1143, DOI 10.1016/j.ultrasmedbio.2005.03.016
   Angelini ED, 2001, IEEE T MED IMAGING, V20, P457, DOI 10.1109/42.929612
   BURCKHARDT CB, 1978, IEEE T SON ULTRASON, V25, P1, DOI 10.1109/T-SU.1978.30978
   CARR JC, 1996, THESIS U CANTERBURY
   COPPINI G, 1995, IEEE T MED IMAGING, V14, P301, DOI 10.1109/42.387712
   DUNN F, 1991, IEEE T EDUC, V34, P266, DOI 10.1109/13.85085
   Engel K, 2006, Real-Time Volume Graphics
   Engel Klaus, 2001, P ACM SIGGRAPH EUROG, P9, DOI [DOI 10.1145/383507.383515, 10.1145/383507.383515]
   EVANS AN, 1993, IEE CONF PUBL, P44
   Fattal R, 2001, IEEE VISUAL, P403, DOI 10.1109/VISUAL.2001.964539
   Grimm S, 2004, IEEE SYMPOSIUM ON VOLUME VISUALIZATION AND GRAPHICS 2004, PROCEEDINGS, P1
   HERLIN I, 1993, P COMP VIS PATT REC, P373
   Hönigmann D, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P489, DOI 10.1109/VISUAL.2003.1250411
   Knittel G., 2000, S VOLUME VISUALIZATI, P71, DOI DOI 10.1145/353888.353901
   Krüger J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P287, DOI 10.1109/VISUAL.2003.1250384
   Kuo J, 2005, ULTRASOUND MED BIOL, V31, P203, DOI 10.1016/j.ultrasmedbio.2004.09.015
   Kuo J, 2007, IEEE T ULTRASON FERR, V54, P313, DOI 10.1109/TUFFC.2007.245
   LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Lim S, 2005, LECT NOTES ARTIF INT, V3801, P827
   Lim S, 2005, IEICE T INF SYST, VE88D, P2864, DOI 10.1093/ietisy/e88-d.12.2864
   Lim S, 2007, IEICE T INF SYST, V90, P117
   Lim S, 2008, VISUAL COMPUT, V24, P229, DOI 10.1007/s00371-007-0203-y
   Lim S, 2006, LECT NOTES COMPUT SC, V4223, P1044
   Malik Muhammad Muddassir, 2007, Proceedings Graphics Interface 2007, P273, DOI 10.1145/1268517.1268562
   Mora B, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P203, DOI 10.1109/VISUAL.2002.1183776
   RASPE M, 2008, P CENTR EUR COMP GRA, P277
   REZK-SALAMA C., 2000, EGSIGGRAPH WORKSHOP, P109, DOI DOI 10.1145/346876.348238
   Rezk-Salama C, 2006, COMPUT GRAPH FORUM, V25, P597, DOI 10.1111/j.1467-8659.2006.00979.x
   ROTTGER S, 2003, P EG IEEE TCVG S VIS, P231
   SADARJOEN A, 1997, SCI VISUALIZATION OV, P311
   SAKAS G, 1995, P SIGGRAPH, P465
   SCHARSACH H, 2005, P CESCG 2005, P69
   Shamdasani V, 2005, PROC SPIE, V5744, P455, DOI 10.1117/12.596641
   SMITH SW, 1991, IEEE T ULTRASON FERR, V38, P100, DOI 10.1109/58.68466
   SUMANAWEERA T, 2004, APPL REAL TIME SHADI, P693
   TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769
   VanGelder A, 1996, 1996 SYMPOSIUM ON VOLUME VISUALIZATION, PROCEEDINGS, P23, DOI 10.1109/SVV.1996.558039
   VONRAMM OT, 1991, IEEE T ULTRASON FERR, V38, P109, DOI 10.1109/58.68467
   Westermann R., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P169, DOI 10.1145/280814.280860
NR 40
TC 8
Z9 8
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2009
VL 20
IS 1
BP 11
EP 23
DI 10.1002/cav.279
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 407WD
UT WOS:000263394100003
DA 2024-07-18
ER

PT J
AU Castellani, U
   Gay-Bellile, V
   Bartoli, A
AF Castellani, Umberto
   Gay-Bellile, Vincent
   Bartoli, Adrien
TI Robust deformation capture from temporal range data for surface
   rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deformable models; 3D registration; Levenberg-Marquardt; bending energy;
   motion capture
ID REGISTRATION; ALGORITHM
AB Imagine an object such as a paper sheet being waved in front of some sensor. Reconstructing the time-varying 3D shape of the object finds direct applications in computer animation. The goal of this paper is to provide such a deformation capture system for surfaces. It uses temporal range data obtained by sensors such as those based on structured light or stereo. So as to deal with many different kinds of material, we do not make the usual assumption that the object surface has textural information. This rules out those techniques based on detecting and matching keypoints or directly minimizing color discrepancy. The proposed method is based on a planar mesh that is deformed so as to fit each of the range images. We show how to achieve this by minimizing a compound cost function combining several data and regularization terms, needed to make the overall system robust so that it can deal with low quality datasets. Carefully examining the parameter to residual relationship shows that this cost function can be minimized very efficiently by coupling nonlinear least squares methods with sparse matrix operators. Experimental results for challenging datasets coming from different kinds of range sensors are reported. The algorithm is reasonably fast and is shown to be robust to missing and erroneous data points. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Castellani, Umberto] Univ Verona, Dept Comp Sci, I-37100 Verona, Italy.
   [Castellani, Umberto; Gay-Bellile, Vincent] LASMEA Lab, Clermont Ferrand, France.
   [Bartoli, Adrien] Univ Oxford, Visual Geometry Grp, Oxford OX1 2JD, England.
C3 University of Verona; University of Oxford
RP Castellani, U (corresponding author), Univ Verona, Dept Comp Sci, I-37100 Verona, Italy.
EM umberto.castellani@univr.it
RI Castellani, Umberto/H-5101-2013
OI Castellani, Umberto/0000-0002-6099-5682
CR Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575
   Blanz Volker., 1999, P 26 ANN C COMPUTER, P187, DOI DOI 10.1145/311535.311556
   BROWN BJ, 2004, P INT S 3D DAT PROC, P822
   Castellani U, 2002, COMPUT VIS IMAGE UND, V87, P78, DOI 10.1006/cviu.2002.0984
   CASTELLANI U, 2007, P INT C 3D DIG IM MO, P1138
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004
   Fornefett M, 2001, IMAGE VISION COMPUT, V19, P87, DOI 10.1016/S0262-8856(00)00057-3
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   GUSKOV I, 2003, P 2003 ACM SIGGRAPH, P251
   Jian B, 2005, IEEE I CONF COMP VIS, P1246
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Koninckx TP, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P293, DOI 10.1109/IM.2003.1240262
   May S, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P790, DOI 10.1109/iros.2006.281670
   MYRONENKO A., 2007, P NEUR INF PROC SYST, P1009
   Pilet J, 2005, PROC CVPR IEEE, P822, DOI 10.1109/CVPR.2005.293
   Pissanetzky S., 1984, Sparse Matrix Technology
   PRASAD M, 2006, P CVPR, P1345
   Pritchard D, 2003, COMPUT GRAPH FORUM, V22, P263, DOI 10.1111/1467-8659.00673
   Rusinkiewicz S, 2002, ACM T GRAPHIC, V21, P438, DOI 10.1145/566570.566600
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   SALZMANN M, 2005, BRIT MACH VIS C 2005, P1138
   SCHOLS V, 2004, VISION MODELLING VIS, P117
   Scholz V, 2005, COMPUT GRAPH FORUM, V24, P439, DOI 10.1111/j.1467-8659.2005.00869.x
   Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558
   Vemuri B C, 1998, Med Image Anal, V2, P79, DOI 10.1016/S1361-8415(98)80004-2
   WANG F, 2006, P IEEE C COMP VIS PA, P1283
   Yamamoto M., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P460, DOI 10.1109/ICCV.1990.139571
NR 28
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2008
VL 19
IS 5
BP 591
EP 603
DI 10.1002/cav.269
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 377KO
UT WOS:000261250300006
DA 2024-07-18
ER

PT J
AU Kawamoto, S
   Yotsukura, T
   Anjyo, K
   Nakamura, S
AF Kawamoto, Shin-ichi
   Yotsukura, Tatsuo
   Anjyo, Ken
   Nakamura, Satoshi
TI Efficient lip-synch tool for 3D cartoon animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE lip-synch tool; cartoon animation; facial animation
AB We propose a set of algorithms to efficiently make speech animation for 3D cartoon characters. Our prototype system is based on blendshapes, a linear interpolation technique, which is Widely used in facial animation practice. In our system, a few base target shapes of the character, prerecorded voice, and its transcription are required as input. We describe a simple technique that amplifies the target shapes from few inputs using a generic database of viseme mouth shapes. We also introduce additional lip-synch editing parameters that allow designers to quickly tune the lip movements. Based on these, we implement our prototype system as a Maya plug-in. The demonstration movies created with this system illustrate well the practicality of our approach. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Kawamoto, Shin-ichi; Nakamura, Satoshi] ATR Spoken Language Commun Res Labs, Seika, Kyoto, Japan.
   [Kawamoto, Shin-ichi] Doshisha Univ, Kyoto 602, Japan.
   [Nakamura, Satoshi] Natl Inst Informat & Commun Technol, MASTAR Project, Yokosuka, Kanagawa, Japan.
   [Nakamura, Satoshi] Univ Karlsruhe, Karlsruhe, Germany.
C3 Doshisha University; National Institute of Information & Communications
   Technology (NICT) - Japan; Helmholtz Association; Karlsruhe Institute of
   Technology
RP Kawamoto, S (corresponding author), ATR Spoken Language Commun Res Labs, 2-2-2 Hikaridai, Seika, Kyoto, Japan.
EM sinichi.kawamoto@atr.jp
CR [Anonymous], CSTR200202 STANF U
   *AUT, AUT MOT 7 5
   BERGLER C, 1997, P 24 ANN C COMP GRAP, P353
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   Deng Z., 2006, P 2006 S INT 3D GRAP, P43, DOI DOI 10.1145/1111411.1111419]
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Fujimoto M, 2006, IEICE T INF SYST, VE89D, P922, DOI 10.1093/ietisy/e89-d.3.922
   ITOH G, 2004, AUT M AC SOC JAP, P221
   LEE MY, 1995, J DIVORCE REMARRIAGE, V22, P55, DOI 10.1300/J087v22n03_04
   LWEIS JP, 2005, P 2005 S INT 3D GRAP, P25
   PIGHIN F, 1998, P SIGGRAPH 98, P75
   PYUN H, 2003, P ACM SIGGRAPH EUR S, P167
   SAKO S, 2000, 6 INT C SPOK LANG PR, V3, P25
   Thomas Frank, 1995, The illusion of life: Disney animation, V1st
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   WATERS K, 1987, P 14 ANN C COMP GRAP, P17
   YOTSUKURA T, 2003, P 11 ACM INT C MULT, P351
NR 18
TC 2
Z9 2
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 247
EP 257
DI 10.1002/cav.250
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200009
DA 2024-07-18
ER

PT J
AU Park, J
   Kim, Y
   Wi, D
   Kang, N
   Shin, SY
   Noh, J
AF Park, Jinho
   Kim, Younghwi
   Wi, Daehyeon
   Kang, Nahyup
   Shin, Sung Yong
   Noh, Junyong
TI A unified handling of immiscible and miscible fluids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE multiple fluids; lattice Boltzmann method; Cahn-Hilliard equation
ID LATTICE-BOLTZMANN SIMULATIONS; FLOWS
AB Conventional level set-based approaches have an inherent difficulty in tracking miscible fluids due to its discrete treatment for interface. This paper proposes a unified framework to efficiently handle both miscible and immiscible fluid simulations. Based on the chemical potential energy, our method describes the evolution of multiple fluids as time-varying concentration fields. Handling of multiple fluids is straightforward and, unlike level set methods, ad hoc reinitialization or fictitious particle deployment is not necessary. For numerical computation of the Navier-Stokes equations, we adopt advanced lattice Boltzmann methods (LBMs) for computational efficiency. The experiments show that our approach works well with immiscible fluids, miscible fluids, and interaction With objects. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Park, Jinho; Wi, Daehyeon] Korea Adv Inst Sci & Technol, Grad Sch Culture & Technol, Visual Media Lab, Taejon 305701, South Korea.
   [Shin, Sung Yong] Korea Adv Inst Sci & Technol, Dept Elect Engn & Comp Sci, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST)
RP Park, J (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture & Technol, Visual Media Lab, 373-1 Guseong Dong, Taejon 305701, South Korea.
EM c2alpha@gmail.com
RI Shin, Sung Yong/C-1955-2011; Noh, Junyong/C-1663-2011
CR Anderson DM, 1998, ANNU REV FLUID MECH, V30, P139, DOI 10.1146/annurev.fluid.30.1.139
   Bargteil AW, 2006, ACM T GRAPHIC, V25, P19, DOI 10.1145/1122501.1122503
   BHATNAGAR PL, 1954, PHYS REV, V94, P511, DOI 10.1103/PhysRev.94.511
   Buick JM, 2000, PHYS REV E, V61, P5307, DOI 10.1103/PhysRevE.61.5307
   CAHN JW, 1958, J CHEM PHYS, V28, P258, DOI 10.1063/1.1744102
   Chikatamarla SS, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.010201
   Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   Cowan C, 2005, THESIS S FRASER U
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Enright D, 2002, J COMPUT PHYS, V183, P83, DOI 10.1006/jcph.2002.7166
   FORSTER IT, 1995, DESIGNING BUILDING P
   FORSTER N, 2001, P SIGGRAPH 01, P23
   Guo ZL, 2002, PHYS REV E, V65, DOI 10.1103/PhysRevE.65.046308
   He XY, 1997, J STAT PHYS, V87, P115, DOI 10.1007/BF02181482
   HONG JM, 2005, P ACM SIGGRAPH 2005, P915
   Irving G, 2006, ACM T GRAPHIC, V25, P805, DOI 10.1145/1141911.1141959
   KIM B, 2007, P SIGGRAPH 07
   Kim J, 2005, J COMPUT PHYS, V204, P784, DOI 10.1016/j.jcp.2004.10.032
   Kim J, 2004, J COMPUT PHYS, V193, P511, DOI 10.1016/j.jcp.2003.07.035
   KIM J, 2002, THESIS U MINNESOTA
   Kim J, 2007, COMPUT METHOD APPL M, V196, P4779, DOI 10.1016/j.cma.2007.06.016
   Ladd AJC, 2001, J STAT PHYS, V104, P1191, DOI 10.1023/A:1010414013942
   Lamura A, 2001, PHYSICA A, V294, P295, DOI 10.1016/S0378-4371(01)00022-X
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   MIHALEF V, 2007, EUROGRAPHICS
   MULLEN P, 2007, P SIGGRAPH 07
   Sethian J., 1999, LEVEL SET METHODS FA
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Succi S., 2001, The Lattice Boltzmann Equation: For Fluid Dynamics and Beyond
   Swift MR, 1996, PHYS REV E, V54, P5041, DOI 10.1103/PhysRevE.54.5041
   TAKADA N, 2005, P FEDS2005 ASME FLUI
   THUREY N, 2007, PARALLEL CFD 2007
   THUREY N, 2004, WORKSH VIS MOD VIS V, P199
   Wei XM, 2004, IEEE T VIS COMPUT GR, V10, P164, DOI 10.1109/TVCG.2004.1260768
   Widom B., 2002, STAT MECH CONCISE IN
   Yin XL, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevE.73.026301
   Zheng HW, 2006, J COMPUT PHYS, V218, P353, DOI 10.1016/j.jcp.2006.02.015
   Zhu HB, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P55
NR 40
TC 22
Z9 25
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 455
EP 467
DI 10.1002/cav.256
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200027
DA 2024-07-18
ER

PT J
AU Carvalho, SR
   Boulic, R
   Thalmann, D
AF Carvalho, Schubert R.
   Boulic, Ronan
   Thalmann, Daniel
TI Interactive low-dimensional human motion synthesis by combining motion
   models and PIK
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE human motion synthesis; motion models; prioritized inverse kinematics
AB This paper explores the issue of interactive low-dimensional human motion synthesis. We compare the performances of two motion models, i.e. Principal Components Analysis (PCA) or Probabilistic PCA (PPCA), for solving a constrained optimization problem within a low-dimensional latent space. We use PCA or PPCA as a first step of preprocessing to reduce the dimensionality of the database to make it tractable, and to encapsulate only the essential aspects of a specific motion pattern. Interactive user control is provided by formulating a low-dimensional optimization framework that uses a Prioritized Inverse Kinematics (PIK) strategy. The key insight of PIK is that the user can adjust a motion by adding constraints with different priorities. We demonstrate the robustness of our approach by synthesizing various styles of golf swing. This movement is challenging in the sense that it is highly coordinated and requires a great precision while moving with high speeds. Hence, any artifact is clearly noticeable in the solution movement. We simultaneously show results comparing local and global motion models regarding synthesis realism and performance. Finally, the quality of the synthesized animations is assessed by comparing our results against a per-frame PIK technique. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Ecole Polytech Fed Lausanne, VRLab, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Carvalho, SR (corresponding author), Ecole Polytech Fed Lausanne, VRLab, EPFL IC ISIM VRLAB Stn 14, CH-1015 Lausanne, Switzerland.
EM schubert.carvalho@epfl.ch
RI Thalmann, Daniel/AAL-1097-2020; Thalmann, Daniel/A-4347-2008; BOULIC,
   RONAN/A-9108-2008
OI Thalmann, Daniel/0000-0002-0451-7491; BOULIC, RONAN/0000-0001-9176-6877
CR [Anonymous], SIGGRAPH 85
   Baerlocher P, 2004, VISUAL COMPUT, V20, P402, DOI 10.1007/s00371-004-0244-4
   Baerlocher P., 2001, Inverse Kinematics Techniques for the Interactive Posture Con- trol of Articulated Figures
   CARVALHO SR, 2007, P 15 WSCG JAN FEB, P97
   Farrally MR, 2003, J SPORT SCI, V21, P753, DOI 10.1080/0264041031000102123
   GEHRIG N, 2003, BRIT MACH VIS C NORW
   Glardon P, 2006, VISUAL COMPUT, V22, P194, DOI 10.1007/s00371-006-0376-9
   Glardon P., 2004, Proceedings of Computer Animation and Social Agent, P73
   Gleicher M., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P139, DOI 10.1145/253284.253321
   Gleicher M, 2001, GRAPH MODELS, V63, P107, DOI 10.1006/gmod.2001.0549
   Grassia F. S., 1998, J. Graph. Tools, V6, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kulpa R, 2005, COMPUT GRAPH FORUM, V24, P343, DOI 10.1111/j.1467-8659.2005.00859.x
   LECALLENNEC B, 2004, GRAPH MODELS, V68, P175
   LEE J, 1999, P ACM SIGGRAPH
   LEE J, 1999, EUROGRAPHICS, V24
   LIU L, 2006, P WSCG JAN, P303
   MACIEJEWSKI AA, 1990, IEEE COMPUT GRAPH, V10, P63, DOI 10.1109/38.55154
   MACIEJEWSKI AA, 1988, J ROBOTIC SYST, V5, P527, DOI 10.1002/rob.4620050603
   RAYMOND AP, 2003, REPORTS PROGRESS PHY, V66, P131
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Shin HJ, 2006, COMPUT ANIMAT VIRT W, V17, P219, DOI 10.1002/cav.125
   Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728
   URTASUN R, 2005, CVPR, V1, P932
   Urtasun R, 2006, COMPUT VIS IMAGE UND, V104, P157, DOI 10.1016/j.cviu.2006.08.006
   WHITNEY DE, 1969, IEEE T MAN MACHINE, VMM10, P47, DOI 10.1109/TMMS.1969.299896
NR 27
TC 13
Z9 19
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 493
EP 503
DI 10.1002/cav.210
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000028
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Oshita, M
AF Oshita, Masaki
TI Real-time hair simulation on GPU with a dynamic wisp model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE hair simulation; GPU; wisp model; geometric deformation
ID ANIMATION
AB In this paper, we present a method for real-time hair animation. We combine a conventional particle-based dynamic simulation and a dynamic hair generation technique. First, the movements of a small number of hairs (coarse model) are simulated using a dynamic simulation. Since this stage uses only a small number of hairs, the simulation is quick. A larger number of hairs (fine model) are then generated from the coarse model using a dynamic wisp model. The shape of a wisp and the shapes of the individual strands are geometrically controlled based on the velocity of the corresponding particle in the coarse model. This model simulates hair-hair interactions between the strands in the hair wisps. Our method is designed to work on a GPU and generates a realistic hair animation in real-time. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Kyushu Inst Technol, Iizuka, Fukuoka, Japan.
C3 Kyushu Institute of Technology
RP Oshita, M (corresponding author), Kyushu Inst Technol, 680-4 Kawazu, Iizuka, Fukuoka, Japan.
EM oshita@ces.kyutech.ac.jp
CR ANJYO K, 1992, COMP GRAPH, V26, P111, DOI 10.1145/142920.134021
   Bando Y, 2003, COMPUT GRAPH FORUM, V22, P411, DOI 10.1111/1467-8659.00688
   Bertails F., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P207
   Bhat K. S., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P37
   Chang JohnnyT., 2002, P 2002 ACM SIGGRAPHE, P73
   Choe BW, 2005, IEEE T VIS COMPUT GR, V11, P160, DOI 10.1109/TVCG.2005.20
   FERNANDO R, 2003, ADDISON WESLEY PROFE
   GUPTA R, 2006, COMPUTER GRAPHICS IN, P702
   Hadap S, 2001, COMPUT GRAPH FORUM, V20, pC329, DOI 10.1111/1467-8659.00525
   Kajiya J. T., 1989, Computer Graphics, V23, P271, DOI 10.1145/74334.74361
   Kim TY, 2002, ACM T GRAPHIC, V21, P620
   Lokovic T, 2000, COMP GRAPH, P385, DOI 10.1145/344779.344958
   Meyer M, 2001, J VISUAL COMP ANIMAT, V12, P1, DOI 10.1002/vis.244
   Nguyen H., 2005, GPU Gems, V2, P361
   *NVIDIA, 2005, GPU CLOTH
   Paris S, 2004, ACM T GRAPHIC, V23, P712, DOI 10.1145/1015706.1015784
   RODRIGUEZNAVARR.J, 2005, EUROGRAPHICS, P85
   Volino P, 2006, IEEE T VIS COMPUT GR, V12, P131, DOI 10.1109/TVCG.2006.36
   Ward K, 2003, COMP ANIM CONF PROC, P41, DOI 10.1109/CASA.2003.1199302
   WATANABE Y, 1992, IEEE COMPUT GRAPH, V12, P47, DOI 10.1109/38.135883
   Yang XD, 2000, GRAPH MODELS, V62, P85, DOI 10.1006/gmod.1999.0518
   Yu YH, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P295, DOI 10.1109/PCCGA.2001.962885
NR 22
TC 3
Z9 6
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 583
EP 593
DI 10.1002/cav.203
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000036
DA 2024-07-18
ER

PT J
AU Xiong, H
   Peng, HY
   Qin, AH
   Shi, JY
AF Xiong, Hua
   Peng, Haoyu
   Qin, Aihong
   Shi, Jiaoying
TI Parallel strategies of occlusion culling on cluster of GPUs
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Virtual Reality Continuum and Its
   Applications (VRCIA)
CY 2006
CL Hong Kong, PEOPLES R CHINA
SP ACM SIGGRAPH, Eurgograph Assoc, Chinese Soc Image & Graph, INI GraphicsNet
DE GPUs cluster; occlusion culling; parallel rendering; cluster rendering;
   tiled display; immersive environments
ID VISIBILITY
AB Parallel rendering, visibility culling and level-of-detail are key techniques to improve the rendering performance for large geometric data sets. Although each of these techniques has been researched extensively and some systems have been developed to combine them together. However, parallel occlusion culling, that is distributing the computation of occlusion culling to multiple computing nodes such as a CPUs cluster or a GPUs cluster, has rarely been touched. This is because most existing occlusion culling algorithms are difficult to parallelize or do not scale well when parallelized. We first introduce a novel occlusion culling algorithm that uses the occlusion query functionality provided by current GPU. We employ a visibility prediction technique based on temporal coherence to reduce the times of occlusion query. Furthermore, different strategies of parallelizing the occlusion culling algorithm on a GPUs cluster are proposed including data parallelism strategies and functionality parallelism strategies. Data parallelism strategies decompose the data sets for occlusion query into disjoint parts and map these queries on different cluster nodes for parallel execution while functionality parallelism strategies assemble an occlusion culling pipeline with multiple cluster nodes which outputs image stream steadily. We propose a number of solutions to some special issues on parallelizing this occlusion culling algorithm, such as the transferring of data dependency and the load-balancing of occlusion culling pipeline. Experimental results demonstrate the efficiency of the proposed parallelism strategies of the occlusion culling algorithm based on the visibility predictor. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Xiong, H (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, 38 Zheda Rd, Hangzhou 310027, Peoples R China.
EM xionghua@cad.zju.edu.cn
CR ABRAHAM F, 2004, SIBGRAPI 04, P292
   AILA T, 2003, SIGGRAPH 03 ACM SIGG, P792
   BAXTER WV, 2002, EGRW 02 P 13 EUR WOR, P203
   Cohen-Or D, 2003, IEEE T VIS COMPUT GR, V9, P412, DOI 10.1109/TVCG.2003.1207447
   Fan Z., 2004, SC 04, P47, DOI [DOI 10.1109/SC.2004.26, 10.1109/SC.2004.26]
   GOVINDARAJU NK, 2002, TR02027 U N CAR
   GREENE N, 1993, SIGGRAPH 93, P231
   HUMPHREYS G, 2002, SIGGRAPH 02 P 29 ANN, P692
   Klosowski JT, 2001, IEEE T VIS COMPUT GR, V7, P365, DOI 10.1109/2945.965350
   MOLNAR S, 1994, IEEE COMPUT GRAPH, V14, P23, DOI 10.1109/38.291528
   NIRENSTEIN S, 2004, P 15 EUR S REND, P207
   RAJAGOPALAN R, 2005, IPDPS 05 P 19 IEEE I, P18
   ZHANG H, 1997, SIGGRAPH 97 C P ANN, P77
NR 13
TC 4
Z9 5
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2007
VL 18
IS 3
BP 165
EP 177
DI 10.1002/cav.170
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 185HG
UT WOS:000247701400003
DA 2024-07-18
ER

PT J
AU Solenthaler, B
   Schlafli, J
   Pajarola, R
AF Solenthaler, Barbara
   Schlafli, Jurg
   Pajarola, Renato
TI A unified particle model for fluid-solid interactions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE physically based simulation; smoothed particle hydrodynamics; fluids;
   solids; melting; solidification
ID ANIMATION
AB We present a new method for the simulation of melting and solidification in a unified particle model. Our technique uses the Smoothed Particle Hydrodynamics (SPH) method for the simulation of liquids, deformable as well as rigid objects, which eliminates the need to define an interface for coupling different models. Using this approach, it is possible to simulate fluids and solids by only changing the attribute values of the underlying particles. We significantly changed a prior elastic particle model to achieve a flexible model for melting and solidification. By using an SPH approach and considering a new definition of a local reference shape, the simulation of merging and splitting of different objects, as may be caused by phase change processes, is made possible. In order to keep the system stable even in regions represented by a sparse set of particles we use a special kernel function for solidification processes. Additionally, we propose a surface reconstruction technique based on considering the movement of the center of mass to reduce rendering errors in concave regions. The results demonstrate new interaction effects concerning the melting and solidification of material, even while being surrounded by liquids. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Univ Zurich, Visualizat & MultiMedi Lab, Dept Informat, CH-8050 Zurich, Switzerland.
   Univ Calif Irvine, Irvine, CA 92717 USA.
C3 University of Zurich; University of California System; University of
   California Irvine
RP Solenthaler, B (corresponding author), Univ Zurich, Visualizat & MultiMedi Lab, Dept Informat, Binzmuhlestr 14, CH-8050 Zurich, Switzerland.
EM solenthaler@ifi.unizh.ch
OI Pajarola, Renato/0000-0002-6724-526X
CR BARAFF D, 1997, INTRO PHYSL BASED MO
   CaniGascuel MP, 1997, IEEE T VIS COMPUT GR, V3, P39, DOI 10.1109/2945.582343
   Carlet C, 2004, PROG COM SC, V23, P3
   Carlson M., 2002, ACM SIGGRAPH/Eurographics Symp. Comp. Anim, P167
   Chentanez N., 2006, ACM SIG- GRAPH/Eurographics Symposium on Computer Animation, P83
   DESBRUN M, 1996, 6 EUR WORKSH COMP AN, P61
   Génevaux O, 2003, PROC GRAPH INTERF, P31
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Goktekin TG, 2004, ACM T GRAPHIC, V23, P463, DOI 10.1145/1015706.1015746
   Guendelman E, 2005, ACM T GRAPHIC, V24, P973, DOI 10.1145/1073204.1073299
   Keiser R., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P125, DOI 10.1109/PBG.2005.194073
   Losasso F, 2006, IEEE T VIS COMPUT GR, V12, P343, DOI 10.1109/TVCG.2006.51
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Muller M., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, P154
   NEALEN A, 2005, EUROGRAPHICS STATE A, P71
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   Pozrikidis C., 1998, NUMERICAL COMPUTATIO
   Premoze S, 2003, COMPUT GRAPH FORUM, V22, P401, DOI 10.1111/1467-8659.00687
   Stam Jos., 1995, Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, SIGGRAPH '95, P129
   Stora D, 1999, PROC GRAPH INTERF, P203
   Terzopoulos D., 1989, Proceedings. Graphics Interface'89, P219
   Tonnesen D., 1991, Proceedings. Graphics Interface '91, P255
   Wald I., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P9, DOI 10.1109/PBG.2005.194058
   WICKE M., 2006, Proceedings of Eurographics Symposium on Point-Based Graphics 2006, P137
   Zhao Y, 2006, COMPUT GRAPH-UK, V30, P519, DOI 10.1016/j.cag.2006.03.009
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 30
TC 152
Z9 193
U1 2
U2 24
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2007
VL 18
IS 1
BP 69
EP 82
DI 10.1002/cav.162
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 149ML
UT WOS:000245150900007
DA 2024-07-18
ER

PT J
AU Papagiannakis, G
   Schertenleib, S
   O'Kennedy, B
   Arevalo-Poizat, M
   Magnenat-Thalmann, N
   Stoddart, A
   Thalmann, D
AF Papagiannakis, G
   Schertenleib, S
   O'Kennedy, B
   Arevalo-Poizat, M
   Magnenat-Thalmann, N
   Stoddart, A
   Thalmann, D
TI Mixing virtual and real scenes in the site of ancient Pompeii
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE virtual humans; augmented-mixed reality; computer animation;
   component-based framework; real-time camera tracking; virtual
   storytelling
AB This paper presents an innovative 3D reconstruction of ancient fresco paintings through the real-time revival of their fauna and flora, featuring groups of virtual animated characters with artificial-life dramaturgical behaviours in an immersive, fully mobile augmented reality (AR) environment. The main goal is to push the limits of current AR and virtual storytelling technologies and to explore the processes of mixed narrative design of fictional spaces (e.g. fresco paintings) where visitors can experience a high degree of realistic immersion. Based on a captured/real-time video sequence of the real scene in a video-see-through HMD set-up, these scenes are enhanced by the seamless accurate real-time registration and 3D rendering of realistic complete simulations of virtual flora and fauna (virtual humans and plants) in a real-time storytelling scenario-based environment. Thus the visitor of the ancient site is presented with an immersive and innovative multi-sensory interactive trip to the past. Copyright (c) 2005 John Wiley T Sons, Ltd.
C1 Univ Geneva, CUI, MIRALab, CH-1211 Geneva, Switzerland.
C3 University of Geneva
RP Papagiannakis, G (corresponding author), Univ Geneva, CUI, MIRALab, 24 Rue Gen Dufour, CH-1211 Geneva, Switzerland.
EM george.papagiannakis@miralab.unige.ch
RI Thalmann, Daniel/AAL-1097-2020; Thalmann, Daniel/A-4347-2008;
   papagiannakis, george/AAI-7973-2020; Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Daniel/0000-0002-0451-7491; papagiannakis,
   george/0000-0002-2977-9850; Thalmann, Nadia/0000-0002-1459-5960
CR ARNOLD D, 2003, CHARISMATIC PROJECT
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   CORDIER F, 2002, EUROGRAPHICS C P BLA
   FEINER S, 2002, SCI AM, P36
   Gamma Erich., 1994, DESIGN PATTERNS
   Kshirsagar S, 2001, INT FED INFO PROC, V68, P24
   KSHIRSAGAR S, 2003, P EUROGRAPHICS
   Lee W.S. L. W. S., 2000, Proceedings DCC 2000. Data Compression Conference, P1
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   NANDI A, 2000, P VIRT REAL INT C LA
   Papagiannakis G., 2002, LIFEPLUS REVIVAL LIF
   Ponder M., 2003, Proceedings of Computer Graphics International (CGI)
   Sannier G, 1999, VISUAL COMPUT, V15, P320, DOI 10.1007/s003710050181
   Schwald B, 2001, STARMATE USING AUGME
   STRICKER D., 2001, EUROIMAGE ICAV 3D C
   Thomas B, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P139, DOI 10.1109/ISWC.2000.888480
   VOLINO P, 2001, P CGI 01 HONG KONG
   WOHLGEMUTH W, 2000, P DARE 2000 DES AUG
NR 18
TC 75
Z9 83
U1 2
U2 31
PU WILEY-BLACKWELL
PI MALDEN
PA COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2005
VL 16
IS 1
BP 11
EP 24
DI 10.1002/cav.53
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 912IF
UT WOS:000228070300003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cerezo, E
   Seron, FJ
AF Cerezo, E
   Seron, FJ
TI Rendering natural waters taking fluorescence into account
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fluorescence; inelastic phenomena; participating media; discrete
   ordinates; global illumination
ID GLOBAL ILLUMINATION
AB The aim of the work presented here is to generalize a system, developed to treat general participating media, to make it capable of considering volumetric inelastic processes such as fluorescence. Our system, based on the discrete ordinates method, is adequate to treat a complex participating medium such as natural waters as it is prepared to deal with not only anisotropic but also highly peaked phase functions, as well as to consider the spectral behaviour of the medium's characteristic parameters. It is also able to generate detailed quantitative illumination information, such as the amount of light that reaches the medium boundaries or the amount of light absorbed in each of the medium voxels. First, we present an extended form of the radiative transfer equation to incorporate inelastic volumetric phenomena. Dien, we discuss the necessary changes in the general calculation scheme to include inelastic scattering. We have applied all this to consider the most common inelastic effect in natural waters: fluorescence in chlorophyll-a. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Zaragoza, GIGA, Dept Informat Ingn Sistemas, E-50018 Zaragoza, Spain.
   Univ Zaragoza, Tech Sch Engn, E-50018 Zaragoza, Spain.
C3 University of Zaragoza; University of Zaragoza
RP Univ Zaragoza, GIGA, Dept Informat Ingn Sistemas, Campus Politecn Actur,Edifico Ada Byron C Maria L, E-50018 Zaragoza, Spain.
EM ecerezo@unizar.es
RI Cerezo, Eva/L-6095-2014; Seron Arbeloa, Francisco Jose/L-3146-2014
OI Cerezo, Eva/0000-0003-4424-0770; Seron Arbeloa, Francisco
   Jose/0000-0003-1683-4694
CR Amanatides J., 1987, EUROGRAPHICS, V87, P3, DOI DOI 10.2312/EGTP.19871000
   Bhate N., 1992, Proceedings of the Third Eurographics Workshop on Rendering, P227
   BHATE N, 1993, P ATARV 93 ADV TECHN, P43
   Blasi P., 1993, Computer Graphics Forum, V12, pC201, DOI 10.1111/1467-8659.1230201
   Cerezo E, 2004, PROC SPIE, V5233, P281, DOI 10.1117/12.517198
   Cerezo E, 2001, W S C G ' 2001, VOLS I & II, CONFERENCE PROCEEDINGS, P395
   DEVLIN K, 2002, STATE ART REPORT EUR
   Glassner A. S., 1995, Photorealistic Rendering Techniques, P60
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Languenou E., 1995, Photorealistic Rendering Techniques, P71
   Lindholm E, 2001, COMP GRAPH, P149, DOI 10.1145/383259.383274
   Max N., 1995, Photorealistic Rendering Techniques, P87
   Mobley C., 1994, LIGHT WATER RAD TRAN
   PATMORE C, 1993, P INT C COMP GRAPH I, P29
   PATTANAIK SN, 1993, J VISUAL COMP ANIMAT, V4, P133, DOI 10.1002/vis.4340040303
   Peercy MS, 2000, COMP GRAPH, P425, DOI 10.1145/344779.344976
   PEREZ F, 1997, P 8 EUR WORKSH REND, P309
   Proudfoot K, 2001, COMP GRAPH, P159, DOI 10.1145/383259.383275
   Rushmeier H.E., 1987, P SIGGRAPH, P293, DOI 10.1145/37402.37436
   SIEGEL H, 1992, THERMAL RADIATION HE
   SILLION FX, 1995, IEEE T VIS COMPUT GR, V1, P240, DOI 10.1109/2945.466719
   Spinrad RichardW., 1994, Ocean optics
   Wilkie Alexander., 2001, Proceedings of the 12th Eurographics Workshop on Rendering Techniques, P197
NR 23
TC 4
Z9 4
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2004
VL 15
IS 5
BP 471
EP 484
DI 10.1002/cav.10
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 880TP
UT WOS:000225812600002
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Yan, FP
   Ji, X
   Wang, B
   Feng, DZ
AF Zhang, Ye
   Yan, Fangpeng
   Ji, Xiang
   Wang, Bo
   Feng, Dingzhong
TI A study on finger vein recognition with few samples based on residual
   connected meta-learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE finger vein recognition; meta-learning; residual structure; singular
   value decomposition
ID SYSTEM; EXTRACTION
AB A meta-learning based method for finger vein recognition with few samples is proposed to overcome the problem of low recognition accuracy caused by the small number and variety of finger vein samples as well as fuzzy vein lines. The method is based on meta-learning, incorporating multiscale features, and using the idea of residual networks to join meta-learning to improve the recognition accuracy of finger vein images with few samples; to further improve its recognition ability, a differential map is constructed in the form of a differential between the finger vein image of singular value decomposition and finger vein image. We are the first to apply meta-learning to the field of finger vein recognition, to our knowledge, and the experiments show that this approach is superior, with recognition accuracy of up to 99.13% for finger vein datasets with few-shot samples.
C1 [Zhang, Ye; Yan, Fangpeng; Ji, Xiang; Wang, Bo; Feng, Dingzhong] Zhejiang Univ Technol, Coll Mech Engn, Hangzhou, Peoples R China.
   [Feng, Dingzhong] Zhejiang Univ Technol, Coll Mech Engn, 228 Liuhe Rd, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang University of Technology
RP Feng, DZ (corresponding author), Zhejiang Univ Technol, Coll Mech Engn, 228 Liuhe Rd, Hangzhou, Zhejiang, Peoples R China.
EM 2112002037@zjut.edu.cn
RI Liu, Yuxuan/JVO-7759-2024; Zhang, Zixuan/JSL-3603-2023; feng,
   dingzhong/G-8051-2012; Wang, YUJIE/JXY-8442-2024; LIU,
   YUTING/JUV-1285-2023
OI Yan, Fangpeng/0000-0003-2324-7420
CR Ahmad Radzi S, 2016, TURK J ELECTR ENG CO, V24, P1863, DOI 10.3906/elk-1311-43
   [Anonymous], SDUMLA HMTFINGER VEI
   Banerjee A, 2018, MULTIMED TOOLS APPL, V77, P5857, DOI 10.1007/s11042-017-4501-8
   Das R, 2019, IEEE T INF FOREN SEC, V14, P360, DOI 10.1109/TIFS.2018.2850320
   Fairuz S, 2018, PROCEEDINGS OF THE 2018 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING (ICCCE), P453, DOI 10.1109/ICCCE.2018.8539342
   Finn C, 2017, PR MACH LEARN RES, V70
   Van HT, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), P348, DOI 10.1109/KSE.2015.12
   Hong HG, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061297
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang H., 2017, P IEEE INT C IDENTIT, V8
   Jialiang Peng, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P45, DOI 10.1109/IIH-MSP.2012.17
   Kim W, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072296
   Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   Miura N, 2007, IEICE T INF SYST, VE90D, P1185, DOI 10.1093/ietisy/e90-d.8.1185
   Peng BL, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P172
   Qin HF, 2018, IEEE T CIRC SYST VID, V28, P1677, DOI 10.1109/TCSVT.2017.2684826
   Qiu SR, 2016, EXPERT SYST APPL, V64, P618, DOI 10.1016/j.eswa.2016.08.031
   Rosdi BA, 2011, SENSORS-BASEL, V11, P11357, DOI 10.3390/s111211357
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snell J, 2017, ADV NEUR IN, V30
   Song JM, 2019, IEEE ACCESS, V7, P66845, DOI 10.1109/ACCESS.2019.2918503
   Pham TD, 2015, SENSORS-BASEL, V15, P16866, DOI 10.3390/s150716866
   Veluchamy S, 2017, IET BIOMETRICS, V6, P232, DOI 10.1049/iet-bmt.2016.0112
   Vinyals O., P 30 INT C NEURAL IN, P3630
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wu JD, 2011, EXPERT SYST APPL, V38, P14284, DOI 10.1016/j.eswa.2011.05.086
   Xie SJ, 2014, COGN COMPUT, V6, P446, DOI 10.1007/s12559-014-9254-3
   Yang JF, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P500, DOI 10.1109/ICICISYS.2009.5357631
   Yang JC, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040096
   Yang L, 2018, IEEE T CIRC SYST VID, V28, P1892, DOI 10.1109/TCSVT.2017.2684833
   Yang L, 2017, IEEE ACCESS, V5, P21020, DOI 10.1109/ACCESS.2017.2728797
NR 32
TC 0
Z9 0
U1 3
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2130
EA DEC 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000898354600001
DA 2024-07-18
ER

PT J
AU Almushyti, M
   Li, FWB
AF Almushyti, Muna
   Li, Frederick W. B.
TI Distillation of human-object interaction contexts for action recognition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE global context; graph attention network local context; human-object
   interaction
AB Modeling spatial-temporal relations is imperative for recognizing human actions, especially when a human is interacting with objects, while multiple objects appear around the human differently over time. Most existing action recognition models focus on learning overall visual cues of a scene but disregard a holistic view of human-object relationships and interactions, that is, how a human interacts with respect to short-term task for completion and long-term goal. We therefore argue to improve human action recognition by exploiting both the local and global contexts of human-object interactions (HOIs). In this paper, we propose the Global-Local Interaction Distillation Network (GLIDN), learning human and object interactions through space and time via knowledge distillation for holistic HOI understanding. GLIDN encodes humans and objects into graph nodes and learns local and global relations via graph attention network. The local context graphs learn the relation between humans and objects at a frame level by capturing their co-occurrence at a specific time step. The global relation graph is constructed based on the video-level of human and object interactions, identifying their long-term relations throughout a video sequence. We also investigate how knowledge from these graphs can be distilled to their counterparts for improving HOI recognition. Finally, we evaluate our model by conducting comprehensive experiments on two datasets including Charades and CAD-120. Our method outperforms the baselines and counterpart approaches.
C1 [Almushyti, Muna; Li, Frederick W. B.] Univ Durham, Dept Comp Sci, South Rd, Durham DH1 3LE, England.
   [Almushyti, Muna] Qassim Univ, Deanship Educ Serv, Buraydah, Saudi Arabia.
C3 Durham University; Qassim University
RP Almushyti, M (corresponding author), Univ Durham, Dept Comp Sci, South Rd, Durham DH1 3LE, England.
EM muna.i.almushyti@durham.ac.uk
OI Li, Frederick W. B./0000-0002-4283-4228; Almushyti,
   Muna/0000-0002-7828-7553
FU N8 Research Partnership; EPSRC [EP/T022167/1]; Unversity of Durham;
   Unversity of Manchester; Unversity of York
FX N8 Research Partnership and EPSRC, Grant/Award Number: EP/T022167/1;
   Unversities of Durham, Manchester and York
CR Arnab A., 2021, arXiv, DOI DOI 10.48550/ARXIV.2103.15691
   Bansal A, 2020, Arxiv, DOI arXiv:1904.03181
   Baradel F, 2018, LECT NOTES COMPUT SC, V11217, P106, DOI 10.1007/978-3-030-01261-8_7
   Bian CL, 2021, IEEE T IMAGE PROCESS, V30, P2963, DOI 10.1109/TIP.2021.3056895
   Bingjie Xu, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P2019, DOI 10.1109/CVPR.2019.00212
   Boxiao Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10867, DOI 10.1109/CVPR42600.2020.01088
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Cheng K., DECOUPLING GCN DROPG
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Crasto N, 2019, PROC CVPR IEEE, P7874, DOI 10.1109/CVPR.2019.00807
   Dai R., 2021, P IEEECVF INT C COMP
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan H., 2020, Pyslowfast
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Garcia NC, 2021, IEEE WINT CONF APPL, P2754, DOI 10.1109/WACV48630.2021.00280
   Ghosh P, 2020, IEEE WINT CONF APPL, P565, DOI 10.1109/WACV45572.2020.9093361
   Girdhar R, 2019, IEEE I CONF COMP VIS, P852, DOI 10.1109/ICCV.2019.00094
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Guo JY, 2021, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR46437.2021.00219
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herzig R, 2019, IEEE INT CONF COMP V, P2347, DOI 10.1109/ICCVW.2019.00288
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Huang D, 2020, AAAI CONF ARTIF INTE, V34, P11021
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Kingma D. P., 2014, arXiv
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Li F, 2017, Arxiv, DOI arXiv:1707.04555
   Liu YC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P700, DOI 10.1145/3240508.3240567
   Liu Z., 2021, P INT C LEARN REPR I
   Liu Z., 2020, IEEE ACCESS, V8
   Lopez-Paz D, 2016, Arxiv, DOI [arXiv:1511.03643, DOI 10.48550/ARXIV.1511.03643]
   Lu LH, 2020, IEEE T MULTIMEDIA, V22, P524, DOI 10.1109/TMM.2019.2930344
   Luo ZL, 2018, LECT NOTES COMPUT SC, V11218, P174, DOI 10.1007/978-3-030-01264-9_11
   Materzynska J, 2020, PROC CVPR IEEE, P1046, DOI 10.1109/CVPR42600.2020.00113
   Neimark D., 2021, Video transformer network
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sanou I., 2019, EXTENSIBLE DEEP ARCH
   Shah A., 2020, arXiv
   Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7
   Sigurdsson GA, 2017, PROC CVPR IEEE, P5650, DOI 10.1109/CVPR.2017.599
   Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31
   Simonyan K, 2014, ADV NEUR IN, V27
   Sun C, 2018, LECT NOTES COMPUT SC, V11215, P335, DOI 10.1007/978-3-030-01252-6_20
   Sunkesula SPR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P691, DOI 10.1145/3394171.3413778
   Tan H., 2019, BMVC
   Tayyub J., 2014, Asian Conference on Computer Vision, P115
   Thoker FM, 2019, IEEE IMAGE PROC, P6, DOI [10.1109/icip.2019.8802909, 10.1109/ICIP.2019.8802909]
   Tomei M, 2021, COMPUT VIS IMAGE UND, V206, DOI 10.1016/j.cviu.2021.103187
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tu ZG, 2019, IEEE T IMAGE PROCESS, V28, P2799, DOI 10.1109/TIP.2018.2890749
   Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Vongkulbhisal J, 2019, PROC CVPR IEEE, P3170, DOI 10.1109/CVPR.2019.00329
   Wang KZ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P97, DOI 10.1145/2647868.2654912
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Wu CY, 2019, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2019.00037
   Xu BJ, 2020, IEEE T MULTIMEDIA, V22, P1423, DOI 10.1109/TMM.2019.2943753
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang JR, 2020, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR42600.2020.00335
   Yang Z., 2020, P IEEECVF C COMPUTER, P4643
   Yukang Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P346, DOI 10.1007/978-3-030-58571-6_21
   Zhang L., 2020, P INT C LEARNING REP
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhang ZB, 2022, Arxiv, DOI [arXiv:2205.03650, 10.48550/ARXIV.2205.03650]
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
NR 76
TC 0
Z9 0
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2022
VL 33
IS 5
AR e2107
DI 10.1002/cav.2107
EA AUG 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5E9FV
UT WOS:000838103500001
OA Green Accepted, Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Pan, ZX
   Wu, FY
   Zhang, BL
AF Pan, Zhengxin
   Wu, Fangyu
   Zhang, Bailing
TI Kernel triplet loss for image-text retrieval
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deep metric learning; image-text retrieval; kernel triplet loss;
   weighting scheme
AB Triplet loss is widely used as the objective function in image-text retrieval tasks. However, as all the triplets are treated equally, triplet loss has a bottleneck problem of slow convergence and other unsatisfactory performances. In this article, we propose solutions by appropriately weighting triplets according to the relative similarities among the training samples. Specifically, we present three weighting functions to assign an appropriate weight for the selected informative triplets to accelerate the convergence. We evaluate our approach on two widely used benchmark datasets: Flickr30k and MSCOCO, with results outperforming the previous methods, which demonstrates its superiority.
C1 [Pan, Zhengxin; Wu, Fangyu; Zhang, Bailing] NingboTech Univ, Sch Comp & Data Engn, Ningbo, Peoples R China.
   [Pan, Zhengxin; Wu, Fangyu] Zhejiang Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
C3 NingboTech University; Zhejiang University
RP Wu, FY (corresponding author), NingboTech Univ, Sch Comp & Data Engn, Ningbo, Peoples R China.
EM fangyu.wu@zju.edu.cn
OI wu, fangyu/0000-0001-9618-8965
FU Ningbo 2025 Key Scientific Research Programs [2019B10128]; Zhejiang
   Provincial Philosophy and Social Sciences Planning Project [22JCXK08Z]
FX Ningbo 2025 Key Scientific Research Programs, Grant/Award Number:
   2019B10128; Zhejiang Provincial Philosophy and Social Sciences Planning
   Project, Grant/Award Number: 22JCXK08Z
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Chen FY, 2021, IEEE T MULTIMEDIA, V23, P3073, DOI 10.1109/TMM.2020.3019710
   Chen T., 2020, ADAPTIVE OFFLINE QUI, P549
   Diao H., 2021, AAAI
   Faghri F., VSE IMPROVING VISUAL
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2014, arXiv
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Liu C., 2020, P IEEE CVF C COMP VI, P10921, DOI DOI 10.1109/CVPR42600.2020.01093
   Niu YL, 2021, PROC CVPR IEEE, P12695, DOI 10.1109/CVPR46437.2021.01251
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Radford A, 2021, PR MACH LEARN RES, V139
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang X, 2019, PROC CVPR IEEE, P5017, DOI 10.1109/CVPR.2019.00516
   Wei JW, 2022, IEEE T PATTERN ANAL, V44, P6534, DOI 10.1109/TPAMI.2021.3088863
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Zhang Q, 2020, PROC CVPR IEEE, P3533, DOI 10.1109/CVPR42600.2020.00359
   Zheng H, 2015, IEEE IJCNN
NR 23
TC 0
Z9 0
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2093
DI 10.1002/cav.2093
EA JUN 2022
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000810296100001
DA 2024-07-18
ER

PT J
AU Zhang, HY
   Zhang, MM
   Pan, ZG
   Cao, ML
   Li, YH
   Zhong, Y
   Chen, GL
   Liu, X
AF Zhang, Haoyang
   Zhang, Mingmin
   Pan, Zhigeng
   Cao, Mingliang
   Li, Yongheng
   Zhong, Yong
   Chen, Ganglin
   Liu, Xin
TI GiantScope: A simulation microscopy for middle school biological
   experiment education
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE embedded technology; human-computer interaction; middle school biology
   education; virtual microscope
ID VIRTUAL MICROSCOPY
AB We present a simulation microscope device called GiantScope, which combines virtual microscope, cloud computing, and embedded technologies. Users can complete most of the microscope-based experiments in biology courses by operating our device, while learning the operating skills of microscopes at the same time. Our device supports most of the operation functions of optical microscopes, including quasifocus screw adjustment, slide movement recognition and so on, and also has auxiliary enhancement functions including manual measurement, annotation and so on. In addition, we have built a cloud-based digital slide database, which enables users to select experimental observations through digital slides, including static cell specimens or dynamic cell activities. After user study, we found that using GiantScope for biological experiments has better learning efficiency and user experience than traditional microscopes.
C1 [Zhang, Haoyang; Li, Yongheng; Zhong, Yong; Chen, Ganglin; Liu, Xin] Foshan Univ, Foshan, Peoples R China.
   [Zhang, Mingmin] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Pan, Zhigeng] Nanjing Univ Informat Sci & Technol, Virtual Real & Intelligent Syst Res Inst, Nanjing, Peoples R China.
   [Cao, Mingliang] Guangdong Polytech Ind & Commerce, Sch Comp & Informat Engn, Guangzhou, Peoples R China.
C3 Foshan University; Zhejiang University; Nanjing University of
   Information Science & Technology
RP Zhang, MM (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
EM zhangmm95@zju.edu.cn
RI Li, Jiaai/JCO-0168-2023; zhang, mm/IWV-4201-2023; Zhang,
   Miao/JXY-8985-2024; Han, Yang/JVN-5921-2024; Chen, Fang/JZE-4446-2024;
   Cao, Mingliang/J-7335-2012
OI Haoyang, Zhang/0000-0002-8036-4917
FU National Natural Science Foundation of China [62077041]; Key Science and
   Technology Innovation Project of Hangzhou [20182014B02]
FX National Natural Science Foundation of China, Grant/Award Number:
   62077041; Key Science and Technology Innovation Project of Hangzhou,
   Grant/Award Number: 20182014B02
CR Afework A, 1998, J AM MED INFORM ASSN, P912
   Al Qassem LMMS, 2016, IEEE GLOB ENG EDUC C, P842, DOI 10.1109/EDUCON.2016.7474650
   Cai S, 2014, COMPUT HUM BEHAV, V37, P31, DOI 10.1016/j.chb.2014.04.018
   Chandler-Grevatt, 2021, SCH SCI REV, V102, P49
   Chen J, 2018, ISPRS ANN PHOTO REM, V4-4, P27, DOI 10.5194/isprs-annals-IV-4-W7-27-2018
   Chen LS, 2015, 2015 8TH INTERNATIONAL CONFERENCE ON UBI-MEDIA COMPUTING (UMEDIA) CONFERENCE PROCEEDINGS, P355, DOI 10.1109/UMEDIA.2015.7297485
   Chou PN, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13073663
   Fadzil HM., 2020, J PENDIDIKAN IPA IND, V9, P117
   Fall JF., 2004, HAMMING CODES
   Herodotou C, 2020, INTERACT LEARN ENVIR, V28, P713, DOI 10.1080/10494820.2018.1552874
   Husmann PR, 2019, ANAT SCI EDUC, V12, P6, DOI 10.1002/ase.1777
   imer A., 2012, EDUC RES REV-NETH, V7, P61, DOI [DOI 10.5897/ERR11.205, 10.5897/ERR11.205]
   Jin Q, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P611, DOI 10.1145/3202185.3210784
   Lee LMJ, 2018, ANAT SCI EDUC, V11, P510, DOI 10.1002/ase.1774
   Musawi BAK., 2021, P 2021 PALESTINIAN I
   Ntemngwa C, 2018, INT J EDUC MATH SCI, V6, P12, DOI 10.18404/ijemst.380617
   Rhodes JA., 2020, FASEB J, V34, P1
   Sadeh I, 2012, RES SCI EDUC, V42, P831, DOI 10.1007/s11165-011-9222-9
   Samal N, 2019, INDIAN J PATHOL MICR, V62, P84, DOI 10.4103/IJPM.IJPM_241_18
   dos Santos FS, 2021, ANAT SCI EDUC, V14, P408, DOI 10.1002/ase.2072
   Songfei Fang, 2020, 2020 International Conference on Virtual Reality and Visualization (ICVRV), P346, DOI 10.1109/ICVRV51359.2020.00095
   Taraban R, 2007, J RES SCI TEACH, V44, P960, DOI 10.1002/tea.20183
   Vasiliadou R, 2020, BIOCHEM MOL BIOL EDU, V48, P482, DOI 10.1002/bmb.21407
   Wozniak Mikolaj P., 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3381441
   Xia SH, 2020, INT CONF ACOUST SPEE, P5175, DOI [10.1109/ICASSP40776.2020.9054415, 10.1109/icassp40776.2020.9054415]
   Zhou X., 2020, Virtual Reality Intelligent Hardware, V2, P316, DOI [10.1016/j.vrih.2020.07.004, DOI 10.1016/J.VRIH.2020.07.004]
NR 26
TC 0
Z9 0
U1 2
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2083
DI 10.1002/cav.2083
EA JUN 2022
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000810265600001
DA 2024-07-18
ER

EF