FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Liu, HJ
   Yao, C
   Zhang, YL
   Ban, XJ
AF Liu, Hongjun
   Yao, Chao
   Zhang, Yalan
   Ban, Xiaojuan
TI GestureTeach: A gesture guided online teaching interactive model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation generation; gesture recognition; online education
ID CHINA
AB Online education has become more popular and effective due to the availability of high-speed internet and technological innovations, which allow people from different locations to access educational resources and opportunities. However, online classes often face challenges such as limited interactivity and display options, which can affect the quality and effectiveness of the online learning experience. In this article, we propose GestureTeach, a new pedagogical paradigm that enables free handwriting interaction and animation generation for online teaching. GestureTeach uses gestures as a natural and intuitive way of interaction, which enhances the teacher's intention expression and the student's engagement. GestureTeach also generates animations from handwritten sketches, which improves the display effects of the interaction and the student's knowledge comprehension. We conducted a two-stage study with 15 teachers and 90 students to evaluate the effectiveness of GestureTeach in facilitating classroom interaction. The results show that GestureTeach is preferred by both teachers and students over traditional online teaching methods and has the potential to transform the online teaching landscape by providing a seamless and interactive experience.
   We propose GestureTeach, a new pedagogical paradigm that enables free handwriting interaction and animation generation for online teaching. GestureTeach uses gestures as a natural and intuitive way of interaction, which enhances the teacher's intention expression and the student's engagement. GestureTeach also generates animations from handwritten sketches, which improves the display effects of the interaction and the student's knowledge comprehension.image
C1 [Liu, Hongjun; Yao, Chao; Zhang, Yalan; Ban, Xiaojuan] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing Adv Innovat Ctr Mat Genome Engn,Minist Edu, Inst Artificial Intelligence,Sch Intelligence Sci, Beijing, Peoples R China.
   [Ban, Xiaojuan] Liaoning Acad Mat, Inst Mat Intelligent Technol, Shenyang, Peoples R China.
   [Yao, Chao; Ban, Xiaojuan] Univ Sci & Technol Beijing, Inst Artificial Intelligence, Beijing Adv Innovat Ctr Mat Genome Engn,Minist Edu, Sch Comp & Commun Engn,Sch Intelligence Sci & Tech, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing; Liaoning Academy Materials;
   University of Science & Technology Beijing
RP Yao, C; Ban, XJ (corresponding author), Univ Sci & Technol Beijing, Inst Artificial Intelligence, Beijing Adv Innovat Ctr Mat Genome Engn,Minist Edu, Sch Comp & Commun Engn,Sch Intelligence Sci & Tech, Beijing 100083, Peoples R China.
EM yaochao@ustb.edu.cn; banxj@ustb.edu.cn
OI zhang, ya lan/0000-0002-8736-7125
FU National Key Research and Development Program of China [2022ZD0118001];
   National Natural Science Foundation of China [61972028, 62332017,
   U22A2022]; Guangdong Basic and Applied Basic Research Foundation
FX National Key Research and Development Program of China, Grant/Award
   Number: 2022ZD0118001; National Natural Science Foundation of China,
   Grant/Award Numbers: 61972028, 62332017, U22A2022; Guangdong Basic and
   Applied Basic Research Foundation
CR Blackler A., 2005, NEW DES PAR P INT DE, P1
   Bluche T, 2017, PROC INT CONF DOC, P646, DOI 10.1109/ICDAR.2017.111
   Bradski G, 2000, DR DOBBS J, V25, P120
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Gong H., 2019, ARXIV
   He J., 2020, arXiv
   Ho J, 2022, J MACH LEARN RES, V23, P1
   Huang J, 2020, J CHEM EDUC, V97, P2810, DOI 10.1021/acs.jchemed.0c00671
   HuANG Y., 2020, Lecture Notes in Computer Science, V12351, P156, DOI 10.1007/
   Iqbal U, 2018, LECT NOTES COMPUT SC, V11215, P125, DOI 10.1007/978-3-030-01252-6_8
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jin HY, 2021, ASIAN J SURG, V44, P672, DOI 10.1016/j.asjsur.2021.01.034
   Kim U-H., 2022, IEEE T ARTIF INTELL, P1
   Kizilirmak F., CNN BILSTM MODEL ENG
   Krishnan P, 2023, IEEE T PATTERN ANAL, V45, P9122, DOI 10.1109/TPAMI.2023.3239736
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Lee SK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1267, DOI 10.1145/3474085.3475694
   Liu MQ, 2023, IEEE T CIRC SYST VID, V33, P1507, DOI 10.1109/TCSVT.2022.3214538
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Ruiz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P197
   Shuyang Luo, 2021, 2021 Nicograph International (NicoInt), P7, DOI 10.1109/NICOINT52941.2021.00009
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Wu WB, 2017, IEEE INT CONF COMP V, P623, DOI 10.1109/ICCVW.2017.79
   Xia ZH, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/4387337
   Xiao S., 2020, SN COMPUT SCI, V1, P1, DOI DOI 10.1007/S42979-020-00133-Y
   Xing Yingxin, 2016, 2016 6th International Conference on Digital Home (ICDH), P64, DOI 10.1109/ICDH.2016.023
   Yan CM, 2022, SYSTEM, V105, DOI 10.1016/j.system.2021.102717
   Yao C, 2019, IEEE T BROADCAST, V65, P521, DOI 10.1109/TBC.2018.2871370
   Zhang F., 2020, ARXIV
   Zhang L., 2023, ARXIV
NR 32
TC 1
Z9 1
U1 3
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2218
EA SEP 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001066692200001
DA 2024-07-18
ER

PT J
AU Liu, Y
   Huang, EQ
   Zhou, ZY
   Wang, KX
   Liu, S
AF Liu, Yu
   Huang, Enquan
   Zhou, Ziyu
   Wang, Kexuan
   Liu, Shu
TI 3D facial attractiveness prediction based on deep feature fusion
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE facial attractiveness prediction; 3D face; deep feature learning;
   feature fusion; cyclical learning rate
ID NETWORK
AB Facial attractiveness prediction is an important research topic in the computer vision community. It not only contributes to the development of interdisciplinary research in psychology and sociology, but also provides fundamental technical support for applications like aesthetic medicine and social media. With the advances in 3D data acquisition and feature representation, this paper aims to investigate the facial attractiveness from deep learning and three-dimensional perspectives. The 3D faces are first processed to unwrap the texture images and refine the raw meshes. The feature extraction networks for texture, point cloud, and mesh are then delicately designed, considering the characteristics of different types of data. A more discriminative face representation is derived by feature fusion for the final attractiveness prediction. During network training, the cyclical learning rate with an improved range test is introduced, so as to alleviate the difficulty in hyperparameter setting. Extensive experiments are conducted on a 3D FAP benchmark, where the results demonstrate the significance of deep feature fusion and enhanced learning rate in cooperatively facilitating the performance. Specifically, the fusion of texture image and point cloud achieves the best overall prediction, with PC, MAE, and RMSE of 0.7908, 0.4153, and 0.5231, respectively.
C1 [Liu, Yu] Natl Univ Def Technol, Coll Syst Engn, Changsha, Peoples R China.
   [Huang, Enquan; Zhou, Ziyu; Wang, Kexuan; Liu, Shu] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
   [Huang, Enquan; Zhou, Ziyu; Wang, Kexuan; Liu, Shu] Hunan Engn Res Ctr Machine Vis & Intelligent Med, Changsha, Peoples R China.
   [Liu, Shu] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
C3 National University of Defense Technology - China; Central South
   University; Central South University
RP Liu, S (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
EM sliu35@csu.edu.cn
FU National Natural Science Foundation of China [62171451]; Hunan
   Provincial Natural Science Foundation of China [2023JJ30700];
   Fundamental Research Funds for the Central Universities of Central South
   University; High Performance Computing Center of Central South
   University
FX National Natural Science Foundation of China, Grant/Award Number:
   62171451; Hunan Provincial Natural Science Foundation of China,
   Grant/Award Number: 2023JJ30700; Fundamental Research Funds for the
   Central Universities of Central South University
CR Aarabi P, 2002, IEEE SYS MAN CYBERN, P2644
   [Anonymous], 2016, Computer models for facial beauty analysis
   Bottino A, 2012, IEEE T BIO-MED ENG, V59, P3439, DOI 10.1109/TBME.2012.2217496
   Bougourzi F, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108246
   Chen FM, 2016, NEUROCOMPUTING, V177, P98, DOI 10.1016/j.neucom.2015.11.010
   Chiang WC, 2014, PATTERN RECOGN, V47, P1249, DOI 10.1016/j.patcog.2013.09.007
   Cignoni P., 2008, P EUR IT CHAPT C, P129, DOI [DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136, 10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/129-136]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Ferrari C, 2017, SOC COGN AFFECT NEUR, V12, P707, DOI 10.1093/scan/nsx002
   Garland M., 1997, P 24 ANN C COMP GRAP, V1997, P209, DOI DOI 10.1145/258734.258849
   Gong X., 2006, IEEE INT C IND TECHN, P1154
   Gray D, 2010, LECT NOTES COMPUT SC, V6316, P434, DOI 10.1007/978-3-642-15567-3_32
   He DX, 2022, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000454
   Jiankai Xu, 2021, 2021 2nd International Conference on Computing and Data Science (CDS), P44, DOI 10.1109/CDS52072.2021.00015
   Kagian A, 2007, INT C NEURAL INFORM, P649
   Kingma D. P., 2014, arXiv
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Li JS, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P793, DOI 10.1145/2733373.2807966
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Liang LY, 2017, IEEE T CIRC SYST VID, V27, P125, DOI 10.1109/TCSVT.2016.2602812
   Liao QQ, 2012, IEEE T VIS COMPUT GR, V18, P1704, DOI 10.1109/TVCG.2012.26
   Lin LJ, 2022, IEEE T AFFECT COMPUT, V13, P122, DOI 10.1109/TAFFC.2019.2933523
   Lin LJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P847
   Liu S, 2022, SOFT COMPUT, V26, P10401, DOI 10.1007/s00500-022-07324-0
   Liu S, 2017, NEUROCOMPUTING, V238, P168, DOI 10.1016/j.neucom.2017.01.050
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P16633, DOI 10.1007/s11042-016-3830-3
   Paszke A, 2019, ADV NEUR IN, V32
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2017, ADV NEUR IN, V30
   Rothe Rasmus, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P5553, DOI 10.1109/CVPR.2016.599
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Singh VV, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4883, DOI 10.1145/3474085.3475468
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Weng NN, 2021, INT C PATT RECOG, P10026, DOI 10.1109/ICPR48806.2021.9413333
   Wenming Han, 2020, ICCPR 2020: Proceedings of the 2020 9th International Conference on Computing and Pattern Recognition, P213, DOI 10.1145/3436369.3436476
   Xiao QJ, 2021, COMPUT GRAPH-UK, V98, P11, DOI 10.1016/j.cag.2021.04.023
   Xie DR, 2015, IEEE SYS MAN CYBERN, P1821, DOI 10.1109/SMC.2015.319
   Xu J, 2017, INT CONF ACOUST SPEE, P1657, DOI 10.1109/ICASSP.2017.7952438
   Xu L., 2018, TRANSFERRING RICH DE
   Yin B., 2005, BJUT 3D LARGE SCALE
   Zhao N, 2015, SOC BEHAV PERSONAL, V43, P855, DOI 10.2224/sbp.2015.43.5.855
NR 42
TC 0
Z9 0
U1 3
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2203
EA AUG 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001051957200001
DA 2024-07-18
ER

PT J
AU Zhao, J
   Sun, MM
   Wang, F
   Wang, XL
   Zhang, J
   Tang, Y
AF Zhao, Jing
   Sun, Mengmeng
   Wang, Feng
   Wang, Xiaolong
   Zhang, Jian
   Tang, Yong
TI A rapid diffusion simulation method of multiple-fluid coupling combined
   with MPM and PFM
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE bulk energy function; MPM; multiple-fluid; PFM
ID TENSION FORCE FORMULATION; PHASE-FIELD MODELS; NONUNIFORM SYSTEM;
   FREE-ENERGY
AB To solve the low diffusion efficiency in the multiple-fluid coupling process by the Lagrangian method, the paper presents a multiple-fluid coupling simulation algorithm based on MPM and PFM. First, based on the MPM, we model multiphase flow on Eulerian grids and capture the sharp interfaces between immiscible fluids combined with the PFM. The gas phase is further treated as fluid during the gas-liquid interaction. Second, to demonstrate the natural fluid moving evolution from the high energy state to the low energy state, the paper proposes the local minimize bulk energy function to control the low energy state. Finally, the paper designs and achieves various groups of multiple-fluid coupling comparison experiments. Experimental results showed that the proposed approach can simulate various effects of rapid diffusion in the multiple-fluid coupling, such as complete dissolution, mutual solubility, extraction, and other phenomena. Meanwhile, our approach is simple to integrate with existing state-of-the-art MPM solvers.
C1 [Zhao, Jing; Sun, Mengmeng; Wang, Feng; Wang, Xiaolong; Zhang, Jian; Tang, Yong] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao, Hebei, Peoples R China.
   [Zhao, Jing; Sun, Mengmeng; Wang, Feng; Wang, Xiaolong; Zhang, Jian; Tang, Yong] Key Lab Comp Virtual Technol & Syst Integrat Hebei, Qinhuangdao, Hebei, Peoples R China.
   [Tang, Yong] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University; Yanshan University
RP Tang, Y (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM tangyong@ysu.edu.cn
RI sun, mengxiang/KGM-8445-2024; sun, meng/JGE-3753-2023
OI Zhao, Jing/0000-0003-4971-9983
FU National Natural Science Foundation of China [61902340]; Innovation
   Capability Improvement Plan Project of Hebei Province [22567626H]
FX National Natural Science Foundation of China, Grant/Award Number:
   61902340; Innovation Capability Improvement Plan Project of Hebei
   Province, Grant/Award Number: 22567626H
CR Anderson DM, 1998, ANNU REV FLUID MECH, V30, P139, DOI 10.1146/annurev.fluid.30.1.139
   CAHN JW, 1961, ACTA METALL MATER, V9, P795, DOI 10.1016/0001-6160(61)90182-1
   CAHN JW, 1959, J CHEM PHYS, V30, P1121, DOI 10.1063/1.1730145
   CAHN JW, 1959, J CHEM PHYS, V31, P688, DOI 10.1063/1.1730447
   Chen J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459851
   Han XC, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340258
   Hu YM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201293
   Jiang C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766996
   Kang N, 2010, COMPUT GRAPH FORUM, V29, P685, DOI 10.1111/j.1467-8659.2009.01638.x
   Kim D., 2017, Fluid engine development
   Kim J, 2005, J COMPUT PHYS, V204, P784, DOI 10.1016/j.jcp.2004.10.032
   Kim J, 2007, COMPUT METHOD APPL M, V196, P4779, DOI 10.1016/j.cma.2007.06.016
   Kim J, 2012, COMMUN COMPUT PHYS, V12, P613, DOI 10.4208/cicp.301110.040811a
   Kim J, 2009, COMPUT METHOD APPL M, V198, P3105, DOI 10.1016/j.cma.2009.05.008
   Klár G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925906
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   Nielsen MB, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461918
   Park J, 2008, COMPUT ANIMAT VIRT W, V19, P455, DOI 10.1002/cav.256
   Ram D., MAT POINT METHOD VIS
   Ren B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459764
   Ren B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2645703
   Steffen M, 2008, INT J NUMER METH ENG, V76, P922, DOI 10.1002/nme.2360
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Su HZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459820
   SULSKY D, 1995, COMPUT PHYS COMMUN, V87, P236, DOI 10.1016/0010-4655(94)00170-7
   Yan X, 2018, COMPUT GRAPH FORUM, V37, P183, DOI 10.1111/cgf.13523
   Yan X, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925897
   Yang T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130882
   Yang T, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818117
   Yue YH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2751541
NR 30
TC 0
Z9 0
U1 2
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2142
EA APR 2023
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HA0S8
UT WOS:000971846500001
DA 2024-07-18
ER

PT J
AU Zhao, SH
   Ni, YX
   Dong, GZ
   Tian, JL
   Chen, YL
AF Zhao, Shenghuan
   Ni, Yaxue
   Dong, Guozheng
   Tian, Jianglan
   Chen, Yulin
TI Comparing three XR technologies in reviewing performance-based building
   design: A pilot study of facade fenestrations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; building design; human computer interaction;
   interaction design; mixed reality; virtual reality
ID AUGMENTED REALITY APPLICATIONS; VIRTUAL-REALITY; ARCHITECTURE;
   USABILITY; AR
AB Extended reality (XR), including augmented reality (AR), mixed reality (MR), and virtual reality (VR), can make complex information more intuitively understandable. However, it still needs to be determined which XR technology is the most suitable for reviewing performance-based building design, during which architects check whether design strategies increase energy efficiency, indoor environment quality and so forth. It requires comprehensive design and simulation information to be vividly represented. The authors develop three XR apps (AR, MR, and VR) to interactively visualize facade fenestration geometries and indoor illuminance simulations. Then XR technologies are assessed by 120 students and young architects, from task performance and engagement level two aspects. The task performance is measured by correct rate and time consumption two indicators, while the engagement level is measured by usability and interest two indicators. Evaluation results show that compared to AR and VR, MR is the best XR technology for this aim. VR outperforms AR on three indicators except for usability. By exposing three different XR technologies' performances in aiding fenestration design, this study increases the practical value of applying XR to the building design field.
C1 [Zhao, Shenghuan; Ni, Yaxue; Dong, Guozheng; Tian, Jianglan; Chen, Yulin] Suzhou Univ Sci & Technol, Sch Architecture & Urban Planning, Suzhou, Jiangsu, Peoples R China.
C3 Suzhou University of Science & Technology
RP Zhao, SH (corresponding author), Suzhou Univ Sci & Technol, Sch Architecture & Urban Planning, Suzhou, Jiangsu, Peoples R China.
EM shenghuan.z@gmail.com
RI Chen, Yulin/IUO-6274-2023
OI ZHAO, Shenghuan/0000-0003-3109-6087
FU Jiangsu Youth Research Funding;  [BK20210869]
FX ACKNOWLEDGMENT This study is supported by Jiangsu Youth Research Funding
   under the grant of BK20210869.
CR Ahn K., 2019, APPL COMPUTING INFOR
   Alizadehsalehi S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073225
   Arkio ehf, 2022, ARK
   Ashour Z., 2022, BIMXAR BIM EMPOWERED
   Belcher D., 2008, 28 ANN C ASS COMPUTE, P464
   Belcher D.e., 2008, 26th eCAADe Conference Proceedings, P561
   Broll W., 2004, J VIRTUAL REALITY BR, V1, P1, DOI DOI 10.20385/1860-2037/1.2004.1
   Calderon CP., 2000, VIRT REAL INT C, P46
   Canadinc ST., 2022, ECAADE 40, V2, P495
   Carbonari A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142013239
   Carmo MB, 2014, INT SYM MIX AUGMENT, P255, DOI 10.1109/ISMAR.2014.6948437
   Carrasco MDO, 2021, AUTOMAT CONSTR, V126, DOI 10.1016/j.autcon.2021.103677
   Chan VS, 2022, MULTIMED TOOLS APPL, V81, P12459, DOI 10.1007/s11042-022-12293-5
   Chi HL, 2013, AUTOMAT CONSTR, V33, P116, DOI 10.1016/j.autcon.2012.12.017
   Colley Ashley, 2020, MUM 2020: 19th International Conference on Mobile and Ubiquitous Multimedia, P309, DOI 10.1145/3428361.3432074
   de Klerk R, 2019, AUTOMAT CONSTR, V103, P104, DOI 10.1016/j.autcon.2019.03.009
   Du J, 2018, AUTOMAT CONSTR, V85, P51, DOI 10.1016/j.autcon.2017.10.009
   Du J, 2018, J CONSTR ENG M, V144, DOI 10.1061/(ASCE)CO.1943-7862.0001426
   Elawady Mohamed, 2020, Internet of ThingsApplications and Future. Proceedings of ITAF 2019. Lecture Notes in Networks and Systems (LNNS 114), P125, DOI 10.1007/978-981-15-3075-3_9
   Fast-Berglund Å, 2018, PROCEDIA MANUF, V25, P31, DOI 10.1016/j.promfg.2018.06.054
   Fenu C, 2018, INT J HUM-COMPUT ST, V114, P20, DOI 10.1016/j.ijhcs.2018.01.009
   Fidan M, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103635
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   Fogarty J, 2018, J PROF ISS ENG ED PR, V144, DOI 10.1061/(ASCE)EI.1943-5541.0000349
   Foroughi SabzevarM., 2020, International Journal of Construction Education and Research, V17, P178
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Georgiou Y, 2017, INT J HUM-COMPUT ST, V98, P24, DOI 10.1016/j.ijhcs.2016.09.014
   Graziani T., 2019, WHAT ARE WECHAT MINI
   Hartless JF, 2020, J ARCHIT ENG, V26, DOI 10.1061/(ASCE)AE.1943-5568.0000396
   Heuveline V., 2011, P 1 INT C ADV COMM C, P115
   Huang KT, 2019, CYBERPSYCH BEH SOC N, V22, P105, DOI 10.1089/cyber.2018.0150
   Huang Y., 2019, J CIVIL ENG ARCHITEC, V13, P409
   IRISVR, 2021, PROSP PLUG RHIN
   Jing-Ying Wong, 2020, International Journal of Interactive Mobile Technologies, V14, P15, DOI 10.3991/ijim.v14i06.13397
   Jun Wang, 2014, Construction Innovation, V14, P453, DOI 10.1108/CI-03-2014-0019
   Jung T, 2020, INT J HUM-COMPUT INT, V36, P239, DOI 10.1080/10447318.2019.1630933
   Keshavarzi M, 2021, AUTOMAT CONSTR, V125, DOI 10.1016/j.autcon.2021.103623
   Kirakosian S., 2021, P S VLSI CIRC, P1
   Ko SM, 2013, INT J HUM-COMPUT INT, V29, P501, DOI 10.1080/10447318.2012.722466
   Kolecki Radek., 2022, Translational Research in Anatomy, V28, P100214, DOI DOI 10.1016/J.TRIA.2022.100214
   Kraus MA, 2022, STRUCTURES CONGRESS 2022, P283
   Krichenbauer M, 2018, IEEE T VIS COMPUT GR, V24, P1038, DOI 10.1109/TVCG.2017.2658570
   Labovitz J, 2020, CLIN PODIATR MED SUR, V37, P409, DOI 10.1016/j.cpm.2019.12.008
   Lakaemper R, 2009, J COMPUT CIVIL ENG, V23, P384, DOI 10.1061/(ASCE)0887-3801(2009)23:6(384)
   Lee Y, 2021, J COMPUT DES ENG, V8, P756, DOI 10.1093/jcde/qwab012
   Li Wenkai., 2017, Multimodal Technol Inter, V1, P17, DOI [DOI 10.3390/MTI1030017, 10.3390/mti1030017]
   Liu YF, 2020, J COMPUT CIVIL ENG, V34, DOI 10.1061/(ASCE)CP.1943-5487.0000856
   Manuri Federico., 2016, ACSIJ ADV COMPUTER S, V5, P19
   Meza S, 2014, AUTOMAT CONSTR, V42, P1, DOI 10.1016/j.autcon.2014.02.011
   Microsoft, MICR HOLOLENS 2 2022
   Microsoft, WHAT IS MIX REAL TOO
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Milovanovic J., 2017, CAAD FUTURES, V2017, P1
   Muller Jens., 2019, Proceedings of Mensch und Computer, P399, DOI [10.1145/3340764.3340773, DOI 10.1145/3340764.3340773]
   O'Brien HL, 2010, J AM SOC INF SCI TEC, V61, P50, DOI 10.1002/asi.21229
   Olbina, 2022, INT J CONSTR ED RES, P1
   Ong SK, 2017, CIRP ANN-MANUF TECHN, V66, P149, DOI 10.1016/j.cirp.2017.04.035
   Paes D, 2021, AUTOMAT CONSTR, V130, DOI 10.1016/j.autcon.2021.103849
   Paredes L, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3550305
   Ph D., 2015, STRUCTURES C, V2015, P1401
   Piroozfar A., 2018, 10 INT C CONSTRUCTIO
   Qiao XQ, 2018, IEEE INTERNET COMPUT, V22, P46, DOI 10.1109/MIC.2018.043051464
   Rauschnabel PA, 2022, COMPUT HUM BEHAV, V133, DOI 10.1016/j.chb.2022.107289
   Reinhart CF, 2011, BUILD ENVIRON, V46, P386, DOI 10.1016/j.buildenv.2010.08.001
   Safikhani S, 2022, INT J DIGIT EARTH, V15, P503, DOI 10.1080/17538947.2022.2038291
   Vergel RS, 2020, IEEE T HUM-MACH SYST, V50, P337, DOI 10.1109/THMS.2020.2984746
   Shahinmoghadam M, 2021, BUILD ENVIRON, V199, DOI 10.1016/j.buildenv.2021.107905
   Shore J, 2023, J CIV ENG EDUC, V149, DOI 10.1061/(ASCE)EI.2643-9115.0000069
   Siltanen S, 2017, VISUAL COMPUT, V33, P193, DOI 10.1007/s00371-015-1174-z
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Tcha-Tokey K, 2018, ADV HUM-COMPUT INTER, V2018, DOI 10.1155/2018/7827286
   Tea S, 2022, J ENG DES TECHNOL, V20, P281, DOI 10.1108/JEDT-12-2020-0500
   Thees M, 2020, COMPUT HUM BEHAV, V108, DOI 10.1016/j.chb.2020.106316
   Try S, 2021, COMPUT APPL ENG EDUC, V29, P1771, DOI 10.1002/cae.22422
   Tsujimoto R, 2022, PROCEEDINGS OF THE 2022 ANNUAL MODELING AND SIMULATION CONFERENCE (ANNSIM'22), P605, DOI 10.23919/ANNSIM55834.2022.9859400
   Unity Technologies, UN 2022
   Verhulst I, 2021, COMPUT HUM BEHAV, V125, DOI 10.1016/j.chb.2021.106951
   Vizcay S, 2022, 28TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2022, DOI 10.1145/3562939.3565634
   Voit A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300737
   Wang L., 2017, AUGMENTED REALITY VI
   Wild Technology Inc, 2021, WILD
   Yehia A., 2022, C P ASEE ANN C EXPOS
   Yilei H., 2020, J CIVIL ENG CONSTRUC, V11, P1, DOI DOI 10.5897/JCECT2020.0534
   Zhang LF, 2022, TRANSPORTMETRICA B, V10, P1206, DOI 10.1080/21680566.2022.2034550
   Zhang YX, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103311
   Zhao S., 2019, P 2019 EUR C COMP CO, P435
   Zhao SH, 2022, EDUC INF TECHNOL, V27, P9125, DOI 10.1007/s10639-022-10998-6
   Zhao SH, 2020, SCI TECHNOL BUILT EN, V26, P1337, DOI 10.1080/23744731.2020.1777048
   Zhao SH, 2018, J INTEGR DES PROCESS, V22, P55, DOI 10.3233/JID190001
   Zhu YH, 2020, TECHNOLOGIES, V8, DOI 10.3390/technologies8010004
NR 91
TC 0
Z9 0
U1 2
U2 24
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2139
EA JAN 2023
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HA0V1
UT WOS:000906521000001
DA 2024-07-18
ER

PT J
AU Zhang, ZJ
   Zheng, JM
   Thalmann, NM
AF Zhang, Zhijie
   Zheng, Jianmin
   Thalmann, Nadia Magnenat
TI Engagement estimation of the elderly from wild multiparty human-robot
   interaction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE affective computing; engagement estimation; human-robot interaction;
   machine learning; multiparty
AB The use of social robots in healthcare systems or nursing homes to assist the elderly and their caregivers will be becoming common, where robots' understanding of engagement of the elderly is important. Traditional engagement estimation (EE) often requires expert involvement in a controlled dyadic interaction environment. In this article, we propose a supervised machine learning method to estimate the engagement state of the elderly in a multiparty human-robot interaction (HRI) scenario from the real-world video recording as input. The method is built upon the basic concept of engagement in geriatric psychiatry and HRI video representations. It adapts pretrained models to extract behavior, affective, and visual signals to form the multi-modal features. These features are then fed into a neural network made of a self-attention mechanism and average pooling for individual learning, a graph attention network for group learning and a fully connected layer to estimate the engagement. We tested the proposed method using 43 wild multiparty elderly robot interaction (ERI) videos. The experimental results show that our method is capable of detecting the key participants and estimating the engagement state of the elderly effectively. Also our study demonstrates the signals from side-participants in the main interaction group considerably contribute to the EE of the elderly in the multiparty ERI.
C1 [Zhang, Zhijie; Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Thalmann, Nadia Magnenat] Univ Geneva, MIRALab, CUI, Geneva, Switzerland.
C3 Nanyang Technological University; University of Geneva
RP Zheng, JM (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
EM asjmzheng@ntu.edu.sg
OI ZHANG, ZHIJIE/0000-0002-7164-2751; Thalmann, Nadia/0000-0002-1459-5960
FU WASP/NTU Project [04INS000440C130]; National Research Foundation,
   Singapore
FX WASP/NTU Project, Grant/Award Number: 04INS000440C130; National Research
   Foundation, Singapore
CR Abedi A., 2021, ARXIV
   Anagnostopoulou D, 2021, IEEE INT CONF ROBOT, P3641, DOI 10.1109/ICRA48506.2021.9561687
   [Anonymous], 2007, Mind, hands, face and body: a goal and belief view of multimodal communication
   [Anonymous], 2009, P 2009 INT C MULT IN, DOI DOI 10.1145/1647314.1647336
   [Anonymous], 2021, Ageing and health
   Archambault I, 2017, J EDUC RES, V110, P188, DOI 10.1080/00220671.2015.1060931
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Ben-Eliyahu A, 2018, CONTEMP EDUC PSYCHOL, V53, P87, DOI 10.1016/j.cedpsych.2018.01.002
   Ben-Youssef A, 2021, IEEE T AFFECT COMPUT, V12, P776, DOI 10.1109/TAFFC.2019.2898399
   Bin Zhu, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P841, DOI 10.1145/3382507.3417965
   Celiktutan O, 2019, IEEE T AFFECT COMPUT, V10, P484, DOI 10.1109/TAFFC.2017.2737019
   Chen CFR., CVPR 2021, V202, P6165
   Clark H. H., 1996, USING LANGUAGE
   Cohen-Mansfield J, 2011, AM J GERIAT PSYCHIAT, V19, P859, DOI 10.1097/JGP.0b013e318202bf5b
   Cohen-Mansfield J, 2009, AM J GERIAT PSYCHIAT, V17, P299, DOI 10.1097/JGP.0b013e31818f3a52
   Corrigan LJ, 2016, INTEL SYST REF LIBR, V105, P29, DOI 10.1007/978-3-319-31056-5_4
   Del Duchetto F, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00116
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Finn JD, 2012, HANDBOOK OF RESEARCH ON STUDENT ENGAGEMENT, P97, DOI 10.1007/978-1-4614-2018-7_5
   Fölster M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00030
   Gao N, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411813
   Ghafurian M, 2021, ACM T HUM-ROBOT INTE, V10, DOI 10.1145/3469653
   Goffman E., 1981, Forms of Talk
   Guhan P., 2020, ABC NET SEMI SUPERVI
   Guo GD, 2013, IEEE T AFFECT COMPUT, V4, P291, DOI 10.1109/T-AFFC.2013.13
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Jain S, 2020, SCI ROBOT, V5, DOI 10.1126/scirobotics.aaz3791
   Jones C, 2018, J ADV NURS, V74, P2227, DOI 10.1111/jan.13717
   Kamel A, 2021, IEEE T MULTIMEDIA, V23, P1330, DOI 10.1109/TMM.2020.2999181
   Kay W., 2017, ARXIV170506950
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liang CA, 2021, ACM T COMPUT-HUM INT, V28, DOI 10.1145/3443686
   Mishra N, 2021, LECT NOTES COMPUT SC, V13002, P491, DOI 10.1007/978-3-030-89029-2_38
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   Oertel C, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.555913
   Oertel C, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00092
   Perugia G, 2022, IEEE T AFFECT COMPUT, V13, P926, DOI 10.1109/TAFFC.2020.2980275
   Rudovic O, 2019, IEEE COMPUT SOC CONF, P217, DOI 10.1109/CVPRW.2019.00031
   Salam H, 2017, IEEE ACCESS, V5, P705, DOI 10.1109/ACCESS.2016.2614525
   Saleh K, 2021, ACMIEEE INT CONF HUM, P190, DOI 10.1145/3434074.3447157
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   She JH, 2021, PROC CVPR IEEE, P6244, DOI 10.1109/CVPR46437.2021.00618
   Sidner CL, 2005, ARTIF INTELL, V166, P140, DOI 10.1016/j.artint.2005.03.005
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Steinert Lars, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P558, DOI 10.1145/3382507.3418856
   Sumer O, 2021, ARXIV
   Trahan MA, 2014, HEALTH EDUC BEHAV, V41, p70S, DOI 10.1177/1090198114531782
   Tulsulkar G, 2021, VISUAL COMPUT, V37, P3019, DOI 10.1007/s00371-021-02242-y
   Velickovic Petar, 2017, ARXIV171010903, DOI DOI 10.48550/ARXIV.1710.10903
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Zeghoud S, 2022, VISUAL COMPUT, V38, P1345, DOI 10.1007/s00371-021-02229-9
   Zhang Y.-F., 2021, arXiv
NR 54
TC 2
Z9 2
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2022
VL 33
IS 6
AR e2120
DI 10.1002/cav.2120
EA AUG 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6Z9LE
UT WOS:000842532200001
DA 2024-07-18
ER

PT J
AU Zhang, JS
   Zhu, SQ
   Liu, KX
   Liu, XY
AF Zhang, Junsong
   Zhu, Shaoqiang
   Liu, Kunxiang
   Liu, Xiaoyu
TI UGSC-GAN: User-guided sketch colorization with deep convolution
   generative adversarial networks
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE colorization; generative adversarial networks; painting; sketch
ID IMAGE
AB Inspired by the creating process of human paintings, we propose a novel adversarial architecture for multiple sketch colorization which is a scribble-based, automatic, and exemplar-based colorization method. The proposed framework has two stages, namely, imitating stage and shading stage. In the imitating stage, to address the challenge of lack of texture in the sketch, we train a grayscale generation network to accomplish a mapping task, namely, generating a grayscale map with textured, grayscale, boundary information from the input sparse sketch. In the shading stage, the model can accurately colorize the objects in the gray image generated in the previous stage, and generate high-quality colorized images. With the proposed model trained on our database, the experimental results show that our method can generate vivid colorized images and achieve a better performance than previous methods evaluated by FID metric.
C1 [Zhang, Junsong; Zhu, Shaoqiang; Liu, Kunxiang; Liu, Xiaoyu] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Peoples R China.
   [Zhang, Junsong] Xiamen Univ, Dept Artificial Intelligence, Mind Art & Computat Grp, Xiamen 361005, Fujian, Peoples R China.
C3 Central China Normal University; Xiamen University
RP Zhang, JS (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Peoples R China.
EM jszhang@outlook.com
RI Zhao, Chunxia/KBB-4190-2024; Zhang, JunSong/HTQ-4981-2023; zhao,
   yujie/JLL-1283-2023; Zhang, Junsong/HKW-6976-2023
FU National Natural Science Foundation of China [61772440]
FX National Natural Science Foundation of China, Grant/Award Number:
   61772440
CR [Anonymous], 2019, LLLYASVIEL STYLE2PAI
   Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460
   Cao Yang, 2010, P 18 ACM INT C MULT, P1605
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Chen WL, 2018, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR.2018.00981
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Ci YZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1536, DOI 10.1145/3240508.3240661
   Deshpande A, 2015, IEEE I CONF COMP VIS, P567, DOI 10.1109/ICCV.2015.72
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Eitz M, 2011, IEEE COMPUT GRAPH, V31, P56, DOI 10.1109/MCG.2011.67
   Eitz M, 2010, COMPUT GRAPH-UK, V34, P482, DOI 10.1016/j.cag.2010.07.002
   Endo Y, 2016, COMPUT GRAPH FORUM, V35, P189, DOI 10.1111/cgf.12822
   Frans Kevin, 2018, INT C LEARN REPR
   Furusawa C, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149430
   Guadarrama S, 2017, ARXIV170507208
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Heusel M., 2017, Advances in Neural Information Processing Systems, P6627, DOI [DOI 10.48550/ARXIV.1706.08500, 10.48550/arXiv.1706.08500]
   IIZUKA S, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/2897824.2925974
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jheng-Wei Su, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7965, DOI 10.1109/CVPR42600.2020.00799
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lee J, 2020, PROC CVPR IEEE, P5800, DOI 10.1109/CVPR42600.2020.00584
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Liao J., 2017, ACM Trans. Graph.
   Liu Y, 2017, COMMUN MATH BIOL NEU, DOI 10.1080/10408398.2017.1329704
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Saito Masaki, 2015, SIGGRAPH ASIA 2015 T
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Shao C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185541
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sykora D, 2009, COMPUT GRAPH FORUM, V28, P599, DOI 10.1111/j.1467-8659.2009.01400.x
   Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Winnemoeller H, 2012, COMPUT GRAPH-UK, V36, P740, DOI 10.1016/j.cag.2012.03.004
   Yonezu T, 2017, IEEE T MAGN, V53, DOI 10.1109/TMAG.2017.2697002
   Yu Y, 2017, LECT NOTES COMPUT SC, V10667, P97, DOI 10.1007/978-3-319-71589-6_9
   Zhang LM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275090
   Zhang LM, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P506, DOI 10.1109/ACPR.2017.61
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zheng Q., 2020, ARXIV PREPRINT ARXIV
   Zhong Y., 2020, ARXIV PREPRINT ARXIV
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 46
TC 4
Z9 4
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2022
VL 33
IS 1
AR e2032
DI 10.1002/cav.2032
EA OCT 2021
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH4XD
UT WOS:000703983500001
DA 2024-07-18
ER

PT J
AU Cui, DX
   Kao, D
   Mousas, C
AF Cui, Dixuan
   Kao, Dominic
   Mousas, Christos
TI Toward understanding embodied human-virtual character interaction
   through virtual and tactile hugging
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE tactile feedback; tactile sensation; virtual character interaction;
   virtual hugging; virtual reality
ID TOUCH; REALITY; MOTION
AB This between-group study investigated participants' experiences of tactile feedback patterns when asked to hug a virtual character. Five experimental conditions were developed, one with no tactile feedback and four with tactile feedback. The participants were placed in a virtual city and informed they would be meeting a virtual friend, who they were instructed to hug once the character came close to them. During the virtual hug, one of the five experimental conditions was examined. Immediately after the hug, participants were asked to complete a questionnaire to capture their experiences. The results obtained from this study indicated that: (1) even if the tactile feedback is not considered to be highly accurate in terms of timing, duration, and position, as long as it is perceived as less persistent, it provides a more positive experience; (2) the perceived realism of the virtual hug is strongly correlated with the perceived realism of the tactile feedback; and (3) the female participants had a more intense interaction with the virtual character (friend) compared with the male participants. Limitations and future study directions are discussed.
C1 [Cui, Dixuan; Mousas, Christos] Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
   [Kao, Dominic] Purdue Univ, Dept Comp & Informat Technol, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University; Purdue University System;
   Purdue University
RP Mousas, C (corresponding author), Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
EM cmousas@purdue.edu
RI Mousas, Christos/AGV-3533-2022
OI Mousas, Christos/0000-0003-0955-7959; Cui, Dixuan/0000-0003-0114-042X
CR [Anonymous], 2006, ACM SIGGRAPH 2006 EM
   Benali-Khoudja M., 2004, INT S ROBOTICS, V31, P23
   Biocca F., 2001, 4 ANN INT WORKSH PRE, P1
   Block AE, 2019, INT J SOC ROBOT, V11, P49, DOI 10.1007/s12369-018-0495-2
   Burdea G, 1996, INT J HUM-COMPUT INT, V8, P5, DOI 10.1080/10447319609526138
   Cohen S, 2015, PSYCHOL SCI, V26, P135, DOI 10.1177/0956797614559284
   Collier G., 1985, EMOTIONAL EXPRESSION
   Colwell C., 1998, ASSETS'98. Third International ACM Conference on Assistive Technologies, P92, DOI 10.1145/274497.274515
   Debrot A, 2013, PERS SOC PSYCHOL B, V39, P1373, DOI 10.1177/0146167213497592
   DERLEGA VJ, 1989, J NONVERBAL BEHAV, V13, P83
   DiSalvo C, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P403
   Foottit J., 2016, ARXIV PREPRINT ARXIV
   Forlines C, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1563
   Freeman D, 2003, J NERV MENT DIS, V191, P509, DOI 10.1097/01.nmd.0000082212.83842.fe
   Frissen P., 1997, The Governance of Cyberspace: Public. Technology and Global Restructuring, P111, DOI DOI 10.4324/9780203360408_
   Fröhner J, 2019, IEEE T HAPTICS, V12, P339, DOI 10.1109/TOH.2018.2889497
   Galambos P., 2011, PROC 2 INT C COGN IN, P1
   García-Valle G, 2018, IEEE ACCESS, V6, P7224, DOI 10.1109/ACCESS.2017.2782254
   Gatti E, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P247, DOI 10.1109/WHC.2013.6548416
   Gobron SC, 2015, LECT NOTES COMPUT SC, V9254, P199, DOI 10.1007/978-3-319-22888-4_15
   Haans A., 2007, P AC M C HUMAN FACTO, P2405
   Haans Antal, 2006, Virtual Reality, P149
   Israr A, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2641570
   Kappers AML, 2011, PHILOS T R SOC B, V366, P3106, DOI 10.1098/rstb.2011.0171
   Koilias A, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1963
   Koilias A, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6020018
   Kreimeier J, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P289, DOI 10.1145/3316782.3321536
   Krishna Sreekar, 2010, CHI 10 EXTENDED ABST, P3637
   Krogmeier C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1032, DOI [10.1109/VR.2019.8798139, 10.1109/vr.2019.8798139]
   Krogmeier C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1883
   Kurita Y, 2013, IEEE T HUM-MACH SYST, V43, P333, DOI 10.1109/TSMC.2013.2242886
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Lee J, 2017, IEEE T HUM-MACH SYST, V47, P101, DOI 10.1109/THMS.2016.2599492
   MAJOR B, 1982, J NONVERBAL BEHAV, V6, P148, DOI 10.1007/BF00987064
   Martínez J, 2016, IEEE COMPUT GRAPH, V36, P42, DOI 10.1109/MCG.2014.81
   McGregor Carolyn, 2016, 2016 IEEE 6th International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P214, DOI 10.1109/ICCE-Berlin.2016.7684758
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Naveteur J, 2013, TRANSPORT RES F-TRAF, V18, P58, DOI 10.1016/j.trf.2012.12.008
   Otaduy M.A., 2016, ACM SIGGRAPH 2016 CO, P1
   Pabon S., 2007, 10 ANN INT WORKSHOP, P345
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Perry J.S., 2018, IBM developerWorks, P1
   Ramsamy P, 2006, LECT NOTES COMPUT SC, V3992, P603, DOI 10.1007/11758525_81
   Sanfilippo F, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1, DOI 10.1109/ROBIO.2015.7407010
   Singer MJ, 1999, PRESENCE-TELEOP VIRT, V8, P566, DOI 10.1162/105474699566486
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   STIER DS, 1984, J PERS SOC PSYCHOL, V47, P440, DOI 10.1037/0022-3514.47.2.440
   Tanaka  Y., 2002, P JFPS INT S FLUID P, V2002, P309
   Trovato G, 2016, IEEE-RAS INT C HUMAN, P318, DOI 10.1109/HUMANOIDS.2016.7803295
   Tsalamlal MY, 2015, J MULTIMODAL USER IN, V9, P69, DOI 10.1007/s12193-014-0162-3
   Tsetserukou D, 2010, LECT NOTES COMPUT SC, V6191, P340, DOI 10.1007/978-3-642-14064-8_49
   Tsetserukou Dzmitry., 2009, ACII, P1, DOI [DOI 10.1109/ACII.2009.5349516, https://doi.org/10.1109/ACII.2009.5349516]
   van der Meulen E, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P102, DOI [10.1109/ISMAR-Adjunct.2016.0050, 10.1109/ISMAR-Adjunct.2016.43]
   von der Pütten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Wilson Erin, 2018, Adv Simul (Lond), V3, P21, DOI 10.1186/s41077-018-0080-7
   Zhao S, 2015, P INT C INT DES CHIL, P239, DOI 10.1145/2771839.2771886
NR 57
TC 9
Z9 10
U1 0
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2009
DI 10.1002/cav.2009
EA MAY 2021
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000653528300001
DA 2024-07-18
ER

PT J
AU Normoyle, A
   Jörg, S
AF Normoyle, Aline
   Jorg, Sophie
TI The effect of animation controller and avatar on player perceptions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE controller; digital games; motion quality; perception; responsiveness;
   virtual character
ID HUMAN MOTION
AB Real-time animation controllers are fundamental for animating characters in response to player input in digital games. However, the design of such controllers requires making trade-offs between the naturalness of the character's motions and the promptness of the character's response. In this paper, we investigate the effects of such trade-offs on the players' enjoyment, control, satisfaction, and opinion of the character in a simple platform game. In our first experiment, we compare three controllers having the same responsiveness, but varying levels of naturalness. In the second experiment, we compare three controllers having increasing realism at the expense of responsiveness. In our third experiment, we keep motion naturalness and responsiveness constant but vary the avatar. Not surprisingly, our least responsive controller negatively affects players' performance and perceived ability to control the character. However, we also find that players are most satisfied with their own performance using our least natural controller, that differences in animation can significantly alter players' enjoyment with responsiveness being equal, that players do not report increased motion quality with our most natural controller, although view IS outside of the game context do, and that the avatar model affected the perception of the character but not players' enjoyment or perceived realism.
C1 [Normoyle, Aline] Univ Penn, SIG Ctr Comp Graph, 220 S 33rd St, Philadelphia, PA 19104 USA.
   [Jorg, Sophie] Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
C3 University of Pennsylvania; Clemson University
RP Jörg, S (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
EM sjoerg@clemson.edu
CR Amin Rahul, 2013, Human-Computer Interaction. Users and Contexts of Use. 15th International Conference, HCI International 2013. Proceedings: LNCS 8006, P97, DOI 10.1007/978-3-642-39265-8_11
   [Anonymous], 2014, UNITY 3D MANUAL MECA
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096
   Beigbeder T, 2004, SIGCOMM WORKSH NETW, P144
   Beznosyk A, 2011, P 10 INT C VIRT REAL, P351
   Carter Marcus., 2012, P 24 AUSTR COMPUTERH, P68, DOI DOI 10.1145/2414536.2414547
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Chaminade T, 2007, SOC COGN AFFECT NEUR, V2, P206, DOI 10.1093/scan/nsm017
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Cooper S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239456
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   Dick M., 2005, NetGames'05, P1
   Gleicher M, 2003, ACM T GRAPHIC, V22, P702, DOI 10.1145/882262.882333
   Gleicher M, 2008, LECT NOTES COMPUT SC, V5277, P82
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Hefner D, 2007, LECT NOTES COMPUT SC, V4740, P39
   Hodgins J, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823740
   Hodgins JK, 1998, IEEE T VIS COMPUT GR, V4, P307, DOI 10.1109/2945.765325
   Hoyet L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185586
   HULSKEN F, 2007, INT J VIRTUAL REALIT, V6, P11
   Jorg S., 2012, Proceedings of the ACM Symposium on Applied Perception, SAP '12, P33, DOI DOI 10.1145/2338676.2338683
   Jin SAA, 2009, CYBERPSYCHOL BEHAV, V12, P761, DOI 10.1089/cpb.2009.0130
   Jorg S., 2010, P 7 S APPL PERCEPTIO, P129, DOI DOI 10.1145/1836248.1836273
   Kines Melianthe., 2000, PLANNING DIRECTING M
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lau M., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA '05, P271
   Lee J, 2006, GRAPH MODELS, V68, P158, DOI 10.1016/j.gmod.2005.03.004
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lee Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866160
   Lim S, 2009, MEDIA PSYCHOL, V12, P348, DOI 10.1080/15213260903287242
   McCann J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276385, 10.1145/1239451.1239457]
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   Mcdonnell R, 2009, ACM T APPL PERCEPT, V5, DOI 10.1145/1462048.1462051
   McDonnell R, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P259
   McDonnell R, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P67
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Normoyle A., 2014, Proceedings of the ACM symposium on applied perception, P117
   Normoyle Aline, 2014, P 7 INT C MOT GAM PL, P61, DOI [10.1145/ 2668064.2668087, DOI 10.1145/2668064.2668087]
   Quax Peter., 2004, NETGAMES 04, P152
   Reitsma PSA, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289609
   Trepte S., 2010, J MEDIA PSYCHOL-GER, V22, P171, DOI [DOI 10.1027/1864-1105/A000022, https://doi.org/10.1027/1864-1105/a000022]
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
   Trutoiu LC, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010327
   van Welbergen H, 2010, COMPUT GRAPH FORUM, V29, P2530, DOI 10.1111/j.1467-8659.2010.01822.x
   Yee N, 2006, CYBERPSYCHOL BEHAV, V9, P772, DOI 10.1089/cpb.2006.9.772
   Zhao L, 2008, S COMP AN SCA 08, P139
NR 47
TC 2
Z9 2
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2018
VL 29
IS 6
AR e1731
DI 10.1002/cav.1731
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HH9VW
UT WOS:000456089800004
DA 2024-07-18
ER

PT J
AU Parhi, DR
   Sahu, C
   Kumar, PB
AF Parhi, Dayal R.
   Sahu, Chinmaya
   Kumar, Priyadarshi Biplab
TI Navigation of multiple humanoid robots using hybrid adaptive
   swarm-adaptive ant colony optimisation technique
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE AACO; APSO; humanoid; hybridisation; navigation; Petri-net
ID MOBILE ROBOT; PARTICLE SWARM; CONTROLLER; PLANNER; MOTION
AB This paper is aimed at designing a navigation strategy for humanoid robots using a hybridised technique consisting of adaptive particle swarm optimisation and adaptive ant colony optimisation. The inputs to the navigational controller are the front obstacle distance, left obstacle distance, and right obstacle distance, and the output is the required final turning angle to reach the target position. Here, the governing parameters of the adaptive ant colony optimisation technique are optimised by using adaptive particle swarm optimisation method. These optimised parameters are subsequently used by the adaptive ant colony optimisation technique to get the final turning angle by which the humanoid navigates in a cluttered environment. Here, navigation is performed in both static and dynamic environments. To avoid the intercollision among the humanoids, a Petri-net controller has been designed and implemented along with the proposed hybridised method. Humanoid navigation is performed in both simulated and experimental environments, and a comparison is done between them. Finally, the proposed controller is compared with the developed method by other researchers.
C1 [Parhi, Dayal R.; Sahu, Chinmaya; Kumar, Priyadarshi Biplab] Natl Inst Technol, Dept Mech Engn, Robot Lab, Rourkela 769008, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Parhi, DR (corresponding author), Natl Inst Technol, Dept Mech Engn, Robot Lab, Rourkela 769008, Odisha, India.
EM dayaldoc@yahoo.com
RI Sahu, Chinmaya/AAQ-8127-2020; Parhi, Dayal/M-7935-2018
OI Sahu, Chinmaya/0000-0002-4987-4337; Parhi, Dayal/0000-0002-2073-7136;
   Kumar, Priyadarshi Biplab/0000-0002-6495-3228
CR [Anonymous], 2013, INT C CONTR AUT ROB
   [Anonymous], 2009 INT WORKSH INT
   Balaprakash Prasanna, 2009, Swarm Intelligence, V3, P223, DOI 10.1007/s11721-009-0031-y
   Busoniu L, 2016, ENG APPL ARTIF INTEL, V55, P70, DOI 10.1016/j.engappai.2016.05.003
   Chaari I., 2012, 2012 IEEE C EVOLUTIO, P1
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   Clever D, 2016, ROBOTICS SCI SYSTEMS
   Contreras-Cruz MA, 2015, APPL SOFT COMPUT, V30, P319, DOI 10.1016/j.asoc.2015.01.067
   Das PK, 2016, SWARM EVOL COMPUT, V28, P14, DOI 10.1016/j.swevo.2015.10.011
   Deepak BBVL, 2016, J EXP THEOR ARTIF IN, V28, P417, DOI 10.1080/0952813X.2015.1132261
   Deepak BBVL, 2014, ARAB J SCI ENG, V39, P6477, DOI 10.1007/s13369-014-1154-z
   Deepak BBVL, 2013, INTEL SERV ROBOT, V6, P155, DOI 10.1007/s11370-013-0131-9
   Deepak BBVL, 2012, PROCEDIA ENGINEER, V38, P2663, DOI 10.1016/j.proeng.2012.06.313
   Dorigo M, 2003, INT SER OPER RES MAN, V57, P251
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81, DOI 10.1109/CEC.2001.934374
   Gigras Y, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1616
   He KP, 2008, LECT NOTES ARTIF INT, V5314, P1127
   Hossen J, 2015, PROCEDIA COMPUT SCI, V76, P449, DOI 10.1016/j.procs.2015.12.307
   Huang HC, 2015, IEEE T IND INFORM, V11, P915, DOI 10.1109/TII.2015.2440173
   Jiangsong Lu, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P4301, DOI 10.1109/EMEIT.2011.6023113
   Karkowski P, 2016, IEEE-RAS INT C HUMAN, P69, DOI 10.1109/HUMANOIDS.2016.7803256
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kundu S, 2017, INT J AUTOM COMPUT, V14, P307, DOI 10.1007/s11633-016-0983-5
   Lee JW, 2009, PROC IEEE INT SYMP, P1979
   Mirjalili R, 2016, RSI INT CONF ROBOT M, P416, DOI 10.1109/ICRoM.2016.7886774
   Mohanty PK, 2016, J EXP THEOR ARTIF IN, V28, P35, DOI 10.1080/0952813X.2014.971442
   Mohanty PK, 2014, ADV INTELL SYST, V247, P353, DOI 10.1007/978-3-319-02931-3_40
   Pan J, 2010, COMPUT ANIMAT VIRT W, V21, P137, DOI 10.1002/cav.365
   Pandey A, 2017, DEF TECHNOL, V13, P47, DOI 10.1016/j.dt.2017.01.001
   Parhi D.R., 2011, J. Mech. Eng. Res, V3, P307
   Parhi DR, 2009, INT J AUTOM CONTROL, V3, P114, DOI 10.1504/IJAAC.2009.025237
   Parhi DR, 2017, P I MECH ENG M-J ENG
   Patle BK, 2017, WORLD J ENG, V14, P65, DOI 10.1108/WJE-11-2016-0133
   Patle BK, 2017, J COMPUT, V12, P135, DOI 10.17706/jcp.12.2.135-142
   Peterson J.L., 1981, Petri Net Theory and the Modeling of Systems
   Plaku E., 2016, COMPUT ANIM VIRTUAL
   Pothal JK, 2015, ROBOT AUTON SYST, V72, P48, DOI 10.1016/j.robot.2015.04.007
   Razzazi M, 2017, SCI IRAN, V24, P1335, DOI 10.24200/sci.2017.4116
   Shi Y., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1945, DOI 10.1109/CEC.1999.785511
   Sim KM, 2003, IEEE T SYST MAN CY A, V33, P560, DOI 10.1109/TSMCA.2003.817391
   Singh MK, 2011, INT J SYST SCI, V42, P107, DOI 10.1080/00207720903470155
   Suganthan P. N., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1958, DOI 10.1109/CEC.1999.785514
   Watanabe I, 2003, IEEE C EVOL COMPUTAT, P1355
   Yang SX, 2005, IFAC P, V38, P343, DOI DOI 10.3182/20050703-6-CZ-1902.01327
   Yoshida E, 2009, COMPUT ANIMAT VIRT W, V20, P511, DOI 10.1002/cav.280
   Zhang Q, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P2537, DOI 10.1109/WCICA.2012.6358300
   Zhang Y, 2007, PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II, P693
   Ziadi S, 2015, 12 INT MULT C SYST S, P1
NR 48
TC 9
Z9 9
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2018
VL 29
IS 2
AR e1802
DI 10.1002/cav.1802
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GD0DX
UT WOS:000430170900004
DA 2024-07-18
ER

PT J
AU Wu, CL
   Kanai, T
AF Wu, Chenlei
   Kanai, Takashi
TI Data-driven detailed hair animation for game characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE data driven; interactive applications; hair animation; game characters;
   Secondary Motion Graph
AB We propose a data-driven method to realize high-quality detailed hair animations in interactive applications like games. By devising an error metric method to evaluate hair animation similarities, we take hair features into consideration as much as possible. We also propose a novel database construction algorithm based on Secondary Motion Graph. Our algorithm can improve the efficiency of such graphs to reduce redundant data and also achieves visually smooth connection of two animation clips while taking into consideration their future motions. The costs for the run-time process using our Secondary Motion Graph are relatively low, allowing real-time interactive operations. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Wu, Chenlei; Kanai, Takashi] Univ Tokyo, Grad Sch Arts & Sci, Tokyo, Japan.
C3 University of Tokyo
RP Wu, CL (corresponding author), Univ Tokyo, Grad Sch Arts & Sci, Tokyo, Japan.
EM shinraigo@graco.c.u-tokyo.ac.jp
FU Grants-in-Aid for Scientific Research [16K00169] Funding Source: KAKEN
CR Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   Bertails F, 2006, ACM T GRAPHIC, V25, P1180, DOI 10.1145/1141911.1142012
   Guan Peng, 2012, P 11 ACM SIGGRAPHEUR, P295
   Hahn Fabian, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601160
   Han D., 2012, P VRIPHYS 2012, P45
   James DL, 2003, ACM T GRAPHIC, V22, P879, DOI 10.1145/882262.882359
   Kim DY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462020
   Kim T., 2013, ACM T GRAPHIC, V32
   Koh CK, 2000, SPRING COMP SCI, P101
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Nguyen H., 2005, GPU Gems, V2, P361
   Robbins C.R., 2002, CHEM PHYS BEHAV HUMA, V4th, DOI DOI 10.1007/978-3-642-25611-0
   Selle A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360663
   Stanton M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601196
   Xu F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601210
NR 15
TC 2
Z9 2
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 221
EP 230
DI 10.1002/cav.1700
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300006
DA 2024-07-18
ER

PT J
AU Vogt, D
   Lorenz, B
   Grehl, S
   Jung, B
AF Vogt, David
   Lorenz, Ben
   Grehl, Steve
   Jung, Bernhard
TI Behavior generation for interactive virtual humans using
   context-dependent interaction meshes and automated constraint extraction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE virtual agents; human-agent interaction; interaction mesh; motion
   adaption
ID MOTION
AB Interaction meshes are a promising approach for generating natural behaviors of virtual characters during ongoing user interactions. In this paper, we propose several extensions to the interaction mesh approach based on statistical analyses of the underlying example interactions. By applying principal component analysis and correlation analysis in addition to joint distance calculations, both the interaction mesh topology and the constraints used for mesh optimization can be generated in an automated fashion that accounts for the spatial and temporal contexts of the interaction. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Vogt, David; Lorenz, Ben; Grehl, Steve; Jung, Bernhard] Tech Univ Bergakad Freiberg, Inst Informat, D-09599 Freiberg, Germany.
C3 Technical University Freiberg
RP Vogt, D (corresponding author), Tech Univ Bergakad Freiberg, Inst Informat, Bernhard von Cotta Str 2, D-09599 Freiberg, Germany.
EM david.vogt@informatik.tu-freiberg.de
RI Grehl, Steve/AAU-7977-2020
CR [Anonymous], 2014, P 20 ACM S VIRT REAL
   Ben Amors H, 2010, THESIS
   Hos ESL, 2013, ACM T MULTIM COMPUT, V9
   Hos ESL, 2010, ACM T GRAPHIC, P29
   Hos ESL, 2013, P 2013 IEEE INT C RO
   Nakaoka S, 2012, IEEE-RAS INT C HUMAN, P625, DOI 10.1109/HUMANOIDS.2012.6651585
   Ntouskoss V, 2012, INT C COMP VIS THEOR
   Roudposhti KK, 2013, PATTERN RECOGN LETT, V34, P820, DOI 10.1016/j.patrec.2012.09.021
   Tang JKT, 2008, COMPUT ANIMAT VIRT W, V19, P211, DOI 10.1002/cav.260
   Vogt D, 2014, LECT NOTES ARTIF INT, V8637, P463, DOI 10.1007/978-3-319-09767-1_57
NR 10
TC 5
Z9 5
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 227
EP 235
DI 10.1002/cav.1648
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700005
DA 2024-07-18
ER

PT J
AU Sasaki, N
   Chen, HT
   Sakamoto, D
   Igarashi, T
AF Sasaki, Naoki
   Chen, Hsiang-Ting
   Sakamoto, Daisuke
   Igarashi, Takeo
TI Facetons: face primitives for building 3D architectural models in
   virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE geometric modeling; polygonal mesh; virtual reality
AB We present facetons, geometric modeling primitives designed for building architectural models especially effective for a virtual environment where six degrees of freedom input devices are available. A faceton is an oriented point floating in the air and defines a plane of infinite extent passing through the point. The polygonal mesh model is constructed by taking the intersection of the planes associated with the facetons. With the simple interaction of faceton, users can easily create 3D architecture models. The faceton primitive and its interaction reduce the overhead associated with standard polygonal mesh modeling, where users have to manually specify vertexes and edges which could be far away. The faceton representation is inspired by the research on boundary representations (B-rep) and constructive solid geometry, but it is driven by a novel adaptive bounding algorithm and is specifically designed for 3D modeling activities in an immersive virtual environment. We describe the modeling method and our current implementation. The implementation is still experimental but shows potential as a viable alternative to traditional modeling methods. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Sasaki, Naoki; Chen, Hsiang-Ting; Sakamoto, Daisuke; Igarashi, Takeo] Univ Tokyo, JST ERATO Igarashi Design Interface Project, Tokyo, Japan.
C3 University of Tokyo
RP Sasaki, N (corresponding author), Univ Tokyo, JST ERATO Igarashi Design Interface Project, Tokyo, Japan.
EM naoki.sasaki@ui.is.s.u-tokyo.ac.jp
RI Sakamoto, Daisuke/AAA-5428-2022; Igarashi, Takeo/ITT-5921-2023; Chen,
   Hsiang-Ting/W-9252-2019
OI Sakamoto, Daisuke/0000-0002-2219-4198; Chen,
   Hsiang-Ting/0000-0003-0873-2698
CR Anderson L., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P57, DOI 10.1145/769953.769960
   [Anonymous], 2013, IEEE 3DUI 2013 CONT
   Bourdot P, 2010, COMPUT AIDED DESIGN, V42, P445, DOI 10.1016/j.cad.2008.10.014
   Branits B, 2007, WORLD BUILDER
   Butterworth J., 1992, Proceeding of the Symposium on Interactive 3D Graphics, P135, DOI DOI 10.1145/147156.147182
   Fernando T., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P147, DOI 10.1145/323663.323686
   GALYEAN TA, 1991, COMP GRAPH, V25, P267, DOI 10.1145/127719.122747
   Hagens H, 1991, GEOMETRIC MODELING M
   Lau M., 2012, ACM Conference on Tangible, Embedded and Embodied Interaction (TEI'12), P275
   Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X
   Ma WY, 2004, COMPUT AIDED DESIGN, V36, P903, DOI 10.1016/j.cad.2003.09.001
   Matsumiya M., 2000, Proceedings of the ACM symposium on Virtual reality software and technology, P67
   Raposo A, 2009, IEEE COMPUT GRAPH, V29, P91, DOI 10.1109/MCG.2009.118
   Salamin Patrick, 2006, Proceedings of the ACM symposium on Virtual reality software and technology, P27
   Schells B, 2000, US Patent, Patent No. 6628279
   Schkolne S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P261, DOI 10.1145/365024.365114
   Schmidt R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618495
   Strouds I, 2006, BOUNDARY REPRESENTAT
   Tsangs EKH, 1998, VRST 98 TAIP TAIW, P179
   Zeleznik R. C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P163, DOI 10.1145/237170.237238
NR 20
TC 2
Z9 2
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2015
VL 26
IS 2
BP 185
EP 194
DI 10.1002/cav.1603
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CG3GB
UT WOS:000353165400009
DA 2024-07-18
ER

PT J
AU Shum, HPH
   Hoyet, L
   Ho, ESL
   Komura, T
   Multon, F
AF Shum, Hubert P. H.
   Hoyet, Ludovic
   Ho, Edmond S. L.
   Komura, Taku
   Multon, Franck
TI Natural preparation behavior synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE preparation behavior; motion synthesis; reinforcement learning; motion
   blending; posture optimization
AB Humans adjust their movements in advance to prepare for the forthcoming action, resulting in efficient and smooth transitions. However, traditional computer animation approaches such as motion graphs simply concatenate a series of actions without taking into account the following one. In this paper, we propose a new method to produce preparation behaviors using reinforcement learning. As an offline process, the system learns the optimal way to approach a target and to prepare for interaction. A scalar value called the level of preparation is introduced, which represents the degree of transition from the initial action to the interacting action. To synthesize the movements of preparation, we propose a customized motion blending scheme based on the level of preparation, which is followed by an optimization framework that adjusts the posture to keep the balance. During runtime, the trained controller drives the character to move to a target with the appropriate level of preparation, resulting in a humanlike behavior. We create scenes in which the character has to move in a complex environment and to interact with objects, such as crawling under and jumping over obstacles while walking. The method is useful not only for computer animation but also for real-time applications such as computer games, in which the characters need to accomplish a series of tasks in a given environment. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Shum, Hubert P. H.] Northumbria Univ, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
   [Hoyet, Ludovic] Univ Dublin Trinity Coll, Dublin 2, Ireland.
   [Ho, Edmond S. L.] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Komura, Taku] Univ Edinburgh, Sch Informat, Inst Percept Act & Behav, Edinburgh EH8 9YL, Midlothian, Scotland.
   [Multon, Franck] Univ Rennes 2, F-35043 Rennes, France.
C3 Northumbria University; Trinity College Dublin; Hong Kong Baptist
   University; University of Edinburgh; Universite Rennes 2; Universite de
   Rennes
RP Shum, HPH (corresponding author), Northumbria Univ, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
EM hubert.shum@northumbria.ac.uk
RI Ho, Edmond S. L./JDW-1835-2023; Hoyet, Ludovic/IWU-9100-2023; Shum,
   Hubert P. H./E-8060-2015
OI Ho, Edmond S. L./0000-0001-5862-106X; Hoyet,
   Ludovic/0000-0002-7373-6049; Shum, Hubert P. H./0000-0001-5651-6039;
   Multon, Franck/0000-0003-2690-0077
CR [Anonymous], REINFORCEMENT LEARNI
   [Anonymous], ANTHROPOMETRY MASS D
   [Anonymous], P INT C COMP GAM ART
   [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], 13D 08 P 2008 S INT
   [Anonymous], SIGGRAPH 05 ACM SIGG
   [Anonymous], SIGGRAPH 88 P 15 ANN
   [Anonymous], SCA 04 P 2004 ACM SI
   [Anonymous], SCA 05 P 2005 ACM SI
   [Anonymous], SCA 06 P 2006 ACM SI
   [Anonymous], ACM T GRAPH
   [Anonymous], 2002, ACM T GRAPHIC
   [Anonymous], 166 CUEDFINFENGTR
   [Anonymous], ACM T GRAPH
   [Anonymous], BRAZIL
   [Anonymous], SIGGRAPH 02 P 29 ANN
   [Anonymous], ACM T GRAPHICS
   [Anonymous], GAM DEV C P
   [Anonymous], P 22 ANN C COMP GRAP
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Fang AC, 2003, ACM T GRAPHIC, V22, P417, DOI 10.1145/882262.882286
   Gleicher M, 1998, J VISUAL COMP ANIMAT, V9, P65, DOI 10.1002/(SICI)1099-1778(199804/06)9:2<65::AID-VIS176>3.0.CO;2-Z
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   KWON T., 2005, SCA 05, P29
   McCann J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276385, 10.1145/1239451.1239457]
   Ménardais S, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P156, DOI 10.1109/CGI.2004.1309206
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   Safonovas A, 2007, SIGGRAPH 07 ACM SIGG, P1
   Shum HPH, 2012, IEEE T VIS COMPUT GR, V18, P741, DOI 10.1109/TVCG.2010.257
   Shum HPH, 2009, COMPUT ANIMAT VIRT W, V20, P385, DOI 10.1002/cav.315
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
   Zordan V, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P81
NR 32
TC 1
Z9 2
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2014
VL 25
IS 5-6
BP 531
EP 542
DI 10.1002/cav.1546
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AR9DE
UT WOS:000343871000003
DA 2024-07-18
ER

PT J
AU Um, K
   Kim, TY
   Kwon, Y
   Han, J
AF Um, Kiwon
   Kim, Tae-Yong
   Kwon, Youngdon
   Han, JungHyun
TI Porous deformable shell simulation with surface water flow and
   saturation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE shell simulation; fluid simulation; absorption; diffusion; tearing
ID ANIMATION; BODIES; FLUID
AB This paper proposes a method for simulating the dynamics of porous deformable shells in the presence of water that floats on the surface or is absorbed into the interior. The proposed method enables various effects such as surface flow, capillary flow involving absorption and saturation of water, changes of the material properties caused by water saturation, and the deformable body dynamics including tearing. The experiments demonstrate that the proposed method produces promising results.Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Um, Kiwon; Han, JungHyun] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Kim, Tae-Yong] NVIDIA, PhysX Grp, Seoul, South Korea.
   [Kwon, Youngdon] Sungkyunkwan Univ, Sch Chem Engn, Gyeonggi Do, South Korea.
C3 Korea University; Sungkyunkwan University (SKKU)
RP Han, J (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM jhan@korea.ac.kr
RI Um, Kiwon/AAO-6776-2020
OI /0000-0002-4139-9308; Kwon, Youngdon/0000-0002-2001-0113
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA) in the Culture Technology (CT) Research and Development
   Program
FX This research is supported by the Ministry of Culture, Sports and
   Tourism (MCST) and Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) Research and Development Program 2012.
CR [Anonymous], 2002, SURFACES
   [Anonymous], 1994, INTRO CONJUGATE GRAD
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Batty C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276502
   Bridson R., 2008, Fluid Simulation
   Carlson M, 2004, ACM T GRAPHIC, V23, P377, DOI 10.1145/1015706.1015733
   Chentanez N., 2006, ACM SIG- GRAPH/Eurographics Symposium on Computer Animation, P83
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   Curtis C. J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P421, DOI 10.1145/258734.258896
   Djado K, 2012, COMPUT ANIMAT VIRT W, V23, P301, DOI 10.1002/cav.1446
   English E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360665
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Goldenthal R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239500
   Guendelman E, 2005, ACM T GRAPHIC, V24, P973, DOI 10.1145/1073204.1073299
   HARLOW FH, 1965, PHYS FLUIDS, V8, P2182, DOI 10.1063/1.1761178
   Huber M., 2011, COMP GRAPH INT WORKS
   Irving G, 2006, ACM T GRAPHIC, V25, P805, DOI 10.1145/1141911.1141959
   Kaufmann P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531356
   Lenaerts T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360648
   Li Y, 2003, TEXT RES J, V73, P515
   Metaaphanon N, 2009, COMPUT GRAPH FORUM, V28, P1837, DOI 10.1111/j.1467-8659.2009.01561.x
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Mullen P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239517, 10.1145/1276377.1276459]
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   Robinson-Mosher A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360645
   Sethian J., 1999, LEVEL SET METHODS FA
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   TERZOPOULOS D., 1988, SIGGRAPH COMPUT GRAP, V22, P269
   Wang HM, 2005, ACM T GRAPHIC, V24, P921, DOI 10.1145/1073204.1073284
   Washburn EW, 1921, PHYS REV, V17, P273, DOI 10.1103/PhysRev.17.273
   Zhang YZ, 2012, IEEE T VIS COMPUT GR, V18, P1281, DOI 10.1109/TVCG.2011.141
NR 37
TC 9
Z9 12
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 247
EP 254
DI 10.1002/cav.1497
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500012
DA 2024-07-18
ER

PT J
AU Ennis, C
   O'Sullivan, C
AF Ennis, Cathy
   O'Sullivan, Carol
TI Perceptually plausible formations for virtual conversers
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE perception; virtual social groups
ID INTERPERSONAL DISTANCE
AB Recent progress in real-time simulations has led to a higher demand for believability from virtual characters. Background characters are becoming a more integral part of games, with emphasis being placed in particular on interactions between them. Conversing groups can play a significant role in adding plausibility, or a sense of presence, to a real-time simulation. However, it is not obvious how best to generate and vary these kinds of groups. In this paper, using anthropological standards for interacting distances and formations, we conduct a series of experiments to examine how these parameters inherent in human conversation are perceived for virtual characters. Our results show that, although participants were sensitive to both distance and orientation changes between talkers and listeners in a virtual conversation, they were not as sensitive to anomalous gesturing behaviours across different distances. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Ennis, Cathy; O'Sullivan, Carol] Univ Utrecht, Games Media & Agent Technol Grp, Utrecht, Netherlands.
   [Ennis, Cathy] Trinity Coll Dublin, Graph Vis & Visualisat Grp, Dublin, Ireland.
   [Ennis, Cathy] Univ Utrecht, Games & Virtual Worlds Grp, Utrecht, Netherlands.
C3 Utrecht University; Trinity College Dublin; Utrecht University
RP Ennis, C (corresponding author), Univ Utrecht, Games Media & Agent Technol Grp, Utrecht, Netherlands.
EM c.ennis@uu.nl
OI O'Sullivan, Carol/0000-0003-3772-4961; Ennis, Cathy/0000-0002-1274-5347
FU Science Foundation Ireland
FX We would like to thank the Science Foundation Ireland, who funded this
   work as part of the Natural Movers Project.
CR AIELLO JR, 1977, SOCIOMETRY, V40, P271, DOI 10.2307/3033534
   ARGYLE M, 1965, SOCIOMETRY, V28, P289, DOI 10.2307/2786027
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Ennis C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778828
   Hall Edward Twitchell, 1966, HIDDEN DIMENSION
   Herrera D, 2011, LECT NOTES COMPUT SC, V6766, P450, DOI 10.1007/978-3-642-21663-3_48
   Jan D., 2007, Proceedings of the Workshop on Embodied Language Processing, P59, DOI DOI 10.1145/1329125.1329142
   Kendon A, 2010, LECT NOTES COMPUT SC, V5967, P1
   Kendon Adam, 1990, CUP Archive, P153
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Pedica C, 2008, LECT NOTES COMPUT SC, V5208, P104
   Pedica C, 2009, LECT NOTES ARTIF INT, V5773, P344, DOI 10.1007/978-3-642-04380-2_38
   THOMPSON DE, 1979, J NONVERBAL BEHAV, V4, P113, DOI 10.1007/BF01006355
NR 13
TC 21
Z9 23
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 321
EP 329
DI 10.1002/cav.1453
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100019
DA 2024-07-18
ER

PT J
AU Zeng, M
   Liang, L
   Liu, XG
   Bao, HJ
AF Zeng, Ming
   Liang, Lin
   Liu, Xinguo
   Bao, Hujun
TI Video-driven state-aware facial animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE facial animation; face state recognition; video-driven animation;
   state-aware face action estimation
AB It is important in computer animation to synthesize expressive facial animation for avatars from videos. Some traditional methods track a set of semantic feature points on the face to drive the avatar. However, these methods usually suffer from inaccurate detection and sparseness of the feature points and fail to obtain high-level understanding of facial expressions, leading to less expressive and even wrong expressions on the avatar. In this paper, we propose a state-aware synthesis framework. Instead of simply fitting 3D face to the 2D feature points, we use expression states obtained by a set of low-cost classifiers?(based on local binary pattern and support vector machine) on the face texture to guide the face fitting procedure. Our experimental results show that the proposed hybrid framework enjoys the advantages of the original methods based on feature point and the awareness of the expression states of the classifiers and thus vivifies and enriches the face expressions of the avatar. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Zeng, Ming; Liu, Xinguo; Bao, Hujun] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
   [Liang, Lin] Microsoft Corp, Seattle, WA USA.
C3 Zhejiang University; Microsoft
RP Liu, XG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
EM xgliu@cad.zju.edu.cn
RI Zeng, Ming/GXF-3628-2022
OI Zeng, Ming/0000-0003-2836-9240
FU NSFC [60970074]; China 973 Program [2009CB320801]; Fok Ying Tung
   Education Foundation; Fundamental Research Funds for the Central
   Universities
FX Many thanks to Xin Tong and Jian Sun for fruitful discussions; Luoying
   Liu, Tao Wang, and Lin Zhou for providing the CG characters; and the
   anonymous reviewers for their valuable comments. This work was partially
   supported by NSFC (No. 60970074), China 973 Program (No. 2009CB320801),
   Fok Ying Tung Education Foundation, and the Fundamental Research Funds
   for the Central Universities.
CR Ahlberg J., 2001, CANDIDE-3 -- an updated parameterized face
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229
   Chuang E, 2005, ACM T GRAPHIC, V24, P331, DOI 10.1145/1061347.1061355
   Chuang E, 2002, SUCSTR200202
   DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811
   Deng Z., 2006, Proc. of ACM SIGGGRAPH/Eurographics Symposium on Computer Animation, P251
   Deng Z.et., 2008, Proc. of 2008 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P67
   Ekman P, 1994, NATURE EMOTIONL FUND
   Ekman P., 1978, Facial action coding system
   Fidaleo D, 1999, INT C DIG COMP VID T
   Har-Peled Sariel., 2003, ADV NEURAL INFORM PR, V15, P785
   Jin-xiang Chai, 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P193
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   Parke W, 1996, COMPUTER FACIAL ANIM
   Pighin F., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P143, DOI 10.1109/ICCV.1999.791210
   Rhee T., 2011, Proceedings of the 2011 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '11, P215
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Williams L., 1990, Proceedings of SIGGRAPH, V24, P235
   Williams Lance, 2006, ACM SIGGRAPH 2006 CO
   Zalewski L, 2005, PROC CVPR IEEE, P217
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang W, 2008, LECT NOTES COMPUT SC, V5303, P720, DOI 10.1007/978-3-540-88688-4_53
   Zhou MC, 2010, PROC CVPR IEEE, P701, DOI 10.1109/CVPR.2010.5540146
NR 32
TC 11
Z9 14
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 167
EP 178
DI 10.1002/cav.1455
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100005
DA 2024-07-18
ER

PT J
AU Liang, XB
   Li, QL
   Zhang, X
   Zhang, S
   Geng, WD
AF Liang, Xiubo
   Li, Qilei
   Zhang, Xiang
   Zhang, Shun
   Geng, Weidong
TI Performance-driven motion choreographing with accelerometers
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE motion recognition; motion editing; accelerometers; perceptual user
   interface
AB Live performance is air intuitive Way to naturally draft tire desired motion in the choreographer's mind. In this paper We present a travel approach to choreographing motions by live performance captured With degree of freedom (3-DOF) accelerometers. The process be gins by placing tire accelerometers air tire riser's limbs according to tire pre-specified positions. Tire computer then recognizes tire performed actions using Hidden Markov Model (HMM), Which is pre-trained by the acceleration data samples automatically generated from a pre-segmented motion capture database. At last, the captured actions are further synthesized with motion retiming and exaggeration based on tire acceleration signals from the accelerometers. This method can intuitively rap id-pro to type the choreographed motions for pre-production of animation, the avatar control in virtual reality and game-like scenarios, etc. The experimental results show that it can effectively recognize actions with spatial-time variance, and is easy-to-use especially for a novice with little experience. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Zhang, Shun; Geng, Weidong] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Zhang, Xiang] Zhejiang Univ, Dept Comp Sci, Hangzhou 310027, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Geng, WD (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, 38 Zheda Rd, Hangzhou 310027, Peoples R China.
EM gengwd@zju.edu.cn
CR Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Dontcheva M, 2003, ACM T GRAPHIC, V22, P409, DOI 10.1145/882262.882285
   HSU E, 2007, P ACM SIGGRAPH EUR S, P45
   Kallio S, 2006, INT J PATTERN RECOGN, V20, P505, DOI 10.1142/S0218001406004776
   Kay S, 2000, IEEE SIGNAL PROC LET, V7, P8, DOI 10.1109/97.809511
   Lasseter John., 1987, Proceedings of the 14th annual conference on Computer graphics and interactive techniques, P35
   Liang X., 2008, P COMP GRAPH INT, P64
   Liu Guodong., 2006, Proceedings of the 2006 symposium on Interactive 3D graphics and games, P35
   Mantyjarvi J., 2004, Proceedings of the 3rd international conference on Mobile and ubiquitous multimedia - MUM '04, P25
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ren L, 2005, ACM T GRAPHIC, V24, P1303, DOI 10.1145/1095878.1095882
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Shiratori T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409076
   SLYPER R, 2008, P ACM SIGGRAPH EUR S
   Smith L.I., 2002, Statistics
   Sturman DJ, 1998, IEEE COMPUT GRAPH, V18, P38, DOI 10.1109/38.637269
   Vlasic D, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276421, 10.1145/1239451.1239486]
   YIN K, 2003, P 2003 ACM SIGGRAPH, P329
NR 19
TC 11
Z9 18
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 89
EP 99
DI 10.1002/cav.311
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700003
DA 2024-07-18
ER

PT J
AU Assassi, L
   Charbonnier, C
   Schmid, J
   Volino, P
   Magnenat-Thalmann, N
AF Assassi, Lazhari
   Charbonnier, Caecilia
   Schmid, Jerome
   Volino, Pascal
   Magnenat-Thalmann, Nadia
TI From MRI to anatomical simulation of the hip joint
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE anatomical modeling; physical-based simulation; hip motion analysis;
   computer simulation; hip osteoarthritis
ID SKIN MOVEMENT ARTIFACT; MESH GENERATION; ADVANCING-FRONT; ALGORITHM;
   POSITION; MUSCLE; MODEL
AB This paper describes a methodology for the simulation of musculoskeletal disorders. Our clinical study is related to osteoarthritis (OA) of the hip, a pathogenesis possibly due to impingements. These bone collisions lead to abnormal joint mechanics which is characterized by contact pressure and stress distribution upon the joint cartilages. The proposed methodology combines different approaches from modeling to simulation. The simulation is based oil patient-specific anatomical models, where acquisition modalities are noninvasive and flexible. Based on static magnetic resonance imaging (MRI) data, a discrete deformable models method is used for modeling the organs of the musculoskeletal system. Femoroacetabular movements are estimated using all optical motion capture system and are validated by a dynamic MRI analysis. To achieve accurate deformations, techniques to generate volumetric meshes are developed based on the medial axis (MA) information. Finally, a computationally efficient fast functional joint model is used to simulate the mechanical behavior of the soft tissues. The goal of such a simulation is to allow the investigation of the relevant contact and cartilages deformation under movement, which call be useful for diagnosis, pro- or post- operative planning and training. This will benefit further developments in surgical techniques and minimally invasive procedures. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Assassi, Lazhari; Volino, Pascal] Univ Geneva, MIRA Lab, CH-1227 Geneva, Switzerland.
C3 University of Geneva
RP Assassi, L (corresponding author), Univ Geneva, MIRA Lab, Bldg A,7 Route Drize, CH-1227 Geneva, Switzerland.
EM lazhari.assassi@miralab.unige.ch
RI Thalmann, Nadia/AAK-5195-2021; Charbonnier, Caecilia/HLV-7680-2023
OI Thalmann, Nadia/0000-0002-1459-5960; Charbonnier,
   Caecilia/0000-0002-7018-885X; assassi, Lazhari/0000-0002-2551-7431;
   Schmid, Jerome/0000-0003-2464-8971
FU Swiss National Research Foundation; European Union [MRTN-CT-2006-035763]
FX This work is supported by the Co-Me project funded by Swiss National
   Research Foundation and by the 3D Anatomical Human project
   (MRTN-CT-2006-035763) funded by the European Union. We would like to
   thank the University Hospital of Geneva for their help and precious
   advice.
CR AHMET CC, 2007, TRENDS BIOMATERIALS, V21, P63
   Alexander EJ, 2001, J BIOMECH, V34, P355, DOI 10.1016/S0021-9290(00)00192-5
   ALLIEZ P, 2005, SIGGRAPH 2005, P617
   [Anonymous], EUROGRAPHICS
   [Anonymous], 1995, FINITE ELEMENT PROCE
   [Anonymous], 2004, P 2004 ACM SIGGRAPH, DOI DOI 10.1145/1028523.1028541
   ARBABI E, 2007, COMPUTER ASSISTED OR, P497
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   BARBIC J, 2005, ACM T GRAPH
   Benoit DL, 2006, GAIT POSTURE, V24, P152, DOI 10.1016/j.gaitpost.2005.04.012
   Blemker SS, 2005, ANN BIOMED ENG, V33, P661, DOI 10.1007/s10439-005-1433-7
   BLUM H, 1964, S MOD PERC SPEECH VI, P139
   Bonet J., 1997, Nonlinear continuum mechanics for finite element analysis
   BRONIELSEN M, 1996, EUROGRAPHICS, P21
   Cappello A, 1997, HUM MOVEMENT SCI, V16, P259, DOI 10.1016/S0167-9457(96)00055-3
   Cappozzo A, 1996, CLIN BIOMECH, V11, P90, DOI 10.1016/0268-0033(95)00046-1
   Cereatti A, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-7
   CHENG SW, 2002, ACM SIAM S DISCR ALG, P137
   Cootes T. F., 1993, Information Processing in Medical Imaging. 13th International Conference, IPMI '93 Proceedings, P33, DOI 10.1007/BFb0013779
   Cotin S, 1999, IEEE T VIS COMPUT GR, V5, P62, DOI 10.1109/2945.764872
   Crouch JR, 2003, LECT NOTES COMPUT SC, V2878, P108
   CUTLER B, 2004, EUR ACM SIGGRAPH S G, P95
   Delingette H, 1999, INT J COMPUT VISION, V32, P111, DOI 10.1023/A:1008157432188
   Etzmuss O, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P244, DOI 10.1109/PCCGA.2003.1238266
   Ganz R., 2003, CLIN ORTHOP RELAT R, P112, DOI DOI 10.1097/01.BL0.0000096804.78689.C2
   Gilles B, 2005, ACAD RADIOL, V12, P1285, DOI 10.1016/j.acra.2005.08.006
   GILLES B, 2007, THESIS U GENEVE
   Gilles B, 2006, LECT NOTES COMPUT SC, V4190, P289
   Hadwiger Marcus., 2004, STATE ART REPORT 200
   Hang S., TetGen: A Quality Tetrahedral Mesh Generator and Three-Dimensional Delaunay Triangulator
   HAUTH M, 2003, EUR S COMP AN, P17
   Hauth M., 2004, PROC WSCG, V12, P137
   HAUTH M, 2001, EUROGRAPHICS 01, P137
   Hirota G., 2001, COMPUTER ANIMATION
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KUMAGAI M, 2003, SUMM BIOENG C, P53
   Lawrence CT, 2001, SIAM J OPTIMIZ, V11, P1092, DOI 10.1137/S1052623498344562
   Lefohn AE, 2004, IEEE T VIS COMPUT GR, V10, P422, DOI 10.1109/TVCG.2004.2
   Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835
   Li XY, 2000, INT J NUMER METH ENG, V49, P61, DOI 10.1002/1097-0207(20000910/20)49:1/2<61::AID-NME923>3.3.CO;2-P
   Lu TW, 1999, J BIOMECH, V32, P129, DOI 10.1016/S0021-9290(98)00158-4
   Lucchetti L, 1998, J BIOMECH, V31, P977, DOI 10.1016/S0021-9290(98)00083-9
   MACIEL A, 2005, COMPUTER ASSISTED OR, P298
   Manal K, 2002, GAIT POSTURE, V15, P10, DOI 10.1016/S0966-6362(01)00174-6
   Martin HD, 2005, OPER TECH ORTHOP, V15, P177, DOI 10.1053/j.oto.2005.07.008
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Michaeli DA, 1997, MED ENG PHYS, V19, P180, DOI 10.1016/S1350-4533(96)00051-3
   Molino N., 2003, INT MESHING ROUNDTAB, P103
   Müller M, 2004, PROC GRAPH INTERF, P239
   MURDOCH P, 1995, INT MESHING ROUNDTAB, P243
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Picinbono G, 2003, GRAPH MODELS, V65, P305, DOI 10.1016/S1524-0703(03)00045-6
   Pizer SM, 2003, INT J COMPUT VISION, V55, P85, DOI 10.1023/A:1026313132218
   Price MA, 1997, INT J NUMER METH ENG, V40, P111, DOI 10.1002/(SICI)1097-0207(19970115)40:1<111::AID-NME56>3.0.CO;2-K
   Radovitzky R, 2000, COMPUT METHOD APPL M, V187, P543, DOI 10.1016/S0045-7825(99)00339-4
   RANZUGLIA G, 2006, EUROGRAPHICS ITALIAN, P213
   RUSSELL ME, 2006, J ORTHOPTERA RES, V1, P169
   Sato Y, 2000, LECT NOTES COMPUT SC, V1935, P1114
   Scheepers F., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P163, DOI 10.1145/258734.258827
   Schmitt J, 2001, MED ENG PHYS, V23, P529, DOI 10.1016/S1350-4533(01)00085-6
   Schneiders R, 1996, ENG COMPUT, V12, P168, DOI 10.1007/BF01198732
   SCHNEIDERS R, 1993, ENG COMPUTING, V2, P83
   SHEPHARD MS, 1991, INT J NUMER METH ENG, V32, P709, DOI 10.1002/nme.1620320406
   Shewchuk J. R., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P86, DOI 10.1145/276884.276894
   Shewchuk J.R., 2002, Eleventh International Meshing Roundtable, P193
   SOUSSOU JE, 1970, J RHEOL, V14, P573
   Stagni R, 2005, CLIN BIOMECH, V20, P320, DOI 10.1016/j.clinbiomech.2004.11.012
   STAIB LH, 1992, P SOC PHOTO-OPT INS, V1808, P90, DOI 10.1117/12.131070
   Tautges TJ, 1996, INT J NUMER METH ENG, V39, P3327
   Teran J, 2005, IEEE T VIS COMPUT GR, V11, P317, DOI 10.1109/TVCG.2005.42
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Volino P, 2005, COMPUT ANIMAT VIRT W, V16, P163, DOI 10.1002/cav.78
   Volino P, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P257, DOI 10.1109/CGI.2000.852341
   Wang YM, 2000, MED IMAGE ANAL, V4, P7, DOI 10.1016/S1361-8415(00)00004-9
   Yao JH, 2000, LECT NOTES COMPUT SC, V1935, P531
   ZHANG Y, 2003, ACM S SOL MOD APPL, P286
   WEBPAGE 3D ANATOMICA
NR 77
TC 12
Z9 14
U1 1
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2009
VL 20
IS 1
BP 53
EP 66
DI 10.1002/cav.266
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 407WD
UT WOS:000263394100006
DA 2024-07-18
ER

PT J
AU Rueda, S
   Morillo, P
   Orduña, JM
AF Rueda, S.
   Morillo, P.
   Orduna, J. M.
TI A comparative study of awareness methods for peer-to-peer distributed
   virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE distributed virtual environments; peer-to-peer architectures; awareness
   methods
ID PERFORMANCE
AB The increasing popularity of multi-player online games is leading to the widespread use of large-scale Distributed Virtual Environments (DVEs) nowadays. In these systems, peer-to-peer (P2P) architectures have been proposed as an efficient and scalable solution for supporting massively multi-player applications. However, the main challenge for P2P architectures consists of providing each avatar with updated information about which other avatars are its neighbors. This problem is known as the awareness problem. In this paper, we propose a comparative study of the performance provided by those awareness methods that are supposed to fully solve the awareness problem. This study is performed using well-known performance metrics in distributed systems. Moreover, while the evaluations shown in the literature are performed by executing P2P simulations on a single (sequential) computer, this paper evaluates the performance of the considered methods on actually distributed systems. The evaluation results show that only a single method actually provides full awareness to avatars. This method also provides the best performance results. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Orduna, J. M.] Univ Valencia, Dept Informat, GREV Res Grp, E-46100 Valencia, Spain.
   [Orduna, J. M.] Univ Politecn Valencia, Valencia, Spain.
C3 University of Valencia; Universitat Politecnica de Valencia
RP Orduña, JM (corresponding author), Univ Valencia, Dept Informat, GREV Res Grp, Av Vicent Andres Estelles S-N, E-46100 Valencia, Spain.
EM juan.orduna@uv.es
RI Rueda Pascual, Silvia/A-2132-2019; Morillo, Pedro/ABG-8408-2020; Orduña,
   Juan M./AAB-5732-2020
OI Rueda Pascual, Silvia/0000-0002-1020-706X; Orduña, Juan
   M./0000-0002-2932-0214; Morillo, Pedro/0000-0002-9506-9611
FU Spanish MEC; European Commission FEDER [CSD2006-00046,
   TIN2006-15516-CO4-04]
FX This work has been jointly supported by the Spanish MEC and European
   Commission FEDER funds under grants Consolider Ingenio-2010
   CSD2006-00046 and TIN2006-15516-CO4-04.
CR ALEXANDER T, 2005, MASSIVELY MULTIPLAYE, V2
   ANDERSON DB, 1995, IEEE MULTIMEDIA, V2, P77, DOI 10.1109/93.482298
   Androutsellis-Theotokis S, 2004, ACM COMPUT SURV, V36, P335, DOI 10.1145/1041680.1041681
   [Anonymous], 1999, Creating Computer Simulation Systems: an Introduction to the High Level Architecture
   BOURAS C, 1998, 4 INT C VIRT SYST MU
   Claypool M, 2005, COMPUT NETW, V49, P52, DOI 10.1016/j.comnet.2005.04.008
   CRONIN E, 2002, NETGAMES 02, P67
   Dias JMS, 1997, IEEE COMPUT GRAPH, V17, P55, DOI 10.1109/38.574682
   Duato J., 1997, INTERCONNECTION NETW
   *FIPA, 2000, FIP AG MAN SPEC
   Fujimoto RM, 1996, TENTH WORKSHOP ON PARALLEL AND DISTRIBUTED SIMULATION - PADS 96, PROCEEDINGS, P60, DOI 10.1109/PADS.1996.761563
   Gautier L, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P233, DOI 10.1109/MMCS.1998.693647
   GERNDT A, 2004, P 2004 ACM IEEE C SU, P50
   Greenhalgh C, 1997, PROCEEDINGS OF THE FIFTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P313
   Greenhalgh C, 2001, PRESENCE-TELEOP VIRT, V10, P142, DOI 10.1162/105474601750216777
   Greenhlagh F.C., 1998, Distributed Systems Engineering, V5, P129
   GUIBAS L, 1985, ACM T GRAPHIC, V4, P74, DOI 10.1145/282918.282923
   Henderson T., 2003, Proceedings of the ACM SIGCOMM 2003, P141
   Hu S.-Y., 2004, Proceedings of NetGames, Association for Computer Machinery, P129
   Hu SY, 2006, IEEE NETWORK, V20, P22, DOI 10.1109/MNET.2006.1668400
   *IEEE, 1997, 12781 IEEE
   Kawahara Y, 2004, TELECOMMUN SYST, V25, P353, DOI 10.1023/B:TELS.0000014789.70171.fd
   Keller J, 2003, PDPTA'03: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED PROCESSING TECHNIQUES AND APPLICATIONS, VOLS 1-4, P262
   Knutsson B, 2004, IEEE INFOCOM SER, P96
   Li LWF, 2006, IEEE T VIS COMPUT GR, V12, P989, DOI 10.1109/TVCG.2006.114
   Lui JCS, 2002, IEEE T PARALL DISTR, V13, P193, DOI 10.1109/71.993202
   Macedonia M. R., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P2, DOI 10.1109/VRAIS.1995.512473
   Macedonia MR, 1997, IEEE MULTIMEDIA, V4, P48, DOI 10.1109/93.580395
   MATIJASEVIC M, 1999, MACH INTELL, V1, P11
   Mauve M, 2004, IEEE T MULTIMEDIA, V6, P47, DOI 10.1109/TMM.2003.819751
   MILLER DC, 1955, P IEEE, V8, P1114
   Milojicic Dejan S., 2002, Technical Report
   MINAR N, 2001, P PEER TO PEER WEB S
   Mooney S., 1998, Battlezone: Official Strategy Guide
   Morillo P, 2006, INT CONF PARA PROC, P74, DOI 10.1109/ICPPW.2006.16
   Morillo P, 2006, LECT NOTES COMPUT SC, V4035, P336
   Morillo P, 2005, IEEE T PARALL DISTR, V16, P637, DOI 10.1109/TPDS.2005.83
   Morillo P, 2006, LECT NOTES COMPUT SC, V3980, P490
   Ng B., 2002, VRST 02, P163
   Oliveira M, 2001, PRESENCE-TELEOP VIRT, V10, P51, DOI 10.1162/105474601750182315
   Roberts D, 2004, EIGHTH IEEE INTERNATIONAL SYMPOSIUM ON DISTRIBUTED SIMULATION AND REAL-TIME APPLICATIONS, PROCEEDINGS, P46, DOI 10.1109/DS-RT.2004.13
   Rueda S, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P107
   SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930
   SAMET H, 1988, COMPUT SURV, V20, P271, DOI 10.1145/50020.50021
   Samet H, 2006, FDN MULTIDIMENSIONAL
   Singhal S., 1999, Networked Virtual Environments
   SMED J, 2002, 454 TURK CTR COMP SC
   Smith J. R., 1994, Proceedings ACM Multimedia '94, P279, DOI 10.1145/192593.192676
   Smith RandallB., 2001, Collaborative Virtual Environments, chapter Supporting Flexible Roles in a Shared Space
   WORTHAM S, TERRA3D
   Zhou S., 2004, ACM Transactions on Modeling and Computer Simulation, V14, P31, DOI 10.1145/974734.974736
NR 51
TC 6
Z9 6
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2008
VL 19
IS 5
BP 537
EP 552
DI 10.1002/cav.230
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 377KO
UT WOS:000261250300002
DA 2024-07-18
ER

PT J
AU Ben Amor, H
   Heumer, G
   Jung, B
   Vitzthum, A
AF Ben Amor, Heni
   Heumer, Guido
   Jung, Bernhard
   Vitzthum, Arnd
TI Grasp synthesis from low-dimensional probabilistic grasp models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE grasp synthesis; principal component analysis; Gaussian mixture models
AB We propose a novel data-driven animation method for the synthesis of natural looking human grasping. Motion data captured from human grasp actions is used to train a probabilistic model of the human grasp space. This model greatly reduces the high number of degrees of freedom of the human hand to a few dimensions ire a continuous grasp space. The low dimensionality of the grasp space in turn allows for efficient optimization when synthesizing grasps for arbitrary objects. The method requires only a short training phase with no need for preprocessing of graphical objects for which grasps are to be synthesized. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Ben Amor, Heni; Jung, Bernhard; Vitzthum, Arnd] TU Bergakad Freiberg, Inst Informat, VR & Multimedia Grp, D-09599 Freiberg, Germany.
C3 Technical University Freiberg
RP Ben Amor, H (corresponding author), TU Bergakad Freiberg, Inst Informat, VR & Multimedia Grp, Bernhardvon Cotta Str 2, D-09599 Freiberg, Germany.
EM amor@tu-freiberg.de
CR [Anonymous], STANF 3D SCANN REP
   [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], 2005, ACM SIGGRAPH EUR S C, DOI DOI 10.1145/1073368.1073413
   [Anonymous], 1994, The Grasping Hand
   BORST CW, 2005, VR 05
   CUTKOSKY MR, 1989, IEEE T ROBOTIC AUTOM, V5, P269, DOI 10.1109/70.34763
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Grassia F. S., 1998, J. Graph. Tools, V6, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]
   Kry PG, 2006, ACM T GRAPHIC, V25, P872, DOI 10.1145/1141911.1141969
   Li Y, 2007, IEEE T VIS COMPUT GR, V13, P732, DOI [10.1109/TVCG.2007.1033, 10.1109/TVCG.2007.1033.]
   Miller AT, 2003, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ROBOT.2003.1241930
   MOON A, 1996, IEEE C PHYS MOD BAS
   Pelleg D., 2000, P 17 INT C MACH LEAR, DOI DOI 10.1007/3-540-44491-2_3
   Rezzonicol S., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P107
   RIJPKEMA H, 1991, COMP GRAPH, V25, P339, DOI 10.1145/127719.122754
   SANSO RM, 1994, COMPUT GRAPH FORUM, V13, pC167, DOI 10.1111/1467-8659.1330167
   Santello M, 1998, J NEUROSCI, V18, P10105
   Schlesinger G., 1919, Der mechanische Aufbau der kunstlichen Glieder, in Ersatzglieder und Arbeitshilfen, P321, DOI [10.1007/978-3-662-33009-8, DOI 10.1007/978-3-662-33009-8]
   WEBER M, 2006, P 16 INT C ART REL T, P65
NR 19
TC 14
Z9 14
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 445
EP 454
DI 10.1002/cav.252
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200026
DA 2024-07-18
ER

PT J
AU Ting, SP
   Zhou, SP
AF Ting, Shang-Ping
   Zhou, Suiping
TI Snap: A time critical decision-making framework for MOUT simulations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE time critical decision making; virtual environments; Military Operations
   on Urban Terrain (MOUT)
AB Deliberative reasoning based oil the rational analysis of various alternatives often requires too much information and may be too slow in time critical situations. In these situations, humans rely mainly on their intuitions rather than some structured decision-making processes. An important and challenging problem in Military Operations oil Urban Terrain (MOUT) simulations is how to generate realistic tactical behaviors for the non-player characters (also known as bots), as these bots often need to make quick decisions in time-critical and uncertain situations. In this paper, we describe our work on Snap, a time critical decision-making framework for the bots in MOUT simulations. The novel features of Snap include case-based reasoning (CBR) and thin slicing. CBR is used to make quick decisions by comparing the current situation with past experience cases. Thin slicing is used to model human's ability to quickly form up situation awareness under uncertain and complex situations using key cues from partial information. To assess the effectiveness of Snap, we have integrated it into Twilight City, a virtual environment for MOUT simulations. Experimental results show that Snap is very effective in generating quick decisions during time critical situations for MOUT simulations. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Ting, Shang-Ping; Zhou, Suiping] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Ting, SP (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM ting0021@ntu.edu.sg
CR [Anonymous], 1998, EPIC GAMES UNREAL EN
   [Anonymous], 2007, SCI STRATEGY WAR STR
   [Anonymous], P 2 INT WORKSH INFR
   [Anonymous], 1932, REMEMBERING EXPT SOC
   AZUMA R, 2006, P 2006 IEEE AER C MT
   Ballard John R., 2006, Fighting for Fallujah: A New Dawn for Iraq
   BARRETT LF, 2007, SCIEMOTION WHAT PEOP, P13
   BREWER WF, 1981, COGNITIVE PSYCHOL, V13, P207, DOI 10.1016/0010-0285(81)90008-6
   De Mantaras RL, 2005, KNOWL ENG REV, V20, P215, DOI 10.1017/S0269888906000646
   EVANS K, 2006, WHAT SQUAD LEADERS W
   GLADWELL M, 2005, BLINK POWER THINK WI
   *HEADQ DEP ARM, 1979, 9010 FM HEADQ DEP AR
   *HEADQ DEP ARM, 2003, 306 FM HEADQ DEP ARM
   KARAGOSIAN JW, 2000, INFANTRY MAGAZINE
   Klein G. A., 2017, SOURCES POWER PEOPLE
   MARSHALL AN, 2003, JAVABOT UNREAL TOURN
   MCDERMOTT P. L, 2001, MILITARY OPERATIONS
   *PROJ GUT, 1910, ART WAR
   Schultz D. P, 1971, Panic in the Military
   STACEY CP, 1960, OFFICAL HIST CANADIA, V3
   Widmayer S. A., SCHEMA THEORY INTRO
   Wray RE, 2005, AI MAG, V26, P82
   WRAY RE, 2003, P BEH REPR MOD SIM C
   ZHOU SP, INT J COMPU IN PRESS
   ZHOU SP, 2006, 39 ANN SIM S HUNTSV
NR 25
TC 7
Z9 8
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 505
EP 514
DI 10.1002/cav.262
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200031
DA 2024-07-18
ER

PT J
AU Lee, MH
   Park, IK
AF Lee, Man Hee
   Park, In Kyu
TI Image-based modeling of 3D objects with curved surfaces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE image-based method; curved surface; NURBS; corresponding curve;
   interactive user interface; stereo reconstruction; surface modeling
ID SHAPE
AB This paper addresses an image-based method for modeling 3D objects with curved surfaces based on the non-uniform rational B-splines (NURBS) representation. The user fits the feature curves on a few calibrated images with 2D NURBS curves using the interactive user interface. Then, 3D NURBS curves are constructed by stereo reconstruction of the corresponding feature curves. Using these as building blocks, NURBS surfaces are reconstructed by the known surface building methods including bilinear surfaces, ruled surfaces, generalized cylinders, and surfaces of revolution. In addition to them, we also employ various advanced techniques, including skinned surfaces, swept surfaces, and boundary patches. Based on these surface modeling techniques, it is possible to build various types of 3D shape models with textured curved surfaces without much effort. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 [Lee, Man Hee; Park, In Kyu] Inha Univ, Sch Informat & Commun Engn, Inchon 402751, South Korea.
C3 Inha University
RP Park, IK (corresponding author), Inha Univ, Sch Informat & Commun Engn, 253 Yonghyun Dong, Inchon 402751, South Korea.
EM pik@inha.ac.kr
RI Park, In Kyu/B-5967-2013
OI Lee, Man Hee/0000-0002-5529-7548
CR [Anonymous], THESIS U CALIFORNIA
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   HARTLEY R, 2003, MNLTIPLE VIEW GEONZE
   KOSECKA J, 2004, SIGGRAPH 2004
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   LEE MH, 2006, P PAC GRAPH TAIP TAI, P70
   MAGNOR M, 2005, SIGGRAPH 2005 COURS
   MARTIN W, 1983, IEEE T PATTERN ANAL, V71, P789
   Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951
   McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Park SK, 2000, PHARMACOGENETICS, V10, P301, DOI 10.1097/00008571-200006000-00004
   Piegl L., 1997, The Nurbs Book, Vsecond
   POLLEFEYS M, 2003, SIGGRAPH 2003
   Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 17
TC 0
Z9 0
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2008
VL 19
IS 2
BP 93
EP 109
DI 10.1002/cav.216
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 296PY
UT WOS:000255559500003
DA 2024-07-18
ER

PT J
AU Vidal, FP
   John, NW
   Healey, AE
   Gould, DA
AF Vidal, F. P.
   John, N. W.
   Healey, A. E.
   Gould, D. A.
TI Simulation of ultrasound guided needle puncture using patient specific
   data with 3D textures and volume haptics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE medical virtual environment; imaging guidance; interventional radiology
   training; needle puncture; volume haptics; vertex and pixel shaders
AB We present an integrated system for training ultrasound (LIS) guided needle puncture. Our aim is to provide a validated training tool for interventional radiology (IR) that uses actual patient data. IR procedures are highly reliant on the sense of touch and so haptic hardware is an important part Of our solution. A hybrid surface/volume haptic rendering of an US transducer is proposed to constrain the device to remain outside the bony structures when scanning the patient's skin. A volume haptic model is proposed that implements an effective model of needle puncture. Force measurements have been made on real tissue and the resulting data is incorporated into the model. The other input data required is a computed tomography (CT) scan of the patient that is used to create the patient specific models. It is also the data source for a novel simulation of a virtual LIS scanner, which is used to guide the needle to the correct location. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 [Vidal, F. P.; John, N. W.] Univ Wales, Sch Comp Sci, Bangor, Gwynedd, Wales.
C3 Bangor University
RP John, NW (corresponding author), Univ Wales, Sch Comp Sci, Bangor, Gwynedd, Wales.
EM n.w.john@bangor.ac.uk
RI Vidal, Franck P/K-3348-2012; John, Nigel/ABC-8011-2020; Vidal,
   Franck/D-9887-2013
OI Vidal, Franck P/0000-0002-2768-4524; John, Nigel/0000-0001-5153-182X;
   Vidal, Franck/0000-0001-5059-8491
CR Aster R. C., 2018, PAR EST INV PROBL 3
   BECKER GJ, SIR CIRSE JOINT MED
   Brett PN, 1997, P I MECH ENG H, V211, P335, DOI 10.1243/0954411971534467
   Carrino JA, 2005, ACAD RADIOL, V12, P1063, DOI 10.1016/j.acra.2005.06.008
   Chapman GA, 2006, ANAESTHESIA, V61, P148, DOI 10.1111/j.1365-2044.2005.04475.x
   CONTI F, 2005, WORLD HAPT C WHC 05
   DAWSON SL, 1927, CATHETERIZATION CARD, V51, P522, DOI DOI 10.1002/1522-726X(200012)51:4<522::AID-CCD3.0.CO
   DiMaio SP, 2005, IEEE T BIO-MED ENG, V52, P1167, DOI 10.1109/TBME.2005.847548
   DIMAIO SP, 1953, MICCAI 02, P253
   FOREST C, 2007, P MMVR, P136
   GOBBETTI E, 2000, P MED MEETS VIRT REA, P96
   Gould DA, 2006, CARDIOVASC INTER RAD, V29, P4, DOI 10.1007/s00270-005-0354-z
   HEALEY AE, 2005, P MMVR, V13, P178
   Heijnsdijk EAM, 2004, SURG ENDOSC, V18, P980, DOI 10.1007/s00464-003-9244-0
   HOSTETTLER A, 2005, P MMVR, V13, P191
   Johnson S, 2006, CLIN RADIOL, V61, P97, DOI 10.1016/j.crad.2005.09.003
   JOHNSON S, 2007, BIOPSY ULTRASOUND GU
   Laycock S. D., 2007, Computer Graphics Forum, V26, P50, DOI 10.1111/j.1467-8659.2007.00945.x
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   MATALON TAS, 1990, RADIOLOGY, V174, P43, DOI 10.1148/radiology.174.1.2403684
   MERALD J, 1991, B ACAD NATL MED, V175, P1079
   OTTO R, 1980, RADIOLOGY, V134, P784, DOI 10.1148/radiology.134.3.7355237
   PEDERSEN JF, 1974, J UROLOGY, V112, P157, DOI 10.1016/S0022-5347(17)59669-X
   PERSSON E, 2005, ATI RADEON SDK DOCUM
   PETER VK, 2003, EFORT 6 C JUN
   Raspolli M, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P148
   Ruspini D. C., 1997, ANN C COMP GRAPH INT, P345, DOI DOI 10.1145/258734.258878
   Simone C, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2085, DOI 10.1109/ROBOT.2002.1014848
   Sklair-Levy M, 2000, EUR RADIOL, V10, P714, DOI 10.1007/s003300050991
   Vidal FP, 2006, COMPUT GRAPH FORUM, V25, P113, DOI 10.1111/j.1467-8659.2006.00822.x
   VIDAL FP, 2007, P MMVR, V15, P479
   VIDAL FP, 2005, P 19 INT C CARS COMP, P418, DOI DOI 10.1016/J.ICS.2005.03.200
   WATT A, 2000, COMPUTER GRAPHICS, P21
   ZHU Y, 2006, P MED IM UND AN MIUA, V1, P61
NR 34
TC 54
Z9 63
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2008
VL 19
IS 2
BP 111
EP 127
DI 10.1002/cav.217
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 296PY
UT WOS:000255559500004
DA 2024-07-18
ER

PT J
AU Mansa, I
   Amundarain, A
   Matey, L
   García-Alonso, A
AF Mansa, Ignacio
   Amundarain, Aiert
   Matey, Luis
   Garcia-Alonso, Alejandro
TI Analysis of coherence strategies for stereo occlusion culling
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE occlusion culling; stereoscopic visualization; temporal coherence;
   stereo coherence; haptic-immersive environment
ID VISIBILITY; VISUALIZATION
AB This paper explores the benefits that can be achieved for stereoscopic visualization when using occlusion culling strategies. Graphics processing units (GPUs) are improving their computational power and functionalities. On the other hand, models are also increasing their size and users require more demanding image quality. Occlusion culling provides significant frame rate speed-ups in densely occluded scenarios. This paper shows the limitations placed by compact and not densely occluded scenarios and the gains that can be achieved when rendering stereo images using occlusion culling. The experiments carried out test combinations of occlusion stereo coherence and occlusion frame coherence. The methods also take advantage of efficient depth sorting strategy and aggressive occlusion frame coherence, whose image artefacts have been found to be negligible. Results clearly point out that eye-independent frame coherence offers more benefits than mixing frame and stereo coherence. As in monoscopic occlusion culling, using simplified geometric models, instead of bounding boxes, when posting occlusion queries, improves significantly the number of objects discriminated as occluded. The algorithm presented can be easily implemented and provides a significant boost in performances. Copyright (C) 2007 John Wiley & Sons, Ltd.
C1 [Mansa, Ignacio; Amundarain, Aiert; Matey, Luis] CEIT, Appl Mech, San Sebastian, Spain.
   [Matey, Luis] Univ Navarra, E-31080 Pamplona, Spain.
   [Garcia-Alonso, Alejandro] Univ Basque Country, Madrid, Spain.
C3 University of Navarra; University of Navarra; University of Basque
   Country
RP Mansa, I (corresponding author), CEIT, Appl Mech, San Sebastian, Spain.
EM imansa@ceit.es
RI Amundarain, Aiert/B-6031-2008
OI Amundarain, Aiert/0000-0003-0530-0275; GARCIA ALONSO MONTOYA,
   ALEJANDRO/0000-0002-6711-6871; Matey, Luis/0000-0002-7294-1825
CR Aila T, 2004, IEEE COMPUT GRAPH, V24, P86, DOI 10.1109/MCG.2004.1274066
   Aliaga DG, 1999, COMP GRAPH, P307, DOI 10.1145/311535.311574
   Andújar C, 2000, COMPUT AIDED DESIGN, V32, P773, DOI 10.1016/S0010-4485(00)00067-1
   [Anonymous], P ACM SIGGRAPH 91 JU
   BARTZ Dirk., 2005, - Tighter Bounding Volumes for Better Occlusion Culling Performance
   BAXTER WV, 2002, EUR REND WORKSH
   Bernardini F, 2000, COMPUT GRAPH FORUM, V19, pC507, DOI 10.1111/1467-8659.00443
   Bittner J, 2004, COMPUT GRAPH FORUM, V23, P615, DOI 10.1111/j.1467-8659.2004.00793.x
   Bittner J, 2003, ENVIRON PLANN B, V30, P729, DOI 10.1068/b2957
   Borro D, 2004, COMPUT GRAPH FORUM, V23, P13, DOI 10.1111/j.1467-8659.2004.00002.x
   BRUNET P, 2001, COMPUTER GRAPHICS FO, V20
   Burdea G., 2003, VIRTUAL REALITY TECH, P464
   CARROZZINO M, 2001, P COMP GRAPH VIRT RE
   Cohen-Or D, 2003, IEEE T VIS COMPUT GR, V9, P412, DOI 10.1109/TVCG.2003.1207447
   Diaz I.n., 2006, Virtual Reality, V10, P31
   ERIKSON C., 2001, I3D 01 P 2001 S INTE, P111, DOI [10.1145/364338.364376, DOI 10.1145/364338.364376]
   Garland M., 1997, COMPUTER GRAPHICS, V31, P209, DOI DOI 10.1145/258734.258849
   Govindaraju N.K., 2003, P 2003 S INTERACTIVE, P103
   Güdükbay U, 2002, IEEE T VIS COMPUT GR, V8, P330, DOI 10.1109/TVCG.2002.1044519
   Hodges LarryF., 1993, Presence: Teleoperators Virtual Environments, V2, P34, DOI 10.1162/pres.1993.2.1.34
   Klosowski JT, 2001, IEEE T VIS COMPUT GR, V7, P365, DOI 10.1109/2945.965350
   KLOSOWSKI JT, 1999, P C VIS 99 SAN FRANC
   Li S, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P313
   MANSA I, 2006, P INF VIS, P591
   MANSA I, 2007, THESIS U NAVARRA SAN
   MOREIN S, 2000, P HOT3D GRAPH HARDW
   NIRENSTEIN S, 2004, P 15 EUR S REND
   Sekulic  D., 2004, GPU GEMS, P487
   Sillion F, 1997, COMPUT GRAPH FORUM, V16, pC207, DOI 10.1111/1467-8659.00158
   STANEKER D, 2005, THESIS EBERHARDKARLS
   VERON H, 1990, P SPIE STEREOSCOPIC, P124
   WANG M, 2004, IEEE T VISUALIZATION, V10, P15
   Wonka P, 2006, ACM T GRAPHIC, V25, P494, DOI 10.1145/1141911.1141914
   YEH YY, 1990, HUM FACTORS, V32, P45, DOI 10.1177/001872089003200104
   YOON SE, 2003, P IEEE VIS C SEATTL
   Zhang H., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P77, DOI 10.1145/258734.258781
NR 36
TC 1
Z9 1
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2008
VL 19
IS 1
BP 67
EP 77
DI 10.1002/cav.215
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 283ZM
UT WOS:000254675000007
DA 2024-07-18
ER

PT J
AU Zhou, YX
   Sun, XH
   Lan, XY
   Lin, SY
AF Zhou, Yongxia
   Sun, Xiehua
   Lan, Xiangyang
   Lin, Shengyou
TI Fast smoke simulation of moving object
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE smoke; shape-controlled; physics-based; animation; simulation
ID REALISTIC ANIMATION; FLUID; WATER
AB We describe a novel method for efficiently controlling the smoke's shape. Given a moving object's shape sequence represented by a geometric model sequence, our method can generate a simulation in which smoke flows out somewhere and quickly forms shapes in sequence. It looks like a cloud of moving smoke that maintains fundamentally the object shapes and the fluid-like behavior. By adding two control forces to the physics-based free flow, the smoke shape can be controlled well while flowing. In our system, the free flow and the shape-controlled flow can be easily switched to each other. The additional computation to controlling the shape is negligible compared with the free flow, and is less than that of previous work. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 China Jiliang Univ, Hangzhou, Peoples R China.
C3 China Jiliang University
RP Zhou, YX (corresponding author), China Jiliang Univ, Hangzhou, Peoples R China.
EM zhou_yongx@163.com
RI liu, shilong/JZD-8395-2024; Lan, Xiangyang/A-1079-2012
CR Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Feldman BE, 2005, ACM T GRAPHIC, V24, P904, DOI 10.1145/1073204.1073281
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Foster N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P181, DOI 10.1145/258734.258838
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P178, DOI 10.1109/CGI.1997.601299
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   IRVING G, 2006, ACM SIGGRAPH
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   KLINGNER BM, 2006, ACM SIGGRAPH
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   LOSASSO F, 2006, IEEE TVCG, P343
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   Park S. I., 2005, Computer Animation, Conference Proceedings, P261, DOI [DOI 10.1145/1073368.1073406, 10.1145/1073368.1073406]
   Rasmussen N, 2003, ACM T GRAPHIC, V22, P703, DOI 10.1145/882262.882335
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   SHAH M, 2004, ACM SIGGRAPH EUR S C, P213
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J, 2003, ACM T GRAPHIC, V22, P724, DOI 10.1145/882262.882338
   Takahashi T, 2003, COMPUT GRAPH FORUM, V22, P391, DOI 10.1111/1467-8659.00686
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
NR 25
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 455
EP 461
DI 10.1002/cav.201
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000024
DA 2024-07-18
ER

PT J
AU Park, J
   Heo, N
   Choi, SH
   Shin, SY
AF Park, Jinho
   Heo, Nambin
   Choi, Sunghee
   Shin, Sung Yong
TI Tour into the picture with water surface reflection and object movements
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE image-based rendering; tour into the picture; reflection map
AB Given a still picture, tour in to the picture (TIP) generates a Walk-through animation of a 3D scene constructed from the picture. In this paper, We generalize TIP to deal With Water surface reflection While allowing foreground objects to move. We formulate a non-linear optimization problem to find the 3D scene parameters with respect to the camera position, to automatically construct a reasonable 3D scene ,model, provided With a set of points and their corresponding points on the Water surface. To synthesize a stream of reflected images on the water surface in accordance With the camera movement, We propose a novel image-based approach, Which makes the best of the limited in formation available in the input picture. Furthermore, we incorporate Water surface movement data acquired from Water simulation on top of stochastic motion textures for objects such as trees and plants, to create a dynamic scene. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Korea Adv Inst Sci & Technol, Div Comp Sci, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Shin, SY (corresponding author), Korea Adv Inst Sci & Technol, Div Comp Sci, 373-1 Guseong Dong, Taejon 305701, South Korea.
EM syshin@jupiter.kaist.ac.kr
RI Choi, Sunghee/C-1617-2011; Shin, Sung Yong/C-1955-2011
CR Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   Criminisi A, 2003, PROC CVPR IEEE, P721
   Darsa L., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P25, DOI 10.1145/253284.253298
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Horry Y., 1997, SIGGRAPH 97, P225
   KANG H, 2001, P EUROGRAPHICS, P132
   Kang HW, 2004, PRESENCE-VIRTUAL AUG, V13, P638, DOI 10.1162/1054746043280556
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   LIEBOWITZ D, 1999, P EUR, P39
   LIPPMAN A, 1980, P SIGGRAPH 80, P32
   McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398
   Miller G., 1992, Journal of Visualization and Computer Animation, V3, P183, DOI 10.1002/vis.4340030305
   PARK J, TOUR PICTURE WATER S
   QIN X, 2003, COMPUT GRAPH FORUM, P243
   *REALFL, 2005, NEXTL TECH
   Sloan P.-P., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P17, DOI 10.1145/253284.253296
   Zhang L, 2001, PROC CVPR IEEE, P990
NR 20
TC 3
Z9 3
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 315
EP 324
DI 10.1002/cav.135
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400018
DA 2024-07-18
ER

PT J
AU Ryan, J
   O'Sullivan, C
   Bell, C
AF Ryan, J
   O'Sullivan, C
   Bell, C
TI Real-time interactive volumetric animation of the heart's electrical
   cycle from automatically synchronized ECG
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE virtual reality; ECG simulation; cardiac modelling; texture-based volume
AB We present a novel method for representing the electrical depolarisation and repolarisation of cardiac cells using real-time volumetric animation techniques. The visual representation coincides with automatically synchronized electrocardiogram (ECG) input. Whilst other projects in similar fields use super-computers or vastly complex cellular structures, one Of the aims of this project is to simplify the process for real-time optimization. The current techniques are being used in a teaching tool and also are being implemented in a myocardial infarction diagnostic tool. Cellular automata are used to demonstrate the electrical progression with a multi-pass nearest-neighbour algorithm and automatic ECG recognition and detection algorithms are used to synchronize the animation with the inputted ECG. We use texture-based slices to represent the myocardial volume to improve speed. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Trinity Coll Dublin, Dept Comp Sci, Image Synthesis Grp, Dublin 2, Ireland.
C3 Trinity College Dublin
RP Trinity Coll Dublin, Dept Comp Sci, Image Synthesis Grp, Dublin 2, Ireland.
EM john.t.ryan@cs.tcd.ie
OI O'Sullivan, Carol/0000-0003-3772-4961
CR Dobson HD, 2003, DIS COLON RECTUM, V46, P349, DOI 10.1007/s10350-004-6554-9
   FOLEY JB, 2002, IRISH MED J, V95, P274
   Kadambe S, 1999, IEEE T BIO-MED ENG, V46, P838, DOI 10.1109/10.771194
   Kähler R, 2003, IEEE T VIS COMPUT GR, V9, P341, DOI 10.1109/TVCG.2003.1207442
   KENNEDY CW, 2002, CARDIOVASCULAR ENG I, V2, P16
   Kohl P, 2001, VISIONS FUTURE CHEM, P127
   Köhler BU, 2002, IEEE ENG MED BIOL, V21, P42, DOI 10.1109/51.993193
   MOONEY R, 2003, P 11 INT C CENTR EUR, P97
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   POLI R, 1995, IEEE T BIO-MED ENG, V42, P1137, DOI 10.1109/10.469381
   Ryan J, 2004, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P250
   Sara K, 1999, East Mediterr Health J, V5, P182
   Sermesant M, 2003, LECT NOTES COMPUT SC, V2673, P230
   So HH, 1997, P ANN INT IEEE EMBS, V19, P289, DOI 10.1109/IEMBS.1997.754529
   Tan KF, 2000, IEE CONF PUBL, P41, DOI 10.1049/cp:20000315
   TATARA E, 2002, IEEE ENG MED BIO JAN, P42
   TRAHANIAS P, 1990, IEEE T PATTERN ANAL, V12, P648, DOI 10.1109/34.56207
   Weiskopf D, 2003, IEEE T VIS COMPUT GR, V9, P298, DOI 10.1109/TVCG.2003.1207438
   XUE QZ, 1992, IEEE T BIO-MED ENG, V39, P317, DOI 10.1109/10.126604
NR 19
TC 3
Z9 3
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 353
EP 360
DI 10.1002/cav.39
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700026
DA 2024-07-18
ER

PT J
AU Zhou, XY
   Liu, SN
   Zeng, HK
   Wang, XK
   Ban, XJ
AF Zhou, Xiangyang
   Liu, Sinuo
   Zeng, Haokai
   Wang, Xiaokun
   Ban, Xiaojuan
TI Efficient and high precision target-driven fluid simulation based on
   spatial geometry features
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE smoothed particle hydrodynamics; spatial geometry weighting;
   target-driven fluid simulation
ID ANIMATION
AB We proposed a novel target-driven fluid simulation method based on the weighted control model derived from the spatial geometric features of the target shape. First, the spatial geometric characteristics of the target model are taken into account to set the color field weights of control particles. This enabled the full expression of geometric characteristics of the target model, and improve the shape accuracy of controlled fluid. Then, the fluid is controlled to form the target shape under driving constraints, wherein we proposed a new adaptive constraint mechanism that enables efficient target shape generation. Finally, a new density constraint between the control particles and the controlled fluid particles is proposed to ensure the incompressibility of fluid during control. Compared to the state-of-the-art target-driven fluid control methods, our method achieves higher precision fluid control with higher efficiency.
C1 [Zhou, Xiangyang; Liu, Sinuo; Zeng, Haokai; Wang, Xiaokun; Ban, Xiaojuan] Univ Sci & Technol Beijing, Beijing Adv Innovat Ctr Mat Genome Engn, Beijing, Peoples R China.
   [Zhou, Xiangyang; Liu, Sinuo; Zeng, Haokai; Wang, Xiaokun; Ban, Xiaojuan] Univ Sci & Technol Beijing, Sch Intelligence Sci & Technol, Beijing, Peoples R China.
   [Zhou, Xiangyang; Liu, Sinuo; Zeng, Haokai; Wang, Xiaokun; Ban, Xiaojuan] Univ Sci & Technol Beijing, Key Lab Intelligent Bion Unmanned Syst, Beijing, Peoples R China.
   [Liu, Sinuo] Peking Univ, Sch Comp Sci, Beijing, Peoples R China.
   [Wang, Xiaokun] Bournemouth Univ, Natl Centrefor Comp Animat, Poole, England.
   [Ban, Xiaojuan] Liaoning Acad Mat, Inst Mat Intelligent Technol, Shenyang, Peoples R China.
   [Ban, Xiaojuan] Univ Sci & Technol Beijing, Beijing Adv Innovat Ctr Mat Genome Engn, 30 Xueyuan Rd, Beijing, Peoples R China.
   [Liu, Sinuo] Peking Univ, Sch Comp Sci, 5 Yiheyuan Rd, Beijing, Peoples R China.
C3 University of Science & Technology Beijing; University of Science &
   Technology Beijing; University of Science & Technology Beijing; Peking
   University; Bournemouth University; Liaoning Academy Materials;
   University of Science & Technology Beijing; Peking University
RP Ban, XJ (corresponding author), Univ Sci & Technol Beijing, Beijing Adv Innovat Ctr Mat Genome Engn, 30 Xueyuan Rd, Beijing, Peoples R China.; Liu, SN (corresponding author), Peking Univ, Sch Comp Sci, 5 Yiheyuan Rd, Beijing, Peoples R China.
EM sinuoliu@pku.edu.cn; banxj@ustb.edu.cn
RI Wang, Xiaokun/AAH-6815-2021; Liu, Sinuo/JLM-6911-2023
OI Wang, Xiaokun/0000-0003-4148-5561; zhou, xiang yang/0000-0002-9614-939X;
   Wang, Xiaokun/0000-0002-4449-591X
FU Guangdong Basic and Applied Basic Research Foundation [2022A1515110350,
   2021A1515012285, 2023A1515030177]; H2020 Marie Sklodowska-Curie
   Individual Fellowship [895941]; National Key Ramp;D Program of China
   [2022ZD0118001]; National Natural Science Foundation of China
   [U22A2022]; Postdoctoral Innovation Talents Support Program
   [BX20220007]; Marie Curie Actions (MSCA) [895941] Funding Source: Marie
   Curie Actions (MSCA)
FX Guangdong Basic and Applied Basic Research Foundation, Grant/Award
   Numbers: 2022A1515110350, 2021A1515012285, 2023A1515030177; H2020 Marie
   Sklodowska-Curie Individual Fellowship, Grant/Award Number: 895941;
   National Key R & D Program of China, Grant/Award Number: 2022ZD0118001;
   National Natural Science Foundation of China, Grant/Award Number:
   U22A2022; Postdoctoral Innovation Talents Support Program, Grant/Award
   Number: BX20220007
CR Bergou M, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239501
   Bojsen-Hansen M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925963
   Chu MY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459845
   Cornelis J, 2015, COMPUT GRAPH-UK, V52, P72, DOI 10.1016/j.cag.2015.07.022
   Dionne Olivier., 2013, P 12 ACM SIGGRAPH EU, P173, DOI DOI 10.1145/2485895.2485919
   Fattal R., 2004, ACM SIGGRAPH 2004 PA
   Forootanina Z, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417842
   Foster N., 1997, P COMPUTER GRAPHICS
   Foster N., 2001, P 28 ANN C COMP GRAP
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   Inglis T, 2017, COMPUT GRAPH FORUM, V36, P354, DOI 10.1111/cgf.13084
   Jones B, 2016, ACM T GRAPHIC, V35, DOI [10.1145/2956233, 10.1145/2897824.2925979]
   Lu JM, 2019, COMPUT GRAPH FORUM, V38, P501, DOI 10.1111/cgf.13856
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Manteaux PL., 2016, P 9 INT C MOT GAM 20
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Mihalef V., 2004, P 2004 ACM SIGGRAPH
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Nielsen MB., 2011, ACM SIGGRAPH 2011 PA
   Nielsen MB., 2009, P 2009 ACM SIGGRAPH
   Nielsen MB, 2010, COMPUT GRAPH FORUM, V29, P705, DOI 10.1111/j.1467-8659.2009.01640.x
   Pan Zherong, 2017, [Computational Visual Media, 计算可视媒体], V3, P369
   Pan ZR, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3016963
   Pan ZR, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508429
   Rasmussen N., 2004, P 2004 ACM SIGGRAPH
   Raveendran K., 2012, P ACM SIGGRAPH EUR S
   Sato S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459846
   Sato S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3213771
   Sato S, 2015, VISUAL COMPUT, V31, P959, DOI 10.1007/s00371-015-1122-y
   Schoentgen A, 2020, COMPUT GRAPH FORUM, V39, P79, DOI 10.1111/cgf.14103
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Stomakhin A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073597
   Stuyck T., 2016, ACM SIGGRAPH 2016 PO
   Treuille A., 2003, ACM SIGGRAPH 2003 PA
   Zhang S, 2015, PROCEEDINGS - I3D 2015, P61, DOI 10.1145/2699276.2699287
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 36
TC 0
Z9 0
U1 3
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2202
EA AUG 2023
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001052032500001
DA 2024-07-18
ER

PT J
AU Torii, T
AF Torii, Takuma
TI Hand-painted yuzen-dyeing simulation for online handcraft experience
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer simulation; fluid dynamics; traditional Japanese craft;
   watercolor painting; yuzen-dyeing
AB On-site workshops provide an opportunity to learn the craftsmanship, but the first hurdle is often high. Online handcraft experiences can be a solution to this first hurdle by providing preliminary craft experience from anywhere on the internet. In collaboration with a traditional craftsman, this motivated us to develop an online simulator for a thin-brush dyeing, called yuzen, one of the Japanese traditional handcrafts innovated in the 17th century. The goal of this simulator is providing easy-going experience, that is, it can be materially unrealistic but mimicking visual appearance. The simulator incorporates various characteristics of yuzen, by which the developed 2D fluid simulation algorithm reduces its computational burden. The yuzen dyeing algorithm is similar to an existing ink-wash painting algorithm, but the present work provides (1) theoretical justification for the algorithm and parameter choices, (2) implementing yuzen dyeing-specific characteristics, and (3a) a physical experiment to examine qualitative resemblance, and (3b) to identify unknown physical parameters for further reality in future development.
C1 [Torii, Takuma] Tokyo Denki Univ, Sch Sci & Engn, Div Informat Syst & Design, Saitama, Japan.
C3 Tokyo Denki University
RP Torii, T (corresponding author), Tokyo Denki Univ, Sch Sci & Engn, Div Informat Syst & Design, Saitama, Japan.
EM tak.torii@mail.dendai.ac.jp
FU Japan Advanced Institute of Science and Technology; Tokyo Denki
   University
FX Japan Advanced Institute of Science and Technology; Tokyo Denki
   University
CR [Anonymous], 2004, GPU gems
   Curtis C. J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P421, DOI 10.1145/258734.258896
   DiVerdi S, 2013, IEEE T VIS COMPUT GR, V19, P723, DOI 10.1109/TVCG.2012.295
   Evans HR., 2019, COMPUTER SCI HONORS
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Kunii T. L., 2001, International Journal of Shape Modeling, V7, P45, DOI 10.1142/S0218654301000047
   Morimoto Y., 2011, NATURAL DYES, P15
   Rigamonti R, 2013, PROC CVPR IEEE, P2754, DOI 10.1109/CVPR.2013.355
   SMALL D, 1991, P SOC PHOTO-OPT INS, V1460, P140, DOI 10.1117/12.44417
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J., Real-time fluid dynamics for games
   Takeishi H., 2003, J GRAPH SCI JPN, V37, P11
   Way DL, 2006, J CHIN INST ENG, V29, P1041, DOI 10.1080/02533839.2006.9671203
   Xu SB, 2012, COMPUT GRAPH-UK, V36, P1025, DOI 10.1016/j.cag.2012.08.003
   Zhang Q, 1999, J VISUAL COMP ANIMAT, V10, P27, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<27::AID-VIS194>3.0.CO;2-C
NR 15
TC 0
Z9 0
U1 2
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2200
EA JUL 2023
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001039962600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Akita, K
   Morimoto, Y
   Tsuruno, R
AF Akita, Kenta
   Morimoto, Yuki
   Tsuruno, Reiji
TI Hand-drawn anime line drawing colorization of faces with texture details
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE colorization; deep learning; line drawings
AB Automatic or semi-automatic colorization can reduce the burden of illustrators in color illustration production, which is a research area with significant market demand. Texture details in eyes and hair influence the impression of character illustrations. Generally, these details are not expressed in line drawings. Many existing automatic or semi-automatic colorization methods do not target hand-drawn line drawings and it is difficult to paint texture details on such drawings. In this paper, we propose the semi-automatic colorization of character line drawings around faces with texture details. Our method uses a reference image as a color hint and transfers the textures of the reference image to a line drawing. To achieve this, our method uses semantic segmentation masks to match parts of the line drawing with the same parts of the reference image. We create two types of segmentation datasets to train a segmentation network that creates segmentation masks. We transfer texture details to a hand-drawn line drawing by mapping each part of the reference image to the corresponding part of the line drawing using segmentation masks. We show that our method is more effective for hand-drawn line drawings than existing methods using qualitative and quantitative evaluations.
C1 [Akita, Kenta; Morimoto, Yuki; Tsuruno, Reiji] Kyushu Univ, Fukuoka, Japan.
C3 Kyushu University
RP Akita, K (corresponding author), Kyushu Univ, Fukuoka, Japan.
EM akita.kenta.633@s.kyushu-u.ac.jp
FU JST SPRING [JPMJSP2136]
FX ACKNOWLEDGMENTS This work was supported by JST SPRING, Grant Number
   JPMJSP2136 and was partly achieved through the use of SQUID at the
   Cybermedia Center, Osaka University.
CR Akita K, 2020, COMPUT GRAPH FORUM, V39, P601, DOI 10.1111/cgf.14171
   [Anonymous], 2018, ILL SKETCHK
   Ashtari A, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555504
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Branwen G., 2022, DANBOORU2021 LARGE S
   Cao RZ, 2021, COMPUT GRAPH FORUM, V40, P1, DOI 10.1111/cgf.14396
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen SY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392386
   Chen WL, 2018, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR.2018.00981
   Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254
   Ci YZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1536, DOI 10.1145/3240508.3240661
   Cui J., 2022, MATHEMATICS-BASEL, V10
   Furusawa C., 2017, COMICOLORIZATION SEM
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hart C., 2017, MASTER GUIDE DRAWING
   Heusel M., 2017, Advances in Neural Information Processing Systems, P6627, DOI [DOI 10.48550/ARXIV.1706.08500, 10.48550/arXiv.1706.08500]
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kim H., 2019, INT C COMP VIS ICCV
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Lee J, 2020, PROC CVPR IEEE, P5800, DOI 10.1109/CVPR42600.2020.00584
   Li BY, 2022, IEEE COMPUT SOC CONF, P2225, DOI 10.1109/CVPRW56347.2022.00242
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Liu BC, 2021, AAAI CONF ARTIF INTE, V35, P2073
   lllyasviel, 2018, STYLE2PAINTS V4 5
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mou Chong, 2023, T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models, P2
   Parakkat AD, 2022, COMPUT GRAPH FORUM, V41, P166, DOI 10.1111/cgf.14517
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Parmar G., 2022, ALIASED RESIZING SUR
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Seo CW., 2021, APPL SCI, V11
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tritrong N, 2021, PROC CVPR IEEE, P4473, DOI 10.1109/CVPR46437.2021.00445
   Voynov Andrey, 2022, SKETCH GUIDED TEXT T
   Wang M, 2019, PROC CVPR IEEE, P1495, DOI 10.1109/CVPR.2019.00159
   Winnemoeller H, 2012, COMPUT GRAPH-UK, V36, P740, DOI 10.1016/j.cag.2012.03.004
   Yonetsuji T., 2017, PETALICA PAINT
   Zhan FN, 2022, LECT NOTES COMPUT SC, V13676, P224, DOI 10.1007/978-3-031-19787-1_13
   Zhang L, 2023, IEEE ICCE, DOI 10.1109/ICCE56470.2023.10043551
   Zhang LM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275090
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou XR, 2021, PROC CVPR IEEE, P11460, DOI 10.1109/CVPR46437.2021.01130
   Zhu PH, 2020, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR42600.2020.00515
NR 46
TC 0
Z9 0
U1 3
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2198
EA JUL 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001034344100001
OA Bronze
DA 2024-07-18
ER

PT J
AU Randall, M
   Harvey, C
   Williams, I
AF Randall, Mathew
   Harvey, Carlo
   Williams, Ian
TI Correlation as a measure for alignment and similarity of human motions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human motion; motion similarity; motion alignment
AB The ability to measure similarity and alignment of motions is a key tool in motion retrieval and motion editing. Similarity metrics based on distance functions are often utilized when measuring similarity of human motions, however, metrics based on correlation can also potentially useful for measuring similarity and alignment. This paper evaluates the use of correlation as a method of measuring the alignment and similarity of human motion and compares them against more established distance-based metrics. Three correlation methods and five methods of parameterising rotation are evaluated. The results show that parameterization based on displacement vectors and Kendall Tau rank correlation are optimal for measuring the alignment between two motions. If measuring similarity of motions, however, an approach based on distance metrics for angular or positional distance should be used.
C1 [Randall, Mathew; Harvey, Carlo; Williams, Ian] Birmingham City Univ, DMTLab, Birmingham, England.
   [Randall, Mathew] Birmingham City Univ, Sch Comp & Digital Technol, Birmingham B4 7XG, England.
C3 Birmingham City University; Birmingham City University
RP Randall, M (corresponding author), Birmingham City Univ, Sch Comp & Digital Technol, Birmingham B4 7XG, England.
EM mathew.randall@bcu.ac.uk
RI Randall, Mathew/KEI-2804-2024
OI Randall, Mathew/0009-0000-2869-1008; Williams, Ian/0000-0002-0651-0963
CR Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Chan JCP, 2011, IEEE T LEARN TECHNOL, V4, P187, DOI 10.1109/TLT.2010.27
   Etemad SA, 2015, VISUAL COMPUT, V31, P1569, DOI 10.1007/s00371-014-1034-2
   Folgado D, 2018, PATTERN RECOGN, V81, P268, DOI 10.1016/j.patcog.2018.04.003
   Haslwanter T, 2016, STAT COMPUT SER, DOI 10.1007/978-3-319-28316-6
   Johnson M.P., 2003, EXPLOITING QUATERNIO
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   KRZESZOWSKI T, 2014, DTW BASED GAIT RECOG, P356
   LEE J, INTERACTIVE CONTROL, P491
   LI Z, GENERIC FRAMEWORK HU, P299
   Puth MT, 2015, ANIM BEHAV, V102, P77, DOI 10.1016/j.anbehav.2015.01.010
   Randall M., 2022, MOTION CAPTURE DATAS
   REITSMA PSA, 2003, P ACM SIGGRAPH 2003, P537
   Tormene P, 2009, ARTIF INTELL MED, V45, P11, DOI 10.1016/j.artmed.2008.11.007
   Valcik J, 2016, COMPUT ANIMAT VIRT W, V27, P484, DOI 10.1002/cav.1674
   Wang J., 2003, EUR SIGGRAPH S COMP, P232
   Xia SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766999
   Yang H., 2004, MOTION SIMILARITY AN
NR 18
TC 0
Z9 0
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2157
EA MAY 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000990588300001
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Randall, M
   Harvey, C
   Williams, I
AF Randall, Mathew
   Harvey, Carlo
   Williams, Ian
TI Online alignment of human motion using forward plotting-dynamic time
   warping
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human motion; motion alignment; time warping
AB A number of approaches to online time warping have been proposed based on plotting an alignment path backwards from a selected end-point. When continually updating a time warp to align a time series with a live data source, such as a stream of motion capture data, the use of backwards plotting makes it hard to maintain a monotonic constraint. To solve this problem, a number of time warping approaches based on forward plotting, referred to as FP-DTW, are proposed and evaluated by applying them to human motions. We demonstrate that forward plotting for temporal alignment is a viable solution when backwards plotting is otherwise not possible.
C1 [Randall, Mathew; Harvey, Carlo; Williams, Ian] Birmingham City Univ, DMTLab, Birmingham, England.
   [Randall, Mathew] Birmingham City Univ, DMT Lab, Birmingham B4 7XG, England.
C3 Birmingham City University; Birmingham City University
RP Randall, M (corresponding author), Birmingham City Univ, DMT Lab, Birmingham B4 7XG, England.
EM mathew.randall@bcu.ac.uk
RI Randall, Mathew/KEI-2804-2024
OI Williams, Ian/0000-0002-0651-0963; Randall, Mathew/0009-0000-2869-1008
CR Dixon S., P 8 INT C DIG AUD EF
   Etemad SA, 2015, VISUAL COMPUT, V31, P1569, DOI 10.1007/s00371-014-1034-2
   Fu AWC, 2008, VLDB J, V17, P899, DOI 10.1007/s00778-006-0040-z
   Guerra-Filho Gutemberg, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P436, DOI 10.1007/978-3-642-25090-3_37
   Hoyet L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185586
   Macrae R., P 11 INT SOC MUS INF
   Muller M, 2007, I INFORM 2 U BONN, V2
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Randall M., MOTION CAPTURE DATAS
   Randall M., ONLINE TIME WARPED M
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Stakem F., IMMERSCOM 09
   Tormene P, 2009, ARTIF INTELL MED, V45, P11, DOI 10.1016/j.artmed.2008.11.007
NR 13
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
AR e2166
DI 10.1002/cav.2166
EA MAY 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000988334000001
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Xu, YR
   Song, CM
   Wang, XK
   Ban, XJ
   Wang, JM
   Zhang, YL
   Chang, J
AF Xu, Yanrui
   Song, Chongming
   Wang, Xiaokun
   Ban, Xiaojuan
   Wang, Jiamin
   Zhang, Yalan
   Chang, Jian
TI Spatial adaptivity with boundary refinement for smoothed particle
   hydrodynamics fluid simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE boundary handling; computer animation; fluid simulation; spatial
   adaptivity
ID SPH
AB Fluid simulation is well-known for being visually stunning while computationally expensive. Spatial adaptivity can effectively ease the computational cost by discretizing the simulation space with varying resolutions. Adaptive methods nowadays mainly focus on the mechanism of refining the fluid surfaces to obtain more vivid splashes and wave effects. But such techniques hinder further performance gain under the condition where most of the vast fluid surface is tranquil. Moreover, energetic flow beneath the surface cannot be adequately captured with the interior of the fluid still being simulated under coarse discretization. This article proposes a novel boundary-distance based adaptive method for smoothed particle hydrodynamics fluid simulation. The signed-distance field constructed with respect to the coupling boundary is introduced to determine particle resolution in different spatial positions. The resolution is maximal within a specific distance to the boundary and decreases smoothly as the distance increases until a threshold is reached. The sizes of the particles are then adjusted towards the resolution via splitting and merging. Additionally, a wake flow preservation mechanism is introduced to keep the particle resolution at a high level for a period of time after a particle flows through the boundary object to prevent the loss of flow details. Experiments show that our method can refine fluid-solid coupling details more efficiently and effectively capture dynamic effects beneath the surface.
C1 [Xu, Yanrui; Song, Chongming; Wang, Xiaokun; Ban, Xiaojuan; Wang, Jiamin; Zhang, Yalan; Chang, Jian] Univ Sci & Technol Beijing, Sch Intelligence Sci & Technol, Beijing, Peoples R China.
   [Wang, Xiaokun] Univ Sci & Technol Beijing, Beijing Key Lab Knowledge Engn Mat Sci, Beijing, Peoples R China.
   [Wang, Xiaokun] Bournemouth Univ, Natl Ctr Comp Animat, Poole, England.
   [Ban, Xiaojuan] Univ Sci & Technol Beijing, Beijing Adv Innovat Ctr Mat Genome Engn, Beijing, Peoples R China.
   [Ban, Xiaojuan] Univ Sci & Technol Beijing, Key Lab Percept & Control Intelligent Bion Unmanne, Minist Educ, Beijing, Peoples R China.
C3 University of Science & Technology Beijing; University of Science &
   Technology Beijing; Bournemouth University; University of Science &
   Technology Beijing; University of Science & Technology Beijing
RP Wang, XK; Ban, XJ (corresponding author), Univ Sci & Technol Beijing, Sch Intelligence Sci & Technol, Beijing, Peoples R China.
EM wangxiaokun@ustb.edu.cn; banxj@ustb.edu.cn
RI SONG, CHONGMING/GXG-3587-2022; Xu, Yanrui/KHU-2854-2024; Wang,
   Xiaokun/AAH-6815-2021
OI Xu, Yanrui/0000-0002-2154-1178; Wang, Xiaokun/0000-0003-4148-5561;
   zhang, ya lan/0000-0002-8736-7125; Wang, Xiaokun/0000-0002-4449-591X
FU Horizon 2020-Marie Sklodowska-Curie Action-Individual Fellowships
   [895941]; National Natural Science Foundation of China [61873299]; Key
   Research and Development Project of Hainan Province [ZDYF2020031];
   Fundamental Research Funds for the Central Universities [QNXM20220043];
   Marie Curie Actions (MSCA) [895941] Funding Source: Marie Curie Actions
   (MSCA)
FX Horizon 2020-Marie Sklodowska-Curie Action-Individual Fellowships,
   Grant/Award Number: 895941; National Natural Science Foundation of
   China, Grant/Award Number: 61873299; Key Research and Development
   Project of Hainan Province, Grant/Award Number: ZDYF2020031; Fundamental
   Research Funds for the Central Universities, Grant/Award Number:
   QNXM20220043
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Ando R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392460
   Band S, 2018, COMPUT GRAPH-UK, V76, P37, DOI 10.1016/j.cag.2018.08.001
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender Jan, 2019, Motion, Interaction and Games, DOI [DOI 10.1145/3359566.3360077, 10.1145/3359566.3360077]
   Chang Y, 2020, COMPUT GRAPH FORUM, V39, P131, DOI 10.1111/cgf.14132
   Fujisawa M, 2015, COMPUT GRAPH FORUM, V34, P155, DOI 10.1111/cgf.12754
   Horvath C., 2013, MASS PRESERVING MULT
   Hu YM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356506
   Koschier D, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099565
   Koschier Dan., 2019, Eurographics 2019-Tutorials, DOI DOI 10.2312/EGT.20191035
   Nakanishi R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417794
   Orthmann J, 2012, COMPUT GRAPH FORUM, V31, P2436, DOI 10.1111/j.1467-8659.2012.03186.x
   Sato T, 2018, COMPUT GRAPH FORUM, V37, P169, DOI 10.1111/cgf.13351
   SOLENTHALER B, 2011, ACM T GRAPHIC, V30, P1
   Vacondio R, 2016, COMPUT METHOD APPL M, V300, P442, DOI 10.1016/j.cma.2015.11.021
   Winchenbach R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3363555
   Winchenbach R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417829
   Winchenbach R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073713
   Xiao YW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417837
NR 22
TC 0
Z9 0
U1 3
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2136
EA JAN 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000906336200001
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Wang, H
   Yang, MC
   Li, Z
   Liu, ZH
   Hu, J
   Fu, ZW
   Liu, F
AF Wang, Hao
   Yang, Mingchuan
   Li, Zheng
   Liu, Zhenhua
   Hu, Jie
   Fu, Ziwang
   Liu, Feng
TI SCANET: Improving multimodal representation and fusion with sparse- and
   cross-attention for multimodal sentiment analysis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cross-modal attention; multimodal fusion; multimodal sentiment analysis;
   sparse transformer
AB Learning unimodal representations and improving multimodal fusion are two cores of multimodal sentiment analysis (MSA). However, previous methods ignore the information differences between different modalities: Text modality has high-order semantic features than other modalities. In this article, we propose a sparse- and cross-attention (SCANET) framework which has asymmetric architecture to improve performance of multimodal representation and fusion. Specifically, in the unimodal representation stage, we use sparse attention to improve the representation efficiency of two modalities and reduce the low-order redundant features of audio and visual modalities. In the multimodal fusion stage, we design an innovative asymmetric fusion module, which utilizes audio and visual modality information matrix as weights to strengthen the target text modality. We also introduce contrastive learning to effectively enhance complementary features between modalities. We apply SCANET on the CMU-MOSI and CMU-MOSEI datasets, and experimental results show that our proposed method achieves state-of-the-art performance.
C1 [Wang, Hao; Yang, Mingchuan; Liu, Zhenhua; Hu, Jie; Fu, Ziwang] China Telecom Corp Ltd, Inst Big Data & Artificial Intelligence, Beijing Res Inst, Beijing 102209, Peoples R China.
   [Li, Zheng] Beijing Normal Univ Huhai, Ctr Cognit & Neuroergon, State Key Lab Cognit Neurosci & Learning, Zhuhai, Guangdong, Peoples R China.
   [Fu, Ziwang] Beijing Univ Post & Telecommun, Sch Comp Sci, Beijing, Peoples R China.
   [Liu, Feng] East China Normal Univ, Inst AI Educ, Shanghai, Peoples R China.
C3 China Telecom Corp. Ltd.; Beijing University of Posts &
   Telecommunications; East China Normal University
RP Wang, H (corresponding author), China Telecom Corp Ltd, Inst Big Data & Artificial Intelligence, Beijing Res Inst, Beijing 102209, Peoples R China.
EM wangh82@chinatelecom.cn
RI ZHAO, S/IWV-4219-2023; Liu, Feng/ABB-1886-2021
OI Liu, Feng/0000-0002-5289-5761; Wang, Hao/0000-0001-9866-972X
FU China Telecom Corporation Limited Research Institute Research Funding
   [I-2022-06]
FX China Telecom Corporation Limited Research Institute Research Funding,
   Grant/Award Number: I-2022-06
CR Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Beltagy I., 2020, Longformer: The long-document transformer, V2004, P05150, DOI DOI 10.48550/ARXIV.2004.05150
   Cheng JY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2447
   Child Rewon, 2019, Generating long sequences with sparse transformers
   Choromanski K., 2021, ARXIV200914794 CS ST
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Degottex G, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853739
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Nguyen D, 2018, COMPUT VIS IMAGE UND, V174, P33, DOI 10.1016/j.cviu.2018.06.005
   Fang Y., 2022, ARXIV211202740 CS
   Gutmann Michael, 2010, P MACHINE LEARNING R, P297, DOI DOI 10.1145/3292500.3330651
   Han W, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9180
   Hazarika D, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1122, DOI 10.1145/3394171.3413678
   Kitaev Nikita, 2020, INT C LEARN REPR
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Lv F, 2021, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR46437.2021.00258
   Morency L.-P., 2011, P 13 INT C MULT INT, P169, DOI DOI 10.1145/2070481.2070509
   Paszke A, 2019, ADV NEUR IN, V32
   Perez-Rosas V., 2013, P ANN M ASS COMP LIN, P973
   Poria Soujanya, 2020, ARXIV200500357 CS
   Rae Jack W., 2019, Compressive transformers for long-range sequence modelling
   Rahman W, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2359, DOI 10.18653/v1/2020.acl-main.214
   Smith L, 2005, ARTIF LIFE, V11, P13, DOI 10.1162/1064546053278973
   Sun ZK, 2020, AAAI CONF ARTIF INTE, V34, P8992
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   van den Oord A., 2018, ARXIV
   Wang HH, 2017, IEEE INT CON MULTI, P949, DOI 10.1109/ICME.2017.8019301
   Wu J, 2021, P 2021 INT C MULT IN, P521, DOI [10.1145/3462244.3479931, DOI 10.1145/3462244.3479931]
   Yu WM, 2021, AAAI CONF ARTIF INTE, V35, P10790
   Zadeh A., 2016, ABS160606259 CORR
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
   Zaheer M., 2020, ADV NEURAL INFORM PR, P17283, DOI DOI 10.5555/3495724.3497174
   Zhao SC, 2021, IEEE SIGNAL PROC MAG, V38, P59, DOI 10.1109/MSP.2021.3106895
   Zhou HY, 2021, AAAI CONF ARTIF INTE, V35, P11106
NR 36
TC 5
Z9 5
U1 7
U2 50
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2090
DI 10.1002/cav.2090
EA JUN 2022
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000810278200001
DA 2024-07-18
ER

PT J
AU Chu, YF
   Liu, Z
   Liu, TT
   Zhao, YM
   Chai, YJ
AF Chu, Yifan
   Liu, Zhen
   Liu, Tingting
   Zhao, Yumeng
   Chai, Yanjie
TI Seismic evacuation simulation in a dynamic indoor environment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd evacuation; earthquake; flow field; scenario simulation
ID SOCIAL FORCE MODEL; BEHAVIOR
AB During an earthquake, interior nonstructural components of a building will be damaged. The damaged objects will obstruct pedestrians' evacuation routes and increase casualties. But this issue has received scant attention in evacuation simulation research. This paper focuses on this issue and proposes an indoor seismic evacuation model to simulate crowd evacuation in a dynamic environment. A physical model of nonstructural components is presented to simulate the dynamics of the indoor scenario. The flow field algorithm is constructed to guide pedestrian's avoidance behaviors globally to reflect the impact of environmental changes on indoor crowd path selection, and a modified social force model is built to simulate the joint influence of seismic forces and the environment on pedestrian motion states. The results of the experiments shows that the proposed model can generate realistic evacuation scene and rational evacuation routes in the earthquake.
C1 [Chu, Yifan; Liu, Zhen; Zhao, Yumeng; Chai, Yanjie] Ningbo Univ, Fac Informat Sci & Technol, Ningbo, Peoples R China.
   [Liu, Tingting] Ningbo Univ, Coll Sci & Technol, Cixi, Peoples R China.
C3 Ningbo University; Ningbo University
RP Liu, Z (corresponding author), Ningbo Univ, Fac Informat Sci & Technol, Ningbo, Peoples R China.
EM liuzhen@nbu.edu.cn
OI Chu, Yifan/0000-0002-7202-6117; liu, tingting/0000-0002-3469-275X
FU Natural Science Foundation of Zhejiang Province [LY20F020007]; Ningbo
   Science Technology Plan Projects [2020Z082, 2021S091]; K.C. Wong Magna
   Fund in Ningbo University
FX Natural Science Foundation of Zhejiang Province, Grant/Award Number:
   LY20F020007; Ningbo Science Technology Plan Projects, Grant/Award
   Numbers: 2020Z082, 2021S091; K.C. Wong Magna Fund in Ningbo University
CR Abeling S, 2020, EARTHQ SPECTRA, V36, P138, DOI 10.1177/8755293019878190
   Ancheta TD, 2014, EARTHQ SPECTRA, V30, P989, DOI 10.1193/070913EQS197M
   [Anonymous], 2011, Fundamentals of Physics
   Battegazzorre E, 2021, ADV ENG SOFTW, V153, DOI 10.1016/j.advengsoft.2020.102956
   Castro S, 2019, EARTHQ SPECTRA, V35, P137, DOI 10.1193/101917EQS218M
   Chen JY, 2021, SAFETY SCI, V142, DOI 10.1016/j.ssci.2021.105378
   Cimellaro GP, 2017, EARTHQ ENG STRUCT D, V46, P985, DOI 10.1002/eqe.2840
   Dong B, 2018, BUILD SIMUL-CHINA, V11, P899, DOI 10.1007/s12273-018-0452-x
   Haghpanah F, 2021, FIRE SAFETY J, V122, DOI 10.1016/j.firesaf.2021.103322
   He J, 2021, EARTHQ SPECTRA, V37, P95, DOI 10.1177/8755293020957353
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Jia XL, 2017, SIMUL-T SOC MOD SIM, V93, P1013, DOI 10.1177/0037549717734633
   Jiang YQ, 2020, APPL MATH MODEL, V80, P815, DOI 10.1016/j.apm.2019.10.016
   Li XC, 2018, PROC INT CONF DATA, P617, DOI 10.1109/ICDE.2018.00062
   Liu H, 2018, APPL SOFT COMPUT, V68, P360, DOI 10.1016/j.asoc.2018.04.015
   Liu TT, 2019, SIMUL-T SOC MOD SIM, V95, P65, DOI 10.1177/0037549717753294
   Lu XZ, 2020, ADV ENG SOFTW, V143, DOI 10.1016/j.advengsoft.2020.102792
   Lu XZ, 2019, SAFETY SCI, V114, P61, DOI 10.1016/j.ssci.2018.12.028
   Mannan M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18063276
   Mitsopoulou Martha, 2020, Parallel Processing and Applied Mathematics. 13th International Conference, PPAM 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12044), P445, DOI 10.1007/978-3-030-43222-5_39
   Perrone D, 2020, B EARTHQ ENG, V18, P1499, DOI 10.1007/s10518-019-00755-5
   Ronchi E, 2019, FIRE SAFETY J, V106, P197, DOI 10.1016/j.firesaf.2019.05.002
   Sabbagh M, 2020, INT SYM HIGH CAPAC, P103, DOI 10.1109/HONET50430.2020.9322832
   Sun YT, 2021, PHYSICA A, V566, DOI 10.1016/j.physa.2020.125652
   Wu PY, 2021, APPL MATH MODEL, V92, P687, DOI 10.1016/j.apm.2020.11.036
   Xiao ML, 2016, B EARTHQ ENG, V14, P1757, DOI 10.1007/s10518-016-9887-6
   Xiao ML, 2019, NAT HAZARDS, V96, P669, DOI 10.1007/s11069-018-3563-x
   Xiong C, 2020, COMPUT-AIDED CIV INF, V35, P322, DOI 10.1111/mice.12496
   Xu Z, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173465
   Zhang FR, 2021, ADV ENG INFORM, V49, DOI 10.1016/j.aei.2021.101351
   Zhang HW, 2016, 2016 INTERNATIONAL COMPUTER SYMPOSIUM (ICS), P384, DOI [10.1109/ICS.2016.83, 10.1109/ICS.2016.0084]
   Zhang H, 2018, PHYSICA A, V492, P1107, DOI 10.1016/j.physa.2017.11.041
   Zhou JX, 2020, GEOMAT NAT HAZ RISK, V11, P335, DOI 10.1080/19475705.2020.1724202
   Zhou JX, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197964
NR 34
TC 1
Z9 1
U1 1
U2 27
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2074
DI 10.1002/cav.2074
EA JUN 2022
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000805604300001
DA 2024-07-18
ER

PT J
AU Güler, O
   Savas, S
AF Guler, Osman
   Savas, Serkan
TI Stereoscopic 3D teaching material usability analysis for interactive
   boards
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D education; Cronbach's alpha; human-computer interaction; image
   processing; stereoscopic 3D; virtual reality
ID HEALTH
AB The Ministry of National Education of Turkey equipped all schools with interactive boards (IBs) within the scope of the FATIH project. The need for appropriate materials has arisen for the effective use of IBs in educational activities. Three-dimensional (3D) technologies are also among these materials. It has been determined in the study that IBs have the necessary hardware to run stereoscopic 3D (S3D) training materials, but the panel has not got an S3D imaging feature. Therefore, only the anaglyph S3D imaging method can be applied to IBs. Thus, an anaglyph S3D training material was prepared for the interaction of the skeletal system and interactive 3D material design for IBs with its effects in education was investigated. Besides, S3D imaging methods with features of IBs were examined. A Likert-type scale was developed to measure the usability of the training material on IBs and the material was evaluated by 20 experts. The data were analyzed by the SPSS statistical program and the results were interpreted. According to the results, educational material seems to be positive in terms of image characteristics, content, navigation, and ease of use, font sizes were moderate for readability, the feedback process and the help menu were moderately effective.
C1 [Guler, Osman] TUSAS Sehit Hakan Gulsen Vocat & Tech Anatolian H, Dept Informat Technol, Ankara, Turkey.
   [Savas, Serkan] Cankiri Karatekin Univ, Dept Comp Engn, Cankiri, Turkey.
C3 Cankiri Karatekin University
RP Savas, S (corresponding author), Cankiri Karatekin Univ, Dept Comp Engn, Cankiri, Turkey.
EM serkansavas@karatekin.edu.tr
RI GÜLER, OSMAN/D-3303-2017; Savaş, Serkan/S-4340-2016
OI GÜLER, OSMAN/0000-0003-3272-5973; Savaş, Serkan/0000-0003-3440-6271
CR Akay A., 2007, DERINLIK ALGISINA ED
   Akkoyunlu B., 2003, HACETTEPE NIVERSITES, V24, P1
   [Anonymous], 2014, MERSIN U EGITIM FAKU
   [Anonymous], 2013, SPECIAL ISSUE COMPUT
   Bakanligi ME., 2018, ETKILESIMLI TAHTA EG
   Bakanligi ME., 2018, EGITIMDE FATIH PROJE
   Bamford A., 2011, THE J, P1
   Barber SR, 2020, OTOLARYNG HEAD NECK, V162, P922, DOI 10.1177/0194599820907866
   Bernard F, 2020, SURG RADIOL ANAT, V42, P843, DOI 10.1007/s00276-020-02465-z
   Bogomolova K, 2021, ANAT SCI EDUC, V14, P385, DOI 10.1002/ase.2055
   Boher P., 2010, P SID S, V41, P323
   Brown E., 2021, 3D IMAGING SPACE VI
   Buyrukoglu S, 2019, COMPUT APPL ENG EDUC, V27, P733, DOI 10.1002/cae.22094
   Calp MH, 2019, TAM METIN BILDIRI KI, P396
   Calp MH., 2011, POLITEKNIK DERGISI, V14, P303
   Christopher LA, 2013, NEUROSURGERY, V72, pA131, DOI 10.1227/NEU.0b013e318270d9c0
   Chu PY., 2017, P INT C HUM COMP INT, P293
   Deakyne AJ., 2020, FRONTIERS BIOMEDICAL, V83549, DOI [10.1115/DMD2020-9014, DOI 10.1115/DMD2020-9014]
   Education S, 2013, FUTURE 3D ED SENSAVI
   Faria R, 2013, EUR J RADIOL, V82, pE342, DOI 10.1016/j.ejrad.2013.02.015
   Goggin PM, 2016, EUR CELLS MATER, V31, P264, DOI 10.22203/eCM.v031a18
   Goodarzi A, 2017, WORLD NEUROSURG, V107, P35, DOI [10.1016/J.WNEU.2017.07.119, 10.1016/j.wneu.2017.07.119]
   Guler O., 2018, ETKILESIMLI TAHTALAR
   Guler O., 2014, BILISIM TEKNOLOJILER, V7, P1
   Gursas Y., 1993, 3 BOYUTLU BILGISAYAR
   Hackett MA., 2018, THESIS U CENTRAL FLO
   Holliman N., 2002, THESIS U DURHAM
   Ilgner J, 2006, PROC SPIE, V6055, DOI 10.1117/12.647591
   Jeli Z., 2017, J. Ind. Des. Eng. Graph, V12, P231
   Kalkan ÖK, 2021, ARAB J SCI ENG, V46, P12697, DOI 10.1007/s13369-021-06138-w
   Kaplan-Rakowski R, 2022, INT J HUM-COMPUT INT, V38, P299, DOI 10.1080/10447318.2021.1938394
   Lau KW, 2021, VIRTUAL REAL-LONDON, V25, P985, DOI 10.1007/s10055-021-00504-7
   Lau KW, 2017, INT J INF LEARN TECH, V34, P242, DOI 10.1108/IJILT-05-2016-0016
   Lawton G, 2011, COMPUTER, V44, P17, DOI 10.1109/MC.2011.3
   Leung H., 2012, P IEEE INT C TEACH A
   Lin CC., 2012, P SID S, V43, P965
   Mahoney Noel, 2011, Proceedings of the 2011 16th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational & Serious Games (CGAMES 2011), P148, DOI 10.1109/CGAMES.2011.6000331
   NASA, 2021, JOBS LAND PAG 2021
   Noah N, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2020
   Obrist M, 2013, ENTERTAIN COMPUT, V4, P71, DOI 10.1016/j.entcom.2012.03.001
   Pehlivan H., 2018, 1 UL EG PROGR VE OGR
   Permana D., 2021, Int. J. Educ. Vocat. Stud, V3, P116, DOI [10.29103/ijevs.v3i2.3294, DOI 10.29103/IJEVS.V3I2.3294]
   Ribas GC, 2001, J NEUROSURG, V95, P1057, DOI 10.3171/jns.2001.95.6.1057
   Roettl J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200724
   Savas S, 2021, Journal of Information Systems and Management Research, V3, P14
   Savas S., 2019, EGIT ARAST, P227
   Starks M., 2018, 3DTV 3D MOVIE TECHNO, V2nd
   Stoffer P., 2003, P AGU FALL M, V2003
   Uzunsakal E., 2018, Uygulamali Sosyal Bilimler Dergisi, V2, P14
   Wang Q, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/9694316
   Woods AJ, 2012, PROC SPIE, V8288, DOI 10.1117/12.912061
   Woods AJ, 2010, P SOC PHOTO-OPT INS, V7524, DOI 10.1117/12.840835
   Xu D., 2013, THESIS U BRIT COLUMB
   Yilmaz M., 2012, BILISIM TEKNOLOJILER, V5, P19
NR 54
TC 3
Z9 3
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2022
VL 33
IS 2
AR e2041
DI 10.1002/cav.2041
EA FEB 2022
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0T8YJ
UT WOS:000751714500001
DA 2024-07-18
ER

PT J
AU Zhao, SM
   Chen, MM
   Wang, PJ
   Cao, Y
   Zhang, PP
   Yang, X
AF Zhao, Shimin
   Chen, Miaomiao
   Wang, Pengjie
   Cao, Ying
   Zhang, Pingping
   Yang, Xin
TI RGB-D salient object detection via deep fusion of semantics and details
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cross-model and multilevel features; feature fusion and deep fusion;
   RGB-D; salient object detection
AB In this paper, we address RGB-D salient object detection task by jointly leveraging semantics and contour details of salient objects. We propose a novel semantics-and-details complementary fusion network to adaptively integrate cross-model and multilevel features. Specifically, we employ two kinds of fusion modules in our model, which are designed for fusing high-level semantic features and integrating contour detail features of the scene components, respectively. The semantics fusion module aggregates high-level interdependent semantic relationships by a nonlinear weighted summation of small and medium receptive fields. Meanwhile, the details module integrates multi-level contour detail features to leverage expressive details of salient objects. We achieve new state-of-the-art salient object detection results on seven RGB-D datasets, that is, STERE, NJU2000, LFSD, NLPR, SSD, DES, and SIP2019 dataset. Experimental results demonstrate that our method outperforms eleven state-of-the-art salient object detection methods.
C1 [Zhao, Shimin; Chen, Miaomiao; Wang, Pengjie] Dalian Minzu Univ, Sch Comp Sci, Dalian 116600, Peoples R China.
   [Cao, Ying] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Zhang, Pingping; Yang, Xin] Dalian Univ Technol, Sch Comp Sci, Dalian, Peoples R China.
C3 Dalian Minzu University; City University of Hong Kong; Dalian University
   of Technology
RP Wang, PJ (corresponding author), Dalian Minzu Univ, Sch Comp Sci, Dalian 116600, Peoples R China.
EM pengjiewang@gmail.com
OI , Xin/0000-0002-8046-722X
FU Liaoning Innovative Talents Support Plan [LR2016071]
FX Our work is supported by Liaoning Innovative Talents Support Plan (Grant
   No. LR2016071). The corresponding author of this paper is Pengjie Wang.
CR Bai R, 2018, ASIAPAC SIGN INFO PR, P312, DOI 10.23919/APSIPA.2018.8659565
   Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen YT, 2014, ECS TRANSACTIONS, V64, P23, DOI 10.1149/06416.0023ecst
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Li NY, 2017, IEEE T PATTERN ANAL, V39, P1605, DOI 10.1109/TPAMI.2016.2610425
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Ren JK, 2015, EUROMICRO, P25, DOI 10.1109/ECRTS.2015.10
   Siméoni O, 2018, IEEE WINT CONF APPL, P1745, DOI 10.1109/WACV.2018.00194
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107
   Wibisono JK, 2016, ASIAPAC SIGN INFO PR, P1, DOI DOI 10.1109/APSIPA.2016.7820913
   Zhang ZH, 2018, LECT NOTES COMPUT SC, V11211, P504, DOI 10.1007/978-3-030-01234-2_30
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhu C., 2018, PDNET PRIOR MODEL GU, P199
   Zhu CB, 2017, IEEE INT CONF COMP V, P3008, DOI 10.1109/ICCVW.2017.355
NR 30
TC 3
Z9 3
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1954
DI 10.1002/cav.1954
EA SEP 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000567815000001
DA 2024-07-18
ER

PT J
AU Tian, Y
   Yang, WJ
   Liu, QS
   Yang, Q
AF Tian, Yu
   Yang, Wenjing
   Liu, Qingsong
   Yang, Qiong
TI Deep supervised multimodal semantic autoencoder for cross-modal
   retrieval
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE autoencoder; cross-modal retrieval; semantic-aware feature vectors
AB Cross-modal retrieval aims to do flexible retrieval among different modals, whose main issue is how to measure the semantic similarities among multimodal data. Though many existing methods have been proposed to enable cross-modal retrieval, they rarely consider the preservation of content information among multimodal data. In this paper, we present a three-stage cross-modal retrieval method, namedMMCA-CMR. To reduce the discrepancy among multimodal data, we first attempt to embed multimodal data into a common representation space. We then combine the feature vectors with the content information into the semantic-aware feature vectors. We finally obtain the feature-aware and content-aware projections via multimodal semantic autoencoders. With semantic deep autoencoders, MMCA-CMR promotes a more reliable cross-modal retrieval by learning feature vectors from different modalities and content information simultaneously. Extensive experiments demonstrate that the proposed method is valid in cross-modal retrieval, which significantly outperforms state-of-the-art on four widely-used benchmark datasets.
C1 [Tian, Yu; Yang, Wenjing; Yang, Qiong] Natl Univ Def Technol, Inst Quantum Informat, Coll Comp, Changsha 410073, Hunan, Peoples R China.
   [Tian, Yu; Yang, Wenjing; Yang, Qiong] Natl Univ Def Technol, State Key Lab High Performance Comp, Coll Comp, Changsha 410073, Hunan, Peoples R China.
   [Liu, Qingsong] Naval Aeronaut Univ, Yantai, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China
RP Yang, WJ (corresponding author), Natl Univ Def Technol, Inst Quantum Informat, Coll Comp, Changsha 410073, Hunan, Peoples R China.; Yang, WJ (corresponding author), Natl Univ Def Technol, State Key Lab High Performance Comp, Coll Comp, Changsha 410073, Hunan, Peoples R China.
EM wenjing.yang@nudt.edu.cn
OI , Yu/0000-0002-2732-3841
FU National Key Research and Development Program of China [2017YFB1300203]
FX This work was supported by the National Key Research and Development
   Program of China under Grant 2017YFB1300203.
CR Andrew G., 2013, ICML, P1247
   [Anonymous], 2012, P INT C NEUR INF PRO
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Mark JH, 2008, P 1 ACM INT C MULT I, P39
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Rupnik J., 2010, P C DATA MINING DATA, P1
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wu YL, 2019, NEUROCOMPUTING, V331, P165, DOI 10.1016/j.neucom.2018.11.042
   Zhang X, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P213, DOI 10.1145/3206025.3206042
   Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064
NR 26
TC 1
Z9 2
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1962
DI 10.1002/cav.1962
EA SEP 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000566406000001
DA 2024-07-18
ER

PT J
AU Han, D
   Hong, S
   Noh, J
   Jin, XG
   Shin, JS
AF Han, Daseong
   Hong, Seokpyo
   Noh, Junyong
   Jin, Xiaogang
   Shin, Joseph S.
TI Online real-time locomotive motion transformation based on biomechanical
   observations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE online real-time motion control; motion transformation; character
   animation; biomechanics
ID CURVED PATHS; WALKING; HEAD
AB In the paper, we present an online real-time method for automatically transforming a basic locomotive motion to a desired motion of the same type, based on biomechanical results. Given an online request for a motion of a certain type with desired moving speed and turning angle, our method first extracts a basic motion of the same type from a motion graph, and then transforms it to achieve the desired moving speed and turning angle by exploiting the following biomechanical observations: contact-driven center-of-mass control, anticipatory reorientation of upper body segments, moving speed adjustment, and whole-body leaning. Exploiting these observations, we propose a simple but effective method to add physical and behavioral naturalness to the resulting locomotive motions without preprocessing. Through experiments, we show that our method enables a character to respond agilely to online user commands while efficiently generating walking, jogging, and running motions with a compact motion library. Our method can also deal with certain dynamical motions such as forward roll. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Han, Daseong; Hong, Seokpyo; Noh, Junyong] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, 291 Daehak Ro, Daejeon, South Korea.
   [Shin, Joseph S.] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
   [Shin, Joseph S.] Handong Global Univ, Sch Creat Convergence Educ, Pohang, South Korea.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST); Handong Global University;
   Zhejiang University
RP Noh, J (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, 291 Daehak Ro, Daejeon, South Korea.
EM junyongnoh@kaist.ac.kr
RI Noh, Junyong/C-1663-2011; Shin, Sung Yong/C-1955-2011
OI Shin (formerly Sung Yong Shin), Joseph S./0000-0003-4437-6459
CR Akram SB, 2010, GAIT POSTURE, V32, P211, DOI 10.1016/j.gaitpost.2010.04.017
   Ferris DP, 1998, P ROY SOC B-BIOL SCI, V265, P989, DOI 10.1098/rspb.1998.0388
   Gleicher M., 2001, P 2001 S INTERACTIVE, P195
   Hicheur H, 2005, EXP BRAIN RES, V162, P145, DOI 10.1007/s00221-004-2122-8
   Hollands MA, 2001, EXP BRAIN RES, V140, P223, DOI 10.1007/s002210100811
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Levine S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185524
   Lockwood Noah., 2011, P 2011 ACM SIGGRAPHE, P267, DOI DOI 10.1145/2019406.2019442
   Novacheck TF, 1998, GAIT POSTURE, V7, P77, DOI 10.1016/S0966-6362(97)00038-6
   Orendurff MS, 2006, GAIT POSTURE, V23, P106, DOI 10.1016/j.gaitpost.2004.12.008
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Sreenivasa MN, 2008, EXP BRAIN RES, V191, P313, DOI 10.1007/s00221-008-1525-3
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
   Yang WC, 2016, GAIT POSTURE, V44, P83, DOI 10.1016/j.gaitpost.2015.10.023
NR 15
TC 2
Z9 2
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 378
EP 384
DI 10.1002/cav.1708
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300022
DA 2024-07-18
ER

PT J
AU Li, P
   Sun, HQ
AF Li, Ping
   Sun, Hanqiu
TI Density-enhanced perceptual mosaic on GPU
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE perceptual mosaic; bilateral grid; GPU parallelism; real-time processing
AB Image mosaic effects are wildly applied in print media, domestic decoration, and many image beautification applications. However, the current image mosaic methods are mostly based on fixed-size image tiles, simple color adjustment, and irregular image segmentation, which are inaccurate and very time-consuming. In this paper, we present a graphics processing unit-accelerated perceptual mosaic using density tiles replacement and brightness lighting optimization, keeping original image structure details and providing more expressive visual effects. Automatic density replacement map segmentation and color-based region tiles replacement are performed to facilitate the mosaic. Delicate brightness optimization and perceptual color correction are further applied to enhance expressive lighting effects. We also consider the salience perception of images and similarity correlation among neighboring tiles for our perceptual mosaic. The experimental results have shown the efficiency and high-quality performance of our density-enhanced perceptual mosaic on graphics processing unit. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Li, Ping] Hong Kong Inst Educ, Dept MIT, Tai Po, Hong Kong, Peoples R China.
   [Sun, Hanqiu] Chinese Univ Hong Kong, Dept CSE, Sha Tin, Hong Kong, Peoples R China.
C3 Education University of Hong Kong (EdUHK); Chinese University of Hong
   Kong
RP Li, P (corresponding author), Hong Kong Inst Educ, Dept MIT, Tai Po, Hong Kong, Peoples R China.
EM pli@ied.edu.hk
RI Li, Ping/AAO-2019-2020
OI Li, Ping/0000-0002-1503-0240
CR Allison W., 2002, P 2 INT S NONPHOTORE, P21
   [Anonymous], P SIGGRAPH AS C
   [Anonymous], 2008, TECHNOL ENG TEACHER
   Chen J, 2007, P ACM SIGGRAPH
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Choi YS, 2007, LECT NOTES COMPUT SC, V4740, P475
   Finkelstein A, 1998, TR57498 PRINC U
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Hertzmann A, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P47, DOI 10.1109/CGI.2001.934657
   [黄海 Huang Hai], 2011, [机械传动, Journal of Mechanical Transmission], V35, P8
   Huang H, 2010, COMPUT GRAPH FORUM, V29, P2055, DOI 10.1111/j.1467-8659.2010.01792.x
   Jing L, 2005, LECT NOTES COMPUT SC, V3804, P1
   Kagaya M, 2011, IEEE T VIS COMPUT GR, V17, P74, DOI 10.1109/TVCG.2010.25
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kim J, 2002, ACM T GRAPHIC, V21, P657
   Li P, 2012, COMPUT GRAPH-UK, V36, P1048, DOI 10.1016/j.cag.2012.07.004
   Lu J., 2010, PROC ACM SIGGRAPH S, P127
   Mavridis Pavlos., 2011, Proceedings of the Symposium on Interactive 3D Graphics and Games, P23, DOI [10.1145/1944745.1944749, DOI 10.1145/1944745.1944749]
   Orchard J., 2008, P 6 INT S NONPH AN R, P79, DOI DOI 10.1145/1377980.1377997
   Paris S, 2006, LECT NOTES COMPUT SC, V3954, P568
   Ping Li, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2473, DOI 10.1109/ICIP.2011.6116162
   Plant W, 2013, MULTIMED TOOLS APPL, V64, P695, DOI 10.1007/s11042-011-0951-6
   Vadivel A, 2005, PROC SPIE, P598, DOI 10.1117/12.586823
   Wen F., 2006, PROC INT S NONPHOTOR, P47
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Zhang SH, 2011, IEEE T MULTIMEDIA, V13, P1286, DOI 10.1109/TMM.2011.2165052
   Zhao HL, 2008, VISUAL COMPUT, V24, P727, DOI 10.1007/s00371-008-0254-8
   Zhao HL, 2009, VISUAL COMPUT, V25, P973, DOI 10.1007/s00371-008-0308-y
NR 29
TC 1
Z9 1
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 241
EP 249
DI 10.1002/cav.1709
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300008
DA 2024-07-18
ER

PT J
AU Kim, YS
   Kim, Y
   Kim, KH
AF Kim, Yong Sun
   Kim, Yongwan
   Kim, Ki-Hong
TI Interactive digital graffiti canvas system
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE digital graffiti; digital spray can; spray simulation; virtual reality
AB This paper presents an interactive digital painting system that allows a user to draw graffiti on a virtual 3D canvas with a digital spray can. The system visualizes a stereoscopic representation of the canvas by tracking the user's head. It also emulates real-time spray painting by tracking the spray can in the user's hand as well as sensing the button pressure of the spray device. After painting a 3D object, the user can interact with the object on the display and see it flying in the 3D environment through a tracked head-mounted display. As demonstrated in the results of our evaluation, we verified that the system resembles real graffiti in regard to a natural and realistic graffiti experience. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Kim, Yong Sun; Kim, Yongwan; Kim, Ki-Hong] Elect & Telecommun Res Inst, Virtual Real Res Lab, 218 Gajeong Ro, Daejeon 305700, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Kim, YS (corresponding author), Elect & Telecommun Res Inst, Virtual Real Res Lab, 218 Gajeong Ro, Daejeon 305700, South Korea.
EM yongsun.kim@etri.re.kr
FU ICT R&D program of MSIP/IITP [10039923]
FX This work was supported by the ICT R&D program of MSIP/IITP (10039923,
   Development of Live 4D contents platform technology based on expansion
   of realistic experiential space).
CR Batagelj B, 2009, ELMAR PROC, P305
   Kim DS, 2007, IEEE Virtual Reality 2007, Proceedings, P307
   Konieczny J, 2008, LECT NOTES COMPUT SC, V5358, P998, DOI 10.1007/978-3-540-89639-5_95
   Konieczny Jonathan., 2009, Proceedings of Non-Photorealistic Animation and Rendering, P61
   Lim MY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P847
   Papagiannakis G, 2008, COMPUT ANIMAT VIRT W, V19, P3, DOI 10.1002/cav.221
   Yang UY, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P289
   Yang U, 2013, ETRI J, V35, P352, DOI 10.4218/etrij.13.0212.0245
NR 8
TC 1
Z9 1
U1 1
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2016
VL 27
IS 2
BP 113
EP 121
DI 10.1002/cav.1633
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ2BZ
UT WOS:000374010000003
DA 2024-07-18
ER

PT J
AU Tang, W
   Wan, TR
   Huang, DJ
AF Tang, Wen
   Wan, Tao Ruan
   Huang, Donjing
TI Interactive thin elastic materials
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; computer games; cloth simulation; interactive
   virtual reality applications
AB Despite great strides in past years are being made to generate motions of elastic materials such as cloth and biological skin in virtual world, unfortunately, the computational cost of realistic high-resolution simulations currently precludes their use in interactive applications. Thin elastic materials such as cloth and biological skin often exhibit complex nonlinear elastic behaviors. However, modeling elastic nonlinearity can be computationally expensive and numerically unstable, imposing significant challenges for their use in interactive applications. This paper presents a novel simulation framework for simulating realistic material behaviors with interactive frame rate. Central to the framework is the use of a constraint-based multi-resolution solver for efficient and robust modeling of the material nonlinearity. We extend a strain-limiting method to work on deformation gradients of triangulated surface models in three-dimensional space with a novel data structure. The simulation framework utilizes an iterative nonlinear Gauss-Seidel procedure and a multilevel hierarchy structure to achieve computational speedups. As material nonlinearity are generated by enforcing strain-limiting constraints at a multilevel hierarchy, our simulation system can rapidly accelerate the convergence of the large constraint system with simultaneous enforcement of boundary conditions. The simplicity and efficiency of the framework makes simulations of highly realistic thin elastic materials substantially fast and is applicable of simulations for interactive applications. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Tang, Wen] Bournemouth Univ, Fac Sci Design & Technol, Pool House, Poole BH12 5BB, Dorset, England.
   [Wan, Tao Ruan] Univ Bradford, Fac Engn & Informat, Bradford BD7 1DP, W Yorkshire, England.
   [Huang, Donjing] Shanghai Univ, Sch Film & TV Arts Technol, Shanghai, Peoples R China.
C3 Bournemouth University; University of Bradford; Shanghai University
RP Tang, W (corresponding author), Bournemouth Univ, Fac Sci Design & Technol, Pool House, Poole BH12 5BB, Dorset, England.
EM wtang@bournemouth.ac.uk
RI Huang, Di/AGJ-9783-2022
OI Huang, Di/0000-0003-3698-5158
FU Xi'an Polytechnic University, China
FX This work is partially supported by the Xi'an Polytechnic University,
   China. Authors would like to acknowledge the contribution of Mr. Daniel
   Green to experiments in this paper.
CR Bridson R., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P28
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Grinspun Eitan., 2003, P 2003 ACM SIGGRAPH
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Muller M, 2010, P 10 ACM SIGGRAPH EU, P85
   MULLER M., 2008, P VIRT REAL INT PHYS
   Narain R, 2012, ACM T GRAPHIC, V31
   Schmitt A., 2005, 17 I BETR DIAL
   Tang M., 2010, P ACM SIGGRAPH S INT, P7, DOI [10.1145/1730804.1730806, DOI 10.1145/1730804.1730806]
   Thomaszewski B, 2009, COMPUT GRAPH FORUM, V28, P569, DOI 10.1111/j.1467-8659.2009.01397.x
   Volino P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559762
   Wang HM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964966
   Wang Jue, 2010, Sarcoma, V2010, P454792, DOI 10.1155/2010/454792
NR 13
TC 1
Z9 1
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2016
VL 27
IS 2
BP 141
EP 150
DI 10.1002/cav.1666
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ2BZ
UT WOS:000374010000005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kotsilieris, T
   Karetsos, GT
   Anagnostopoulos, I
   Dimopoulou, NA
AF Kotsilieris, Theodore
   Karetsos, George T.
   Anagnostopoulos, Ioannis
   Dimopoulou, Nikoletta A.
TI Interconnecting distributed virtual worlds using Metabots: performance
   evaluation against the traditional client-server model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D virtual worlds; mobile agents; Metabot; distributed information
   systems
ID MOBILE AGENTS; NETWORK; PLATFORM; INTERNET
AB Virtual Worlds evolution is breaking the barriers of virtual isolation, thus allowing users to participate in geographically dispersed and culturally diverse places. At the same time, mobile agents have been established as a solid programming method for heterogeneous networking and computing environments. Our work focuses on the definition of a distributed Virtual World reference platform for enhanced users' experience. Towards interconnecting virtual worlds with mobile agents, we have further enriched the concept of a human-like appearance avatar. We propose two distributed virtual world architectures, namely loose and tight. In parallel, we present a relevant implementation scheme along with experimental results that prove the performance enhancements achieved against the classic client/server model. Copyright (C) 2014 John Wiley & Sons, Ltd.
C1 [Kotsilieris, Theodore] Antikalamos Messinias Technol Educ Inst Peloponne, Dept Hlth & Welf Units Adm, Kalamata, Greece.
   [Karetsos, George T.] Technol Educ Inst Thessaly, Dept Comp Engn, Larisa, Greece.
   [Anagnostopoulos, Ioannis] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
   [Dimopoulou, Nikoletta A.] Secondary Educ Reg West Attiki, Athens, Greece.
RP Kotsilieris, T (corresponding author), Antikalamos Messinias Technol Educ Inst Peloponne, Dept Hlth & Welf Units Adm, Kalamata, Greece.
EM tkots@teikal.gr
RI Kotsilieris, Theodore/AAP-4261-2021; Karetsos, George T./O-6370-2015
OI Kotsilieris, Theodore/0000-0003-3959-4531; 
CR [Anonymous], 2010, International Journal of Computer Game Research
   [Anonymous], 2012, Journal of Virtual Worlds Research, DOI DOI 10.4101/JVWR.V5I1.6173
   [Anonymous], 2009, 2009 IEEE/PES Power Systems Conference and Exposition, DOI DOI 10.1109/PSCE.2009.4840087
   Antonello R, 2009, MULTIMEDIA SYST, V15, P33, DOI 10.1007/s00530-008-0125-1
   Arroyo A, 2011, EXPERT SYST, V28, P339, DOI 10.1111/j.1468-0394.2011.00595.x
   Barfield W., 1995, PRESENCE PERFORMANCE, P473
   Bartle R, 2003, DESIGNING VIRTUAL WO, P741
   Bell M., 2008, J VIRTUAL WORLDS RES, V1, DOI [10.4101/jvwr.v1i1.283, DOI 10.4101/JVWR.V1I1.283]
   Blair J., 2011, Proceedings 2011 25th IEEE International Conference on Advanced Information Networking and Applications Workshops (WAINA 2011), P580, DOI 10.1109/WAINA.2011.15
   Boulos MNK, 2007, HEALTH INFO LIBR J, V24, P233, DOI 10.1111/J.1471-1842.2007.00733.x
   Bullot T, 2008, INT J NETW MANAG, V18, P171, DOI 10.1002/nem.679
   Chen B, 2010, ENCY E BUSINESS DEV, P846
   Chen B, 2010, IEEE T INTELL TRANSP, V11, P485, DOI 10.1109/TITS.2010.2048313
   Chen KT, 2006, COMMUN ACM, V49, P34, DOI 10.1145/1167838.1167859
   Chen KT, 2009, IEEE T PARALL DISTR, V20, P593, DOI 10.1109/TPDS.2008.148
   Chen M, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/36871
   Coulouris G., 2012, DISTRIBUTED SYSTEMS, P1067
   Des Butler P, 2012, ASCILITE AUSTR SOC C
   Dickey MD, 2005, BRIT J EDUC TECHNOL, V36, P439, DOI 10.1111/j.1467-8535.2005.00477.x
   Du TC, 2003, COMMUN ACM, V46, P127, DOI 10.1145/792704.792710
   FISHWICK PA, 2009, SIM C WSC P 2009 WIN, P177
   Franceschi K., 2008, HAWAII INT C SYSTEMS, V41, P1
   FRANKLIN S., 1997, INT WORKSHOP AGENT T, V1193, P21
   Freitas S., 2008, Serious virtual worlds. A scoping guide
   Friedman D, 2007, LECT NOTES ARTIF INT, V4722, P252
   Gavalas D, 2009, J SYST SOFTWARE, V82, P355, DOI 10.1016/j.jss.2008.06.034
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Kaplan J, 2011, IEEE INTERNET COMPUT, V15, P38, DOI 10.1109/MIC.2011.76
   Kinicki J., 2008, Proceedings of the 18th International Workshop on Network and Operating Systems Support for Digital Audio and Video, P69
   Kluge Stacy, 2008, Journal of Issues in Informing Science and Information Technology Journal, V5, P127
   Lai CH, 2013, COMPUT EDUC, V69, P303, DOI 10.1016/j.compedu.2013.07.009
   Leung S., 2011, Proceedings of the 2011 IEEE International Conference on Internet of Things and 4th IEEE International Conference on Cyber, Physical and Social Computing (iThings/CPSCom 2011), P570, DOI 10.1109/iThings/CPSCom.2011.89
   Lin K, 2012, FUTURE GENER COMP SY, V28, P446, DOI 10.1016/j.future.2011.03.001
   Lo SK, 2005, CYBERPSYCHOL BEHAV, V8, P15, DOI 10.1089/cpb.2005.8.15
   Maassen J, 2001, ACM T PROGR LANG SYS, V23, P747, DOI 10.1145/506315.506317
   Nichols J, 2006, IEEE T SYST MAN CY C, V36, P353, DOI 10.1109/TSMCC.2006.871574
   Nijholt A, 2000, EUROGRAPHICS 2000
   Pavlou G, 2007, J NETW SYST MANAG, V15, P425, DOI 10.1007/s10922-007-9082-9
   Smith DA, 2003, FIRST CONFERENCE ON CREATING, CONNECTING AND COLLABORATING THROUGH COMPUTING, PROCEEDINGS, P2, DOI 10.1109/C5.2003.1222325
   Stewart S, 2010, REHABIL NURS, V35, P254, DOI 10.1002/j.2048-7940.2010.tb00056.x
   Su CJ, 2008, COMPUT IND, V59, P55, DOI 10.1016/j.compind.2007.06.001
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Varvello M., 2009, 2009 8 ANN WORKSH NE, P1
   Varvello M, 2011, IEEE ACM T NETWORK, V19, P80, DOI 10.1109/TNET.2010.2060351
   Vasalou A, 2009, COMPUT HUM BEHAV, V25, P510, DOI 10.1016/j.chb.2008.11.007
   Voyager, 2012, VOYAG PLATF
   Wasko M, 2011, MIS QUART, V35, P645
   Weitnauer E, 2008, LECT NOTES COMPUT SC, V5208, P552
   Xiao B, 2007, MIS QUART, V31, P137
   Youngho Lee, 2008, International Symposium on Ubiquitous Virtual Reality - ISUVR 2008, P33, DOI 10.1109/ISUVR.2008.27
NR 50
TC 0
Z9 0
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2015
VL 26
IS 6
BP 549
EP 561
DI 10.1002/cav.1623
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DB2QO
UT WOS:000368354300002
DA 2024-07-18
ER

PT J
AU Huang, TC
   Huang, YJ
   Lin, WC
AF Huang, Ting-Chieh
   Huang, Yi-Jheng
   Lin, Wen-Chieh
TI Real-time horse gait synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character animation; motion synthesis; quadruped gait synthesis
ID LOCOMOTION
AB Horse locomotion exhibits rich variations in gaits and styles. Although there have been many approaches proposed for animating quadrupeds, there is not much research on synthesizing horse locomotion. In this paper, we present a horse locomotion synthesis approach. A user can arbitrarily change a horse's moving speed and direction, and our system would automatically adjust the horse's motion to fulfill the user's commands. At preprocessing, we manually capture horse locomotion data from Eadweard Muybridge's famous photographs of animal locomotion and expand the captured motion database to various speeds for each gait. At runtime, our approach automatically changes gaits based on speed, synthesizes the horse's root trajectory, and adjusts its body orientation based on the horse's turning direction. We propose an asynchronous time warping approach to handle gait transition, which is critical for generating realistic and controllable horse locomotion. Our experiments demonstrate that our system can produce smooth, rich, and controllable horse locomotion in real time. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Huang, Ting-Chieh; Huang, Yi-Jheng; Lin, Wen-Chieh] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lin, WC (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM wclin@cs.nctu.edu.tw
FU Taiwan National Science Council [NSC-100-2628-E-009-002-]; UST-UCSD
   International Center of Excellence in Advanced Bioengineering; Taiwan
   National Science Council I-RiCE Program [NSC-100-2911-I-009-101]
FX We thank the anonymous reviewers for their valuable comments. This work
   was supported in part by Taiwan National Science Council under grant
   NSC-100-2628-E-009-002- and the UST-UCSD International Center of
   Excellence in Advanced Bioengineering sponsored by the Taiwan National
   Science Council I-RiCE Program under Grant Number:
   NSC-100-2911-I-009-101.
CR Alexander R. M., 1996, Optima for animals
   Alexander R.McN., 1968, ANIMAL MECH
   ALEXANDER RM, 1983, J ZOOL, V201, P135, DOI 10.1111/j.1469-7998.1983.tb04266.x
   ALEXANDER RM, 1984, INT J ROBOT RES, V3, P49, DOI 10.1177/027836498400300205
   BIEWENER AA, 1983, J BIOMECH, V16, P565, DOI 10.1016/0021-9290(83)90107-0
   Coros S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964954
   Favreau L, 2004, S COMP AN SCA 2004 E
   Girard M., 1987, INTERACTIVE 3D GRAPH
   Golubovic D, 2003, LECT NOTES COMPUTER
   Hoyt DF, 2000, J EXP BIOL, V203, P221
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   KOKKEVIS E, 1995, GRAPH INTER, P10
   Kolter JZ, 2008, IEEE INT CONF ROBOT, P811, DOI 10.1109/ROBOT.2008.4543305
   Kry PG, 2009, COMPUT GRAPH FORUM, V28, P289, DOI 10.1111/j.1467-8659.2009.01368.x
   Marsland SA, 2005, P 9 INT C INF VIS
   Muybridge Eadweard., 1957, ANIMALS MOTION
   Playter R, 2006, P SPIE
   Poulakakis I, 2005, INT J ROBOT RES, V24, P239, DOI 10.1177/0278364904050917
   RAIBERT MH, 1991, COMP GRAPH, V25, P349
   RAIBERT MH, 1990, J BIOMECH, V23, P79, DOI 10.1016/0021-9290(90)90043-3
   Shi XH, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239532
   Simmons M, 2002, S COMP AN
   Sims K., 1994, SIGGRAPH 1994
   Skrba L, 2009, COMPUT GRAPH FORUM, V28, P1541, DOI 10.1111/j.1467-8659.2008.01312.x
   Torkos N, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P151
   Tsai M, 2011, INT J DIGITAL CONTEN, V5
   vandePanne M, 1996, IEEE COMPUT GRAPH, V16, P40, DOI 10.1109/38.486679
   WALTER M, 2001, SIGGRAPH 01
   Wampler K, 2009, ACM SIGGRAPH
   Zucker M, 2010, IEEE INT CONF ROBOT, P3589, DOI 10.1109/ROBOT.2010.5509176
NR 30
TC 16
Z9 22
U1 2
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2013
VL 24
IS 2
BP 87
EP 95
DI 10.1002/cav.1469
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 131ZB
UT WOS:000318036300003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, GY
   Lu, KK
AF Liu, Guanyang
   Lu, Keke
TI Networked multiplayer cooperative interaction using decoupled motion
   control method in a shared virtual environment with haptic, visual and
   movementfeedback
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE haptic; decoupled motion control; shared virtual environment; movement
   feedback; performance enhancement; computer network
ID COLLABORATION; SYSTEMS
AB This paper focuses on multiplayer cooperative interaction in a shared haptic environment based on a local area network. Decoupled motion control, which allows one user to manipulate a haptic interface to control only one-dimensional movement of an avatar, is presented as a new type haptic-based cooperation among multiple users. Users respectively move an avatar along one coordinate axis so that the motion of the avatar is the synthesis of movements along all axes. It is different from previous haptic cooperation where all users can apply forces on an avatar along any direction to move it, the motion of which completely depends on the resultant force. A novel concept of movement feedback is put forward where one user can sense other users' hand motions through his or her own haptic interface. The concept can also be explained wherein one person who is required to move a virtual object along only one axis can also feel the motions of the virtual object along other axes. Movement feedback, which is a feeling of motion, differs from force feedback, such as gravity, collision force and resistance. A spring-damper force model is proposed for the computation of motion feedback to implement movement transmission among users through haptic devices. Experimental results validate that movement feedback is beneficial for performance enhancement of such kind of haptic-based cooperation, and the effect of movement feedback in performance improvement is also evaluated by all subjects.Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Liu, Guanyang; Lu, Keke] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Inst Robot, Sch Mech Engn & Automat, Beijing 100191, Peoples R China.
C3 Beihang University
RP Liu, GY (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Inst Robot, Sch Mech Engn & Automat, Beijing 100191, Peoples R China.
EM gyliu@me.buaa.edu.cn
FU National Nature Science Foundation of China [60803070]
FX This research was supported by the National Nature Science Foundation of
   China (no. 60803070).
CR Adams R.J., 2001, HAPTICS E J IEEE ROB, V2, P1
   Basdogan C., 2000, ACM Transactions on Computer-Human Interaction, V7, P443, DOI 10.1145/365058.365082
   Buttolo P, 1997, COMPUT GRAPH-UK, V21, P421, DOI 10.1016/S0097-8493(97)00019-8
   Dinse H.R., 2005, ACM Transactions on Applied Perception (TAP), V2, P71, DOI [DOI 10.1145/1060581.1060583, 10.1145/1060581.1060583]
   Field A, 2018, Discovering Statistics Using IBM SPSS Statistics, Vfifth
   Field AP, 2003, BEHAV RES THER, V41, P1277, DOI 10.1016/S0005-7967(03)00034-2
   Gentry S., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3402
   Glencross M, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P115
   Hudson TC, 2004, PRESENCE-TELEOP VIRT, V13, P193, DOI 10.1162/1054746041382447
   Iglesias R, 2007, WSCG 2007, FULL PAPERS PROCEEDINGS I AND II, P241
   Jay C, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1275511.1275514
   Kim J, 2004, PRESENCE-TELEOP VIRT, V13, P328, DOI 10.1162/1054746041422370
   Kwon YM, 2005, LECT NOTES COMPUT SC, V3480, P913
   Marsh J, 2006, IEEE T VIS COMPUT GR, V12, P405, DOI 10.1109/TVCG.2006.40
   McNeely WA, 1999, COMP GRAPH, P401, DOI 10.1145/311535.311600
   Ni LY, 2007, J INTELL ROBOT SYST, V48, P209, DOI 10.1007/s10846-006-9086-9
   O'Malley MK, 2006, J DYN SYST-T ASME, V128, P75, DOI 10.1115/1.2168160
   Osama M., 2001, EUROHAPTICS, P60
   Pinelle D, 2009, GROUP 2009 PROCEEDINGS, P169
   Prada R, 2009, VIRTUAL REAL-LONDON, V13, P117, DOI 10.1007/s10055-009-0115-4
   Reed K, 2006, PSYCHOL SCI, V17, P365, DOI 10.1111/j.1467-9280.2006.01712.x
   Reed KB, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2109, DOI 10.1109/IROS.2006.282489
   Reiley CE, 2008, J THORAC CARDIOV SUR, V135, P196, DOI 10.1016/j.jtcvs.2007.08.043
   Sallnas E.-L., 2000, ACM Transactions on Computer-Human Interaction, V7, P461, DOI 10.1145/365058.365086
   Sallnas E.-L., 2003, Interact, P97
   Shen XJ, 2008, IEEE MULTIMEDIA, V15, P64, DOI 10.1109/MMUL.2008.9
   Shen XJ, 2004, EIGHTH IEEE INTERNATIONAL SYMPOSIUM ON DISTRIBUTED SIMULATION AND REAL-TIME APPLICATIONS, PROCEEDINGS, P53
   Shergill SS, 2003, SCIENCE, V301, P187, DOI 10.1126/science.1085327
   Wang D, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P291, DOI 10.1109/HAPTIC.2004.1287209
   WEGNER N, 1956, J GEN PSYCHOL, V55, P127, DOI 10.1080/00221309.1956.9920301
NR 30
TC 2
Z9 2
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2013
VL 24
IS 2
BP 97
EP 109
DI 10.1002/cav.1475
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 131ZB
UT WOS:000318036300004
DA 2024-07-18
ER

PT J
AU Du, P
   Tang, M
   Tong, RF
AF Du, Peng
   Tang, Min
   Tong, Ruofeng
TI Fast continuous collision culling with deforming noncollinear filters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE continuous collision detection; deforming noncollinear filters; bounding
   volume hierarchies; deformable models
AB We present a novel culling algorithm that uses deforming noncollinear filters to improve the performance of continuous collision detection (CCD) algorithms. The underlying idea is to use simple and effective filters, deforming noncollinear filters (NCFs), that reduce the number of false positives between the primitives. These filters are derived from the collinear conditions and can be easily combined with other culling methods. We have tested its performance on several benchmarks. Comparing with previous methods, we can reduce the number of false positives significantly and improve the overall performance of CCD algorithms, especially for simulations with large time steps. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Du, Peng; Tang, Min; Tong, Ruofeng] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310003, Zhejiang, Peoples R China.
   [Du, Peng; Tang, Min] Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Tang, M (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310003, Zhejiang, Peoples R China.
EM tang_m@zju.edu.cn
RI Tang, Min/KOC-3090-2024
FU National Basic Research Program [2011CB302205]; National Key Technology
   RD Program [2012BAD35B01]; Natural Science Foundation of China
   [61170140]; Natural Science Foundation of Zhejiang, China [Y1100069,
   Y1100018]
FX The project is supported in part by National Basic Research Program
   (2011CB302205), National Key Technology R&D Program (2012BAD35B01),
   Natural Science Foundation of China (61170140), and Natural Science
   Foundation of Zhejiang, China (Y1100069, Y1100018).
CR [Anonymous], 1997, J GRAPH TOOLS, DOI DOI 10.1080/10867651.1997.10487480
   Barbic J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778818
   Böttcher G, 2010, VISUAL COMPUT, V26, P903, DOI 10.1007/s00371-010-0450-1
   Bradshaw G, 2004, ACM T GRAPHIC, V23, P1, DOI 10.1145/966131.966132
   Chen M, 2010, VISUAL COMPUT, V26, P853, DOI 10.1007/s00371-010-0467-5
   Curtis S, 2008, P ACM SIGGRAPH S INT
   GOTTSCHALK S, 1996, P 23 ANN C COMP GRAP
   HUBBARD PM, 1993, P IEEE S RES FRONT V
   Kim D, 2009, COMPUT GRAPH FORUM, V28, P1791, DOI 10.1111/j.1467-8659.2009.01556.x
   Klosowski JT, 1998, IEEE T VIS COMPUT GR, V4, P21, DOI 10.1109/2945.675649
   Pabst S, 2010, COMPUT GRAPH FORUM, V29, P1605, DOI 10.1111/j.1467-8659.2010.01769.x
   Provot X, 1997, P GRAPH INT 1997 C M, V97
   Redon S, 2002, COMPUT GRAPH FORUM, V21, P279, DOI 10.1111/1467-8659.t01-1-00587
   Schvartzman SC, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778817
   Tang C, 2011, P ACM SIGGRAPH S INT
   Tang M, 2010, P ACM SIGGRAPH S INT
   Tang M., 2008, P 2008 ACM S SOL PHY
   Tang M, 2011, P ACM SIGGRAPH S INT
   Tang M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019630
   Tang M, 2010, GRAPH MODELS, V72, P7, DOI 10.1016/j.gmod.2010.01.001
NR 20
TC 4
Z9 9
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 375
EP 383
DI 10.1002/cav.1439
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100024
DA 2024-07-18
ER

PT J
AU Lee, CY
   Lee, S
   Chin, S
AF Lee, Chung-Yeon
   Lee, Sangyong
   Chin, Seongah
TI Multi-layer structural wound synthesis on 3D face
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE skin layer; facial tissue depth; disparity; wound synthesis; 3D face
ID SIMULATION
AB In this paper, we propose multi-layer structural wound synthesis on a 3D face. The fundamental knowledge of the facial skin is derived from the structure of tissue, being composed of epidermis, dermis and subcutis. The approach first defines the facial tissue depth map to measure details at various locations on the face. Each layer of skin in a wound image has been determined by hue-based segmentation. In addition, we have employed disparity parameters to realise 3D depth in order to make a wound model volumetric. Finally, we validate our methods using 3D wound simulation experiments. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Lee, Sangyong; Chin, Seongah] Sungkyul Univ, Coll Engn, Div Multimedia Engn, XiCom Lab, Anyang, South Korea.
   [Lee, Chung-Yeon] Seoul Natl Univ, Sch Comp Sci & Engn, Biointelligence Lab, Seoul, South Korea.
   [Lee, Chung-Yeon] Seoul Natl Univ, Interdisciplinary Program Neurosci, Seoul, South Korea.
C3 Sungkyul University; Seoul National University (SNU); Seoul National
   University (SNU)
RP Chin, S (corresponding author), Sungkyul Univ, Coll Engn, Div Multimedia Engn, XiCom Lab, Anyang, South Korea.
EM solideochin@gmail.com
CR Berkley J, 2004, IEEE T VIS COMPUT GR, V10, P314, DOI 10.1109/TVCG.2004.1272730
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   COOPER D M, 1991, Clinical Materials, V8, P263, DOI 10.1016/0267-6605(91)90040-M
   GLANNOU C, 2010, WAR SURG
   Hung A., 2009, WORLD ACAD SCI ENG T, V54, P134
   Igarashi T, 2007, FOUND TRENDS COMPUT, V3, P1, DOI 10.1561/0600000013
   Oh KJ, 2010, IEEE ICC
   Seevinck J, 2006, STUD HEALTH TECHNOL, V119, P491
   Shen YZ, 2006, ST HEAL T, V119, P512
   Stephan CN, 2008, J FORENSIC SCI, V53, P1257, DOI 10.1111/j.1556-4029.2008.00852.x
   Veredas F, 2010, IEEE T MED IMAGING, V29, P410, DOI 10.1109/TMI.2009.2033595
   Zhang MD, 2004, I C COMP GRAPH IM VI, P165
   Zhang Y, 2006, J VISUAL LANG COMPUT, V17, P126, DOI 10.1016/j.jvlc.2005.10.002
   Zhang ZY, 2004, INT J COMPUT VISION, V58, P93, DOI 10.1023/B:VISI.0000015915.50080.85
NR 14
TC 6
Z9 6
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 177
EP 185
DI 10.1002/cav.399
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700013
DA 2024-07-18
ER

PT J
AU Sloan, RJS
   Robinson, B
   Scott-Brown, K
   Moore, F
   Cook, M
AF Sloan, Robin J. S.
   Robinson, Brian
   Scott-Brown, Ken
   Moore, Fhionna
   Cook, Malcolm
TI Choreographing emotional facial expressions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE character animation; facial animation; emotional expression;
   practice-led research; human perception
AB While much is known about the appearance and human perception of emotional facial expressions, researchers and professionals experience difficulties when attempting to create believable animated characters. Methods for automating or capturing dynamic facial expressions have come on in leaps and bounds in recent years, resulting in increasingly realistic characters. However, accurate replication of naturalistic movement does not necessarily ensure authentic character performance. In this paper, the authors present a project which makes use of creative animation practices and artistic reflection as methods of research. The output of animation practice is tested experimentally by measuring observer perception and comparing the results with artistic observations and predictions. Ultimately, the authors aim to demonstrate that animation practice can generate new knowledge about dynamic character performance, and that arts-based methods can and should be considered valuable tools in afield often dominated by technical methods of research. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Sloan, Robin J. S.] Univ Abertay Dundee, Sch Comp & Engn Syst, Inst Arts Media & Comp Games, Dundee DD1 1HG, Scotland.
C3 University of Abertay Dundee
RP Sloan, RJS (corresponding author), Univ Abertay Dundee, Sch Comp & Engn Syst, Inst Arts Media & Comp Games, Kydd Bldg,Bell St, Dundee DD1 1HG, Scotland.
EM r.sloan@abertay.ac.uk
OI Sloan, Robin/0000-0002-8342-0785; Moore, Fhionna/0000-0001-9463-3148
CR [Anonymous], 1977, FACIAL ACTION CODING
   [Anonymous], 2004, VISUALISING RES GUID
   [Anonymous], REFLECTIVE PRACTICE
   [Anonymous], 1981, ILLUSION LIFE DISNEY
   Arya A, 2009, INT J COMPUT GAMES T, V2009, DOI 10.1155/2009/462315
   Battista S, 1999, IEEE MULTIMEDIA, V6, P74, DOI 10.1109/93.809236
   Callesen J, 2004, DIGIT CREAT, V15, P32, DOI 10.1076/digc.15.1.32.28157
   Egges A, 2004, COMPUT ANIMAT VIRT W, V15, P1, DOI 10.1002/cav.3
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   Ekman P., 1975, UNMASKING FACE
   HASEMAN B, 2007, PRACTICE RES APPROAC, pCH11
   HELZLE V, 2004, INT C COMP GRAPH INT
   Howell D.C., 2006, STAT METHODS PSYCHOL, V6th
   *IM METR, SUP FAC AN SIMPL
   Johns C., 1995, Towards Advanced Nursing Practice: key concepts forhealth care, P252
   Malatesta L, 2009, APPL INTELL, V30, P58, DOI 10.1007/s10489-007-0076-9
   Messinger DS, 1999, DEV PSYCHOL, V35, P701, DOI 10.1037/0012-1649.35.3.701
   Montagne Barbara, 2005, Cogn Process, V6, P136, DOI 10.1007/s10339-005-0050-6
   Nusseck M, 2008, J VISION, V8, DOI 10.1167/8.8.1
   PYUN H, 2003, P 2003 ACM SIGGR EUR
   SLOAN R, 2009, 1 INT C CREAT CONT T
   SLOAN RJS, 2010, 11 INT C COMP GRAPH
   TANGUY E, 2007, 20 INT JOINT C ART I
   Wehrle T, 2000, J PERS SOC PSYCHOL, V78, P105, DOI 10.1037/0022-3514.78.1.105
   Zemeckis Robert., 2009, CHRISTMAS CAROL
   Zemeckis Robert., 2007, Beowulf
NR 26
TC 1
Z9 1
U1 1
U2 4
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 203
EP 213
DI 10.1002/cav.339
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400008
DA 2024-07-18
ER

PT J
AU Liang, Z
   Xiao, J
   Zhuang, YT
   Chen, C
AF Liang, Zhang
   Xiao, Jun
   Zhuang, Yueting
   Chen, Cheng
TI Competitive motion synthesis based on hybrid control
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE character animation; motion capture and reuse; hybrid approach; RVM
AB We propose a simple and effective framework to deal with the problem of synthesizing interactive mid competitive motions while reflecting the interactions. Two nontrivial issues are addressed in synthesizing two-character motions in competitive environment: how to reveal the embedded routines While keeping visual reality and how to build interactive models based on singly captured motions. To solve these issues, we employ a hierarchical framework: the finite state machine (FSM) controls the state transition in the higher layer, and the hybrid approach controls the action selection in the lower layer. The proposed approach contains two folds: first, a rule-based control scheme is proposed to simulate routine steps based on statistical analysis. Second, the interactive models are designed for simulating dense interactions between two players. The Relevance Vector Machine (RVM) algorithm is adopted to select attack styles and coupled with motion transition graph to determine combination blows. Here we apply the proposed framework of hybrid paradigm to boxing sport as an example. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Liang, Zhang; Xiao, Jun; Chen, Cheng] ZJU, Microsoft Visual Percept Lab, Hangzhou, Zhejiang, Peoples R China.
   [Zhuang, Yueting] ZJU, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Xiao, J (corresponding author), Zhejiang Univ, Inst Artificial Intelligcnce, Hangzhou 310027, Peoples R China.
EM junx@cs.zju.edu.cn
CR Berger J. O., 1985, STAT DECISION THEORY, DOI DOI 10.1007/978-1-4757-4286-2
   COOPER S, 2007, P INT C COMP GRAPH I
   Hsu Eugene, 2004, P ACM SIGGRAPH EUR S, P69, DOI DOI 10.1145/1028523.1028534
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kulpa R, 2005, COMPUT GRAPH FORUM, V24, P343, DOI 10.1111/j.1467-8659.2005.00859.x
   Kwon T, 2008, IEEE T VIS COMPUT GR, V14, P707, DOI 10.1109/TVCG.2008.22
   Lee J, 2006, GRAPH MODELS, V68, P158, DOI 10.1016/j.gmod.2005.03.004
   Liu Karen, 2006, P 2006 ACM SIGGRAPHE, P215
   Meyn S. P., 1993, Markov chains and stochastic stability, DOI [10.1007%2F978-1-4471-3267-7, DOI 10.1007/978-1-4471-3267-7, 10.1007/978-1-4471-3267-7]
   Shapiro A, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P455, DOI 10.1109/PCCGA.2003.1238294
   Shum HPH, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P131
   Tipping M., 2000, NEURAL INFORM PROCES
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Zordan V. B., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P89
   Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249
NR 15
TC 0
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 225
EP 235
DI 10.1002/cav.304
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700016
DA 2024-07-18
ER

PT J
AU Kondo, R
   Anjyo, K
AF Kondo, Ryo
   Anjyo, Ken
TI Directable animation of elastic bodies with point-constraints
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE computer animation; elastically deformable objects; constraints;
   keyframe control
ID DEFORMATION
AB We propose a simple framework for making elastic body animation with point constraints. In general, a physics-based approach for constraint animation offers a variety of animations with physically correct realism, which are achieved by solving the equations of motion. However, in the digital animation industry, solving the equations of motion is an indirect path to creating more art-directed animations that maintain a plausible realism. Our algorithms provide animators a practical way to make elastic body animation with plausible realism, while effectively using point-constraints to offer directatorial control. The animation examples illustrate that our framework creates a wide variety of point-constraint animations of elastic objects with greater directability than existing methods. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Kondo, Ryo] Keio Univ, Fujisawa, Kanagawa 2528520, Japan.
C3 Keio University
RP Kondo, R (corresponding author), Keio Univ, 5322 Endo, Fujisawa, Kanagawa 2528520, Japan.
EM n04468rk@sfc.keio.ac.jp
CR [Anonymous], P 25 ANN C COMP GRAP
   [Anonymous], 2004, P 2004 ACM SIGGRAPH, DOI DOI 10.1145/1028523.1028541
   Baraff D., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P137, DOI 10.1145/237170.237226
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Baraff D., 1997, CMURITR9733
   BERGOU M, 2007, P SIGGRAPH 07
   Capell S, 2002, ACM T GRAPHIC, V21, P586, DOI 10.1145/566570.566622
   Capell S., 2005, P 2005 ACM SIGGRAPH, P301, DOI DOI 10.1145/1073368.1073412
   Choi MG, 2005, IEEE T VIS COMPUT GR, V11, P91
   Faloutsos P, 2001, COMP GRAPH, P251, DOI 10.1145/383259.383287
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   GISSLER M, 2006, P VIRT REAL INT PHYS, P25
   Hauser KK, 2003, PROC GRAPH INTERF, P247
   Hirota G, 2003, VISUAL COMPUT, V19, P291, DOI 10.1007/s00371-002-0188-5
   James DougL., 2002, SIGGRAPH 02, P582
   Jeon H, 2007, IEEE INT CONF ROBOT, P2582, DOI 10.1109/ROBOT.2007.363854
   Kondo R., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation - SCA '05, P127, DOI [10.1145/1073368.1073385, DOI 10.1145/1073368.1073385]
   LENOIR J, 2004, MIXING DEFORMABLE RI, P327
   METAXAS D, 1992, P SIGGRAPH 92, P309
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   TESCHNER M, 2004, VERSATILE ROBUST MOD, P312
   TU X., 1994, P ACM SIGGRAPH 94, P43, DOI DOI 10.1145/192161.192170
   WITKIN A, 1988, P SIGGRAPH 88, P159
NR 24
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 165
EP 173
DI 10.1002/cav.259
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200002
DA 2024-07-18
ER

PT J
AU Xu, LL
   Sun, HQ
   Wang, LF
AF Xu, Leilei
   Sun, Hanqiu
   Wang, Lifeng
TI Multi-resolution parametric synthesis of manipulative dynamic textures
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE dynamic textures; linear dynamic system; multi-resolution analysis
AB Dynamic textures are composed of spatially multi-scale and temporally coherent visual signals. lit this paper We propose a novel approach for multi-resolution parametric synthesis (MPS) of manipulative dynamic textures, including learning, analysis, and motion manipulation of layered feature spaces. The proposed approach separates the motions into different scales or frequencies, and the dynamic feature spaces are analyzed in modeling and then mapped to a global coordinate system to expose the multi-scale structures. Our approach emphasizes the importance of fine-scale data appearing more informative, While coarse signals are less focused. The synthesized dynamic textures using our MPS approach are strongly entranced in dynamic appearance than the single-scale LDS model, and also flexible in manipulating the decomposed feature spaces for creating different dynamic textures of the real world. Our experimental results showed the more faithful synthesized dynamic textures from input short videos, and their manipulative controls by simple editing of feature space basis, not only the whole video data. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Xu, Leilei] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   [Wang, Lifeng] Autodesk Shanghai, Shanghai, Peoples R China.
C3 Chinese University of Hong Kong; Autodesk, Inc.
RP Xu, LL (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
EM llxu@cse.cuhk.edu.hk
CR Borman S., 2004, EXPECTATION MAXIMIZA
   Chetverikov D, 2005, ADV SOFT COMP, P17
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   DORETTO G, 2003, P IEEE COMP SOC C CO
   DORETTO G, 2003, ICCV 03
   Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584
   Ghahramani Z, 2000, NEURAL COMPUT, V12, P831, DOI 10.1162/089976600300015619
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jack K., 2001, VIDEO DEMYSTIFIED, V3rd
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   LIU C, 2006, 17 BRIT MACH VIS C B, P859
   Lu Z., 2005, P WORKSHOP MOTION, P241
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Saisan P, 2001, PROC CVPR IEEE, P58
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   SZUMMER M, 1995, P IEEE INT C IM PROC, V3, P823
   TEH Y, 2003, ADV NEURAL INFORM PR, V15
   Wang YZ, 2004, IEEE T PATTERN ANAL, V26, P1348, DOI 10.1109/TPAMI.2004.76
   Wexler Yonatan, 2004, P IEEE COMP SOC C CO
   Woolfe F, 2006, LECT NOTES COMPUT SC, V3952, P549
   Yuan L, 2004, LECT NOTES COMPUT SC, V3022, P603
NR 23
TC 0
Z9 0
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 387
EP 398
DI 10.1002/cav.240
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200021
DA 2024-07-18
ER

PT J
AU Meredith, M
   Maddock, S
AF Meredith, Michael
   Maddock, Steve
TI Approximating character biomechanics with real-time weighted inverse
   kinematics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE motion capture reconfiguration; individualisation; rigid-body
   biomechanical animation; retargeting; character animation; inverse
   kinematics
AB In this paper we show how the expensive, offline dynamic simulations of character motions can be approximated using the cheaper weighted inverse kinematics (WIK)-based approach. We first show how a dynamics-based approach can be used to produce a motion that is representative Of a real target actor using the motion of a different source actor and the biomechanics of the target actor. This is compared against a process that uses WIK to achieve the same motion mapping goal without direct biomechanical input. The parallels between the results of the two approaches are described and further reasoned from a mathematical perspective. Thus we demonstrate how character biomechanics can be approximated with real-time WIK. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England.
C3 University of Sheffield
RP Meredith, M (corresponding author), Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England.
EM M.Meredith@dcs.shef.ac.uk
RI Maddock, Steve/J-1849-2016
OI Maddock, Steve/0000-0003-3179-0263
CR [Anonymous], 1981, Practical Optimization
   [Anonymous], 1987, An Introduction to Splines for use in Computer Graphics Geometric Modeling
   [Anonymous], 2005, HUMAN BODY COMPOSITI
   Barzel R., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P183
   Brogan DC, 1998, IEEE COMPUT GRAPH, V18, P58, DOI 10.1109/38.708561
   COHEN MF, 1992, COMP GRAPH, V26, P293
   Densley DJ, 1997, COMP ANIM CONF PROC, P8, DOI 10.1109/CA.1997.601034
   FEDOR M, 2003, COMPUTER GRAPHICS IN, P203
   GLEICHER M, 1998, INT C COMP GRAPH INT, P33
   Goldstein H., 2002, CLASSICAL MECH
   Goswami A, 1998, GAIT POSTURE, V8, P15, DOI 10.1016/S0966-6362(98)00014-9
   Green RD, 2004, IEEE T CIRC SYST VID, V14, P179, DOI 10.1109/TCSVT.2003.821976
   GRZESZCZUK R, 1998, SIGGRAPH 98, P9
   HODGINS JK, 1997, ACM SIGGRAPH, V97, P153
   HODGINS JK, 1995, ANN C SERIES, P71
   Kibble T.W. B., 1996, Classical Mechanics
   KOMURA T, 2001, GRAPHICS INTERFACE 2, P27
   KRAUS M, 1999, CENTRL EUROPEAN SEMI, V93, P77
   Liu CK, 2005, ACM T GRAPHIC, V24, P1071, DOI 10.1145/1073204.1073314
   MEREDITH M, 2006, THESIS U SHEFFIELD
   MEREDITH M, 2005, ACM COMPUTERS ENTERT, V3
   PARK J, 1997, COMPUGRAPHICS, V97, P260
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   Unuma M., 1993, COMPUTER ANIMATION, V93, P77
   Watt A., 1992, ADV ANIMATION RENDER
   Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507
   YAMANE K, 2000, P IEEE INT C ROB AUT, V1, P688
   YOO JH, 2000, MARKERLESS HUMAN GAI
   ZHAO JM, 1994, ACM T GRAPHIC, V13, P313, DOI 10.1145/195826.195827
   ZORDAN VB, 2005, P SIGGRAPH
   1988, NBDL87R003 NAV BIOD
NR 31
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 349
EP 359
DI 10.1002/cav.191
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000014
DA 2024-07-18
ER

PT J
AU Lee, WS
   Soon, A
AF Lee, Won-Sook
   Soon, Andrew
TI Facial shape and 3D skin
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D skin; exaggeration; skin transfer; mesh adaptation; generic model;
   global shape
AB We present novel ideas for facial shape and skin simulation on extremely detailed three-dimensional facial meshes. Our input database is composed of a small number of scanned human faces with resolutions up to several million triangles, where even the pores are clearly distinguished. We show how to decompose the facial meshes into the global shape of the face plus skin detail (3D skin), and then to reconstitute them. Our modeling methodology allows us to simulate the exaggeration of the facial global shape, retaining the original skin detail, as well as to transfer 3D skin from one face to another. First, we represent all the input faces in terms of a homogeneous structure oil the base model in low resolution by using mesh adaptation techniques. Second, the differences between the original mesh and a base mesh, which appear as skin detail, are captured and stored, so that each face is decomposed into the global shape (a base mesh) plus skin detail. Face reconstitution after global shape exaggeration and/or skin transfer enables delicate simulation of facial models. In addition, we can increase the resolution of any model scanned at a low resolution by transferring skin from a higher resolution model. Our method shows successful manipulation of the minute structure of 3D skin differently from other methods such as Normal Mapping, Displacement Mapping, Displaced Subdivision Surfaces, and Normal Meshes where none of these techniques show manipulation of minute structure like ours and only approximation is used while our method recovers the original structure. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Lee, WS (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, 800 King Edward Ave,POB 450,Stn A, Ottawa, ON K1N 6N5, Canada.
EM wslee@uottawa.ca
CR Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blinn J., 1978, Proceedings of the 5th annual conference on Computer graphics and interactive techniques-SIGGRAPH'78, V12, P286
   Borshukov G., 2003, ACM SIGGRAPH Sketches and Applications, page, P1
   BUI TD, 2003, P 6 IASTED INT C COM, P19
   COOK RL, 1984, P 11 ANN C COMP GRAP, P223, DOI DOI 10.1145/800031.808602
   Guskov I, 2000, COMP GRAPH, P95, DOI 10.1145/344779.344831
   Hilton A, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P246, DOI 10.1109/TDPVT.2002.1024069
   Kahler K., 2002, Eurographics Symp. on Comp. Animation, P55, DOI DOI 10.1145/545261.545271
   LANIR Y., 1987, HDB BIOENGINEERING, p11.1
   LASSETER J, 1987, COMPUTER GRAPHICS, V21, P35, DOI DOI 10.1145/37401.37407
   Lee A, 2000, COMP GRAPH, P85, DOI 10.1145/344779.344829
   Lee WS, 2000, IMAGE VISION COMPUT, V18, P355, DOI 10.1016/S0262-8856(99)00057-8
   Lee Y., 1995, SIGGRAPH, P55, DOI [10.1145/218380.218407, DOI 10.1145/218380.218407]
   Loop C, 1987, THESIS U UTAH
   Magnenat-Thalmann N, 2002, IEEE T INF TECHNOL B, V6, P317, DOI 10.1109/TITB.2002.806097
   NA K, 2004, COMPUT GRAPH FORUM, V23, P667
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   NOH JY, 2000, P ACM S VIRT REAL SO, P166
   OToole AJ, 1997, PERCEPTION, V26, P719, DOI 10.1068/p260719
   PEERCY M, 1997, P 24 ANN C COMP GRAP, P303, DOI DOI 10.1145/258734.258873
   Praun E, 2001, COMP GRAPH, P179, DOI 10.1145/383259.383277
   SOON A, 2006, IN PRESS VISUAL COMP
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Sun W, 2001, VISUAL COMPUT, V17, P457, DOI 10.1007/s003710100121
   TAYLOR J, 2002, P 1 INT WORKSH 3D VI, P70
   VLASIC D, 2005, P ACM SIGGRAPH 2005, P223, DOI DOI 10.1145/1073204.1073209
NR 27
TC 6
Z9 6
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 501
EP 512
DI 10.1002/cav.152
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400035
DA 2024-07-18
ER

PT J
AU Ali, N
   Ullah, S
   Raees, M
AF Ali, Numan
   Ullah, Sehat
   Raees, Muhammad
TI The effect of task specific aids on students' performance and
   minimization of cognitive load in a virtual reality chemistry laboratory
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cognitive aids; cognitive load; computer-based learning; virtual
   chemistry laboratory; virtual learning environment; virtual reality
ID ENVIRONMENT; TECHNOLOGY; ONLINE; MODELS; WORLD; LABS
AB Different cognitive aids (such as arrows, audio, etc.) are used in virtual laboratories for the enhancement of students' performance during their experimental tasks. However, excessive use of aids in virtual laboratories can lead to increased cognitive load, which affects task performance. In this article, we first conducted a subjective study with field experts to investigate about the practical implementation of our existing virtual chemistry laboratory. To consider the suggestions of the field experts, we propose task specific aids based virtual reality chemistry laboratory (TSA-VRCL) to minimize students' cognitive load and enhance their performance. The task specific aids consist of an arrow, animation, and audio aids that are separately rendered with each step of the experimental tasks. During evaluations, eighty students performed the experiments in four different groups using four different experimental conditions. Evaluations revealed that the proposed TSA-VRCL minimizes students' cognitive load and enhances their performance.
C1 [Ali, Numan; Ullah, Sehat; Raees, Muhammad] Univ Malakand, Dept Comp Sci & IT, Chakdara, Pakistan.
   [Ali, Numan] Air Univ Islamabad, Fac Comp & Artificial Intelligence FCAI, Dept Comp Games Dev, Islamabad, Pakistan.
   [Ali, Numan] Air Univ Islamabad, Fac Comp & Artificial Intelligence FCAI, Dept Comp Games Dev, Islamabad 44230, Pakistan.
C3 University of Malakand; Air University Islamabad; Quaid I Azam
   University; Air University Islamabad; Quaid I Azam University
RP Ali, N (corresponding author), Air Univ Islamabad, Fac Comp & Artificial Intelligence FCAI, Dept Comp Games Dev, Islamabad 44230, Pakistan.
EM numan.ali@mail.au.edu.pk
RI Ali, Dr. Numan/AAQ-6257-2020
OI Ali, Dr. Numan/0000-0002-9087-4814
CR Akaygun S, 2016, CHEM EDUC RES PRACT, V17, P788, DOI 10.1039/c6rp00067c
   Alam A., 2016, P PAK ACAD SCI, V53, P255
   Alam A, 2018, IEEE ACCESS, V6, P3400, DOI 10.1109/ACCESS.2017.2783951
   Albus P, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104154
   Ali N., P INT C COMP GRAPH A
   Ali N, 2022, EDUC INF TECHNOL, V27, P7629, DOI 10.1007/s10639-022-10936-6
   Ali N, 2022, EDUC INF TECHNOL, V27, P1635, DOI 10.1007/s10639-021-10691-0
   Ali N, 2020, J CHEM EDUC, V97, P3563, DOI 10.1021/acs.jchemed.0c00185
   Ali N, 2014, LECT NOTES COMPUT SC, V8853, P65, DOI 10.1007/978-3-319-13969-2_5
   Aljuhani Khulood, 2018, Smart Learning Environments, V5, DOI 10.1186/s40561-018-0067-9
   Andersen MS, 2021, J COMPUT ASSIST LEAR, V37, P183, DOI 10.1111/jcal.12478
   Clark RC, 2011, E-Learning and the Science of Instruction: Proven Guidelines for Consumers and Designers of Multimedia Learning, 3rd Edition, P1, DOI 10.1002/9781118255971
   Cohen J., 1992, Current Directions in Psychological Science, V1, P98, DOI [DOI 10.1111/1467-8721.EP10768783, 10.1111/1467-8721.ep10768783]
   Diwakar S., 2012, INNOVATIONS BIOTECHN, P379
   Driscoll M.P., 2005, PSYCHOL LEARNING INS, V3
   Farooq MS., SOCIAL SUPPORT ENTRE
   Faulconer EK, 2018, INT REV RES OPEN DIS, V19, P155
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   He L, 2016, INT CONF COMP SCI ED, P917, DOI 10.1109/ICCSE.2016.7581705
   Hern?ndez-Garces A., 2021, AFR J CHEM ED, V11, P85
   Hu-Au E, 2021, J SCI EDUC TECHNOL, V30, P862, DOI 10.1007/s10956-021-09925-0
   Jagodzinski P, 2015, J SCI EDUC TECHNOL, V24, P16, DOI 10.1007/s10956-014-9517-5
   Keeney-Kennicutt WL, 2013, ACS SYM SER, V1142, P181
   Khalid S., 2016, Sindh University Research Journal -Science Series, V48, P521
   LateNite Labs1, US
   Limniou M, 2008, COMPUT EDUC, V51, P584, DOI 10.1016/j.compedu.2007.06.014
   Mayer RE, 2001, J EDUC PSYCHOL, V93, P187, DOI 10.1037//0022-0663.93.1.187
   Merchant Z, 2012, COMPUT EDUC, V59, P551, DOI 10.1016/j.compedu.2012.02.004
   Model Science Software, CHEM ED SOFTW PAG
   Nonis D., 2005, 3D VIRTUAL LEARNING
   Orru G., 2019, INT S HUM MENT WORKL, P23, DOI [DOI 10.1007/978-3-030-14273-53, 10.1007/978-3-030- 14273-5_3, DOI 10.1007/978-3-030-14273-5_3, 10.1007/978-3-030-14273-5_3]
   PhET Interactive Simulations, ACID BAS SOL
   Ryoo K, 2018, J SCI EDUC TECHNOL, V27, P508, DOI 10.1007/s10956-018-9739-z
   Saadé R, 2005, INFORM MANAGE-AMSTER, V42, P317, DOI 10.1016/j.im.2003.12.013
   Scheckler RK, 2003, INT J DEV BIOL, V47, P231
   Schlender D., 2000, Spatial Cognition and Computation, V2, P421, DOI 10.1023/A:1015544021492
   Schofield D., 2010, SEMINAR NET INT J ME, V6, P76
   Schroeder NL, 2020, J EDUC PSYCHOL, V112, P254, DOI 10.1037/edu0000372
   Shudayfat E., P ANN DAAAM 2012
   Softpedia Virtual Chemistry Lab, US
   Stone DC, 2007, J CHEM EDUC, V84, P1488, DOI 10.1021/ed084p1488
   Su CH, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11041027
   Taibu R, 2021, INT J EDUC MATH SCI, V9, P353, DOI 10.46328/ijemst.1214
   Tsovaltzi D, 2010, INT J TECHNOL ENHANC, V2, P91, DOI 10.1504/IJTEL.2010.031262
   Tugtekin U, 2022, EDUC INF TECHNOL, V27, P7019, DOI 10.1007/s10639-022-10912-0
   Tuysuz C., 2010, International Online Journal of Educational Sciences, V2, P37
   Ullah S, 2016, J CHEM EDUC, V93, P2018, DOI 10.1021/acs.jchemed.5b00969
   Vaidyanath S., 2007, CHEM ENG EDUC, V41, P144
   Vector Chemistry Laboratory, US
   Vesga JB, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P645, DOI 10.1109/VR50410.2021.00090
   Winkelmann K, 2017, J CHEM EDUC, V94, P849, DOI 10.1021/acs.jchemed.6b00733
   Winkelmann K, 2014, J CHEM EDUC, V91, P1432, DOI 10.1021/ed500009e
   Wu BJ, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1882
   Yaron D, 2010, SCIENCE, V328, P584, DOI 10.1126/science.1182435
   Zhong Y, 2014, MULTIMED TOOLS APPL, V72, P2895, DOI 10.1007/s11042-013-1554-1
NR 55
TC 0
Z9 0
U1 4
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2194
EA JUL 2023
PG 26
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CY6H8
UT WOS:001021895100001
DA 2024-07-18
ER

PT J
AU Ji, XY
   Zhou, LF
AF Ji, Xiaoyun
   Zhou, Lanfeng
TI Location of acupuncture points based on graph convolution and 3D deep
   learning in virtual humans
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE acupoints location; computer aided medicine; computer animation; deep
   learning application; graph convolution; point cloud feature extraction;
   robotic version
AB Automatic acupoint searching is an indispensable part of intelligent acupuncture robot. Clinical practice have proofed that Dazhu, Fengmen and Xinshu, which could be located by Dazhui, are curative when these points are acupuncture. The existing methods are mainly based on regular or image. The regular-based methods are based on the experience of physicians, and the accuracy will decrease for different patients; While the image-based methods will lose some features in image. In order to solve the existing problems, we propose a novel graph convolution mixed with point cloud deep learning method. In this method, the skinned multi-person linear model is regarded as a graph structure input, and the coarsened graph is obtained by graph convolution. After feeding the coarsened graph into the PointNet network, the coordinates of Dazhui are output. Different from the existing methods, the proposed method can directly label the results on the adaptive model, thus improving the accuracy on different models. An optimization method based on graph structure is introduced for better fit the predicted acupoints to the surface. In addition, a dataset marked with Dazhui is constructed for training. Experiments show that the accuracy of positioning could meet the requirements of needle application under certain circumstances.
C1 [Ji, Xiaoyun; Zhou, Lanfeng] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai, Peoples R China.
   [Zhou, Lanfeng] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, 100 Haiquan Rd, Shanghai, Peoples R China.
C3 Shanghai Institute of Technology; Shanghai Institute of Technology
RP Zhou, LF (corresponding author), Shanghai Inst Technol, Sch Comp Sci & Informat Engn, 100 Haiquan Rd, Shanghai, Peoples R China.
EM 206141153@mail.sit.edu.cn; lfzhou@sit.edu.cn
CR Bulusu N, 2000, IEEE PERS COMMUN, V7, P28, DOI 10.1109/98.878533
   Chang M., 2017, 5 INT C FRONT MAN SC, P130
   Chang M., 2011, THESIS BEIJING U TEC
   Chen D., 2022, VISUAL COMPUT, V39, P1
   Choi DH, 2019, INTEGR MED RES, V8, P261, DOI 10.1016/j.imr.2019.11.005
   Cordonnier Jean-Baptiste, 2019, ARXIV
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dang L., 2020, AGR EQUIP TECHNOL, V46, P39
   Defferrard M, 2016, ADV NEUR IN, V29
   Dong S., 2018, IND COMMUN, V2, P187
   Du G., 2011, B SCI TECHNOLOGY, V27, P637
   freepatentsonline, APP DISPL AC POINTS
   Fu Y., 2020, INFORM TRADITIONAL C, V37, P106
   [郭雨怡 Guo Yuyi], 2020, [世界科学技术：中医药现代化, Modernization of Traditional Chinese Medicine and Materia Medica--World Science and Technology], V22, P3485
   He L., 2011, THESIS TIANJIN U
   HT Jiang JS Ming-Chun Huang aCHK, 2015, BODYNETS, P10975
   Huang L., 2006, NOMENCLATURE LOCATIO
   JQ Gong XS Liang Y, 2018, TCM, V31, P51
   Kaashki NN, 2023, IEEE T MULTIMEDIA, V25, P831, DOI 10.1109/TMM.2021.3132487
   Kaashki NN, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3106126
   Kim J., 2015, EVID-BASED COMPL ALT, V2015, P12
   Kingma D. P., 2014, arXiv
   Kipf T.N., 2017, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Lan Kun-Chan, 2019, Medicines (Basel), V6, DOI 10.3390/medicines6030087
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li WZ, 2020, ISPRS J PHOTOGRAMM, V164, P26, DOI 10.1016/j.isprsjprs.2020.03.016
   Li Y., 2022, SHANGHAI J ACU MOX, V41, P1228
   Li Y., 2018, P ADV NEUR INF PROC, VVolume 31, P1
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Liu Z., 2018, WORLD CHINESE MED, V13, P1992
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Qi CR, 2017, ADV NEUR IN, V30
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shi X., 2019, CHINESE ACUPUNCT MOX, V2020, P462
   Su JB, 2019, IEEE ACCESS, V7, P82154, DOI 10.1109/ACCESS.2019.2923632
   Sun X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P980, DOI 10.1145/3343031.3351042
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Wang C., 2020, Master's thesis,
   Wang Rui-Qing, 2020, Zhen Ci Yan Jiu, V45, P345, DOI 10.13702/j.1000-0607.200275
   Wang X., 2018, ELECT MEASUREMENT TE, V41, P66
   Wang Y., 2022, JETCM, V31, P1159
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang ZY, 2021, MICROPROCESS MICROSY, V87, DOI 10.1016/j.micpro.2021.104394
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Xia X., 2019, RES CONTROLLER REDUN, P130
   Yan X, 2020, PROC CVPR IEEE, P5588, DOI 10.1109/CVPR42600.2020.00563
   Yan Z., 2003, VIRTUAL REALITY ACUP
   Yang Xiao, 2018, arXiv
   Zhai J., 2011, THESIS TIANJIN U
   Zhang H., 2011, B SCI TECHNOLOGY, V5, P666
   Zhang SZ, 2021, IEEE ACCESS, V9, P8595, DOI 10.1109/ACCESS.2021.3049548
   Zhang ZY, 2019, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2019.00169
   Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571
   Zhou L., 2022, 18 ACM SIGGRAPH INT, P1
   Zhou Y., 2022, W J TRADIT CHIN MED, V35, P6
   Zhu M., 2012, Ph.D. thesis
NR 56
TC 0
Z9 0
U1 4
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2159
EA JUN 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HA0M3
UT WOS:001011812900001
DA 2024-07-18
ER

PT J
AU Cho, Y
   Kang, J
   Jeon, J
   Park, J
   Kim, M
   Kim, J
AF Cho, Yunsik
   Kang, Jiewon
   Jeon, Jaekyung
   Park, Jongchan
   Kim, Mingyu
   Kim, Jinmo
TI X-person asymmetric interaction in virtual and augmented realities
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE asymmetric virtual environment; augmented reality; immersive
   interaction; presence; virtual reality
ID IMMERSION; AUDIO; MODEL
AB This study proposes simple, highly immersive x-person asymmetric interactions that account for the experience type characteristics of asymmetric virtual environments, jointly experienced by virtual reality (VR) users and augmented reality (AR) users. The first person interactions for VR users are performed through the use of hand gestures, and they define a manipulation process that maps the gestures and object control scheme to provide intuitive interactions with the virtual environment and objects. The third person interaction for AR users is designed to view the overall virtual scene and recognize and judge situations to allow for intuitive communication and interactions among the virtual environment, objects, and users based on a touch interface. The core goal of this process is to provide all users who participate in asymmetric virtual environments with satisfying experiences and presence through individualized experience modes and roles. To this end, an application that uses the x-person asymmetric interactions was created. Furthermore, a survey experiment is performed to statistically analyze the interactions and verify that they provided users with a satisfactory experience, that is, a satisfactory sense of presence and social presence in each user's situation.
C1 [Cho, Yunsik; Kang, Jiewon; Jeon, Jaekyung; Park, Jongchan; Kim, Jinmo] Hansung Univ, Div Comp Engn, Seoul, South Korea.
   [Kim, Mingyu] Korea Univ, Program Visual Informat Proc, Seoul, South Korea.
C3 Hansung University; Korea University
RP Kim, J (corresponding author), Hansung Univ, Seoul 02876, South Korea.
EM jinmo.kim@hansung.ac.kr
OI Kim, Jinmo/0000-0002-1663-9306
FU Korea Foundation for the Advancement of Science and Creativity [2020
   URP]; National Research Foundation of Korea [NRF-2020R1F1A1063442]
FX Korea Foundation for the Advancement of Science and Creativity,
   Grant/Award Number: 2020 URP; National Research Foundation of Korea,
   Grant/Award Number: NRF-2020R1F1A1063442
CR Biocca F., 2001, 4 ANN INT WORKSH PRE, P1
   CARLSSON J, 1993, IEEE AP-S, P394, DOI 10.1109/APS.1993.385323
   Carvalheiro C, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1146, DOI 10.1145/2964284.2964293
   Cheng LP, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P417
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   Duval T., 2009, P INT C WEB3D TECHN, P33, DOI [10.1145/1559764.1559769, DOI 10.1145/1559764.1559769]
   Gonzalez-Liencres C, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00820
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P127, DOI [10.1109/VR.2019.8798080, 10.1109/vr.2019.8798080]
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Han S, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9020022
   Ibayashi Hikaru, 2015, SIGGRAPH ASIA 2015 E, P8
   IJsselsteijn Wijnand A, 2013, Eindhoven: Technische Universiteit Eindhoven, p3s9
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Kim M, 2020, INT J HUM-COMPUT INT, V36, P685, DOI 10.1080/10447318.2019.1680920
   Kim M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051141
   Lacoche J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139142
   Le KD, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139163
   Lee J, 2020, MULTIMED TOOLS APPL, V79, P979, DOI 10.1007/s11042-019-08220-w
   Lee J, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1756
   Leonardis D, 2017, IEEE T HAPTICS, V10, P305, DOI 10.1109/TOH.2016.2640291
   Marwecki S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173815
   Nordahl R, 2010, LECT NOTES COMPUT SC, V6192, P123, DOI 10.1007/978-3-642-14075-4_18
   Park W, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040476
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Remelli E, 2017, IEEE I CONF COMP VIS, P2554, DOI 10.1109/ICCV.2017.277
   Schissler C, 2016, IEEE T VIS COMPUT GR, V22, P1356, DOI 10.1109/TVCG.2016.2518134
   Sidorakis N, 2015, 2015 IEEE 1ST WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P15, DOI 10.1109/WEVR.2015.7151689
   Slater M., 2020, Frontiers in Virtual Reality, V1, DOI [DOI 10.3389/FRVIR.2020.00001, 10.3389/frvir.2020.00001]
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Vinayagamoorthy V, 2004, COMPUT GRAPH FORUM, V23, P1, DOI 10.1111/j.1467-8659.2004.00001.x
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Wrede KJ, 2000, CARCASSONNE HANS GLU
   Zhao Wenping, 2012, Proceedings of the ACM SIGGRAPH/eurographics symposium on computer animation. Eurographics Association, P33, DOI [10.2312/SCA/SCA12/033-042, DOI 10.2312/SCA/SCA12/033-042]
NR 35
TC 9
Z9 9
U1 0
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2021
VL 32
IS 5
DI 10.1002/cav.1985
EA DEC 2020
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WJ5HR
UT WOS:000594691600001
DA 2024-07-18
ER

PT J
AU Tauscher, JP
   Witt, A
   Bosse, S
   Schottky, FW
   Grogorick, S
   Castillo, S
   Magnor, M
AF Tauscher, Jan-Philipp
   Witt, Alexandra
   Bosse, Sebastian
   Schottky, Fabian W.
   Grogorick, Steve
   Castillo, Susana
   Magnor, Marcus
TI Exploring neural and peripheral physiological correlates of simulator
   sickness
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human-computer interaction; EEG; motion sickness; peripheral
   physiological measures; simulator sickness; virtual reality
ID MOTION SICKNESS; TIME
AB This article investigates neural and physiological correlates of simulator sickness (SS) through a controlled experiment conducted within a fully immersive dome projection system. Our goal is to establish a reliable, objective, and in situ measurable predictive indicator of SS. SS is a problem common to all types of visual simulators consisting of motion sickness-like symptoms that may be experienced while and after being exposed to a dynamic, immersive visualization. It leads to ethical concerns and impaired validity of simulator-based research. Due to the popularity of virtual reality devices, the number of people exposed to this problem is increasing and, therefore, it is crucial to find reliable predictors of this condition before any symptoms appear. Despite its relevance and the several theories about its origins, SS cannot yet be quantitatively modeled and predicted. Our results indicate that, while neural correlates did not materialize, physiological measures may be a solid early indicator of oncoming SS.
C1 [Tauscher, Jan-Philipp; Schottky, Fabian W.; Grogorick, Steve; Castillo, Susana; Magnor, Marcus] Tech Univ Carolo Wilhelmina Braunschweig, Inst Comp Graph, Muhlenpfordtstr 23, D-38106 Braunschweig, Germany.
   [Witt, Alexandra] Georg August Univ Gottingen, Int Max Planck Res Sch IMPRS Neurosci, Gottingen, Germany.
   [Bosse, Sebastian] Heinrich Hertz Inst Nachrichtentech Berlin GmbH, Fraunhofer Inst Telecommun, Berlin, Germany.
C3 Braunschweig University of Technology; University of Gottingen;
   Fraunhofer Gesellschaft
RP Tauscher, JP (corresponding author), Tech Univ Carolo Wilhelmina Braunschweig, Inst Comp Graph, Muhlenpfordtstr 23, D-38106 Braunschweig, Germany.
EM tauscher@cg.cs.tu-bs.de
RI Castillo, Susana/U-6432-2019; Bosse, Sebastian/HNR-3792-2023
OI Castillo, Susana/0000-0003-1245-4758; Grogorick,
   Steve/0000-0003-2837-2642; Tauscher, Jan-Philipp/0000-0003-2407-391X;
   Magnor, Marcus/0000-0003-0579-480X; Witt, Alexandra/0009-0000-3537-5249
FU German Science Foundation [INST 188/409-1, MA2555/15-1]
FX German Science Foundation, Grant/Award Numbers: INST 188/409-1 FUGG ICG
   Dome, MA2555/15-1 Immersive Digital Reality
CR [Anonymous], 1975, Motion sickness
   Bach DR, 2013, BIOL PSYCHOL, V94, P490, DOI 10.1016/j.biopsycho.2013.09.010
   Bach DR, 2010, INT J PSYCHOPHYSIOL, V75, P349, DOI 10.1016/j.ijpsycho.2010.01.005
   Bosse S, 2018, IEEE T CIRC SYST VID, V28, P1694, DOI 10.1109/TCSVT.2017.2694807
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Chen YC, 2010, NEUROIMAGE, V49, P2862, DOI 10.1016/j.neuroimage.2009.10.005
   Cohen MX, 2014, ISS CLIN COGN NEUROP, P1
   DENNISON M, 2019, PROC SPIE, V1006
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Doweck I, 1997, J AUTONOM NERV SYST, V67, P31, DOI 10.1016/S0165-1838(97)00090-8
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Gianaros PJ, 2003, PSYCHOPHYSIOLOGY, V40, P39, DOI 10.1111/1469-8986.00005
   Golding JF, 1997, AVIAT SPACE ENVIR MD, V68, P396
   Golding JF, 2006, AUTON NEUROSCI-BASIC, V129, P67, DOI 10.1016/j.autneu.2006.07.019
   Greco A, 2016, IEEE T BIO-MED ENG, V63, P797, DOI 10.1109/TBME.2015.2474131
   Grogorick S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1780, DOI [10.1109/VR.2019.8797902, 10.1109/vr.2019.8797902]
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Lin CY, 2012, APPL PHYS LETT, V101, DOI 10.1063/1.4739003
   Lin CT, 2007, P ANN INT IEEE EMBS, P3872, DOI 10.1109/IEMBS.2007.4353178
   Lin CT, 2013, IEEE T NEUR NET LEAR, V24, P1689, DOI 10.1109/TNNLS.2013.2275003
   Martin N., 2018, IBC 2018
   Naqvi SAA, 2015, AUSTRALAS PHYS ENG S, V38, P721, DOI 10.1007/s13246-015-0379-9
   Neukum A, 2006, KINETOSE FAHRSIMUL 2
   Nishiyama T, 2001, AUTON NEUROSCI-BASIC, V88, P117, DOI 10.1016/S1566-0702(01)00229-6
   Pane ES, 2018, INT CONF INTEL INFOR, P170, DOI 10.1109/ICIIBMS.2018.8549968
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Son HJ, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/7862539
   Stoner H, 2011, HDB DRIVING SIMULATI
   Tauscher JP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1794, DOI [10.1109/VR.2019.8797858, 10.1109/vr.2019.8797858]
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   WOOD CD, 1994, J CLIN PHARMACOL, V34, P628, DOI 10.1002/j.1552-4604.1994.tb02016.x
NR 35
TC 14
Z9 14
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1953
DI 10.1002/cav.1953
EA AUG 2020
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000563883500001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Podila, S
   Zhu, Y
AF Podila, Sahithi
   Zhu, Ying
TI Animating predator and prey fish interactions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE behavior animation; crowd simulation; fish escape maneuvers; fish
   schooling behavior
ID BEHAVIOR; EVASION; SIMULATION; MANEUVERS; SCHOOLS
AB Fish exhibit a wide variety of behavior, including swimming and schooling. Animating a school of fish is difficult because of the large number of fish and because a school of fish often swims in distinctive and coordinated patterns, particularly when they are attacked by a predator. Previous work in computer graphics has not provided satisfactory models to simulate the many distinctive interactions between a school of prey fish and their predator. In this paper, we present a fish school escape behavior model that can simulate 12 fish escape maneuvers identified in biological studies: compact, avoid, fast avoid, skitter, fountain, flash, ball, split, join, herd, vacuole, and hourglass. This behavior animation model can free an animator from dealing with the low-level animations but instead controls the fish behavior on a higher level by modifying a state machine and a small set of system parameters.
C1 [Podila, Sahithi; Zhu, Ying] Georgia State Univ, Dept Comp Sci, Atlanta, GA 30302 USA.
   [Podila, Sahithi; Zhu, Ying] Georgia State Univ, Creat Media Ind Inst, Atlanta, GA 30302 USA.
C3 University System of Georgia; Georgia State University; University
   System of Georgia; Georgia State University
RP Zhu, Y (corresponding author), Georgia State Univ, Dept Comp Sci, Atlanta, GA 30302 USA.; Zhu, Y (corresponding author), Georgia State Univ, Creat Media Ind Inst, Atlanta, GA 30302 USA.
EM yzhu@gsu.edu
OI Zhu, Ying/0000-0002-9155-2315
CR Demsar J, 2015, ECOL MODEL, V304, P22, DOI 10.1016/j.ecolmodel.2015.02.018
   Fernández-Juricic E, 2004, TRENDS ECOL EVOL, V19, P25, DOI 10.1016/j.tree.2003.10.003
   HALL SJ, 1986, MAR BIOL, V91, P143, DOI 10.1007/BF00397579
   Lee SH, 2006, J THEOR BIOL, V240, P250, DOI 10.1016/j.jtbi.2005.09.009
   Li WZ, 2015, COMPUT GRAPH FORUM, V34, P425, DOI 10.1111/cgf.12572
   Lopez Ugo, 2012, Interface Focus, V2, P693, DOI 10.1098/rsfs.2012.0033
   MAGURRAN AE, 1987, PROC R SOC SER B-BIO, V229, P439, DOI 10.1098/rspb.1987.0004
   MAGURRAN AE, 1990, ANN ZOOL FENN, V27, P51
   Marras S, 2012, ADAPT BEHAV, V20, P44, DOI 10.1177/1059712311426799
   Martinez-Gil F, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3117808
   Nottestad L, 1999, CAN J ZOOL, V77, P1540, DOI 10.1139/cjz-77-10-1540
   Oboshi T, 2003, P 8 INT C SIM SYNTH, VVIII, P386
   PARTRIDGE BL, 1980, J COMP PHYSIOL, V135, P315, DOI 10.1007/BF00657647
   Pitcher T. J., 1983, PREDATORS PREY FISHE, V54, P193
   Podila Sahithi, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10073, P586, DOI 10.1007/978-3-319-50832-0_57
   Podila S, 2017, P 43 GRAPH INT C 201
   Reynolds CW, 1988, SIGGRAPH COURSE NOTE
   Reynolds CW., 2001, Boids - Background and Update [Internet]
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Satoi D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925977
   Suppi R, 2004, LECT NOTES COMPUT SC, V3019, P505
   Terzopoulos D., 1999, Communications of the ACM, V42, P32, DOI 10.1145/310930.310966
   Terzopoulos D., 1994, Artificial Life, V1, P327
   Tunstrom K, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002915
   Vabo R, 1997, FISH OCEANOGR, V6, P155, DOI 10.1046/j.1365-2419.1997.00037.x
   Wang H, 2017, IEEE T VIS COMPUT GR, V23, P1454, DOI 10.1109/TVCG.2016.2642963
   Wang Xinjie, 2015, P 14 ACM SIGGRAPHEUR, P111, DOI DOI 10.1145/2786784.2786790
   Xiaoyuan Tu, 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P43
   Zheng M, 2005, J THEOR BIOL, V235, P153, DOI 10.1016/j.jtbi.2004.12.025
   Zhou SP, 2010, ACM T MODEL COMPUT S, V20, DOI 10.1145/1842722.1842725
NR 30
TC 4
Z9 4
U1 2
U2 34
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2019
VL 30
IS 2
AR e1866
DI 10.1002/cav.1866
PG 24
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR7XB
UT WOS:000463367400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Han, D
   Noh, J
   Shin, JS
AF Han, Daseong
   Noh, Junyong
   Shin, Joseph S.
TI Physics-based trajectory optimization with automatic time warping
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE model predictive control; optimal control; physics-based character
   animation; time warping
AB This paper presents a novel online model predictive control framework based on automatic time warping. In general, existing model predictive control frameworks employ reference motions with sampling time uniform and fixed. Unlike these, our framework allows to change the sampling time of a reference motion based on physics-based simulation so that the character effectively responds to external forces unexpectedly applied to it. In order to do so, we formulate an optimal control problem, taking into account both optimal time warping and full-body dynamics simultaneously. We adopt differential dynamic programming to produce an optimal control policy by solving the problem, which is used to compute the optimal feedback information for character motion and sampling time. We show the robustness of our framework to external perturbations through experiments. We also show the effectiveness of this framework for rhythmic motion synthesis.
C1 [Han, Daseong; Shin, Joseph S.] Handong Global Univ, Sch Entrepreneurship & ICT, Pohang 37554, South Korea.
   [Noh, Junyong] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon 305701, South Korea.
   [Shin, Joseph S.] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon 34141, South Korea.
C3 Handong Global University; Korea Advanced Institute of Science &
   Technology (KAIST); Korea Advanced Institute of Science & Technology
   (KAIST)
RP Han, D (corresponding author), Handong Global Univ, Sch Entrepreneurship & ICT, Pohang 37554, South Korea.
EM dshan@handong.edu
RI Noh, Junyong/C-1663-2011; Shin, Sung Yong/C-1955-2011
OI Shin (formerly Sung Yong Shin), Joseph S./0000-0003-4437-6459
FU National Research Foundation of Korea (NRF) [NRF-2017R1A2A1A05000979];
   Korea government (Ministry of Science, ICT and Future Planning)
FX National Research Foundation of Korea (NRF), Grant/Award Number:
   NRF-2017R1A2A1A05000979; Korea government (Ministry of Science, ICT and
   Future Planning)
CR Coros S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964954
   da Silva M, 2008, COMPUT GRAPH FORUM, V27, P371, DOI 10.1111/j.1467-8659.2008.01134.x
   da Silva M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360681
   Guenter B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239559
   Han D, 2016, COMPUT GRAPH FORUM, V35, P533, DOI 10.1111/cgf.12853
   Han D, 2014, COMPUT GRAPH FORUM, V33, P245, DOI 10.1111/cgf.12323
   Hodgins J. K., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P71, DOI 10.1145/218380.218414
   Hsu E, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P45
   Jacobson D. H., 1970, DIFFERENTIAL DYNAMIC
   Kim T-h, 2003, ACM T GRAPH, V22
   Kumar V, 2014, IEEE INT C ROB AUT W
   Kwon Taesoo, 2010, P 2010 ACM SIGGRAPHE, P129
   Liu Karen, 2006, P 2006 ACM SIGGRAPHE, P215
   Mordatch I., 2010, ACM T GRAPH, V29
   Muico U, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966395
   Muico U, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531387
   Park SI, 2004, COMPUT ANIMAT VIRT W, V15, P125, DOI 10.1002/cav.15
   Peng XB, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766910
   Pratt J, 2001, INT J ROBOT RES, V20, P129, DOI 10.1177/02783640122067309
   Raibert M. H., 1991, Computer Graphics, V25, P349, DOI 10.1145/127719.122755
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Tassa Y., 2012, 2012 IEEE RSJ INT C
   Tassa Y, 2014, IEEE INT C ROB AUT W
   Todorov E, 2014, 2014 IEEE INT C ROB
   Witkin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P105, DOI 10.1145/218380.218422
   Ye YT, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778811
   Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556
NR 27
TC 0
Z9 0
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1813
DI 10.1002/cav.1813
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100004
DA 2024-07-18
ER

PT J
AU Jung, JK
   Ahn, YJ
AF Jung, Jinki
   Ahn, Young Joong
TI Effects of interface on procedural skill transfer in virtual training:
   Lifeboat launching operation study
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE interface; maritime safety; procedural skill transfer; virtual reality;
   virtual training
ID INTERACTION FIDELITY; REALITY; ENVIRONMENT; KNOWLEDGE
AB A comparative study assessing the effect of interface type on procedural skill transfer during virtual training is presented. The aim of this research is to evaluate the transferability of two aspects of procedural skills, that is, procedural knowledge and technical skills. We established one group with a lecture and three virtual training groups with a combination of output and input devices: a monitor and keyboard/mouse, a head-mounted display (HMD) and joypad, and an HMD and wearable sensors. The task for assessment was a lifeboat launching operation that requires a participant to memorize a 10-step procedure utilizing 14 different pieces of equipment that should be manipulated in each step. Before and after training, we evaluated the participants' procedural knowledge and technical skill on a real lifeboat. The monitor and keyboard/mouse group showed the best performance in a procedural knowledge assessment that addressed visually induced recollections from the real lifeboat. Alternatively, in the assessment of technical skills that determined manipulation ability that requires word-based mnemonics, the HMD and wearable sensors group outperformed the other groups. Moreover, the results showed that the virtual training was a more efficient training format for short-term training than a lecture due to the freedom of observation viewpoint, despite simulator sickness.
C1 [Jung, Jinki] Korea Res Inst Ships & Ocean Engn, Maritime Safety Div, Daejeon, South Korea.
   [Ahn, Young Joong] Korea Inst Maritime & Fisheries Technol, Busan, South Korea.
C3 Korea Research Institute of Ships & Ocean Engineering
RP Jung, JK (corresponding author), Korea Res Inst Ships & Ocean Engn, Maritime Safety Div, Daejeon, South Korea.
EM your.jinki.jung@gmail.com
OI Jung, Jinki/0000-0001-6202-871X
FU Ministry of Oceans and Fisheries of Korea [PMS3840]
FX Ministry of Oceans and Fisheries of Korea, Grant/Award Number: PMS3840
CR [Anonymous], 2018, Understanding Virtual Reality: Interface Application, and Design
   Backlund P, 2007, 11 INT C INF VIS ZUR
   BAILEY JH, 1994, HUM FAC ERG SOC P, P1158, DOI 10.1177/154193129403801803
   Cabral M.C., 2005, P 2005 LATIN AM C HU, DOI DOI 10.1145/1111360.1111370
   Carlson P, 2015, IEEE T VIS COMPUT GR, V21, P770, DOI 10.1109/TVCG.2015.2393871
   Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004
   Chellali A, 2016, INT J HUM-COMPUT ST, V96, P22, DOI 10.1016/j.ijhcs.2016.07.005
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Gallagher AG, 2013, ANN SURG, V257, P1025, DOI 10.1097/SLA.0b013e318284f658
   Ganier F, 2014, ERGONOMICS, V57, P828, DOI 10.1080/00140139.2014.899628
   Hall CR, 1998, P IEEE VIRT REAL ANN, P184, DOI 10.1109/VRAIS.1998.658488
   HAMBLIN CJ, 2005, THESIS
   Insinna V, 2013, NATL DEFENSE, P26
   International Maritime Organization, 2006, GUID DEV OP MAINT MA
   International Maritime Organization [IMO], 2001, INT CONV SAF LIF SEA
   Jorge Vitor A. M., 2013, P 19 ACM S VIRT REAL, P83, DOI DOI 10.1145/2503713.2503725
   Lee C, 2010, VIRT REAL C BOST MA
   Lindsey S., 2017, THESIS
   Mania K, 2006, IEEE T VIS COMPUT GR, V12, P396, DOI 10.1109/TVCG.2006.55
   Mania K, 2003, PRESENCE-TELEOP VIRT, V12, P296, DOI 10.1162/105474603765879549
   Mania Katerina., 2004, Proceedings of the 1st Symposium on Applied Perception in Graphics and Visualization, APGV '04, P39, DOI [10.1145/1012551.1012559, DOI 10.1145/1012551.1012559]
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Swanson R.A., 1987, J EUR IND TRAIN, V11, P7
   Tecchia Franco., 2014, Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology, P73, DOI DOI 10.1145/2671015.2671123
   Vidani A.C., 2010, 2010 2 INT C GAM VIR
   Waller D, 1998, PRESENCE-TELEOP VIRT, V7, P129, DOI 10.1162/105474698565631
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Yohan J., 2000, NATO S INF PROC TECH
NR 31
TC 24
Z9 25
U1 1
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1812
DI 10.1002/cav.1812
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100003
DA 2024-07-18
ER

PT J
AU Li, TT
   Yang, LY
   Wang, ML
   Fan, YL
   Zhang, FY
   Guo, SH
   Chang, J
   Zhang, JJ
AF Li, Tingting
   Yang, Liying
   Wang, Meili
   Fan, Yuling
   Zhang, Feiyu
   Guo, Shihui
   Chang, Jian
   Zhang, Jian Jun
TI Visual saliency-based bas-relief generation with symmetry composition
   rule
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE bas-relief; symmetry composition; visual saliency
AB This paper presents a novel approach for bas-relief generation and synthesis. In contrast to previous methods, we divide this problem into two parts: the selection of the best view and arrangement of the relief layout. Taking these into account, we incorporate the visual saliency and photographic composition rules into the bas-relief generation. Additionally, a nonlinear compression function is used to compress the models, and finally, we implement surface parameterization by directly manipulating the mesh triangles to generate curved surface bas-relief. We validate our approach through a variety of models. The results indicate that the proposed approach is effective to adapt different types of target surface with topology unchanged. Comparing with conventional methods, our approach is able to effectively produce bas-relief with a reasonable layout and distinct details.
C1 [Li, Tingting; Yang, Liying; Wang, Meili; Fan, Yuling; Zhang, Feiyu] Northwest Agr & Forestry Univ, Coll Informat Engn, Yangling, Xianyang, Peoples R China.
   [Wang, Meili; Fan, Yuling] Minist Agr, Key Lab Agr Internet Things, Yangling, Xianyang, Peoples R China.
   [Wang, Meili] Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling, Xianyang, Peoples R China.
   [Guo, Shihui] Xiamen Univ, Software Sch, Xiamen, Peoples R China.
   [Chang, Jian; Zhang, Jian Jun] Bournemouth Univ, Natl Ctr Comp Animat, Bournemouth, Dorset, England.
C3 Northwest A&F University - China; Ministry of Agriculture & Rural
   Affairs; Xiamen University; Bournemouth University
RP Wang, ML (corresponding author), Northwest Agr & Forestry Univ, Coll Informat Engn, Yangling, Xianyang, Peoples R China.
EM wml@nwsuaf.edu.cn
RI zhang, feiyu/KRP-6203-2024
FU National Natural Science Foundation [61402374, 61702433, 61661146002];
   Fujian Provincial Education & Research Project for Young Teachers
   [JAT170014]
FX National Natural Science Foundation, Grant/Award Number: 61402374,
   61702433 and 61661146002; Fujian Provincial Education & Research Project
   for Young Teachers, Grant/Award Number: JAT170014
CR Alexander C, 2004, ART BOOK, V12, P58
   [Anonymous], 1981, Attention and Performance
   Brachmann A, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00102
   Cignoni P., 1997, Journal of Graphics Tools, V2, P15, DOI 10.1080/10867651.1997.10487476
   Gardner J., 2011, THESIS
   Getis A, 1987, SPATIAL AUTOCORRELAT
   Lau M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925927
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Li Bo, 2012, Journal of Computer Aided Design & Computer Graphics, V24, P799
   Liu Sheng-lan, 2011, Journal of Computer Applications, V31, P33, DOI 10.3724/SP.J.1087.2011.00033
   Mousa M, 2007, C COMP GRAPH APPL MA
   Peyre G, 2001, GRAPH THEORY TOOLBOX
   Rossion B, 2003, NEUROIMAGE, V20, P1609, DOI 10.1016/j.neuroimage.2003.07.010
   Secord A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019628
   Song W, 2007, IEEE INT C SHAP MOD
   Sun XF, 2009, IEEE T VIS COMPUT GR, V15, P642, DOI 10.1109/TVCG.2009.21
   Tao Y, 2009, IEEE PAC VIS S BEIJ
   Wang ML, 2016, CHIN J MECH ENG-EN, V29, P1128, DOI 10.3901/CJME.2016.0720.084
   Wang ML, 2013, IETE TECH REV, V30, P454, DOI 10.4103/0256-4602.125659
   Wang ML, 2012, VISUAL COMPUT, V28, P1127, DOI 10.1007/s00371-011-0663-y
   Wu J, 2013, COMPUT AIDED DESIGN, V45, P671, DOI 10.1016/j.cad.2012.11.002
   Yao L Q, 2013, THESIS
   Zhang DB, 2017, COMPUT AIDED DESIGN, V87, P1, DOI 10.1016/j.cad.2017.02.003
   Zhang YW, 2016, COMPUT GRAPH FORUM, V35, P311, DOI 10.1111/cgf.13028
   Zhang YW, 2015, IEEE T VIS COMPUT GR, V21, P328, DOI 10.1109/TVCG.2014.2377773
   Zhou Shizhe, 2010, Journal of Computer Aided Design & Computer Graphics, V22, P434
NR 26
TC 2
Z9 2
U1 2
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1815
DI 10.1002/cav.1815
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Feng, G
   Liu, SG
AF Feng, Gang
   Liu, Shiguang
TI Detail-preserving SPH fluid control with deformation constraints
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE control force transfer; fluid control; fluid simulation; point
   correspondence; SPH
ID VORTEX PARTICLE METHOD; SMOKE; WATER
AB It is challenging to drive particle-based smoothed-particle hydrodynamics fluid to match the target shape and the deforming fluid shape between different models smoothly, especially when the natural fluid motion must be preserved. To achieve the desired behavior, we first generate control particles by sampling the target shapes and then apply a deformation constraint to each control particle, with its neighboring fluid particles keeping details within its influence region. For the generation of control particles, we classify input models into source object and target object, then separately sample them by voxelization method, and generate source control particles and target control particles, respectively. Our deformation constraint includes two parts. In the first part, we deform the source control model to the target control model according to specific space point correspondence between source control particles and target control particles; then, fluid particles are attracted by control particles and complete deformation between different shapes. In the second part, to reduce the lacking of fluid details when fluid deforms, we introduce a new control energy transfer mechanism for control particles. This deformation constraint is solved under smoothed-particle hydrodynamics-based fluid simulation framework, which makes our simulation fast, robust, and well suitable for interactive applications. Various experiments demonstrated the effectiveness of our method.
C1 [Feng, Gang; Liu, Shiguang] Tianjin Univ, Sch Comp Sci & Technol, 135 Yaguan Rd, Tianjin, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, 135 Yaguan Rd, Tianjin, Peoples R China.
EM lsg@tju.edu.cn
FU Natural Science Foundation of China [61170118, 61672375]; Application
   Foundation Research Plan Project of Tianjin [14JCQNJC00100]; RGC
   research [416212]; UGC fund for research [4055060]
FX Natural Science Foundation of China, Grant/Award Number: 61170118, and
   61672375; Application Foundation Research Plan Project of Tianjin,
   Grant/Award Number: 14JCQNJC00100; RGC research, Grant/Award Number:
   416212; UGC fund for research, Grant/Award Number: 4055060
CR Cornelis J, 2015, COMPUT GRAPH-UK, V52, P72, DOI 10.1016/j.cag.2015.07.022
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811
   Madill J., 2013, PROC GRAPHICS INTERF, P125
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Pan ZR, 2012, COMPUT GRAPH FORUM, V31, P2029, DOI 10.1111/j.1467-8659.2012.03195.x
   Pfaff T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866196
   Rasmussen N, 2004, P 2004 ACM SIG GRAPH, P193
   Saba S, 2005, SMI 05 INT C SHAP MO
   Scharnowski K, 2014, COMPUT GRAPH FORUM, V33, P191, DOI 10.1111/cgf.12375
   Schreiner J, 2004, ACM T GRAPHIC, V23, P870, DOI 10.1145/1015706.1015812
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Shi L, 2005, P 2005 ACM SIGGRAPH
   Thürey N, 2009, GRAPH MODELS, V71, P221, DOI 10.1016/j.gmod.2008.12.007
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Weng YL, 2013, COMPUT GRAPH FORUM, V32, P381, DOI 10.1111/cgf.12246
   Yoon JC, 2009, COMPUT GRAPH FORUM, V28, P1853, DOI 10.1111/j.1467-8659.2009.01563.x
   Zayer R, 2005, COMPUT GRAPH FORUM, V24, P601, DOI 10.1111/j.1467-8659.2005.00885.x
   ZHANG S, 2015, MATH PROBL ENG, V2015, P1, DOI DOI 10.1093/T0XSCI/KFU311
   Zhang XY, 2015, COMPUT ANIMAT VIRT W, V26, P357, DOI 10.1002/cav.1637
   Zhu B, 2010, COMPUT GRAPH FORUM, V29, P2207, DOI 10.1111/j.1467-8659.2010.01809.x
NR 24
TC 9
Z9 11
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2018
VL 29
IS 1
AR e1781
DI 10.1002/cav.1781
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FV0GZ
UT WOS:000424235300002
DA 2024-07-18
ER

PT J
AU Qiu, YX
   Yang, LP
   Li, S
   Xia, Q
   Qin, H
   Hao, AM
AF Qiu, Yuxing
   Yang, Lipeng
   Li, Shuai
   Xia, Qing
   Qin, Hong
   Hao, Aimin
TI Novel fluid detail enhancement based on multi-layer depth regression
   analysis and FLIP fluid simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE depth peeling; FLIP; fluid detail enhancement; GPU; image space method;
   time-space analysis model
ID ANIMATION; WATER
AB In this paper, we propose a novel integrated method for effective modeling and realistic enhancement of scale-sensitive fluid simulation details. The core of our method is the organic of multi-layer depth image regression analysis and fluid implicit particle fluid simulation of which the regression analysis induces the criterion where the fluid details should be produced. First, we capture the depth buffer of the fluid surface dynamically from the top of scene. Second, we employ depth peeling technique to decompose the target fluid volume into multiple depth layers and conduct time-space analysis over surface layers. Third, we propose a logistic regression-based model to rigorously pinpoint the complex interacting regions, wherein multiple detail-relevant factors are taken into account based on the captured multiple depth layers. Finally, details are enhanced by animating extra diffuse materials and augmenting the air-fluid mixing phenomenon. It is evident that, with depth peeling technology, we can afford rigorous analysis not only across surface layers at different fluid depth but along the depth direction as well. After integrating the analysis results from these two sources, we are capable of performing detail enhancement both on the fluid surface and inside the fluid to obtain a great visual effect, even when large occlusion exists. Directly benefiting from the flexibility of image-space-dominant processing, our unified framework can be entirely implemented on graphics processing units and thus achieves interactive performance. For various fluid phenomena with different diffuse materials (e.g., spray, foam, and bubble), comprehensive experiments and evaluations have demonstrated its superiority in high-fidelity fluid detail enhancement and its interaction with surrounding environment.
C1 [Qiu, Yuxing; Yang, Lipeng; Li, Shuai; Xia, Qing; Hao, Aimin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, New York, NY USA.
C3 Beihang University; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook
RP Li, S; Hao, AM (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM lishuai@buaa.edu.cn; ham_buaa@163.com
OI Xia, Qing/0000-0002-0328-7882
FU National Natural Science Foundation of China [61190120, 61190125,
   61190124, 61300067, 61672077, 6167214, 61602341, 61532002]
FX National Natural Science Foundation of China, Grant/Award Number:
   61190120, 61190125, 61190124, 61300067, 61672077, 6167214, 61602341 and
   61532002
CR Adams B, 2007, P ACM SIGGRAPH 2007, V26, P481
   Ando R, 2012, IEEE T VIS COMPUT GR, V18, P1202, DOI 10.1109/TVCG.2012.87
   [Anonymous], P ACM SIGGRAPH EUR S
   Bagar F, 2010, COMPUT GRAPH FORUM, V29, P1383, DOI 10.1111/j.1467-8659.2010.01734.x
   Bemardon F. F., 2006, Journal of Graphics Tools, V11, P1
   Borland D, 2006, PROC SPIE, V6060, DOI 10.1117/12.641497
   Boyd L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159522
   Cagniart C, 2010, LECT NOTES COMPUT SC, V6314, P326, DOI 10.1007/978-3-642-15561-1_24
   Carmi A, 2012, AUTOMATICA, V48, P2454, DOI 10.1016/j.automatica.2012.06.086
   Ciocca G, 2015, MULTIMED TOOLS APPL, V74, P3013, DOI 10.1007/s11042-013-1766-4
   Cornelis J, 2014, COMPUT GRAPH FORUM, V33, P255, DOI 10.1111/cgf.12324
   Diefenbach PJ, 1996, IRCS TECHNICAL REPOR
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Everitt C., 2001, WHITE PAPER, V7, P491
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Gerszewski D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508430
   Goswami P., 2010, P 2010 ACM SIGGRAPHE, P55
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hong J-M, 2008, BUBBLES ALIVE
   Hong JM, 2003, COMPUT GRAPH FORUM, V22, P253, DOI 10.1111/1467-8659.00672
   Ihmsen M, 2012, VISUAL COMPUT, V28, P669, DOI 10.1007/s00371-012-0697-9
   Ihmsen M, 2011, GRAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P225
   Ihmsen Markus, 2014, P 35 ANN C EUR ASS C, DOI [10.2312/egst.20141034, DOI 10.2312/EGST.20141034]
   Khan Z. H., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1402, DOI 10.1109/ICCVW.2011.6130415
   Kim J., 2006, Proc ACM SIGGRAPH/Eurograph Symp Comp Anim, SCA '06, P335
   Krog OE, 2012, LECT NOTES COMPUT SC, V7134, P98
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   Lu F, 2009, IEEE AS PAC POW EN E, P1
   MAMMEN A, 1989, IEEE COMPUT GRAPH, V9, P43, DOI 10.1109/38.31463
   Mihalef V, 2009, COMPUT GRAPH FORUM, V28, P229, DOI 10.1111/j.1467-8659.2009.01362.x
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Nagy Z, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P429, DOI 10.1109/PCCGA.2003.1238289
   Narang SK, 2013, IEEE T SIGNAL PROCES, V61, P4673, DOI 10.1109/TSP.2013.2273197
   Nielsen M. B., 2013, ACM T GRAPHIC, V32
   Selino A, 2013, COMPUT GRAPH FORUM, V32, P75, DOI 10.1111/j.1467-8659.2012.03232.x
   Solenthaler B., 2008, P 2008 ACM SIGGRAPH, P211, DOI 10.2312/SCA/SCA08/211-218
   Takahashi T, 2003, COMPUT GRAPH FORUM, V22, P391, DOI 10.1111/1467-8659.00686
   Thürey N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P191
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Um K, 2014, COMPUT GRAPH FORUM, V33, P209, DOI 10.1111/cgf.12489
   Van der Laan W.J., 2009, P 2009 S INT 3D GRAP, P91, DOI [DOI 10.1145/1507149.1507164, 10.1145/1507149.1507164]
   Wang CB, 2013, VISUAL COMPUT, V29, P937, DOI 10.1007/s00371-013-0849-6
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yang LP, 2014, COMPUT GRAPH FORUM, V33, P199, DOI 10.1111/cgf.12488
   Yang LP, 2012, COMPUT GRAPH FORUM, V31, P2037, DOI 10.1111/j.1467-8659.2012.03196.x
   Zheng W., 2006, Proc. of the ACM Siggraph/Eurographics Symposium on Computer Animation, P325
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 51
TC 2
Z9 2
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2017
VL 28
IS 5
AR e1741
DI 10.1002/cav.1741
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9XG
UT WOS:000417251100006
DA 2024-07-18
ER

PT J
AU Cai, ZX
   Chang, XF
   Wang, YZ
   Yi, XD
   Yang, XJ
AF Cai, Zhongxuan
   Chang, Xuefeng
   Wang, Yanzhen
   Yi, Xiaodong
   Yang, Xue-Jun
TI Distributed control for flocking and group maneuvering of nonholonomic
   agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE distributed control; flocking; multiagent system; nonholonomic system
ID MULTI-AGENTS
AB In this paper, we propose a distributed control approach for flocking and group maneuvering of nonholonomic agents, with constrained kinematic properties commonly found in practical systems, such as fixed-wing unmanned aerial vehicles. Flocking of agents with differential drive kinematics is addressed by introducing a virtual leader-follower mechanism into the Olfati-Saber's algorithm, which is originally proposed for holonomic agents with double integrator kinematics. Then, group maneuverability of the flock is achieved by superimposing a group motion onto each agent's flocking motion. Moreover, it is proven that speed limits are intrinsically guaranteed by the approach, which renders it more applicable in practical systems. Experimental results in MATLAB and Gazebo, a popular robotic simulator, are presented to evaluate the performance and demonstrate the effectiveness of the proposed approach.
C1 [Cai, Zhongxuan; Chang, Xuefeng; Wang, Yanzhen; Yi, Xiaodong; Yang, Xue-Jun] Natl Univ Def Technol, Sch Comp, State Key Lab High Performance Comp HPCL, Changsha, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Wang, YZ (corresponding author), Natl Univ Def Technol, Sch Comp, State Key Lab High Performance Comp HPCL, Changsha, Hunan, Peoples R China.
EM yzwang@nudt.edu.cn
RI YANG, Xue/HPI-0953-2023
FU NSFC [91648204, 61303185]; HPCL [201502-01]
FX NSFC, Grant/Award Number: 91648204, 61303185; HPCL, Grant/Award Number:
   201502-01
CR Moshtagh N, 2005, DISTRIBUTED GEODESIC
   Necsulescu D, 2010, 2010 15TH INTERNATIONAL CONFERENCE ON METHODS AND MODELS IN AUTOMATION AND ROBOTICS (MMAR), P37, DOI 10.1109/MMAR.2010.5587268
   Olfati-Saber R, 2006, IEEE T AUTOMAT CONTR, V51, P401, DOI 10.1109/TAC.2005.864190
   Peng ZH, 2014, INT J ADAPT CONTROL, V28, P479, DOI 10.1002/acs.2400
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Su HS, 2009, IEEE T AUTOMAT CONTR, V54, P293, DOI 10.1109/TAC.2008.2010897
   Tang MS, 2014, ENTROPY-SWITZ, V16, P4583, DOI 10.3390/e16084583
   Tang MS, 2013, SCI WORLD J, DOI 10.1155/2013/196823
   Tanner HG, 2004, COOPERATIVE CONTROL, V309, P458
   Varga M, 2015, DISTRIBUTED FORMATIO
   VICSEK T, 1995, PHYS REV LETT, V75, P1226, DOI 10.1103/PhysRevLett.75.1226
   Wang W, 2013, CHINA'S BANKING LAW AND THE NATIONAL TREATMENT OF FOREIGN-FUNDED BANKS, P1
   Yang ZQ, 2012, INT J SYST SCI, V43, P2125, DOI 10.1080/00207721.2011.564675
   Yu WW, 2010, SYST CONTROL LETT, V59, P543, DOI 10.1016/j.sysconle.2010.06.014
   Zavlanos MM, 2007, FLOCKING PRESERVING
NR 16
TC 8
Z9 8
U1 1
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1777
DI 10.1002/cav.1777
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200023
DA 2024-07-18
ER

PT J
AU Imai, T
   Kanamori, Y
   Mitani, J
AF Imai, Takuya
   Kanamori, Yoshihiro
   Mitani, Jun
TI Real-time screen-space liquid rendering with complex refractions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE particle-based liquids; multiple refractions; real-time rendering;
   screen-space approach
AB Particle-based liquid is often rendered only with single refraction in real-time applications, which deteriorates the reality of liquid. We present a screen-space method for rendering particle-based liquids with up to four refractions in real time. Our method separates liquid particles into splashes and aggregations (i.e., liquid bodies) and generates a pair of depth maps of front-facing and back-facing surfaces for each. We use the depth maps of splashes as they are but smooth those of aggregations to reduce small bumps. For smoothing depth, we iteratively fit planes locally using moving least squares, unlike previous filtering-based approaches that cause undesirable refractions around depth boundaries. By calculating refractions with physically based light attenuation, our method can render liquids more realistically than previous methods. Copyright (C) 2016 John Wiley & Sons,
C1 [Imai, Takuya; Kanamori, Yoshihiro; Mitani, Jun] Univ Tsukuba, Tsukuba, Ibaraki, Japan.
C3 University of Tsukuba
RP Kanamori, Y (corresponding author), Univ Tsukuba, Tsukuba, Ibaraki, Japan.
EM kanamori@cs.tsukuba.ac.jp
CR Alexa Marc., 2004, ACM SIGGRAPH 2004 Course Notes, P7
   [Anonymous], P GRAPH INT MONTR CA
   [Anonymous], 2013, ACM T GRAPHICS TOG, DOI DOI 10.1145/2421636.2421641
   [Anonymous], 2006, P 3 EUROGRAPHICS IEE
   Bagar F, 2010, COMPUT GRAPH FORUM, V29, P1383, DOI 10.1111/j.1467-8659.2010.01734.x
   Cords H., 2009, J GRAPH TOOLS, V14, P1
   Fraedrich R, 2010, IEEE T VIS COMPUT GR, V16, P1533, DOI 10.1109/TVCG.2010.148
   Goswami P., 2010, P 2010 ACM SIGGRAPHE, P55
   Gourmel O, 2010, COMPUT GRAPH FORUM, V29, P281, DOI 10.1111/j.1467-8659.2009.01597.x
   Green S, 2010, GDC 2010 GAM DEV C 2
   Harada T, 2008, ACM SIGGRAPH 2008 TA
   Ihmsen Markus, 2014, P 35 ANN C EUR ASS C, DOI [10.2312/egst.20141034, DOI 10.2312/EGST.20141034]
   Imai T, 2014, P NICOGRAPH INT VISB, P71
   Kanamori Y, 2008, COMPUT GRAPH FORUM, V27, P351, DOI 10.1111/j.1467-8659.2008.01132.x
   Ladicky L, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818129
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Müller M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P9
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Oliveira MM, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P89
   Reichl F., 2014, P HIGH PERFORMANCE G, P105
   SCHLICK C, 1994, COMPUT GRAPH FORUM, V13, pC233, DOI 10.1111/1467-8659.1330233
   Van der Laan W.J., 2009, P 2009 S INT 3D GRAP, P91, DOI [DOI 10.1145/1507149.1507164, 10.1145/1507149.1507164]
   Wyman C, 2005, ACM T GRAPHIC, V24, P1050, DOI 10.1145/1073204.1073310
NR 23
TC 6
Z9 9
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 425
EP 434
DI 10.1002/cav.1707
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300027
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huang, Q
   Yang, J
AF Huang, Qiao
   Yang, Jie
TI Person re-identification with local descriptors across multicameras
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human motion analysis; multicamera tracking; bag of features; support
   vector machine; person re-identification
ID MOTION CAPTURE; IMAGE; VIEWS
AB Tracking the same person across multiple cameras is an important task in human motion analysis systems. It is also desirable to re-identify the individuals who have been previously seen with a single camera. This paper addresses this problem by the re-identification of the same individual in two different datasets, which are both challenging situations from human motion analysis systems. In this paper, local descriptors are introduced for image description, and support vector machines are employed for high classification performance and so an efficient bag-of-features approach for image presentation. In this way, robustness against low resolution, occlusion, and pose, viewpoint and illumination changes is achieved in a very fast way. We obtain promising results from the evaluation with situations where a number of individuals vary continuously from a multicamera system. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
   Minist Educ China, Key Lab Syst Control & Informat Proc, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
EM jieyang@sjtu.edu.cn
RI Huang, Qiao/AAX-2824-2020; Yang, Jie/JCD-9867-2023
OI Huang, Qiao/0000-0002-9044-2464; 
FU National Science Foundation, China [61273258]; National High-Tech
   Research and Development Plan of China [2011AA01Z164]
FX The authors are grateful to the reviewers for their comments, which will
   helped us to improve this paper. This research is partly supported by
   the National Science Foundation, China (no.: 61273258) and the National
   High-Tech Research and Development Plan of China (2011AA01Z164).
CR Ahonen T, 2009, PATTERN RECOGN LETT, V30, P368, DOI 10.1016/j.patrec.2008.10.012
   [Anonymous], P CVPR MINN US
   [Anonymous], P SCAND C IM AN
   [Anonymous], P ICCV 2003
   [Anonymous], BMVC
   [Anonymous], P IEEE INT WORKSH PE
   Bird ND, 2005, IEEE T INTELL TRANSP, V6, P167, DOI 10.1109/TITS.2005.848370
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Davison AJ, 2001, SPRING EUROGRAP, P3
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hamdouns O, 2008, P IEEE C DISTRIBUTED, P1
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Jojic N, 2009, PROC CVPR IEEE, P2044, DOI 10.1109/CVPRW.2009.5206581
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Madden C, 2007, MACH VISION APPL, V18, P233, DOI 10.1007/s00138-007-0070-6
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Rahimi A, 2004, PROC CVPR IEEE, P187
   Smith R. A., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P295
   Teixeira LF, 2009, PATTERN RECOGN LETT, V30, P157, DOI 10.1016/j.patrec.2008.04.001
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Yang XC, 2008, SIGNAL PROCESS, V88, P2350, DOI 10.1016/j.sigpro.2008.03.006
   Zhu ZF, 2004, PATTERN RECOGN LETT, V25, P515, DOI 10.1016/j.patrec.2003.12.014
NR 27
TC 0
Z9 1
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2014
VL 25
IS 5-6
BP 543
EP 551
DI 10.1002/cav.1556
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AR9DE
UT WOS:000343871000004
DA 2024-07-18
ER

PT J
AU Lv, N
   Huang, Y
   Feng, ZQ
   Peng, JL
AF Lv, Na
   Huang, Yan
   Feng, Zhiquan
   Peng, Jingliang
TI A genetic algorithm approach to human motion capture data segmentation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion capture; segmentation; genetic algorithm; sparse learning;
   symbolic representation
AB In this paper, we propose a novel genetic algorithm approach to human motion capture (MoCap) data segmentation. For a given MoCap sequence, it constructs a symbolic representation through unsupervised sparse learning, detects the candidate segmenting points to the sequence, models the selection/deselection of each candidate with a gene, and employs the genetic algorithm to find the optimal solution. To the best of our knowledge, we for the first time introduce the genetic algorithm and the sparse learning technique to the problem of MoCap data segmentation, leading to excellent segmentation performance as experimentally demonstrated. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Lv, Na; Huang, Yan; Peng, Jingliang] Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
   [Lv, Na; Feng, Zhiquan] Univ Jinan, Dept Informat Sci & Technol, Jinan 250022, Shandong, Peoples R China.
C3 Shandong University; University of Jinan
RP Huang, Y (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
EM yan.h@sdu.edu.cn
FU National Natural Science Foundation of China [61303083, 61173079,
   U1035004, U1201258]; Scientific Research Foundation for the Excellent
   Middle-Aged and Youth Scientists of Shandong Province of China
   [BS2011DX017]; Shandong Provincial Natural Science Foundation, China
   [ZR2011FZ003, ZR2011FZ004]; Program for New Century Excellent Talents in
   University (NCET) in China
FX This work is supported by the National Natural Science Foundation of
   China (61303083, 61173079, U1035004, and U1201258), the Scientific
   Research Foundation for the Excellent Middle-Aged and Youth Scientists
   of Shandong Province of China (BS2011DX017), Shandong Provincial Natural
   Science Foundation, China (ZR2011FZ003, ZR2011FZ004), and the Program
   for New Century Excellent Talents in University (NCET) in China.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 1975, Adatation in Natural and Artificial Systems
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Bouchard D, 2007, LECT NOTES ARTIF INT, V4722, P37
   CMU, 2007, CMU MOT CAPT LIB
   Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430
   Fod A, 2002, AUTON ROBOT, V12, P39, DOI 10.1023/A:1013254724861
   Jenkins OC, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2551, DOI 10.1109/IRDS.2002.1041654
   Jong D., 1975, ANAL BEHAV CLASS GEN
   Lan RY, 2015, VISUAL COMPUT, V31, P35, DOI 10.1007/s00371-013-0902-5
   Li C, 2007, MULTIMED TOOLS APPL, V35, P55, DOI 10.1007/s11042-007-0119-6
   Li Y, 2010, PROC CVPR IEEE, P2630, DOI 10.1109/CVPR.2010.5539977
   Lin CD, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, VOLS 1 AND 2, P1
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Seward AE, 2005, P 43 ANN SE REG C NE, V2, P388
   Souvenir R, 2005, IEEE I CONF COMP VIS, P648
   [杨跃东 Yang Yuedong], 2008, [计算机研究与发展, Journal of Computer Research and Development], V45, P527
   Zhao LW, 2005, GRAPH MODELS, V67, P1, DOI 10.1016/j.gmod.2004.08.002
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
NR 20
TC 8
Z9 8
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 283
EP 292
DI 10.1002/cav.1597
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300009
DA 2024-07-18
ER

PT J
AU Liu, YQ
   Chen, YY
   Wu, W
   Max, N
   Wu, EH
AF Liu, Youquan
   Chen, Yanyun
   Wu, Wen
   Max, Nelson
   Wu, Enhua
TI Physically based object withering simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE withering; decay; deformation; heterogeneous; physical simulation
AB This paper presents a finite element method-based framework for an object withering simulation modeled with heterogeneous material, such as fruits drying or decay. We introduce diffusion procedures for both the moisture content and decay spread, which are solved directly on a tetrahedral mesh representation of the fruit flesh. Then, we use the moisture content to control shrinkage through the initial strain, which is integrated into the Lagrangian dynamic equation, and solved with the finite element method. For the complex structure of the object, another fine triangle mesh is used to represent the skin, and its deformation is solved by a thin shell technique. To couple the motion between different layers of the fruit, a tracking force is used to pull the skin and drive its deformation together with the volume mesh. In comparison with the previous work, our method provides temporally and spatially varying parameters to model the complex phenomena of object withering. Moreover, the water diffusivity can also be given by user input to present various material properties of the cut section and skin-covered area. Our algorithm is easy to implement and highly efficient in generating a realistic appearance for the withering effect. For a medium-scale model, we can achieve interactive simulation. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Liu, Youquan] Changan Univ, Sch Informat Engn, Xian, Peoples R China.
   [Liu, Youquan; Chen, Yanyun; Wu, Enhua] Chinese Acad Sci, Inst Software, LCS, Beijing, Peoples R China.
   [Wu, Wen; Wu, Enhua] Univ Macau, FST, Macau, Peoples R China.
   [Max, Nelson] Univ Calif Davis, Davis, CA 95616 USA.
C3 Chang'an University; Chinese Academy of Sciences; Institute of Software,
   CAS; University of Macau; University of California System; University of
   California Davis
RP Liu, YQ (corresponding author), Changan Univ, Sch Informat Engn, Xian, Peoples R China.
EM youquan@chd.edu.cn
RI Liu, Youquan/C-1628-2012
FU National Grand Fundamental Research 973 Program of China [2009CB320802];
   National Natural Science Foundation of China [60973066, 60833007]; Open
   fund of the State Key LCS, Institute of Software, Chinese Academy of
   Sciences [SYSKF1004]
FX The apple models used in this paper came from flatpyramid.com and are
   used with permission. This paper is supported by the National Grand
   Fundamental Research 973 Program of China under (grant no.
   2009CB320802), the National Natural Science Foundation of China (under
   grant nos. 60973066 and 60833007), and the Open fund of the State Key
   LCS, Institute of Software, Chinese Academy of Sciences(SYSKF1004).
CR [Anonymous], 2000, FINITE ELEMENT METHO
   [Anonymous], 2010, ACM T GRAPHICS TOG A
   Aoki K, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P467, DOI 10.1109/PCCGA.2002.1167903
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bickel B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531395
   Bridson R, 2002, P ACM SIGGRAPH SAN A, P227
   Chemkhi S, 2005, BRAZ J CHEM ENG, V22, P153, DOI 10.1590/S0104-66322005000200001
   Choi MG, 2007, COMPUT GRAPH FORUM, V26, P349, DOI 10.1111/j.1467-8659.2007.01057.x
   Dorsey J, 1999, COMP GRAPH, P225, DOI 10.1145/311535.311560
   Dorsey J., 2007, DIGITAL MODELING MAT
   Galoppo N., 2006, Proc. Symp. on Computer Animation, P73
   Goldenthal R, 2007, ACM T GRAPHICS ACM S, V26, P1
   Grinspun E., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P62
   Gu JW, 2006, ACM T GRAPHIC, V25, P762, DOI 10.1145/1141911.1141952
   Iben H.N., 2006, P ACM SIGGRAPHEUROGR, P177
   Irving G, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239464
   Kharevych L, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1531326.1531357, 10.1145/15313261531357]
   Kider JT, 2011, COMPUT GRAPH FORUM, V30, P257, DOI 10.1111/j.1467-8659.2011.01857.x
   Lenaerts T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360648
   Loviscach J, 2006, COMPUT GRAPH FORUM, V25, P467, DOI 10.1111/j.1467-8659.2006.00966.x
   Lu J., 2005, EGNP, P7, DOI DOI 10.2312/NPH/NPH05/007-016
   Mérillou S, 2008, COMPUT GRAPH-UK, V32, P159, DOI 10.1016/j.cag.2008.01.003
   Müller M, 2004, PROC GRAPH INTERF, P239
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Nesme M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531358
   Selle A, 2009, IEEE T VIS COMPUT GR, V15, P339, DOI 10.1109/TVCG.2008.79
   Sifakis E, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P81
   Tsami E, 2000, DRY TECHNOL, V18, P1559, DOI 10.1080/07373930008917793
   Wojtan C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360646
   Yang H, 2001, DRY TECHNOL, V19, P1441, DOI 10.1081/DRT-100105299
NR 31
TC 7
Z9 8
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 395
EP 406
DI 10.1002/cav.1459
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100026
DA 2024-07-18
ER

PT J
AU Brand, S
   Bidarra, R
AF Brand, Sandy
   Bidarra, Rafael
TI Multi-core scalable and efficient pathfinding with Parallel Ripple
   Search
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Parallel Ripple Search; pathfinding; parallel algorithms; multi-core
   architectures
AB Game developers are often faced with very demanding requirements on huge numbers of agents moving naturally through increasingly large and detailed virtual worlds. With the advent of multi-core architectures, new approaches to accelerate expensive pathfinding operations are worth being investigated. Traditional single-processor pathfinding strategies, such as A* and its derivatives, have been long praised for their flexibility. We implemented several parallel versions of such algorithms to analyze their intrinsic behavior, concluding that they have a large overhead, yield far from optimal paths, do not scale up to many cores or are cache unfriendly. In this article, we propose Parallel Ripple Search, a novel parallel pathfinding algorithm that largely solves these limitations. It utilizes a high-level graph to assign local search areas to CPU cores at equidistant intervals. These cores then use A* flooding behavior to expand towards each other, yielding good guesstimate points at border touch on. The process does not rely on expensive parallel programming synchronization locks but instead relies on the opportunistic use of node collisions among cooperating cores, exploiting the multi-core's shared memory architecture. As a result, all cores effectively run at full speed until enough way-points are found. We show that this approach is a fast, practical and scalable solution and that it flexibly handles dynamic obstacles in a natural way. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Brand, Sandy; Bidarra, Rafael] Delft Univ Technol, NL-2628 CD Delft, Netherlands.
C3 Delft University of Technology
RP Bidarra, R (corresponding author), Delft Univ Technol, Mekelweg 4, NL-2628 CD Delft, Netherlands.
EM R.Bidarra@tudelft.nl
OI Bidarra, Rafael/0000-0003-4281-6019
CR Amato N., 2004, RANDOMIZED MOTION PL
   Bjornsson Y., 2005, P IEEE S COMPUTATION, P125
   Bleiweiss A., 2008, P 23 ACM SIGGRAPHEUR, P65
   Botea A, 2006, NEAR OPTIMAL HIERARC
   Brand S., 2009, THESIS DELFT U TECHN
   Buluc A, 2009, PARALLEL COMPUT, DOI [10.0106/j.parco.2009.12.002, DOI 10.0106/J.PARCO.2009.12.002]
   Cohen D., 2010, Implementation of parallel path finding in a shared memory architecture
   Cvetanovic Z., 1990, Proceedings of the Twenty-Third Annual Hawaii International Conference on System Sciences, P82, DOI 10.1109/HICSS.1990.205103
   Nohra J, 2010, INTEL SOFTWARE NETWO
   Patel AJ, 2004, AMITS GAME PROGRAMMI
   Sniedovich M, DIJKSTRAS ALGORITHM
   Sturtevant NR, P AIIDE 2010 6 C ART, P76
NR 12
TC 6
Z9 7
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2012
VL 23
IS 2
BP 73
EP 85
DI 10.1002/cav.1427
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 926VJ
UT WOS:000302859700003
DA 2024-07-18
ER

PT J
AU Liew, PS
   Chin, CL
   Huang, ZY
AF Liew, Pak-San
   Chin, Ching-Ling
   Huang, Zhiyong
TI Development of a computational cognitive architecture for intelligent
   virtual character
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE computational cognitive architecture; virtual exploration; intelligent
   virtual character; simulation
AB A development of a computational cognitive architecture for the simulation of intelligent virtual characters is described in this paper. By specializing and adapting front an existing structure for a situated design agent, we propose three process models-reflexive, reactive and reflective-which derive behavioural models that underlie intelligent behaviours for these characters. Various combinations of these process models allow intelligent virtual character.,; to reason in a reflexive, reactive and/or reflective manner according to the retrieval, modification and reconstruction of their memory contents. This paper offers an infrastructure for combining simple reasoning models, found in crowd simulations, and highly deliberative processing models or reasoning, found in 'heavy' agents with high-level cognitive abilities. Intelligent virtual characters simulated via this adapted architecture can exhibit system level intelligence across a broad range of relevant tasks. To demonstrate the usefulness of the proposed architecture, We describe the effect of the reflexive, reactive and reflective processes on a virtual character in our virtual tour application. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Chin, Ching-Ling; Huang, Zhiyong] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.
   [Chin, Ching-Ling] DSO Natl Labs, Singapore, Singapore.
   [Huang, Zhiyong] NUS, Sch Comp, Singapore, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); National University of Singapore
RP Liew, PS (corresponding author), ASTAR, Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis,S Tower, Singapore 138632, Singapore.
EM psliew@i2r.a-star.edu.sg
CR BLUMBERG BM, 1995, P SIGGRAPH 95, P47
   Buckland M., 2005, PROGRAMMING GAME AI
   Funge J, 1999, COMP GRAPH, P29, DOI 10.1145/311535.311538
   FUNGE J, 1999, AL GAMES ANIMATION C
   Langley P, 2009, COGN SYST RES, V10, P141, DOI 10.1016/j.cogsys.2006.07.004
   LIEW PS, 2004, THESIS U SYDNEY
   LIEW PS, 2002, P CAADRIA 2002, P199
   LUO L, 2007, COMPUTER ANIMATION V, V19, P271
   MAHAR ML, 2002, P ACADIA 2002 THRESH, P127
   Park A, 2008, COMPUT ANIMAT VIRT W, V19, P331, DOI 10.1002/cav.243
   Reynolds C. W., 1999, P GAM DEV C, P763
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Sun R, 1998, AI MAG, V19, P113
   Sun R, 2004, PHILOS PSYCHOL, V17, P341, DOI 10.1080/0951508042000286721
   Sun R, 2008, CAMB HANDB PSYCHOL, P3
NR 15
TC 4
Z9 4
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 257
EP 266
DI 10.1002/cav.316
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700019
DA 2024-07-18
ER

PT J
AU Ohta, M
   Kanamori, Y
   Nishita, T
AF Ohta, Makoto
   Kanamori, Yoshihiro
   Nishita, Tomoyuki
TI Deformation and fracturing using adaptive shape matching with stiffness
   adjustment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE interactive deformation; soft body; shape matching; fracturing
AB This paper presents; a fast method that computes deformations with fracturing of an object using a hierarchical lattice. Our method allows numerically stable computation based on so-called shape matching. During the simulation, the deformed shape of the object and the condition of fracturing are used to determine the appropriate detail level in the hierarchy of the lattices. Our method modifies the computation of the stiffness of the object in different levels of the hierarchy so that the stiffness is maintained uniform by introducing a stiffness parameter that does not depend on the hierarchy. By merging the subdivided lattices, our method minimizes the increase of computational cost. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Kanamori, Yoshihiro; Nishita, Tomoyuki] Univ Tokyo, Dept Informat Sci, Bunkyo Ku, Tokyo 1130033, Japan.
C3 University of Tokyo
RP Kanamori, Y (corresponding author), Univ Tokyo, Dept Informat Sci, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1130033, Japan.
EM pierrot@nis-lab.is.s.u-tokyo.ac.jp
RI Ohta, Makoto M/I-7104-2018
CR BARGTEIL AW, 2007, P SIGGRAPH 07
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   METAXAS D, 1992, P SIGGRAPH 92, P309
   MOLINO N, 2004, P SIGGRAPH 04, P385
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Müller M, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P26, DOI 10.1109/CGI.2004.1309189
   Müller M, 2004, PROC GRAPH INTERF, P239
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   NEALEN A, 2005, COMPUT GRAPH FORUM, V4, P809
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   OBRIEN JF, 1999, P SIGGRAPH 1999, P287
   PAULY M, 2000, P SIGGRAPH 05, P957
   RIVERS AR, 2007, P SIGGRAPH 07
   Steinemann D., 2008, P 2008 ACM SIGGRAPHE, P87
   Sukumar N, 2000, INT J NUMER METH ENG, V48, P1549, DOI 10.1002/1097-0207(20000820)48:11<1549::AID-NME955>3.0.CO;2-A
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
NR 18
TC 3
Z9 5
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 365
EP 373
DI 10.1002/cav.318
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700029
DA 2024-07-18
ER

PT J
AU Ting, SP
   Zhou, SP
AF Ting, Shang-Ping
   Zhou, Suiping
TI Dealing with dynamic changes in time critical decision-making for MOUT
   simulations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE time critical decision-making; MOUT simulations; expectations; dynamic
   environments
AB Generating realistic behaviors for the non-player characters (also known as bots) is all important task for Military Operations on Urban Terrain (MOUT) simulations. Most of the current bots reasoning models are based on complete rational analysis of all alternatives. However, such models may not be adequate in time critical and uncertain situations. In such situations, due to time constraints and incomplete information, humans rely mainly oil experience rather than some structured analysis of the given situation to make decisions. In our previous Work, we have developed SNAP, a time critical decision-making framework which aims to imitate human decision-making processes for MOUT simulations. A major limitation that we found about SNAP is its difficulty in dealing with dynamic changes in MOUT simulations. In this paper, we propose to address this problem by incorporating a novel feature of expectations into SNAP. The effectiveness of this new feature is assessed With Twilight City, a virtual environment for MOUT simulations. Experimental results show that our expectation model works well in dealing with dynamic changes in MOUT. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Ting, Shang-Ping; Zhou, Suiping] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Ting, SP (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM ting0021@ntu.edu.sg
CR [Anonymous], 1998, EPIC GAMES UNREAL EN
   [Anonymous], 1932, REMEMBERING EXPT SOC
   AZUMA R, 2006, P 2006 IEEE AER C MT, P4
   BALLARD JR, 2006, NEW DAWN IRAQ
   BARRETT LF, 2007, HUMAN BEHAV MILITARY
   BREWER WF, 1981, COGNITIVE PSYCHOL, V13, P207, DOI 10.1016/0010-0285(81)90008-6
   De Mantaras RL, 2005, KNOWL ENG REV, V20, P215, DOI 10.1017/S0269888906000646
   EVANS K, 2006, SQUAD LEADERS WANT K
   *FM DEP ARM, 1979, 9010 FM DEP ARM
   *FM DEP ARM, 2003, 306 FM DEP ARM
   GLADWELL M, 2005, BLINK POWER THINKING, P215
   Griffith S.B., 1963, The art of war
   Klein G. A., 2017, SOURCES POWER PEOPLE
   Laird J. E, 2001, P 5 INT C AUT AG MON
   MCDERMOTT P. L, 2001, MILITARY OPERATIONS
   Osinga FPB, 2007, STRATEG HIST, P1
   Schultz D. P, 1971, Panic in the Military
   Stacey C.P., 1960, OFFICIAL HIST CANADI, V3
   Ting SP, 2008, COMPUT ANIMAT VIRT W, V19, P505, DOI 10.1002/cav.262
   Widmayer S. A., SCHEMA THEORY INTRO
   Wray RE, 2005, AI MAG, V26, P82
   WRAY RE, 2003, P BEH REPR MOD SIM C
   ZHOU SP, 2008, INT J COMPUTER APPL, V30
   ZHOU SP, 2006, P 39 ANN SIM S HUNTS
NR 24
TC 2
Z9 2
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 427
EP 436
DI 10.1002/cav.291
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700035
DA 2024-07-18
ER

PT J
AU Ye, KJ
   Yin, BC
   Wang, LC
AF Ye, Kejia
   Yin, Baocai
   Wang, Lichun
TI CSLML: a markup language for expressive Chinese sign language synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE Chinese sign language synthesis; representation language; virtual human
AB This paper presents a Chinese Sign Language Markup Language (CSLML), which is developed for expressive Chinese sign language synthesis by introducing features and structure of sign language prosody. The tags of CSLML are divided into two levels: function level and phonetic level. Function level provides abstract information about signed content and prosody, so it facilitates text annotating for text-driven automatic synthetic system and adapts to diversified synthetic methods, such as motion capture animation or image-based synthesis, Which may not be good at processing lower-level information. Phonetic level provides detailed behavioral manners based on phonetics and phonology to interpret the meaning in function level. It facilitates creation and edit of any motions. The two levels co-exist in CSLML documents and high-level description can be mapped into corresponding low-level behavior to provide one-to-many variability and expression of synthesis. Therefore, We also introduce a framework for this mapping processing mid exhibit results of our animated prototype system based on this framework. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Ye, Kejia; Yin, Baocai; Wang, Lichun] Beijing Univ Technol, Coll Comp Sci, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Wang, LC (corresponding author), Beijing Univ Technol, Coll Comp Sci, Beijing Key Lab Multimedia & Intelligent Software, Pingleyuan 100, Beijing 100124, Peoples R China.
EM chrisie.ykj@gmail.com; ybc@bjut.edu.cn; wanglc@bjut.edu.cn
CR Brentari Diane, 1998, A prosodic model of sign language phonology
   *CHIN ASS DEAF, 2002, CHIN SIGN LANG
   COSTA ACD, 2009, SUPPORTING DEAF SIGN
   De Carolis B, 2004, COG TECH, P65
   ELLIOTT R, 2004, WORKSH REPR PROC SIG, P98
   Hanke Thomas., 2004, Workshopproceedings: Representation and processing of signlanguages, P1
   KOPP S, 2006, P INT VIRT AG IVA, P105
   KRANSTEDT A, 2002, P AAMAS 02 WORKSH
   LEBOURQUE T, 1999, P 3 INT WORKSH GEST, P227
   PIWEK P, 2002, P WORKSH EMB CONV AG
   Sandler W, 2006, SIGN LANGUAGE AND LINGUISTIC UNIVERSALS, P1, DOI 10.2277/ 0521483956
   Stokoe W.C., 1978, Sign Language structure: The first linguistic analysis of American sign language
   Tseng CY, 2005, SPEECH COMMUN, V46, P284, DOI 10.1016/j.specom.2005.03.015
NR 13
TC 4
Z9 6
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 237
EP 245
DI 10.1002/cav.307
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700017
DA 2024-07-18
ER

PT J
AU Luo, LB
   Zhou, SP
   Cai, WT
   Low, MYH
   Tian, F
   Wang, YW
   Xiao, X
   Chen, D
AF Luo, Linbo
   Zhou, Suiping
   Cai, Wentong
   Low, Malcolm Yoke Hean
   Tian, Feng
   Wang, Yongwei
   Xiao, Xian
   Chen, Dan
TI Agent-based human behavior modeling for crowd simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE human behavior modeling; agent-based system; crowd simulation
AB Human crowd is a fascinating social phenomenon in nature. This paper presents our work on designing behavior model for virtual humans in a crowd simulation under normal-life and emergency situations. Our mode! adopts an agent-based approach and employs a layered framework to reflect the natural pattern of human-like decision making process, which generally involves a person's awareness of the situation and consequent changes on the internal attributes. The social group and crowd-related behaviors are modeled according to the findings and theories observed from social psychology (e.g., social attachment theory). By integrating our model into an agent execution process, each individual agent call response differently to the perceived environment and make realistic behavioral decisions based oil various physiological, emotional, and social group attributes. To demonstrate the effectiveness of our model, a case study has been conducted, Which shouts that realistic human behaviors call be generated at both individual and group level. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Luo, Linbo] Nanyang Technol Univ, Parallel & Distributed Comp Ctr, Singapore 639798, Singapore.
   [Zhou, Suiping] China Aerosp Corp, Beijing Simulat Ctr, Beijing, Peoples R China.
   [Cai, Wentong; Low, Malcolm Yoke Hean; Xiao, Xian] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Low, Malcolm Yoke Hean] SIMTech, Singapore, Singapore.
C3 Nanyang Technological University; Nanyang Technological University;
   Agency for Science Technology & Research (A*STAR); A*STAR - Singapore
   Institute of Manufacturing Technology (SIMTech)
RP Luo, LB (corresponding author), Nanyang Technol Univ, Parallel & Distributed Comp Ctr, Singapore 639798, Singapore.
EM lbluo@ntu.edu.sg
RI Low, Malcolm Yoke Hean/AAT-1030-2020; Cai, Wentong/A-3720-2011
OI Low, Malcolm Yoke Hean/0000-0002-5371-0896; Cai,
   Wentong/0000-0002-0183-3835
CR [Anonymous], P 1 INT WORKSH CROWD
   [Anonymous], 1973, ATTACHMENT LOSS
   [Anonymous], 1969, ATTACHMENT LOSS ATTA
   Bowlby J, 1980, ATTACHMENT LOSS SADN
   Brogan DC, 1997, AUTON ROBOT, V4, P137, DOI 10.1023/A:1008867321648
   Burstedde C, 2001, PHYSICA A, V295, P507, DOI 10.1016/S0378-4371(01)00141-8
   *CROWD DYN, 2008, CROWD DIS
   Hassoun MH., 1995, FUNDAMENTALS ARTIFIC
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   KAMINKA GA, 2001, P AAAI 2006 WORKSH C
   Mawson AR, 2005, PSYCHIATRY, V68, P95, DOI 10.1521/psyc.2005.68.2.95
   Nguyen Q.H., 2005, Proceedings of the 2005 Conference on Behavior Representation in Modeling and Simulation (BRIMS), P55
   Pearl J., 1988, PROBABILISTIC REASON
   RAO AS, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P439
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rymill S.J., 2005, THEORY PRACTICE COMP, P35
   SHENDARKA A, 2006, P 2006 WINT SIM C DE
   SUNG M, 2005, EUR ACM SIGGRAPH S C, P291
   Ulicny B, 2001, SPRING EUROGRAP, P163
   YU Q, 2007, P EUR ACM SIGGRAPH S
   ZADEH LA, 1988, COMPUTER, V21, P83, DOI 10.1109/2.53
NR 21
TC 83
Z9 96
U1 1
U2 41
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 271
EP 281
DI 10.1002/cav.238
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200011
OA Bronze
DA 2024-07-18
ER

PT J
AU Kwon, TS
   Shin, SY
AF Kwon, Taesoo
   Shin, Sung Yong
TI A steering model for on-line locomotion synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE computer animation; character animation; motion control
AB For applications such as video games and virtual walk-throughs, on-line locomotion control is an important issue. In general, the user prescribes a sequence of motions one by one while providing an input trajectory. Since the input trajectory lacks in human characteristics, one may not synthesize quality motions by blindly following it. In this paper, we present a novel data-driven scheme for transforming a user-prescribed trajectory to a human trajectory in an on-line manner. As preprocessing, we analyze example motion data to extract human steering behavior. At run-time, the input trajectory is refined to reflect the steering behavior. Together with an existing on-line motion synthesis system, our scheme forms a feedback loop, in which the user effectively specifies an intended human trajectory. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Korea Adv Inst Sci & Technol, Taejon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Shin, SY (corresponding author), Korea Adv Inst Sci & Technol, Taejon, South Korea.
EM syshin@jupiter.kaist.ac.kr
RI Shin, Sung Yong/C-1955-2011
CR [Anonymous], 1987, An Introduction to Splines for use in Computer Graphics Geometric Modeling
   CORREIA L, 1995, ECAL 95 EUR C ART LI, P625
   Go J., 2004, S COMPUTER ANIMATION, P9
   GUO S, 1996, P EUR WORKSH COMP AN, P95
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   KWON T., 2005, SCA 05, P29
   Metoyer RA, 2004, VISUAL COMPUT, V20, P635, DOI 10.1007/s00371-004-0265-z
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   Park S, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P105, DOI 10.1109/MOTION.2002.1182221
   Park SI, 2004, COMPUT ANIMAT VIRT W, V15, P125, DOI 10.1002/cav.15
   Reynolds Craig., 1999, STEERING BEHAV AUTON
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Wiley DJ, 1997, IEEE COMPUT GRAPH, V17, P39, DOI 10.1109/38.626968
NR 15
TC 9
Z9 10
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 463
EP 472
DI 10.1002/cav.185
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000025
OA Bronze
DA 2024-07-18
ER

PT J
AU de Melo, C
   Paiva, A
AF de Melo, Celso
   Paiva, Ana
TI Multimodal expression in virtual humans
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE multimodal expression; virtual humans; gesticulation expression;
   environment expression; facial expression; vocal expression
AB This work proposes a real-time virtual human multimodal expression model. Five modalities explore the affordances of the body: deterministic, non-deterministic, gesticulation, facial, and vocal expression. Deterministic expression is keyframe body animation. Non-deterministic expression is robotics-based procedural body animation. Vocal expression is voice synthesis, through Festival, and parameterization, through SABLE. Facial expression is lip-synch and emotion expression through a parametric muscle-based face model. Inspired by psycholinguistics, gesticulation expression is unconventional, idiosyncratic, and unconscious hand gestures animation described as sequences of Portuguese Sign Language hand shapes, positions and orientations. Inspired by the arts, one modality goes beyond the body to explore the affordances of the environment and express emotions through camera, lights, and music. To control multimodal expression, this work proposes a high-level integrated synchronized markup language-expressive markup language. Finally, three studies, involving a total of 197 subjects, evaluated the model in storytelling contexts and produced promising results. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Univ Tecn Lisboa, IST, P-2780990 Porto Salvo, Portugal.
   INESCID, P-2780990 Porto Salvo, Portugal.
C3 Universidade de Lisboa
RP de Melo, C (corresponding author), Univ Tecn Lisboa, IST, Ave Prof Cavaco Silva,Taguspk, P-2780990 Porto Salvo, Portugal.
EM cmme@mega.ist.utl.pt
RI Paiva, Ana/B-9900-2011
OI Paiva, Ana/0000-0003-3998-5188
CR Albrecht I., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P98
   Amaya K, 1996, PROC GRAPH INTERF, P222
   [Anonymous], 1976, Grammar of the film language
   [Anonymous], SIMULATING HUMANS CO
   [Anonymous], 2000, Language and Gesture, DOI DOI 10.1017/CBO9780511620850.018
   [Anonymous], 2011, Handbook of music and emotion: Theory, research, applications
   [Anonymous], P AAMAS WORKSH EMB C
   [Anonymous], 2000, Language and Gesture, DOI [10.1017/CBO9780511620850.017, DOI 10.1017/CBO9780511620850.017]
   [Anonymous], 1999, Proceedings of the SIGCHI conference on human factors in computing systems, DOI [10.1145/302979.303150, DOI 10.1145/302979.303150]
   ARAFA Y, 2003, CHARACTER ANIMATION
   Birn Jeremy., 2000, [Digital] Lighting Rendering
   Blumberg B., 1995, P SIGGRAPH 95, V30, P47
   Cassell J., 1994, P 21 ANN C COMP GRAP, P413, DOI DOI 10.1145/192161.192272
   Cavazza M, 1998, IEEE COMPUT GRAPH, V18, P24, DOI 10.1109/38.708558
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   de Melo C, 2005, LECT NOTES COMPUT SC, V3784, P715
   DEMELO C, 2006, IN PRESS INTELLIGENT
   Ekman P., 1999, HDB COGNITION EMOTIO
   Gratch J, 2002, IEEE INTELL SYST, V17, P54, DOI 10.1109/MIS.2002.1024753
   GUT U, 1993, COGEST CONVNERSATION
   Kalra P, 1998, IEEE COMPUT GRAPH, V18, P42, DOI 10.1109/38.708560
   KAY N, 2004, RELATIONSHIP COLOR E
   Kipp M., 2001, Proceedings of the European Conference on Speech Communication and Technology, P1367
   KOPP S, 2004, P INT C MULT INT ICM, P97
   KOPP S, 2000, P 14 EUR C ART INT A
   McNeill D., 1992, WHAT GESTURES REVEAL
   McNeill D., 2000, Language and Gesture, V2
   *NASA, 2000, MAN SYST INT MAN NAS
   NOH J, 1998, SURVEY FACIAL MODELI, P99
   Ortony A., 1988, COGNITIVE STRUCTURE
   PERLIN K, VIRTUAL WORLDS P SIG, P205
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   *SABLE, SABLE SYNTH MARK LAN
   *SECR NAC REAB INT, GEST LING GEST PORT
   Thompson D. E., 1988, Computer Graphics, V22, P335, DOI 10.1145/378456.378540
   WATERS K, 1987, P 14 ANN C COMP GRAP, P17
NR 36
TC 14
Z9 15
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 239
EP 248
DI 10.1002/cav.127
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400011
DA 2024-07-18
ER

PT J
AU Shin, HJ
   Lee, J
AF Shin, Hyun Joon
   Lee, Jehee
TI Motion synthesis and editing in low-dimensional spaces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE multi dimensional scaling; character animation; user interface
AB Human motion is difficult to create and manipulate because of the high dimensionality and spatiotemporal nature of human motion data. Recently, tire use of large collections of captured motion data has added increased realism in character animation. In order to make the synthesis and analysis of motion data tractable, we present a low-dimensional motion space in which high-dimensional human motion can be effectively visualized, synthesized, edited, parameterized, and interpolated in both spatial and temporal domains. Our system allows users to create and edit the motion of animated characters in several ways: The user can sketch and edit a curve oil low-dimensional motion space, directly manipulate the character's pose in three-dimensional object space, or specify key poses to create in-between motions. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Ajou Univ, Div Digital Media, Suwon 441749, South Korea.
C3 Ajou University
RP Shin, HJ (corresponding author), Ajou Univ, Div Digital Media, San 5,Woncheon Dong, Suwon 441749, South Korea.
EM joony@ajou.ac.kr
RI Lee, Jehee/V-7545-2019
OI Shin, Hyun Joon/0000-0002-7786-6908
CR ADLER NI, 1994, P COMP AN 95, P13
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Assa J, 2005, ACM T GRAPHIC, V24, P667, DOI 10.1145/1073204.1073246
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Davis J., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P320
   Gleicher M., 2003, P 2003 S INTERACTIVE, P181
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   JENKINS OC, 2004, P INT C MACH LEARN, P225
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   LI Y, 2003, P 2003 ACM SIGGRAPH, P309
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
NR 18
TC 29
Z9 43
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 219
EP 227
DI 10.1002/cav.125
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400009
DA 2024-07-18
ER

PT J
AU Cheung, GKL
   Lau, RWH
   Li, FWB
AF Cheung, GKL
   Lau, RWH
   Li, FWB
TI Efficient rendering of deformable objects for real-tine applications
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deformable object handling; real-time rendering; incremental rendering;
   trimmed NURBS surfaces
ID DESIGN
AB Deformable objects can be used to model soft objects such as clothing, human faces and animal characters. They are important as they can improve the realism of the applications. However, most existing hardware accelerators cannot render deformable objects directly. A tessellation process is often used to convert a deformable object into polygons so that the hardware graphics accelerator may render them. Unfortunately, this tessellation process is computationally very expensive. While the object is deforming, the tessellation process needs to be performed repeatedly to convert the deforming objects into polygons. As a result, deforrnable objects are seldom used in real-time applications such as virtual environments and computer games. Since trimmed NURBS surfaces are often used to represent deformable objects, in this paper we present an efficient method for incremental rendering of deformable trimmed NURBS surfaces. A trimmed NURBS surface typically deforms through the deformation of the trimmed NURBS surface and/or the trimming curve. Our method handles both trimmed surface deformation as well as trimming curve deformation. Experimental results show that our method performs significantly faster than the method used in OpenGL and can be used in real-time applications, such as computer games. Copyright (C) 2006 John Wiley & Sons, Ltd.
C1 Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
   City Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; City University of Hong Kong
RP Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
EM csbor@comp.polyu.edu.hk
RI Li, Frederick W. B./AAM-6662-2021
OI Li, Frederick W. B./0000-0002-4283-4228; LAU, Rynson W
   H/0000-0002-8957-8129
CR ABIEZZI S, 1994, P EUR 94, P108
   CHANG S, 1989, P ACM SIGGRAPH 89, P157
   COHEN E, 1980, COMPUT VISION GRAPH, V14, P87, DOI 10.1016/0146-664X(80)90040-4
   de Casteljau P., 1959, Courbes et surfaces a poles
   Farin G., 2000, The Essentials of CAGD
   Farin G., 1997, Curves and surfaces for computer-aided geometric design: A practical guide
   Guthe M, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P204, DOI 10.1109/PCCGA.2002.1167860
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Kahlesz F., 2002, PROC 7 ACM S SOLID M, P281
   Kumar S., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P51, DOI 10.1145/199404.199413
   Kumar S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P91, DOI 10.1145/253284.253313
   Lau RWH, 1997, P IEEE VIRT REAL ANN, P20, DOI 10.1109/VRAIS.1997.583040
   LI F, 1999, P ACM S VIRT REAL SO, P131
   LI F, 1997, P EUR 97 SEPT, P47
   Li F. W. B., 1999, Journal of Graphics Tools, V4, P37, DOI 10.1080/10867651.1999.10487514
   Li FWB, 2003, IEEE T MULTIMEDIA, V5, P570, DOI [10.1109/TMM.2003.814795, 10.1109/TTM.2003.814795]
   Li FWB, 2001, P IEEE VIRT REAL ANN, P217, DOI 10.1109/VR.2001.913789
   Lien S., 1987, Computer Graphics (Proceedings of ACM SIGGRAPH 87), V21, P111
   Piegl L., 1997, The Nurbs Book, Vsecond
   ROCKWOOD A, 1989, P ACM SIGGRAPH, P107
   SHANTZ M, 1988, P ACM SIGGRAPH C, P189
   SHIRMAN LA, 1993, P EUROGRAPHICS 93, P261
NR 22
TC 0
Z9 0
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2006
VL 17
IS 1
BP 69
EP 81
DI 10.1002/cav.71
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 019YN
UT WOS:000235874800006
DA 2024-07-18
ER

PT J
AU Link, QP
   Wang, WH
   Zhang, L
   Ng, JM
   Low, CP
AF Link, QP
   Wang, WH
   Zhang, L
   Ng, JM
   Low, CP
TI Behaviour-based multiplayer collaborative interaction management
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE collaborative virtual environment; multiplayer role-playing;
   collaborative interaction management; Collaborative Behaviour
   Description Language
ID MULTIUSER VIRTUAL ENVIRONMENTS
AB A collaborative virtual environment (CVE) allows geographically dispersed users to interact with each other and objects in a common virtual environment via network connections. One of the successful applications of CVE is multiplayer on-line role-playing game. To support massive interactions among virtual entities in a large-scale CVE and maintain consistent status of the interaction among users with the constraint of limited network bandwidth, an efficient collaborative interaction management method is required. In this paper, we propose a behaviour-based interaction management framework for supporting multiplayer role-playing CVE applications. It incorporates a two-tiered architecture which includes high-level role behaviour-based interaction management and low-level message routing. In the high level, interaction management is achieved by enabling interactions based on collaborative behaviour definitions. In the low level, message routing controls interactions according to the run-time status of the interactive entities. Collaborative Behaviour Description Language is designed as a scripting interface for application developers to define collaborative behaviours of interactive entities and simulation logics/game rules in a CVE. We demonstrate and evaluate the performance of the proposed framework through a prototype system and simulations. Copyright (C) 2006 John Wiley & Sons, Ltd.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Informat Commun Inst Singapore, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Elect & Elect Engn, Informat Commun Inst Singapore, Nanyang Ave, Singapore 639798, Singapore.
EM iqplin@ntu.edu.sg
RI Low, ChorPing/A-5086-2011
CR Barrus JW, 1996, IEEE COMPUT GRAPH, V16, P50, DOI 10.1109/38.544072
   CARLSSON C, 1993, COMPUT GRAPH, V17, P663, DOI 10.1016/0097-8493(93)90115-P
   DAS T, 1997, P VRST 97
   FUNKHOUSER TA, 1995, S INT 3D GRAPH, P85
   Greenhalgh C, 1997, SIXTH IEEE WORKSHOPS ON ENABLING TECHNOLOGIES: INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES, PROCEEDINGS, P193, DOI 10.1109/ENABL.1997.630813
   GREENHALGH C, 1994, P 6 ERCIM WORKSH STO
   GREENHALGH C, 1997, THESIS U NOTTINGHAM
   KAZMAN R, 1995, PARALLEL COMPUTATION
   LAU RWH, 2002, P ACM MULT 02 LES PI
   Lea R., 1997, J COLLABORATIVE COMP, V6, P227
   LIN Q, 2003, P ACM VRST2003 OS JA, P124
   MACEDONIA M, 1993, PRESENCE, V3, P265
   MASTAGLIO TW, 1995, COMPUTER, V28, P49, DOI 10.1109/2.391041
   Morse KL, 2000, PRESENCE-TELEOP VIRT, V9, P52, DOI 10.1162/105474600566619
   PETTIFER SR, 1997, VIRTUAL REALITY UNIV
   POWELL ET, 1996, 14 WORKSH STNAD INT, P807
   Reddy M, 1997, PRESENCE-TELEOP VIRT, V6, P658, DOI 10.1162/pres.1997.6.6.658
   ROEHL B, 1997, LATE NIGHT VRML 2 0
   SHAW C, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P463, DOI 10.1109/VRAIS.1993.380743
   Singh G., 1994, PRESENCE, V3, P19
   *SON ONL ENT, EVERQUEST
   STEINMAN JS, 1994, 1994 WORKSH PAR DIST, P3
   THORPE JA, 1987, P 9 INT TRAIN SYST C, P492
   WANG W, 2001, P ACM VRST 2001 CAN
NR 24
TC 1
Z9 1
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2006
VL 17
IS 1
BP 1
EP 19
DI 10.1002/cav.73
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 019YN
UT WOS:000235874800002
DA 2024-07-18
ER

PT J
AU Oshita, M
AF Oshita, M
TI Motion control with strokes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE user interface; motion control; character animation
AB We present a novel interface for interactive and intuitive motion control of human figures. By drawing a stroke on the screen using a pen or a mouse, a user of our system can make virtual human figures perform various types of motions. An important feature of 'stroke' is that it has initial and terminal points. With a single stroke, users can specify the source and target Of an action at the same time. An appropriate action is determined based on single stroke and the context. For example, by drawing a stroke from the foot of a character to a ball, the character kicks the ball. By drawing a stroke from a prop to one of the character's hands, the character takes the prop with the specified hand. By drawing a stroke from a character to any point on the ground, the character walks to the specified position. First, we categorize selectable objects into some types. The motions are then described using combinations of the defined types. We also detail the implementation Of our system and the methods for motion generation, and finally we discuss some issues based on experiments with the implemented system. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Kyushu Inst Technol, Dept Syst Innovat & Informat, Iizuka, Fukuoka 8208502, Japan.
C3 Kyushu Institute of Technology
RP Oshita, M (corresponding author), Kyushu Inst Technol, Dept Syst Innovat & Informat, 680-4 Kawazu, Iizuka, Fukuoka 8208502, Japan.
EM oshita@ces.kyutech.ac.jp
CR BINDIGANAVALE R, 1998, WORKSH MOT CAPT TECH
   Gleicher M., 2001, P 2001 S INTERACTIVE, P195
   IGARASHI T, 2005, ACM SIGGR EUR S COMP
   Kallmann M, 1999, COMP ANIM CONF PROC, P138, DOI 10.1109/CA.1999.781207
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   LEE J, 2004, P EUR ACM SIGGR S CO
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   OSHITA M, 2004, EUROGRAPHICS WORKSH, P43
   Park SI, 2004, COMPUT ANIMAT VIRT W, V15, P125, DOI 10.1002/cav.15
   Perlin Ken., 1996, SIGGRAPH 96, P205
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   ROSE C, 1995, SIGGRAPH 95 P, P147
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Sun HC, 2001, COMP GRAPH, P261, DOI 10.1145/383259.383288
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Wiley DJ, 1997, IEEE COMPUT GRAPH, V17, P39, DOI 10.1109/38.626968
   Yin KangKang, 2003, 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, P329
NR 18
TC 4
Z9 4
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 237
EP 244
DI 10.1002/cav.97
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000010
DA 2024-07-18
ER

PT J
AU Choi, YJ
   Hong, M
   Choi, MH
   Myoung-Hee, K
AF Choi, YJ
   Hong, M
   Choi, MH
   Myoung-Hee, K
TI Adaptive surface-deformable model with shape-preserving spring
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE physically based modelling; mass-spring deformable model; spatial
   adaptation; adaptive refinement; multi-resolution; subdivision
AB This paper presents a multi-resolutional surface deformable model with physical property adjustment scheme and shape-preserving springs to represent surface-deformable objects efficiently and robustly. In order to reduce the computational complexity while ensuring the same global volumetric behaviour for the deformable object, we introduce a multi-resolutional mass-spring model that is locally refined using the modified-butterfly subdivision scheme. For robust deformation, a shape-preserving spring, which helps to restore the model to the original shape, is proposed to reduce the animation instability. Volume and shape preservation is indirectly achieved by restoring the model to the original shape without computing the actual volume and associated forces at every iteration. Most existing methods concentrate on visual realism of multi-resolutional deformation and often neglect to maintain the dynamic behavioural integrity between detail levels. In order to preserve overall physical behaviour, we present a new scheme for adjusting physical properties between different levels of details. During the animation of deformable objects, the part of the object under external forces beyond a threshold or with large surface curvature variations is refined with a higher level of detail. The physical properties of nodes and springs in the locally refined area are adjusted in order to preserve the total mass and global behaviour of the object. The adequacy of the proposed scheme was analysed with tests using practical mesh examples. Experimental results demonstrate improved efficiency in object deformation and preservation of overall behaviour between different levels. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Ewha Womans Univ, Dept Comp Sci & Engn, Seoul 120750, South Korea.
C3 Ewha Womans University
RP Myoung-Hee, K (corresponding author), Ewha Womans Univ, Dept Comp Sci & Engn, Daehyun Dong 11-1, Seoul 120750, South Korea.
EM mhkim@ewha.ac.kr
CR ARVO J, 1991, GRAPHICS GEMS 2, V2, P191
   Bro-Nielsen M, 1998, P IEEE, V86, P490, DOI 10.1109/5.662874
   Cartwright J. H., 1992, International Journal of Bifurcation and Chaos, V2, P427
   CIGNONI P, 1999, SCCG 99 C P BUDM APR, P149
   Cotin S, 2000, VISUAL COMPUT, V16, P437, DOI 10.1007/PL00007215
   Debunne G, 2000, COMP ANIM CONF PROC, P15, DOI 10.1109/CA.2000.889022
   DEBUNNE G, 1999, 10 EUR WORKSH COMP A
   DEBUNNE G, 2001, ACM SIGGRAPH 2001
   DYN N, 1990, ACM T GRAPHIC, V9, P160, DOI 10.1145/78956.78958
   Ganovelli F, 2001, VISUAL COMPUT, V17, P274, DOI 10.1007/s003710100098
   GANOVELLI F, 2000, EUROGRAPHICS, V19
   GRINSPUN E, ACM SIGGRAPH 2002, V21
   Hutchinson D., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P31
   KAWAI H, 2001, SIGGRAPH 2001
   Meseure P, 1997, WSCG '97: THE FIFTH INTERNATIONAL CONFERENCE IN CENTRAL EUROPE ON COMPUTER GRAPHICS AND VISUALIZATION '97, CONFERENCE PROCEEDINGS, VOL 1-4, P361
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   PRESS WH, 2002, NUMERICAL RECIPES C, P715
   Thingvold J. A., 1990, Computer Graphics, V24, P129, DOI 10.1145/91394.91430
   Van Gelder A., 1998, Journal of Graphics Tools, V3, P21, DOI 10.1080/10867651.1998.10487490
   VILLARD J, 2002, P 11 INT  MESH ROUND
   VOLKOV V, 2002, P 1 INT C INF TECHN
   WU X, 2001, EUROGRAPHICS, V20
   ZORIN D, P SIGGRAPH 1996, P189
NR 23
TC 3
Z9 4
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2005
VL 16
IS 1
BP 69
EP 83
DI 10.1002/cav.57
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 912IF
UT WOS:000228070300007
DA 2024-07-18
ER

PT J
AU Lee, J
   Burton, LC
   Machiraju, R
   Reese, DS
AF Lee, J
   Burton, LC
   Machiraju, R
   Reese, DS
TI Efficient rendering of multiblock curvilinear grids with complex
   boundaries
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE visibility; domain-specific decomposition; parallel rendering; image
   composition; view-space partitioning; characteristic views
ID PARALLEL
AB Domain decomposition is a popular technique for solving large computational problems that require data to be divided into smaller sub-domains. The exact manner of decomposition depends on the computational needs of the algorithm and often introduces irregular boundaries. Each subdomain forms a block of a larger grid and can be solved or rendered separately by different processing nodes. Rendering of each sub-domain can result in images which are then composited in a back-to-front or front-to-back manner. This scenario is useful when visualization is used concurrently with the simulation. However, the irregularity of boundaries may prohibit the correct image composition due to a visibility anomaly between the sub-domains. In this paper, we present an algorithm based on object-space partitioning to resolve this problem. To accelerate the partitioning process, two techniques are introduced. First, an image-space partition representation is employed for fast assignment of data points to correct partitions. Secondly, a k-d tree is used to subdivide the view-space adaptively according to the complexity of the surface. This view-space partition provides a trade-off between performance and accuracy of the rendered image. Large gains in performance can be achieved with only small losses of accuracy. Two examples of curvilinear grids of different complexity are used to demonstrate the effectiveness of this scheme. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Ohio State Univ, Dept Comp Sci & Engn, Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA.
C3 University System of Ohio; Ohio State University
RP Lee, J (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Mitsubishi Elect Res Labs, 201 Broadway, Cambridge, MA 02139 USA.
OI Reese, Donna/0000-0002-5586-6106
CR Airey J.M., 1990, THESIS U N CAROLINA
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   BURTON L, 1999, THESIS MISSISSIPPI S
   Burton L. C., 1999, Proceedings 1999 IEEE Parallel Visualization and Graphics Symposium (Cat. No.99EX381), P89, DOI 10.1109/PVGS.1999.810143
   Comba J, 1999, COMPUT GRAPH FORUM, V18, pC369, DOI 10.1111/1467-8659.00357
   Gropp W., 1994, USING MPI PORTABLE P
   KELLAWAY G, MAP PROJECTIONS
   Lacroute P, 1996, IEEE T VIS COMPUT GR, V2, P218, DOI 10.1109/2945.537305
   MA KL, 1994, IEEE COMPUT GRAPH, V14, P59, DOI 10.1109/38.291532
   Mao XY, 1996, IEEE T VIS COMPUT GR, V2, P156, DOI 10.1109/2945.506227
   McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398
   Neumann U., 1993, Proceedings. 1993 Parallel Rendering Symposium (IEEE Cat. No.93TH0592-6), P97, DOI 10.1109/PRS.1993.586093
   Silva CT, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P87, DOI 10.1109/SVV.1998.729589
   SNYDER J, 1998, P SIGGRAPH 98, P219
   TELLER S, 1992, THESIS U CALIFORNIA
   Watt A., 1992, ADV ANIMATION RENDER
   Weinshall D, 1997, IEEE T PATTERN ANAL, V19, P97, DOI 10.1109/34.574783
   WILLIAMS PL, 1992, ACM T GRAPHIC, V11, P103, DOI 10.1145/130826.130899
   Wittenbrink CM, 1997, J PARALLEL DISTR COM, V46, P148, DOI 10.1006/jpdc.1997.1386
   XIE F, 1999, P 1999 EUR SIGGRAPH, P75
   YAGEL R, 1995, VISUAL COMPUT, V11, P319
NR 21
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2005
VL 16
IS 1
BP 53
EP 68
DI 10.1002/cav.56
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 912IF
UT WOS:000228070300006
DA 2024-07-18
ER

PT J
AU Yu, SQ
   Wang, ZH
   Zhou, SW
   Yang, XS
   Wu, C
   Wang, Z
AF Yu, Shuqing
   Wang, Zhihao
   Zhou, Shuowen
   Yang, Xiaosong
   Wu, Chao
   Wang, Zhao
TI PerimetryNet: A multiscale fine grained deep network for
   three-dimensional eye gaze estimation using visual field analysis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE EYEDIAP; fine grained; gaze estimation; MPIIGaze; multiscale; visual
   field
ID ROBUST PUPIL DETECTION
AB Three-dimensional gaze estimation aims to reveal where a person is looking, which plays an important role in identifying users' point-of-interest in terms of the direction, attention and interactions. Appearance-based gaze estimation methods could provide relatively unconstrained gaze tracking from commodity hardware. Inspired by medical perimetry test, we have proposed a multiscale framework with visual field analysis branch to improve estimation accuracy. The model is based on the feature pyramids and predicts vision field to help gaze estimation. In particular, we analysis the effect of the multiscale component and the visual field branch on challenging benchmark datasets: MPIIGaze and EYEDIAP. Based on these studies, our proposed PerimetryNet significantly outperforms state-of-the-art methods. In addition, the multiscale mechanism and visual field branch can be easily applied to existing network architecture for gaze estimation. Related code would be available at public repository .
C1 [Yu, Shuqing; Wang, Zhao] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
   [Wang, Zhihao] Zhejiang Univ, Sch Software Technol, Hangzhou, Peoples R China.
   [Zhou, Shuowen] Sir Run Run Shaw Hosp, Dept Ophthalmol, Hangzhou, Peoples R China.
   [Zhou, Shuowen] Zhejiang Univ, Sch Med, Hangzhou, Peoples R China.
   [Yang, Xiaosong] Bournemouth Univ, Natl Ctr Comp Animat, Bournemouth, England.
   [Wu, Chao] Zhejiang Univ, Sch Publ Affairs, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang
   University; Bournemouth University; Zhejiang University
RP Wang, Z (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
EM zhao_wang@zju.edu.cn
RI Wang, Zhao/JBJ-5365-2023; Zhang, Zhipeng/KHY-2239-2024; zhao,
   wenqing/KEZ-9488-2024
OI Wang, Zhao/0000-0002-7144-1511; 
FU Arts and Humanities Research Council [AH/W009323/1]; National Key
   Research and Development Project of China [2021ZD0110505]; National
   Natural Science Foundation of China [U19B2042]; Natural Science
   Foundation of Ningbo [2021J167, 2022Z072]; UK High Education Innovation
   Fund; FIC [AH/W009323/1] Funding Source: UKRI
FX Arts and Humanities Research Council, Grant/Award Number: AH/W009323/1;
   National Key Research and Development Project of China, Grant/Award
   Number: 2021ZD0110505; National Natural Science Foundation of China,
   Grant/Award Number: U19B2042; Natural Science Foundation of Ningbo,
   Grant/Award Numbers: 2021J167, 2022Z072; UK High Education Innovation
   Fund
CR Abdelrahman AA, 2022, ARXIV
   Baltrusaitis Tadas, 2018, 2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018), P59, DOI 10.1109/FG.2018.00019
   Borgestig M, 2017, DEV NEUROREHABIL, V20, P129, DOI 10.3109/17518423.2015.1132281
   Brousseau Braiden, 2018, Vision (Basel), V2, DOI 10.3390/vision2030035
   Chen ZK, 2019, LECT NOTES COMPUT SC, V11366, P309, DOI 10.1007/978-3-030-20876-9_20
   Chen ZK, 2023, IEEE T PATTERN ANAL, V45, P1174, DOI 10.1109/TPAMI.2022.3148386
   Cheng Y.C., 2021, ARXIV
   Cheng YH, 2020, AAAI CONF ARTIF INTE, V34, P10623
   Chong E, 2020, PROC CVPR IEEE, P5395, DOI 10.1109/CVPR42600.2020.00544
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Eivazi S, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319914
   Eraslan S, 2016, J EYE MOVEMENT RES, V9
   Fischer T, 2018, LECT NOTES COMPUT SC, V11214, P339, DOI 10.1007/978-3-030-01249-6_21
   Fuhl W, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P123, DOI 10.1145/2857491.2857505
   Fuhl W, 2015, LECT NOTES COMPUT SC, V9256, P39, DOI 10.1007/978-3-319-23192-1_4
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Hsieh YH, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18105134
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Lian DZ, 2019, AAAI CONF ARTIF INTE, P2488
   Liu Y, 2021, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR46437.2021.00379
   Mora K. A. F., 2014, P S EYE TRACK RES AP, P255, DOI [10.1145/2578153.2578190, 10.1145/2578153]
   Mora KAF, 2014, PROC CVPR IEEE, P1773, DOI 10.1109/CVPR.2014.229
   Murthy LRD, 2021, J EYE MOVEMENT RES, V14, DOI 10.16910/jemr.14.4.2
   Murthy LRD, 2020, AEROSP CONF PROC, DOI 10.1109/aero47225.2020.9172480
   Park S, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204545
   Poitschke T, 2011, IEEE SYS MAN CYBERN, P543, DOI 10.1109/ICSMC.2011.6083740
   Prabhakar G, 2020, J MULTIMODAL USER IN, V14, P101, DOI 10.1007/s12193-019-00316-9
   Rahal RM, 2019, J EXP SOC PSYCHOL, V85, DOI 10.1016/j.jesp.2019.103842
   Ranjan R, 2018, IEEE COMPUT SOC CONF, P2237, DOI 10.1109/CVPRW.2018.00290
   Santini T, 2018, COMPUT VIS IMAGE UND, V170, P40, DOI 10.1016/j.cviu.2018.02.002
   Santini Thiago., 2018, Proceedings of the 2018 ACM Symposium on Eye Tracking Research Applications, P1
   Schiefer U, 2005, OPHTHALMOLOGE, V102, P627, DOI 10.1007/s00347-005-1189-3
   Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235
   Valliappan N, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18360-5
   Wang K, 2019, PROC CVPR IEEE, P11899, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Xiong YY, 2019, PROC CVPR IEEE, P7735, DOI 10.1109/CVPR.2019.00793
   Yiu YH, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.05.016
   Yu Y, 2020, PROC CVPR IEEE, P7312, DOI 10.1109/CVPR42600.2020.00734
   ZHANG X, 2018, P ACM S EYE TRACK RE, P1
   Zhang X., 2015, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI 10.1109/CVPR.2015.7299081
   Zhang XC, 2019, IEEE T PATTERN ANAL, V41, P162, DOI 10.1109/TPAMI.2017.2778103
   Zhang X, 2017, IEEE COMPUT SOC CONF, P2299, DOI 10.1109/CVPRW.2017.284
NR 42
TC 0
Z9 0
U1 0
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2141
EA FEB 2023
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000930081100001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sun, LB
   Yan, JH
   Qin, WH
AF Sun, Libo
   Yan, Jiahui
   Qin, Wenhu
TI Path planning for multiple agents in an unknown environment using soft
   actor critic and curriculum learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE curriculum learning; multiple agents; path planning; soft actor critic
ID COLLISION-AVOIDANCE; REINFORCEMENT
AB Path planning can guarantee that agents reach their goals without colliding with obstacles and other agents in an optimal way and it is a very important component in the research of crowd simulation. In this article, we propose a novel path planning approach for multiple agents which combines soft actor critic (SAC) algorithm and curriculum learning to solve the problems of single policy, slow convergence of the policy in an unknown environment with sparse rewards. The path planning task is set as lessons from easy to difficult, and the neural network of the SAC algorithm is arranged to learn in sequence, and finally the neural network can be fully competent for the path planning task. We also stack the state information to address the problems caused by limited observation for policy learning, and design a comprehensive reward function to make agents reach their goals successfully and avoid collisions with static obstacles and other agents. The experimental results demonstrate that our approach can plan smooth and natural paths for multiple agents, and furthermore, our model has a certain generalization ability and a better adaptability to the changes in a dynamic environment.
C1 [Sun, Libo; Yan, Jiahui; Qin, Wenhu] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Sun, LB; Qin, WH (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
EM sunlibo@seu.cdu.cn; qinwenhu@seu.edu.cn
OI Yan, Jiahui/0000-0001-9131-060X
FU Key R&D Program of Jiangsu Province [BE2019311]; Jiangsu Modern
   Agricultural Industry Key Technology Innovation Project [CX(20)2013];
   National Key Research and Development Program [2020YFB160070301]
FX This work was supported by the Key R&D Program of Jiangsu Province under
   Grant BE2019311, Jiangsu Modern Agricultural Industry Key Technology
   Innovation Project under Grant CX(20)2013 and National Key Research and
   Development Program under Grant 2020YFB160070301.
CR Arul SH, 2021, IEEE INT C INT ROBOT, P8097, DOI 10.1109/IROS51168.2021.9636618
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Bangyu Qin, 2019, 2019 4th International Conference on Robotics and Automation Engineering (ICRAE), P1, DOI 10.1109/ICRAE48301.2019.9043822
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bounini F, 2017, IEEE INT VEH SYM, P180, DOI 10.1109/IVS.2017.7995717
   Damani M, 2021, IEEE ROBOT AUTOM LET, V6, P2666, DOI 10.1109/LRA.2021.3062803
   de Jesus JC, 2021, J INTELL ROBOT SYST, V102, DOI 10.1007/s10846-021-01367-5
   Dong Y, 2018, J INTELL ROBOT SYST, V89, P387, DOI 10.1007/s10846-017-0567-9
   Douthwaite JA, 2019, UNMANNED SYST, V7, P55, DOI 10.1142/S2301385019400065
   Gasparetto A, 2015, MECH MACH SCI, V29, P3, DOI 10.1007/978-3-319-14705-5_1
   Haarnoja T., 2018, SOFT ACTOR CRITIC AL
   Haarnoja T, 2017, PR MACH LEARN RES, V70
   Haarnoja T, 2018, PR MACH LEARN RES, V80
   Han RH, 2022, IEEE ROBOT AUTOM LET, V7, P5896, DOI 10.1109/LRA.2022.3161699
   Haworth B., 2020, P 13 ACM SIGGRAPH C, P26894
   Juliani A., 2018, ARXIV180902627
   Kostrikov I., 2018, ARXIV180902925
   Liu LS, 2021, IEEE ACCESS, V9, P19632, DOI 10.1109/ACCESS.2021.3052865
   Long PX, 2018, IEEE INT CONF ROBOT, P6252
   Ma H, 2024, IEEE T NEUR NET LEAR, V35, P5295, DOI [10.1109/TNNLS.2022.3203074, 10.1109/TII.2022.3143606]
   Marin-Plaza P., 2018, Journal of Advanced Transportation, V2018, DOI DOI 10.1155/2018/6392697
   Molina-Leal A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210689
   Parisotto Emilio, 2017, Neural map: Structured memory for deep reinforcement learning
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Raja P., 2012, Int. J. Phys. Sci., V7, P1314, DOI 10.5897/IJPS11.1745
   Schulman J., 2017, ARXIV
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Veerik M., 2017, Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards
   Wang BY, 2020, IEEE ROBOT AUTOM LET, V5, P6932, DOI 10.1109/LRA.2020.3026638
   Wang X, 2022, IEEE T PATTERN ANAL, V44, P4555, DOI 10.1109/TPAMI.2021.3069908
   WARREN CW, 1993, PROCEEDINGS : IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, pB662
   Xu Y., 2021, P 2021 IEEE INT C NE, V1, P1
   Yu X, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175893
   Zhelo O., 2018, Curiosity-driven exploration for mapless navigation with deep reinforcement learning
   Ziebart BD, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P322, DOI 10.1145/1409635.1409678
NR 35
TC 3
Z9 3
U1 4
U2 42
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2023
VL 34
IS 1
SI SI
AR e2113
DI 10.1002/cav.2113
EA AUG 2022
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Z2BA
UT WOS:000840372800001
DA 2024-07-18
ER

PT J
AU Chen, J
   Yuan, HDQ
   Zhang, Y
   He, RH
   Liang, JX
AF Chen, Jia
   Yuan, Haidongqing
   Zhang, Yi
   He, Ruhan
   Liang, Jinxing
TI DCR-Net: Dilated convolutional residual network for fashion image
   retrieval
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dilated convolution; fashion image retrieval; metric learning; residual
   network
AB Fashion image retrieval is an important branch of image retrieval technology. With the rapid development of online shopping, fashion image retrieval technology has made a breakthrough from text-based to content-based. But there is still not a proper deep learning method used for fashion image retrieval. This article proposes a fashion image retrieval framework based on dilated convolutional residual network which consists of two major parts, image feature extraction and feature distance measurement. For image feature extraction, we first extract the shallow features of the input image by a multi-scale convolutional network, and then develop a novel dilated convolutional residual network to obtain the deep features of the image. Finally, the extracted features are transformed into high-dimensional features vector by a binary retrieval vector module. For feature distance measurement, we first use PCA to reduce the dimension of the extracted high-dimensional vectors. Then we propose a mixed distance measurement algorithm combined with cosine distance and Mahalanobis distance to calculate the spatial distance of the feature vectors for similarity ranking, which solves the problems of poor robustness in complex background fashion image retrieval and the inefficiency calculation of Mahalanobis distance. The experimental results show the superiority of our fashion image retrieval framework over existing state-of-the-art methods.
C1 [Chen, Jia; Yuan, Haidongqing; Zhang, Yi; He, Ruhan; Liang, Jinxing] Wuhan Text Univ, Sch Comp Sci & Artificial Intelligence, Wuhan 430200, Peoples R China.
   [Chen, Jia] Wuhan Text Univ, Engn Res Ctr Hubei Prov Clothing Informat, Wuhan, Peoples R China.
C3 Wuhan Textile University; Wuhan Textile University
RP Yuan, HDQ (corresponding author), Wuhan Text Univ, Sch Comp Sci & Artificial Intelligence, Wuhan 430200, Peoples R China.
EM costinyuan@gmail.com
RI Yuan, Haidongqing/HZJ-7938-2023
OI Yuan, Haidongqing/0000-0002-2854-0020
FU Natural Science Foundation of Hubei Province [2020CFB801]
FX Natural Science Foundation of Hubei Province, Grant/Award Number:
   2020CFB801
CR [Anonymous], 1989, Principal Components Analysis
   [Anonymous], 2013, ICMR
   [Anonymous], 2016, P 24 ACM INT C MULTI
   Ben Ismail MM, 2017, INT J ADV COMPUT SC, V8, P159
   Bozas K., 2014, THESIS QUEEN MARY U
   Chang C, 2019, PROC CVPR IEEE, P9415, DOI 10.1109/CVPR.2019.00965
   Chiao-Meng Huang, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P314, DOI 10.1109/ISPACS.2012.6473502
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Daliakopoulos IN, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051123
   GREENWALD RA, 1995, SPACE SCI REV, V71, P761, DOI 10.1007/BF00751350
   Guo, 2021, GUANGXUE JINGMI GONG, P4
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He T., 2018, ARXIV PREPRINT ARXIV
   Hong Y., 2019, COMPUTER SCI, V46, P215
   Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127
   Huang Q, 2017, VLDB J, V26, P683, DOI 10.1007/s00778-017-0472-7
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Kovashka A, 2015, INT J COMPUT VISION, V115, P185, DOI 10.1007/s11263-015-0814-0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laenen K, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P342, DOI 10.1145/3159652.3159716
   Li ZM, 2016, INT C PATT RECOG, P2912, DOI 10.1109/ICPR.2016.7900079
   Liu S., 2012, P 20 ACM INT C MULTI, P13356
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Meeran AR., 2018, INT J ENG TECHNOL, V7, P353
   Quillet G, 2007, INT J HEAT MASS TRAN, V50, P654, DOI 10.1016/j.ijheatmasstransfer.2006.07.030
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Schuster R, 2019, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2019.00266
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Unar S, 2019, IET IMAGE PROCESS, V13, P515, DOI 10.1049/iet-ipr.2018.5277
   Veerashetty S, 2017, 2017 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER, ELECTRICAL, ELECTRONICS AND COMMUNICATION (CTCEEC), P1173, DOI 10.1109/CTCEEC.2017.8455138
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang R, 2020, P IEEE CVF WINT C AP, P2493
   Wang X., 2001, ACM MULTIMED, V2011, P1353
   [王振 Wang Zhen], 2019, [计算机工程与科学, Computer Engineering and Science], V41, P1671
   Weng TF, 2013, 2013 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), P1016, DOI 10.1109/ICCSNT.2013.6967276
   Xu P., 2020, ARXIV PREPRINT ARXIV
   Zhao B., 2017, P 30 IEEE C COMPUTER
NR 39
TC 3
Z9 3
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2023
VL 34
IS 2
AR e2050
DI 10.1002/cav.2050
EA MAY 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D7UU4
UT WOS:000795844200001
DA 2024-07-18
ER

PT J
AU Mazumdar, A
   Mousas, C
AF Mazumdar, Angshuman
   Mousas, Christos
TI Synthesizing affective virtual reality multicharacter experiences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE affect; optimization; virtual crowds; virtual population; virtual
   reality
ID APPEARANCE; CROWD
AB This article presents a methodology for automatically synthesizing a virtual population (pedestrians placed in a virtual environment) that impacts a user with a specified affective experience. The pipeline began by developing a dataset of behaviors that could be assigned to virtual characters. Next, an annotation phase assigned affective responses of participants to each character's behavior. The design considerations of our affective multicharacter virtual reality experience were then encoded to cost terms and assigned to a total cost function. This method allowed the developer to control the priority and the targets of the cost terms, and given the user inputs, our application could optimize the multicharacter experience using a Markov chain Monte Carlo method known as simulated annealing. A user study was conducted to investigate whether our method could synthesize virtual reality multicharacter experiences that affect participants in an expected way. The results of our study showed that the three different synthesized multicharacter experiences (low, medium, and high negative affect) were perceived as expected by participants; therefore, we argue that we can indeed automatically synthesize virtual reality multicharacter experiences that impact participants' affect levels in an expected way. Limitations and future research directions are discussed.
C1 [Mazumdar, Angshuman; Mousas, Christos] Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Mousas, C (corresponding author), Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
EM cmousas@purdue.edu
RI Mousas, Christos/AGV-3533-2022
OI Mousas, Christos/0000-0003-0955-7959; Mazumdar,
   Angshuman/0000-0003-1632-5152
CR Ahn Junghyun., 2012, P 11 ACM SIGGRAPH IN, P231
   Alghofaili R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P464, DOI [10.1109/vr.2019.8797816, 10.1109/VR.2019.8797816]
   [Anonymous], 1996, 5 FACTOR MODEL PERSO
   Aranyi G, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00070
   Argyle Michael, 2013, Bodily communication
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Bopp JA, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2996, DOI 10.1145/2858036.2858227
   Brooks SP, 1998, J ROY STAT SOC D-STA, V47, P69, DOI 10.1111/1467-9884.00117
   CHIB S, 1995, AM STAT, V49, P327, DOI 10.2307/2684568
   Durupinar F., 2008, P 7 INT JOINT C AUT, P1217
   Ennis C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778828
   Ennis C, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870078
   Federal Highway Administration, 2003, US MANUAL UNIFORM TR
   Gilroy S., 2012, Intelligent User Interaction, P119, DOI [10.1145/2166966.2166990, DOI 10.1145/2166966.2166990]
   GRANT DA, 1948, PSYCHOL BULL, V45, P427, DOI 10.1037/h0053912
   HALL ET, 1968, CURR ANTHROPOL, V9, P83, DOI 10.1086/200975
   Harrison Brent., 2014, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, V10, P23
   Hartsook K, 2011, IEEE CONF COMPU INTE, P297, DOI 10.1109/CIG.2011.6032020
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Huerre S., 2010, P ACM SIGGRAPH US CO, p13:1
   Hullett Kenneth., 2009, Proceedings of the 4th International Conference on Foundations of Digital Games, P99
   Kapadia M., 2016, Proceedings of the 9th International Conference on Motion in Games, P15
   Kätsyri J, 2019, PERCEPTION, V48, P968, DOI 10.1177/0301006619869134
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Knapp M.L., 2002, HDB INTERPERSONAL CO
   Krogmeier C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1883
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   Liu HM, 2020, INT SYM MIX AUGMENT, P566, DOI 10.1109/ISMAR50242.2020.00084
   Luo LB, 2013, COMPUT ANIMAT VIRT W, V24, P345, DOI 10.1002/cav.1525
   Marschner L, 2015, INT J PSYCHOPHYSIOL, V97, P85, DOI 10.1016/j.ijpsycho.2015.05.007
   Mcdonnell Rachel, 2009, ACM T APPL PERCEPT, V6, P1, DOI DOI 10.1145/1620993.1609969
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   Moustafa F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281527
   Nelson Michael G., 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12509), P617, DOI 10.1007/978-3-030-64556-4_48
   Pelechano Nuria., 2008, P 7 INT JOINT C AUTO, V1, P136
   Peters C, 2009, IEEE COMPUT GRAPH, V29, P54, DOI 10.1109/MCG.2009.69
   Rowe J.P., 2014, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, P160
   Saberi M, 2014, PROCEDIA COMPUT SCI, V41, P204, DOI 10.1016/j.procs.2014.11.104
   Shoulson Alexander., 2013, Proceedings of Motion on Games, P121, DOI DOI 10.1145/2522628.2522629
   Smith AdamM., 2012, P INT C FDN DIGITAL, P156, DOI [10.1145/2282338.2282370, DOI 10.1145/2282338.2282370]
   Stamatopoulou I, 2012, PROC INT C TOOLS ART, P1133, DOI 10.1109/ICTAI.2012.161
   Volonte M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P293, DOI [10.1109/VR46266.2020.1581610451331, 10.1109/VR46266.2020.00-55]
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Xie B, 2018, IEEE T VIS COMPUT GR, V24, P1661, DOI 10.1109/TVCG.2018.2793618
   Xu ML, 2014, J COMPUT SCI TECH-CH, V29, P799, DOI 10.1007/s11390-014-1469-y
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Zhang Y., 2019, P ACM CHI C HUM FACT, P121
NR 49
TC 1
Z9 1
U1 0
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2004
DI 10.1002/cav.2004
EA MAY 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000653163000001
DA 2024-07-18
ER

PT J
AU Tastan, O
   Sahillioglu, Y
AF Tastan, Oguzhan
   Sahillioglu, Yusuf
TI Human body reconstruction from limited number of points
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D body reconstruction; database&#8208; assisted modeling; modeling
ID REGISTRATION; MODEL
AB We propose a novel approach for reconstructing plausible three-dimensional (3D) human body models from small number of 3D points which represent body parts. We leverage a database of 3D models of humans varying from each other by physical attributes such as age, gender, weight, and height. First we divide the bodies in database into seven semantic regions. Then, for each input region consisting of maximum 40 points, we search the database for the best matching body part. For the matching criterion, we use the distance between novel point-based features of input points and body parts in the database. We then combine the matched parts from different bodies into one body, with the help of Laplacian deformation, which results in a plausible human body. To evaluate our results objectively, we pick points from each part of the ground-truth human body models, then reconstruct them using our method and compare the resulting bodies with the corresponding ground-truths. Also, our results are compared with registration-based results. In addition, we run our algorithm with noisy data to test the robustness of our method and run it with input points whose body parts are manually edited, which produces plausible human bodies that do not even exist in our database. Our experiments verify qualitatively and quantitatively that the proposed approach reconstructs human bodies with different physical attributes from a small number of points using a small database.
C1 [Tastan, Oguzhan; Sahillioglu, Yusuf] Middle East Tech Univ, Comp Engn Dept, TR-06800 Ankara, Turkey.
C3 Middle East Technical University
RP Sahillioglu, Y (corresponding author), Middle East Tech Univ, Comp Engn Dept, TR-06800 Ankara, Turkey.
EM ys@ceng.metu.edu.tr
OI Sahillioglu, Yusuf/0000-0002-7997-4232
FU Turkiye Bilimsel ve Teknolojik Arastirma Kurumu [215E255]
FX Turkiye Bilimsel ve Teknolojik Arastirma Kurumu, Grant/Award Number:
   215E255
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Anguelov D., 2005, ADV NEURAL INFORM PR, V17, P33
   Atmosukarto Indriyati, 2010, Proc IAPR Int Conf Pattern Recogn, V2010, P2444, DOI 10.1109/ICPR.2010.598
   Ballan L, 2012, LECT NOTES COMPUT SC, V7577, P640, DOI 10.1007/978-3-642-33783-3_46
   BATOUCHE M, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P591, DOI 10.1109/ICPR.1992.201631
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Bondi E., 2015, 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, V7, P1
   Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103
   Buss S. R., 2004, IEEE J ROBOTIC AUTOM, V17, P16
   Chang W, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966405
   Chen QF, 2015, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2015.236
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Frasconi P, 2014, BIOINFORMATICS, V30, pI587, DOI 10.1093/bioinformatics/btu469
   FULLER NJ, 1992, CLIN SCI, V82, P687, DOI 10.1042/cs0820687
   Glauser O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311972
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Groueix T, 2018, LECT NOTES COMPUT SC, V11206, P235, DOI 10.1007/978-3-030-01216-8_15
   Guo Yunhui, 2018, SURVEY METHODS THEOR
   Hodgins J.K., 1995, Animating human athletics
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Huang QX, 2008, COMPUT GRAPH FORUM, V27, P1449, DOI 10.1111/j.1467-8659.2008.01285.x
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Jones PRM, 1997, OPT LASER ENG, V28, P89, DOI 10.1016/S0143-8166(97)00006-7
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Jourabloo A, 2015, IEEE I CONF COMP VIS, P3694, DOI 10.1109/ICCV.2015.421
   Kocabas M, 2019, PROC CVPR IEEE, P1077, DOI 10.1109/CVPR.2019.00117
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Liang Shu, 2014, Proc Int Conf 3D Vis, V2014, P31, DOI 10.1109/3DV.2014.67
   Loper M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661273
   Maron H, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925913
   Mehta D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392410
   Mercan E, 2013, IEEE ENG MED BIO, P6083, DOI 10.1109/EMBC.2013.6610940
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Miller Christian, 2010, ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D), P31
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nealen A., 2006, P 4 INT C COMP GRAPH, P381, DOI DOI 10.1145/1174429.1174494
   Persson A, 2006, J PROSTHET DENT, V95, P194, DOI 10.1016/j.prosdent.2006.01.003
   Sahillioglu Y, 2010, COMPUT VIS IMAGE UND, V114, P334, DOI 10.1016/j.cviu.2009.12.003
   Sahillioglu Y, 2020, VISUAL COMPUT, V36, P1705, DOI 10.1007/s00371-019-01760-0
   Sahillioglu Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3243593
   Sahillioglu Y, 2015, MED IMAGE ANAL, V23, P15, DOI 10.1016/j.media.2015.03.005
   Sorkine O, 2006, COMPUT GRAPH FORUM, V25, P789, DOI 10.1111/j.1467-8659.2006.00999.x
   Taubin G., 1995, P 22 ANN C COMP GRAP, P351, DOI DOI 10.1145/218380.218473
   Thalmann, 1998, P ISPRS COMM 5 S SWI
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   von Marcard T, 2017, COMPUT GRAPH FORUM, V36, P349, DOI 10.1111/cgf.13131
   Yang KJ, 2017, SMART INNOV SYST TEC, V63, P217, DOI 10.1007/978-3-319-50209-0_27
   Yemez Y, 2009, PATTERN RECOGN LETT, V30, P1198, DOI 10.1016/j.patrec.2009.05.012
   Zhao RQ, 2016, LECT NOTES COMPUT SC, V9914, P590, DOI 10.1007/978-3-319-48881-3_41
   Zuffi S, 2015, PROC CVPR IEEE, P3537, DOI 10.1109/CVPR.2015.7298976
NR 54
TC 0
Z9 0
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2021
VL 32
IS 5
DI 10.1002/cav.1995
EA APR 2021
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WJ5HR
UT WOS:000637750800001
DA 2024-07-18
ER

PT J
AU Tseng, YC
   Wong, SK
AF Tseng, Yi-Chun
   Wong, Sai-Keung
TI Transferring video to dynamic relief structures with water interaction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE image processing; interaction; relief maps; simulation; video
   processing; water flows
ID SIMULATION
AB In this article, we present a framework which transfers video to dynamic relief-structures with water interaction. Our method enables the interaction between video content and waterflows. The key idea is that the dynamic 2.5D structures of the objects in video are constructed and then waterflows are simulated to interact with the 2.5D structures. We performed experiments for still images, and video in which objects had various motion styles. User interaction with our system was also demonstrated. The result of a user study indicated that our method could produce visually acceptable results.
C1 [Tseng, Yi-Chun; Wong, Sai-Keung] Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Wong, SK (corresponding author), Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
EM cswingo@cs.nctu.edu.w
FU Ministry of Science and Technology of the ROC [MOST 108-2221-E-009-080]
FX Ministry of Science and Technology of the ROC, Grant/Award Number: MOST
   108-2221-E-009-080
CR [Anonymous], 2014, P 7 INT S VISUAL INF
   Bousseau A., 2006, P NPAR, P141, DOI [DOI 10.1145/1124728.1124751, 10.1145/1124728.1124751]
   Chen K, 2012, MOLECULAR IMAGING PROBES FOR CANCER RESEARCH, P341
   Chen KC, 2013, COMPUT GRAPH-UK, V37, P963, DOI 10.1016/j.cag.2013.08.004
   Clavet S., 2005, SCA '05, P219, DOI DOI 10.1145/1073368.1073400
   Faraj N., 2017, P S NONPH AN REND LO, P1
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Frigo O, 2019, VISUAL COMPUT, V35, P429, DOI 10.1007/s00371-018-1474-1
   Jhou WC, 2016, IEEE T MULTIMEDIA, V18, P4, DOI 10.1109/TMM.2015.2500031
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kang H, 2008, COMPUT GRAPH FORUM, V27, P1773, DOI 10.1111/j.1467-8659.2008.01322.x
   KIM G, 2014, I SYMP CONSUM ELECTR
   Kyprianidis J. E., 2008, P EG UK THEOR PRACT, P51
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Lii SY, 2014, VISUAL COMPUT, V30, P531, DOI 10.1007/s00371-013-0878-1
   Lu CW, 2018, IEEE T VIS COMPUT GR, V24, P2051, DOI 10.1109/TVCG.2017.2700470
   Ma YT, 2017, IEEE INT CON MULTI, P1033, DOI 10.1109/ICME.2017.8019369
   Meier B. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P477, DOI 10.1145/237170.237288
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Okabe M, 2011, COMPUT GRAPH FORUM, V30, P1973, DOI 10.1111/j.1467-8659.2011.02062.x
   Paris S, 2008, LECT NOTES COMPUT SC, V5303, P460, DOI 10.1007/978-3-540-88688-4_34
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Sun TH, 2017, IEEE INT CON MULTI, P1464, DOI 10.1109/ICME.2017.8019293
   Sykora D, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591011
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
NR 26
TC 0
Z9 0
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1961
DI 10.1002/cav.1961
EA SEP 2020
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000566447400001
DA 2024-07-18
ER

PT J
AU Ozcan, CY
   Sezer, EA
   Haciomeroglu, M
AF Ozcan, Cumhur Yigit
   Sezer, Ebru Akcapinar
   Haciomeroglu, Murat
TI A time-based global path planning strategy for crowd navigation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; global path planning; machine learning
ID MODEL
AB In a competent crowd navigation system, it is very important for the agents in the system to plan their movements being aware of the other agents. In this study, we propose the use of machine learning methods to create time-based global path plans by utilizing the information as to when and where the other agents would be at a future time. The application of a machine learning method in the traditional manner for the global path planning problem is not a straightforward task due to the complexity of data collection; therefore, this study proposes a novel method to apply machine learning methods for global path planning. This enables us to create a context-free model. We organize experiments to compare our method to a recent and competitive approach that is referred to as the potential-based method (PBM). We employed three different machine learning methods, namely, artificial neural networks, polynomial regression, and support vector regression. The results of the mass scenario tests and a corridor scenario indicate that the versions with polynomial regression and support vector regression outperform the PBM. This encourages further investigations on the use of machine learning methods for global path planning in crowd navigation.
C1 [Ozcan, Cumhur Yigit; Sezer, Ebru Akcapinar] Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
   [Haciomeroglu, Murat] Gazi Univ, Dept Comp Engn, Ankara, Turkey.
C3 Hacettepe University; Gazi University
RP Sezer, EA (corresponding author), Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM ebru@hacettepe.edu.tr
RI Ozcan, Cumhur Yigit Y/M-7747-2018; Sezer, Ebru Akcapinar/H-5566-2011
OI Sezer, Ebru Akcapinar/0000-0002-9287-2679
CR Akaydin A, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.2.027002
   [Anonymous], 1991, INT J COMPUT VIS
   [Anonymous], 1963, Journal of the Society for Industrial and Applied Mathematics, DOI [DOI 10.1137/0111030, 10.1137/0111030]
   [Anonymous], 1999, P GAM DEV C
   [Anonymous], 2016, MATLAB POL TOOL REL
   Banerjee B, 2009, SIMUL-T SOC MOD SIM, V85, P621, DOI 10.1177/0037549709340659
   Bera A, 2016, COMPUT GRAPH-UK, V55, P68, DOI 10.1016/j.cag.2015.10.009
   Boatright CD, 2015, COMPUT ANIMAT VIRT W, V26, P483, DOI 10.1002/cav.1572
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Fiorini P, 1998, INT J ROBOT RES, V17, P760, DOI 10.1177/027836499801700706
   Godoy J, 2013, P INT C AUT AG MULT
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   Haciomeroglu M, 2013, COMPUT ANIMAT VIRT W, V24, DOI 10.1002/cav.1491
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Helbing D., 1992, Complex Systems, V6, P391
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Henry P, 2010, IEEE INT CONF ROBOT, P981, DOI 10.1109/ROBOT.2010.5509772
   Kapadia M., 2013, P 12 ACM SIG GRAPHEU, P115, DOI DOI 10.1145/2485895.2485909
   Kim S, 2016, P 2015 IEEE INT S MU, P21
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164, DOI [10.1090/QAM/10666, DOI 10.1090/QAM/10666]
   MAC TT, 2016, J IEEE, P930
   Negnevitsky M., 2011, Artificial Intelligence electronic Resource: a Guide to Intelligent Systems, DOI DOI 10.1007/S00894-010-0935-X
   Oguz O, 2010, COMPUT GRAPH-UK, V34, P136, DOI 10.1016/j.cag.2009.12.004
   Ozcan CY, 2015, VISUAL COMPUT, V31, P863, DOI 10.1007/s00371-015-1110-2
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Torrey L., 2010, PAPER PRESENTED P 6
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   Wolinski D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982442
   Wong Saikeung, 2017, [Computational Visual Media, 计算可视媒体], V3, P243
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
NR 35
TC 1
Z9 2
U1 1
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2019
VL 30
IS 2
AR e1864
DI 10.1002/cav.1864
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR7XB
UT WOS:000463367400005
DA 2024-07-18
ER

PT J
AU Plaku, E
   Rashidian, S
   Edelkamp, S
AF Plaku, Erion
   Rashidian, Sara
   Edelkamp, Stefan
TI Multi-group motion planning in virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE sampling-based motion planning; generalized traveling salesman problem;
   probabilistic roadmap; motion dynamics
ID ALGORITHMS
AB Toward enhancing automation, this paper proposes an efficient approach for multi-group motion planning, where the set of goals is divided into k groups and the objective is to compute a collision-free and dynamically feasible trajectory that enables a virtual vehicle to reach at least one goal from each group. The approach works with ground and aerial vehicles operating in complex environments containing numerous obstacles. In addition to modeling the vehicle dynamics by differential equations, the approach can use physics-based game engines, which provide an increased level of realism. The approach is based on a hybrid search that uses generalized traveling salesman tours over a probabilistic roadmap to effectively guide the sampling-based expansion of a motion tree. As the motion tree is expanded with collision-free and dynamically feasible trajectories, tours are adjusted based on a partition of the motion tree into equivalence classes. This gives the approach the flexibility to discover new tours that avoid collisions and are compatible with the vehicle dynamics. Comparisons to related work show significant improvements both in terms of runtime and solution length. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Plaku, Erion; Rashidian, Sara] Catholic Univ Amer, Dept Elect Engn, Comp Sci, Washington, DC 20064 USA.
   [Edelkamp, Stefan] Univ Bremen, Fac Math, Comp Sci, Bremen, Germany.
C3 Catholic University of America; University of Bremen
RP Plaku, E (corresponding author), Catholic Univ Amer, Dept Elect Engn, Comp Sci, Washington, DC 20064 USA.
EM plaku@cua.edu
FU NSF [IIS-1449505, IIS-1548406, ACI-1440587]; Direct For Computer & Info
   Scie & Enginr; Div Of Information & Intelligent Systems [1449505,
   1548406] Funding Source: National Science Foundation; Direct For
   Computer & Info Scie & Enginr; Office of Advanced Cyberinfrastructure
   (OAC) [1440587] Funding Source: National Science Foundation
FX The work by S. Rashidian and E. Plaku is supported by NSF IIS-1449505,
   NSF IIS-1548406, and NSF ACI-1440587.
CR AHUJA RK, 1990, J ACM, V37, P213, DOI 10.1145/77600.77615
   Amato NM, 1998, ROBOTICS: THE ALGORITHMIC PERSPECTIVE, P155
   [Anonymous], 2014, ACM SIGGRAPH 2014 CO
   Behzad Arash., 2002, Proceedings of the 15th International Conference of Systems Engineering (ICSE), P6
   Berg M., 2008, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-3-540-77974-2
   Bhatia A, 2011, IEEE ROBOT AUTOM MAG, V18, P55, DOI 10.1109/MRA.2011.942115
   Bonfiglioli R, 2014, ACM SIGGRAPH MOTION, P25
   Brin S., 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases, P574
   Burgard W., 2005, Principles of Robot Motion: Theory, Algorithms, and Implementations
   Coumans Erwin., 2012, BULLET PHYS ENGINE
   Danner T., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P971, DOI 10.1109/ROBOT.2000.844726
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Edelkamp S, 2014, IEEE C COMP INT GAM, P176
   Edelkamp S., 2014, IEEE Conference on Computational Intelligence and Games, P115
   Englot B. J., 2012, INT C AUT PLANN SCHE, P29, DOI DOI 10.1609/ICAPS.V22I1.13529
   Fainekos GE, 2009, AUTOMATICA, V45, P343, DOI 10.1016/j.automatica.2008.08.008
   Geraerts R, 2007, COMPUT ANIMAT VIRT W, V18, P107, DOI 10.1002/cav.166
   Geraerts R, 2010, IEEE INT CONF ROBOT, P1997, DOI 10.1109/ROBOT.2010.5509263
   Goldenberg M, 2014, J ARTIF INTELL RES, V50, P141, DOI 10.1613/jair.4171
   GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5
   Heckel F, 2009, P 4 INT C FDN DIG GA, P79
   Helsgaun K, 2009, MATH PROGRAM COMPUT, V1, P119, DOI 10.1007/s12532-009-0004-6
   Hsu D, 2003, IEEE INT CONF ROBOT, P4420
   Huang TY, 2014, IEEE INT CONF ROBOT, P1652, DOI 10.1109/ICRA.2014.6907073
   Kallmann M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2580947
   Kallmann M, 2010, LECT NOTES COMPUT SC, V6459, P230
   Kapadia M., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games, I3D '09, P215
   Karaman S, 2012, P AMER CONTR CONF, P735
   Karaman S, 2011, INT J ROBOT RES, V30, P846, DOI 10.1177/0278364911406761
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Kumar T.K. Satish., 2013, Proc. the 10th Symposium on Abstraction, Reformulation, P73
   Latombe JC, 1999, INT J ROBOT RES, V18, P1119, DOI 10.1177/02783649922067753
   LAVALLE S.M., 2006, Planning algorithms, DOI DOI 10.1017/CBO9780511546877
   LaValle SM, 2001, INT J ROBOT RES, V20, P378, DOI 10.1177/02783640122067453
   LaValle SM, 2011, IEEE ROBOT AUTOM MAG, V18, P79, DOI 10.1109/MRA.2011.940276
   Lawrence R, 2013, IEEE T COMP INTEL AI, V5, P227, DOI 10.1109/TCIAIG.2012.2230632
   LIEN YN, 1993, INFORM SCIENCES, V74, P177, DOI 10.1016/0020-0255(93)90133-7
   McMahon J., 2015, Robotica, FirstView, P1
   McMahon J, 2014, IEEE INT C INT ROBOT, P3726, DOI 10.1109/IROS.2014.6943085
   NVIDIA, 2015, PHYSX
   Papadopoulos G, 2013, IEEE INT CONF ROBOT, P4126, DOI 10.1109/ICRA.2013.6631159
   Perez D., 2013, IEEE T COMPUTATIONAL, V99, P1
   Perez D, 2012, IEEE C EVOL COMPUTAT
   Plaku Erion, 2012, Advances in Autonomous Robotics. Joint Proceedings of the 13th Annual TAROS Conference and the 15th Annual FIRA RoboWorld Congress, P331, DOI 10.1007/978-3-642-32527-4_30
   Rashidian S., 2014, ACM SIGGRAPH Motion in Games, P87
   Rodriguez Samuel, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P340, DOI 10.1007/978-3-642-25090-3_29
   Saha M, 2006, INT J ROBOT RES, V25, P207, DOI 10.1177/0278364906061705
   Schuerman M, 2010, COMPUT ANIMAT VIRT W, V21, P267, DOI 10.1002/cav.367
   Shewchuk JR, 2002, COMP GEOM-THEOR APPL, V22, P21, DOI 10.1016/S0925-7721(01)00047-5
   Siméon T, 2001, VSMM 2001: SEVENTH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA, PROCEEDINGS, P854, DOI 10.1109/VSMM.2001.969761
   Singh S, 2011, COMPUT ANIMAT VIRT W, V22, P151, DOI 10.1002/cav.403
   Smith M., 2006, Open dynamics engine
   Solovey K, 2014, INT J ROBOT RES, V33, P82, DOI 10.1177/0278364913506268
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Vardi MY, 2014, COMMUN ACM, V57, P5, DOI 10.1145/2578043
   Wein R, 2008, SPRINGER TRAC ADV RO, V47, P491
NR 56
TC 7
Z9 7
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2018
VL 29
IS 6
AR e1688
DI 10.1002/cav.1688
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HH9VW
UT WOS:000456089800001
DA 2024-07-18
ER

PT J
AU Shao, XQ
   Wu, W
   Wang, BY
AF Shao, Xuqiang
   Wu, Wei
   Wang, Baoyi
TI Position-based simulation of cloth wetting phenomena
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cloth wetting; particle-based simulation; position-based dynamics;
   water-cloth coupling
ID FLUID; ANIMATION
AB Because of the advantages of high stability and efficiency, position-based dynamics (PBD) is becoming increasingly popular with game developers and filmmakers. On the basis of the unified adaptive PBD, we present a nonlinear cloth wetting model to simulate visually realistic cloth wetting phenomena, which takes into account the influence of gravity on all aspects of the wetting process. Specifically, in order to model water diffusion in unsaturated cloth, we propose a novel nonlinear saturation constraint of cloth particles, which considers the influence of gravity, and then solve it using PBD to stably smooth the saturation field. The dynamic behaviors of the cloth and the water-cloth coupling during the cloth wetting process are modeled by using PBD. Moreover, a water absorption model and a water emission model are proposed to simulate the unsaturated cloth absorbing water and the oversaturated cloth draining water under the influence of gravity, respectively. The experimental results demonstrate that our novel wetting model provides an efficient way to model more stable and realistic cloth wetting phenomena using PBD.
C1 [Shao, Xuqiang; Wang, Baoyi] North China Elect Power Univ, Sch Control & Comp Engn, Baoding 071003, Peoples R China.
   [Shao, Xuqiang; Wu, Wei] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 North China Electric Power University; Beihang University
RP Shao, XQ (corresponding author), North China Elect Power Univ, Sch Control & Comp Engn, Baoding 071003, Peoples R China.; Shao, XQ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM shaoxuqiang@gmail.com
RI wu, jun/ISB-8607-2023
FU National Natural Science Foundation of China [61502168, 61472020];
   Natural Science Foundation of Hebei Province [F2016502069]; Open Fund of
   the State Key Laboratory of Virtual Reality Technology and Systems
   [BUAA-VR-16KF-03]; National 863 Program of China [2015AA016403]
FX National Natural Science Foundation of China, Grant/Award Number:
   61502168 and 61472020; Natural Science Foundation of Hebei Province,
   Grant/Award Number: F2016502069; Open Fund of the State Key Laboratory
   of Virtual Reality Technology and Systems, Grant/Award Number:
   BUAA-VR-16KF-03; National 863 Program of China, Grant/Award Number:
   2015AA016403
CR Abu Rumman N, 2015, COMPUT GRAPH FORUM, V34, P240, DOI 10.1111/cgf.12533
   Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Andrysco N, 2008, P EUR ACM SIGGRAPH S
   [Anonymous], 2003, P ACM SIGGRAPH EUR S
   Bayraktar S, 2010, J VISUAL-JAPAN, V13, P327, DOI 10.1007/s12650-010-0041-2
   Bender J, 2014, COMPUT GRAPH-UK, V44, P1, DOI 10.1016/j.cag.2014.07.004
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   Chen YJ, 2012, VISUAL COMPUT, V28, P765, DOI 10.1007/s00371-012-0687-y
   Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   Deul C, 2016, COMPUT ANIMAT VIRT W, V27, P103, DOI 10.1002/cav.1614
   Fratarcangeli M, 2015, COMPUT GRAPH FORUM, V34, P405, DOI 10.1111/cgf.12570
   Fratarcangeli M, 2012, COMPUT ANIMAT VIRT W, V23, P457, DOI 10.1002/cav.1450
   Goswami P., 2010, P 2010 ACM SIGGRAPHE, P55
   Güdükbay U, 2014, SIGNAL IMAGE VIDEO P, V8, P415, DOI 10.1007/s11760-012-0308-2
   Huber M, 2015, COMPUT GRAPH FORUM, V34, P14, DOI 10.1111/cgf.12455
   Huber MF, 2011, 14 INT C INFORM FUSI, P1
   Lenaerts T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360648
   Lenaerts T, 2009, COMPUT GRAPH FORUM, V28, P213, DOI 10.1111/j.1467-8659.2009.01360.x
   Lin WC, 2014, P 11 WORKSH VIRT REA
   Lin WC, 2015, COMPUT GRAPH-UK, V52, P33, DOI 10.1016/j.cag.2015.06.005
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Müller MH, 2008, PROGRESS AND CHALLENGES IN TRANSFUSION MEDICINE, HEMOSTASIS AND HEMOTHERAPY: STATE OF THE ART 2008, P1, DOI 10.1159/000176608
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muller Matthias, 2014, P EG S COMP AN, V2, P149, DOI DOI 10.1016/J.JVCIR.2007.01.005
   Patkar S, 2013, IEEE T VIS COMPUT GR, V19, P1592, DOI 10.1109/TVCG.2013.8
   Rungjiratananon W, 2012, COMPUT GRAPH FORUM, V31, P1993, DOI 10.1111/j.1467-8659.2012.03191.x
   Rungjiratananon W, 2008, COMPUT GRAPH FORUM, V27, P1887, DOI 10.1111/j.1467-8659.2008.01336.x
   Shao X, 2015, COMPUT GRAPH FORUM, V34, P191, DOI 10.1111/cgf.12467
   Shi X, 2015, 14TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, VRCAI 2015, P23, DOI 10.1145/2817675.2817691
   Umetani Nobuyuki, 2014, ACM SIGGRAPH 2014 TA, P21, DOI [DOI 10.1145/2614106.2614158, 10.1145/2614106.2614158]
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 34
TC 0
Z9 0
U1 3
U2 28
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2018
VL 29
IS 1
AR e1788
DI 10.1002/cav.1788
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FV0GZ
UT WOS:000424235300005
DA 2024-07-18
ER

PT J
AU Kim, JH
   Kim, CH
   Lee, J
AF Kim, Jong-Hyun
   Kim, Chang-Hun
   Lee, Jung
TI Incorporating particle motion into an ADF for fast coupling of fluids
   with rigid and deformable solids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE direct motion tree; tunneling problem; particle motion path; particle
   transfer
ID DISTANCE FIELDS
AB We present a new method for the fast simulation of interactions between fluids and solids by incorporating particle-based water flow into an adaptive signed distance field. In some previous methods, the motion of every water particle is checked when simulating the collision with the solid in the coupling process, and the computational cost becomes very great as the number of particles increases. If only the particles on the leaf nodes surrounding the solid are considered, this reduces the computational cost of collision detection, but some collisions may not be detected. This may lead to the tunneling artifact, in which particles with high velocities skip across the layer of leaf nodes. This paper addresses the problem by (i) considering particles only on the leaf nodes in the adaptive structure to improve the processing time required for the water-solid coupling and (ii) considering the water flow to avoid the tunneling artifact by incorporating particle motion into the tree structure of the adaptive signed distance field. Our method can be computed in parallel, and experimental results show that it outperforms previous methods while producing animations that are largely free of artifacts. Copyright (c) 2016 John Wiley & Sons, Ltd.
C1 [Kim, Jong-Hyun; Kim, Chang-Hun] Korea Univ, 407B Woojung Bldg,Anam Dong 5o Ga, Seoul 136713, South Korea.
   [Lee, Jung] Hallym Univ, Chunchon, Gangwon, South Korea.
C3 Korea University; Hallym University
RP Kim, CH (corresponding author), Korea Univ, 407B Woojung Bldg,Anam Dong 5o Ga, Seoul 136713, South Korea.
EM chkim@korea.ac.kr
FU Hallym University Research Fund [HRF-201603-005]; Basic Science Research
   Program through the National Research Foundation of Korea (NRF) -
   Ministry of Education, Science and Technology [NRF-2012R1A1A1012895,
   NRF-2013R1A1A2011602, NRF-2014R1A2A2A01007143, NRF-2015R1A1A1A05001196,
   NRF-2015R1C1A2A01053543]; Convergence Technology Development [S2172401]
FX This research was supported by Hallym University Research Fund, 2016
   (HRF-201603-005), Basic Science Research Program through the National
   Research Foundation of Korea (NRF) funded by the Ministry of Education,
   Science and Technology (NRF-2012R1A1A1012895, NRF-2013R1A1A2011602,
   NRF-2014R1A2A2A01007143, NRF-2015R1A1A1A05001196, and
   NRF-2015R1C1A2A01053543), and Convergence Technology Development
   (S2172401).
CR Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Akinci N, 2013, COMPUT ANIMAT VIRT W, V24, P195, DOI 10.1002/cav.1499
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Ando R., 2011, Proceedings-SCA 2011: ACM SIGGRAPH / Eurographics Symposium on Computer Animation, P7, DOI DOI 10.1145/2019406.2019408
   Becker M, 2009, IEEE T VIS COMPUT GR, V15, P493, DOI 10.1109/TVCG.2008.107
   Bell N., 2005, P 2005 ACM SIGGRAPH, P77, DOI DOI 10.1145/1073368.1073379
   Bridson R., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P28
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Brochu T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185592
   Fedkiw RP, 2002, J COMPUT PHYS, V175, P200, DOI 10.1006/jcph.2001.6935
   Frisken SF, 2000, COMP GRAPH, P249, DOI 10.1145/344779.344899
   Hongyi X, 2014, WORKSH VIRT REAL INT
   Houston B., 2004, ACM SIGGRAPH TECHNIC, P137, DOI DOI 10.1145/1186223.1186394
   Huamin W, 2014, ACM T GRAPHIC, V33
   Ihmsen M., 2010, P VRIPHYS, P79
   Jian H, 2001, IEEE VISUAL, P247
   Kaufman DM, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601100
   Larsson T, 2006, COMPUT GRAPH-UK, V30, P450, DOI 10.1016/j.cag.2006.02.011
   Lauterbach C, 2009, COMPUT GRAPH FORUM, V28, P375, DOI 10.1111/j.1467-8659.2009.01377.x
   Lee SH, 2013, COMPUT GRAPH FORUM, V32, P419, DOI 10.1111/cgf.12062
   Lefebvre S., 2007, P 18 EUR C REND TECH, P339
   Liu FC, 2014, IEEE T VIS COMPUT GR, V20, P714, DOI 10.1109/TVCG.2013.268
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Müller M, 2004, PROC GRAPH INTERF, P239
   Museth K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487235
   Nielsen MB, 2006, J SCI COMPUT, V26, P261, DOI 10.1007/s10915-005-9062-8
   Qin J., 2010, P 2010 S INFORM COMM, P128, DOI DOI 10.1145/1852611.1852636
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Sun HQ, 2010, COMPUT ANIMAT VIRT W, V21, P589, DOI 10.1002/cav.379
   Tang M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019630
   Tang M, 2010, GRAPH MODELS, V72, P7, DOI 10.1016/j.gmod.2010.01.001
   Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47
   Weller R, 2009, ROBOTICS, P181
   Weller R, 2009, INT DES ENG TECHN C
   Weller R, 2008, INNER SPHERE TREES, V08-09
   Weller R, 2011, VIRTUAL REALITIES: DAGSTUHL SEMINAR 2008, P181, DOI 10.1007/978-3-211-99178-7_10
   Yang LP, 2012, COMPUT GRAPH FORUM, V31, P2037, DOI 10.1111/j.1467-8659.2012.03196.x
   Yin K, 2011, PROC 19 PACIFIC C CO, DOI [10.2312/PE/PG/PG2011short/025-030, DOI 10.2312/PE/PG/PG2011SHORT/025-030]
   Zhao HK, 2005, MATH COMPUT, V74, P603
   Zheng CX, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185594
NR 41
TC 0
Z9 0
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2017
VL 28
IS 2
AR e1689
DI 10.1002/cav.1689
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ER2AB
UT WOS:000398595200007
DA 2024-07-18
ER

PT J
AU Lee, KH
   Choi, MG
AF Lee, Kang Hoon
   Choi, Myung Geol
TI A path browser for exploratory motion assembly
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE character animation; data-driven synthesis; motion capture; path browser
AB We present an interactive method for creating animation sequences of characters based on captured motion data in an exploratory way as in assembling construction toys. The key component of our method is a path browser that can retrieve and visualize paths as diverse as possible connecting a given pair of initial and final motion fragments instantiated in the space. With the aid of our path browser, the user can develop large-scale assembly of motions gradually through iterations of arranging and putting together motion fragments. For the efficient retrieval of connecting paths, we use a bidirectional search tree that grows from the initial and final configurations simultaneously under the guidance of a mixed strategy for both global exploration and local optimization. The usefulness of our approach is demonstrated through experiments with a variety of motion data including box moving, basketball, and breakdance data. Copyright (C) 2016 JohnWiley & Sons, Ltd.
C1 [Lee, Kang Hoon] Kwangwoon Univ, Dept Comp Sci, Seoul, Bucheon, South Korea.
   [Choi, Myung Geol] Catholic Univ Korea, Dept Media Technol & Contents Technol, Seoul, South Korea.
C3 Kwangwoon University; Catholic University of Korea
RP Choi, MG (corresponding author), Catholic Univ Korea, Seoul, South Korea.
EM mgchoi@catholic.ac.kr
CR Choi MG, 2012, COMPUT GRAPH FORUM, V31, P2057, DOI 10.1111/j.1467-8659.2012.03198.x
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Choi MG, 2011, COMPUT GRAPH FORUM, V30, P445, DOI 10.1111/j.1467-8659.2011.01889.x
   Davis J, 2003, P 2007 S COMP AN SAN, P320
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Karaman S, 2013, IEEE INT CONF ROBOT, P5041, DOI 10.1109/ICRA.2013.6631297
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kuffner J. J.  Jr., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P995, DOI 10.1109/ROBOT.2000.844730
   Lau M., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA '05, P271
   LaValle S, 1998, TECHNICAL REPORTS
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lee KH, 2006, ACM T GRAPHIC, V25, P898, DOI 10.1145/1141911.1141972
   Lee S, 1997, IEEE T VIS COMPUT GR, V3, P228, DOI 10.1109/2945.620490
   Lee Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866160
   Levine S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966402
   Lo WY, 2010, COMPUT GRAPH FORUM, V29, P563, DOI 10.1111/j.1467-8659.2009.01626.x
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Min JY, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640452
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Shin H.J., 2006, Proceedings of ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P291
   Shum HPH, 2012, IEEE T VIS COMPUT GR, V18, P741, DOI 10.1109/TVCG.2010.257
   SUNG M., 2005, SCA 05, P291
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Yoo I, 2014, VISUAL COMPUT, V30, P213, DOI 10.1007/s00371-013-0797-1
NR 24
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 205
EP 212
DI 10.1002/cav.1692
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300004
DA 2024-07-18
ER

PT J
AU Barbosa, CWF
   Dobashi, Y
   Yamamoto, T
AF Barbosa, Charles Welton Ferreira
   Dobashi, Yoshinori
   Yamamoto, Tsuyoshi
TI Adaptive cloud simulation using position based fluids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE cloud simulation; particle-based; adaptive simulation
AB In this paper, we propose a method for the simulation of clouds using particles exclusively. The method is based on position based fluids, which simulates fluids using position constraints. To reduce the simulation time, we have used adaptive splitting and merging to concentrate computation on regions where it is most needed. When clouds are formed, particles are split so as to add more details to the generated cloud surface and when they disappear, particles are merged back. We implement our adaptive method on the Graphics Processing Unit (GPU) to accelerate the computation. While the splitting portion is easily parallelizable, the merge portion is not. We develop a simple algorithm to address this problem and achieve reasonable simulation times. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Barbosa, Charles Welton Ferreira; Dobashi, Yoshinori; Yamamoto, Tsuyoshi] Hokkaido Univ, Grad Sch Informat Sci & Technol, Kita Ku, Sapporo, Hokkaido 0600814, Japan.
C3 Hokkaido University
RP Barbosa, CWF (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Kita Ku, Kita 14,Nishi 9, Sapporo, Hokkaido 0600814, Japan.
EM charles@ime.ist.hokudai.ac.jp
CR ADAMS B., 2007, ACM SIGGRAPH 2007
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   [Anonymous], 2015, NVIDIA ARC MENTAL RA
   Bouthors A., 2004, MODELING CLOUDS SHAP
   Dobashi Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366164
   Dobashi Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360693
   Ebert D. S., 1997, VISUAL P SIGGRAPH 97, P147
   Gustavson Stefan, 2005, RES REPORT
   Harris M., 2007, GPU GEMS
   Harris M.J., 2003, Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware, Eurographics Association, P92
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Ihmsen M, 2011, COMPUT GRAPH FORUM, V30, P99, DOI [10.1111/j.1467-8659.2010.01832.x, 10.1111/j.1467-8659.2010.01834.x]
   Kim M., 2012, Proceedings of the 5th Annual Workshop on General Purpose Processing with Graphics Processing Units, P38
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Miyazaki Ryo., 2002, Proceedings of Eurographics 2002 Short Papers (EG'02), P405
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Petronetto F, 2010, IEEE T VIS COMPUT GR, V16, P338, DOI 10.1109/TVCG.2009.61
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Schpok J., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P160
   Solenthaler B., 2009, ACM SIGGRAPH 2009 PA, P40
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Voss R., 1983, STATE ART IMAGE SYNT, V10
   Wither J., 2008, P 5 EUR C SKETCH BAS, P113
   Yuan CQ, 2014, COMPUT GRAPH FORUM, V33, P288, DOI 10.1111/cgf.12350
NR 26
TC 11
Z9 13
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 367
EP 375
DI 10.1002/cav.1657
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700018
DA 2024-07-18
ER

PT J
AU Karimaghalou, N
   Bernardet, U
   DiPaola, S
AF Karimaghalou, Nahid
   Bernardet, Ulysses
   DiPaola, Steve
TI A model for social spatial behavior in virtual characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE social navigation; group dynamics; virtual characters; behavior
   regulation
ID INTERPERSONAL DISTANCE
AB Plausible spatial behavior is a key capability that autonomous virtual characters need in order to provide ecologically valid social interactions. However, there is a lack of psychological data on spatial behavior in the larger scale social settings and over extended periods of time. In this paper, we present a social navigation model that aims at generating human-like spatial behavior for a virtual human in a social setting with group dynamics. We employ an engineering approach by defining a dynamic representation of interest and then using it as the psychometric function that regulates the behavior of the agent. We evaluate our model by means of two test cases that address different aspect of the model and serve as a proof of concept. Our work is a step toward models for generating more plausible social spatial behavior for virtual characters that is based on both internal dynamics and attributes of the social environment. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Karimaghalou, Nahid; Bernardet, Ulysses; DiPaola, Steve] Simon Fraser Univ, IVizLab, Surrey, BC, Canada.
C3 Simon Fraser University
RP DiPaola, S (corresponding author), Simon Fraser Univ, IVizLab, Surrey, BC, Canada.
EM sdipaola@sfu.ca
RI Bernardet, Ulysses/D-5477-2016; DiPaola, Stephen R/M-5861-2013
OI Bernardet, Ulysses/0000-0003-4659-3035; 
FU "Moving Stories" and "Moving + Meaning" Canadian Social Sciences and
   Humanities Research Council (SSHRC); CANARIE
FX This work was partially supported by "Moving Stories" and "Moving +
   Meaning" Canadian Social Sciences and Humanities Research Council
   (SSHRC) and CANARIE grants, respectively.
CR Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Bischof N, 1991, INFANT DEV PERSPECTI
   Cristani M., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P290, DOI 10.1109/PASSAT/SocialCom.2011.32
   Friedman D, 2007, LECT NOTES ARTIF INT, V4722, P252
   GEIWITZ PJ, 1966, J PERS SOC PSYCHOL, V3, P592, DOI 10.1037/h0023202
   GROVES P M, 1970, Psychological Review, V77, P419, DOI 10.1037/h0029810
   Hall E.T., 1992, The Hidden Dimension
   HILL AB, 1985, BRIT J PSYCHOL, V76, P235, DOI 10.1111/j.2044-8295.1985.tb01947.x
   Inderbitzin Martin, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P809, DOI 10.1109/FG.2011.5771353
   Kendon Adam, 1990, CUP Archive, P153
   Klein RM, 2000, TRENDS COGN SCI, V4, P138, DOI 10.1016/S1364-6613(00)01452-2
   LIBERMAN N, 2007, HDB BASIC PRINCIPLES
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   PATTERSON ML, 1977, J SOC PSYCHOL, V101, P205, DOI 10.1080/00224545.1977.9924008
   Pedica C, 2008, LECT NOTES COMPUT SC, V5208, P104
   Rehm M, 2005, LECT NOTES COMPUT SC, V3814, P124, DOI 10.1007/11590323_13
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rist T, 2008, ADV CONSC RES, V74, P213
   Sun LB, 2012, COMPUT ANIMAT VIRT W, V23, P17, DOI 10.1002/cav.1421
   Thiebaux Marcus., 2008, P AAMAS 08, P151
   Thórisson KR, 2010, LECT NOTES ARTIF INT, V6356, P350, DOI 10.1007/978-3-642-15892-6_37
NR 22
TC 1
Z9 2
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 507
EP 519
DI 10.1002/cav.1600
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA AJ2WD
UT WOS:000337524300031
DA 2024-07-18
ER

PT J
AU Pelkey, CD
   Allbeck, JM
AF Pelkey, Cameron D.
   Allbeck, Jan M.
TI Populating semantic virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE smart objects; autonomous actors; virtual humans; semantics and
   ontologies for virtual environments
AB The capacity for knowledge representation within simulated environments is a growing field of research geared toward the inclusion of detailed descriptors within the environment through which to provide a virtual agent the knowledge necessary to afford decision-making and interaction. One such layer of representation is that concerning the natural-language, or semantic, depiction of the environment and the objects within it. However, even as technology grows more capable of representing such information-rich environments, the process of authoring and injecting this knowledge has largely remained a manual effort. Not only is this effort arduous for the author in both time and energy expenditure required, but the process also lends itself to limiting the ontology of the simulation further constraining the extent to which such knowledge may be used. Here, we offer an affordable method for semi-automating the generation and injection of semantic properties into a virtual environment for the purpose of producing more natural agent-object interaction. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Pelkey, Cameron D.; Allbeck, Jan M.] George Mason Univ, GAIA Lab, Fairfax, VA 22030 USA.
C3 George Mason University
RP Pelkey, CD (corresponding author), George Mason Univ, GAIA Lab, Fairfax, VA 22030 USA.
EM cpelkey2@gmu.edu; jallbeck@gmu.edu
FU George Mason University's Undergraduate Research Scholars Program
FX Additional support is appreciated from fellow researchers John Balint
   and Shible Duman. We also appreciate donations from Autodesk. Partial
   support for this effort is also acknowledged from George Mason
   University's Undergraduate Research Scholars Program.
CR [Anonymous], 1995, ARTIFICIAL INTELLIGE
   [Anonymous], 2010, About WordNet
   [Anonymous], P 2013 INT C AUT AG
   Bindiganavale R, 2000, P 4 INT C AUT AG AGE
   Bird S., 2009, NATURAL LANGUAGE PRO
   Cavazza M, 2004, P 9 INT C INT US INT
   Eckert K, 2010, P 10 ANN JOINT C DIG
   Gibson J. J., 2014, The ecological approach to visual perception, Vclassic
   Inc. Cycorp, 2014, OPENCYC PLATF
   Kalicinski M, 2009, RAPIDXML
   Kallmann M, 2002, J VISUAL LANG COMPUT, V13, P177, DOI 10.1006/jvlc.2001.0229
   Kalogerakis E, 2006, P IEEE VIRT REAL ANN, P43, DOI 10.1109/VR.2006.41
   Lugrin JL, 2007, P 12 INT C INT US IN
   Massachusetts Institute of Technology, 2013, CONCEPTNET 5
   McGrenere J, 2000, PROC GRAPH INTERF, P179
   Palmer M, 2013, VERBNET CLASS BASED
   Pellens B, 2005, P 2005 OTM CONF INT
   Pittarello F, 2006, P 11 INT C 3D WEB TE
   TUTENEL T., 2008, Computers in Entertainment CIE, V6, P57
   Van Rossum G., 2007, P 2007 USENIX ANN TE, VVolume 41, P1
NR 20
TC 6
Z9 7
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 405
EP 412
DI 10.1002/cav.1587
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300021
DA 2024-07-18
ER

PT J
AU Li, SW
   Huang, J
   Desbrun, M
   Jin, XG
AF Li, Siwang
   Huang, Jin
   Desbrun, Mathieu
   Jin, Xiaogang
TI Interactive elastic motion editing through spacetime position
   constraints
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion editing; elastic animation; spacetime constraints; model
   reduction; adjoint method
AB We present an intuitive and interactive approach for motion editing through spacetime constraints on positions. Given an input motion of an elastic body, our approach enables the user to interactively edit node positions in order to alter and fine-tune the motion. We formulate our motion editing as an optimization problem with dynamics constraints to enforce a physically plausible result. Through linearization of the editing around the input trajectory, we simplify this constrained optimal control problem into an unconstrained quadratic optimization. The optimal motion thus becomes the solution of a dense linear system, which we solve efficiently by applying the adjoint method in each iteration of a conjugate gradient solver. We demonstrate the efficiency and quality of our motion editing technique on a series of examples. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Li, Siwang; Huang, Jin; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Desbrun, Mathieu] CALTECH, Dept Comp & Math Sci MS 305 16, Pasadena, CA 91125 USA.
C3 Zhejiang University; California Institute of Technology
RP Huang, J (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM hj@cad.zju.edu.cn
RI Desbrun, Mathieu/AAG-9974-2021
OI Desbrun, Mathieu/0000-0003-3424-6079
FU NSFC [61210007]; National High Technology Research, and Development
   (863) Program of China [2012AA011503]; NSF [CCF-1011944]; Zhejiang
   Provincial Natural Science Foundation of China [Z1110154]; National
   Natural Science Foundation of China [61272298]; Direct For Computer &
   Info Scie & Enginr; Division of Computing and Communication Foundations
   [1011944] Funding Source: National Science Foundation
FX The authors would like to thank the reviewers for their valuable
   comments. We thank Miss Linling Zhou for the creation of the animation
   for Figures 3, 4, and 6; Mr. Xiaoqiang Zhu for the codes to prepare the
   volumetric meshes; and Miss Nina Qiu for proofreading. This research was
   partially supported by NSFC (No. 61210007), National High Technology
   Research, and Development (863) Program of China (No. 2012AA011503). M.
   D. was partially supported by NSF grant CCF-1011944. Xiaogang Jin was
   supported by Zhejiang Provincial Natural Science Foundation of China
   (No. Z1110154) and National Natural Science Foundation of China (No.
   61272298).
CR [Anonymous], 1971, GRUNDLEHREN MATH WIS
   [Anonymous], 2005, ACMEUROGRAPHICS S CO
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Barbi J, 2012, ACM T GRAPHICS, V31, P70
   Barbi J, 2008, ACM T GRAPHICS, V27, P163
   Barbi J, 2009, ACM T GRAPHICS, V28, P53
   Barbic J, 2005, ACM T GRAPHIC, V24, P982, DOI 10.1145/1073204.1073300
   Bergou M, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239501
   Choi MG, 2005, IEEE T VIS COMPUT GR, V11, P91
   Etzmuss O, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P244, DOI 10.1109/PCCGA.2003.1238266
   Fang AC, 2003, ACM T GRAPHIC, V22, P417, DOI 10.1145/882262.882286
   Gleicher M., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P139, DOI 10.1145/253284.253321
   HAUSER K. K., 2003, Graphics Interface, V3, P6
   Hildebrandt K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185567
   Huang J, 2011, IEEE T VIS COMPUT GR, V17, P983, DOI 10.1109/TVCG.2010.109
   Jeon H, 2007, IEEE INT CONF ROBOT, P2582, DOI 10.1109/ROBOT.2007.363854
   Kim T, 2009, P ACM SIGGRAPH AS NE
   Kim Y., 2006, P 2006 ACM SIGGRAPHE, P33
   Kondo R., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation - SCA '05, P127, DOI [10.1145/1073368.1073385, DOI 10.1145/1073368.1073385]
   McAdams A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964932
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Müller M, 2004, PROC GRAPH INTERF, P239
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   Nielsen MB, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964978
   PENTLAND A., 1989, COMPUT GRAPHICS-US, V23, P207
   Popovic J, 2000, COMP GRAPH, P209, DOI 10.1145/344779.344880
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Twigg Christopher D., 2007, ACM T GRAPHIC, V26
   Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507
   Wojtan C., 2006, P 2006 ACM SIGGRAPHE, P15
NR 31
TC 7
Z9 7
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 409
EP 417
DI 10.1002/cav.1521
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500028
DA 2024-07-18
ER

PT J
AU Buche, C
   De Loor, P
AF Buche, C.
   De Loor, P.
TI Anticipatory behavior in virtual universe, application to a virtual
   juggler
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE anticipation; real-time interaction; decision making; behavioral model;
   virtual juggler; virtual character; computer animation
ID SIMULATION
AB To be believable, virtual entities must be equipped with the ability to anticipate, that is, to predict the behavior of other entities and the subsequent consequences on the environment. For that purpose, we propose an original approach where the entity possesses an autonomous world of simulation within simulation, in which it can simulate itself (with its own model of behavior) and simulate the environment (with the representation of the behaviors of the other entities). This principle is illustrated by the development of an artificial juggler in 3D. In this application, the juggler predicts the motion of the balls in the air and uses its predictions to coordinate its own behavior to continue to juggle.Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Buche, C.; De Loor, P.] CERV, UEB ENIB LAB STICC, F-29280 Plouzane, France.
C3 Ecole Nationale d'Ingenieurs de Brest (ENIB)
RP Buche, C (corresponding author), CERV, UEB ENIB LAB STICC, 25 Rue Claude Chappe, F-29280 Plouzane, France.
EM buche@enib.fr
RI De Loor, Pierre/AAP-7967-2020
CR [Anonymous], 1950, MIND, DOI 10.1093/mind/LIX.236.433
   [Anonymous], 1994, TECHNICAL REPORT
   [Anonymous], REAL TIME CHARACTER
   Aubry M, 2010, CAS 2010 23 INT C CO
   BATES J, 1992, CMUCS92200
   Bergson H., 1896, Matiere et memoire.
   Berthoz A., 2000, The brain's sense of movement
   Berthoz Alain., 2006, EMOTION REASON
   Bossard C, 2009, P 11 VIRT REAL INT C
   BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032
   Brunia CHM, 1999, ACTA PSYCHOL, V101, P213, DOI 10.1016/S0001-6918(99)00006-2
   Buche C, 2010, COMPUT ANIMAT VIRT W, V21, P573, DOI 10.1002/cav.363
   Buche C, 2011, COMPUT ANIMAT VIRT W, V22, P133, DOI 10.1002/cav.401
   Butz MV, 2003, LECT NOTES ARTIF INT, V2684, P1
   Chin-Chang Ho, 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P169
   COLWILL RM, 1985, J EXP PSYCHOL-ANIM B, V11, P520, DOI 10.1037/0097-7403.11.4.520
   Craik K.J.W., 1943, The Nature of Explanation, DOI DOI 10.2307/2018933
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Davidsson P, 2003, LECT NOTES ARTIF INT, V2684, P151
   DUFOSSE M, 1985, EXP BRAIN RES, V60, P330
   Gorman B, 2006, LECT NOTES COMPUT SC, V4095, P655
   Groom V, 2009, INT J HUM-COMPUT ST, V67, P842, DOI 10.1016/j.ijhcs.2009.07.001
   Hawkins J., 2006, HIERARCHICAL TEMPORA
   Hesslow G, 2002, TRENDS COGN SCI, V6, P242, DOI 10.1016/S1364-6613(02)01913-7
   Hoffmann J, 2003, LECT NOTES ARTIF INT, V2684, P44
   Hoffmann Joachim, 2007, Cogn Process, V8, P133, DOI 10.1007/s10339-007-0166-y
   HUGON M, 1982, PFLUG ARCH EUR J PHY, V393, P292, DOI 10.1007/BF00581412
   Hume, 1740, TRAITE NATURE HUMAIN
   Husserl E., 1992, MEDITATIONS CARTESIE
   JOHANSSON B, 2007, ANTICIPATORY BEHAV A
   Julliard F, 1999, LECT NOTES ARTIF INT, V1739, P265
   Kipp M, 2007, LECT NOTES ARTIF INT, V4722, P15
   Kunde W, 2004, Q J EXP PSYCHOL-A, V57, P87, DOI 10.1080/02724980343000143
   Kunde W, 2002, ACTA PSYCHOL, V109, P137, DOI 10.1016/S0001-6918(01)00053-1
   Labbe V, 2004, P ABIALS 2004 WORKSH, P51
   Laird J. E., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, P385, DOI 10.1145/375735.376343
   Laroque Ph., 2010, J BEHAV ROBOT, V1, P25, DOI [10.2478/s13230-010-0004-2, DOI 10.2478/S13230-010-0004-2]
   LIVINGSTONE D, 2006, COMPUTER ENTERTAINME, V4, DOI DOI 10.1145/1111293.1111303
   Mac Namee B., 2004, THESIS TRINITY COLL
   Morineau T, 2003, INT J AVIAT PSYCHOL, V13, P107, DOI 10.1207/S15327108IJAP1302_02
   Multon F, 2001, VISUAL COMPUT, V17, P91, DOI 10.1007/s003710000086
   Pezzulo G., 2007, COGN PROCESS, V8, P67, DOI DOI 10.1007/S10339-007-0173-Z
   Riegler A, 2001, AIP CONF PROC, V573, P534, DOI 10.1063/1.1388719
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0
   Rosen R., 1985, Anticipatory systems: Philosophical, mathematical, and methodological foundations (ifsr international series on systems science and engineering)
   Sigaud O, 2007, SOFT COMPUT, V11, P1065, DOI 10.1007/s00500-007-0164-0
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Stoffregen TA, 1999, J EXP PSYCHOL HUMAN, V25, P120, DOI 10.1037/0096-1523.25.1.120
   Tani J, 2008, IEEE T SYST MAN CY B, V38, P43, DOI 10.1109/TSMCB.2007.907738
   Tolman E.C., 1959, Psychology: A Study of a Science, V2, P92
   Watkins C. J. C. H., 1989, LEARNING DELAYED REW
NR 51
TC 2
Z9 2
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2013
VL 24
IS 2
BP 111
EP 125
DI 10.1002/cav.1486
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 131ZB
UT WOS:000318036300005
DA 2024-07-18
ER

PT J
AU Yoshiyasu, Y
   Yamazaki, N
AF Yoshiyasu, Yusuke
   Yamazaki, Nobutoshi
TI Example-based inverse kinematics using cage
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE cage-based deformation; example-based deformation
ID DEFORMATION
AB This paper presents a cage-based inverse kinematics (CageIK) that enables interactive posing of character models in a wide range of mesh representations using handle points. By providing a set of cage geometries as examples, CageIK optimizes deformations of the cage according to handle movements and reconstructs the model using a subspace deformation method based on Green Coordinates. CageIK therefore not only poses the model naturally but also preserves details even when leaving the example space. Furthermore, by blending deformations based on bounded biharmonic weights, CageIK can edit the pose of the model locally. Because example cages can be generated from existing models, we can reuse animation assets that were already created by artists or simulations, which avoids repeating the time-consuming process of creating examples. We show that CageIK can edit a wide variety of models, including multicomponent meshes, polygon soups, and quadrilateral meshes. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Yamazaki, Nobutoshi] Keio Univ, Dept Mech Engn, Yokohama, Kanagawa 223, Japan.
C3 Keio University
RP Yoshiyasu, Y (corresponding author), 3-14-1 Hiyoshi,Kohoku Ku, Yokohama, Kanagawa 2238522, Japan.
EM yusuke_2_ax_es@z6.keio.jp
RI Yoshiyasu, Yusuke/M-4386-2016
CR Baran I, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531342
   Ben-Chen M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531340
   Ben-Chen Mirela, 2009, P 2009 ACM SIGGRAPH, P67
   Botsch Mario, 2006, DEFORMATION TRANSFER
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Chen L, 2010, COMPUT GRAPH-UK, V34, P107, DOI 10.1016/j.cag.2010.01.003
   Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995
   Der KG, 2006, ACM T GRAPHIC, V25, P1174, DOI 10.1145/1141911.1142011
   Feng WW, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360690
   Fröhlich S, 2011, COMPUT GRAPH FORUM, V30, P2246, DOI 10.1111/j.1467-8659.2011.01974.x
   Grinspun E., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P62
   Huang H., 2011, PROC 2011 ACM SIGGRA, P73, DOI DOI 10.1145/2019406.2019416
   Jacobson A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964973
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Kircher S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1356682.1356685
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Savoye Y, 2010, LECT NOTES COMPUT SC, V6169, P280, DOI 10.1007/978-3-642-14061-7_27
   Sumner RW, 2005, ACM T GRAPHIC, V24, P488, DOI 10.1145/1073204.1073218
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Weber O, 2007, COMPUT GRAPH FORUM, V26, P265, DOI 10.1111/j.1467-8659.2007.01048.x
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zayer R, 2005, COMPUT GRAPH FORUM, V24, P601, DOI 10.1111/j.1467-8659.2005.00885.x
NR 25
TC 1
Z9 1
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 203
EP 213
DI 10.1002/cav.1444
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100008
DA 2024-07-18
ER

PT J
AU Pantuwong, N
   Sugimoto, M
AF Pantuwong, Natapon
   Sugimoto, Masanori
TI A novel template-based automatic rigging algorithm for
   articulated-character animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE automatic rigging; skeleton; animation; template skeleton; skeleton
   reusing
ID SKELETONS
AB Rigging is a process for creating skeletons used to animate articulated characters. In conventional computer-animation software, this process must be performed manually. Although several automatic rigging algorithms have been proposed, these methods still require user intervention. This paper proposes an automatic algorithm that generates an inverse kinematic skeleton for a character by locating an appropriate template skeleton on the extracted curve skeleton of the input 3D character model. After the curve skeleton is extracted, it is analyzed and classified into an appropriate category. The classification conditions are developed from the characteristics of each kind of real animal. We also develop an algorithm to extract the anatomical meaning of each skeleton segment. On the basis of the classification result, a suitable template skeleton is retrieved from the database. Each bone of the template skeleton can then be located on the appropriate skeleton segment of the input skeleton graph by using the extracted anatomical meanings. In contrast to previous methods, the algorithm does not require the input 3D character models to have certain poses or orientations. Moreover, all processes can be completed without user intervention. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Pantuwong, Natapon] Univ Tokyo, Interact Technol Lab, Bunkyo Ku, Tokyo 1138658, Japan.
C3 University of Tokyo
RP Pantuwong, N (corresponding author), Univ Tokyo, Interact Technol Lab, Bunkyo Ku, Room 504,5th Floor,Informat Technol Ctr Bldg,2-11, Tokyo 1138658, Japan.
EM na@itl.t.u-tokyo.ac.jp
CR Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Aujay G, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P151
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Baran I, AUTOMATIC RIGGING AN
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Blender Foundation, BLEND 3D
   CMU Graphics Lab, CMU graphics lab motion capture database
   Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Hasler N., 2010, P ACM SIGGRAPH S INT, P23, DOI DOI 10.1145/1730804.1730809
   He Y, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P53, DOI 10.1109/SMI.2008.4547949
   Lien J, 2006, P 2006 ACM S SOL PHY, P219
   Liu PC, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P409
   Nooruddin FS, 2003, IEEE T VIS COMPUT GR, V9, P191, DOI 10.1109/TVCG.2003.1196006
   Oshita M, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P146, DOI 10.1109/CW.2009.46
   Pan JJ, 2009, COMPUT ANIMAT VIRT W, V20, P121, DOI 10.1002/cav.284
   Pantuwong N, 2010, VMV 10, P235
   Pantuwong N, 2010, SIGGRAPH ASIA 10 SKE
   Poirier M, 2009, Graphics interface, P103
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Wade L, 2000, COMP ANIM CONF PROC, P164, DOI 10.1109/CA.2000.889075
   Yuksel Can, 2007, Symposium on Geometry Processing, P153, DOI DOI 10.2312/SGP/SGP07/153-162
NR 22
TC 12
Z9 14
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2012
VL 23
IS 2
BP 125
EP 141
DI 10.1002/cav.1429
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 926VJ
UT WOS:000302859700007
DA 2024-07-18
ER

PT J
AU van Toll, WG
   Cook, AF
   Geraerts, R
AF van Toll, Wouter G.
   Cook, Atlas F.
   Geraerts, Roland
TI Real-time density-based crowd simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; crowd density; navigation mesh; path planning
AB Virtual characters in games and simulations often need to plan visually convincing paths through a crowded environment. This paper describes how crowd density information can be used to guide a large number of characters through a crowded environment. Crowd density information helps characters avoid congested routes that could lead to traffic jams. It also encourages characters to use a wide variety of routes to reach their destination. Our technique measures the desirability of a route by combining distance information with crowd density information. We start by building a navigation mesh for the walkable regions in a polygonal two-dimensional (2-D) or multilayered three-dimensional (3-D) environment. The skeleton of this navigation mesh is the medial axis. Each walkable region in the navigation mesh maintains an up-to-date density value. This density value is equal to the area occupied by all the characters inside a given region divided by the total area of this region. These density values are mapped onto the medial axis to form a weighted graph. An A* search on this graph yields a backbone path for each character, and forces are used to guide the characters through the weighted environment. The characters periodically replan their routes as the density values are updated. Our experiments show that we can compute congestion-avoiding paths for tens of thousands of characters in real-time. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [van Toll, Wouter G.; Cook, Atlas F.; Geraerts, Roland] Univ Utrecht, Dept Informat & Comp Sci, NL-3584 CC Utrecht, Netherlands.
C3 Utrecht University
RP Geraerts, R (corresponding author), Univ Utrecht, Dept Informat & Comp Sci, NL-3584 CC Utrecht, Netherlands.
EM R.J.Geraerts@uu.nl
RI Geraerts, Roland/B-3859-2016
OI Geraerts, Roland/0000-0002-8161-579X
FU GATE; INCONTROL Simulation Solutions; Netherlands Organization for
   Scientific Research (NWO)
FX This research has been supported by the GATE project
   (http://gate.gameresearch.nl), INCONTROL Simulation Solutions, and the
   Netherlands Organization for Scientific Research (NWO). The authors are
   part of the Institute of Information and Computing Sciences, Utrecht
   University, 3584 CC Utrecht, the Netherlands.
CR [Anonymous], 2009, P 4 INT C FDN DIGITA, DOI DOI 10.1145/1536513.1536540
   Daamen W., 2004, MODELLING PASSENGER
   Daamen W., 2004, TRAIL conference proceedings 2004, P103
   Geraerts R, 2010, IEEE INT CONF ROBOT, P1997, DOI 10.1109/ROBOT.2010.5509263
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Hocker M., 2010, EWORK EBUSINESS ARCH, P389, DOI DOI 10.1201/B10527-65
   Kallmann M., 2005, P WORKSHOP REASONING, P49
   Karamouzas Ioannis, 2009, 2009 International IEEE Consumer Electronics Society's Games Innovations Conference (ICE-GIC 2009), P160, DOI 10.1109/ICEGIC.2009.5293590
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Kneidl A., 2011, Emergency Evacuation of people from Buildings
   Koenig S, 2005, IEEE T ROBOT, V21, P354, DOI 10.1109/TRO.2004.838026
   Kuffner J. J.  Jr., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P995, DOI 10.1109/ROBOT.2000.844730
   Mononen M, 2011, RECAST NAVIGATION
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Patil S., 2010, IEEE T VISUALIZATION, P244
   PETTRE J, 2005, P 1 INT WORKSH CROWD
   Pettré J, 2007, IEEE INT CONF ROBOT, P3062, DOI 10.1109/ROBOT.2007.363937
   Preperata F.P., 1977, MATH FDN COMPUTER SC, V53, P443
   Rabin S, 2004, AI GAMES PROGRAMMING
   Roland G., 2008, Comput. Animation Social Agents, P64
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van Toll W, 2011, IEEE INT C INT ROBOT, P3526, DOI 10.1109/IROS.2011.6048397
   Weidmann U, 1993, 90 ETH I VERK TRANSP
   Wein R, 2007, COMP GEOM-THEOR APPL, V36, P66, DOI 10.1016/j.comgeo.2005.11.007
   Yersin B, 2008, VISUAL COMPUT, V24, P859, DOI 10.1007/s00371-008-0286-0
   Zheng XP, 2009, BUILD ENVIRON, V44, P437, DOI 10.1016/j.buildenv.2008.04.002
NR 28
TC 52
Z9 56
U1 3
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2012
VL 23
IS 1
BP 59
EP 69
DI 10.1002/cav.1424
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 897SH
UT WOS:000300675800007
DA 2024-07-18
ER

PT J
AU Kim, JH
   Choi, JJ
   Hoffmann, CM
AF Kim, Jong-Hyuk
   Choi, Jung-Ju
   Hoffmann, Christoph M.
TI Pose space parameterization and style transfer of skin deformation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE skin deformation; parameterization; style transfer
AB We present a technique to parameterize skin deformation by skeletal motion and to transfer the deformation style from one character to another. We decompose skin deformation into time-varying signals and basis matrices by using dimension reduction techniques and then approximate the time-varying signals by using radial basis functions with respect to joint angles that define skeletal motion. This decomposition reduces the size of deformation data to a small number of time-varying signals that represent the complex role of muscle action. The subsequent parameterization yields a fast and intuitive control of characters; thus, it allows us to construct faithful skin deformations quickly as skeletal bones move. The representation of our parameterization allows us to capture and transfer a derived deformation style to another skeletonskin structure without considering the input dimension of the deformation data. This style transfer can be used as a basis for realistically animating variants of sample characters that have the same skeletal topology. Parameterization of skin deformation and its style transfer can be performed within a small amount of error once the preprocessing time and control of the deformation is carried out in real time by our graphics processing unit implementation. Copyright (c) 2011 John Wiley & Sons, Ltd.
C1 [Choi, Jung-Ju] Ajou Univ, Grad Sch Informat & Commun, Suwon 441749, South Korea.
   [Kim, Jong-Hyuk] Ajou Univ, Dept Digital Media, Suwon 441749, South Korea.
   [Hoffmann, Christoph M.] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
C3 Ajou University; Ajou University; Purdue University System; Purdue
   University
RP Choi, JJ (corresponding author), Ajou Univ, Grad Sch Informat & Commun, Suwon 441749, South Korea.
EM jungju@ajou.ac.kr
FU Ajou University
FX This paper was completed with Ajou University research fellowship of
   2008.
CR Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2001, P 2001 S INTERACTIVE
   [Anonymous], 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'02
   BARAN I, 2009, ACM SIGGRAPH 2009 PA, V36, P1
   Buhmann M.D., 2003, C MO AP C M, V12, DOI 10.1017/CBO9780511543241
   DER KG, 2006, SIGGRAPH 06, P1174
   FENG WW, 2008, SIGGRAPH, P1
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Jolliffe L., 2002, Principal Component Analysis
   Kavan L, 2010, COMPUT GRAPH FORUM, V29, P327, DOI 10.1111/j.1467-8659.2009.01602.x
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Kurihara Tsuneya, 2004, P 2004 ACM SIGGRAPHE, P355
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   MAGNENATTHALMAN.N, 1988, GRAPHICS INTERFACE, P26
   MOHR A, 2003, SIGGRAPH 03, P562
   Park SI, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360695
   PARK SI, 2006, SIGGRAPH 06, P881
   Sand P, 2003, ACM T GRAPHIC, V22, P578, DOI 10.1145/882262.882310
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Wang Robert Y., 2007, ACM SIGGRAPH 2007 PA
   Wang XiaohuanGorina., 2002, S COMPUTER ANIMATION, P129
   XIAN X, 2006, COMPUTER ANIMATION S
NR 24
TC 0
Z9 0
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2011
VL 22
IS 6
BP 511
EP 518
DI 10.1002/cav.428
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856IA
UT WOS:000297631200004
DA 2024-07-18
ER

PT J
AU He, J
   Zhang, CM
   Wei, Y
   Li, WT
AF He, Jun
   Zhang, Caiming
   Wei, Yu
   Li, Weitao
TI Feature sensitive deformation for triangular mesh models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Laplacian deformation; dual mesh; feature sensitive
ID SHAPE DEFORMATION
AB Shape deformation is a useful tool for shape modeling and animation in computer graphics. In this paper, we propose a novel surface deformation method based on a feature sensitive (FS) metric. Firstly, taking unit normal vectors into account, we derive a FS Laplacian operator, which is more sensitive to featured regions of mesh models than existing operators. Secondly, we use the 1-ring tetrahedron in the dual mesh, a volumetric structure, to encode geometric details. To preserve the shape of the tetrahedron, we introduce linear tetrahedron constraints minimizing both the distortion of the base triangle and the change of the corresponding height. These ensure that geometric details are accurately preserved during deformation. The time complexity of our new method is similar to that of existing linear Laplacian methods. Examples are included to show that our FS deformation method better preserves mesh details, especially features, than existing Laplacian methods. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Zhang, Caiming] Shandong Univ, Sch Comp Sci & Technol, Qilu Software Coll, Jinan 250061, Shandong, Peoples R China.
   [He, Jun; Zhang, Caiming] Shandong Econ Univ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
C3 Shandong University; Shandong University of Finance & Economics
RP Zhang, CM (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Qilu Software Coll, Middle Shunhua Rd, Jinan 250061, Shandong, Peoples R China.
EM czhang@sdu.edu.cn
RI Zhang, Caiming/AHD-6558-2022
OI Zhang, Caiming/0000-0002-6365-6221
FU National Key Basic Research 973 program of China [2006CB303102];
   National Natural Science Foundation of China [60703081, 60903109,
   60933008]
FX The authors are grateful to Shi-Min Hu for his insightful discussions.
   And they would like to thank Yukun Lai and Guoxin Zhang for their kind
   help. This work was done when Jun He was a visiting student at Visual
   media Research center, Tsinghua University. Furthermore, we appreciate
   the suggestions of the anonymous reviewers. This work is supported by
   the National Key Basic Research 973 program of China (Grant No.
   2006CB303102) and the National Natural Science Foundation of China
   (Grant NO. 60703081, 60903109, 60933008).
CR Alexa M, 2003, VISUAL COMPUT, V19, P105, DOI 10.1007/s00371-002-0180-0
   Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Au OKC, 2006, IEEE T VIS COMPUT GR, V12, P386, DOI 10.1109/TVCG.2006.47
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Gain J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409629
   Guskov I, 1999, COMP GRAPH, P325, DOI 10.1145/311535.311577
   Hu SM, 2001, VISUAL COMPUT, V17, P370, DOI 10.1007/s003710100114
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   JOSHI P, 2007, SIGGRAPH 07 ACM SIGG
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   JU T, 2008, SIGGRAPH ASIA 08 ACM, P1
   Kobbelt L., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P105, DOI 10.1145/280814.280831
   Kraevoy Vladislav., 2006, International Journal of Shape Modeling, V12, P29
   Lai Y.K., 2006, PROC ACM S SOLID PHY, P17
   Lai YK, 2007, IEEE T VIS COMPUT GR, V13, P34, DOI 10.1109/TVCG.2007.19
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Lipman Y., 2007, S GEOM PROC, P117
   LIPMAN Y, 2005, P ACM SIGGRAPH 2005, P479
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Masuda H, 2007, COMPUT AIDED DESIGN, V39, P361, DOI 10.1016/j.cad.2007.02.010
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Pinkall U., 1993, Exp. Math., V2, P15, DOI 10.1080/10586458.1993.10504266
   Popa T, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P141
   Pottmann H, 2004, LECT NOTES COMPUT SC, V2034, P560
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Sheffer A, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P68
   SORKINE O, 2007, SGP 07, P109
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Taubin G, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P180, DOI 10.1109/PCCGA.2001.962871
   Toledo Sivan., 2003, Taucs: A library of sparse linear solvers
   Wardetzky M., 2007, P EUROGRAPHICS S GEO, P33, DOI [DOI 10.2312/SGP/SGP07/033-037, 10.2312/SGP/SGP07/033-037]
   WU HY, 2006, CGIV 06 P INT C COMP, P156
   Yan HB, 2008, IEEE T VIS COMPUT GR, V14, P693, DOI 10.1109/TVCG.2008.28
   Yang WW, 2008, VISUAL COMPUT, V24, P495, DOI 10.1007/s00371-008-0230-3
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zayer R, 2005, COMPUT GRAPH FORUM, V24, P601, DOI 10.1111/j.1467-8659.2005.00885.x
   Zhang HX, 2008, VISUAL COMPUT, V24, P85, DOI [10.1007/s00371-007-0187-7, 10.1007/S00371-007-0187-7]
   Zorin D., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P259, DOI 10.1145/258734.258863
NR 42
TC 1
Z9 1
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2011
VL 22
IS 1
BP 15
EP 25
DI 10.1002/cav.381
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 727SD
UT WOS:000287820600003
DA 2024-07-18
ER

PT J
AU Tang, C
   Li, S
   Wang, GP
   Zang, YT
AF Tang, Chen
   Li, Sheng
   Wang, Guoping
   Zang, Yutong
TI Stable stylized wireframe rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE wireframe rendering; stylized rendering; adjacency; visibility; aliasing
AB Stylized wireframe rendering of 3D model is widely used in animation software in order to depict the configuration of deformable model in comprehensible ways. However, since some inherent flaws in traditional depth test based rendering technology, shape of lines cannot been preserved as continuous movement or deformation of models. There often exists severe aliasing like flickering artifact when objects rendered in line form animate, especially rendered with thick or dashed line. To cover this artifact, unlike traditional approach, we propose a novel fast line drawing method with high visual fidelity for wireframe depiction which only depends on intrinsic topology of primitives without any preprocessing step or extra adjacent information pre-stored. In contrast to previous widely used solutions, our method is advantageous in highly accurate visibility, clear and stable line appearance without flickering even for thick and dashed lines with uniform width, and steady configuration as model moves or animates, so that it is strongly suitable for animation system. In addition, our approach can be easily implemented and controlled without any additional preestimate parameters supplied by users. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Li, Sheng] Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing 100871, Peoples R China.
C3 Peking University
RP Li, S (corresponding author), Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing 100871, Peoples R China.
EM lisheng@pku.edu.cn
RI wang, guoping/KQU-3394-2024
CR Anjyo K, 2003, IEEE COMPUT GRAPH, V23, P54, DOI 10.1109/MCG.2003.1210865
   [Anonymous], 2006, ACM SIGGRAPH, DOI DOI 10.1145/1179849.1180035
   APPEL A, 1967, P 1967 22 NAT C ACM, P393
   COLE F, 2008, P 6 INT S NONPH AN R, P9, DOI DOI 10.1145/1377980.1377985
   Cole F., 2009, Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games, P115
   Cole F., 2006, EUROGRAPHICS S RENDE, P377
   DOMINE S, 2002, OPENGL MULTISAMPLE P
   HERTZMANN A, 1999, NONPH REND SIGGRAPH
   Isenberg T, 2003, IEEE COMPUT GRAPH, V23, P28, DOI 10.1109/MCG.2003.1210862
   Kalnins RD, 2003, ACM T GRAPHIC, V22, P856, DOI 10.1145/882262.882355
   Kalnins RD, 2002, ACM T GRAPHIC, V21, P755, DOI 10.1145/566570.566648
   Lake A., 2000, Proceedings of the 1st International Symposium on Non-Photorealistic Animation and Rendering New York, NY, USA,, P13
   Markosian L., 1997, ANN C SERIES, P415
   Northrup J. D., 2000, Proceedings of the 1st International Symposium on Non-photorealistic Animation and Rendering, P31, DOI DOI 10.1145/340916.340920
   PEREZ LJ, 1997, COMPUT GRAPH-UK, V21, P359
   Raskar R., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P135, DOI 10.1145/300523.300539
   ROSSIGNAC J, 1992, P 7 WORKSH COMP GRAP
   RUSTAGI P, 1989, SILHOUETTE LINE DISP, P42
   Saito T., 1990, Computer Graphics, V24, P197, DOI 10.1145/97880.97901
   SANDER PV, 2008, ACM SIGGRAPH AS 2008, P144
NR 20
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 411
EP 421
DI 10.1002/cav.370
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400027
DA 2024-07-18
ER

PT J
AU Vása, L
   Skala, V
AF Vasa, Libor
   Skala, Vaclav
TI Combined compression and simplification of dynamic 3D meshes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dynamic mesh; compression; simplification; animation; PCA; prediction
AB We present a new approach to dynamic mesh compression, which combines compression with simplification to achieve improved compression results, a natural support for incremental transmission and level of detail. The algorithm allows fast progressive transmission of dynamic 3D content. Our scheme exploits both temporal and spatial coherency of the input data, and is especially efficient for the case of highly detailed dynamic meshes. The algorithm can be seen as an ultimate extension of the clustering and local coordinate frame (LCF)-based approaches, where each vertex is expressed within its own specific coordinate system. The presented results show that we have achieved better compression efficiency compared to the state of the art methods. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Vasa, Libor] Univ W Bohemia, Dept Comp Sci & Engn, Fac Sci Appl, Plzen, Czech Republic.
C3 University of West Bohemia Pilsen
RP Vása, L (corresponding author), Univ W Bohemia, Dept Comp Sci & Engn, Fac Sci Appl, Plzen, Czech Republic.
EM lvasa@kiv.zcu.cz
RI Skala, Vaclav/F-9141-2011; Vasa, Libor/F-6706-2011
OI Skala, Vaclav/0000-0001-8886-4281; Vasa, Libor/0000-0002-0213-3769
FU EU [511568]; Ministry of Education, Youth and Sports of the Czech
   Republic [LC-06008]
FX This work has been supported by EU within FP6 under Grant 511568 with
   the acronym 3DTV and by the Ministry of Education, Youth and Sports of
   the Czech Republic under the research program LC-06008 (Center for
   Computer Graphics). The chicken character was created by Andrew
   Glassner, Tom McClure, Scott Benza, and Mark Van Langeveld. This short
   sequence of connectivity and vertex position data is distributed solely
   for the purpose of comparison of geometry compression techniques.
CR Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   Amjoun R, 2007, JOURNAL WSCG, V15, P99
   [Anonymous], P VIS MOD VIS WORKSH
   Briceno H. M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P136
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   GARLAND M, 1998, QUADRIC BASED POLYGO
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Ibarria L., 2003, Dans SCA '03, P126
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Kavan L, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P39
   KIRCHER S, 2005, SCA 05, P191
   LENGYEL JE, 1999, SI3D 99, P89, DOI DOI 10.1145/300523.300533
   Mamou K, 2006, COMPUT ANIMAT VIRT W, V17, P337, DOI 10.1002/cav.137
   MEISTERS GH, 1975, AM MATH MONTHLY  JUN, P8548
   MOHR A., 2003, Deformation sensitive deformation
   Müller K, 2006, SIGNAL PROCESS-IMAGE, V21, P812, DOI 10.1016/j.image.2006.07.002
   MULLER K, 2005, ICIP05, P621
   PAYAN F, 2005, P IEEE ACIDCA ICMI 2
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Sand P, 2003, ACM T GRAPHIC, V22, P578, DOI 10.1145/882262.882310
   Sattler Mirko, 2005, P ACM SIGGRAPH EUR S, P209
   STEFANOSKI N, 2006, P ICIP 06 IEEE INT C
   STEFANOSKI N, 2007, 3DTV CON TRUE VISION
   Vasa L, 2007, 3DTV CONF, P49, DOI 10.1109/3DTV.2007.4379408
   Vasa L, 2006, LECT NOTES COMPUT SC, V4069, P29
   Zhang JH, 2004, IEEE DATA COMPR CONF, P508
NR 26
TC 11
Z9 11
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL-AUG
PY 2009
VL 20
IS 4
BP 447
EP 456
DI 10.1002/cav.227
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 488QG
UT WOS:000269364200002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Gissler, M
   Schmedding, R
   Teschner, M
AF Gissler, Marc
   Schmedding, Ruediger
   Teschner, Matthias
TI Time-critical collision handling for deformable modeling
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE time-critical collision detection; time-critical collision response;
   deformable modeling
ID ANIMATION
AB Collision handling is a comparatively time-consuming task in dynamic simulations and the computational efficiency of collision handling techniques call vary significantly dependent oil the spatial configuration of the environment. These issues have to be addressed in interactive simulations such as games or surgical simulators, Where a pre-defined response time should be guaranteed for each simulation step. We present a time-critical collision handling approach for deformable objects. The technique employs spatial subdivision for the detection of collisions and penetration depth information is computed to estimate penalty forces. Detection, penetration depth estimation, and response are divided into atomic tasks, In case of an interruption, the algorithm basically resumes ill the next time step. If collisions are not completely handled in one simulation step, the algorithm ensures that persistent collisions are handled in a subsequent simulation step. If all exact response cannot be computed in a given time frame, the algorithm efficiently approximates penalty forces for colliding points. Experiments indicate that the proposed technique provides a physically plausible collision handling in the case of incomplete or inconsistent collision information. User-defined limits for the computation time can be guaranteed With all efficiency gain of up to factor three. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Gissler, Marc] Univ Freiburg, Dept Comp Sci, Comp Graph Grp, D-79110 Freiburg, Germany.
   [Teschner, Matthias] Stanford Univ, Stanford, CA 94305 USA.
   [Teschner, Matthias] Swiss Fed Inst Technol, Zurich, Switzerland.
C3 University of Freiburg; Stanford University; Swiss Federal Institutes of
   Technology Domain; ETH Zurich
RP Gissler, M (corresponding author), Univ Freiburg, Dept Comp Sci, Comp Graph Grp, Georges Koehler Allee 052, D-79110 Freiburg, Germany.
EM gisslerm@informatik.uni-freiburg.de
OI Gissler, Mika/0000-0001-8254-7525
CR Cameron S, 1997, IEEE INT CONF ROBOT, P3112, DOI 10.1109/ROBOT.1997.606761
   CLEMENT J, 1982, AM J PHYS, V50, P66, DOI 10.1119/1.12989
   Coming DS, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P241
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   Dequidt B, 2005, COMPUT ANIMAT VIRT W, V16, P177, DOI 10.1002/cav.110
   DINGLIANA J, 2000, P EUR 2000, P239
   FARES C, 2005, GRAPHICON 2005
   GRINSPUN E, 2002, SIGGRAPH 2002 C P AN, P281
   Hauser KK, 2003, PROC GRAPH INTERF, P247
   Heidelberger B., 2004, P VISION MODELING VI, P339
   Hubbard P. M., 1993, Proceedings IEEE 1993 Symposium on Research Frontiers in Virtual Reality (Cat. No.93TH0585-0), P24, DOI 10.1109/VRAIS.1993.378267
   Hubbard PM, 1996, ACM T GRAPHIC, V15, P179, DOI 10.1145/231731.231732
   KLEIN J, 2003, P 8 INT FALL WORKSH, P37
   KLEIN J, 2003, VRST 03, P22
   Klingner BM, 2006, ACM T GRAPHIC, V25, P820, DOI 10.1145/1141911.1141961
   LARSSON T, 2001, EUROGRAPHICS, P325
   Lin MingC., 2004, HDB DISCRETE COMPUTA
   Müller M, 2004, PROC GRAPH INTERF, P239
   O'Sullivan C, 2001, ACM T GRAPHIC, V20, P151, DOI 10.1145/501786.501788
   O'Sullivan C., 1999, PROC SPRING C COMPUT, P83
   OSULLIVAN C, 2005, P C COMP AN SOC AG P, P1
   OSULLIVAN C, 2003, SIGGRAPH 03, P527
   Spillmann J, 2007, JOURNAL WSCG, V15, P33
   Staadt OG, 1998, VISUALIZATION '98, PROCEEDINGS, P397, DOI 10.1109/VISUAL.1998.745329
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47
   VANDAM A, 1993, IEEE S RES FRONT VIR, P5
NR 27
TC 2
Z9 3
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 355
EP 364
DI 10.1002/cav.298
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700028
DA 2024-07-18
ER

PT J
AU Moss, W
   Lin, MC
   Manocha, D
AF Moss, William
   Lin, Ming C.
   Manocha, Dinesh
TI Constraint-based motion synthesis for deformable models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE goal-directed motion; finite element
AB We present a fast goal-directed motion synthesis technique that integrates sample-based planning methods with constraint-based dynamics simulation using a finite element formulation to generate collision free paths for deformable models. Our method allows the user to quickly specify various constraints, including a desired trajectory as a sparse sequence of waypoints, and it automatically computes a physically plausible path that satisfies geometric and physical constraints. We demonstrate the performance of our algorithm by computing animated realistic motion of deformable characters and simulation of a medical procedure. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Moss, William] Univ N Carolina, Dept Comp Sci, GAMMA Grp, Chapel Hill, NC 27599 USA.
   [Moss, William] Software Co, New York, NY USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Moss, W (corresponding author), Univ N Carolina, Dept Comp Sci, GAMMA Grp, Campus Box 3175,Sitterson Hall, Chapel Hill, NC 27599 USA.
EM wmoss@cs.unc.edu
OI Manocha, Dinesh/0000-0001-7047-9801
CR Anshelevich E., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2290, DOI 10.1109/ROBOT.2000.846368
   *AUT CREAT INC MAT, MATW MAT PROP DAT
   Burchan O. Bayazit, 2002, IEEE INT C ROB AUT I
   CERVERAI M, 1989, J PHYS MED BIOL, V34, P177
   Galoppo N, 2007, COMPUT GRAPH FORUM, V26, P243, DOI 10.1111/j.1467-8659.2007.01046.x
   GAYLE R, 2005, IEEE C ROB AUT
   GAYLE R, 2005, P ROB SCI SYST
   Gibson S.F. F., 1997, SURVEY DEFORMABLE MO
   Guibas L. J., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P254, DOI 10.1109/IROS.1999.813013
   HOLLEMAN C, 1998, IEEE INT C ROB AUT I
   KIM K, 2004, IEEE ULTR S
   Lamiraux F, 2001, INT J ROBOT RES, V20, P188, DOI 10.1177/02783640122067354
   LaValle S. M., 2006, Planning algorithms
   Moller T., 1997, J. Graph. Tools, V2, P25, DOI [DOI 10.1080/10867651.1997.10487472, 10.1080/10867651.1997.10487472]
   Müller M, 2004, PROC GRAPH INTERF, P239
   Nealen Andrew., 2005, EUROGRAPHICS STAR
   Popovic J, 2000, COMP GRAPH, P209, DOI 10.1145/344779.344880
   REDON S, 2005, P IEEE ICRA
   Rodriguez S., 2006, P IEEE INT C ROB AUT
   SEGARS WP, 2001, THESIS U N CAROLINA
   SHEWCHUK JR, 1998, P 14 ANN S COMP GEOM
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   TWIGG C, 2007, ACM T GRAPHICS
   VANDENBERGEN C, 1997, J GRAPHICS TOOLS, V2, P1
   Witkin A., 1990, Computer Graphics, V24, P243
   Wojtan C., 2006, P 2006 ACM SIGGRAPHE, P15
NR 26
TC 5
Z9 8
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 421
EP 431
DI 10.1002/cav.246
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200024
DA 2024-07-18
ER

PT J
AU Courty, N
   Corpetti, T
AF Courty, N.
   Corpetti, T.
TI Crowd motion capture
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE crowd simulation; motion estimation; vision for computer animation
ID DENSE ESTIMATION; OPTICAL-FLOW; SIMULATION; MODEL
AB In this paper a new and original technique to animate a crowd of human beings is presented. Following the success of data-driven animation models (such as motion capture) in the context Of articulated figures control, we propose to derivate a similar type of approach for crowd motions. In our framework, the motion of the crowds are represented as a time series Of velocity fields estimated from a video of a real crowd. This time series is used as an input of a simple animation model that 'advect' people along this time-varying flow. We demonstrate the power of our technique on both synthetic and real examples of crowd videos. We also introduce the notions of crowd motion editing and present possible extensions to our work. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 UBS, Bat Yves Coppen, F-56017 Vannes, France.
RP Courty, N (corresponding author), UBS, Bat Yves Coppen, BP 573, F-56017 Vannes, France.
EM Nicolas.Courty@univ-ubs.fr
OI Corpetti, Thomas/0000-0002-0257-138X
CR Andrade EL, 2006, INT C PATT RECOG, P175
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bhat KS, 2004, ACM T GRAPHIC, V23, P360, DOI 10.1145/1015706.1015729
   BLACK M, 1994, P EUR C COMP VIS STO, P138
   Blue VJ, 2001, TRANSPORT RES B-METH, V35, P293, DOI 10.1016/S0191-2615(99)00052-1
   Bouvier E, 1997, J ELECTRON IMAGING, V6, P94, DOI 10.1117/12.261175
   BRAUN A, 2003, P COMP AN SOC AG CAS
   Brogan DC, 2003, COMP ANIM CONF PROC, P94, DOI 10.1109/CASA.2003.1199309
   CHAI J, 2003, EUR ACM SIGGRAPH S C, P79
   Chenney Stephen., 2004, Proceedings of the 2004 ACM SIGGRAPH/Euro- graphics symposium on Computer animation, P233, DOI [10.1145/1028523.1028553, DOI 10.1145/1028523.1028553.]
   Corpetti T, 2002, IEEE T PATTERN ANAL, V24, P365, DOI 10.1109/34.990137
   Courty N, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P206
   Crisan D, 2001, STAT ENG IN, P17
   DIENER J, 2006, EUR ACM SIGGRAPH S C
   FAVREAU L, 2004, EUR ACM SIGGRAPH S C
   GIBSON D, 2005, EUR ACM SIGGRAPH S C, P39
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huber Peter J, 2011, ROBUST STAT, P1248
   Hughes RL, 2003, ANNU REV FLUID MECH, V35, P169, DOI 10.1146/annurev.fluid.35.101101.161136
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Memin E, 1998, IEEE T IMAGE PROCESS, V7, P703, DOI 10.1109/83.668027
   Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Sakuma T, 2005, COMPUT ANIMAT VIRT W, V16, P343, DOI 10.1002/cav.105
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Somasundaram A, 2003, COMP ANIM CONF PROC, P137, DOI 10.1109/CASA.2003.1199315
   Sung M, 2004, COMPUT GRAPH FORUM, V23, P519, DOI 10.1111/j.1467-8659.2004.00783.x
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   YANG T, 2005, P C COMP VIS PATT RE, P406
   Zhao T, 2004, PROC CVPR IEEE, P406
NR 33
TC 38
Z9 45
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 361
EP 370
DI 10.1002/cav.199
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000015
DA 2024-07-18
ER

PT J
AU Li, Y
   Yu, JH
   Ma, KH
   Shi, JY
AF Li, Yan
   Yu, Jinhui
   Ma, Kwan-Hu
   Shi, Jiaoying
TI 3D paper-cut modeling and animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE paper-cut; pattern; modeling; animation
AB Paper-cut is one of the most characteristic Chinese folk arts, often used during festivals and celebrations. Chinese artists have used paper-cut to make animations. Typical paper-cut artwork is made with 2D illustrations on paper, and making many frames necessary for an entire animation can be tedious and expensive. We present a system that allows a designer to directly annotate a 3D model with paper-cut patterns, while still allowing for adding an artistic touch to the design. We have designed special motifs coupled with templates, resulting in a parameterized set of decorative paper-cut patterns which give the artist flexible control and allow editing of the pattern size, orientation, and shape. The artist chooses a pattern and places the pattern on the model in the desired position. The system determines actual surface coverage and trims the object's surface geometry to simulate the cut-out effect we observe in traditional 2D paper-cut art. We demonstrate that our system allows faster and easier addition of paper-cut decoration to 3D models compared to general purpose modeling tools, such as Maya. Animations made with the 3D paper-cut models escape from the limitations of traditional 2D paper-cut animation on the movement in perspective, furthermore, our system allows for easy pattern animations on 3D models, which is very powerful but hard to do with traditional paper-cut animation. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Li, Y (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
EM yli@cad.zju.edu.cn
CR [Anonymous], 1996, P 23 ANN C COMP GRAP
   BAXTER B, 2001, P SIGGRAPH 01, P433
   Bruyns CD, 2001, COMPUT GRAPH-UK, V25, P635, DOI 10.1016/S0097-8493(01)00092-9
   Chu NSH, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P413, DOI 10.1109/PCCGA.2002.1167885
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Curtis C. J., 1997, Proceedings of the 24th annual conference on Computer graphics and interactive techniques, P421
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Kalnins R., 2002, P 29 ANN C COMPUTER, P755, DOI DOI 10.1145/566570.566648
   Kaplan CS, 2004, ACM T GRAPHIC, V23, P97, DOI 10.1145/990002.990003
   KLEIN AW, 1999, P SIGGRAPH99, P527
   Kowalski MA, 1999, COMP GRAPH, P433, DOI 10.1145/311535.311607
   Lee Y, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P279
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Li WC, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P62, DOI 10.1109/SMI.2005.29
   LIU YX, 2005, SIGGRAPH SKETCH
   MARKOSIAN L, 1997, P SIGGRAPH 97, P415
   Mitani J, 2004, ACM T GRAPHIC, V23, P259, DOI 10.1145/1015706.1015711
   Mortara M, 2004, ALGORITHMICA, V38, P227, DOI 10.1007/s00453-003-1051-4
   OLSEN L, 2005, EUR WORKSH SKETCHB I, P43
   Saito T., 1990, Computer Graphics, V24, P197, DOI 10.1145/97880.97901
   SANDER PV, 2003, P EUR ACM SIGGRAPH S, P146
   Sousa MC, 1999, COMPUT GRAPH FORUM, V18, pC195, DOI 10.1111/1467-8659.00340
   WAY DL, 2001, P EUR 01, V20, P123
   WINKENBACH G, 1997, P SIGGRAPH 97 LOS AN, P91
   WINKENBACH G, 1994, P SIGGRAPH 94 JUL, P469
   Yamauchi H, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P236, DOI 10.1109/SMI.2005.21
NR 28
TC 19
Z9 25
U1 8
U2 42
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 395
EP 403
DI 10.1002/cav.188
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000018
DA 2024-07-18
ER

PT J
AU Chen, H
   Sun, HQ
   Jin, XG
AF Chen, Hui
   Sun, Hanqiu
   Jin, Xiaogang
TI Interactive soft-touch dynamic deformations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Virtual Reality Continuum and Its
   Applications (VRCIA)
CY 2006
CL Hong Kong, PEOPLES R CHINA
SP ACM SIGGRAPH, Eurgograph Assoc, Chinese Soc Image & Graph, INI GraphicsNet
DE haptics interface; interactive modelling; free-form deformation
ID HAPTICS
AB It is crucial for the users to touch, grasp and manipulate the interested objects through our sense of touch in many interactive applications, such as on-line computer games, interactive cartoon design, and virtual prototyping. In this paper, we propose an interactive haptic deformation approach which incorporates the dynamic simulation of mass-spring systems and flexible control of free-form deformation in the touch-enabled soft-object deformation. Through distributing mass, spring and damping coefficients of the object to the bounded Bezier volume lattice, the deformation of the object related to the haptic avatar follows the physical laws and has high working rate. Both homogenous and inhomogenous materials are simulated. The anchor nodes of haptic input are specified to create amazing special effects during the interactive haptic deformation. Interactive haptic deformations of three-type tropic fishes, Angel, Demekin, and GuppyBlueGrass, have been experimented to simulate vivid fish swimming processes in the virtual ocean scene. Our proposed approach provides touch-enabled input and efficient performance in the flexible deforming controls, letting the objects move in a dynamic, cartoon-style deforming manner. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Chinese Univ Hong Kong, Shenzhen Inst Adv Integrat Technol, Chinese Acad Sci, Shenzhen, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; The Chinese University of Hong Kong, Shenzhen
RP Chen, H (corresponding author), Chinese Univ Hong Kong, Shenzhen Inst Adv Integrat Technol, Chinese Acad Sci, Shenzhen, Peoples R China.
EM hui.chen@siat.ac.cn
CR AAMISEPP H, 2003, THESIS LUND I TECHNO
   [Anonymous], 1997, TR9719 MITS EL RES L
   [Anonymous], 2001, P 2001 S INT 3D GRAP
   AVILA RS, 1999, SIGGRAPH
   AVILA RS, 1998, SIGGRAPH
   Basdogan C, 2001, STUD HEALTH TECHNOL, V81, P46
   Bathe K.J., 1996, Finite Element Procedures
   BENCHMANN D, 1998, P EUROGRAPHICS, P102
   Chen H, 2006, PRESENCE-VIRTUAL AUG, V15, P186, DOI 10.1162/pres.2006.15.2.186
   CHEN H, 2002, ACM VIRTUAL REALITY, P81
   Dachille F, 2001, COMPUT AIDED DESIGN, V33, P403, DOI 10.1016/S0010-4485(00)00131-7
   DACHILLE F, 1999, ACM S INT 3D GRAPH, P103
   EDWARDS J, 1996, JAPAN US S FLEX AUT, P221
   Faloutsos P, 1997, IEEE T VIS COMPUT GR, V3, P201, DOI 10.1109/2945.620488
   Gregory A, 2000, IEEE VISUAL, P139, DOI 10.1109/VISUAL.2000.885687
   GRIESSMAIR J, 1998, P EUROGRAPHICS, P137
   HECKER C, 1996, GAME DEVELOPERS MANA
   HIGASHI M, 2002, J COMPUTING INFORM S, V2, P265
   HUANG J, 2006, ACM SIGGRAPH, P1226
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   KARLA P, 1992, COMPUT GRAPH FORUM, V2, P59
   Kim YJ, 2003, PRESENCE-VIRTUAL AUG, V12, P277, DOI 10.1162/105474603765879530
   LAMOUSIN HJ, 1994, IEEE COMPUT GRAPH, V14, P59, DOI 10.1109/38.329096
   LANDER J, 2000, GAME DEVELOPER MAGAZ, P17
   Landers J. L., 1999, General Technical Report - Southern Research Station, USDA Forest Service
   Mark W.R., 1996, Proceedings of SIGGRAPH on Computer Graphics, P447, DOI DOI 10.1145/237170.237284
   McNeely WA, 1999, COMP GRAPH, P401, DOI 10.1145/311535.311600
   Ruspini D. C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P345, DOI 10.1145/258734.258878
   SEDERBERG TW, 1986, ACM COMPUTER GRAPHIC, V20, P537
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   SUN H, 2006, J VIRTUAL REALITY RE
   Waters K., 1991, Journal of Visualization and Computer Animation, V2, P123, DOI 10.1002/vis.4340020405
   ZILLES CB, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P146, DOI 10.1109/IROS.1995.525876
NR 33
TC 1
Z9 3
U1 2
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2007
VL 18
IS 3
BP 153
EP 163
DI 10.1002/cav.171
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 185HG
UT WOS:000247701400002
DA 2024-07-18
ER

PT J
AU Tang, B
   Pan, ZG
   Zheng, L
   Zhang, MM
AF Tang, Bing
   Pan, Zhigeng
   Zheng, Le
   Zhang, Mingmin
TI Interactive generation of falling motions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE character motion; physical simulation; animation; motion capture
ID LIMB
AB Interactive generation of falling motions for virtual character with realistic responses to unexpected push, hit or Collision With tire environment is interesting work to many applications, such as computer games, film production, and virtual training environments. In this paper, we propose a new method to simulate protective behaviors in response to tire ways a human may fall to the ground as Well as incorporate tire reactive motions into motion capture animation. It is based on simulated trajectory prediction and biomechanics inspired adjustment. According to the external perturbations, our system predicts a motion trajectory and uses it to select a desired transition-to sequence. At tire same time, physically generated falling motions will fill ill the gap between tire two-motion capture sequences before and after the transition. Utilizing a parallel simulation, our method is able to predict a character's motion trajectory real-time under dynamics, Which ensures that the character moves towards the target sequence and makes the character's behavior, more life-like. Our controller is designed to generate physically plausible motion-following all upcoming motion with adjustment from biomechanics rules, Which is key to avoid air unconscious look for a character during the transition. Based on a relatively small motion database, our system is effective in generating various interactive falling behaviors. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Tang, B (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM btang@cad.zju.edu.cn
RI Zhang, Miao/JXY-8985-2024; zhang, mm/IWV-4201-2023
CR Arikan Okan., 2005, SCA 2005: Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P59
   FALOUTSOS P, P ACM SIGGRAPH 2001, P251
   HODGINS JK, 1995, P ACM SIGGRAPH, V29, P71
   Komura T, 2005, COMPUT ANIMAT VIRT W, V16, P213, DOI 10.1002/cav.101
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Maki BE, 1997, PHYS THER, V77, P488, DOI 10.1093/ptj/77.5.488
   MANDEL M, 2004, THESIS CARNEGIE MELL
   Marigold DS, 2003, J NEUROPHYSIOL, V89, P1727, DOI 10.1152/jn.00683.2002
   Marigold DS, 2002, J NEUROPHYSIOL, V88, P339, DOI 10.1152/jn.00691.2001
   MOUNT D, 1993, SODA ACM SIAM S DISC
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Shapiro A, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P455, DOI 10.1109/PCCGA.2003.1238294
   SHIIN H, 2003, P 11 PAC C COMP GRAP, P194
   Shin HJ, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P194
   WOOTEN W, 1998, THESIS GEORGIA I TEC
   YIN KK, 2005, P PAC GRAPH 2005
   Zordan V. B., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P89
   Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249
NR 18
TC 8
Z9 11
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 271
EP 279
DI 10.1002/cav.131
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400014
DA 2024-07-18
ER

PT J
AU Yan, HB
   Hu, SM
   Martin, R
AF Yan, HB
   Hu, SM
   Martin, R
TI Morphing based on strain field interpolation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE morphing; strain field; finite element method; isomorphic mesh
AB Strain fields provide a method of deformation measurement based on physics. Using these as a tool, we can analyze deformation of objects in a measurable way. We have developed a new morphing technique based on strain field interpolation. Shape shaking and squeezing, which often happen when using linear interpolation for morphing, do not arise in our approach. We have also developed a new method to create isomorphic meshes from corresponding objects in two images. Meshes generated by this method have much fewer triangles than other methods, which greatly decreases calculation loads in the morphing process. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Cardiff Univ, Sch Comp Sci, Cardiff, S Glam, Wales.
C3 Cardiff University
RP Cardiff Univ, Sch Comp Sci, Cardiff, S Glam, Wales.
EM ralph@cs.cf.ac.uk
RI Martin, Ralph R/D-2366-2010
OI Martin, Ralph/0000-0002-8495-8536
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   ARONOV B, 1993, COMP GEOM-THEOR APPL, V3, P27, DOI 10.1016/0925-7721(93)90028-5
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Belytschko T., 2000, Nonlinear Finite Elements for Continua and Structures, DOI 10.1055/s-2006-943830
   DeCarlo D, 1998, IEEE T PATTERN ANAL, V20, P1186, DOI 10.1109/34.730554
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   HU SM, 2004, ACM S SOL MOD APPL 2
   Lee S, 1996, IEEE T VIS COMPUT GR, V2, P337, DOI 10.1109/2945.556502
   LEE SY, 1994, P COMPUTER ANIMATION, P31
   Liang YD, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P448, DOI 10.1109/PCCGA.2002.1167896
   Ortega J. M., 1970, ITERATIVE SOLUTION N, DOI [10.1137/1.9780898719468, DOI 10.1137/1.9780898719468]
   Praun E, 2001, COMP GRAPH, P179, DOI 10.1145/383259.383277
   Sederberg T. W., 1993, Computer Graphics Proceedings, P15, DOI 10.1145/166117.166118
   SEDERBERG TW, 1992, COMP GRAPH, V26, P25, DOI 10.1145/142920.134001
   SHAPIRA M, 1995, IEEE COMPUT GRAPH, V15, P44, DOI 10.1109/38.365005
   SHOEMAKE K, 1992, GRAPH INTER, P258
   WILHELM F, 1972, TENSOR ANAL CONTINUU
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Zhang YF, 1996, IEEE COMPUT GRAPH, V16, P34, DOI 10.1109/38.511850
   Zienkiewicz OC, 2005, FINITE ELEMENT METHOD FOR FLUID DYNAMICS, 6TH EDITION, P1
NR 20
TC 14
Z9 15
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 443
EP 452
DI 10.1002/cav.48
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700035
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kim, DM
   Ahn, J
   Kim, SW
   Lee, J
   Kim, M
   Han, J
AF Kim, Dong-Min
   Ahn, JeongHyeon
   Kim, Seung-wook
   Lee, Jongmin
   Kim, Myungho
   Han, JungHyun
TI Real-time reconstruction of pipes using RGB-D cameras
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D reconstruction; pipe; RGB-D
AB This paper presents a novel method that automatically reconstructs pipes in real time using an RGB-D camera. The input image is decomposed into superpixels, and a pipe element, which is a 3D circle lying on the pipe surface, is generated for each superpixel. Over frames, the pipe elements are grouped into sequences and are finally modeled in parametric equations. The method is tested in daily settings, where the pipes may be curved and their radii may vary along the axes. The test results show that the method is able to reconstruct pipes efficiently, precisely and robustly.
C1 [Kim, Dong-Min; Ahn, JeongHyeon; Kim, Seung-wook; Lee, Jongmin; Han, JungHyun] Korea Univ, Comp Sci Dept, Seoul, South Korea.
   [Kim, Myungho] Iaan Co Ltd, ICT Business Div, Seoul, South Korea.
C3 Korea University
RP Han, J (corresponding author), Korea Univ, Comp Sci Dept, Seoul, South Korea.
EM jhan@korea.ac.kr
RI Kim, Dong-Min/M-2495-2019
OI Kim, Dong-Min/0000-0003-0216-4036; Kim, Seung-wook/0000-0003-4178-772X
FU Ministry of Science and ICT, South Korea [IITP-2023-2020-0-01819];
   Information Technology Research Center [IITP-2023-2020-0-01460,
   2020-0-00861]
FX Ministry of Science and ICT, South Korea, Grant/Award
   Number:IITP-2023-2020-0-01819; Information Technology Research Center,
   Grant/Award Numbers:IITP-2023-2020-0-01460, 2020-0-00861
CR Araújo AMC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107161
   Bolelli F, 2020, IEEE T IMAGE PROCESS, V29, P1999, DOI 10.1109/TIP.2019.2946979
   Cheng LL, 2020, GRAPH MODELS, V111, DOI 10.1016/j.gmod.2020.101079
   Huttenlocher, 2012, THEORY COMPUT, V8, P415, DOI [10.4086/toc.2012.v008a019, DOI 10.4086/TOC.2012.V008A019]
   Kim Y, 2020, AUTOMAT CONSTR, V116, DOI 10.1016/j.autcon.2020.103236
   Kirillov A., 2023, Segment anything
   Liu YJ, 2013, IEEE T VIS COMPUT GR, V19, P1700, DOI 10.1109/TVCG.2013.74
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Oh I, 2021, VISUAL COMPUT, V37, P1385, DOI 10.1007/s00371-020-01872-y
   Patil AK, 2017, AUTOMAT CONSTR, V75, P65, DOI 10.1016/j.autcon.2016.12.002
   POWELL MJD, 1993, MATH APPL, V275, P51
   Ren C. Y, 2011, Technical Report
   Son H, 2016, AUTOMAT CONSTR, V68, P203, DOI 10.1016/j.autcon.2016.05.010
   Zhang J., 2021, IEEE Trans. Instrum. Meas., V1, P1
NR 14
TC 0
Z9 0
U1 4
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2197
EA JUL 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001040084000001
DA 2024-07-18
ER

PT J
AU Qi, D
   De, SVN
AF Qi, Di
   De, Suvranu
TI Split and join: An efficient approach for simulating stapled intestinal
   anastomosis in virtual reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cutting simulation; intestine simulation; stapled intestinal
   anastomosis; virtual reality
AB Colorectal cancer is a life-threatening disease. It is the second leading cause of cancer-related deaths in the United States. Stapled anastomosis is a rapid treatment for colorectal cancer and other intestinal diseases and has become an integral part of routine surgical practice. However, to the best of our knowledge, there is no existing work simulating intestinal anastomosis that often involves sophisticated soft tissue manipulations such as cutting and stitching. In this paper, for the first time, we propose a novel split and join approach to simulate a side-to-side stapled intestinal anastomosis in virtual reality. We mimic the intestine model using a new hybrid representation-a grid-linked particles model for physics simulation and a surface mesh for rendering. The proposed split and join operations handle the updates of both the grid-linked particles model and the surface mesh during the anastomosis procedure. The simulation results demonstrate the feasibility of the proposed approach in simulating intestine models and the side-to-side anastomosis operation.
C1 [Qi, Di] Chapman Univ, Dale E & Sara Ann Fowler Sch Engn, Orange, CA USA.
   [De, Suvranu] Florida A&M Univ, Florida State Univ, Coll Engn, Tallahassee, FL USA.
   [Qi, Di; De, Suvranu] Chapman Univ, Sch Engn, Orange, CA 92866 USA.
C3 Chapman University System; Chapman University; State University System
   of Florida; Florida A&M University; Florida State University; Chapman
   University System; Chapman University
RP Qi, D; De, SVN (corresponding author), Chapman Univ, Sch Engn, Orange, CA 92866 USA.
EM dqi@chapman.edu
RI Qi, Di/AAR-4974-2020
OI Qi, Di/0000-0002-0467-6628
FU National Institute of Biomedical Imaging and Bioengineering (NIBIB) of
   the National Institutes of Health [R01EB005807]
FX ACKNOWLEDGMENTS The authors would like to thank Dr. Rahul-Senior
   Research Scientist at Rensselaer Polytechnic Institute, for providing
   insightful comments on the manuscript. Research reported in this article
   was supported by the National Institute of Biomedical Imaging and
   Bioengineering (NIBIB) of the National Institutes of Health under Award
   Number R01EB005807. The content is solely the responsibility of the
   authors and does not necessarily represent the official views of the
   National Institutes of Health.
CR [Anonymous], 2022, LAP MENT
   [Anonymous], 2022, LAPSIM
   Bro-Nielsen M, 1998, P IEEE, V86, P490, DOI 10.1109/5.662874
   Camara M, 2016, INT J COMPUT ASS RAD, V11, P919, DOI 10.1007/s11548-016-1373-8
   Chang J, 2007, COMPUT ANIMAT VIRT W, V18, P429, DOI 10.1002/cav.197
   Chang JA, 2011, VISUAL COMPUT, V27, P97, DOI 10.1007/s00371-010-0533-z
   Cotin S, 1999, IEEE T VIS COMPUT GR, V5, P62, DOI 10.1109/2945.764872
   Feng J-S., 2018, MEDICINE
   France L, 2005, MED IMAGE ANAL, V9, P123, DOI 10.1016/j.media.2004.11.006
   Goulder F., 2012, WORLD J GASTRO SURG
   I. 3D Systems, 2014, GEOM TOUCH HAPT DEV
   Jayasudha K., 2020, INT J INTELL SUSTAIN
   Koschier D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073666
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Pan JJ, 2015, INT J MED ROBOT COMP, V11, P194, DOI 10.1002/rcs.1582
   Qi D, 2017, J BIOMED INFORM, V75, P48, DOI 10.1016/j.jbi.2017.09.010
   Shewchuk J.R., 2002, WHAT IS GOOD LINEAR
   U.S. Department of Health and Human Services  Center for Disease Control and Prevention and National Cancer Institute, 2022, US CANC STAT
   United Nations, 2022, About us
   Xu L, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.171587
NR 21
TC 0
Z9 0
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2023
VL 34
IS 6
DI 10.1002/cav.2151
EA FEB 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HA0T4
UT WOS:000939788000001
PM 38283985
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Liang, H
   Dong, XH
   Pan, JJ
   Zheng, XY
AF Liang, Hui
   Dong, Xiaohang
   Pan, Junjun
   Zheng, Xiangyu
TI Virtual scene generation promotes shadow puppet art conservation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Chinese cultural protection; shadow puppet play; semantic-based scene
   generation; virtual scene generation
AB As an ancient performing art, shadow puppetry is a treasure of Chinese art. However, with the development of society, shadow puppetry becomes less well-known among the young generation. To preserve and further spread this traditional culture, the digitization of shadow puppets is playing an increasingly important role in shadow puppetry conservation. Despite this, the spread of shadow puppetry culture in modern times still faces many hindrances. In digitalized shadow puppet art, the virtual scenes in certain degree determine the artistic effect of shadow puppet performance. The commonly used method for digital shadow puppet scene construction is via artificially created models which are then placed in corresponding positions. Obviously, this is a cumbersome and time-consuming task. Therefore, a semantic-based scene generation method for digital shadow puppet performance scene is proposed in this paper. According to this method, the key information is extracted from the descriptive text using the Chinese text segmentation technology. Meanwhile, we generate semantic scene graphs and search the corresponding shadow puppet models in the model library to construct the virtual scenes of digital shadow puppet performance. In the evaluation experiment, we invited 30 volunteers (10 female and 20 male) who had been exposed to traditional shadow puppet play in their daily lives. As suggested by the experimental results, the digital shadow puppet performance scene generated in this paper exhibit advantages of convenient use and high availability, which largely enhance the effect of digital shadow puppet performance. It should nonetheless be noted that it's not easy to extract the spatial relations from complicated texts, which inevitably limits the effectiveness of our scene generation method. The research work of this paper aims to promote digital shadow puppet technology and provide insights for the inheritance and conservation of traditional shadow puppet art.
C1 [Liang, Hui; Dong, Xiaohang; Zheng, Xiangyu] Zhengzhou Univ Light Ind, Sch Software, Zhengzhou, Peoples R China.
   [Pan, Junjun] Beihang Univ, Sch Comp Sci, Beijing, Peoples R China.
   [Liang, Hui] Zhengzhou Univ Light Ind, Zhengzhou, Peoples R China.
C3 Zhengzhou University of Light Industry; Beihang University; Zhengzhou
   University of Light Industry
RP Liang, H (corresponding author), Zhengzhou Univ Light Ind, Zhengzhou, Peoples R China.
EM hliang@zzuli.edu.cn
RI Pan, Junjun/A-1316-2013
OI Dong, Xiaohang/0000-0001-7969-3134
FU Scientific and Technological Project in Henan Province [222102210030];
   Jie Bang Gua Shuaie Science and Technology Project of Henan Province
   [211110110500]
FX Scientific and Technological Project in Henan Province, Grant/Award
   Number:222102210030; Jie Bang Gua Shuaie Science and Technology Project
   of Henan Province, Grant/Award Number:211110110500
CR Aijazi AK, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19245345
   Cai Y., 2021, REMOTE SENS-BASEL, V13
   Capasso-Ballesteros IF., 2020, REV FAC ING-UNIV ANT
   Chang A., 2014, P WORKSHOP INTERACTI, P14
   Cui CY, 2021, INT COMMUN CHIN CULT, V8, P483, DOI 10.1007/s40636-021-00237-x
   He MY, 2018, I COMP CONF WAVELET, P27, DOI 10.1109/ICCWAMTIP.2018.8632562
   Li T, 2021, MULTIMED TOOLS APPL, V80, P20403, DOI 10.1007/s11042-021-10726-1
   Liang H, 2018, VIRTUAL REAL-LONDON, V22, P149, DOI 10.1007/s10055-018-0333-8
   Liu Z., 2015, GRAPHICS INTERFACE
   Maipradit R, 2019, IEEE SOFTWARE, V36, P65, DOI 10.1109/MS.2019.2919573
   Meng H., 2019, INT C COMPUTATIONAL, P364
   Neves AB, 2021, PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS 2021), VOL 1, P126, DOI 10.5220/0010519401260137
   Sun J., 2019, 2019 IEEE 2 INT C CO
   Tahara T, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P249, DOI 10.1109/ISMAR-Adjunct51615.2020.00072
   Wald J., 2020, C COMPUTER VISION PA, DOI DOI 10.48550/ARXIV.2004.03967
   Watanabe Naok, 2020, Procedia Computer Science, V176, P1763, DOI 10.1016/j.procs.2020.09.215
   Xiao Q., 2019, IEEE INT CONF ELECTR
   Zeng M., 2020, INT C ROBOTS INTELLI
   Zhao LW, 2018, SPECTROSC SPECT ANAL, V38, P1420, DOI 10.3964/j.issn.1000-0593(2018)05-1420-10
   Zhu S., 2018, 19 WORKSH CLSW 2018, P559
NR 20
TC 0
Z9 0
U1 9
U2 38
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2148
EA FEB 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000935462400001
DA 2024-07-18
ER

PT J
AU Xu, T
   Wang, XH
   Lun, X
   Pan, H
   Wang, ZL
AF Xu, Tao
   Wang, Xinheng
   Lun, Xie
   Pan, Hang
   Wang, Zhiliang
TI ADReFV: Face video dataset based on human-computer interaction for
   Alzheimer's disease recognition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Alzheimer's disease; assisted assessment; attention mechanisms; facial
   video dataset; human-computer interaction
ID CLASSIFICATION; APRAXIA; PERFORMANCE; ATTENTION; DEFICITS; MEMORY
AB With the global aging problem becoming more and more serious, the initial screening for Alzheimer's disease (AD) will become increasingly important. We understand that facial expressions are related to the severity of dementia, but there is no face-related data in the existing Alzheimer's dataset. This article attempts to establish a facial video-based AD recognition dataset through a human-computer interaction method. This interactive task was designed for AD in attention, execution, visual space ability, facial apraxia, and facial changes in task success and failure. Using this task as the collection method, the final dataset includes 102 faces video data, specific task scores, and emotional self-evaluation. For baseline evaluation, the improved local binary pattern on three orthogonal planes and RF were employed respectively for feature extraction and classification with the 5-fold cross-validation method. The best performance was 76.00% for 3-class classification. In addition, a frame attention network based on fine-grained local region localization was proposed, which improved the accuracy of cognitive classification to 84.45%. Finally, the analysis was conducted for the association of expressions with cognition and emotion in the AD dataset. This study aims to solve the current lack of standards for AD in the field of facial recognition and contribute to future research and clinical applications.
C1 [Xu, Tao; Wang, Xinheng; Pan, Hang] Univ Sci & Technol, Beijing, Peoples R China.
   [Lun, Xie; Wang, Zhiliang] Univ Sci & Technol, Sch Comp & Commun Engn, Beijing, Peoples R China.
   [Lun, Xie] Univ Sci & Technol, Beijing, Peoples R China.
C3 University of Science & Technology Beijing; University of Science &
   Technology Beijing; University of Science & Technology Beijing
RP Lun, X (corresponding author), Univ Sci & Technol, Beijing, Peoples R China.
EM xielun@ustb.edu.cn
RI Pan, Hang/GVT-3336-2022; Wang, Xinheng (Henry)/AAQ-3959-2021
OI Pan, Hang/0000-0002-0522-018X; Wang, Xinheng (Henry)/0000-0001-8771-8901
FU National Key Research and Development Program of China [2022YFB4703000]
FX National Key Research and Development Program of China, Grant/Award
   Number:2022YFB4703000
CR Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   Alzheimer's Association, 2016, Alzheimers Dement, V12, P459
   Benini S, 2019, SIGNAL PROCESS-IMAGE, V74, P21, DOI 10.1016/j.image.2019.01.005
   Binnewijzend MAA, 2012, NEUROBIOL AGING, V33, P2018, DOI 10.1016/j.neurobiolaging.2011.07.003
   Brookmeyer R, 2007, ALZHEIMERS DEMENT, V3, P186, DOI 10.1016/j.jalz.2007.04.381
   Camus JF, 2003, PSYCHOL MED, V33, P169, DOI 10.1017/S003329170200689X
   Capone JG, 2003, BEHAV NEUROL, V14, P1
   Gerardin E, 2009, NEUROIMAGE, V47, P1476, DOI 10.1016/j.neuroimage.2009.05.036
   Hett K, 2018, COMPUT MED IMAG GRAP, V70, P8, DOI 10.1016/j.compmedimag.2018.08.002
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Johnen A, 2016, J ALZHEIMERS DIS, V49, P593, DOI 10.3233/JAD-150447
   Johnen A, 2015, J NEUROL NEUROSUR PS, V86, P809, DOI 10.1136/jnnp-2014-308773
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kokmen E, 1998, EUR J NEUROL, V5, P175, DOI 10.1046/j.1468-1331.1998.520175.x
   Kruthika, 2018, ADV SIGNAL PROCESSIN
   Lehmann C, 2007, J NEUROSCI METH, V161, P342, DOI 10.1016/j.jneumeth.2006.10.023
   Lesourd M, 2013, NEUROPSYCHOL REV, V23, P234, DOI 10.1007/s11065-013-9235-4
   Luz S., ALZHEIMERS DEMENT
   Mandal PK, 2012, J ALZHEIMERS DIS, V31, pS117, DOI 10.3233/JAD-2012-120901
   Maurer K, 2004, J NEURAL TRANSM, V111, P235, DOI 10.1007/s00702-003-0046-2
   Meng DB, 2019, IEEE IMAGE PROC, P3866, DOI [10.1109/ICIP.2019.8803603, 10.1109/icip.2019.8803603]
   Mograbi DC, 2012, NEUROPSYCHOLOGIA, V50, P2075, DOI 10.1016/j.neuropsychologia.2012.05.008
   Mograbi DC., 2014, TEMAS PSICOLOGIA, V22, P579
   Moulin CJA, 2004, J CLIN EXP NEUROPSYC, V26, P1, DOI 10.1076/jcen.26.1.1.23940
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Papagno C, 2000, J NEUROL NEUROSUR PS, V69, P694, DOI 10.1136/jnnp.69.5.694
   Perry RJ, 1999, BRAIN, V122, P383, DOI 10.1093/brain/122.3.383
   Perry RJ, 2000, NEUROPSYCHOLOGIA, V38, P252, DOI 10.1016/S0028-3932(99)00079-2
   Prince M, 2015, World Alzheimer Report 2015. The global impact of dementia. An analysis of prevalence, incidence, cost and trends
   Searle T., COMPARING NATURAL LA
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Spasov S, 2019, NEUROIMAGE, V189, P276, DOI 10.1016/j.neuroimage.2019.01.031
   Tang Y., DEEP LEARNING USING
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
NR 36
TC 1
Z9 1
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2023
VL 34
IS 1
SI SI
DI 10.1002/cav.2127
EA DEC 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Z2BA
UT WOS:000899644600001
DA 2024-07-18
ER

PT J
AU Ju, E
   Kim, KY
   Lee, J
   Yoon, S
   Choi, MG
AF Ju, Eunjung
   Kim, Kwang-yun
   Lee, Jaehoon
   Yoon, Sungjin
   Choi, Myung Geol
TI Interactive exploration of drapes by simulation parameters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cloth simulation; parameter tuning; user interface
AB How similar a virtual product is to a real product is one of the most important issues when using virtual simulation to develop real apparel designs. The first step to achieve high similarity is finding optimal simulation parameters for the desired fabrics. However, it is notoriously difficult to find an optimal parameter set that reproduces the physical properties of a specific fabric as closely as possible. It is because the relationship between the changes of simulation parameters and drape shapes is highly non-linear, not intuitive, and hard to be predicted even by experts. Therefore, users have to repeat trial and error based on personal experience until they find satisfactory results, which is time consuming due to the simulation time required for each trial. To handle this problem, we proposed a neural network model that learns the relationship between the parameter space and the drape space, then we presented a user interface that allows users to quickly explore the extensive drape space through simulation parameters. To validate our method, we provided our UI with experts in the fashion design industry and conducted user studies with them for qualitative evaluation.
C1 [Ju, Eunjung; Kim, Kwang-yun; Lee, Jaehoon; Yoon, Sungjin] CLO Virtual Fash Inc, Seoul, South Korea.
   [Choi, Myung Geol] Catholic Univ Korea, Seoul, South Korea.
C3 Catholic University of Korea
RP Choi, MG (corresponding author), Catholic Univ Korea, Seoul, South Korea.
EM mgchoi@catholic.ac.kr
FU Catholic University of Korea; Ministry of Science and ICT, South Korea
   [NRF-2021R1F1A1048002]
FX Catholic University of Korea, Grant/Award Number: 2020; Ministry of
   Science and ICT, South Korea, Grant/Award Number: NRF-2021R1F1A1048002
CR Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bhat Kiran S., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, P37
   Bi WY, 2018, J VISION, V18, DOI 10.1167/18.5.12
   Bouman KL, 2013, IEEE I CONF COMP VIS, P1984, DOI 10.1109/ICCV.2013.455
   Carrera-Gallissà E, 2017, J TEXT I, V108, P325, DOI 10.1080/00405000.2016.1166804
   CLO Virtual Fashion Inc, 2020, FABR KIT MAN
   CLO Virtual Fashion Inc, 2009, CLO
   Cusick GE, 1965, J Textile Inst Trans, V56, pT596
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Glombikova V, 2014, TEKST KONFEKSIYON, V24, P279
   Hussain A, 2020, AUTEX RES J, V20, P155, DOI 10.2478/aut-2019-0011
   Ju E, 2020, IEEE ACCESS, V8, P195113, DOI 10.1109/ACCESS.2020.3033765
   Kawabata S, 2005, WOODH PUBL TEXT, P389
   Kenkare N, 2008, J TEXT I, V99, P211, DOI 10.1080/00405000701489222
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Miguel E, 2012, COMPUT GRAPH FORUM, V31, P519, DOI 10.1111/j.1467-8659.2012.03031.x
   Pfaff T., 2021, P INT C LEARNING REP
   Sands KE, 2021, INFECT CONT HOSP EP, V42, P399, DOI 10.1017/ice.2020.461
   Yang S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3026479
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
NR 20
TC 3
Z9 3
U1 3
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2058
DI 10.1002/cav.2058
EA JUN 2022
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000810261800001
DA 2024-07-18
ER

PT J
AU Muni, MK
   Parhi, DR
   Kumar, PB
AF Muni, Manoj K.
   Parhi, Dayal R.
   Kumar, Priyadarshi Biplab
TI Implementation of grey wolf optimization controller for multiple
   humanoid navigation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE GWOC; NAO humanoid; navigation; petri-net model
ID MOBILE ROBOT NAVIGATION; FUZZY-LOGIC; CLUTTERED ENVIRONMENT; OBSTACLE
   AVOIDANCE; ALGORITHM
AB In this paper, grey wolf optimization controller (GWOC) is considered as a multiobjective technique for multiple humanoid navigations. Upon activation of GWOC, the humanoids mimic the group hunting behavior of grey wolves and navigate toward the target in a collision-free manner in presence of both static and dynamic hurdles. The wolves in the pack will either diverge for searching prey or converge together for attacking the prey following the best search agent (Leader Alpha). GWOC has the ability to keep the humanoid free from being trapped in local minima whereas it facilitates it to head toward global minima. GWOC provides better results as compared to other intelligent techniques because of its five characteristics that include safe boundary, protection, following, hunting, and caring. Both simulation and experimental navigation in laboratory conditions for single as well as for multiple humanoid NAOs have been carried out. From the results of simulation and experimental data, it is confirmed that GWOC provides global minima for humanoid robots in complex environments with different shaped obstacles. A Petri-net controller is considered while navigating multiple humanoids, as during multiple humanoid navigations, one humanoid robot acts as a dynamic obstacle to other humanoids.
C1 [Muni, Manoj K.; Parhi, Dayal R.] Natl Inst Technol, Dept Mech Engn, Robot Lab, Rourkela 769008, Odisha, India.
   [Kumar, Priyadarshi Biplab] Natl Inst Technol, Dept Mech Engn, Hamirpur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; National Institute of Technology (NIT System);
   National Institute of Technology Hamirpur
RP Muni, MK (corresponding author), Natl Inst Technol, Dept Mech Engn, Robot Lab, Rourkela 769008, Odisha, India.
EM manoj1986nitr@gmail.com
RI Parhi, Dayal/M-7935-2018; Muni, Manoj/AAE-8667-2021
OI Parhi, Dayal/0000-0002-2073-7136; Muni, Manoj/0000-0002-9391-7509;
   Kumar, Priyadarshi Biplab/0000-0002-6495-3228
CR [Anonymous], ASIA CONTROL CONF AS
   [Anonymous], NAO DOCUMENTATION V1
   [Anonymous], MATH PROBL ENG
   [Anonymous], 2012, J MECH ENG AUTOM
   Aouf A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/3145436
   Ariffin IM, 2017, PROCEDIA COMPUT SCI, V105, P34, DOI 10.1016/j.procs.2017.01.185
   Arvanitakis I, 2017, IFAC PAPERSONLINE, V50, P12710, DOI 10.1016/j.ifacol.2017.08.2267
   Cao KC, 2017, ISA T, V71, P161, DOI 10.1016/j.isatra.2017.06.028
   Casini M, 2016, IFAC PAPERSONLINE, V49, P69, DOI 10.1016/j.ifacol.2016.07.155
   Chen WH, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417711643
   Chilian A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4571, DOI 10.1109/IROS.2009.5354535
   Costanzi R, 2016, IFAC PAPERSONLINE, V49, P145, DOI 10.1016/j.ifacol.2016.07.723
   Delgado-Galvan J, 2015, LECT NOTES COMPUT SC, V9116, P169, DOI 10.1007/978-3-319-19264-2_17
   Duchon F, 2014, PROCEDIA ENGINEER, V96, P59, DOI 10.1016/j.proeng.2014.12.098
   Eyer YK, 2017, PROCEDIA COMPUT SCI, V120, P83, DOI 10.1016/j.procs.2017.11.213
   Fakoor Mahdi, 2016, J. appl. res. technol, V14, P300
   Fang Z., 2018, P COMPUTER GRAPHICS, P163
   Guzzi J, 2013, IEEE INT CONF ROBOT, P423, DOI 10.1109/ICRA.2013.6630610
   Han YJ, 2018, ETRI J, V40, P446, DOI 10.4218/etrij.2018-0109
   Hildebrandt AC, 2017, IEEE ROBOT AUTOM LET, V2, P1856, DOI 10.1109/LRA.2017.2712650
   Hu Y, 2016, ROBOT AUTON SYST, V85, P37, DOI 10.1016/j.robot.2016.08.013
   Kuffner J, 2005, SPR TRA ADV ROBOT, V15, P365
   Kumar PB, 2020, SCI IRAN, V27, P262, DOI 10.24200/sci.2018.50018.1466
   Kumar PB, 2019, MULTIMED TOOLS APPL, V78, P11463, DOI 10.1007/s11042-018-6703-0
   Kumar PB, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12360
   Kumar PB, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1858
   Kumar PB, 2018, APPL SOFT COMPUT, V68, P565, DOI 10.1016/j.asoc.2018.04.023
   Lobos-Tsunekawa K, 2018, IEEE ROBOT AUTOM LET, V3, P3247, DOI 10.1109/LRA.2018.2851148
   Malayjerdi E, 2017, RSI INT CONF ROBOT M, P211, DOI 10.1109/ICRoM.2017.8466169
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mylvaganam T, 2018, EUR J CONTROL, V40, P53, DOI 10.1016/j.ejcon.2017.11.005
   Panda MR, 2020, J KING SAUD UNIV-COM, V32, P1020, DOI 10.1016/j.jksuci.2017.12.009
   Pandey A, 2014, 2014 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO), P36
   Pandey A, 2014, PROC TECH, V14, P28, DOI 10.1016/j.protcy.2014.08.005
   Parhi DR, 2008, P I MECH ENG C-J MEC, V222, P2281, DOI 10.1243/09544062JMES955
   Parhi DR, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1802
   Parhi DR, 2005, J INTELL ROBOT SYST, V42, P253, DOI 10.1007/s10846-004-7195-x
   Patle BK, 2018, COMPUT ELECTR ENG, V67, P708, DOI 10.1016/j.compeleceng.2017.12.011
   Pradhan SK, 2009, APPL SOFT COMPUT, V9, P290, DOI 10.1016/j.asoc.2008.04.008
   Rao AM, 2018, MATER TODAY-PROC, V5, P19116, DOI 10.1016/j.matpr.2018.06.265
   Rath AK, 2018, DEF TECHNOL, V14, P677, DOI 10.1016/j.dt.2018.03.008
   Rioux A, 2018, ROBOT AUTON SYST, V99, P50, DOI 10.1016/j.robot.2017.10.001
   Sabe K, 2004, IEEE INT CONF ROBOT, P592, DOI 10.1109/ROBOT.2004.1307213
   SAHOO B, 2018, EMERGING TRENDS ENG
   Shi HB, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417710444
   Singh NH, 2018, PROCEDIA COMPUT SCI, V125, P11, DOI 10.1016/j.procs.2017.12.004
   Mac TT, 2017, APPL SOFT COMPUT, V59, P68, DOI 10.1016/j.asoc.2017.05.012
   Wang BF, 2018, NEUROCOMPUTING, V282, P42, DOI 10.1016/j.neucom.2017.12.015
   Wirbel E, 2013, IEEE INT C NETW SENS, P678, DOI 10.1109/ICNSC.2013.6548820
   Zhang ZJ, 2015, IEEE T CYBERNETICS, V45, P1390, DOI 10.1109/TCYB.2014.2351416
NR 50
TC 10
Z9 10
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2020
VL 31
IS 3
AR e1919
DI 10.1002/cav.1919
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LY8SD
UT WOS:000540797600004
DA 2024-07-18
ER

PT J
AU Liu, KY
   Volonte, M
   Hsu, YC
   Babu, SV
   Wong, SK
AF Liu, Kuan-Yu
   Volonte, Matias
   Hsu, Yu-Chun
   Babu, Sabarish V.
   Wong, Sai-Keung
TI Interaction with proactive and reactive agents in box manipulation tasks
   in virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE box manipulation; proactive agent; reactive agent; user study; virtual
   reality; voice communication
AB This paper studies the user collaboration experience with proactive and reactive agents in transporting boxes in virtual environments. Two main characters, the avatar and the agent, are controlled by a user and a controller, respectively. The user and the agent communicate with each other by voice. The agent can be proactive or reactive. The user follows the instruction issued by the proactive agent, whereas the user instructs the reactive agent to perform actions. The goal is to transport boxes to goal positions with orientation constraints. We conducted a user study to analyze the behaviors of participants in several aspects, including task completion time, path length, control experience, and co-presence experience. We report our findings and make suggestions for future development.
C1 [Liu, Kuan-Yu; Hsu, Yu-Chun; Wong, Sai-Keung] Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu 30010, Taiwan.
   [Volonte, Matias; Babu, Sabarish V.] Clemson Univ, Sch Comp, Clemson, SC USA.
C3 National Yang Ming Chiao Tung University; Clemson University
RP Wong, SK (corresponding author), Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu 30010, Taiwan.
EM cswingo@cs.nctu.edu.tw
FU Ministry of Science and Technology (MOST), Taiwan (Republic of China)
   [MOST 106-2221-E-009-161-MY2]
FX The Ministry of Science and Technology (MOST), Taiwan (Republic of
   China), Grant/Award Number: MOST 106-2221-E-009-161-MY2
CR [Anonymous], IEEE T SYST MAN CYBE
   Babu SV, 2011, IEEE T VIS COMPUT GR, V17, P14, DOI 10.1109/TVCG.2009.211
   Barange M, 2017, LECT NOTES ARTIF INT, V10498, P29, DOI 10.1007/978-3-319-67401-8_4
   Chen H, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1826
   Delecroix F, 2012, ADV INTEL SOFT COMPU, V155, P57
   Fink J, 2008, IEEE INT CONF ROBOT, P1471, DOI 10.1109/ROBOT.2008.4543409
   Guo SH, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1779
   Harms C., 2004, Seventh Annual International Workshop: Presence 2004
   Hoffman G., 2004, AIAA 1 INT SYST TECH, P6434
   Huang PH, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1818
   IJsselsteijn Wijnand A, 2013, Eindhoven: Technische Universiteit Eindhoven, p3s9
   Jan D, 2009, LECT NOTES ARTIF INT, V5773, P372, DOI 10.1007/978-3-642-04380-2_40
   Jennings N. R., 1993, International Journal of Intelligent & Cooperative Information Systems, V2, P289, DOI 10.1142/S0218215793000137
   LEWIS JR, 1992, PROCEEDINGS OF THE HUMAN FACTORS SOCIETY, 36TH ANNUAL MEETING, VOLS 1 AND 2, P1259, DOI 10.1177/154193129203601617
   Li QG, 2007, INT J ROBOT RES, V26, P377, DOI 10.1177/0278364907076819
   MATARIC MJ, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P556, DOI 10.1109/IROS.1995.525940
   Mavridis N, 2015, ROBOT AUTON SYST, V63, P22, DOI 10.1016/j.robot.2014.09.031
   Meriçli T, 2015, J INTELL ROBOT SYST, V80, pS189, DOI 10.1007/s10846-015-0232-0
   Nieuwenhuisen D, 2007, IEEE T ROBOT, V23, P431, DOI 10.1109/TRO.2007.898967
   Ohashi K, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P1019, DOI 10.1109/ROBIO.2014.7090466
   Parra-Gonzalez EF, 2008, IB AM C ART INT 2008
   Rozo L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00030
   Rozo L, 2015, IEEE INT C INT ROBOT, P1024, DOI 10.1109/IROS.2015.7353496
   Sheng WH, 2015, IEEE T CYBERNETICS, V45, P2030, DOI 10.1109/TCYB.2014.2363664
   Wagoner AR, 2015, PROCEDIA COMPUT SCI, V56, P119, DOI 10.1016/j.procs.2015.07.178
   Wong SK, 2018, P ACM SIGGRAPH S INT
   Wu YX, 2014, IEEE T VIS COMPUT GR, V20, P626, DOI 10.1109/TVCG.2014.19
   Xiang W, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1867
   Yamashita A., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3144, DOI 10.1109/ROBOT.2000.845147
   Yildirim I., 2015, THESIS
NR 30
TC 5
Z9 5
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1881
DI 10.1002/cav.1881
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400002
DA 2024-07-18
ER

PT J
AU Rabbani, AH
   van de Panne, M
   Kry, PG
AF Rabbani, Amir H.
   van de Panne, Michiel
   Kry, Paul G.
TI Anticipatory balance control and dimension reduction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE anticipatory control; character animation; humanoid balance; momentum
   control; physics-based simulation; principal component analysis
ID DYNAMIC-RESPONSE; HUMAN MOTION; MODEL
AB A hallmark of many skilled motions is the anticipatory nature of the balance-related adjustments that happen in preparation for the expected evolution of forces during the motion. This can shape simulated and animated motions in subtle but important ways, help lend physical credence to the motion, and help signal the character's intent. In this article, we investigate how center-of-mass reference trajectories (CMRTs) can be learned SO as to achieve anticipatory balance control with a state-of-the-art reactive balancing system. This enables the design of physics-based motion simulations that involve fast pose transitions as well as force-based interactions with the environment, such as punches, pushes, and catching heavy objects. We also show that generating CMRTs in a reduced space may result in faster computation times for similar task motions that deal with environmental interactions. We demonstrate the results on planar human models and show that CMRTs generalize well across parameterized versions of a motion. We illustrate that they are also effective at conveying a mismatch between a character's expectations and reality, for example, thinking that an object is heavier than it is.
C1 [Rabbani, Amir H.] McGill Univ, Sch Comp Sci, Montreal, PQ, Canada.
   [Kry, Paul G.] McGill Univ, Montreal, PQ, Canada.
   [Kry, Paul G.] McGill Univ, Comp Animat & Interact Capture Lab, Montreal, PQ, Canada.
   [van de Panne, Michiel] Univ British Columbia, Dept Comp Sci, Vancouver, BC, Canada.
   [van de Panne, Michiel] Univ British Columbia, Vancouver, BC, Canada.
C3 McGill University; McGill University; McGill University; University of
   British Columbia; University of British Columbia
RP Rabbani, AH (corresponding author), McGill Univ, Sch Comp Sci, Montreal, PQ, Canada.
EM amir.rabbani@mail.mcgill.ca
OI Rabbani, Amirhassan/0000-0003-0444-5835; Kry, Paul/0000-0003-4176-6857
FU NSERC; GRAND NCE
FX NSERC; GRAND NCE
CR Abdallah M, 2005, IEEE INT CONF ROBOT, P1996
   Abe Y, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P249
   Al Borno M, 2014, COMPUT GRAPH FORUM, V33, P225, DOI 10.1111/cgf.12321
   Andrews S, 2013, ACM SIGGRAPH C MOT G, P177
   [Anonymous], 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'02
   [Anonymous], 1980, Multivariate analysis (probability and mathematical statistics)
   Atkeson CG, 2007, IEEE-RAS INT C HUMAN, P57, DOI 10.1109/ICHR.2007.4813849
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Coros S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1781156
   da Silva M, 2008, COMPUT GRAPH FORUM, V27, P371, DOI 10.1111/j.1467-8659.2008.01134.x
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   de Lasa Martin, 2010, ACM T GRAPHIC, V29
   Faloutsos P, 2001, COMP GRAPH, P251, DOI 10.1145/383259.383287
   Geijtenbeek T., 2012, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P211
   Hansen N, 2006, STUD FUZZ SOFT COMP, V192, P75
   Jain S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477936
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kajita S, 2003, IEEE INT CONF ROBOT, P1620, DOI 10.1109/robot.2003.1241826
   Lee Y, 2010, SIGGRAPH 10
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   Macchietto A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531386
   Metoyer R, 2008, IEEE T VIS COMPUT GR, V14, P173, DOI 10.1109/TVCG.2007.70427
   OH HG, 1988, ARMSTRONG AEROSPACE, V1
   Olivier AH, 2011, COMPUT ANIMAT VIRT W, V22, P421, DOI 10.1002/cav.377
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Santello M., 1998, Journal of Neuroscience, V22, P2002
   Shih CL, 1996, IEEE INT CONF ROBOT, P3008, DOI 10.1109/ROBOT.1996.509169
   Stephens BJ, 2010, IEEE INT C INT ROBOT, P1248, DOI 10.1109/IROS.2010.5648837
   Stewart A. J., 1992, Proceedings. Graphics Interface '92, P273
   Tak S, 2005, ACM T GRAPHIC, V24, P98, DOI 10.1145/1037957.1037963
   Tak S, 2000, COMPUT GRAPH FORUM, V19, pC437, DOI 10.1111/1467-8659.00436
   Tassa Y, 2012, IEEE INT C INT ROBOT, P4906, DOI 10.1109/IROS.2012.6386025
   Wang JM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778810
   Wieber P.-B., 2000, INT S MATH THEOR NET
   Wieber PB, 2006, IEEE-RAS INT C HUMAN, P137, DOI 10.1109/ICHR.2006.321375
   Wooten W., 1998, THESIS
   Yamane K, 2003, IEEE T ROBOTIC AUTOM, V19, P421, DOI 10.1109/TRA.2003.810579
   Yin KK, 2006, TR200611 U BRIT COL
   Zhu M, 2006, COMPUT STAT DATA AN, V51, P918, DOI 10.1016/j.csda.2005.09.010
   Zordan J. K., 2002, P ACM SIGGRAPH EUR S, P89
   Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249
   Zordan V, 2014, IEEE T VIS COMPUT GR, V20, P1356, DOI 10.1109/TVCG.2014.2330610
NR 43
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2018
VL 29
IS 6
AR e1726
DI 10.1002/cav.1726
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HH9VW
UT WOS:000456089800002
DA 2024-07-18
ER

PT J
AU Vermeulen, JL
   Hillebrand, A
   Geraerts, R
AF Vermeulen, Jordi L.
   Hillebrand, Arne
   Geraerts, Roland
TI A comparative study of <i>k</i>-nearest neighbour techniques in crowd
   simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE comparative study; crowd simulation; nearest neighbours
AB The k-nearest neighbour (kNN) problem appears in many different fields of computer science, such as computer animation and robotics. In crowd simulation, kNN queries are typically used by a collision-avoidance method to prevent unnecessary computations. Many different methods for finding these neighbours exist, but it is unclear which will work best in crowd simulations, an application which is characterised by low dimensionality and frequent change of the data points. We therefore compare several data structures for performing kNN queries. We find that the nanoflann implementation of a k-d tree offers the best performance by far on many different scenarios, processing 100,000 agents in about 35ms on a fast consumer PC.
C1 [Vermeulen, Jordi L.; Hillebrand, Arne; Geraerts, Roland] Univ Utrecht, Dept Informat & Comp Sci, Princetonpl 5, NL-3584 CC Utrecht, Netherlands.
C3 Utrecht University
RP Geraerts, R (corresponding author), Univ Utrecht, Dept Informat & Comp Sci, Princetonpl 5, NL-3584 CC Utrecht, Netherlands.
EM R.J.Geraerts@uu.nl
RI Geraerts, Roland/B-3859-2016
OI Vermeulen, Jordi/0000-0001-7255-561X
CR [Anonymous], 2010, ANN: a library for approximate nearest neighbor searching
   [Anonymous], 1990, SIGMOD, DOI DOI 10.1145/93597.98741
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bhatia N., 2010, INT J COMPUT SCI INF, V8, DOI DOI 10.1016/J.PMCJ.2015.02.001
   Blanco-Claraco JL, 2015, NANOFLANN
   Brin S., 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases, P574
   Deepika VermaN.K., 2014, International Journal of Advanced Research in Computer and Communication Engineering, V3, P5291
   Gehrels B, 2016, BOOST GEOMETRY LIB
   Guibas LJ, 1998, ROBOTICS: THE ALGORITHMIC PERSPECTIVE, P191
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Guy S., 2009, EUR ACM SIGGRAPH S C, P177
   Keip Christian, 2009, DOKUMENTATION VERSUC
   LAVALLE SM, 2003, MOTION STRATEGY LIB
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Malheiros MD, 2016, COMPUT GRAPH-UK, V57, P112, DOI 10.1016/j.cag.2016.03.006
   Muja M, 2012, FLANNFAST LIB APPROX
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   OpenMP Architecture Review Board, 2013, OpenMP Application Program Interface
   Pan J, 2010, IEEE INT C INT ROBOT, P2243, DOI 10.1109/IROS.2010.5651449
   Ponomarenko Alexander, 2014, Data Analytics, V2014, P125
   SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930
   Shamos Michael Ian, 1975, 16 ANN S FDN COMP SC, P151, DOI [10.1109/SFCS.1975.8, DOI 10.1109/SFCS.1975.8]
   Sucan IA, 2012, IEEE ROBOT AUTOM MAG, V19, P72, DOI 10.1109/MRA.2012.2205651
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   vanders Zwan M, 2015, THESIS
   vansToll WG, 2015, NICT OPEN AMERSFOORT
   Voronoï G, 1908, J REINE ANGEW MATH, V134, P198, DOI 10.1515/crll.1908.134.198
NR 28
TC 13
Z9 13
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1775
DI 10.1002/cav.1775
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200021
OA Green Published
DA 2024-07-18
ER

PT J
AU Yumak, Z
   van den Brink, B
   Egges, A
AF Yumak, Zerrin
   van den Brink, Bram
   Egges, Arjan
TI Autonomous social gaze model for an interactive virtual character in
   real-life settings
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE engagement; gaze model; multiparty interactions; interactive virtual
   humans
ID ATTENTION
AB This paper presents a gaze behavior model for an interactive virtual character situated in the real world. We are interested in estimating which user has an intention to interact, in other words which user is engaged with the virtual character. The model takes into account behavioral cues such as proximity, velocity, posture, and sound; estimates an engagement score; and drives the gaze behavior of the virtual character. Initially, we assign equal weights to these features. Using data collected in a real setting, we analyze which features have higher importance. We found that the model with weighted features correlates better with the ground-truth data.
C1 [Yumak, Zerrin] Univ Utrecht, Comp Sci, Utrecht, Netherlands.
   [van den Brink, Bram] Univ Utrecht, Master Program Game & Media Technol, Utrecht, Netherlands.
   [Egges, Arjan] Univ Utrecht, Virtual Human Technol Lab, Utrecht, Netherlands.
C3 Utrecht University; Utrecht University; Utrecht University
RP Yumak, Z (corresponding author), Univ Utrecht, Utrecht, Netherlands.
EM z.yumak@uu.nl
FU Horizon RAGE-Realizing an Applied Gaming Eco-system [644187]; Utrecht
   University Game Research Seed Money
FX Horizon 2020 RAGE-Realizing an Applied Gaming Eco-system, Grant/Award
   Number: 644187; Utrecht University Game Research Seed Money
CR [Anonymous], 2009, AFFINE 09
   Bohus D., 2009, P ANN M SPEC INT GRO, P244, DOI DOI 10.3115/1708376.1708411
   Foster ME, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P255, DOI 10.1145/2522848.2522879
   Grillon H, 2009, COMPUT ANIMAT VIRT W, V20, P111, DOI 10.1002/cav.293
   Hall Edward Twitchell, 1966, HIDDEN DIMENSION
   Kendon Adam, 2009, Development of Multimodal Interfaces: Active Listening and Synchrony. Second COST 2102 International Training School. Revised Selected Papers, P1
   Kokkinara E, 2011, COMPUT ANIMAT VIRT W, V22, P361, DOI 10.1002/cav.425
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Michalowski MP, 2006, 9TH IEEE INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, VOLS 1 AND 2, PROCEEDINGS, P762, DOI 10.1109/AMC.2006.1631755
   Ruhland K, 2015, COMPUT GRAPH FORUM, V34, P299, DOI 10.1111/cgf.12603
   Sidner CL, 2005, ARTIF INTELL, V166, P140, DOI 10.1016/j.artint.2005.03.005
   Xu Q., 2013, Proceedings of CHI 2013, P2233
   Yumak Zerrin, 2016, CONTEXT AWARE HUMAN, P275
   Zaraki A, 2014, IEEE T HUM-MACH SYST, V44, P157, DOI 10.1109/THMS.2014.2303083
NR 14
TC 5
Z9 5
U1 2
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1757
DI 10.1002/cav.1757
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200004
OA Green Accepted, Green Published
DA 2024-07-18
ER

PT J
AU Liu, N
   Zhu, DM
   Wang, ZQ
   Wei, Y
   Shi, M
AF Liu, Ning
   Zhu, Dengming
   Wang, Zhaoqi
   Wei, Yi
   Shi, Min
TI Progressive light volume for interactive volumetric illumination
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE volumetric illumination; multi scattering; path tracing; light volume
ID AMBIENT OCCLUSION; MODELS
AB We propose a technique named progressive light volume to support advanced volumetric illumination effects, such as single scattering and multi scattering. The light volume stores direct lighting information for sample points of the volume data. Using the light volume, we are able to compute the direct lighting for any point in the volume data with a single texture lookup. In order to keep the rendering at an interactive frame rate, we build the light volume progressively if necessary. During the light volume construction period, we use a fast ray casting algorithm to produce a rough rendering estimate from the light volume. After the light volume is built, we use a path tracer to continuously estimate the light intensity for each pixel. Our method puts no restrictions on the number, position, and type of lights. We conducted a comprehensive evaluation for various datasets. The rendering results show that our method is able to produce compelling images, and the performance results indicate that our method is practical for interactive use. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Liu, Ning; Zhu, Dengming; Wang, Zhaoqi; Wei, Yi] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Liu, Ning] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Shi, Min] North China Elect Power Univ, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; North China Electric Power University
RP Liu, N (corresponding author), 6 Kexueyuan South Rd, Beijing 100190, Peoples R China.
EM liuning01@ict.ac.cn
CR Ament M, 2013, IEEE T VIS COMPUT GR, V19, P2936, DOI 10.1109/TVCG.2013.129
   Banks DC, 2009, IEEE T VIS COMPUT GR, V15, P1595, DOI 10.1109/TVCG.2009.137
   Hadwiger Markus., 2006, SIGGRAPH EUROGRAPHIC, P49, DOI [10.1145/1283900.1283908, DOI 10.1145/1283900.1283908]
   Hernell F, 2010, IEEE T VIS COMPUT GR, V16, P548, DOI 10.1109/TVCG.2009.45
   Jönsson D, 2014, COMPUT GRAPH FORUM, V33, P27, DOI 10.1111/cgf.12252
   Jönsson D, 2012, IEEE T VIS COMPUT GR, V18, P2364, DOI 10.1109/TVCG.2012.232
   Kniss J, 2003, IEEE T VIS COMPUT GR, V9, P150, DOI 10.1109/TVCG.2003.1196003
   Kniss J, 2002, IEEE T VIS COMPUT GR, V8, P270, DOI 10.1109/TVCG.2002.1021579
   Kroes T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038586
   Kronander J, 2012, IEEE T VIS COMPUT GR, V18, P447, DOI 10.1109/TVCG.2011.35
   Lindemann F, 2011, IEEE T VIS COMPUT GR, V17, P1922, DOI 10.1109/TVCG.2011.161
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Max N., 2010, SCI VISUALIZATION AD, V1, P259, DOI [10.4230/DFU.SciViz.2010.259, DOI 10.4230/DFU.SCIVIZ.2010.259]
   Papaioannou G, 2010, IEEE T VIS COMPUT GR, V16, P752, DOI 10.1109/TVCG.2010.18
   Ropinski T, 2008, COMPUT GRAPH FORUM, V27, P567, DOI 10.1111/j.1467-8659.2008.01154.x
   Schlegel P, 2011, IEEE T VIS COMPUT GR, V17, P1795, DOI 10.1109/TVCG.2011.198
   Shih M, 2015, IEEE PAC VIS SYMP, P239, DOI 10.1109/PACIFICVIS.2015.7156383
   Sundén E, 2011, IEEE T VIS COMPUT GR, V17, P2125, DOI 10.1109/TVCG.2011.211
   Woodcock E, 1965, C APPL COMP METH REA, V557
   Zhang YB, 2013, IEEE T VIS COMPUT GR, V19, P1317, DOI 10.1109/TVCG.2013.17
NR 20
TC 3
Z9 3
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 394
EP 404
DI 10.1002/cav.1706
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300024
DA 2024-07-18
ER

PT J
AU Deul, C
   Charrier, P
   Bender, J
AF Deul, Crispin
   Charrier, Patrick
   Bender, Jan
TI Position-based rigid-body dynamics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE real time; rigid-body dynamics; two-way coupling; position-based
   dynamics
ID SIMULATION; BODIES
AB We propose a position-based approach for large-scale simulations of rigid bodies at interactive frame rates. Our method solves positional constraints between rigid bodies and can therefore be seamlessly integrated into other position-based methods. Interaction of particles and rigid bodies through common constraints enables two-way coupling with deformables. The method exhibits exceptional performance and stability while being user controllable and easy to implement. Various results demonstrate the practicability of our method for the resolution of collisions, contacts, stacking and joint constraints. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Deul, Crispin; Charrier, Patrick; Bender, Jan] Tech Univ Darmstadt, Grad Sch Excellence Computat Engn, Dolivostr 15, D-64293 Darmstadt, Germany.
C3 Technical University of Darmstadt
RP Deul, C (corresponding author), Tech Univ Darmstadt, Grad Sch Excellence Computat Engn, Dolivostr 15, D-64293 Darmstadt, Germany.
EM deul@gsc.tu-darmstadt.de
FU Excellence Initiative of the German Federal and State Governments;
   Graduate School of Excellence Computational Engineering at Technische
   Universitat Darmstadt
FX This work was supported by the Excellence Initiative of the German
   Federal and State Governments and the Graduate School of Excellence
   Computational Engineering at Technische Universitat Darmstadt. The
   authors would like to thank Daniel Thul who investigated the
   applicability of our basic idea in his bachelor thesis. Furthermore, we
   acknowledge the source of the models shown in our examples. The elk
   model used in Scenes 1, 3 and 4 is provided, courtesy of MPII, by the
   AIM@SHAPE Shape Repository. The dolphin model and the Isidore horse used
   in Scene 1 is provided, courtesy of INRIA, by the AIM@SHAPE Shape
   Repository. Additionally, Scene 3 uses the model "Adventure Kid" by
   Clint Bellanger available at
   http://opengameart.org/content/adventure-kid under a Creative Commons
   Attribution 3.0 Unported. Full terms at
   http://creativecommons.org/licenses/by/3.0/. Furthermore, a modified
   version of the duck model "Rubberduck" by rubberduck available at
   http://opengameart.org/content/rubberduck under a CC0 1.0 Universal
   Public Domain Dedication is used in Scene 4.
CR [Anonymous], 2011, ACM T GRAPHICS
   Baraff D., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P23, DOI 10.1145/192161.192168
   Baraff D., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P137, DOI 10.1145/237170.237226
   Benda J., 2013, Encyclopedia of Computational Neuroscience, P1, DOI [DOI 10.1007/978-1-4614-7320-6_339-1, 10.1007/978-1-4614-7320-6_339-1]
   Bender J, 2005, P VIRT CONC, P225
   Bender J., 2006, P 19 INT C COMPUTER, P3
   Bender J., 2007, THESIS U KARLSRUHE G
   Bender J, 2007, COMPUT ANIMAT VIRT W, V18, P225, DOI 10.1002/cav.179
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P246, DOI 10.1111/cgf.12272
   Coumans Erwin., 2014, Bullet Physics Library
   Diziol Raphael., 2011, Proceedings of the 2011 ACM SIGGRAPH/eurographics symposium on computer animation, P237, DOI DOI 10.1145/2019406.2019438
   Erleben K, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243986
   Featherstone R., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P826, DOI 10.1109/ROBOT.2000.844153
   Featherstone R., 2007, RIGID BODY DYNAMICS
   Grassia F. S., 1998, J. Graph. Tools, V6, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]
   Guendelman E, 2003, ACM T GRAPHIC, V22, P871, DOI 10.1145/882262.882358
   Kaufman DM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409117
   Kaufman DM, 2005, ACM T GRAPHIC, V24, P946, DOI 10.1145/1073204.1073295
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Mirtich BV, 1995, P INT 3D GRAPH
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   NVIDIA, 2014, PHYSX
   Redon S, 2005, ACM T GRAPHIC, V24, P936, DOI 10.1145/1073204.1073294
   Smith B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185602
   Tasora A, 2008, 2008 ASME DYN SYST C, P1
   Weber D, 2013, COMPUT GRAPH FORUM, V32, P16, DOI 10.1111/j.1467-8659.2012.03227.x
   Weinstein R, 2006, IEEE T VIS COMPUT GR, V12, P365, DOI 10.1109/TVCG.2006.48
   Witkin A., 1990, Computer Graphics, V24, P11, DOI 10.1145/91394.91400
NR 28
TC 36
Z9 40
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2016
VL 27
IS 2
BP 103
EP 112
DI 10.1002/cav.1614
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DJ2BZ
UT WOS:000374010000002
DA 2024-07-18
ER

PT J
AU Pan, JJ
   Bai, JX
   Zhao, X
   Hao, AM
   Qin, H
AF Pan, Junjun
   Bai, Junxuan
   Zhao, Xin
   Hao, Aimin
   Qin, Hong
TI Real-time haptic manipulation and cutting of hybrid soft tissue models
   by extended position-based dynamics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE position-based dynamics; hybrid geometric models; deformation;
   interactive cutting; tetrahedra
ID DEFORMABLE-BODIES; SIMULATION; OBJECTS
AB This paper systematically describes an interactive dissection approach for hybrid soft tissue models governed by extended position-based dynamics. Our framework makes use of a hybrid geometric model comprising both surface and volumetric meshes. The fine surface triangular mesh with high-precision geometric structure and texture at the detailed level is employed to represent the exterior structure of soft tissue models. Meanwhile, the interior structure of soft tissues is constructed by coarser tetrahedral mesh, which is also employed as physical model participating in dynamic simulation. The less details of interior structure can effectively reduce the computational cost during simulation. For physical deformation, we design and implement an extended position-based dynamics approach that supports topology modification and material heterogeneities of soft tissue. Besides stretching and volume conservation constraints, it enforces the energy preserving constraints, which take the different spring stiffness of material into account and improve the visual performance of soft tissue deformation. Furthermore, we develop mechanical modeling of dissection behavior and analyze the system stability. The experimental results have shown that our approach affords real-time and robust cutting without sacrificing realistic visual performance. Our novel dissection technique has already been integrated into a virtual reality-based laparoscopic surgery simulator. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Pan, Junjun; Bai, Junxuan; Zhao, Xin; Hao, Aimin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Comp Sci, Stony Brook, NY USA.
C3 Beihang University; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook
RP Pan, JJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM pan_junjun@hotmail.com
RI Bai, Junxuan/P-7282-2018; Pan, Junjun/A-1316-2013
OI Bai, Junxuan/0000-0002-7941-0584; 
FU National Natural Science Foundation of China [61402025, 61190120,
   61190121, 61190125]; National Science Foundation of USA [IIS-0949467,
   IIS-1047715, IIS-1049448]; Fundamental Research Funds for the Central
   Universities
FX We thank for Chen Yang's work in FEM. This research is supported by the
   National Natural Science Foundation of China (No. 61402025, 61190120,
   61190121, 61190125), National Science Foundation of USA (No.
   IIS-0949467, IIS-1047715, IIS-1049448), and the Fundamental Research
   Funds for the Central Universities.
CR Aggarwal R, 2004, BRIT J SURG, V91, P1549, DOI 10.1002/bjs.4816
   Alastrué V, 2010, INT J NUMER METH BIO, V26, P35, DOI 10.1002/cnm.1234
   [Anonymous], 2006, EUR OBSTET GYNAECOL, DOI DOI 10.1007/S11296-006-0054-5
   [Anonymous], 2008, HAPTIC RENDERING FDN
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   Bielser D, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P116, DOI 10.1109/PCCGA.2000.883933
   Choi C, 2009, INT J MED ROBOT COMP, V5, P257, DOI 10.1002/rcs.256
   Choi KS, 2009, COMPUT BIOL MED, V39, P1020, DOI 10.1016/j.compbiomed.2009.08.003
   Courtecuisse H, 2014, MED IMAGE ANAL, V18, P394, DOI 10.1016/j.media.2013.11.001
   Dick C, 2011, IEEE T VIS COMPUT GR, V17, P1663, DOI 10.1109/TVCG.2010.268
   Halic T, 2010, INT J MED ROBOT COMP, V6, P431, DOI 10.1002/rcs.353
   Jerábková L, 2010, PROG BIOPHYS MOL BIO, V103, P217, DOI 10.1016/j.pbiomolbio.2010.09.012
   Li X, 2009, IEEE T AUTOM SCI ENG, V6, P409, DOI 10.1109/TASE.2009.2014735
   Maciel A, 2009, INT J MED ROBOT COMP, V5, P341, DOI 10.1002/rcs.266
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Müller M, 2004, PROC GRAPH INTERF, P239
   Pan J, 2015, INT J MED ROBOT COMP, V7, P204
   Pan JJ, 2011, INT J MED ROBOT COMP, V7, P304, DOI 10.1002/rcs.399
   Pan JJ, 2009, COMPUT ANIMAT VIRT W, V20, P121, DOI 10.1002/cav.284
   Pietroni N, 2009, VISUAL COMPUT, V25, P227, DOI 10.1007/s00371-008-0216-1
   Steinemann D., 2006, PROC ACM SIGGRAPHEUR, P63
   Takayama K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360652
   Wu J., 2014, EUROGRAPHICS 2014 ST, P1
   Wu J, 2013, VISUAL COMPUT, V29, P739, DOI 10.1007/s00371-013-0810-8
   Yang C, 2014, COMPUT ANIMAT VIRT W, V25, P423, DOI 10.1002/cav.1594
   Zhang H, 2004, IEEE INT CONF ROBOT, P3908
NR 26
TC 42
Z9 46
U1 1
U2 41
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 321
EP 335
DI 10.1002/cav.1655
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700014
DA 2024-07-18
ER

PT J
AU Zhang, XZ
   Sourin, A
AF Zhang, Xingzi
   Sourin, Alexei
TI Image-inspired haptic interaction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE haptic interaction; image-based visualization; sketch-based modelling;
   tangible images
AB We add new modality to image-based visualization by converting ordinary photos into tangible images, which can be then haptically rendered. This is performed by interactive sketching haptic models on the photos so that the models match the image parts, which will become tangible. In contrast to common geometric modelling, we define the haptic models in a three-dimensional haptic modelling space distorted by the central projection. Analytic FRep functions (variants of implicit functions) are mostly used for defining the haptic models. The tangible images thus created can realistically simulate some actual three-dimensional scenes by implementing the principle What You See Is What You Touch while in fact still be 2D images. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Zhang, Xingzi; Sourin, Alexei] Nanyang Technol Univ, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Sourin, A (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM assourin@ntu.edu.sg
RI Sourin, Alexei/A-3701-2011
OI Sourin, Alexei/0000-0003-4051-2927
FU Joint PhD Degree Programme NTU-TU Darmstadt; Ministry of Education of
   Singapore [MOE2011-T2-1-006]; Fraunhofer IDM@NTU - National Research
   Foundation
FX This project is supported by the Joint PhD Degree Programme NTU-TU
   Darmstadt and partially by the Ministry of Education of Singapore Grant
   MOE2011-T2-1-006 "Collaborative Haptic Modeling for Orthopaedic Surgery
   Training in Cyberspace". The project is also supported by Fraunhofer
   IDM@NTU, which is funded by the National Research Foundation and managed
   through the multiagency Interactive & Digital Media Programme Office
   hosted by the Media Development Authority of Singapore.
CR Buchanan P., 2013, Proceedings of the international symposium on sketch-based interfaces and modeling, P5, DOI 10.1145/2487381.2487385
   Chens K, 2014, P 2014 INT C CYB, P55, DOI [10.1109/CW2014.16, DOI 10.1109/CW2014.16]
   Chens T, 2013, P ACM SIGGRAPH ASIA, V32, DOI [10.1145/2508363.2508378, DOI 10.1145/2508363.2508378]
   Heuvel F.A. V. D., 2001, PHOTOGRAMM FERNERKUN, V4, P247
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Ikei Y, 1998, P IEEE VIRT REAL ANN, P51, DOI 10.1109/VRAIS.1998.658422
   Kagawas T, 2007, SYST MAN CYB 2007 IS, P2443, DOI [10.1109/ICSMC.2007.4414126, DOI 10.1109/ICSMC.2007.4414126]
   Kara L.B., 2006, P 2006 ACM S SOLID P, P149, DOI [10.1145/1128888.1128909, DOI 10.1145/1128888.1128909]
   Lis J, 2010, P 9 ACM SIGGRAPH C V, P237, DOI [10.1145/1900179.1900230, DOI 10.1145/1900179.1900230]
   Nikolakiss G, 2005, P HCI INT
   Olsens L, 2011, COMPUTER GRAPHICS AP, V31, P24, DOI [10.1109/MCG.2011.84, DOI 10.1109/MCG.2011.84]
   PASKO A, 1995, VISUAL COMPUT, V11, P429, DOI 10.1007/BF02464333
   Rasools S, 2011, TANGIBLE IMAGES SIGG, DOI [10.1145/2077378.2077430, DOI 10.1145/2077378.2077430]
   Rasools S, 2013, CYB CW INT C IEEE, P286, DOI [10.1109/CW.2013.28, DOI 10.1109/CW.2013.28]
   SALISBURY K, 1997, P ASME DYN SYST CONT, V61, P61
   Schmidt R., 2007, ACM SIGGRAPH 2007 Courses. SIGGRAPH '07, DOI DOI 10.1145/1281500.1281554
   Siiras J, 1996, P IEEE INT C ROB AUT, V1, P557, DOI [10.1109/ROBOT.1996.503834, DOI 10.1109/ROBOT.1996.503834]
   Sourin A, 2009, VIRTUAL REAL-LONDON, V13, P221, DOI 10.1007/s10055-009-0133-2
   Streileins A, 1999, P 17 CIPA S OCT
   Xus K, 2011, P ACM SIGGRAPH, V30, DOI [10.1145/2010324.1964975, DOI 10.1145/2010324.1964975]
   Yang C., 2005, Eurographics Workshop on Sketch-Based Interfaces and Modeling, P63
   Zengs Q, 2015, P EUROGRAPH IN PRESS, V34
   ZILLES CB, 1995, P IEEE RSJ INT C INT, V3, P146, DOI DOI 10.1109/IR0S.1995.525876
NR 23
TC 5
Z9 5
U1 2
U2 11
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 311
EP 319
DI 10.1002/cav.1643
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shao, XQ
   Zhou, Z
   Zhang, JS
   Wu, W
AF Shao, Xuqiang
   Zhou, Zhong
   Zhang, Jinsong
   Wu, Wei
TI Realistic and stable simulation of turbulent details behind objects in
   smoothed-particle hydrodynamics fluids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE turbulence synthesis; SPH; fluid simulation; fluid-solid coupling;
   physically based animation
ID RECONSTRUCTION
AB This paper presents a novel realistic and stable turbulence synthesis method to simulate the turbulent details generated behind objects in smoothed particle hydrodynamics (SPH) fluids. Firstly, by approximating the boundary layer theory on the fly in SPH fluids, we propose a vorticity production model to identify which fluid particles shed from object surfaces and which are seeded as vortex particles. Then, we employ an SPH-like summation interpolant formulation of the Biot-Savart law to calculate the fluctuating velocities stemming from the generated vorticity field. Finally, the stable evolution of the vorticity field is achieved by combining an implicit vorticity diffusion technique and an artificial dissipation term. Moreover, in order to efficiently catch turbulent details for rendering, we propose an octree-based adaptive surface reconstruction method for particle-based fluids. The experiment results demonstrate that our turbulence synthesis method provides an effect way to model the obstacle-induced turbulent details in SPH fluids and can be easily added to existing particle-based fluid-solid coupling pipelines. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Shao, Xuqiang; Zhou, Zhong; Zhang, Jinsong; Wu, Wei] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhou, Z (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM zz@vrlab.buaa.edu.cn
FU National 863 Program of China [2012AA011801]; National Key Technology
   R&D Program of China [2012BAI06B01]
FX This work is supported by the National 863 Program of China (Grant No.
   2012AA011801), the National Key Technology R&D Program of China (Grant
   No. 2012BAI06B01). We thank the anonymous reviewers for their
   constructive comments.
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Akinci G, 2012, COMPUT GRAPH FORUM, V31, P1797, DOI 10.1111/j.1467-8659.2012.02096.x
   [Anonymous], P SIGGRAPH LOS ANG
   [Anonymous], J COMPUTER ANIMATION
   [Anonymous], P SIGGRAPH LOS ANG C
   [Anonymous], P SIGGRAPH SAN DIEG
   [Anonymous], P COMP GRAPH INT BOU
   [Anonymous], VORTEX METHODS THEOR
   [Anonymous], P SIGGRAPH VANC CAN
   [Anonymous], 2008, P 2008 ACM SIGGRAPHE
   [Anonymous], T GRAPHICS
   [Anonymous], P EUROGRAPHICS MUN G
   Bao K, 2009, COMPUT ANIMAT VIRT W, V20, P311, DOI 10.1002/cav.299
   Clavet S., 2005, SCA '05, P219, DOI DOI 10.1145/1073368.1073400
   Colagrossi A, 2003, J COMPUT PHYS, V191, P448, DOI 10.1016/S0021-9991(03)00324-3
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Hadap S, 2001, COMPUT GRAPH FORUM, V20, pC329, DOI 10.1111/1467-8659.00525
   Hasinoff SW, 2007, IEEE T PATTERN ANAL, V29, P870, DOI 10.1109/TPAMI.2007.1056
   Ihmsen M, 2013, COMPUT GRAPH-UK, V37, P800, DOI 10.1016/j.cag.2013.04.010
   Iwasaki K, 2010, COMPUT GRAPH FORUM, V29, P2215, DOI 10.1111/j.1467-8659.2010.01810.x
   Kim B., 2005, P 1 EUROGRAPHICS C N, DOI DOI 10.2312/NPH/NPH05/051-056
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Markus Becker, 2009, NPH, V9, P27, DOI [10.2312/EG/DL/conf/EG2009/nph/027-034, DOI 10.2312/EG/DL/CONF/EG2009/NPH/027-034]
   Marrone S, 2010, J COMPUT PHYS, V229, P3652, DOI 10.1016/j.jcp.2010.01.019
   Monaghan JJ, 1997, J COMPUT PHYS, V138, P801, DOI 10.1006/jcph.1997.5846
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Narain R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409119
   Pan ZR, 2012, COMPUT GRAPH FORUM, V31, P2029, DOI 10.1111/j.1467-8659.2012.03195.x
   Park S. I., 2005, Computer Animation, Conference Proceedings, P261, DOI [DOI 10.1145/1073368.1073406, 10.1145/1073368.1073406]
   Pfaff T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866196
   Pfaffs T, 2009, P SIGGRAPH ASIA, P1
   Schechter H., 2008, Symposium on Computer animation, P1
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Shao XQ, 2013, INT C COMP AID DES C, P252, DOI 10.1109/CADGraphics.2013.40
   Solenthaler B., 2008, P 2008 ACM SIGGRAPH, P211, DOI 10.2312/SCA/SCA08/211-218
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Solenthalers B, 2009, P SIGGRAPH, P1
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Yoon JC, 2009, COMPUT GRAPH FORUM, V28, P1853, DOI 10.1111/j.1467-8659.2009.01563.x
   Yu Jihun., 2010, Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '10, P217
   Yuan Z, 2012, VISUAL COMPUT, V28, P435, DOI 10.1007/s00371-011-0626-3
   Zhu B, 2010, COMPUT GRAPH FORUM, V29, P2207, DOI 10.1111/j.1467-8659.2010.01809.x
   Zhu J, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-013-4806-9
NR 46
TC 11
Z9 14
U1 1
U2 20
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2015
VL 26
IS 1
BP 79
EP 94
DI 10.1002/cav.1607
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CC1LW
UT WOS:000350103200008
OA Bronze
DA 2024-07-18
ER

PT J
AU Warburton, M
   Maddock, S
AF Warburton, Mark
   Maddock, Steve
TI Physically-based forehead animation including wrinkles
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE physically-based animation; facial animation; soft-tissue animation;
   wrinkle animation; finite element method
ID SKELETAL-MUSCLE; ELEMENT; SKIN; SURGERY; MODEL
AB Physically-based animation techniques enable more realistic and accurate animation to be created. We present a fully physically-based approach for efficiently producing realistic-looking animations of facial movement, including animation of expressive wrinkles. This involves simulation of detailed voxel-based models using a graphics processing unit-based total Lagrangian explicit dynamic finite element solver with an anatomical muscle contraction model, and advanced boundary conditions that can model the sliding of soft tissue over the skull. The flexibility of our approach enables detailed animations of gross and fine-scale soft-tissue movement to be easily produced with different muscle structures and material parameters, for example, to animate different aged skins. Although we focus on the forehead, our approach can be used to animate any multi-layered soft body. (c) 2014 The Authors. Computer Animation and Virtual Worlds published by John Wiley & Sons, Ltd.
C1 [Warburton, Mark; Maddock, Steve] Univ Sheffield, Dept Comp Sci, Sheffield S1 4DP, S Yorkshire, England.
C3 University of Sheffield
RP Warburton, M (corresponding author), Univ Sheffield, Dept Comp Sci, 211 Portobello, Sheffield S1 4DP, S Yorkshire, England.
EM M.Warburton@dcs.shef.ac.uk
RI Maddock, Steve/J-1849-2016
OI Maddock, Steve/0000-0003-3179-0263
FU EPSRC
FX This research was supported by the EPSRC.
CR Avril Q., 2012, PROC EUROGRAPH S PAR, P71, DOI DOI 10.2312/EGPGV/EGPGV12/071-080
   Bando Y, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P166, DOI 10.1109/PCCGA.2002.1167852
   Barbarino G, 2008, LECT NOTES COMPUT SC, V5104, P1, DOI 10.1007/978-3-540-70521-5_1
   Beldie L, 2010, INT J MED ROBOT COMP, V6, P422, DOI 10.1002/rcs.352
   Bickel B, 2007, ACM T GRAPHIC, V26, P33
   Bischoff JE, 2006, ANN BIOMED ENG, V34, P1164, DOI 10.1007/s10439-006-9124-6
   Chen C., 2006, 2006 International Conference on Game Research and Development, P171
   Choe B, 2001, J VISUAL COMP ANIMAT, V12, P67, DOI 10.1002/vis.246
   Coull AD, 2005, THESIS U GLASGOW UK
   Dutreve L, 2009, LECT NOTES COMPUT SC, V5876, P25, DOI 10.1007/978-3-642-10520-3_3
   Duysak A, 2005, P TPCG CANT UK, P139
   Flynn C, 2008, SKIN RES TECHNOL, V14, P261, DOI 10.1111/j.1600-0846.2008.00289.x
   Flynn C, 2010, J BIOMECH, V43, P442, DOI 10.1016/j.jbiomech.2009.10.007
   Fratarcangeli M., 2005, P 2 INT WORKSH VIRT, P32
   Fratarcangeli M, 2012, COMPUT ANIMAT VIRT W, V23, P457, DOI 10.1002/cav.1450
   Hung A., 2009, WORLD ACAD SCI ENG T, V54, P134
   Joldes GR, 2008, COMMUN NUMER METH EN, V24, P1315, DOI 10.1002/cnm.1034
   Kahler K., 2001, GRAPHICS INTERFACE 2, P37, DOI DOI 10.20380/GI2001.05
   Kahler K., 2002, Eurographics Symp. on Comp. Animation, P55, DOI DOI 10.1145/545261.545271
   Kim H, 2010, PROG BIOPHYS MOL BIO, V103, P284, DOI 10.1016/j.pbiomolbio.2010.09.004
   Koch R.M., 2002, P 18 SPRING C COMPUT, P33
   Kuwazuru O, 2008, MED ENG PHYS, V30, P516, DOI 10.1016/j.medengphy.2007.06.001
   Larboulette C, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P522, DOI 10.1109/CGI.2004.1309258
   Lee SH, 2006, ACM T GRAPHIC, V25, P1188, DOI 10.1145/1141911.1142013
   Li M, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P874, DOI 10.1109/ICIG.2007.22
   Maciel A, 2009, INT J MED ROBOT COMP, V5, P341, DOI 10.1002/rcs.266
   Magnenat-Thalmann N, 2002, IEEE T INF TECHNOL B, V6, P317, DOI 10.1109/TITB.2002.806097
   Miller K, 2007, COMMUN NUMER METH EN, V23, P121, DOI 10.1002/cnm.887
   Mithraratne K, 2010, IFMBE PROC, V31, P1024, DOI 10.1007/978-3-642-14515-5_261
   Mollemans W, 2005, INT CONGR SER, V1281, P491, DOI 10.1016/j.ics.2005.03.048
   Mosegaard J, 2005, STUD HEALTH TECHNOL, V111, P342
   Muller Matthias, 2010, Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P85, DOI [10.5555/1921427.19214412, DOI 10.5555/1921427.19214412]
   Nedel LP, 1998, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P156, DOI 10.1109/CGI.1998.694263
   Olovsson L, 2005, INT J NUMER METH ENG, V63, P1436, DOI 10.1002/nme.1293
   Reis CDG, 2008, WSCG 2008, COMMUNICATION PAPERS, P109
   Rohrle O, 2007, J BIOMECH, V40, P3363, DOI 10.1016/j.jbiomech.2007.05.011
   Sanchez M, 2006, THESIS U SHEFFIELD S
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   Tang CY, 2009, J BIOMECH, V42, P865, DOI 10.1016/j.jbiomech.2009.01.021
   Taylor ZA, 2009, MED IMAGE ANAL, V13, P234, DOI 10.1016/j.media.2008.10.001
   Taylor ZA, 2008, IEEE T MED IMAGING, V27, P650, DOI 10.1109/TMI.2007.913112
   Teran J, 2005, IEEE T VIS COMPUT GR, V11, P317, DOI 10.1109/TVCG.2005.42
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Warburton M, 2013, J WSCG, P215
   Warburton M, 2013, P TPCG BATH UK, P1
   Warburton M, 2012, WSCG'2012, CONFERENCE PROCEEDINGS, PTS I & II, P317
   Waters K., 1987, ACM SIGGRAPH Comput. Graph., V21, P17
   Wu T, 2010, IFMBE PROC, V31, P1566, DOI 10.1007/978-3-642-14515-5_399
   Wu Y, 1999, VISUAL COMPUT, V15, P183, DOI 10.1007/s003710050171
   Xu SP, 2011, IEEE T INSTRUM MEAS, V60, P14, DOI 10.1109/TIM.2010.2065450
   Yang XS, 2005, LECT NOTES COMPUT SC, V3515, P199
   Yuencheng Lee, 1995, Computer Graphics Proceedings. SIGGRAPH 95, P55
   Zachow S., 2006, Journal of Computing and Information Technology - CIT, V14, P53, DOI 10.2498/cit.2006.01.06
   Zhang Y, 2005, LECT NOTES COMPUT SC, V3515, P207
   Zhang Y, 2004, IEEE T VIS COMPUT GR, V10, P339, DOI 10.1109/TVCG.2004.1272733
NR 55
TC 7
Z9 8
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2015
VL 26
IS 1
BP 55
EP 68
DI 10.1002/cav.1565
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CC1LW
UT WOS:000350103200006
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Fang, XX
   Sheng, B
   Wu, W
   Fan, ZZ
   Ma, LZ
AF Fang, Xiaoxin
   Sheng, Bin
   Wu, Wen
   Fan, Zengzhi
   Ma, Lizhuang
TI Real-time depth-of-field rendering using single-layer composition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE depth of field; post-processing; GPU; single-layer composition
AB In this paper, we propose a single-layer post-processing method for real-time depth-of-field rendering that uses single-layer composition. In the proposed method, blurring is achieved by gathering background pixels and scattering foreground pixels. Major artifacts in post-filtering techniques such as intensity leakage and blurring discontinuity are reduced by using two different blurring functions and the controllable parameter in the gathering process. The method can be entirely implemented in GPU parallelization to achieve the real-time performance required for virtual reality. The results of comparisons of our method with recent post-processing methods in terms of rendering quality and rendering performance indicate that our method generates realistic natural images and is also the fastest in terms of frames per second. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Fang, Xiaoxin; Sheng, Bin; Fan, Zengzhi; Ma, Lizhuang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Sheng, Bin] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Wu, Wen] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macao, Peoples R China.
C3 Shanghai Jiao Tong University; Chinese Academy of Sciences; Institute of
   Software, CAS; University of Macau
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
EM shengbin@cs.sjtu.edu.cn
FU National Basic Research Project of China [2011CB302203]; National
   Natural Science Foundation of China [61202154, 61133009]; Shanghai
   Pujiang Program [13PJ1404500]; University of Macau
   [MYRG150(Y3-L2)/FST11/WW, MYRG202(Y3-L4)/FST11/WEH]; National Laboratory
   of Pattern Recognition (Chinese Academy of Sciences); State Key
   Laboratory of CAD&CG, Zhejiang University [A1401]
FX We would like to thank the anonymous reviewers for their valuable
   comments. This work was supported in part by the National Basic Research
   Project of China under Grant 2011CB302203, the National Natural Science
   Foundation of China under Grant Nos. 61202154 and 61133009, the Shanghai
   Pujiang Program under Grant 13PJ1404500, the grant of University of
   Macau under Grant No. MYRG150(Y3-L2)/FST11/WW and
   MYRG202(Y3-L4)/FST11/WEH, the Open Project Program of the National
   Laboratory of Pattern Recognition (Chinese Academy of Sciences), and the
   Open Project Program of the State Key Laboratory of CAD&CG, Zhejiang
   University, under Grant A1401.
CR Barsky B.A., 2004, APGV 04, P73, DOI DOI 10.1145/1012551.1012564
   Barsky B.A., 2002, Proc. Eurographics Rendering Workshop, P26
   Barsky BA, 2008, REC ADV COMPUT ENG, P999
   Bertalmío M, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P767, DOI 10.1109/TDPVT.2004.1335393
   Cook R. L., 1984, Computers & Graphics, V18, P137
   Demers J, 2003, GAN DEV C SAN JOS CA
   Demers J, 2004, GPU GEMS, V1, pU390
   Gillham D., 2007, Shader X5: Advanced Rendering Techniques, P163
   Haeberli P., 1990, Computer Graphics, V24, P309, DOI 10.1145/97880.97913
   Hammer Espen., 2007, German Idealism: Contemporary Perspectives, P1
   Kass M., 2006, Pixar Animation Studios Tech Report, V2, P1
   Kraus M, 2007, COMPUT GRAPH FORUM, V26, P645, DOI 10.1111/j.1467-8659.2007.01088.x
   Lee S, 2009, IEEE T VIS COMPUT GR, V15, P453, DOI 10.1109/TVCG.2008.106
   Mather G, 1996, P ROY SOC B-BIOL SCI, V263, P169, DOI 10.1098/rspb.1996.0027
   Mulder J.D., 2000, P ACM S VIRTUAL REAL, P129
   Potmesil M, 1981, ACM SIGGRAPH COMPUTE, V15, P297
   Riguer G., 2003, ShaderX2: Shader Programming Tips and Tricks with DirectX, V9, P529
   Rokita P, 1996, IEEE COMPUT GRAPH, V16, P18, DOI 10.1109/38.486676
   Schedl DC, 2012, J WSCG, V20, P239
   Scheuermann T, 2004, GDC, V8, P1
   Scofield C, 1992, GRAPHICS GEMS, P36
   SHINYA M, 1994, GRAPH INTER, P59
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Zhou TS, 2007, COMPUT GRAPH FORUM, V26, P15, DOI 10.1111/j.1467-8659.2007.00935.x
NR 24
TC 0
Z9 0
U1 0
U2 16
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 235
EP 243
DI 10.1002/cav.1591
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300005
DA 2024-07-18
ER

PT J
AU Tang, ZP
   Xiao, J
   Feng, YF
   Yang, XS
   Zhang, J
AF Tang, Zhangpeng
   Xiao, Jun
   Feng, Yinfu
   Yang, Xiaosong
   Zhang, Jian
TI Human motion retrieval based on freehand sketch
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion retrieval; sketch; motion index; motion graph; computer animation
AB In this paper, we present an integrated framework of human motion retrieval based on freehand sketch. With some simple rules, the user can acquire a desired motion by sketching several key postures. To retrieve efficiently and accurately by sketch, the 3D postures are projected onto several 2D planes. The limb direction feature is proposed to represent the input sketch and the projected-postures. Furthermore, a novel index structure based on k-d tree is constructed to index the motions in the database, which speeds up the retrieval process. With our posture-by-posture retrieval algorithm, a continuous motion can be got directly or generated by using a pre-computed graph structure. What's more, our system provides an intuitive user interface. The experimental results demonstrate the effectiveness of our method. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Tang, Zhangpeng; Xiao, Jun; Feng, Yinfu] Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310003, Zhejiang, Peoples R China.
   [Yang, Xiaosong; Zhang, Jian] Bournemouth Univ, Media Sch, Poole BH12 5BB, Dorset, England.
C3 Zhejiang University; Bournemouth University
RP Xiao, J (corresponding author), Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310003, Zhejiang, Peoples R China.
EM junx@cs.zju.edu.cn
OI Yang, Xiaosong/0000-0003-3815-0584
FU National High Technology Research and Development Program
   [2012AA011502]; National Key Technology RD Program [2013BAH59F00];
   Zhejiang Provincial Natural Science Foundation of China [LY13F020001];
   Zhejiang Province Public Technology Applied Research Projects
   [2014C33090]; Fundamental Research Funds for the Central Universities
   [2014FZA5013]; Sino-UK Higher Education Research Partnership -
   Department of Business, Innovation and Skills of the British Government;
   Ministry of Education of China
FX This research is supported by the National High Technology Research and
   Development Program (2012AA011502), the National Key Technology R&D
   Program (2013BAH59F00), the Zhejiang Provincial Natural Science
   Foundation of China (LY13F020001), the Zhejiang Province Public
   Technology Applied Research Projects (No. 2014C33090), the Fundamental
   Research Funds for the Central Universities(2014FZA5013), and partially
   supported by the grant of the Sino-UK Higher Education Research
   Partnership for PhD Studies Project funded by the Department of
   Business, Innovation and Skills of the British Government and Ministry
   of Education of China.
CR [Anonymous], 2008, P 19 INT C PATT REC
   [Anonymous], 2009, Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games, I3D'09, DOI DOI 10.1145/1507149.1507181
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   Chao MW, 2012, IEEE T VIS COMPUT GR, V18, P729, DOI 10.1109/TVCG.2011.53
   Chiu CY, 2004, J VIS COMMUN IMAGE R, V15, P446, DOI 10.1016/j.jvcir.2004.04.004
   Choi MG, 2012, COMPUT GRAPH FORUM, V31, P2057, DOI 10.1111/j.1467-8659.2012.03198.x
   Gleicher M, 1997, P 1997 S INT 3D GRAP
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Huang TY, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P209
   Jain S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477936
   Johnson M.P., 1999, CHI'99 Proceedings, P152
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Li Q., 2006, Proceedings of SCA 2006, P233
   Min J., 2010, P 2010 ACM SIGGRAPH, DOI [10.1145/1730804.1730811, DOI 10.1145/1730804.1730811]
   Min JY, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640452
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Numaguchi Naoki, 2011, P 2011 ACM SIGGRAPH, P157
   Peng JY, 2007, COMPUT ANIMAT VIRT W, V18, P549, DOI 10.1002/cav.208
   Pullen K, 2002, ACM T GRAPHIC, V21, P501
   Qi T, 2013, COMPUT ANIMAT VIRT W, V24, P399, DOI 10.1002/cav.1505
   Sun C, 2011, COMPUT GRAPH FORUM, V30, P1953, DOI 10.1111/j.1467-8659.2011.02048.x
   SUNG M., 2005, SCA 05, P291
   Tak S, 2005, ACM T GRAPHIC, V24, P98, DOI 10.1145/1037957.1037963
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
   Zhu M Y, 2012, P 2012 ACM SIGGRAPH, P183, DOI [10.2312/SCA/SCA12/183-192, DOI 10.2312/SCA/SCA12/183-192]
NR 28
TC 5
Z9 5
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 273
EP 281
DI 10.1002/cav.1602
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300008
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Rantanen, MT
   Juhola, M
AF Rantanen, Mika T.
   Juhola, Martti
TI Using probabilistic roadmaps in changing environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE path planning; probabilistic roadmaps; changing environments; obstacle
   avoidance
ID CONFIGURATION-SPACE; GENERAL FRAMEWORK
AB In this paper, we examine how a path planning problem can be solved in changing environments using probabilistic roadmap planners. A probabilistic roadmap is built in static environment where all obstacles are known in advance, but we show that a roadmap can be built in such a way that it works well even when new obstacles are added to the workspace. However, our experiments show that the roadmap graph must be built carefully. We compare three different methods that are used to decide which edges are added to the roadmap graph to connect the nodes. One of these is a distance-based method, which we present in this paper. In the tests, we built a roadmap by using only the static obstacles. Then, we added additional obstacles to the environment and tested how well the roadmap still worked. The tests showed that our distance-based method worked quickly and that it produced roadmaps, which could be used to find a path amid additional obstacles with a high success rate.Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Rantanen, Mika T.; Juhola, Martti] Univ Tampere, Sch Informat Sci, FI-33014 Tampere, Finland.
C3 Tampere University
RP Rantanen, MT (corresponding author), Univ Tampere, Sch Informat Sci, FI-33014 Tampere, Finland.
EM mika.t.rantanen@uta.fi
FU Tampere Doctoral Programme in Information Science and Engineering
FX The research of the first author was supported by the Tampere Doctoral
   Programme in Information Science and Engineering.
CR Amato NM, 1998, ROBOTICS: THE ALGORITHMIC PERSPECTIVE, P155
   [Anonymous], 1979, 20 ANN S FDN COMP SC, DOI [10. 1109/sfcs.1979.10, DOI 10.1109/SFCS.1979.10]
   [Anonymous], 2012, Robot Motion Planning
   [Anonymous], ALGORITHMS NETWORKIN
   [Anonymous], 1987, The complexity of robot motion planning
   Bohlin R., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P521, DOI 10.1109/ROBOT.2000.844107
   Boor V, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1018, DOI 10.1109/ROBOT.1999.772447
   Burgard W., 2005, Principles of Robot Motion: Theory, Algorithms, and Implementations
   Geraerts R, 2006, ROBOT AUTON SYST, V54, P165, DOI 10.1016/j.robot.2005.09.026
   Geraerts R, 2007, ROBOT AUTON SYST, V55, P824, DOI 10.1016/j.robot.2007.06.002
   Geraerts R, 2007, COMPUT ANIMAT VIRT W, V18, P107, DOI 10.1002/cav.166
   Hsu D, 2003, IEEE INT CONF ROBOT, P4420
   Jaillet L., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P1606
   Jimenez P, 1998, ROBOT MOTION PLANNIN
   KAVRAKI L, 1994, IEEE INT CONF ROBOT, P2138, DOI 10.1109/ROBOT.1994.350966
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Kuffner J. J.  Jr., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P995, DOI 10.1109/ROBOT.2000.844730
   Larsen E., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3719, DOI 10.1109/ROBOT.2000.845311
   LaValle S.M., 1998, RAPIDLY EXPLORING RA, V129, P98
   LaValle S. M., 2006, Planning algorithms
   Lien JM, 2003, IEEE INT CONF ROBOT, P4439
   Lin Y, 2006, 2006 9 INT C CONTROL, P1, DOI DOI 10.1109/ICARCV.2006.345422
   Lopez T, 2012, COMPUT ANIMAT VIRT W, V23, P87, DOI 10.1002/cav.1428
   LOZANOPEREZ T, 1983, IEEE T COMPUT, V32, P108, DOI 10.1109/TC.1983.1676196
   McMahon T, 2012, IEEE INT C INT ROBOT, P4441, DOI 10.1109/IROS.2012.6386061
   Morales M, 2005, SPRINGER TRAC ADV RO, V17, P361
   Nieuwenhuisen D, 2004, IEEE INT CONF ROBOT, P446, DOI 10.1109/ROBOT.2004.1307190
   Nieuwenhuisen Dennis, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3295, DOI 10.1109/IROS.2007.4398976
   Overmars MH, 1992, RUUCS9293 UTR U
   Rantanen MT, 2012, INT J AUTOM COMPUT, V9, P155, DOI 10.1007/s11633-012-0628-2
   Schwartz J.T., 1987, PLANNING GEOMETRY CO
   Siméon T, 2000, ADV ROBOTICS, V14, P477, DOI 10.1163/156855300741960
   Snook G., 2000, Game Programming Gems, P288
   Sud A, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P99
   van den Berg J. P., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P1053, DOI 10.1109/IROS.2005.1545339
NR 35
TC 7
Z9 8
U1 4
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2014
VL 25
IS 1
BP 17
EP 31
DI 10.1002/cav.1528
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AA4LQ
UT WOS:000331067500003
DA 2024-07-18
ER

PT J
AU Jaklin, N
   Cook, A
   Geraerts, R
AF Jaklin, Norman
   Cook, Atlas
   Geraerts, Roland
TI Real-time path planning in heterogeneous environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE path planning; autonomous agents; heterogeneous virtual environments
ID SHORTEST PATHS; ALGORITHM
AB Modern virtual environments can contain a variety of characters and traversable regions. Each character may have different preferences for the traversable region types. Pedestrians may prefer to walk on sidewalks, but they may occasionally need to traverse roads and dirt paths. By contrast, wild animals might try to stay in forest areas, but they are able to leave their protective environment when necessary. This paper presents a novel path planning method named Modified Indicative Routes and Navigation (MIRAN) that takes a character's region preferences into account. Given an indicative route as a rough estimation of a character's preferred route, MIRAN efficiently computes a visually convincing path that is smooth, keeps clearance from obstacles, avoids unnecessary detours, and allows local changes to avoid other characters. To the best of our knowledge, MIRAN is the first path planning method that supports the aforementioned features while using an exact representation of the navigable space. Experiments show that with our approach, a wide range of different character behaviors can be simulated. It also overcomes problems that occur in previous path planning methods such as the Indicative Route Method. The resulting paths are well suited for real-time simulations and gaming applications. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Jaklin, Norman] Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.
   [Geraerts, Roland] Univ Utrecht, Dept Informat & Comp Sci, Games & Virtual Worlds Grp, Utrecht, Netherlands.
   [Cook, Atlas] Univ Texas Austin, Inst Computat Engn & Sci, Austin, TX 78712 USA.
C3 Utrecht University; Utrecht University; University of Texas System;
   University of Texas Austin
RP Jaklin, N (corresponding author), Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.
EM N.S.Jaklin@uu.nl
RI Geraerts, Roland/B-3859-2016
FU COMMIT project; COMMANDS project; European Design Center; Netherlands
   Forensic Institute
FX This research has been supported by the COMMIT project
   (http://www.commit-nl.nl/) and the COMMANDS project in cooperation with
   the European Design Center (http://www.edc.nl/) and the Netherlands
   Forensic Institute (http://www.forensicinstitute.nl/). Norman Jaklin and
   Roland Geraerts are part of the Institute of Information and Computing
   Sciences, Utrecht University, 3584 CC Utrecht, the Netherlands. Atlas
   Cook IV is part of the Institute for Computational Engineering and
   Sciences at the University of Texas at Austin, USA.
CR Aleksandrov L, 2005, J ACM, V52, P25, DOI 10.1145/1044731.1044733
   ALEKSANDROV L, 1998, P 6 SCAND WORKSH ALG, P11
   Aleksandrov L, 2010, DISCRETE COMPUT GEOM, V44, P762, DOI 10.1007/s00454-009-9204-0
   [Anonymous], 2009, P 4 INT C FDN DIGITA, DOI DOI 10.1145/1536513.1536540
   [Anonymous], 2012, Robot Motion Planning
   BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025
   Burgard W., 2005, Principles of Robot Motion: Theory, Algorithms, and Implementations
   De Carufel J. L., 2012, EUR WORKSH COMP GEOM, P65
   Geraerts R, 2010, IEEE INT CONF ROBOT, P1997, DOI 10.1109/ROBOT.2010.5509263
   Guo Y, 2003, IEEE IND ELEC, P2811
   Harabor D, 2008, 2008 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND GAMES, P258, DOI 10.1109/CIG.2008.5035648
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Kang SJ, 2010, VISUAL COMPUT, V26, P467, DOI 10.1007/s00371-010-0457-7
   Karamouzas I., 2012, THESIS UTRECHT U
   LaValle S. M., 2006, Planning algorithms
   Lo W.Y., 2012, PROC EUROGRAPHICSACM, P145
   Mata C. S., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P264, DOI 10.1145/262839.262983
   MITCHELL JSB, 1991, J ACM, V38, P18, DOI 10.1145/102782.102784
   Reif J, 2000, ALG COMP ROB NEW DIR
   Roland G., 2008, Comput. Animation Social Agents, P64
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Sun Z, 2001, LECT NOTES COMPUT SC, V2223, P160
   van Toll W, 2011, IEEE INT C INT ROBOT, P3526, DOI 10.1109/IROS.2011.6048397
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   Yahja A, 2000, ROBOT AUTON SYST, V32, P129, DOI 10.1016/S0921-8890(99)00114-1
NR 25
TC 12
Z9 13
U1 0
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 285
EP 295
DI 10.1002/cav.1511
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, WZ
   Di, ZC
   Allbeck, JM
AF Li, Weizi
   Di, Zichao
   Allbeck, Jan M.
TI Crowd distribution and location preference
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE CVT; virtual humans; functional populace
AB Most crowd simulators focus on navigation and agents flow. In this paper, we present another perspective that concentrates on the overall distribution of virtual agents and uses psychological preferences for choosing goal locations. Both observation and published theory indicate that most people prefer to maintain their personal space as event spaces increase in density, particularly when they have no previous relationship to other individuals. The geometric structure that naturally forms could be highly approximated by a Voronoi tessellation. Our method allows users to specify sub-regions of an environment and tag the regions with information (e.g., permitted densities and features). A Centroidal Voronoi Tessellation (CVT) is then automatically constructed over the entire virtual world. The centers of mass of each resulting cell are taken as potential agent goal locations. Individual virtual agents then have the ability to choose their preferred goal locations on the basis of their own characteristics (e.g., personality traits, needs, and interests), the CVT, and semantic features of the sub-regions. This method results in more meaningful crowd simulations with minimal additional user effort. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Li, Weizi] George Mason Univ, Dept Comp Sci, Lab Games & Intelligent Animat, Fairfax, VA 22030 USA.
C3 George Mason University
RP Li, WZ (corresponding author), George Mason Univ, Dept Comp Sci, Lab Games & Intelligent Animat, 4400 Univ Dr,MSN 4A5, Fairfax, VA 22030 USA.
EM wlia@gmu.edu
OI Di, Zichao/0000-0002-4131-9363
FU U.S. Army SUBTLE MURI [W911NF-07-1-0216]
FX Partial support for this effort is gratefully acknowledged from the U.S.
   Army SUBTLE MURI W911NF-07-1-0216. We also appreciate donations from
   Autodesk.
CR [Anonymous], 2009, P 2009 S INTERACTIVE, DOI DOI 10.1145/1507149.1507184
   [Anonymous], 1996, 5 FACTOR MODEL PERSO
   [Anonymous], P SIGGRAPH
   Champagne J., 2005, EG UK THEORY PRACTIC, P195
   Chen YQ, 2005, IEEE DECIS CONTR P, P5662
   Di ZC, 2012, NUMER MATH-THEORY ME, V5, P242, DOI 10.4208/nmtma.2012.m1046
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   Du Q, 2010, NUMER MATH-THEORY ME, V3, P119, DOI 10.4208/nmtma.2010.32s.1
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Farenc N, 1999, COMPUT GRAPH FORUM, V18, pC309, DOI 10.1111/1467-8659.00351
   Galindo C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2278, DOI 10.1109/IROS.2005.1545511
   Gu Q., 2011, Graphics Interface 2011, P266, DOI DOI 10.5555/1992917.1992919
   HONDA H, 1978, J THEOR BIOL, V72, P523, DOI 10.1016/0022-5193(78)90315-6
   Hu HB, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P52
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Maslow AH, 1943, PSYCHOL REV, V50, P370, DOI 10.1037/h0054346
   Narain R, 2009, P 2009 ACM SIGGRAPH, V122, P8
   Nash SG, 1984, TN TNBC SOFTWARE
   Nash SG, 1991, SIAM J OPTIMIZ, V1, P358, DOI 10.1137/0801023
   Obermeyer KJ, 2011, INT J ROBUST NONLIN, V21, P1467, DOI 10.1002/rnc.1700
   Pelechano J., 2005, 1 INT WORKSHOP CROWD, P21
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pelechano Nuria., 2008, Virtual Crowds: Methods, Simulation, and Control
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Shum HPH, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P131
   Sud A, 2008, IEEE T VIS COMPUT GR, V14, P526, DOI 10.1109/TVCG.2008.27
   SUNG M., 2005, SCA 05, P291
   SUZUKI A, 1986, J OPER RES SOC JPN, V29, P69, DOI 10.15807/jorsj.29.69
   Thalmann Daniel., 2007, CROWD SIMULATION
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Weizi Li, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P132, DOI 10.1007/978-3-642-25090-3_12
   Zheng LP, 2011, IEEE INT CONF ROBOT, P2281
NR 35
TC 3
Z9 7
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 343
EP 351
DI 10.1002/cav.1447
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100021
DA 2024-07-18
ER

PT J
AU Liao, SH
   Tong, RF
   Geng, JP
   Tang, M
AF Liao, Sheng-hui
   Tong, Ruo-feng
   Geng, Jian-Ping
   Tang, Min
TI Inhomogeneous volumetric Laplacian deformation for rhinoplasty planning
   and simulation system
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE individual prosthesis design; inhomogeneous material; rhinoplasty; soft
   tissue deformation; volumetric Laplacian
AB This paper presents an intuitive rhinoplasty planning and simulation system, to provide high quality prediction of postoperative appearance, and design patient specific nose prosthesis automatically. The key component is a novel volumetric Laplacian deformation tool inspired by the state-of-the-art differential surface deformation techniques. Working on the volumetric domain and incorporating inhomogeneous material from CT data make the new approach suitable for soft tissue simulation. In particular, the system employs a special sketch contour driving deformation interface, which can provide realistic 3D rhinoplasty simulation with intuitive and straightforward 2D manipulation. When satisfied with the appearance, the change of soft tissue before and after simulation is utilized to generate the individual prosthesis model automatically. Clinical validation using post-operative CT data demonstrated that the system can provide prediction results of high quality. And the surgeons who used the system confirmed that this planning system is attractive and has potential for daily clinical practice. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Liao, Sheng-hui] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Tong, Ruo-feng] Hiroshima Univ, Intelligent Syst & Modeling Lab, Hiroshima 730, Japan.
   [Tong, Ruo-feng] Zhejiang Univ, Dept Comp Sci & Engn, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Hiroshima University; Zhejiang University
RP Liao, SH (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM shliao@zju.edu.cn
RI Tang, Min/KOC-3090-2024
CR [Anonymous], 2004, P 2004 EUR ACM SIGGR
   [Anonymous], 2004, P 2004 ACM SIGGRAPH, DOI DOI 10.1145/1028523.1028541
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Kavagiou Z, 2005, ST HEAL T, V111, P247
   Lee TY, 2001, IEEE T INF TECHNOL B, V5, P271, DOI 10.1109/4233.966102
   Liao SH, 2009, COMPUT GRAPH-UK, V33, P424, DOI 10.1016/j.cag.2009.03.018
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Ozkul T, 2004, COMPUT BIOL MED, V34, P697, DOI 10.1016/j.compbiomed.2003.10.006
   Schnabel J. A., 2001, Information Processing in Medical Imaging. 17th International Conference, IPMI 2001. Proceedings (Lecture Notes in Computer Science Vol.2082), P344
   Sifakis E, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P73
   Wang Y., 2003, COMMUN INF SYST, V3, P191, DOI DOI 10.4310/CIS.2003.V3.N3.A4
   Yan HB, 2007, J COMPUT SCI TECH-CH, V22, P147, DOI 10.1007/s11390-007-9020-z
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
NR 14
TC 6
Z9 7
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 331
EP 341
DI 10.1002/cav.347
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400020
DA 2024-07-18
ER

PT J
AU Pan, J
   Zhang, LJ
   Lin, MC
   Manocha, D
AF Pan, Jia
   Zhang, Liangjun
   Lin, Ming C.
   Manocha, Dinesh
TI A hybrid approach for simulating human motion in constrained
   environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE motion capture and retargeting; motion synthesis; path planning
ID MANIPULATION
AB We present a new algorithm to generate plausible motions for high-DOF human-like articulated figures in constrained environments with multiple obstacles. Our approach is general and makes no assumptions about the articulated model or the environment. The algorithm combines hierarchical model decomposition with sample-based planning to efficiently compute a collision-free path in tight spaces. Furthermore, we use path perturbation and replanning techniques to satisfy the kinematic and dynamic constraints on the motion. In order to generate realistic human-like motion, we present a new motion blending algorithm that refines the path computed by the planner with motion capture data to compute a smooth and plausible trajectory. We demonstrate the results of generating motion corresponding to placing or lifting object, walking, and bending for a 38-DOF articulated model. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Pan, Jia] Univ N Carolina, Dept Comp Sci, GAMMA Grp, Chapel Hill, NC 27599 USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Pan, J (corresponding author), Univ N Carolina, Dept Comp Sci, GAMMA Grp, Chapel Hill, NC 27599 USA.
EM panj@cs.unc.edu
OI Manocha, Dinesh/0000-0001-7047-9801
FU Div Of Information & Intelligent Systems; Direct For Computer & Info
   Scie & Enginr [0917040] Funding Source: National Science Foundation
CR ABE Y, 2006, S COMP AN SCA, P195
   Chen Y, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P183, DOI 10.1109/ICIG.2009.82
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Demirel HO, 2007, LECT NOTES COMPUT SC, V4561, P824
   Diankov R., 2008, P ROB SCI SYST RSS, V63, P159
   Drumwright E, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P846, DOI 10.1109/IROS.2006.281735
   Ferguson D, 2006, IEEE INT CONF ROBOT, P1243, DOI 10.1109/ROBOT.2006.1641879
   GIENGER M, 2008, Z KUNSTLICHE INTELLI, V4, P10
   Harada Kensuke, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P4227, DOI 10.1109/IROS.2007.4399209
   Hauser K, 2008, INT J ROBOT RES, V27, P1325, DOI 10.1177/0278364908098447
   Huang Q, 2001, IEEE T ROBOTIC AUTOM, V17, P280, DOI 10.1109/70.938385
   Isto P, 2006, IEEE INT CONF ROBOT, P1249, DOI 10.1109/ROBOT.2006.1641880
   Jain S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477936
   KAGAMI S, 2000, WORKSH ALG FDN ROB, P692
   Kajita S, 2003, IEEE INT CONF ROBOT, P1620, DOI 10.1109/robot.2003.1241826
   KALASIAK M, 2001, J VISUAL COMP ANIMAT, V12, P117
   Kallmann M, 2003, COMPUT GRAPH FORUM, V22, P313, DOI 10.1111/1467-8659.00678
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   KOVAR L, 2003, SCA 03, P214
   Kuffner JJ, 2002, AUTON ROBOT, V12, P105, DOI 10.1023/A:1013219111657
   Laumond JP, 2005, ISATP 2005: IEEE International Symposium on Assembly and Task Planning (ISATP), P132, DOI 10.1109/ISATP.2005.1511462
   PAN J, 2010, INT C ROB A IN PRESS
   PETTRE J, 2008, ACM SIGGRAPH COURS N
   PETTRE J, 2003, SCA 03, P258
   Ren L, 2005, ACM T GRAPHIC, V24, P1090, DOI 10.1145/1073204.1073316
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Saha M, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5960, DOI 10.1109/IROS.2006.282536
   Sentis L, 2006, IEEE INT CONF ROBOT, P2641, DOI 10.1109/ROBOT.2006.1642100
   SHAPIRO A, 2007, S INT 3D GRAPH, P137
   Yamane K, 2004, ACM T GRAPHIC, V23, P532, DOI 10.1145/1015706.1015756
   YOSHIDA E, 2005, INT C HUM ROB, P4227
   ZHANG L, 2009, INT C HUM ROB
NR 32
TC 12
Z9 18
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 137
EP 149
DI 10.1002/cav.365
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Todo, H
   Anjyo, K
   Igarashi, T
AF Todo, Hideki
   Anjyo, Ken
   Igarashi, Takeo
TI Stylized lighting for cartoon shader
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE computer animation; cartoon animation; cartoon shader;
   non-photorealistic rendering; stylized lighting
AB In the context of non-photorealistic imaging, such as digital cel animation, lighting is symbolic and stylized to depict the scene's mood and the geometric or physical features of the objects in the scene. Stylized light and shade should therefore be intentionally animated rather than rigorously simulated. However, it is difficult to achieve smooth animation of light and shade that are stylized with a user's intention, because such stylization cannot be achieved using just conventional 3D lighting. To address this problem, we propose a 3D stylized lighting method, focusing on several stylized effects including straight lighting, edge lighting, and detail lighting Which are important features in hand-drawn cartoon animation. Our method is an extension of the conventional cartoon shader and introduces a light coordinate system for light shape control With smooth animations of light and shade. We also extend a toon mapping process for detailed feature lighting. Having these algorithms in a real-time cartoon shader, our prototype system allows the interactive creation of stylized lighting animations. We show several animation results obtained by our method to illustrate usefulness and effectiveness of our method. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Igarashi, Takeo] Brown Univ, Comp Graph Grp, Providence, RI 02912 USA.
C3 Brown University
RP Todo, H (corresponding author), Univ Tokyo, Bunkyo Ku, Sci Bldg 7,Room 302,7-3-1 Hongo, Tokyo 1130033, Japan.
EM td-rg7@ui.is.s.u-tokyo.ac.jp
RI Igarashi, Takeo/ITT-5921-2023
CR Anjyo Kenichi., 2006, Symposium on Non-photorealistic Animation and Rendering, NPAR '06, P133
   Barla P., 2006, Proceedings of International Symposium on Non-Photorealistic Animation and Rendering, P127, DOI [10.1145/1124728.1124749, DOI 10.1145/1124728.1124749]
   Blinn J., 1978, Proceedings of the 5th annual conference on Computer graphics and interactive techniques-SIGGRAPH'78, V12, P286
   COOK RL, 1984, P 11 ANN C COMP GRAP, P223, DOI DOI 10.1145/800031.808602
   Gooch B., 2001, Non-photorealistic rendering
   Lake A., 2000, Proceedings of the 1st International Symposium on Non-Photorealistic Animation and Rendering New York, NY, USA,, P13
   Mitchell J, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P71
   Oliveira MM, 2000, COMP GRAPH, P359, DOI 10.1145/344779.344947
   Petrovic L, 2000, COMP GRAPH, P511, DOI 10.1145/344779.345073
   Ritschel T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360689
   Rusinkiewicz S, 2006, ACM T GRAPHIC, V25, P1199, DOI 10.1145/1141911.1142015
   Sloan Peter-Pike., 2001, Proc. Graphics Interface, P143
   Todo H, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276399, 10.1145/1239451.1239468]
NR 13
TC 2
Z9 2
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 143
EP 152
DI 10.1002/cav.301
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700008
DA 2024-07-18
ER

PT J
AU Gillies, M
   Pan, X
   Slater, M
   Shawe-Taylor, J
AF Gillies, M.
   Pan, X.
   Slater, M.
   Shawe-Taylor, J.
TI Responsive listening behavior
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Computer animation; non-verbal behavior; motion capture; machine
   learning
ID MOTION; ANIMATION; STYLE
AB Humans use their bodies in a highly expressive way during conversation, and animated characters that lack this form of non-verbal expression call seem stiff and unemotional. An important aspect Of non-verbal expression is that people respond to each others behavior and are highly attuned to picking up this type of response. This is particularly important for the feedback given while listening to some one speak. However, automatically generating this type of behavior is difficult as it is highly complex and subtle. This paper takes a data driven approach to generating interactive social behavior. Listening behavior is motion captured, together with the audio being listened to. These data are used to learn ail animation model of the responses of one person to the other. This allows its to create characters that respond in real-time during a conversation with a real human. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Gillies, M.] Univ London, Dept Comp, Univ London Goldsmiths Coll, London SE14 6NW, England.
   [Pan, X.] UCL, VR Grp, EPSRC Project Empath Avatar, London WC1E 6BT, England.
   [Slater, M.] Univ Barcelona, E-08007 Barcelona, Spain.
   [Shawe-Taylor, J.] Univ Southampton, ISIS Res Grp, Southampton SO9 5NH, Hants, England.
   [Shawe-Taylor, J.] UCL, Ctr Computat Stat & Machine Learning, London WC1E 6BT, England.
C3 University of London; Goldsmiths University London; University of
   London; University College London; UK Research & Innovation (UKRI);
   Engineering & Physical Sciences Research Council (EPSRC); University of
   Barcelona; University of Southampton; University of London; University
   College London
RP Gillies, M (corresponding author), Univ London, Dept Comp, Univ London Goldsmiths Coll, London SE14 6NW, England.
EM m.gillies@gold.ac.uk
RI Pan, Xueni/B-4307-2013; Slater, Mel/M-5210-2014
OI Shawe-Taylor, John/0000-0002-2030-0073; Slater, Mel/0000-0002-6223-0050
FU UK Engineering and Physical Sciences Research Council
FX This work was Supported by the Empathic Avatars project funded by the UK
   Engineering and Physical Sciences Research Council. We thank the member
   of the UCL Department of Computer Science Virtual Environments and
   Computer Graphics research group and the member of the UCL Cewre for
   Computational Statistics, and Machine Learning for their help and
   support. We also thank the anonymous reviewers for their comments and
   suggestions that have improved the paper.
CR [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], ACM CHI 99 C P
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Blumberg B, 2002, ACM T GRAPHIC, V21, P417, DOI 10.1145/566570.566597
   Boersma P., 2018, Praat: doing phonetics by computer, DOI DOI 10.1097/AUD.0B013E31821473F7
   Boersma P., 1993, P I PHONETIC SCI, P97, DOI DOI 10.1371/JOURNAL.PONE.0069107
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Cooper S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239456
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Egges A, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P121, DOI 10.1109/PCCGA.2004.1348342
   GARAU M, 2003, P ACM SIG CHI C HUM
   GLEICHER M, 1997, S INT 3D GRAPH, P139
   GRATCH J, 2001, AGENTS 01, P278
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   HSU E, 2004, 2004 ACM SIGGRAPH EU, P69
   KENDON A, 1970, ACTA PSYCHOL, V32, P100
   Kipp M, 2007, LECT NOTES ARTIF INT, V4722, P15
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee J, 1999, COMP GRAPH, P39
   LEE J, 2004, 2004 ACM SIGGRAPH EU, P79
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   LEE KH, 2007, 2004 ACM SIGGRAPH EU
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Liu CK, 2005, ACM T GRAPHIC, V24, P1071, DOI 10.1145/1073204.1073314
   MAATMAN RM, 2005, INTELLIGENT VIRTUAL
   McCann J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276385, 10.1145/1239451.1239457]
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   NAKANO Y, 2003, ANN M ASS COMP LING
   NEFF M, 2005, ACM SIGGRAPH EUR S C
   PERLIN K, 1995, IEEE T VIS COMPUT GR, V1, P5, DOI 10.1109/2945.468392
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Poggi I, 2005, TEXT SPEECH LANG TEC, V27, P3, DOI 10.1007/1-4020-3051-7_1
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Shiratori T, 2006, COMPUT GRAPH FORUM, V25, P449, DOI 10.1111/j.1467-8659.2006.00964.x
   Stone M, 2004, ACM T GRAPHIC, V23, P506, DOI 10.1145/1015706.1015753
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   TAE HK, 2003, SIGGRAPH 03, P392
   Tak S, 2005, ACM T GRAPHIC, V24, P98, DOI 10.1145/1037957.1037963
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
   TU X, 1994, ANN C SERIES, P43
   VILHJALMSSON HH, 1998, 2 ACM INT C AUT AG
   VINAYAGAMOORTHY V, 2006, EUR C STAL ART REP
NR 44
TC 8
Z9 8
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2008
VL 19
IS 5
BP 579
EP 589
DI 10.1002/cav.267
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 377KO
UT WOS:000261250300005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wang, YZ
   Xu, K
   Xiong, YS
   Cheng, ZQ
AF Wang, Yanzhen
   Xu, Kai
   Xiong, Yueshan
   Cheng, Zhi-Quan
TI 2D shape deformation based on rigid square matching
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE shape deformation; character animation; shape matching; rigid
   transformation; skeletal deformation
AB In this paper, we propose a fast and stable method for 2D shape deformation based on rigid square matching. Our method utilizes uniform quadrangular control meshes for 2D shapes and tries to maintain the rigidity of each square in the control mesh during user manipulation. A rigid shape matching method is performed to find an optimal pure rotational transformation for each square in the control mesh. An iterative solver is proposed to compute the final deformation result for the entire control mesh by minimizing the difference between the deformed vertices and their counterparts in the neighboring rigid square. The deformation result on the 2D shape is as rigid as possible and the details of the shape are preserved well. As extensions, we present a shape-aware splitting method to improve the deformation effect for coarse meshes and a simple sketch-based clustering method for skeletal deformation. Experiments with various 2D shapes show that our method is efficient and easy to use, and can provide physically plausible result for shapes of objects in real world. Therefore, our shape deformation method is especially suitable for applications in cartoon character animation. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Wang, Yanzhen; Xiong, Yueshan; Cheng, Zhi-Quan] Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Wang, YZ (corresponding author), Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Hunan, Peoples R China.
EM yanzhen.wang@gmail.com
CR [Anonymous], 1997, TR9719 MITS EL RES L
   AU OKC, 2005, HKUSTCS0510
   Botsch M, 2007, COMPUT GRAPH FORUM, V26, P339, DOI 10.1111/j.1467-8659.2007.01056.x
   BRUCE HT, 1995, P UIST 95, P3
   CELNIKER G, 1991, COMP GRAPH, V25, P257, DOI 10.1145/127719.122746
   FORSTMANN S, 2007, P EUR ACM SIGGRAPH S, P141
   HUANG J, 2006, P ACM SIGGRAPH 2006, P1126
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   JU T, 2003, SGP 03 P 2003 EUR AC, P166
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   MacCracken Ron., 1996, SIGGRAPH, P181, DOI DOI 10.1145/237170.237247
   Milliron T, 2002, ACM T GRAPHIC, V21, P20, DOI 10.1145/504789.504791
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Ngo T, 2000, COMP GRAPH, P403, DOI 10.1145/344779.344964
   Rivers AR, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239533
   Schaeffer V, 2006, SHOCK, V25, P18, DOI 10.1097/00024382-200606001-00056
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Sheffer A, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P68
   Smythe D.B., 1990, 1030 ILM COMP GRAPH
   Weng YL, 2006, VISUAL COMPUT, V22, P653, DOI 10.1007/s00371-006-0054-y
   Yan HB, 2008, IEEE T VIS COMPUT GR, V14, P693, DOI 10.1109/TVCG.2008.28
NR 21
TC 10
Z9 13
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 411
EP 420
DI 10.1002/cav.251
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200023
DA 2024-07-18
ER

PT J
AU Kallmann, M
AF Kallmann, Marcelo
TI Analytical inverse kinematics with body posture control
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE analytical inverse kinematics; character animation; reaching
AB This paper presents a novel whole-body analytical inverse kinematics (IK) method integrating collision avoidance and customizable body control for animating reaching tasks in real-time. Whole-body control is achieved with the interpolation of pre-designed key body postures, which are organized as a function of the direction to the goal to be reached. Arm postures are computed by the analytical IK solution for human-like arms and legs, extended with a new simple search method for achieving postures avoiding joint limits and collisions. In addition, a new IK resolution is presented that directly solves for joints parameterized in the swing-and-twist decomposition. The overall method is simple to implement,fast, and accurate, and therefore suitable for interactive applications controlling the hands of characters. The source code of the IK implementation is provided. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Univ Calif, Sch Engn, Merced, CA 95343 USA.
C3 University of California System; University of California Merced
RP Kallmann, M (corresponding author), Univ Calif, Sch Engn, 5200 N Lake Rd, Merced, CA 95343 USA.
EM mkallmann@ucmerced.edu
RI Kallmann, Marcelo/HSC-7222-2023
CR Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Baerlocher P, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P323, DOI 10.1109/IROS.1998.724639
   BAERLOCHER P, 2000, P AVATARS C LAUS SWI
   BAERLOCHER P, 2001, THESIS SWISS FEDERAL
   BODENHEIMER B, 1997, 8 EUR COMP AN SIM WO
   Bodenheimer Bobby., 1997, COMPUTER ANIMATION S, P3
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Buss S. R., 2005, Journal of Graphics Tools, V10, P37
   DEVILLERS O, 2001, ACM S COMPUTATIONAL, P106
   ElKoura G., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P110
   Girard M., 1985, P SIGGRAPH, P263
   Grassia F. S., 1998, J. Graph. Tools, V6, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   GUIBAS L, 1985, ACM T GRAPHIC, V4, P74, DOI 10.1145/282918.282923
   KALLMANN M, 2005, P ART INT INT DIG EN, P69
   Korein JamesU., 1985, GEOMETRIC INVESTIGAT
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   Preparata F.P., 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   Rose CF, 2001, COMPUT GRAPH FORUM, V20, pC239
   Schaal S., 2002, The handbook of brain theory and neural networks, P110
   SOECHTING JF, 1989, J NEUROPHYSIOL, V62, P582, DOI 10.1152/jn.1989.62.2.582
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   Tolani D, 1996, PRESENCE-TELEOP VIRT, V5, P393, DOI 10.1162/pres.1996.5.4.393
   Watt A., 1992, ADV ANIMATION RENDER
   WELMAN C, 1993, THESIS SIMON FRASER
   Wiley DJ, 1997, IEEE COMPUT GRAPH, V17, P39, DOI 10.1109/38.626968
   Yamane K, 2003, IEEE T VIS COMPUT GR, V9, P352, DOI 10.1109/TVCG.2003.1207443
   ZHAO JM, 1994, ACM T GRAPHIC, V13, P313, DOI 10.1145/195826.195827
NR 33
TC 40
Z9 49
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2008
VL 19
IS 2
BP 79
EP 91
DI 10.1002/cav.176
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 296PY
UT WOS:000255559500002
DA 2024-07-18
ER

PT J
AU Conde, T
   Thalmann, D
AF Conde, Toni
   Thalmann, Daniel
TI An integrated perception for autonomous virtual agents: active and
   predictive perception
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE perception; virtual sensors; virtual environment; autonomous virtual
   agents
AB This paper presents an original model With methodologies that integrate in a novel Way different types of an autonomous virtual agent's perception in a virtual environment. Our first new approach permits the coherent management of the shared virtual environment for the simulations of an autonomous virtual agent (AVA). Our second approach allows the prediction or the estimation of both the orientation and the attention Of an AVA in a virtual environment. By means of a test application With a 'virtual goalkeeper', We demonstrate the speed and the robustness Of our technique. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Ecole Polytech Fed Lausanne, Virtual Real Lab, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Conde, T (corresponding author), Ecole Polytech Fed Lausanne, Virtual Real Lab, CH-1015 Lausanne, Switzerland.
EM toni.conde@epfl.ch
RI Thalmann, Daniel/AAL-1097-2020; Thalmann, Daniel/A-4347-2008
OI Thalmann, Daniel/0000-0002-0451-7491; 
CR [Anonymous], 1996, The Emotional Brain
   BERSINI H, 1994, P 3 INT C SIM AD BEH, P325
   Berthoz A., 1997, The Brain's Sense of Movement
   BORDEUX C, 1999, P EUR 99 MIL IT, P23
   Conde T, 2004, COMPUT ANIMAT VIRT W, V15, P311, DOI 10.1002/cav.34
   Courty N, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1024
   GILLES M, 2001, TR522 1 CAMBR COMP L
   ITTI L, 2005, HDB BRAIN THEORY NEU, P1196
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Khullar SC, 2001, AUTON AGENT MULTI-AG, V4, P9, DOI 10.1023/A:1010010528443
   Kuffner JJ, 1999, COMP ANIM CONF PROC, P118, DOI 10.1109/CA.1999.781205
   NOSER H, 1995, COMPUT GRAPH, V19, P7, DOI 10.1016/0097-8493(94)00117-H
   Peters C, 2003, COMP ANIM CONF PROC, P111, DOI 10.1109/CASA.2003.1199311
   Peters C, 2002, COMPUT GRAPH FORUM, V21, P743, DOI 10.1111/1467-8659.00632
   Renault O., 1990, Journal of Visualization and Computer Animation, V1, P18, DOI 10.1002/vis.4340010106
   REYNOLDS CW, 1987, COMPUTER GRAPHICS, V4, P5
   Sutton R., 1998, Reinforcement Learning: An Introduction
   TU X., 1994, P ACM SIGGRAPH 94, P43, DOI DOI 10.1145/192161.192170
NR 18
TC 12
Z9 15
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 457
EP 468
DI 10.1002/cav.148
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400031
OA Green Published
DA 2024-07-18
ER

PT J
AU Wong, WSK
   Baciu, G
AF Wong, WSK
   Baciu, G
TI GPU-based intrinsic collision detection for deformable surfaces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE GPU; collision detection; velocity-based; deformable surfaces;
   triangular meshes
AB An intrinsic collision detection unit (ICDU) forms the bottom-most layer of a collision detection pipeline. The ICDU performs collision detection and computes collision information for primitive feature pairs of objects in a 3D dynamic environment. A significant amount of time can be spent by the ICDU during the collision detection process. In this paper, we extend the ICDU framework to take advantages of the computational power of programmable graphics processors (GPUs). Some components of the ICDU framework consist of time demanding and fine-grained tasks that can be implemented on GPUs. By employing the framework, collision information can be computed accurately, robustly, and efficiently. Experimental results show that the proposed method greatly improves the performance of the ICDU. A collection buffer is proposed for the future enhancement of GPU-based collision detectors. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
EM cswingo@comp.polyu.edu.hk
RI Baciu, George/AAU-7143-2021
OI BACIU, George/0000-0002-1766-6357
CR [Anonymous], SORTING SEARCHING AR
   Baciu G, 1997, FIFTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P51, DOI 10.1109/PCCGA.1997.626171
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   COURSHESNES M, 1995, SIGGRAPH 95 C P ANN, P137
   Govindaraju N.K., 2003, Proc. of Symp. on Geom. Processing, P25
   Kipfer P., 2004, GRAPHICS HARDWARE, P115
   KNOTT D, 2003, GRAPHICS INTERFACE
   KOLB A, 2004, GRAPHICS HARDWARE
   Lennerz C, 1999, SIMULATION IN INDUSTRY'99: 11TH EUROPEAN SIMULATION SYMPOSIUM 1999, P309
   Liu JD, 1996, VISUAL COMPUT, V12, P234
   Moore M., 1988, Computer Graphics, V22, P289, DOI 10.1145/378456.378528
   MYSZKOWSKI K, 1995, VISUAL COMPUT, V11, P497, DOI 10.1007/BF02439645
   PROVOT X, 1995, GRAPH INTER, P147
   Redon S, 2002, COMPUT GRAPH FORUM, V21, P279, DOI 10.1111/1467-8659.t01-1-00587
   VOLINO P, 1994, COMPUT GRAPH FORUM, V13, pC155, DOI 10.1111/1467-8659.1330155
   WONG SK, 2005, THESIS HONG KONG U S
   Wong WSK, 2005, IEEE T VIS COMPUT GR, V11, P329, DOI 10.1109/TVCG.2005.44
   Wong WSK, 2004, PRESENCE-VIRTUAL AUG, V13, P681, DOI 10.1162/1054746043280600
   WONG WSK, 2005, RES J TEXTILE APPARE, V9, P60
   WONG WSK, 2004, VIRTUAL REALITY SOFT, P24
NR 20
TC 6
Z9 7
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 153
EP 161
DI 10.1002/cav.104
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000003
DA 2024-07-18
ER

PT J
AU Bastanfard, A
   Bastanfard, O
   Takahashi, H
   Nakajima, M
AF Bastanfard, A
   Bastanfard, O
   Takahashi, H
   Nakajima, M
TI Toward anthropometrics simulation of face rejuvenation and skin cosmetic
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE facial rejuvenation; image processing; face anthropometry; quotient
   image; inpainting
ID INFORMATION; PERCEPTION; COLOR; SHAPE; AGE
AB Facial rejuvenation is the process of reversing the aging effects on the human face digitally. This paper generalizes a new approach for facial rejuvenation in adults image. Applications of facial rejuvenation are widespread. They include face recognition, education, entertainment, telecommunications, Psychology, criminal objects, Cosmetic arts and it can be used as an aid for medical cosmetics surgery and the reconstruction of the face. This paper proposes a novel facial rejuvenation modeling algorithm with two techniques. These techniques discuss the facial deformation based on the face anthropometrics theory and remove wrinkles based on what we called wrinkles inpainting. For example if we have been given a few different faces, we need to be able to compare the difference between the facial characteristics of the youth and the aged, then from there onwards, define a set of outlines which are going to be the basis of the simulation of Face Rejuvenation. The first is the geometric deformation details like skin texture, which differs between the aged and the youth. The second is anthropometrics data change. It was developed in the face anthropometrics measurement theory. Then together with warping technique we map the characteristics to any other particular persons' face in order to generate more expressive and convincing facial rejuvenation. The original contribution and advantage of this paper are that, the proposed methods are simple to implement, reliable, in which they required only one source image without needing to collect a lot of images and their computation are fast for interactive environment. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Tokyo Inst Technol, Grad Sch Engn, Meguro Ku, Tokyo 1528552, Japan.
C3 Tokyo Institute of Technology
RP Tokyo Inst Technol, Grad Sch Engn, Meguro Ku, 2-12-1 Ookayama, Tokyo 1528552, Japan.
EM besmel@img.cs.titech.ac.jp
RI Bastanfard, Azam/AAX-8571-2020
OI Bastanfard, Azam/0000-0002-7935-819X
CR BASTANFARD A, 2002, P IWAIT, P7
   Boissieux L, 2000, SPRING COMP SCI, P15
   BURT DM, 1995, P ROY SOC B-BIOL SCI, V259, P137, DOI 10.1098/rspb.1995.0021
   CHENG J, 2000, P FAC PLAST SURG CLI, V8, P223
   DEWDNEY AK, 1986, SCI AM, V225, P20
   DOUGLAS D, 1998, P SIGGRAPH 98, P67
   EZAKI T, 1995, AESTH PLAST SURG, V15, P70
   Farkas LG, 1994, Anthropometry of Head and Face, Vsecond
   George PA, 1998, PERCEPTION, V27, P295, DOI 10.1068/p270295
   HOENIG JA, 1995, P FAC PLAST SURG CLI, V6, P205
   KDHLER K, 2002, P ACM SIGGRAPH EUR S, P55
   KOCH RM, 1996, SIGGRAPH, V27, P721
   LEE W, 1999, VISUAL COMPUT, V5, P32
   MARK LS, 1998, PERCEPTION PSYCHOHYS, V2, P117
   MUKAIDA S, 2002, VIIP, P12
   ROWLAND DA, 1995, IEEE COMPUT GRAPH, V15, P70, DOI 10.1109/38.403830
   Tiddeman B, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.946630
   TSCHUMPERL D, 2002, P IEEE SIGN PROC MAG, V19, P15
   WOLBERG D, 1990, DIGITAL IMAGE WARPIN, P187
   Wu Y, 1999, VISUAL COMPUT, V15, P183, DOI 10.1007/s003710050171
   WU Y, 1995, VISUALIZATION COMPUT, V6, P165
   WU Y, 1994, P PAC GRAPH 94, P201
NR 22
TC 38
Z9 38
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 347
EP 352
DI 10.1002/cav.38
PG 6
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700025
DA 2024-07-18
ER

PT J
AU Steele, K
   Cline, D
   Egbert, PK
   Dinerstein, J
AF Steele, K
   Cline, D
   Egbert, PK
   Dinerstein, J
TI Modeling and rendering viscous liquids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th Annual Conference on Computer Animation and Social Agents (CASA
   2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE computer animation; physically-based animation; fluid modeling
AB We present a particle-based algorithm for modeling highly viscous liquids. Using a numerical time-integration of particle acceleration and velocity, we apply external forces to particles and use a convenient organization, the adhesion matrix, to represent forces between different types of liquids and objects. Viscosity is handled by performing a momentum exchange between particle pairs such that momentum is conserved. Volume is maintained by iteratively adjusting particle positions after each time step. We use a two-tiered approach to time stepping that allows particle positions to be updated many times per frame while expensive operations, such as calculating viscosity and adhesion, are done only a few times per frame. The liquid is rendered using an implicit surface polygonization algorithm, and we present an implicit function that convolves the liquid surface with a Gaussian function, yielding a smooth liquid skin. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Brigham Young Univ, Provo, UT 84602 USA.
C3 Brigham Young University
RP Steele, K (corresponding author), Brigham Young Univ, 3366 TMCB, Provo, UT 84602 USA.
EM steele@rivit.cs.byu.edu
NR 0
TC 16
Z9 19
U1 0
U2 1
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 183
EP 192
DI 10.1002/cav.20
PG 10
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 839OZ
UT WOS:000222795700007
DA 2024-07-18
ER

PT J
AU Wang, HT
   Zhang, JJ
   Li, SZ
   Wang, YS
AF Wang, HT
   Zhang, JJ
   Li, SZ
   Wang, YS
TI Shape and texture preserved non-photorealistic rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE non-photorealistic rendering; image-space; computer vision; image
   processing
AB Two approaches, image-space and object-space, exist for non-photorealistic rendering WPM. The object-space approach has an advantage that it is able to access the 3D shape information of the scene with a 3D model. In this paper, we present a non-stroke based image-space technique that has the strength similar to that of the object-space approach, but without involving explicit 3D models. The basic idea is to factorise the Lambertian model to obtain the shape and texture information implicitly contained in the image. We also develop a specific anisotropic low-pass image filter, which can smooth an image without blurring important features. With the developed techniques, we present two NPR styles, the sketching style and the painting style. Although our work does not aim to mimic any specific existing art form, the sketching style can generate effects similar to those of the pen-and-ink and the painting style is able to produce the colour permeating effects of watercolour. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Bournemouth Univ, Media Sch, Natl Ctr Comp Animat, Bournemouth, Dorset, England.
C3 Bournemouth University
RP Bournemouth Univ, Media Sch, Natl Ctr Comp Animat, Bournemouth, Dorset, England.
EM jzhang@bournemouth.ac.uk
RI Li, Mengqi/AAG-6804-2021
CR Agarwala Aseem., 2002, Proceedings of the 2nd international symposium on Non-photorealistic animation and rendering, P139
   [Anonymous], P SIGGRAPH
   ARCHAMBAULT C, 2000, P 1 INT S NONPH AN R, P116
   Buck I., 2000, Proceedings of the 1st international symposium on Non-photorealistic animation and rendering, NPAR '00, P101
   GIRSHICK A, 2000, P 1 INT S NONPH AN R, P43, DOI DOI 10.1145/340916.340922
   Gooch B., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P31, DOI 10.1145/300523.300526
   Gooch B., 2002, P 2 INT S NONPH AN R, P83
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Hertzmann A., 2000, NPAR, P7
   KALNINS RD, 2002, ACM T GRAPHIC, P55
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Klein AW, 2000, COMP GRAPH, P527, DOI 10.1145/344779.345075
   Lake A., 2000, Proceedings of the 1st International Symposium on Non-Photorealistic Animation and Rendering New York, NY, USA,, P13
   Litwinowicz P., 1997, Proceedings of the 24th annual conference on Computer graphics and interactive techniques, SIGGRAPH '97, P407
   MARKOSIAN L, 1997, P SIGGRAPH 97, P415
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Raskar Ramesh., 2001, Proceedings of the ACM SIGGRAPH/EUROGRAPHICS workshop on Graphics hardware, HWWS '01, P41, DOI DOI 10.1145/383507.383525
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   SHIRAISHI M, 2000, P 1 INT S NONPH AN R, P53, DOI DOI 10.1145/340916.340923
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   WANG H, 2004, 6 INT C AUT FAC GEST
   WINKENBACH C, 1994, P 21 ANN C COMP GRAP, P91
   WINKENBACH G, 1996, P SIGGRAPH 96, P469
NR 23
TC 7
Z9 10
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 453
EP 461
DI 10.1002/cav.49
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700036
DA 2024-07-18
ER

PT J
AU Zhu, XQ
   Yao, XS
   Zhang, JJ
   Zhu, MY
   You, LH
   Yang, XS
   Zhang, JJ
   Zhao, H
   Zeng, D
AF Zhu, Xiaoqiang
   Yao, Xinsheng
   Zhang, Junjie
   Zhu, Mengyao
   You, Lihua
   Yang, Xiaosong
   Zhang, Jianjun
   Zhao, He
   Zeng, Dan
TI TMSDNet: Transformer with multi-scale dense network for single and
   multi-view 3D reconstruction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deep learning; multi-scale; single-view and multi-view 3D
   reconstruction; transformer
AB 3D reconstruction is a long-standing problem. Recently, a number of studies have emerged that utilize transformers for 3D reconstruction, and these approaches have demonstrated strong performance. However, transformer-based 3D reconstruction methods tend to establish the transformation relationship between the 2D image and the 3D voxel space directly using transformers or rely solely on the powerful feature extraction capabilities of transformers. They ignore the crucial role played by deep multi-scale representation of the object in the voxel feature domain, which can provide extensive global shape and local detail information about the object in a multi-scale manner. In this article, we propose a novel framework TMSDNet (transformer with multi-scale dense network) for single-view and multi-view 3D reconstruction with transformer to solve this problem. Based on our well-designed combined-transformer Block, which is canonical encoder-decoder architecture, voxel features with spatial order can be extracted from the input image, which are used to further extract multi-scale global features in parallel using a multi-scale residual attention module. Furthermore, a residual dense attention block is introduced for deep local features extraction and adaptive fusion. Finally, the reconstructed objects are produced with the voxel reconstruction block. Experiment results on the benchmarks such as ShapeNet and Pix3D datasets demonstrate that TMSDNet outperforms the existing state-of-the-art reconstruction methods substantially.
C1 [Zhu, Xiaoqiang; Yao, Xinsheng; Zhang, Junjie; Zhu, Mengyao; Zeng, Dan] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
   [Zhu, Xiaoqiang; You, Lihua; Yang, Xiaosong; Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Bournemouth, England.
   [Zhao, He] R&D Dept Changzhou Microintelligence Co Ltd, Changzhou, Jiangsu, Peoples R China.
   [Zhang, Junjie] Shanghai Univ, Sch Commun & Informat Engn, 99 Shangda Rd, Shanghai, Peoples R China.
C3 Shanghai University; Bournemouth University; Shanghai University
RP Zhang, JJ (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, 99 Shangda Rd, Shanghai, Peoples R China.
EM junjie_zhang@shu.edu.cn
OI Yao, Xinsheng/0009-0004-2808-6042
FU European Unions Horizon 2020 research and innovation programme under the
   Marie Skodowska-Curie [778035]; PDE-GIR project
FX The authors would like to thank Zai Shi for his critical support with
   the open source distribution of the code, Patrick Min for his important
   help with voxel visualization, and Xiaoxiao Liu, Baojun Hou for their
   helpful suggestions. Lihua You and Jian J Zhang were supported by the
   PDE-GIR project, which had received funding from the European Unions
   Horizon 2020 research and innovation programme under the Marie
   Skodowska-Curie grant agreement No 778035.
CR Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712
   Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464
   Bian W., 2022, P 32 BRIT MACH VIS C
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chang Angel X., 2015, arXiv
   Chen Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13067, DOI 10.1109/ICCV48922.2021.01284
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dai J., 2021, ICLR
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298
   Insafutdinov E, 2018, ADV NEUR IN, V31
   Kar A., 2017, P ADV NEUR INF PROC, P364
   Kingma D. P., 2013, ARXIV13126114
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Xi Li, 2021, 2021 International Conference on Culture-oriented Science & Technology (ICCST), P343, DOI [10.1109/CBFD52659.2021.00076, 10.1109/ICCST53801.2021.00078]
   Li Y., 2022, P IEEE CVF C COMP VI, P4804
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Liu SK, 2018, INT CONF 3D VISION, P542, DOI 10.1109/3DV.2018.00068
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Lu T, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131588
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Özyesil O, 2017, ACTA NUMER, V26, P305, DOI 10.1017/S096249291700006X
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Paschalidou D, 2018, PROC CVPR IEEE, P3897, DOI 10.1109/CVPR.2018.00410
   Peng K, 2022, IEEE COMPUT SOC CONF, P221, DOI 10.1109/CVPRW56347.2022.00036
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Richter SR, 2018, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR.2018.00207
   Sitzmann V, 2019, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2019.00254
   Stier N, 2021, INT CONF 3D VISION, P320, DOI 10.1109/3DV53792.2021.00042
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Tiong LCO., 2022, P ASIAN C COMPUTER V, P1438
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5702, DOI 10.1109/ICCV48922.2021.00567
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang W, 2019, ADV NEUR IN, V32
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu JJ, 2016, ADV NEUR IN, V29
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Xie HZ, 2020, INT J COMPUT VISION, V128, P2919, DOI 10.1007/s11263-020-01347-6
   Yagubbayli F., 2021, LEGOFORMER TRANSFORM
   Yan YT, 2021, IEEE ACCESS, V9, P52202, DOI 10.1109/ACCESS.2021.3069775
   Yang B, 2020, INT J COMPUT VISION, V128, P53, DOI 10.1007/s11263-019-01217-w
   Zai S., 2021, P BRIT MACH VIS C BM, P405
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
NR 61
TC 1
Z9 1
U1 10
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2201
EA AUG 2023
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001041941900001
OA Bronze
DA 2024-07-18
ER

PT J
AU Sun, LB
   Zhang, XK
   Qin, WH
AF Sun, Libo
   Zhang, Xiaokai
   Qin, Wenhu
TI Research on target recognition and tracking in mobile augmented reality
   assisted maintenance
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE assisted maintenance; augmented reality; SLAM; YOLOv5s
AB The recognition and tracking of maintenance targets is the basis of augmented reality assisted maintenance. To address the problems of the current recognition and tracking algorithms, such as high time complexity, low pose tracking accuracy, and high requirements for hardware equipment, this paper studies a light weight maintenance target recognition algorithm based on YOLOv5s, and then the VI ORB-SLAM algorithm is adopted to track the maintenance target. In addition, the ORB feature extraction and the visual inertial initialization are improved for the VI ORB-SLAM algorithm. Finally, the combined algorithm is deployed on the mobile phone. Taking the augmented reality assisted vehicle maintenance as an example, it is verified that the proposed approach is practical feasible and effective in the actual assisted maintenance scene.
C1 [Sun, Libo; Zhang, Xiaokai; Qin, Wenhu] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Sun, LB; Qin, WH (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
EM sunlibo@seu.edu.cn; qinwenhu@seu.edu.cn
FU Key R&D Program of Jiangsu Province [BE2019311]; Jiangsu Modern
   Agricultural Industry Key Technology Innovation Project [CX(20)2013];
   National Key Research and Development Program [2020YFB160070301]
FX This work was supported by the Key R&D Program of Jiangsu Province under
   Grant BE2019311, Jiangsu Modern Agricultural Industry Key Technology
   Innovation Project under Grant CX(20)2013 and National Key Research and
   Development Program under Grant 2020YFB160070301.
CR Bochkovskiy A., 2020, PREPRINT
   de Souza FJ, 2002, FUZZY SET SYST, V130, P189, DOI 10.1016/S0165-0114(01)00145-2
   Doucet A, 2002, STAT COMPUT, V12, P77, DOI 10.1023/A:1013172322619
   Fujiyoshi H, 2019, IATSS RES, V43, P244, DOI 10.1016/j.iatssr.2019.11.008
   Gomezojeda R., 2015, Computer Science
   Jiang XY, 2020, IEEE T IMAGE PROCESS, V29, P736, DOI 10.1109/TIP.2019.2934572
   Klimant P, 2022, INT J INTERACT DES M, V16, P765, DOI 10.1007/s12008-022-00880-7
   Kuznetsova Anna, 2020, Advances in Neural Networks - ISNN 2020. 17th International Symposium on Neural Networks, ISNN 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12557), P233, DOI 10.1007/978-3-030-64221-1_20
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Liu Z, 2021, IEEE ROBOT AUTOM LET, V6, P3184, DOI 10.1109/LRA.2021.3062815
   Luo C., 2019, OVERVIEW IMAGE MATCH, V1237
   Muja M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P404, DOI 10.1109/CRV.2012.60
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359
   Piao JC, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112567
   Servières M, 2021, J SENSORS, V2021, DOI 10.1155/2021/2054828
   Tan SL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SAFETY FOR ROBOTICS (ISR), P330, DOI 10.1109/ISR50024.2021.9419561
   Vock R, 2019, COMPUT GRAPH-UK, V79, P36, DOI 10.1016/j.cag.2018.12.007
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
   Zubizarreta J, 2019, INT J ADV MANUF TECH, V102, P4095, DOI 10.1007/s00170-019-03527-2
NR 20
TC 1
Z9 1
U1 4
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2022
VL 33
IS 6
AR e2112
DI 10.1002/cav.2112
EA AUG 2022
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6Z9LE
UT WOS:000841805700001
DA 2024-07-18
ER

PT J
AU Chen, ZW
   Lyu, DS
AF Chen, Ziwei
   Lyu, Desheng
TI Procedural generation of virtual pavilions via a deep convolutional
   generative adversarial network
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE generative adversarial network; procedural content generation; virtual
   pavilions
AB Virtual pavilions can help spread culture and bring fun. A virtual pavilion needs a designed map, and terrain editors then manually layout each part of it. Procedural content generation via machine learning can quickly generate virtual pavilion maps to assist in virtual pavilion design. This article proposes adding a self-attention module to some commonly used deep convolutional generative adversarial networks to generate virtual pavilion maps. A three-dimensional(3D) virtual pavilion is built based on these maps, and interactive features are added to make it more experiential. Then the improved and original networks are mainly evaluated in generating maps that are solvable and similar to the training data for finding the best generator. The evaluation results show that our improved methods always perform better on each metric, and the WGAN with a self-attention module is what we need.
C1 [Chen, Ziwei; Lyu, Desheng] Harbin Inst Technol, Sch Architecture, POB 772,92 Xidazhi St, Harbin, Heilongjiang, Peoples R China.
   [Chen, Ziwei; Lyu, Desheng] Minist Culture & Tourism Peoples Republ China, Key Lab Interact Media Design & Equipment Serv In, Harbin, Peoples R China.
C3 Harbin Institute of Technology
RP Lyu, DS (corresponding author), Harbin Inst Technol, Sch Architecture, POB 772,92 Xidazhi St, Harbin, Heilongjiang, Peoples R China.
EM desheng1@hit.edu.cn
FU MOE (Ministry of Education in China) Project of Humanities and Social
   Sciences [17YJAZH058]; National Natural Science Foundation of China
   [61872118]; Fundamental Research Funds for the Central Universities
   [HIT.HSS.201844]
FX MOE (Ministry of Education in China) Project of Humanities and Social
   Sciences, Grant/Award Number: 17YJAZH058; National Natural Science
   Foundation of China, Grant/Award Number: 61872118; Fundamental Research
   Funds for the Central Universities, Grant/Award Number: HIT.HSS.201844
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hayashi M., 2020, AUTOMATIC GENERATION, P642
   Kuang Ping, 2020, Advances in Information and Communication. Proceedings of the 2020 Future of Information and Communication Conference (FICC). Advances in Intelligent Systems and Computing (AISC 1129), P400, DOI 10.1007/978-3-030-39445-5_30
   Lucas SM, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P170, DOI 10.1145/3321707.3321781
   Mallia M., 2018, P INT C VR TECHN CUL, P135
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Park K, 2019, IEEE CONF COMPU INTE, DOI 10.1109/cig.2019.8848085
   Radford A., 2015, ARXIV
   Summerville A., 2016, PROC 1 INT JOINT C D
   Summerville A, 2018, IEEE T GAMES, V10, P257, DOI 10.1109/TG.2018.2846639
   Togelius J, 2011, P 2 INT WORKSH PROC, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   Vincent P, 2008, Mach. Learn., P5
   Volz V, 2018, GECCO'18: PROCEEDINGS OF THE 2018 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P221, DOI 10.1145/3205455.3205517
   Zhang H, 2019, PR MACH LEARN RES, V97
NR 16
TC 1
Z9 1
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2063
DI 10.1002/cav.2063
EA JUN 2022
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000813966600001
DA 2024-07-18
ER

PT J
AU Lin, WY
   Hong, HR
   She, YY
   Yang, BR
AF Lin, Weiyue
   Hong, Haoran
   She, Yingying
   Yang, Baorong
TI Landscape Rippling: Context-based water-mediated interaction design
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; context-based interaction; interactive interface;
   water-mediated interaction
ID ROBOT
AB With a core purpose of helping users to understand the context, a water interface provides possibility for enhancing user experience in interaction process. Starting from analyzing existing water-mediated interaction approaches, we proposed a water-mediated interaction design model and a corresponding user experience model, aiming to eliminate the boundary between users and the context with water as the medium. According to the proposed model, we implemented a water-mediated interaction system Landscape Rippling, with the painting "A Panorama of Rivers and Mountains" as its context. Ultimately, user experience tests of the interaction system demonstrate the effectiveness of this water-mediated interaction design model.
C1 [Lin, Weiyue; Hong, Haoran] Xiamen Univ, Sch Informat, Xiamen, Peoples R China.
   [Lin, Weiyue] Peking Univ, Sch Software & Microelect, Beijing, Peoples R China.
   [Hong, Haoran] Univ Tokyo, Grad Sch Frontier Sci, Chiba, Japan.
   [She, Yingying] Xiamen Univ, Sch Film, Xiamen, Peoples R China.
   [Yang, Baorong] Jimei Univ, Coll Comp Engn, Xiamen, Peoples R China.
C3 Xiamen University; Peking University; University of Tokyo; Xiamen
   University; Jimei University
RP She, YY (corresponding author), Xiamen Univ, Sch Film, Xiamen, Peoples R China.; Yang, BR (corresponding author), Jimei Univ, Coll Comp Engn, Xiamen, Peoples R China.
EM yingyingshe@xmu.edu.cn; yangbaorong@jmu.edu.cn
RI Lin, Weiyue/GYD-9573-2022
OI She, Yingying/0000-0002-6770-4622; yang, baorong/0000-0002-2896-2506
FU Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University [VRLAB2020B16]; Fujian
   Science and Technology Program Guiding Project [2020H0001]; Natural
   Science Foundation of Fujian Province [2021J05170]; Fujian Provincial
   Department of Education [JAT200286]; Scientific Research Start-up Fund
   Project of Jimei University [ZQ2021002]
FX Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University, Grant/Award Number:
   VRLAB2020B16; Fujian Science and Technology Program Guiding Project,
   Grant/Award Number: 2020H0001; Natural Science Foundation of Fujian
   Province, Grant/Award Number: 2021J05170; General Program Funded by
   Fujian Provincial Department of Education, Grant/Award Number:
   JAT200286; Scientific Research Start-up Fund Project of Jimei
   University, Grant/Award Number: ZQ2021002
CR Adikari A., 2017, NONCONTACT HUMAN BOD
   Ahmed S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030527
   Barrett SF., 2020, SYNTHESIS LECT DIG C, V15, P1
   Chen SJ, 2015, LECT NOTES ARTIF INT, V9244, P581, DOI 10.1007/978-3-319-22879-2_53
   Colley A, 2018, MINDTREK'18: PROCEEDINGS OF THE 22ND INTERNATIONAL ACADEMIC MINDTREK CONFERENCE, P248, DOI 10.1145/3275116.3275139
   García JC, 2017, IEEE COMPUT GRAPH, V37, P34, DOI 10.1109/MCG.2015.118
   H?kkil? J., 2016, P 9 NORD C HUM COMP, P1
   Koike H., 2013, P 2013 ACM INT C INT, P155, DOI DOI 10.1145/2512349.2512815
   Krueger JM, 2022, INFORMATION, V13, DOI 10.3390/info13020074
   Landau MJ, 2016, IEEE T CYBERNETICS, V46, P3018, DOI 10.1109/TCYB.2015.2494877
   Lee J.C., 2010, XRDS, V16, P9, DOI [10.1145/1764848.1764853, DOI 10.1145/1764848.1764853]
   Matsuura Y, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3214907.3214919
   Menon Karthik Sudhakaran, 2019, International Journal of Green Computing, V10, P43, DOI 10.4018/IJGC.2019010103
   Mutlu-Bayraktar D, 2019, COMPUT EDUC, V141, DOI 10.1016/j.compedu.2019.103618
   Oppermann L, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'16), P330, DOI 10.1145/2935334.2935368
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Raffe W.L., 2015, P COMP HUM INT PLAY, P295
   Sipani Jay P., 2018, International Journal of Interactive Mobile Technologies, V12, P15, DOI 10.3991/ijim.v12i2.7415
   Song W, 2017, MULTIMED TOOLS APPL, V76, P4357, DOI 10.1007/s11042-016-3523-y
   Villani V, 2017, IFAC PAPERSONLINE, V50, P12753, DOI 10.1016/j.ifacol.2017.08.1829
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 22
TC 1
Z9 1
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2064
DI 10.1002/cav.2064
EA JUN 2022
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000808349000001
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Wu, ZK
   Wang, XC
AF Zhang, Yu
   Wu, Zhongke
   Wang, Xingce
TI Dynamic disk B-spline curves
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE disk B-spline curves; dynamics; finite difference method; physics-based
   model
ID NURBS
AB A disk B-spline curve (DBSC) is an extension of a B-spline curve and is used to represent a two-dimensional (2D) region. DBSC is a useful 2D geometric representation and is widely applied in the 2D art design area, such as computer calligraphy, 2D computer animation, and nonphotorealistic rendering. To enhance the flexibility of DBSC, in this article, we propose a physics-based generalization of DBSC-dynamic DBSC (D-DBSC), which extends the traditional DBSC in the time domain. We give the mathematical expression of D-DBSC and prove its several mathematical properties. We derive the motion equations of D-DBSC based on Lagrangian mechanics and investigate the motion equations when it is under linear geometric constraints. Last, a D-DBSC physical simulation system based on finite difference method is presented.
C1 [Zhang, Yu; Wu, Zhongke; Wang, Xingce] Beijing Normal Univ, Coll Aritficial Intelligence, Xinjiekouwai St 19, Beijing 100875, Peoples R China.
C3 Beijing Normal University
RP Wu, ZK (corresponding author), Beijing Normal Univ, Coll Aritficial Intelligence, Xinjiekouwai St 19, Beijing 100875, Peoples R China.
EM zwu@bnu.edu.cn
FU Beijing Natural Science Foundation of China [4172033]; BRICS of China
   [2017YFE0100500]; National Key R&D Programof China [2017YFB1002604,
   2017YFB1402105]; National Natural Science Foundation of China [61972041]
FX Beijing Natural Science Foundation of China, Grant/Award Number:
   4172033; National Key Cooperation between the BRICS of China,
   Grant/Award Number: 2017YFE0100500; National Key R&D Programof China,
   Grant/Award Numbers: 2017YFB1002604, 2017YFB1402105; National Natural
   Science Foundation of China, Grant/Award Number: 61972041
CR Ao XF, 2018, COMPUT GRAPH-UK, V70, P99, DOI 10.1016/j.cag.2017.07.021
   BLOOR MIG, 1990, COMPUT AIDED DESIGN, V22, P324, DOI 10.1016/0010-4485(90)90083-O
   CELNIKER G, 1991, COMP GRAPH, V25, P257, DOI 10.1145/127719.122746
   Celniker George., 1992, SI3D 92, P165
   da Silva JP, 2013, ARXIV E PRINTS
   Goldstein H., 2002, CLASSICAL MECH
   Gossick B.R., 1967, HAMILTONS PRINCIPLE
   Kardestuncer H., 1987, FINITE ELEMENT HDB
   Kunkli R, 2010, COMPUT AIDED GEOM D, V27, P611, DOI 10.1016/j.cagd.2010.07.003
   Lin Q, 1998, COMPUT AIDED GEOM D, V15, P721, DOI 10.1016/S0167-8396(98)00016-8
   Peternell M, 1997, J SYMB COMPUT, V23, P255, DOI 10.1006/jsco.1996.0087
   Peternell M, 2010, J SYMB COMPUT, V45, P1, DOI 10.1016/j.jsc.2009.06.001
   Pottmann H, 1998, COMPUT AIDED GEOM D, V15, P165, DOI 10.1016/S0167-8396(97)00023-X
   Qin H, 1996, IEEE T VIS COMPUT GR, V2, P85, DOI 10.1109/2945.489389
   Qin H, 1995, THESIS
   Seah HockSoon., 2005, Proceedings of the 2005 ACM SIGCHI International Conference on Advances in Computer Entertainment Technology, P88, DOI [10.1145/1178477.1178489, DOI 10.1145/1178477.1178489]
   TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807
   TERZOPOULOS D, 1994, ACM T GRAPHIC, V13, P103, DOI 10.1145/176579.176580
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Thingvold J. A., 1990, Computer Graphics, V24, P129, DOI 10.1145/91394.91430
   Weisstein E. W., 2011, EULERS HOMOGENEOUS F
   Zhang T., 2015, COMPUT AIDED DES APP, V12, P519
NR 22
TC 3
Z9 3
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1955
DI 10.1002/cav.1955
EA SEP 2020
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000569512500001
DA 2024-07-18
ER

PT J
AU Chen, CY
   Wong, SK
   Liu, WY
AF Chen, Chien-Yuan
   Wong, Sai-Keung
   Liu, Wen-Yun
TI Generation of small groups with rich behaviors from natural language
   interface
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd animation; interactive interface; natural language processing;
   small groups
AB In this article, we develop a system with a natural language interface to generate animation of small groups in environments with ambient crowds. Our system takes simple sentences of English as input and these sentences are parsed to obtain information about character attributes, behaviors, and locations for constructing situation nodes. These situation nodes form an animation graph for producing an animation of small groups. The interface assists in interactively managing and editing the animation graph. We demonstrate the effectiveness of the system in some examples. The user study results indicate that the proposed system is user-friendly and flexible in producing animation of small groups in various scenes.
C1 [Chen, Chien-Yuan; Wong, Sai-Keung; Liu, Wen-Yun] Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Wong, SK (corresponding author), Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
EM cswingo@cs.nctu.edu.tw
FU Ministry of Science and Technology of the ROC [MOST 108-2221-E-009-080]
FX The Ministry of Science and Technology of the ROC, Grant/Award Number:
   MOST 108-2221-E-009-080
CR Agirre E., 2012, P SEM 2012 1 JOINT C, P385
   Aikawa T, 2005, L TC 05 2 LANG TECHN, P1
   Bouali N, 2018, LECT NOTES ARTIF INT, V10948, P424, DOI 10.1007/978-3-319-93846-2_79
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Chang Angel X, 2017, ARXIV170300050
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Cheng J., 2016, LONG SHORT TERM MEMO, DOI DOI 10.18653/V1/D16-1053
   Conneau A., 2017, P 2017 C EMPIRCAL ME, P670, DOI [DOI 10.18653/V1/D17-1070, 10.18653/v1/d17-1070]
   Coyne B, 2001, COMP GRAPH, P487, DOI 10.1145/383259.383316
   Kapadia K, 2016, UROL CASE REP, V9, P15, DOI 10.1016/j.eucr.2016.07.012
   Kapadia Mubbasir., 2016, P ACM SIGGRAPHEUROGR, P199
   Krontiris A., 2016, P 29 INT C COMPUTER, P61
   Li FS, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P101, DOI 10.1145/2993369.2993373
   Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314
   Ma M, 2006, THESIS
   Ma R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275035
   MacCartney B., 2009, Natural Language Inference
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Marelli M., 2014, P 8 INT WORKSH SEM E, P1, DOI DOI 10.3115/V1/S14-2001
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Rusu D., 2007, Proceedings of the 10th International Multiconference Information Society-IS, P8
   Tan ZX, 2018, AAAI CONF ARTIF INTE, P4929
   Ulicny Branislav, 2004, SCA'04'- Proc. of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P243, DOI [DOI 10.2312/SCA/SCA04/243-252, 10.1145/1028523.1028555, DOI 10.1145/1028523.1028555]
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   VENDLER Z, 1957, PHILOS REV, V66, P143, DOI 10.2307/2182371
   Wolinski D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982442
   Wong SK, 2015, COMPUT ANIMAT VIRT W, V26, P387, DOI 10.1002/cav.1636
   Xu W., 2015, Proceedings of the 9th international workshop on semantic evaluation (SemEval 2015), P1, DOI [10.18653/v1/S15-2001, DOI 10.18653/V1/S15-2001]
NR 28
TC 4
Z9 4
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1960
DI 10.1002/cav.1960
EA AUG 2020
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000562014600001
DA 2024-07-18
ER

PT J
AU Tian, Y
   Hu, Y
   Shen, XK
AF Tian, Ye
   Hu, Yong
   Shen, Xukun
TI A multi-GPU finite element computation and hybrid collision handling
   process framework for brain deformation simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE nonlinear finite element method; parallel algorithms; parallel collision
   detection; real time
ID MODELS; TISSUE; ALGORITHM; CONTACT; OBJECTS; SHIFT; FEM
AB This paper offers a fast multi-graphics processing unit (GPU) parallel simulation framework to the problem of real-time and nonlinear finite element computation of brain deformation. A load balancing strategy is proposed to ensure the efficient distribution of nonlinear finite element computation on multi-GPU. A data storage structure is designed to minimize the amount of data transfer and make full use of the overlay technique of GPU to reduce the transferring latency between multi-GPUs. We further present a fast central processing unit (CPU)-GPU parallel continuous collision detection and response method, which not only can deal with the collision between the brain and skull but also can handle the self-collision of the brain. Our method can make full use of CPU and GPU to implement a parallel computation about deformation and collision detection. Our experimental results show that our method is able to handle a brain geometric model with high detail gyrus composed of more than 40,000 tetrahedron elements. This can facilitate the fidelity of the current virtual brain surgery simulator. We evaluate our approach qualitatively and quantitatively and compare it with related works.
C1 [Tian, Ye; Shen, Xukun] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Hu, Yong] Beihang Univ, Sch New Media Art & Design, Beijing, Peoples R China.
   [Shen, Xukun] Beihang Univ, Comp Sch, Beijing, Peoples R China.
C3 Beihang University; Beihang University; Beihang University
RP Hu, Y (corresponding author), Beihang Univ, Beijing, Peoples R China.
EM huyong@buaa.edu.cn
OI tian, ye/0000-0002-9402-0402
FU National High-Tech Research and Development Program of China
   [2013AA013803]
FX National High-Tech Research and Development Program of China,
   Grant/Award Number: 2013AA013803
CR Allard J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778819
   [Anonymous], [No title captured]
   [Anonymous], 1997, J GRAPH TOOLS, DOI DOI 10.1080/10867651.1997.10487480
   Belytschko T., 1983, Computational methods for transient analysis, P1
   Bro-Nielsen M., 1996, Computer Graphics Forum, V15, pC57, DOI 10.1111/1467-8659.1530057
   Courtecuisse H, 2014, MED IMAGE ANAL, V18, P394, DOI 10.1016/j.media.2013.11.001
   da Silva JP, 2015, GRAPH MODELS, V81, P1, DOI 10.1016/j.gmod.2015.07.001
   Ericson C., 2005, Real-time collision detection
   Fan W, 2014, COMPUT GRAPH FORUM, V30, P1451
   Faure F, 2008, P 2008 ACM SIGGRAPH
   Fukuhara A., 2014, ROBOMECH J, DOI 10.1186/s40648-014-0006-7
   GOTTSCHALK S, 1996, P 23 ANN C COMP GRAP
   Gress A, 2006, COMPUT GRAPH FORUM, V25, P497, DOI 10.1111/j.1467-8659.2006.00969.x
   Hecht F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231821
   Heidelberger B., 2004, P VISION MODELING VI, P339
   Hermann E, 2008, 3 INT C COMP GRAPH T
   Hirota G, 2003, VISUAL COMPUT, V19, P291, DOI 10.1007/s00371-002-0188-5
   Joachimschoberl, 2015, NETG MESH GEN
   Joldes GR, 2010, COMPUT METHOD APPL M, V199, P3305, DOI 10.1016/j.cma.2010.06.037
   Kim D, 2009, COMPUT GRAPH FORUM, V28, P1791, DOI 10.1111/j.1467-8659.2009.01556.x
   Kim Y, 2010, 2010 INT C CYB 2010
   Klosowski JT, 1998, IEEE T VIS COMPUT GR, V4, P21, DOI 10.1109/2945.675649
   Kühnapfel U, 2000, COMPUT GRAPH-UK, V24, P671, DOI 10.1016/S0097-8493(00)00070-4
   Lauterbach C, 2010, COMPUT GRAPH FORUM, V29, P419, DOI 10.1111/j.1467-8659.2009.01611.x
   Miga MI, 2015, INT J NUMER METHODS, V43, P955
   Miga MI, 1997, P 19 ANN INT C IEEE
   Miller K, 2002, J BIOMECH, V35, P483, DOI 10.1016/S0021-9290(01)00234-2
   Miller K, 2007, COMMUN NUMER METH EN, V23, P121, DOI 10.1002/cnm.887
   Mirtich B, 1996, S INT 3D GRAPH
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Nvidia, 2016, NVIDIA NSIGHT
   Pabst S, 2010, COMPUT GRAPH FORUM, V29, P1605, DOI 10.1111/j.1467-8659.2010.01769.x
   Roberts DW, 1998, NEUROSURGERY, V43, P749, DOI 10.1097/00006123-199810000-00010
   Sahoo D, 2014, J MECH BEHAV BIOMED, V33, P24, DOI 10.1016/j.jmbbm.2013.08.022
   Sin FS, 2013, COMPUT GRAPH FORUM, V32, P36, DOI 10.1111/j.1467-8659.2012.03230.x
   Skrinjar O, 2002, MED IMAGE ANAL, V6, P361, DOI 10.1016/S1361-8415(02)00062-2
   Sun K., 2014, TRANSLATIONAL ENG HL, V2, P1
   Tang M, 2011, S INT 3D GRAPH GAM I
   Tang M, 2009, 2009 SIAM ACM JOINT
   Tang M, 2008, VISUAL COMPUT, V24, P545, DOI 10.1007/s00371-008-0235-y
   Tang M, 2013, COMPUT GRAPH FORUM, V32, P21, DOI 10.1111/cgf.12208
   Tang M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019630
   Tang M, 2010, GRAPH MODELS, V72, P7, DOI 10.1016/j.gmod.2010.01.001
   Tang M, 2009, IEEE T VIS COMPUT GR, V15, P544, DOI 10.1109/TVCG.2009.12
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Wittek A, 2005, LECT NOTES COMPUT SC, V3750, P583, DOI 10.1007/11566489_72
   Wittek A, 2007, J BIOMECH, V40, P919, DOI 10.1016/j.jbiomech.2006.02.021
   Wittek A, 2009, BIOMECH MODEL MECHAN, V8, P77, DOI 10.1007/s10237-008-0118-1
   Wong S-K, 2014, P 18 M ACM SIGGRAPH
   Wong SK, 2016, VISUAL COMPUT, V32, P67, DOI 10.1007/s00371-014-1056-9
   Wong TH, 2014, VISUAL COMPUT, V30, P729, DOI 10.1007/s00371-014-0954-1
   Wong TH, 2012, VISUAL COMPUT, V28, P829, DOI 10.1007/s00371-012-0706-z
   Wu J, 2013, VISUAL COMPUT, V29, P739, DOI 10.1007/s00371-013-0810-8
   Yang C, 2016, COMPUT AIDED GEOM D, V43, P53, DOI 10.1016/j.cagd.2016.02.014
   Zhang XY, 2014, IEEE T VIS COMPUT GR, V20, P447, DOI 10.1109/TVCG.2013.239
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 56
TC 2
Z9 2
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2019
VL 30
IS 1
AR e1846
DI 10.1002/cav.1846
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8YF
UT WOS:000458275000004
OA Bronze
DA 2024-07-18
ER

PT J
AU Monteiro, D
   Liang, HN
   Xu, WG
   Brucker, M
   Nanjappan, V
   Yue, Y
AF Monteiro, Diego
   Liang, Hai-Ning
   Xu, Wenge
   Brucker, Marvin
   Nanjappan, Vijayakumar
   Yue, Yong
TI Evaluating enjoyment, presence, and emulator sickness in VR games based
   on first- and third- person viewing perspectives
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE first-person; gaming; head-mounted displays; immersion; presence;
   simulator sickness; third-person; virtual reality
AB Many virtual reality (VR) games are based on a first-person perspective (1PP). There are, however, advantages in using another perspective, such as the third-person perspective (3PP). Although there has been some research evaluating the effect of 1PP and 3PP in gameplay experiences, it is largely unexplored for VR games played via the new generation of commercial head-mounted display systems, such as the Oculus Rift. In this research we want to shed some light on the relationship between the different perspectives, when games are played using head-mounted display VR, and simulator sickness, enjoyment, and presence. To do so, we perform an experiment using two different perspectives (1PP and 3PP) and displays (VR and a conventional display) with a popular game. Our findings indicate that 3PP-VR is less likely to make people have simulator sickness when compared with 1PP-VR. However, the former is not perceived as immersive, but this might not be a problem because our data also show that presence is not mandatory for enjoyment. Also, the data suggest that there is no clear preference between 1PP-VR and 3PP-VR for gameplay.
C1 [Monteiro, Diego; Liang, Hai-Ning; Xu, Wenge; Brucker, Marvin; Nanjappan, Vijayakumar; Yue, Yong] Xian Jiaotong Liverpool Univ, Dept Comp Sci & Software Engn, Suzhou, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Dept Comp Sci & Software Engn, Suzhou, Peoples R China.
EM haining.liang@xjtlu.edu.cn
RI Xu, Wenge/AAX-7883-2021; Monteiro, Diego/AAJ-7125-2020; Nanjappan,
   Vijayakumar/AFG-5650-2022
OI Xu, Wenge/0000-0001-7227-7437; Monteiro, Diego/0000-0002-1570-3652;
   Nanjappan, Vijayakumar/0000-0001-6081-2826; Yue,
   Yong/0000-0001-7695-4538; Liang, Hai-Ning/0000-0003-3600-8955
FU XJTLU Key Program Special Fund [KSF-A-03]
FX XJTLU Key Program Special Fund, Grant/Award Number: KSF-A-03
CR Bouchard S., 2011, Journal of Computer and Information Technology, V1, P20
   Clarke D, 2016, CHI PLAY 2016: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION, P39, DOI 10.1145/2968120.2968124
   Covaci A, 2015, IEEE COMPUT GRAPH, V35, P55, DOI 10.1109/MCG.2015.95
   Covaci Alexandra, 2014, P 20 ACM S VIRT REAL, P55, DOI [10.1145/2671015.2671023, DOI 10.1145/2671015.2671023]
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Debarba Henrique G., 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P67, DOI 10.1109/3DUI.2015.7131728
   Debarba HG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190109
   Denisova A, 2015, CHI 15 P 33 ANN ACM
   Dolphin VR, 2016, DOLPHIN VR GAMECUBE
   Dziuda L, 2014, APPL ERGON, V45, P406, DOI 10.1016/j.apergo.2013.05.003
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   IBM Analytics, 2016, IBM SPSS SOFTW
   Iwata  S., 2012, 72 ANN GEN M SHAR Q
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Kallinen K., 2007, Presence, P187
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Lim S, 2009, MEDIA PSYCHOL, V12, P348, DOI 10.1080/15213260903287242
   Mazuryk T, 1996, DIGIT OUTCASTS, V63, P92
   Medina Eliana, 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P2102, DOI 10.1518/107118108X352490
   Nintendo of America, 2008, MAR KART WII WII NIN
   Poels K, 2007, DELIVERABLE D3 3 GAM
   Salamin P, 2010, IEEE T LEARN TECHNOL, V3, P272, DOI 10.1109/TLT.2010.13
   Salamin Patrick, 2006, Proceedings of the ACM symposium on Virtual reality software and technology, P27
NR 24
TC 36
Z9 39
U1 4
U2 51
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1830
DI 10.1002/cav.1830
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100021
DA 2024-07-18
ER

PT J
AU Nasim, K
   Kim, YJ
AF Nasim, Kiran
   Kim, Young J.
TI Physics-based assistive grasping for robust object manipulation in
   virtual reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE assistive grasp; human-computer interaction (HCI); proxy hand; virtual
   grasping; virtual reality (VR)
AB In this paper, an effective, interactive grasping algorithm is proposed to provide physically realistic interactions in the virtual world. We have provided a solution to lacking dynamic control resulting in penetrations and frictionless contact due to kinematic virtual hand provided by hand-tracking devices, by including a proxy hand in the system. The introduced proxy hand not only provides correct visual feedback but also is used to simulate dynamics between the hand and virtual objects. Our method also provides semiautonomous assistive grasping, coupled with physics-based grasping, which makes the system help the user in achieving a grasp by identifying grasp pose and orienting the object in the hand to be grasped robustly. We have implemented and evaluated our technique with various benchmarks, conducted a user study to compare our method against the state-of-the-art, pinch-based grasping mechanism, and showed that our technique provides physically realistic, stable, and time-efficient real-time interactions.
C1 [Nasim, Kiran; Kim, Young J.] Ewha Womans Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Ewha Womans University
RP Kim, YJ (corresponding author), Ewha Womans Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM kimy@ewha.ac.kr
OI Kim, Young J./0000-0003-2159-4832
FU NRF [2017R1A2B3012701]; MCST/KOCCA [CT RD 2018]
FX NRF, Grant/Award Number: 2017R1A2B3012701; MCST/KOCCA, Grant/Award
   Number: CT R&D 2018
CR [Anonymous], WIR TOUCH
   Borst CW, 2005, P IEEE VIRT REAL ANN, P91
   Borst CW, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P430, DOI 10.1109/HAPTIC.2003.1191335
   Borst CW, 2012, IEEE S IEEE 3D US IN
   Buchmann V., 2004, VIRTUAL REAL-LONDON, V1, P212
   Bustos-Mendoza CR, 2004, INT C INT VIRT ENV V
   Cakmak M., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P1986, DOI 10.1109/IROS.2011.6048340
   Detry R, 2012, INT C ROB AUT ICRSA
   Detry R, 2010, IEEE INT CONF ROBOT, P2287, DOI 10.1109/ROBOT.2010.5509126
   Kappler D, 2015, IEEE INT C ROB AUT M
   Kitamura Y, 1999, P IEEE VIRT REAL ANN, P198, DOI 10.1109/VR.1999.756951
   Kyota F, 2012, COMPUT GRAPH FORUM, V31, P765, DOI 10.1111/j.1467-8659.2012.03035.x
   Lee T, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P145
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Liu C.K., 2008, ACM SIGGRAPH EUR S C, P163
   Miller AT, 2004, IEEE ROBOT AUTOM MAG, V11, P110, DOI 10.1109/MRA.2004.1371616
   Nasim K., 2016, HCI KOREA HCIK 16, P114
   Ott R., 2010, Computer-Aided Design and Applications, V7, P125, DOI [10.3722/cadaps.2010.125-138, DOI 10.3722/CADAPS.2010.125-138]
   Rafael R, 2012, 5 INT C ADV COMP HUM
   Rettig A, 2001, 8 INT C CONC ENG RES
   Richard MM, 1994, MATH INTRO ROBOTICS
   SANDERS B, 2014, MASTERING LEAP MOTIO
   Scheggi S., 2015, P ACM SIGGRAPH POST
   Thalmann D., 2012, Expanding the Frontiers of Visual Analytics and Visualization, P339
   Thies P, 2008, J VIRTUAL REAL BROAD, V16
   Woo W, 2013, IEEE S 3D US INT MAR
   Yui E, 2007, 10 ANN APPL ERG C CE
   Zhao WP, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508412
NR 28
TC 6
Z9 9
U1 2
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1820
DI 10.1002/cav.1820
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100011
DA 2024-07-18
ER

PT J
AU Wang, K
   Liu, SG
AF Wang, Kai
   Liu, Shiguang
TI Example-based synthesis for sound of ocean waves caused by bubble
   dynamics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE computer animation; example based; ocean waves; sound synthesis; virtual
   worlds
ID GENERATION; TEXTURES
AB We present an automatic approach for the semantic modeling of indoor scenes based on a single photograph, instead of relying on depth sensors. Without using handcrafted features, we guide indoor scene modeling with feature maps extracted by fully convolutional networks. Three parallel fully convolutional networks are adopted to generate object instance masks, a depth map, and an edge map of the room layout. Based on these high-level features, support relationships between indoor objects can be efficiently inferred in a data-driven manner. Constrained by the support context, a global-to-local model matching strategy is followed to retrieve the whole indoor scene. We demonstrate that the proposed method can efficiently retrieve indoor objects including situations where the objects are badly occluded. This approach enables efficient semantic-based scene editing.
C1 [Wang, Kai; Liu, Shiguang] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
   [Liu, Shiguang] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300350, Peoples R China.
C3 Tianjin University; Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.; Liu, SG (corresponding author), Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn
FU National Natural Science Foundation of China [61672375, 61170118]
FX National Natural Science Foundation of China, Grant/Award Number:
   61672375 and 61170118
CR An SS, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185598
   [Anonymous], EUR 2014 STAT ART RE
   Chadwick JN, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964979
   Dobashi Y, 2003, ACM T GRAPHIC, V22, P732, DOI 10.1145/882262.882339
   Doel K, 2005, ACM Trans. Appl. Percept., V2, P534, DOI [10.1145/1101530.1101554, DOI 10.1145/1101530.1101554]
   Dubnov S, 2002, IEEE COMPUT GRAPH, V22, P38, DOI 10.1109/MCG.2002.1016697
   Feng G, 2017, CASA 2017 30 C COMP, P51
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P225, DOI 10.1111/cgf.12825
   Klusek Z, 2013, OCEANOLOGIA, V55, P809, DOI 10.5697/oc.55-4.809
   Langlois TR, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925904
   Lee M, 2017, IEEE VIRT REAL LOS A
   Leighton T., 2007, Acoustics Bulletin, V32, P17
   Leighton TG, 1994, J FLUID MECH, V96
   Liu SG, 2015, VIRTUAL REAL-LONDON, V19, P291, DOI 10.1007/s10055-015-0271-7
   LONGUETHIGGINS MS, 1990, J FLUID MECH, V214, P395, DOI 10.1017/S0022112090000179
   McDermott JH, 2011, NEURON, V71, P926, DOI 10.1016/j.neuron.2011.06.032
   Means SL, 2004, ACOUST RES LETT ONL, V5, P13, DOI 10.1121/1.1636502
   Means SL, 2001, J ACOUST SOC AM, V110, P761, DOI 10.1121/1.1379729
   Moss W, 2010, ACM T GRAPHIC, V29, P483
   Nordahl R, 2011, IEEE T VIS COMPUT GR, V17, P1234, DOI 10.1109/TVCG.2011.30
   Parker JR, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P317
   Peeters G, 2004, CUIDADO I PROJECT RE
   Peltola L, 2007, IEEE T AUDIO SPEECH, V15, P1021, DOI 10.1109/TASL.2006.885924
   Prosperetti A, 1988, BUBBLE DYNAMICS OCEA
   PUMPHREY HC, 1989, J ACOUST SOC AM, V85, P1518, DOI 10.1121/1.397353
   Schreck C., 2016, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'16, P211
   Schwarz D, 2013, INT S COMP MUS MOD R
   Schwarz D., 2004, THESIS
   Schwarz D, 2008, JOURN INF MUS ALB FR
   Schwarz D, 2008, 7 SOUND MUS COMP C B
   Schwarz D, 2015, INT COMP MUS C NEW Y
   Spratt Kyle S., 2013, Journal of the Acoustical Society of America, V134, DOI 10.1121/1.4830819
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   STRASBERG M, 1953, J ACOUST SOC AM, V25, P536, DOI 10.1121/1.1907076
   Yin Q, 2018, IEEE T VIS COMPUT GR, V24, P1179, DOI 10.1109/TVCG.2016.2642958
   Zheng CX, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531343
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 37
TC 6
Z9 7
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1835
DI 10.1002/cav.1835
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100026
DA 2024-07-18
ER

PT J
AU Guo, SH
   Wang, ML
   Notman, G
   Chang, J
   Zhang, JJ
   Liao, MH
AF Guo, Shihui
   Wang, Meili
   Notman, Gabriel
   Chang, Jian
   Zhang, Jianjun
   Liao, Minghong
TI Simulating collective transport of virtual ants
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE character animation; collective transport
ID INSECTS
AB This paper simulates the behaviour of collective transport where a group of ants transports an object in a cooperative fashion. Different from humans, the task coordination of collective transport, with ants, is not achieved by direct communication between group individuals, but through indirect information transmission via mechanical movements of the object. This paper proposes a stochastic probability model to model the decision-making procedure of group individuals and trains a neural network via reinforcement learning to represent the force policy. Our method is scalable to different numbers of individuals and is adaptable to users' input, including transport trajectory, object shape, external intervention, etc. Our method can reproduce the characteristic strategies of ants, such as realign and reposition. The simulations show that with the strategy of reposition, the ants can avoid deadlock scenarios during the task of collective transport.
C1 [Guo, Shihui; Liao, Minghong] Xiamen Univ, Xiamen, Peoples R China.
   [Wang, Meili] Northwest A&F Univ, Yangling, Shaanxi, Peoples R China.
   [Wang, Meili] Key Lab Agr Internet Things, Yangling, Shaanxi, Peoples R China.
   [Notman, Gabriel; Chang, Jian; Zhang, Jianjun] Bournemouth Univ, Poole, Dorset, England.
C3 Xiamen University; Northwest A&F University - China; Bournemouth
   University
RP Wang, ML (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.; Wang, ML (corresponding author), Minist Agr, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
EM wml@nwsuaf.edu.cn
OI Chang, Jian/0000-0003-4118-147X
FU NRF-NSFC Joint Research [6161101193]; Chinese Postdoctoral Science
   Foundation [2016M600506, 2014M562457]; People Programme (Marie Curie
   Actions) [FP7/2007-2013, 612627]; National Natural Science Foundation of
   China [61402374]; National High-tech research and Development Program
   [2013AA10230402]
FX 1st NRF-NSFC Joint Research, Grant/Award Number: 6161101193; Chinese
   Postdoctoral Science Foundation, Grant/Award Number: 2016M600506 and
   2014M562457; People Programme (Marie Curie Actions), Grant/Award Number:
   FP7/2007-2013, 612627; National Natural Science Foundation of China,
   Grant/Award Number: 61402374; National High-tech research and
   Development Program, Grant/Award Number: 2013AA10230402
CR Berman S, 2011, P IEEE, V99, P1470, DOI 10.1109/JPROC.2011.2111450
   Chan JCP, 2013, COMPUT GRAPH FORUM, V32, P41, DOI 10.1111/cgf.12210
   FRANKS NR, 1986, BEHAV ECOL SOCIOBIOL, V18, P425, DOI 10.1007/BF00300517
   Guo SH, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12471
   Guo SH, 2014, COMPUT GRAPH-UK, V38, P78, DOI 10.1016/j.cag.2013.10.021
   He Liang., 2016, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation. SCA'16, P139
   Henry J, 2014, IEEE T VIS COMPUT GR, V20, P211, DOI 10.1109/TVCG.2013.116
   Hwang J, 2014, COMPUT GRAPH FORUM, V33, P21, DOI 10.1111/cgf.12470
   Hyun K, 2016, COMPUT GRAPH FORUM, V35, P103, DOI 10.1111/cgf.12815
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kube CR, 2000, ROBOT AUTON SYST, V30, P85, DOI 10.1016/S0921-8890(99)00066-4
   Kumar GP, 2013, P 16 ACM INT C HYBR, P119, DOI DOI 10.1145/2461328.2461349
   Loria A, 2016, IEEE T CONTR SYST T, V24, P727, DOI 10.1109/TCST.2015.2437328
   Patil S, 2011, IEEE T VIS COMPUT GR, V17, P244, DOI 10.1109/TVCG.2010.33
   Rubenstein M., 2013, 12 INT C AUT AG MULT, V1, P47
   Shum HPH, 2012, IEEE T VIS COMPUT GR, V18, P741, DOI 10.1109/TVCG.2010.257
   SUDD J. H., 1960, BEHAVIOUR, V16, P295, DOI 10.1163/156853960X00197
   Takahashi S, 2009, COMPUT GRAPH FORUM, V28, P639, DOI 10.1111/j.1467-8659.2009.01404.x
   Wang XJ, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12277
   Won J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661271
NR 20
TC 12
Z9 12
U1 2
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1779
DI 10.1002/cav.1779
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200025
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Hajizadeh, M
   Ebrahimnezhad, H
AF Hajizadeh, Mohammadali
   Ebrahimnezhad, Hossein
TI Predictive compression of animated 3D models by optimized weighted
   blending of key-frames
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animated mesh compression; key-frame (key-pose) extraction; predictive
   coding; optimized blending weights; dynamic geometry; 3D dynamic mesh
ID MESH SEQUENCES; SEARCH
AB Efficient compression techniques are required for animated mesh sequences with fixed connectivity and time-varying geometry. In this paper, we propose a key-frame-based technique for three-dimensional dynamic mesh compression. First, key-frames are extracted from the animated sequence. Extracted key-frames are then linearly combined using blending weights to predict the vertex locations of the other frames. These blending weights play a key role in the proposed algorithm because the prediction performance and the required number of key-frames greatly depend on these weights. We present a novel method in order to compute the optimum blending weight that makes it possible to predict location of the vertices of the non-key frames with the minimum number of key-frames. The residual prediction errors are finally quantized and encoded using Huffman coding and another heuristic method. Experimental results on different test sequences with various sizes, topologies, and geometries demonstrate the privileged performance of the proposed method compared with the previous techniques. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Hajizadeh, Mohammadali; Ebrahimnezhad, Hossein] Sahand Univ Technol, Dept Elect Engn, Comp Vis Res Lab, Tabriz, Iran.
C3 Sahand University of Technology
RP Ebrahimnezhad, H (corresponding author), Sahand Univ Technol, Dept Elect Engn, Comp Vis Res Lab, Tabriz, Iran.
EM ebrahimnezhad@sut.ac.ir
RI Ebrahimnezhad, Hossein/ACP-2704-2022; ebrahimnezhad,
   hossein/ABC-3865-2021
OI ebrahimnezhad, hossein/0000-0003-4071-2750
CR Ahn JH, 2001, ELECTRON LETT, V37, P1445, DOI 10.1049/el:20010993
   Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   ALLIEZ P, 2003, P S MULT GEOM MOD
   AMJOUN R, 2008, J VIRTUAL REALITY BR, V5
   AMJOUN R, 2007, J WSCG, V15, P32
   Amjoun R, 2009, THESIS
   Amjoun R, 2006, LECT NOTES COMPUT SC, V4035, P606
   Amjoun R, 2009, COMPUT AIDED DESIGN, V41, P711, DOI 10.1016/j.cad.2009.02.013
   [Anonymous], 1979, Multiple attribute decision making: methods and applications: a state-of-the-art survey
   [Anonymous], 1973, Multiple Criteria Decision Making
   Arikan O, 2006, ACM T GRAPHIC, V25, P890, DOI 10.1145/1141911.1141971
   Beaudoin Philippe, 2007, Proceedings Graphics Interface 2007, P313, DOI 10.1145/1268517.1268568
   Beaudoin P., 2008, P 2008 ACM SIGGRAPHE, P117
   Bici MO, 2011, J VIS COMMUN IMAGE R, V22, P577, DOI 10.1016/j.jvcir.2011.07.006
   Boulfani-Cuisinaud Y, 2007, IEEE IMAGE PROC, P217
   Branke J., 2008, Interactive and Evolutionary Approaches
   Briceno H. M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P136
   Chattopadhyay S, 2007, IEEE T VIS COMPUT GR, V13, P5, DOI 10.1109/TVCG.2007.13
   Das I, 1998, SIAM J OPTIMIZ, V8, P631, DOI 10.1137/S1052623496307510
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deb K., 2010, MULTIOBJECTIVE OPTIM
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Firouzmanesh A, 2011, IEEE T MULTIMEDIA, V13, P829, DOI 10.1109/TMM.2011.2129497
   GALLAGER RG, 1978, IEEE T INFORM THEORY, V24, P668, DOI 10.1109/TIT.1978.1055959
   Gu Q, 2009, COMPUT GRAPH FORUM, V28, P1, DOI 10.1111/j.1467-8659.2008.01309.x
   Guskov I., 2004, Proc. 2004 ACM SIG- GRAPH/Eurographics Symp. Comput. Animation (SCA '04), P183
   Heu JH, 2009, J VIS COMMUN IMAGE R, V20, P439, DOI 10.1016/j.jvcir.2009.05.003
   Huang KS, 2005, VISUAL COMPUT, V21, P532, DOI 10.1007/s00371-005-0316-0
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Ibarria L., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P126
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Kiranyaz S., 2014, Multidimensional Particle Swarm Optimization for Machine Learning and Pattern Recognition
   Kolda TG, 2003, SIAM REV, V45, P385, DOI [10.1137/S003614450242889, 10.1137/S0036144502428893]
   Lengyel J. E., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P89, DOI 10.1145/300523.300533
   Lin IC, 2011, IEEE T VIS COMPUT GR, V17, P527, DOI 10.1109/TVCG.2010.87
   Liu Guodong., 2006, SCA 06, P127
   Luo GL, 2013, COMPUT ANIMAT VIRT W, V24, P365, DOI 10.1002/cav.1522
   Mamou K, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P711
   Mamou K, 2006, COMPUT ANIMAT VIRT W, V17, P337, DOI 10.1002/cav.137
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Messac A, 2003, STRUCT MULTIDISCIP O, V25, P86, DOI 10.1007/s00158-002-0276-1
   Motta RS, 2012, SOC NATUR RESOUR, V1, P1
   Müller K, 2006, SIGNAL PROCESS-IMAGE, V21, P812, DOI 10.1016/j.image.2006.07.002
   Mueller-Gritschneder D, 2009, SIAM J OPTIMIZ, V20, P915, DOI 10.1137/080729013
   Muller K., 2005, IEEE INT C IM PROC, V1, p621 624
   Payan F., 2005, P IEEE ACIDCA ICMI
   Payan F, 2007, COMPUT GRAPH-UK, V31, P77, DOI 10.1016/j.cag.2006.09.009
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   Rabiner LR, 2007, FOUND TRENDS SIGNAL, V1, P1, DOI 10.1561/2000000001
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Sattler M., 2005, P 2005 ACM SIGGRAPH, P209
   STEFANOSKI N, 2007, 3DTV C 2007, P1, DOI DOI 10.1109/3DTV.2007.4379461
   Stefanoski N, 2006, IEEE IMAGE PROC, P2973, DOI 10.1109/ICIP.2006.312961
   Stefanoski N, 2010, COMPUT GRAPH FORUM, V29, P101, DOI 10.1111/j.1467-8659.2009.01547.x
   Stefanoski N, 2008, IEEE IMAGE PROC, P2696, DOI 10.1109/ICIP.2008.4712350
   Tournier M, 2009, COMPUT GRAPH FORUM, V28, P355, DOI 10.1111/j.1467-8659.2009.01375.x
   van den Bergh F, 2006, INFORM SCIENCES, V176, P937, DOI 10.1016/j.ins.2005.02.003
   Vása L, 2014, COMPUT GRAPH FORUM, V33, P283, DOI 10.1111/cgf.12326
   Vása L, 2009, COMPUT GRAPH FORUM, V28, P1529, DOI 10.1111/j.1467-8659.2008.01304.x
   Vasa L, 2007, 3DTV CONF, P49, DOI 10.1109/3DTV.2007.4379408
   Vása L, 2010, COMPUT GRAPH FORUM, V29, P1921, DOI 10.1111/j.1467-8659.2010.01659.x
   Vása L, 2009, COMPUT ANIMAT VIRT W, V20, P447, DOI 10.1002/cav.227
   Vaz AIF, 2007, J GLOBAL OPTIM, V39, P197, DOI 10.1007/s10898-007-9133-5
   Yang JH, 2002, IEEE T CIRC SYST VID, V12, P1178, DOI 10.1109/TCSVT.2002.806814
   Zhang JH, 2004, IEEE DATA COMPR CONF, P508
   Zhang JH, 2007, COMPUT GRAPH-UK, V31, P463, DOI 10.1016/j.cag.2006.12.002
   Zhu M Y, 2012, P 2012 ACM SIGGRAPH, P183, DOI [10.2312/SCA/SCA12/183-192, DOI 10.2312/SCA/SCA12/183-192]
NR 67
TC 6
Z9 6
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2016
VL 27
IS 6
BP 556
EP 576
DI 10.1002/cav.1685
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EE1HQ
UT WOS:000389332200005
DA 2024-07-18
ER

PT J
AU Kochanowicz, J
   Tan, AH
   Thalmann, D
AF Kochanowicz, Jaroslaw
   Tan, Ah-Hwee
   Thalmann, Daniel
TI Dramaturgical and dissonance theories in explicit social context
   modeling for complex agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE social simulation; affective computing; dissonance theory; dramaturgical
   theory
AB Expanding the spectrum of agent social capabilities is an important challenge in agent-based simulation and other domains. While human-like emotionality has been vastly explored in the last 20years, little research addresses explicit, psychologically believable social situation modeling. Recently, some important elements have been underlined: hybrid connectionist models outside formal ontologies; complex subjective representations linking culture, personality and norms, and so on, but proposed solutions do not provide a formalized structure of a social experience, expressive and well-grounded in psychology. In this paper, we develop a new approach to social situation modeling based on the dramaturgical and dissonance theories. A new component (Dramaturgical Module) is described with implementation used to generate example behavior depicting new social modeling capabilities and a believable representation of the relevant psychological theories. We present a case scenario with a dramaturgical interpretation of dynamic social situations and related cognitive dissonances resulting in a simple and flexible classification. Easily usable in reasoning, planning or affect generation, dramaturgical interpretation is additionally presented here as basis of social affect generation. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Kochanowicz, Jaroslaw] Nanyang Technol Univ, SCE, IMI, Singapore 637553, Singapore.
   [Tan, Ah-Hwee] Nanyang Technol Univ, SCE, Singapore 639798, Singapore.
   [Thalmann, Daniel] Nanyang Technol Univ, IMI, Singapore 637553, Singapore.
C3 Nanyang Technological University; Nanyang Technological University;
   Nanyang Technological University
RP Kochanowicz, J (corresponding author), Nanyang Technol Univ, Inst Media Innovat, Singapore 639798, Singapore.
EM jarek108@gmail.com
RI Tan, Ah-Hwee/A-3729-2011; Thalmann, Daniel/A-4347-2008; Thalmann,
   Daniel/AAL-1097-2020
OI Thalmann, Daniel/0000-0002-0451-7491; Tan, Ah Hwee/0000-0003-0378-4069
CR Aylett R, P 8 INT C AUT AG MUL, P329
   Block J, 2010, PSYCHOL INQ, V21, P2, DOI 10.1080/10478401003596626
   Collins A, 1990, The cognitive structure of emotions
   Ferreira N, INTELLIGENT VIRTUAL
   Goffman Erving, 1959, The presentation of self in everyday life
   Jiang H, 2012, WORK, V41, P2274, DOI 10.3233/WOR-2012-0650-2274
   Kochanowicz J, 2013, P 2013 INT C AUT AG, P789
   Kochanowicz J, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P1529
   Leon Festinger, 1962, THEORY COGNITIVE DIS
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   O'Hare GMP, 1999, CEEMAS 99 ST PET RUS, P181
   Prada Rui, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P607, DOI 10.1109/CSE.2009.24
   Shoham Y, 1997, ARTIF INTELL, V94, P139, DOI 10.1016/S0004-3702(97)00028-3
NR 13
TC 1
Z9 1
U1 6
U2 21
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 247
EP 257
DI 10.1002/cav.1639
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700007
DA 2024-07-18
ER

PT J
AU Yang, S
   Lin, M
AF Yang, Shan
   Lin, Ming
TI Simultaneous estimation of elasticity for multiple deformable bodies
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE elasticity parameter reconstruction; human tissue simulation; tissue
   material property
ID ELASTOGRAPHY
AB Material property has great importance in deformable body simulation and medical robotics. The elasticity parameters, such as Young's modulus of the deformable bodies, are important to make realistic animations.Further, in medical applications, the (recovered) elasticity parameters can assist surgeons to perform better pre-op surgical planning and enable medical robots to carry out personalized surgical procedures. Previous elasticity parameters estimation methods are limited to recover one elasticity parameter of one deformable body at a time. In this paper, we propose a novel elasticity parameter estimation algorithm that can recover the elasticity parameters of multiple deformable bodies or multiple regions of one deformable body simultaneously from (at least two sets of) images. We validate our algorithm with both synthetic test cases and real patient computed tomography images. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Yang, Shan; Lin, Ming] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Yang, S (corresponding author), Univ N Carolina, Chapel Hill, NC 27599 USA.
EM alexyang@cs.unc.edu
FU NSF; NIH Smart and Connected Health Program, NIH [R01EB020426 - 01]
FX This research is supported in part by the Joint NSF and NIH Smart and
   Connected Health Program, NIH#R01EB020426 - 01. We would like to thank
   Drs. Ronald Chen and Edward Chaney for CT images from their Lab, and Dr.
   Huai-Ping Lee for data from his thesis in our experiments.
CR [Anonymous], SENSOR BASED MINIMAL
   [Anonymous], SEMIAUTOMATED SOFT T
   [Anonymous], FORCE CONTROLLED TEL
   [Anonymous], ULTRASOUND INDENTATI
   [Anonymous], NUMERICAL OPTIMIZATI
   [Anonymous], TNM CLASSIFICATION M
   [Anonymous], ACM T GRAPHICS
   [Anonymous], INVERSE FINITE ELEME
   [Anonymous], QUALITY TETRAHEDRAL
   [Anonymous], PARAMETER ESTIMATION
   [Anonymous], INT J RAD ONCOLOGY B
   BECKER MARKUS., 2007, SimVis, P15
   Bharatha A, 2001, MED PHYS, V28, P2551, DOI 10.1118/1.1414009
   Bickels B, 2010, ACM SIGGRAPH 2010 PA, P1
   BIRNHOLZ JC, 1985, RADIOLOGY, V157, P495, DOI 10.1148/radiology.157.2.3901109
   Bro-Nielsen M, 1998, P IEEE, V86, P490, DOI 10.1109/5.662874
   Carter FJ, 2001, MED IMAGE ANAL, V5, P231, DOI 10.1016/S1361-8415(01)00048-2
   Chenevert TL, 1998, MAGNET RESON MED, V39, P482, DOI 10.1002/mrm.1910390319
   Chopra R, 2009, MAGN RESON MED, V62, P665, DOI 10.1002/mrm.22038
   Chun TY, 1997, J UROLOGY, V157, P65, DOI 10.1016/S0022-5347(01)65281-9
   Eskandari H, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/8/085002
   Gao L, 1996, ULTRASOUND MED BIOL, V22, P959, DOI 10.1016/S0301-5629(96)00120-2
   Krouskop T A, 1987, J Rehabil Res Dev, V24, P1
   Lee HP, 2012, IEEE T MED IMAGING, V31, P2156, DOI 10.1109/TMI.2012.2212450
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Lyshchik A, 2005, RADIOLOGY, V237, P202, DOI 10.1148/radiol.2363041248
   Maciel A, 2003, LECT NOTES COMPUT SC, V2673, P74
   Manduca A, 2001, MED IMAGE ANAL, V5, P237, DOI 10.1016/S1361-8415(00)00039-6
   Meehan M, 2003, Orthod Craniofac Res, V6 Suppl 1, P102
   Miga M.I., 2002, New approach to elastrograph imaging: modality-independent elastography, P604
   Miguel E, 2012, COMPUT GRAPH FORUM, V31, P519, DOI 10.1111/j.1467-8659.2012.03031.x
   Misra S, 2010, COMPUT METHOD BIOMEC, V13, P811, DOI 10.1080/10255840903505121
   Müller M, 2004, PROC GRAPH INTERF, P239
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   OPHIR J, 1991, ULTRASONIC IMAGING, V13, P111, DOI 10.1016/0161-7346(91)90079-W
   Samur E, 2007, MED IMAGE ANAL, V11, P361, DOI 10.1016/j.media.2007.04.001
   Tanner C, 2006, MED PHYS, V33, P1758, DOI 10.1118/1.2198315
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Van Houten EEW, 1999, MAGNET RESON MED, V42, P779, DOI 10.1002/(SICI)1522-2594(199910)42:4<779::AID-MRM21>3.0.CO;2-Z
   Van Houten EEW, 2001, MAGNET RESON MED, V45, P827, DOI 10.1002/mrm.1111
   WILSON LS, 1982, ULTRASONIC IMAGING, V4, P71, DOI 10.1016/0161-7346(82)90006-2
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhu YN, 2003, IEEE T MED IMAGING, V22, P890, DOI 10.1109/TMI.2003.815065
NR 43
TC 1
Z9 3
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 197
EP 206
DI 10.1002/cav.1649
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700002
PM 26023303
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Luo, JX
   Hu, GY
   Ni, GQ
AF Luo, Jianxin
   Hu, Guyu
   Ni, Guiqiang
TI Dual-space ray casting for height field rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dual-space; ray casting; terrain; spherical height-field; visualization
ID GEOMETRY; GPU
AB This paper presents a realistic ray casting model on a curved surface. Guided by the model, we derive an analytical solution for spherical surfaces and propose a mathematical model by solving one problem in two spaces. By using the solution, we introduce a novel framework for spherical height field rendering. We have successfully implemented a spherical height field rendering framework on the graphics processing unit and obtained real-time rendering rates with screen error below 1pixel. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Luo, Jianxin; Hu, Guyu; Ni, Guiqiang] PLA Univ Sci & Technol, LMNT, Nanjing 210007, Jiangsu, Peoples R China.
C3 Army Engineering University of PLA
RP Luo, JX (corresponding author), PLA Univ Sci & Technol, LMNT, 1 Haifu Lane, Nanjing 210007, Jiangsu, Peoples R China.
EM luojianxin555@yahoo.com
FU National Basic Research Program of China (863 Program) [2012AA01A510]
FX This research work was supported by the National Basic Research Program
   of China (863 Program) (Grant No. 2012AA01A510).
CR Baboud L, 2006, PROC GRAPH INTERF, P195
   Cignoni P, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P147, DOI 10.1109/VISUAL.2003.1250366
   Cignoni P, 2003, COMPUT GRAPH FORUM, V22, P505, DOI 10.1111/1467-8659.00698
   Clasen M., 2006, P EUR IEEE VGTC S VI
   Cohen D., 1998, THESIS U N CAROLINA
   Dick C, 2009, P EUROGRAPHICS
   Dick C, 2009, COMPUT GRAPH FORUM, V28, P67, DOI 10.1111/j.1467-8659.2008.01298.x
   DONNELLY W, 2005, GPU GEMS, V2
   Duchaineau M, 1997, VISUALIZATION '97 - PROCEEDINGS, P81, DOI 10.1109/VISUAL.1997.663860
   Dummer J., 2006, Cone step mapping: An iterative ray-heightfield intersection algorithm'
   FALBY JS, 1993, COMPUT GRAPH, V17, P65, DOI 10.1016/0097-8493(93)90052-B
   Hill D., 2002, THESIS U TORONTO
   Jeschke S., 2007, Proceedings of EGSR07, P351
   Kajiya J. T., 1989, Computer Graphics, V23, P271, DOI 10.1145/74334.74361
   Lindstrom P., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P109, DOI 10.1145/237170.237217
   LIVNY Y, 2007, VISUAL COMPUTER
   Losasso F, 2004, ACM T GRAPHIC, V23, P769, DOI 10.1145/1015706.1015799
   Luo J, 2012, PARALLEL SPACE RAY C
   Luo J, 2011, P 24 INT C COMP AN S
   Luo J, 2011, P 12 INT C CAD GRAPH
   NVIDIA, 2004, CLIPM
   O'Neil S., 2001, GAMASUTRA        AUG
   Oh K., 2006, Proceedings of the ACM symposium on Virtual reality software and technology, P75
   Ohbuchi E, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P190, DOI 10.1109/CGI.2003.1214465
   Pajarola R, 1998, VISUALIZATION '98, PROCEEDINGS, P19, DOI 10.1109/VISUAL.1998.745280
   Policarpo F, TECHNICAL REPORT
   Policarpo F., 2005, Proceedings of the 2005 symposium on Interactive 3D graphics and games, P155, DOI DOI 10.1145/1053427.1053453
   RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150
   Risser E, 2005, TECHNICAL REPORT
   Szirmay-Kalos L, 2005, COMPUT GRAPH FORUM, V24, P695, DOI 10.1111/j.1467-8659.2005.0m894.x
   Tatarchuk N., 2006, Proceedings of the 2006 symposium on Interactive 3D graphics and games, P63
   Wang LF, 2003, ACM T GRAPHIC, V22, P334, DOI 10.1145/882262.882272
   Wang X, 2004, P 2004 EUR S REND
   Wartell Zachary Justin, 1999, TECHNICAL REPORT
   Wyman Chris., 2005, Proceedings of the 3rd international conference on Computer graphics and interactive techniques in Australasia and South East Asia (GRAPHITE '05), P205
NR 35
TC 2
Z9 4
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2014
VL 25
IS 1
BP 45
EP 56
DI 10.1002/cav.1531
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AA4LQ
UT WOS:000331067500005
DA 2024-07-18
ER

PT J
AU Shen, Y
   Lin, X
   Gao, Y
   Sheng, B
   Liu, QS
AF Shen, Yang
   Lin, Xiao
   Gao, Yan
   Sheng, Bin
   Liu, Qisong
TI Video composition by optimized 3D mean-value coordinates
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE MVC; video; composition
ID IMAGE; SEGMENTATION
AB In this paper, we propose a new video composition method by 3D mean-value coordinate (MVC). 2D MVCs have been widely used in image composition; however, when 2D MVC is applied to a video sequence directly, because of over-blending and the lack of temporal consistency, some unnatural effects may appear in the final composite results. Although 3D Poisson editing can maintain spatial and temporal consistency, it also leads to high algorithm complexity. Instead of 3D Poisson editing, we use the 3D MVC to seamlessly blend a given source video patch into a target video sequence; this approach is able to achieve high-performance blending with less computation. We show that the combination of alpha matte-based approaches and our method can further refine the produced video when the boundaries of the source object and the target object are very different. Our algorithm can be paralleled and run on a graphics processing unit. The experimental results show that our method is effective and efficient. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Gao, Yan] E China Normal Univ, Dept Comp Sci & Engn, Shanghai 200062, Peoples R China.
   [Shen, Yang; Sheng, Bin; Liu, Qisong] Shanghai Jiao Tong Univ, Shanghai 200030, Peoples R China.
   [Lin, Xiao] Luoyang Normal Univ, Luoyang, Peoples R China.
C3 East China Normal University; Shanghai Jiao Tong University; Luoyang
   Normal University
RP Gao, Y (corresponding author), E China Normal Univ, Dept Comp Sci & Engn, Shanghai 200062, Peoples R China.
EM ygao@sei.ecnu.edu.cn
FU Innovation Program of the Science and Technology Commission of Shanghai
   Municipality [10511501200]; Open Projects Program of National Laboratory
   of Pattern Recognition, Natural Science Foundation of China [60873136];
   Center for Software/Hardware Co-design Engineering and Application of
   the Ministry of Education
FX This work is supported by the Innovation Program of the Science and
   Technology Commission of Shanghai Municipality (no. 10511501200), the
   Open Projects Program of National Laboratory of Pattern Recognition,
   Natural Science Foundation of China (no. 60873136), and the Center for
   Software/Hardware Co-design Engineering and Application of the Ministry
   of Education.
CR [Anonymous], P IEEE COMP SOC C CO
   Bai X, 2009, INT J COMPUT VISION, V82, P113, DOI 10.1007/s11263-008-0191-z
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Ding M, 2010, VISUAL COMPUT, V26, P721, DOI 10.1007/s00371-010-0448-8
   Farbman Z, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531373
   Floater MS, 2005, COMPUT AIDED GEOM D, V22, P623, DOI 10.1016/j.cagd.2005.06.004
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Mei T, 2009, VISUAL COMPUT, V25, P39, DOI 10.1007/s00371-008-0282-4
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Wang HC, 2004, INT C PATT RECOG, P858, DOI 10.1109/ICPR.2004.1334663
   Wang YZ, 2006, PATTERN RECOGN LETT, V27, P386, DOI 10.1016/j.patrec.2005.09.014
   Xie ZF, 2010, VISUAL COMPUT, V26, P1123, DOI 10.1007/s00371-010-0466-6
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang SH, 2011, IEEE T MULTIMEDIA, V13, P1286, DOI 10.1109/TMM.2011.2165052
NR 19
TC 5
Z9 7
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 179
EP 190
DI 10.1002/cav.1465
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100006
DA 2024-07-18
ER

PT J
AU Lee, J
   Kim, D
   Kim, H
   Henzel, C
   Kim, JI
   Lim, M
AF Lee, Jun
   Kim, DongKyum
   Kim, HyungSeok
   Henzel, Carloa
   Kim, Jee-In
   Lim, MinGyu
TI Real-time fur simulation and rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE fur simulation; fur rendering; real-time simulation
AB Real-time simulation of fur is a key element in many virtual reality applications. However, it is still difficult to simulate effects of fur animation in real-time. In this paper, we propose an interactive fur simulation method, to calculate effects of external forces, such as wind and gravity, and direct manipulation for real-time interactive animation. The proposed method consists of two layered textures for rendering. The first texture represents volumes of fur, and the second texture covers and laps the edge of the first texture. Our approach unifies these two structures using a shared vertex array to enhance rendering performance. We modify the shared vertex array with external force simulations and render it into the graphics pipeline. The proposed method is applied to virtual fashion design and 3D story telling as an example. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Kim, HyungSeok; Lim, MinGyu] Konkuk Univ, Dept Internet & Multimedia Engn, Seoul, South Korea.
   [Kim, HyungSeok; Lim, MinGyu] Univ Geneva, MIRALab, CH-1211 Geneva 4, Switzerland.
C3 Konkuk University; University of Geneva
RP Kim, H (corresponding author), Konkuk Univ, Dept Internet & Multimedia Engn, Seoul, South Korea.
EM hyuskim@konkuk.ac.kr
RI SEOK, KIM HYUNG/C-2742-2009; Lee, Jun/D-9548-2011; Lim,
   Mingyu/D-3819-2011
OI SEOK, KIM HYUNG/0000-0003-4816-2992; Lim, Mingyu/0000-0002-3749-1902
FU National Research Foundation of Korea [과C6A2401] Funding Source: Korea
   Institute of Science & Technology Information (KISTI), National Science
   & Technology Information Service (NTIS)
CR BAKAY B, 2002, P EUR 02
   Bruderlin A., 1999, Proceedings. Seventh Pacific Conference on Computer Graphics and Applications (Cat. No.PR00293), P242, DOI 10.1109/PCCGA.1999.803368
   Choe B., 2005, SCA 05, P153, DOI DOI 10.1145/1073368.1073389
   DAVE J, 2006, P ACM SIGGRAPH 06 CO
   GOLDMAN D, 1997, P ACM SIGGRAPH 97, P127
   KAJIYA JT, 1989, P 16 ANN C COMP GRAP, P271
   Lee J, 2007, COMPUT ANIMAT VIRT W, V18, P121, DOI 10.1002/cav.167
   LENGYEL JE, 2001, ACM S INT 3D TECHN 2, P227
   Matsushita N., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P209, DOI 10.1145/263407.263549
   *MICR, MICR SURF
   Praun E, 2000, COMP GRAPH, P465, DOI 10.1145/344779.344987
   SIEGEL L, 2009, ACM SIGGRAPH 09 TALK, P1
   Volino P, 2005, COMPUT AIDED DESIGN, V37, P593, DOI 10.1016/j.cad.2004.09.003
   Ward K, 2003, COMP ANIM CONF PROC, P41, DOI 10.1109/CASA.2003.1199302
   YANG G, 2006, P 2006 ACM INT C VIR, P343
NR 15
TC 2
Z9 3
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 311
EP 320
DI 10.1002/cav.361
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400018
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Na, KG
   Jung, MR
AF Na, Kyung-Gun
   Jung, Moon-Ryul
TI Weighted local shape blending for facial motion retargetting
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE facial motion retargetting; shape blending
ID CAPTURE; FACES
AB We present a system that maps a sparse configuration of facial markers captured from an actor on to target meshes, by blending highly detailed target key meshes. One way of determining the blending weights is local shape blending which segments a facial mesh into disjoint regions, and tries to represent each region on the facial mesh as a weighted sum of the corresponding regions on the key meshes. This has the side effect of decoupling the natural correlation between different parts of a face. This problem has been improved by a recent method which considers the entire face as the sum of overlapping soft regions centered at each control point, where the influence of the control-points are reduced with distance. But it goes too far in the opposite direction: by treating control points independently and thereby ignoring the spatial coherence among nearby control points on a face, it can cause unwanted interferences between the nearby control-points (i.e. between the associated soft regions). To avoid both problems, we retain the basic framework of local shape blending, but consider nearby control points together by treating them as a weighted region with a weighting function defined over it. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Jung, Moon-Ryul] Sogang Univ, Dept Media Technol, Seoul, South Korea.
C3 Sogang University
RP Jung, MR (corresponding author), Sogang Univ, Dept Media Technol, Seoul, South Korea.
EM moon@sogang.ac.kr
CR Bichke B., 2008, P 2008 ACM SIGGRAPH
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   BUCK I, 2000, NPAR 2000, P101
   Cao Y., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P225
   Choe B, 2001, COMP ANIM CONF PROC, P12, DOI 10.1109/CA.2001.982372
   Choe B, 2001, J VISUAL COMP ANIMAT, V12, P67, DOI 10.1002/vis.246
   Chuang E, 2005, ACM T GRAPHIC, V24, P331, DOI 10.1145/1061347.1061355
   Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387
   JOSHI P, 2003, S COMP AN, P187
   Ju E, 2008, COMPUT GRAPH FORUM, V27, P381, DOI 10.1111/j.1467-8659.2008.01135.x
   Lee Y.C., 1995, SIGGRAPH Proceedings, P55
   Lewis JP, 2005, P 2005 S INT 3D GRAP, P25
   Ma WC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409074
   Na K, 2004, COMPUT GRAPH FORUM, V23, P687, DOI 10.1111/j.1467-8659.2004.00801.x
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   PIGHIN F, 1998, SIGGRAPH P, P75
   Pyun H., 2003, SIGGRAPH/EUROGRAPHICS Symposium on Computer Animation, P167
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang QS, 2006, IEEE T VIS COMPUT GR, V12, P48, DOI 10.1109/TVCG.2006.9
NR 25
TC 3
Z9 4
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 255
EP 265
DI 10.1002/cav.346
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400013
DA 2024-07-18
ER

PT J
AU Quax, P
   Di Fiore, F
   Lamotte, W
   Van Reeth, F
AF Quax, Peter
   Di Fiore, Fabian
   Lamotte, Wim
   Van Reeth, Frank
TI Efficient distribution of emotion-related data through a networked
   virtual environment architecture
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE networked virtual environments; immersive communication; scalability;
   facial animation; emotions; avatars; MPEG-4
AB In this paper we describe the way in which emotion-related data can efficiently be exchanged between participants in a large-scale networked virtual environment. This type of metadata is extracted from real-time captured video streams using off-the-shelf webcams and applied onto a two-dimensional (2D) stylised avatar; thereby improving the immersion the user experiences while navigating and communicating in the virtual world. As emotion-related data-once processed through the system-can be considered a specific type of state information, a generic networked virtual environment architecture can be used to distribute the information between participants. We have opted to extend the in-house developed architecture for large-scale virtual interactive communities (ALVIC-NG) architecture to be able to process the information flows. We Will show that the inclusion of this new type of information does not have a detrimental effect on the scalability of the system. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Di Fiore, Fabian] Hasselt Univ, tUL IBBT, Expertise Ctr Digital Media, BE-3590 Diepenbeek, Belgium.
   [Di Fiore, Fabian] Univ Antwerp, Antwerp, Belgium.
C3 Hasselt University; University of Antwerp
RP Di Fiore, F (corresponding author), Hasselt Univ, tUL IBBT, Expertise Ctr Digital Media, Wetenschapspk 2, BE-3590 Diepenbeek, Belgium.
EM fabian.difiore@uhasselt.be
RI Quax, Paul/W-8520-2019; Lamotte, Wim/F-1796-2017
OI Lamotte, Wim/0000-0003-1888-6383; QUAX, Peter/0000-0003-4811-0578; Di
   Fiore, Fabian/0000-0003-4908-0673; VAN REETH, Frank/0000-0002-3705-7807
FU ERDF (European Regional Development Fund); Flemish government
FX Part of the research at EDM is funded by the ERDF (European Regional
   Development Fund) and the Flemish government. The authors would like to
   thank Panagiotis Issaris, Cedric Vanaken and Jeroen Dierckx for their
   help.
CR Barzel R, 1997, IEEE COMPUT GRAPH, V17, P31, DOI 10.1109/38.586016
   Blair P., 1994, CARTOON ANIMATION
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Di Fiore F, 2001, COMP ANIM CONF PROC, P192, DOI 10.1109/CA.2001.982393
   DIFIORE F, 2005, P COMP AN SOC AG CAS, P73
   DIFIORE F, 2008, LECT NOTES COMPUTER
   Fidaleo D, 2002, COMP ANIM CONF PROC, P17, DOI 10.1109/CA.2002.1017502
   Gooch B., 2001, Non-photorealistic rendering
   INSLEY J, 1997, VIS P 1997 SIGGRAPH, P128
   LU F, 2006, NETGAMES 06
   MacVicar D, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P42
   OGI T, 2000, P 10 ANN INT SOC C
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   QUAX F, 2008, INT J COMPUTER GAMES, P1
   QUAX P, 2007, THESIS TRANSNATIONAL
   Strothotte T, 2002, NONPHOTOREALISTIC CO
   THORISSON KR, 1996, 9601 MIT MED LAB LEA
   Williams Richard., The Animator's Survival Kit
   Yura S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P433, DOI 10.1109/MMCS.1999.778485
NR 19
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2009
VL 20
IS 5-6
SI SI
BP 501
EP 510
DI 10.1002/cav.278
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 516RI
UT WOS:000271559700003
DA 2024-07-18
ER

PT J
AU Chen, H
   Wu, W
   Sun, HQ
   Heng, PA
AF Chen, Hui
   Wu, Wen
   Sun, Hanqiu
   Heng, Pheng-Ann
TI Dynamic touch-enabled virtual palpation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE haptics; palpation; surgical simulation; virtual reality
ID HAPTIC SIMULATION; REALITY; DIAGNOSIS; CONTACT
AB Palpation is an important method of feeling with hands during a physical examination, in which the doctor presses on the surface of the patient body to feel the organs or tissues underneath. In current surgical simulation systems, the lack of an effective sense of touch is still a major problem. In this paper, a dynamic touch-enabled virtual palpation model is proposed. The palpation force sensing between the index finger and virtual tissues is simulated through a body-based haptic interaction model. Both contact and frictional forces are evaluated based on Hertz's contact theory, and the press distribution within the contact area is also specified. The non-linear viscoelastic behavior of typical tissues is mimicked via a volumetric tetrahedral mass-spring system. Reaction during the palpation is restricted to a local area to highly reduce the order of the dynamic equation of the entire system to guarantee a fast working rate. Mechanical tests have been performed to evaluate the palpation force perception and the realistic behavior of typical human tissues. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Chinese Acad Sci, Chinese Univ Hong Kong, Shenzhen Inst Adv Integrat Technol, Beijing 100864, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Chinese University of Hong Kong
RP Chen, H (corresponding author), Chinese Acad Sci, Chinese Univ Hong Kong, Shenzhen Inst Adv Integrat Technol, Beijing 100864, Peoples R China.
EM hui.chen@siat.ac.cn
OI Heng, Pheng Ann/0000-0003-3055-5034
CR [Anonymous], [No title captured]
   Atre A.P., 2006, 9 JOINT FAA DOD NASA
   BARBAGLI F, HAPTICS S 2004, V1, P9
   Basdogan C, 2001, IEEE-ASME T MECH, V6, P269, DOI 10.1109/3516.951365
   Bathe K.J., 1996, Finite Element Procedures
   Borodich FM, 2002, J MECH PHYS SOLIDS, V50, P2441, DOI 10.1016/S0022-5096(02)00031-5
   Burdea G, 1998, P IEEE VIRT REAL ANN, P190, DOI 10.1109/VRAIS.1998.658489
   Burdea G, 1999, IEEE T BIO-MED ENG, V46, P1253, DOI 10.1109/10.790503
   BURTON AC, 1965, PHYSL BIOPHYS CIRCUL
   Chen H, 2006, PRESENCE-VIRTUAL AUG, V15, P186, DOI 10.1162/pres.2006.15.2.186
   Daniulaitis V., 2004, P IROS 04 SEND JAP S, V4, P3907
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   DELSON NJ, P MED MEELS VIRTUAL, P45
   Dinsmore M, 1997, P IEEE VIRT REAL ANN, P54, DOI 10.1109/VRAIS.1997.583044
   Duck F A., 1990, PHYS PROPERTIES TISS
   FARAH JW, 1989, J ORAL REHABIL, V16, P603, DOI 10.1111/j.1365-2842.1989.tb01384.x
   Heng PA, 2004, IEEE T INF TECHNOL B, V8, P217, DOI 10.1109/TITB.2004.826720
   Heng PA, 2006, IEEE T INF TECHNOL B, V10, P28, DOI 10.1109/TITB.2005.855567
   Kaufman D M, 1997, Stud Health Technol Inform, V39, P467
   Kühnapfel U, 2000, COMPUT GRAPH-UK, V24, P671, DOI 10.1016/S0097-8493(00)00070-4
   LANDAU LD, 1986, VOL COURSE THEORETIC, P26
   Langrana N, 1997, COMPUT GRAPH, V21, P451, DOI 10.1016/S0097-8493(97)00021-6
   MCBEIL AR, 1983, ANIMAL MECH
   Morris D, 2006, IEEE COMPUT GRAPH, V26, P48, DOI 10.1109/MCG.2006.140
   Pawluk DTV, 1999, J BIOMECH ENG-T ASME, V121, P178, DOI 10.1115/1.2835100
   Pawluk DTV, 1999, J BIOMECH ENG-T ASME, V121, P605, DOI 10.1115/1.2800860
   Picinbono G, 2001, IEEE INT CONF ROBOT, P1370, DOI 10.1109/ROBOT.2001.932801
   Popescu V, 1999, COMP ANIM CONF PROC, P195, DOI 10.1109/CA.1999.781212
   TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840
   TITZ IR, 1994, P 128 AC SOC AM M
   Waters K., 1991, Journal of Visualization and Computer Animation, V2, P123, DOI 10.1002/vis.4340020405
   Wu W, 2004, COMPUT ANIMAT VIRT W, V15, P219, DOI 10.1002/cav.24
   Yang X, 1999, J MICROELECTROMECH S, V8, P393, DOI 10.1109/84.809053
NR 33
TC 11
Z9 13
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 339
EP 348
DI 10.1002/cav.194
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000013
DA 2024-07-18
ER

PT J
AU Guo, YW
   Zhang, FY
   Liu, CX
   Sun, HQ
   Peng, QS
AF Guo, Yanwen
   Zhang, Fuyan
   Liu, Chunxiao
   Sun, Hanqiu
   Peng, Qunsheng
TI Learning-based 3D face detection using geometric context
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE 3D face model; face detection; geometric context; AdaBoost learning
ID SYMMETRY DETECTION
AB In computer graphics community, face model is one of the most useful entities. The automatic detection of 3D face model has special significance to computer graphics, vision, and human-computer interaction. However, few methods have been dedicated to this task. This paper proposes a machine learning approach for fully automatic 3D face detection. To exploit the facial features, we introduce geometric context, a novel shape descriptor which can compactly encode the distribution of local geometry and can be evaluated efficiently by using a new volume encoding form, named integral volume. Geometric contexts over 3D face offer the rich and discriminative representation of facial shapes and hence are quite suitable to classification. We adopt an AdaBoost learning algorithm to select the most effective geometric context-based classifiers and to combine them into a strong classifier. Given an arbitrary 3D model, our method first identifies the symmetric parts as candidates with a new reflective symmetry detection algorithm. Then uses the learned classifier to judge whether the face part exists. Experiments are performed on a large set of 3D face and non-face models and the results demonstrate high performance of our method. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China.
C3 Nanjing University
RP Guo, YW (corresponding author), Nanjing Univ, Natl Lab Novel Software Technol, Nanjing 210093, Peoples R China.
EM ywguo@cad.zju.edu.cn
CR Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BLANZ V, 1999, SIGGRAPH, V99, P187
   Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70
   Colombo A, 2006, PATTERN RECOGN, V39, P444, DOI 10.1016/j.patcog.2005.09.009
   DONG Z, 2004, P PAC GRAPH 2004 OCT, P73
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gelfand N., 2005, P 3 EUR S GEOM PROC, V2, P5
   GORDON GG, 1992, FACE RECOGNITION BAS, P108
   Guo YW, 2005, COMPUT GRAPH-UK, V29, P972, DOI 10.1016/j.cag.2005.09.013
   Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X
   Mitra NJ, 2006, ACM T GRAPHIC, V25, P560, DOI 10.1145/1141911.1141924
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Podolak J, 2006, ACM T GRAPHIC, V25, P549, DOI 10.1145/1141911.1141923
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sun CM, 1997, IEEE T PATTERN ANAL, V19, P164, DOI 10.1109/34.574800
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   von Funck W, 2006, LECT NOTES COMPUT SC, V4035, P242
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang Z. Y., 2002, CATASTROPHIC LANDSLI, VXV, P149
NR 21
TC 2
Z9 2
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 483
EP 492
DI 10.1002/cav.192
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000027
DA 2024-07-18
ER

PT J
AU van der Schaaf, T
   Germans, D
   Bal, HE
   Koutek, M
AF van der Schaaf, Tom
   Germans, Desmond
   Bal, Henri E.
   Koutek, Michal
TI Lessons learned from building and calibrating the ICWall, a stereo tiled
   display
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Virtual Reality Continuum and Its
   Applications (VRCIA)
CY 2006
CL Hong Kong, PEOPLES R CHINA
SP ACM SIGGRAPH, Eurgograph Assoc, Chinese Soc Image & Graph, INI GraphicsNet
DE parallel rendering; tiled displays; stereo graphics; VR system
   architecture
AB Implementation of stereo tiled displays is a rather demanding task. In this article we want to share the lessons we have learned during the design and construction of the ICWall tiled display. This large display, used in a classroom setting, is a high-resolution stereo tiled display (2 x 8 tiles), built from low-cost commodity components. The overall image is produced by an array of projectors. When building such a system, a key challenge is to align the projector images. We describe our automated approach for alignment/calibration of the left- and right-eye stereo images. We provide measurements that show accuracy of this procedure. We explain and compare two calibration approaches: a single-pass and a two-pass rendering method to align the tiled images. We explain how to provide seamless image on the tiled display and which issues have to be solved. We also discuss the depth perception issues on the ICWall for the large audiences. Another important aspect, is the architecture of the software used for PC-cluster-based rendering. We describe Aura, the parallel scene graph API that is used for rendering on our tiled display. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Vrije Univ Amsterdam, Fac Sci, Amsterdam, Netherlands.
C3 Vrije Universiteit Amsterdam
RP van der Schaaf, T (corresponding author), Vrije Univ Amsterdam, Fac Sci, Amsterdam, Netherlands.
EM Tom@few.vu.nl
OI Bal, H.E./0000-0001-9827-4461
CR [Anonymous], ACM SIGGRAPH 1997 C
   BETHEL EW, 2003, IEEE S PAR LARG DAT
   BODEN NJ, 1995, IEEE MICRO, V15, P29, DOI 10.1109/40.342015
   Buck I., 2000, P ACM SIGGRAPH EUROG, P87, DOI DOI 10.1145/346876.348233
   CHEN Y, 2001, P 1 IEEE ACM INT S C
   Chen YQ, 2000, IEEE VISUAL, P125, DOI 10.1109/VISUAL.2000.885685
   CRUZNEIRA C, 1993, COMPUT GRAPH, V27, P135
   Funkhouser T, 2000, IEEE COMPUT GRAPH, V20, P20, DOI 10.1109/MCG.2000.851745
   GERMANS D, 2001, 5 IMM PROJ TECHN WOR
   Humphreys G, 2001, COMP GRAPH, P129, DOI 10.1145/383259.383272
   HUMPHREYS G, 2002, SIGGRAPH 2002 COMP G
   HUMPHREYS G, 2000, SC2000 HIGH PERFORMA
   KRESSE W, 2003, EGVE 03 P WORKSH VIR, P271
   LEIGH J, 2001, P ACCESSGRID RETR
   MAJUMDER A, 2002, ACM VIRTUAL REALITY, P3
   PAPE D, 2002, ENG REALITY VIRTUAL, P483
   Pape D., 1999, P 3 INT IMM PROJ TEC, P107
   RAIJ A, 2003, IEEE INT WORKSH PROJ
   Raskar R, 2003, ACM T GRAPHIC, V22, P809, DOI 10.1145/882262.882349
   Raskar R., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P109, DOI 10.1109/VR.2000.840488
   Steele RM, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P429
   VANDERSCHAAF T, 2002, 6 IMM PROJ TECHN WOR
   VANDERSCHAAF T, 2006, EUR S PAR GRAP VIS E
   VOS FM, 1998, THESIS VRIJE U AMSTE
   VUYLSTEKE P, 1990, IEEE T PATTERN ANAL, V12, P148, DOI 10.1109/34.44402
NR 25
TC 0
Z9 0
U1 1
U2 3
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2007
VL 18
IS 3
BP 193
EP 210
DI 10.1002/cav.172
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 185HG
UT WOS:000247701400005
DA 2024-07-18
ER

PT J
AU Wong, WSK
   Baciu, G
AF Wong, Wingo Sai-Keung
   Baciu, George
TI Robust continuous collision detection for interactive deformable
   surfaces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Virtual Reality Continuum and Its
   Applications (VRCIA)
CY 2006
CL Hong Kong, PEOPLES R CHINA
SP ACM SIGGRAPH, Eurgograph Assoc, Chinese Soc Image & Graph, INI GraphicsNet
DE interactive continuous collision detection; deformable surfaces; dynamic
   simulation; programmable graphics processing unit
ID AVOIDANCE
AB Collision events between 3D objects in motion in computer animations or simulations are difficult to detect due to the difficulty of accurately sampling the motion paths of objects in space and time. One approach to this problem has been continuous collision detection but because the current approaches process potentially interacting primitive pairs (PIPPs) redundantly. This is time-expensive, especially where there are a large number of PIPPs. In this paper we propose a novel collision detection process that more accurately and robustly detects collisions on simulated meshed deformable surfaces. We embed a new layer, primitive filtering layer (PFL), to extract PIPPs. This has two results. It reduces the number of PIPPs significantly and it means that each interacting primitive pair is processed just one time. Experimental results show that this approach achieves interactive rates for complex deformable surfaces with large contact regions. This is especially practical for cloth dynamics. Our method is efficient, accurate, reliable, and robust even in the presence of objects with sharp features. We also present techniques to implement the method on programmable graphics processing units (GPUs). Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Wong, WSK (corresponding author), Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
EM cswingo@comp.polyu.edu.hk
RI Baciu, George/AAU-7143-2021
OI BACIU, George/0000-0002-1766-6357
CR [Anonymous], J GR GPU GAME TOOLS
   Baciu G, 2004, IEEE T VIS COMPUT GR, V10, P649, DOI 10.1109/TVCG.2004.44
   Baciu George., 2002, P ACM S VIRTUAL REAL, P129
   BANDI S, 1995, EUROGRAPHICS 95, P259
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P200, DOI 10.1109/TPAMI.1986.4767773
   CHEN W, 2004, ACM S VIRT REAL SOFT, P10
   CHOI KJ, 2004, ACM SIGGRAPH, P604
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Govindaraju N.K., 2004, VRST 04, P2
   Govindaraju NK, 2005, ACM T GRAPHIC, V24, P991, DOI 10.1145/1073204.1073301
   Hubbard PM, 1996, ACM T GRAPHIC, V15, P179, DOI 10.1145/231731.231732
   HUBBARD PM, 1995, IEEE T VIS COMPUT GR, V1, P218, DOI 10.1109/2945.466717
   James DL, 2004, ACM T GRAPHIC, V23, P393, DOI 10.1145/1015706.1015735
   Kipfer P., 2004, GRAPHICS HARDWARE, P115
   Klosowski JT, 1998, IEEE T VIS COMPUT GR, V4, P21, DOI 10.1109/2945.675649
   KNOTT D, 2003, GRAPHICS INTERFACE
   KOLB A, 2004, GRAPHICS HARDWARE
   LIN MC, 1999, IMA C MATH SURF
   Liu JD, 1998, COMPUT GRAPH, V22, P117, DOI 10.1016/S0097-8493(97)00087-3
   Liu JD, 1996, VISUAL COMPUT, V12, P234
   Mirtich BV., 1996, Impulse-based dynamic simulation of rigid body systems
   Moore M., 1988, Computer Graphics, V22, P289, DOI 10.1145/378456.378528
   Ponamgi MK, 1997, IEEE T VIS COMPUT GR, V3, P51, DOI 10.1109/2945.582346
   PROVOT X, 1995, GRAPH INTER, P147
   Provot Xavier, 1997, COMPUTER ANIMATION S, P177
   SMITH A, 1995, IEEE VIRT REAL ANN I, P136
   TESCHNER M, 2005, EUROGRAPHICS STATE A
   Vassilev T, 2001, COMPUT GRAPH FORUM, V20, pC260, DOI 10.1111/1467-8659.00518
   VERLET L, 1967, PHYS REV, V159, P98, DOI 10.1103/PhysRev.159.98
   VOLINO P, 1994, COMPUT GRAPH FORUM, V13, pC155, DOI 10.1111/1467-8659.1330155
   Wong WSK, 2005, COMPUT ANIMAT VIRT W, V16, P153, DOI 10.1002/cav.104
   Wong WSK, 2005, IEEE T VIS COMPUT GR, V11, P329, DOI 10.1109/TVCG.2005.44
   WONG WSK, 2005, THESIS HONG KONG U S
   WONG WSK, 2006, ACM INT C VIRT REAL, P181
   WONT WSK, 2005, RES J TEXTILE APPARE, V9, P60
   Zhang DL, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P328, DOI 10.1109/PCCGA.2000.883956
   IEEE INT C ROB AUT U
NR 38
TC 8
Z9 9
U1 2
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2007
VL 18
IS 3
BP 179
EP 192
DI 10.1002/cav.173
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 185HG
UT WOS:000247701400004
DA 2024-07-18
ER

PT J
AU Lee, J
   Lee, J
   Kim, H
   Kim, JI
AF Lee, Jangho
   Lee, Jun
   Kim, HyungSeok
   Kim, Jee-In
TI Believable interaction with a quasi-tangible tabletop interface
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE HCI; tabletop interface; believability; hand gestures; large displays
AB In this paper, we present a believable interaction mechanism for manipulation multiple objects in ubiquitous/augmented virtual environment. A believable interaction in multimodal framework is defined as a persistent and consistent process according to contextual experiences and common-senses on the feedbacks. We present a tabletop interface as a quasi-tangible framework to provide believable processes. An enhanced tabletop interface is designed to support multimodal environment. As an exemplar task, we applied the concept to fast accessing and manipulating distant objects. A set of enhanced manipulation mechanisms is Presented for remote manipulations including inertial widgets, transformable tabletop, and proxies. The proposed method is evaluated in both performance and user acceptability in comparison with previous approaches. The proposed technique uses intuitive hand gestures and provides higher level of believability. It can also support other types of accessing techniques such as browsing and manipulation. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Konkuk Univ, Dept Internet & Multimedia Engn, Seoul, South Korea.
C3 Konkuk University
RP Kim, JI (corresponding author), Konkuk Univ, Dept Internet & Multimedia Engn, Seoul, South Korea.
EM hyung.kim@acm.org
RI Lee, Jun/D-9548-2011; SEOK, KIM HYUNG/C-2742-2009
OI SEOK, KIM HYUNG/0000-0003-4816-2992
CR [Anonymous], 1999, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/302979.303114
   [Anonymous], 1999, P C HUM FACT COMP SY
   Baudisch P., 2003, Proceedings of INTERACT, P57
   Bezerianos A., 2005, Proceedings of the ACM CHI Conference on Human Factors in Computing Systems, P361, DOI [10.1145/1054972.1055023, DOI 10.1145/1054972.1055023]
   BOWMAN DA, 1997, S INTERACTIVE 3D GRA, V182, P35
   Czerwinski M., 2006, PROC CHI 06, P69, DOI DOI 10.1145/1125451.1125471
   GEIBLER J, 1998, CHI 98 CHI 98 C SUMM, P265
   Hinrichs U, 2005, LECT NOTES COMPUT SC, V3638, P185
   KIM HS, 2004, WORKSH BEL VIRT ENV
   LEE J, 2006, ICCSA, P983
   MAGNENATTHALMAN.N, 2005, INT MULT MED MOD C J, P2
   MINE MR, 1995, TR95018, P4
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Reetz A, 2006, PROC GRAPH INTERF, P163
   REKIMOTO J, 1977, P 10 ANN ACM S US IN, P31
   Wu M., 2003, Proceedings of the 16th annual ACM symposium on User interface software and technology, P193, DOI DOI 10.1145/964696.964718
NR 16
TC 3
Z9 4
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2007
VL 18
IS 2
BP 121
EP 132
DI 10.1002/cav.167
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 181AO
UT WOS:000247409300005
DA 2024-07-18
ER

PT J
AU Leung, HC
   Hui, KC
AF Leung, Hoi-Chau
   Hui, Kin-Chuen
TI Deformation by examples: a density flow approach
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deformation; morphing; optical flow
ID SPACE
AB In this article, a shape- transformation technique is introducedfor deforming objects based on a given deformation example. The example consists of two reference shapes representing two different states of an object. The reference shapes are assumed to morph from one state to the other. The evolution between the two reference shapes determines the shape transformation function. Any given objects can then be deformed by the same transformation. A continuous 4D Radial Basis Function is used to construct a densityflow field (an extension of the optical flow in computer vision) representing the shape transformation of the example in 3-space. Objects embedded in the density flow field are deformed by moving vertices of the objects along the density flow vectors. Additional parameters are introduced to control the process of the deformation. This provides explicit control on the shape of the object obtained'in the deformation process. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Chinese Univ Hong Kong, Dept Automat & Comp Aided Engn, Comp Aided Design Lab, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Hui, KC (corresponding author), Chinese Univ Hong Kong, Dept Automat & Comp Aided Engn, Comp Aided Design Lab, Hong Kong, Hong Kong, Peoples R China.
EM kchui@acae.cuhk.edu.hk
CR Albrecht Irene., 2003, P 2003 ACM SIGGRAPHE, P98
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   [Anonymous], 2002, Numerical Recipes in C++: The Art of Scientific Computing
   [Anonymous], P SIGGRAPH 87
   [Anonymous], SIGGRAPH 86
   Carr JC, 1997, IEEE T MED IMAGING, V16, P96, DOI 10.1109/42.552059
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   CARR JC, 2003, GRAPHITE 03 P 1 INT, P119
   CHEN DT, 1992, COMP GRAPH, V26, P89, DOI 10.1145/142920.134016
   Cohen-Or D, 1998, ACM T GRAPHIC, V17, P116, DOI 10.1145/274363.274366
   Duchon Jean, 1976, LECT NOTES MATH, V571, P85, DOI DOI 10.1007/BFB0086566
   Egbert PK, 1996, IEEE COMPUT GRAPH, V16, P18, DOI 10.1109/38.511848
   GALVIN B, 1998, BRIT MED VIS C
   Greenberg M., 1998, ADV ENG MATH
   HOM BKP, 1981, ARTIF INTELL, V17, P185
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   LEFEBURE M, 1999, P CEDYA, V16, P1349
   Ma Y, 2000, INT J COMPUT VISION, V36, P71, DOI 10.1023/A:1008124507881
   MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Schnorr C., 1994, Proceedings of the 12th IAPR International Conference on Pattern Recognition (Cat. No.94CH3440-5), P661, DOI 10.1109/ICPR.1994.576391
   Schroeder W. J., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P126, DOI 10.1109/VISUAL.1991.175789
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Turk G, 1999, COMP GRAPH, P335, DOI 10.1145/311535.311580
   Weickert J, 2001, J MATH IMAGING VIS, V14, P245, DOI 10.1023/A:1011286029287
NR 25
TC 0
Z9 0
U1 0
U2 0
PU WILEY-BLACKWELL
PI MALDEN
PA COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2007
VL 18
IS 2
BP 95
EP 105
DI 10.1002/cav.164
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 181AO
UT WOS:000247409300003
DA 2024-07-18
ER

PT J
AU Kye, H
   Shin, BS
   Shin, YG
   Hong, H
AF Kye, H
   Shin, BS
   Shin, YG
   Hong, H
TI Shear-rotation-warp volume rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE shear-warp factorization; spatial locality of memory references;
   interactive classification
AB Shear-warp volume rendering has the advantages of a moderate image quality and a fast rendering speed. However, in the case of dynamic changes in the opacity transfer function, the efficiency of memory access drops, as the method cannot exploit pre-classified volumes. In this paper, we propose all efficient algorithm that exploits the spatial locality of memory references for interactive classifications. The algorithm inserts a rotation matrix when factorizing the viewing transformation, so that it may perform a scanline-based traversal in both object space and image space. In addition, we present solutions to some problems of the proposed method, namely inaccurate front-to-back composition, the occurrence of holes, and increased computation. Our method is noticeably faster than traditional shear-warp rendering methods because of all improved utilization of cache memory. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Seoul Natl Univ, Sch Elect Engn & Comp Sci, Seoul 151742, South Korea.
C3 Seoul National University (SNU)
RP Hong, H (corresponding author), Seoul Natl Univ, Sch Elect Engn & Comp Sci, San 56-1 Shinlim Dong, Seoul 151742, South Korea.
EM hlhong@cse.snu.ac.kr
CR Cabral B., 1994, P 1994 S VOLUME VISU, P91, DOI DOI 10.1145/197938.197972
   Doggett M.C., 1995, P 10 EUROGRAPHICS WO, P93
   Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484
   ENGEL K, 2001, EUR SIGGRAPH WORKSH, P9
   Farin G., 1997, Curves and surfaces for cagd: a pratical guide, V4th
   Frisken SF, 2000, COMP GRAPH, P249, DOI 10.1145/344779.344899
   GARGANTINI I, P SPIE 1986, V626, P460
   Gibson SFF, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P23, DOI 10.1109/SVV.1998.729581
   Gunther T, 1995, COMPUT GRAPH, V19, P705, DOI 10.1016/0097-8493(95)00049-6
   Hennessy John L, 2011, Computer Architecture: A Quantitative Approach
   KAUFMAN A, 1993, COMPUTER, V26, P51, DOI 10.1109/MC.1993.274942
   Kim TY, 2001, COMPUT GRAPH-UK, V25, P819, DOI 10.1016/S0097-8493(01)00124-8
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   LACROUTE P, 2003, VOLPACK SOFTWARE DIS
   Lacroute P.G., 1995, CSLTR95678 STANF U
   Lee CH, 1997, FIFTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P138, DOI 10.1109/PCCGA.1997.626190
   LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6
   Osborne R., 1997, P SIGGRAPHEUROGRAPHI, P131
   Ray H, 1999, IEEE T VIS COMPUT GR, V5, P210, DOI 10.1109/2945.795213
   UDUPA JK, 1993, IEEE COMPUT GRAPH, V13, P58, DOI 10.1109/38.252558
   Yagel R., 1992, Computer Graphics Forum, V11, pC153, DOI 10.1111/1467-8659.1130153
   ZUIDERVELD KJ, 1992, P SOC PHOTO-OPT INS, V1808, P324, DOI 10.1117/12.131088
   [No title captured]
NR 25
TC 1
Z9 1
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2005
VL 16
IS 5
BP 547
EP 557
DI 10.1002/cav.67
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 989NE
UT WOS:000233680000002
OA Bronze
DA 2024-07-18
ER

PT J
AU Matsuyama, K
   Fujimoto, T
   Muraoka, K
   Chiba, N
AF Matsuyama, K
   Fujimoto, T
   Muraoka, K
   Chiba, N
TI Generation of tree movement sound effects
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; natural phenomena; moving trees; sound modelling;
   sound rendering
AB This paper presents a method for automatically generating sound effects for an animation of branches and leaves moving in the wind. Each tree is divided into branches and leaves, and an independent sound effect generation process is employed for each element. The individual results are then compounded into one sound effect. For the branches, we employ an approach based on the frequencies of experimentally obtained Karman vortex streets. For the leaves, we use the leaf blade state as the input and assume a virtual musical instrument that uses wave tables as the sound source. All computations can be performed independently for each frame step. Therefore, each frame step can be executed on completion of the animation step. The results of the implementation of the approach are presented and it is shown that the process offers the possibility of real-time operation through the use of parallel computing techniques. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Future Univ Hakodate, Dept Media Architecture, Hakodate, Hokkaido 0418655, Japan.
C3 Future University Hakodate
RP Matsuyama, K (corresponding author), Future Univ Hakodate, Dept Media Architecture, 116-2 Kameda,Nakanocho, Hakodate, Hokkaido 0418655, Japan.
EM kmatsu@fun.ac.jp
CR [Anonymous], P 20 ANN C COMP GRAP
   Barnsley M.F, 1988, The Science of Fractal Images
   CHIBA N, 1994, COMPUT GRAPH-UK, V18, P469, DOI 10.1016/0097-8493(94)90059-0
   Cook PR, 2002, IEEE COMPUT GRAPH, V22, P23, DOI 10.1109/MCG.2002.1016695
   DOBASHI Y, 2003, SIGGRAPH 2003, P732
   Dubnov S, 2002, IEEE COMPUT GRAPH, V22, P38, DOI 10.1109/MCG.2002.1016697
   Funkhouser T, 1999, COMP GRAPH, P365, DOI 10.1145/311535.311590
   Funkhouser T., 1998, P 25 ANN C COMPUTER, P21, DOI DOI 10.1145/280814.280818
   Lokki T, 2002, IEEE COMPUT GRAPH, V22, P49, DOI 10.1109/MCG.2002.1016698
   Lugt H. J., 1983, Vortex Flow in Nature and Technology
   Mech Radomir., 1996, Proceedings of the 23rd annual conference on Computer graphics and interactive techniques. SIGGRAPH'96, P397, DOI [10.1145/237170.237279, DOI 10.1145/237170.237279]
   Min P, 2000, COMPUT GRAPH FORUM, V19, pC179, DOI 10.1111/1467-8659.00410
   O'Brien JF, 2001, COMP GRAPH, P529, DOI 10.1145/383259.383321
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   Pai DK, 2001, COMP GRAPH, P87, DOI 10.1145/383259.383268
   REFFYE P, 1988, P ACM SIGGRAPH 88 AC, V22, P151
   Reynolds M, 2001, COMP GRAPH, P553, DOI 10.1145/383259.383324
   Roads Curtis., 1996, The Computer Music Tutorial
   SHINYA M, 1992, COMPUT GRAPH FORUM, V11, pC119
   Takala T., 1992, Computer Graphics, V26, P211, DOI 10.1145/142920.134063
   Tsingos N, 2001, COMP GRAPH, P545, DOI 10.1145/383259.383323
   Tsingos N, 2002, IEEE COMPUT GRAPH, V22, P28, DOI 10.1109/MCG.2002.1016696
   van den Doel K, 2001, COMP GRAPH, P537, DOI 10.1145/383259.383322
NR 23
TC 0
Z9 0
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2005
VL 16
IS 5
BP 531
EP 545
DI 10.1002/cav.58
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 989NE
UT WOS:000233680000001
DA 2024-07-18
ER

PT J
AU Aminian, K
   Najafi, B
AF Aminian, Kamiar
   Najafi, Bijan
TI Capturing human motion using body-fixed sensors: outdoor measurement and
   clinical applications
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Motion capture; sensors; outdoor monitoring; gait; posture; clinical
   studies
ID MINIATURE ACCELEROMETERS; AMBULATORY SYSTEM; PHYSICAL-ACTIVITY;
   KINEMATIC SENSOR; GAIT ANALYSIS; PERFORMANCE; MOVEMENT; POSITION;
   REMOVAL; WALKING
AB Motion capture is mainly based oil standard systems using optic, magnetic or sonic technologies. In this paper, the possibility to detect useful human motion based on new techniques using different types of body-fixed sensors is shown. In particular, a combination of accelerometers and angular rate sensors (gyroscopes) showed a promising design for a hybrid kinematic sensor measuring the 2D kinematics of a body segment. The sensors together with a portable datalogger, and using simple biomechanical models, allow capture of outdoor and long-term movements and overcome some limitations of the standard motion capture systems. Significant parameters of body motion, such as nature Of motion (postural transitions, trunk rotation, sitting, standing, lying, walking, jumping) and its spatio-temporal features (velocity, displacement, angular rotation, cadence and duration) have been evaluated and compared to the camera-based system. Based oil these parameters, the paper outlines the possibility to monitor physical activity and to perform gait analysis in the daily environment, and reviews several clinical investigations related to fall risk in file elderly, quality of life, orthopaedic outcome and sport performance. Taking advantage of till the potential of these body-fixed sensors should be promising for motion capture and particularly in environments not suitable for standard technology such as in any field activity. Copyright (C) 2004 John Wiley & Sons, Ltd.
C1 [Aminian, Kamiar; Najafi, Bijan] Swiss Fed Inst Technol, Sch Engn, Lab Movement Anal & Measurement, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Aminian, K (corresponding author), Swiss Fed Inst Technol, Sch Engn, Lab Movement Anal & Measurement, CH-1015 Lausanne, Switzerland.
EM kamiar.aminian@epfl.ch
RI Najafi, Bijan/AAK-5650-2020; Aminian, Kamiar/H-4568-2011
OI Najafi, Bijan/0000-0002-0320-8101; Aminian, Kamiar/0000-0002-6582-5375
CR AbuFaraj ZO, 1997, J REHABIL RES DEV, V34, P187
   Aminian K, 2002, J BIOMECH, V35, P689, DOI 10.1016/S0021-9290(02)00008-8
   Aminian K, 1999, MED BIOL ENG COMPUT, V37, P304, DOI 10.1007/BF02513304
   Aminian K, 1998, LECT NOTES ARTIF INT, V1537, P1
   Aminian K, 1999, MED BIOL ENG COMPUT, V37, P686, DOI 10.1007/BF02513368
   [Anonymous], 1996, P 7 EUROGRAPHICS INT
   ASCH G, 1991, CAPTEURS INSTRUMENTA, P386
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Bodenheimer Bobby., 1997, COMPUTER ANIMATION S, P3
   BUCHSER EE, 2002, 10 WORLD C PAIN SAN
   CALAME C, P 18 C INT SOC BIOM
   Cappozzo A, 1997, IEEE T BIO-MED ENG, V44, P1165, DOI 10.1109/10.649988
   Cappozzo A, 1996, CLIN BIOMECH, V11, P90, DOI 10.1016/0268-0033(95)00046-1
   Chang TC, 2001, WA SCI TECHNOL, V1, P49, DOI 10.2166/ws.2001.0099
   CHANG WL, 1998, 3 WORLD C BIOM SAPP
   Chau T, 2001, GAIT POSTURE, V13, P102, DOI 10.1016/S0966-6362(00)00095-3
   DEJNABADI H, 2002, EORS 2002 T, V12, pO96
   Delaney B, 1998, IEEE COMPUT GRAPH, V18, P14, DOI 10.1109/38.708556
   Dickstein R, 1996, CLIN BIOMECH, V11, P173, DOI 10.1016/0268-0033(95)00063-1
   FYFE KR, 2001, Patent No. 1066793
   GRETILLAT F, 1998, THESIS U NEUCHATEL
   Hase K, 2003, J VISUAL COMP ANIMAT, V14, P73, DOI 10.1002/vis.306
   Herda L, 2001, HUM MOVEMENT SCI, V20, P313, DOI 10.1016/S0167-9457(01)00050-1
   Kemp B, 1998, ELECTROMYOGR MOTOR C, V109, P484, DOI 10.1016/S0924-980X(98)00053-8
   Komura T, 1999, J VISUAL COMP ANIMAT, V10, P57, DOI 10.1002/(SICI)1099-1778(199904/06)10:2<57::AID-VIS196>3.0.CO;2-R
   Lieberman JR, 1996, J BONE JOINT SURG AM, V78A, P835, DOI 10.2106/00004623-199606000-00005
   Maki BE, 1997, J AM GERIATR SOC, V45, P313, DOI 10.1111/j.1532-5415.1997.tb00946.x
   MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554
   MARTINET N, 1994, MARCHE HUMAINE SA PA, P75
   Najafi B, 2003, IEEE T BIO-MED ENG, V50, P711, DOI 10.1109/TBME.2003.812189
   Najafi B, 2000, 1ST ANNUAL INTERNATIONAL IEEE-EMBS SPECIAL TOPIC CONFERENCE ON MICROTECHNOLOGIES IN MEDICINE & BIOLOGY, PROCEEDINGS, P562, DOI 10.1109/MMB.2000.893847
   Najafi B, 2002, IEEE T BIO-MED ENG, V49, P843, DOI 10.1109/TBME.2002.800763
   NAJAFI B, 2001, ESMAC 2001 GAIT POST, V14, P119
   NAJAFI B, 2001, P INT SOC POST GAIT, P135
   NAJAFI B, 2002, Patent No. 1195139
   NAJAFI B, 2003, THESIS EPFL LAUSANNE
   NYBERG L, 1995, STROKE, V26, P838, DOI 10.1161/01.STR.26.5.838
   PAI YC, 1990, MED SCI SPORT EXER, V22, P378
   PARASCHIVIONESC.A, 2001, P 18 C INT SOC BIOM, P378
   Prince F, 1997, GAIT POSTURE, V5, P128, DOI 10.1016/S0966-6362(97)01118-1
   RODUIT R, IEEE T INSTRUMENTATI, V47, P1020
   Sagawa K, 2000, IEEE SYS MAN CYBERN, P1847, DOI 10.1109/ICSMC.2000.886378
   Sparks DR, 1998, MICROSYST TECHNOL, V4, P139, DOI 10.1007/s005420050117
   TINETTI ME, 1986, J AM GERIATR SOC, V34, P119, DOI 10.1111/j.1532-5415.1986.tb05480.x
   Tong KY, 1999, MED ENG PHYS, V21, P87, DOI 10.1016/S1350-4533(99)00030-2
   Vaughan C., 1999, Dynamics of Human Gait
   Wachowiak MP, 2000, IEEE T BIO-MED ENG, V47, P360, DOI 10.1109/10.827298
   WALL JC, 1981, J BIOMED ENG, V3, P121, DOI 10.1016/0141-5425(81)90004-2
   Williamson R, 2001, MED BIOL ENG COMPUT, V39, P294, DOI 10.1007/BF02345283
   WU G, 1993, J BIOMECH ENG-T ASME, V115, P53, DOI 10.1115/1.2895471
   ZHU HS, 1991, ARCH PHYS MED REHAB, V72, P390
   2000, SPORTS EXERCISE S, V32, pS439
NR 52
TC 189
Z9 227
U1 2
U2 62
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2004
VL 15
IS 2
BP 79
EP 94
DI 10.1002/cav.2
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA V10FD
UT WOS:000207449000003
OA Bronze
DA 2024-07-18
ER

PT J
AU Evripidou, E
   Aristidou, A
   Charalambous, P
AF Evripidou, Eleni
   Aristidou, Andreas
   Charalambous, Panayiotis
TI Collaborative museum heist with reinforcement learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE AI-based animation; collaborative multi-agents; reinforcement learning
ID LEVEL
AB Non-playable characters (NPCs) play a crucial role in enhancing immersion in video games. However, traditional NPC behaviors are often hard-coded using methods such as Finite State Machines, Decision and Behavior trees. This has a few limitations; namely, it is quite difficult to implement complex cooperative behaviors and secondly this makes it easy for human players to identify and exploit patterns in behavior. To overcome these challenges, Reinforcement learning (RL) can be used to generate dynamic and real-time NPC responses to human player actions. In this paper, we report on first results of applying RL techniques to a Non-Zero Sum, adversarial asymmetric game, using a multi-agent team. The game environment simulates a museum heist, where the objective of the successfully trained team of robbers with different skills (Locksmith, Technician) is to steal valuable items from the museum without being detected by the scripted security guards and cameras. Both agents were trained concurrently with separate policies and received both individual and group reward signals. Through this training process, the agents learned to cooperate effectively and use their skills to maximize both individual and team benefits. These results demonstrate the feasibility of realizing the full game where both robbers and security guards are trained at the same time to achieve their adversarial goals.
C1 [Evripidou, Eleni; Aristidou, Andreas] Univ Cyprus, Dept Comp Sci, Nicosia, Cyprus.
   [Evripidou, Eleni; Aristidou, Andreas; Charalambous, Panayiotis] CYENS Ctr Excellence, Res Dept, Nicosia, Cyprus.
C3 University of Cyprus
RP Evripidou, E (corresponding author), Univ Cyprus, Dept Comp Sci, Nicosia, Cyprus.
EM evripidou.eleni@ucy.ac.cy
OI Aristidou, Andreas/0000-0001-7754-0791
FU Horizon 2020 Framework Programme [739578]; University of Cyprus
FX Horizon 2020 Framework Programme,Grant/Award Number: 739578;
   Universityof Cyprus
CR [Anonymous], 1997, DEEP BLUE
   Baker Bowen., 2019, Emergent Tool Use From Multi-Agent Autocurricula
   Berner C., DOTA 2 LARGE SCALE D
   Foerster JN, 2016, ADV NEUR IN, V29
   Juliani A., 2018, ARXIV180902627
   Littman M. L., 1994, P MACH LEARN P, P157
   Mannion P., DEEP REINFORCEMENT L
   Mark D., 2009, APPL MATH SERIES COU
   Millington I., 2018, Artificial Intelligence for Games
   Mirowski Piotr., Learning to navigate in complex environments
   Mnih V., PLAYING ATARI DEEP R
   Nash JF, 1950, ECONOMETRICA, V18, P155, DOI 10.2307/1907266
   Osborne Martin J, 1994, COURSE GAME THEORY
   Panayiotou A., 2022, CCP: configurable crowd profiles. ACM SIGGRAPH 2022 conference proceedings
   Schulman J., 2017, ARXIV
   Silver D., MASTERING CHESS SHOG
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   TESAURO G, 1994, NEURAL COMPUT, V6, P215, DOI 10.1162/neco.1994.6.2.215
   Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z
NR 19
TC 1
Z9 1
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2158
EA MAY 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000988307600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Yu, YF
   Xiang, W
   Jin, XG
AF Yu, Yingfei
   Xiang, Wei
   Jin, Xiaogang
TI Multi-level crowd simulation using social LSTM
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; data-driven method; hybrid control
ID NAVIGATION; MODEL
AB Due to the complex and subtle behaviors of humans, realistic crowd simulation is difficult. To that end, we propose a novel crowd simulation method that can generate realistic crowd animations with behaviors similar to real crowds and model complex pedestrian behaviors at multiple levels using social long short-term memory (LSTM) neural networks. At the high level, our multi-level simulation model provides global group navigation while at the low level, it can simulate local individual interactions with collision avoidance. We introduce a data-driven method using an improved social LSTM for learning local motion decisions from real pedestrian trajectories in order to capture the subtle movements of the crowd. To achieve scalability, we formulate the low-level and high-level motion control in a force-based scheme. Extensive simulation results demonstrate that our method can produce realistic crowd animations in a variety of scenarios. Evaluations in various metrics show that our method produces better crowd behaviors than previous methods.
C1 [Yu, Yingfei; Xiang, Wei; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
EM jin@cad.zju.edu.cn
OI Xiang, Wei/0000-0002-0656-2851; Jin, Xiaogang/0000-0001-7339-2920
FU National Natural Science Foundation of China [62036010]; Key R&D Program
   of Zhejiang [2023C01047]
FX ACKNOWLEDGMENTS Xiaogang Jin was supported by the National Natural
   Science Foundation of China (Grant No. 62036010), and Key R&D Program of
   Zhejiang (No. 2023C01047).
CR Alahi A., P IEEE C COMP VIS PA
   Chao QW, 2019, IEEE INT CONF ROBOT, P8298, DOI [10.1109/icra.2019.8794430, 10.1109/ICRA.2019.8794430]
   Charalambous P, 2014, COMPUT GRAPH FORUM, V33, P95, DOI 10.1111/cgf.12403
   Gupta Agrim, P IEEE C COMP VIS PA
   Han Y, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1974
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Helbing D, 2001, ENVIRON PLANN B, V28, P361, DOI 10.1068/b2697
   Jiang C., P ACM SIGGRAPH EUR S
   Jiang H, 2010, COMPUT GRAPH-UK, V34, P537, DOI 10.1016/j.cag.2010.05.013
   Ju Eunjung., 2010, ACM T GRAPHIC, V29, P1
   Kapadia M, 2012, VISUAL COMPUT, V28, P1209, DOI 10.1007/s00371-011-0669-5
   Karamouzas I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073705
   Karamouzas I, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.238701
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Kim S, 2015, VISUAL COMPUT, V31, P541, DOI 10.1007/s00371-014-0946-1
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Li Y., P ACM SIGGRAPH EUR S
   López A, 2019, COMPUT GRAPH FORUM, V38, P181, DOI 10.1111/cgf.13629
   Moussaïd M, 2009, P ROY SOC B-BIOL SCI, V276, P2755, DOI 10.1098/rspb.2009.0405
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Oshita M, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1878
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Ren JP, 2021, IEEE T VIS COMPUT GR, V27, P1953, DOI 10.1109/TVCG.2019.2946769
   Reynolds CW., P 14 ANN C COMP GRAP
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Tsai TY, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1765
   van Toll W., 2020, P S INTERACTIVE 3D G, P1
   Zhang J, 2012, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2012/02/P02002
NR 29
TC 1
Z9 1
U1 4
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2180
EA MAY 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000987499700001
DA 2024-07-18
ER

PT J
AU Chang, CJ
   Zhao, L
   Zhang, S
   Kapadia, M
AF Chang, Che-Jui
   Zhao, Long
   Zhang, Sen
   Kapadia, Mubbasir
TI Disentangling audio content and emotion with adaptive instance
   normalization for expressive facial animation synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 35th International Conference on Computer Animation and Social Agents
   (CASA)
CY JUL 05-07, 2022
CL Nanjing, PEOPLES R CHINA
SP Nanjing Univ
DE adaptive instance normalization; audio-driven animation; content-emotion
   disentanglement; emotion-conditioning; expressive facial animation
   synthesis
AB 3D facial animation synthesis from audio has been a focus in recent years. However, most existing literature works are designed to map audio and visual content, providing limited knowledge regarding the relationship between emotion in audio and expressive facial animation. This work generates audio-matching facial animations with the specified emotion label. In such a task, we argue that separating the content from audio is indispensable-the proposed model must learn to generate facial content from audio content while expressions from the specified emotion. We achieve it by an adaptive instance normalization module that isolates the content in the audio and combines the emotion embedding from the specified label. The joint content-emotion embedding is then used to generate 3D facial vertices and texture maps. We compare our method with state-of-the-art baselines, including the facial segmentation-based and voice conversion-based disentanglement approaches. We also conduct a user study to evaluate the performance of emotion conditioning. The results indicate that our proposed method outperforms the baselines in animation quality and expression categorization accuracy.
C1 [Chang, Che-Jui; Zhao, Long; Zhang, Sen; Kapadia, Mubbasir] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
C3 Rutgers University System; Rutgers University New Brunswick
RP Chang, CJ (corresponding author), Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
EM chejui.chang@rutgers.edu
RI Zhao, Long/AAK-9782-2020
OI Zhao, Long/0000-0001-8921-8564; Chang, Che-Jui/0000-0001-7935-8723
FU NSF [IIS-1703883, IIS-1955404, IIS-1955365, RETTL-2119265,
   EAGER-2122119]; U.S. Department of Homeland Security [22STESE00001 01
   01]
FX The research was supported in part by NSF awards: IIS-1703883,
   IIS-1955404, IIS-1955365, RETTL-2119265, and EAGER-2122119. This
   material is based upon work supported by the U.S. Department of Homeland
   Security under Grant Award Number 22STESE00001 01 01.
CR Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392469
   [Anonymous], 2021, QUALTRICS PROVO
   Athar SR., 2020, ARXIV
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Chen AP, 2019, IEEE I CONF COMP VIS, P9428, DOI 10.1109/ICCV.2019.00952
   Cudeiro D, 2019, PROC CVPR IEEE, P10093, DOI 10.1109/CVPR.2019.01034
   Egger B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3395208
   Feng Y., 2020, ARXIV
   Guo J., 2020, P EUROPEAN C COMPUTE
   Guo Y., 2021, P IEEECVF INT C COMP, P5784
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Ji X., 2021, P IEEE CVF C COMP VI, P14080
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Pham HX, 2017, IEEE COMPUT SOC CONF, P2328, DOI 10.1109/CVPRW.2017.287
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Qian KZ, 2019, PR MACH LEARN RES, V97
   Qian KZ, 2020, INT CONF ACOUST SPEE, P6284, DOI [10.1109/ICASSP40776.2020.9054734, 10.1109/icassp40776.2020.9054734]
   Radford A., UNSUPERVISED REPRESE
   SONG L., 2020, ARXIV
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Thies Justus, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P716, DOI 10.1007/978-3-030-58517-4_42
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8
   Wang K., 2020, MEAD LARGE SCALE AUD
   Wen X, 2020, IEEE T VIS COMPUT GR, V26, P3457, DOI 10.1109/TVCG.2020.3023573
   Yang HT, 2020, PROC CVPR IEEE, P598, DOI 10.1109/CVPR42600.2020.00068
   Zhao L, 2020, INT J COMPUT VISION, V128, P2514, DOI 10.1007/s11263-020-01328-9
   Zhou H, 2021, PROC CVPR IEEE, P4174, DOI 10.1109/CVPR46437.2021.00416
   [周亚星 Zhou Yaxing], 2020, [电工电能新技术, Advanced Technology of Electrical Engineering and Energy], V39, P1
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
NR 31
TC 4
Z9 4
U1 4
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2076
DI 10.1002/cav.2076
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 2S4AL
UT WOS:000821735900010
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, RZ
   Oji, R
   Fujishiro, I
AF Li, Ruizhe
   Oji, Ryo
   Fujishiro, Issei
TI Controllable automatic generation of non-player characters in 3D anime
   style
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D character generation; outfit; neural network; non-player characters
AB Game creators always use prefabricated models as non-player characters (NPCs) to create an atmosphere for game scenes. However, players are likely to see different NPCs with the same 3D models because creators usually cannot prepare a high number of NPC models for big game scenes. In this article, we present an anime-like character customization system, where each customizing parameter can adjust the shape or color for the corresponding part of the character model. Based on this system, we propose an improved approach for generating a rich variety of 3D anime-like NPCs including body models and clothing items in different styles. We introduce a neural network to control the facial appearances, Gaussian mixture models to control the colors of hair and clothes, and a Bayesian network to control the outfits of clothing items. We demostrate that the proposed approach can maintain the variety and stability of the generated characters.
C1 [Li, Ruizhe; Oji, Ryo] Keio Univ, Grad Sch Sci & Technol, Yokohama, Kanagawa, Japan.
   [Fujishiro, Issei] Keio Univ, Fac Sci & Technol, Yokohama, Kanagawa, Japan.
C3 Keio University; Keio University
RP Fujishiro, I (corresponding author), Keio Univ, Fac Sci & Technol, Yokohama, Kanagawa, Japan.
EM ifujishiro@keio.jp
OI Li, Ruizhe/0000-0003-0216-3703
FU Japan Society for the Promotion of Science [17H00737, 20K20481,
   21H04916]; Grants-in-Aid for Scientific Research [20K20481, 21H04916]
   Funding Source: KAKEN
FX Japan Society for the Promotion of Science, Grant/Award Numbers:
   17H00737, 20K20481, 21H04916
CR [Anonymous], 2012, P 20 ACM INT C MULT
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Chalás I, 2017, VISUAL COMPUT, V33, P443, DOI 10.1007/s00371-016-1277-1
   COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110
   Electronic Arts Inc , SIMS 4
   Jackson C., 1987, COLOR ME BEAUTIFUL D
   Juliani A., 2018, ARXIV180902627
   Koei Tecmo Holdings Company Limited , AT RYZ 2 LOST LEG SE
   Li R., 2020, AUTOMATIC GENERATION, P110
   McDonnell R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360625
   McDonnell R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531361
   Niki T, 2019, 2019 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P53, DOI 10.1109/CW.2019.00017
   O'Donovan P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964958
   Pixiv Inc, VROID STUD
   Sega Games Company Limited , YAK DRAG
   Shi TY, 2019, IEEE I CONF COMP VIS, P161, DOI 10.1109/ICCV.2019.00025
   SIMOSERRA E, 2015, PROC CVPR IEEE, P869, DOI DOI 10.1109/CVPR.2015.7298688
   Square Enix Company Limited , FIN FANT 15
   Tangseng P, 2017, IEEE INT CONF COMP V, P2275, DOI 10.1109/ICCVW.2017.267
   Tsujita H., 2010, P INT C ADV VISUAL I, P127, DOI DOI 10.1145/1842993.1843016
   Ulicny B, 2002, COMPUT GRAPH FORUM, V21, P767, DOI 10.1111/1467-8659.00634
   Yu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366153
NR 23
TC 1
Z9 1
U1 4
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2023
VL 34
IS 2
AR e2047
DI 10.1002/cav.2047
EA APR 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D7UU4
UT WOS:000782201200001
DA 2024-07-18
ER

PT J
AU Li, K
   Zhao, HT
   Zhang, Q
   Jia, JY
AF Li, Ke
   Zhao, Hantao
   Zhang, Qian
   Jia, Jinyuan
TI CEBOW: A Cloud-Edge-Browser Online Web3D approach for visualizing large
   BIM scenes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cache management; Cloud-Edge-Browser collaboration; edge computing;
   optimal initial loading; transmission scheduling; WebBIM
ID CONSTRUCTION; ARCHITECTURE; MANAGEMENT
AB With the mobile technology continues to grow and evolve, the technology of presenting building information modeling (BIM) with an online platform has become an important application in the fields of civil engineering, architecture, and computer visualization. However, due to network bandwidth and browser performance limitations, it was difficult to display large-scale BIM scenes in a flawless manner on mobile browsers. CEBOW, a Cloud-Edge-Browser Online architecture for visualizing BIM components with online solutions, is proposed in this article. The method combines transmission scheduling, cache management, and optimal initial loading into a single system architecture. For network transmission testing, BIM scenes are used, and the results show that our method effectively reduces scene loading time and networking delay while improving the visualization effect of large-scale scenes.
C1 [Li, Ke; Zhang, Qian; Jia, Jinyuan] Tongji Univ, Sch Software Engn, Jishi Bldg 4800 Caoan Rd, Shanghai, Peoples R China.
   [Zhao, Hantao] Southeast Univ, Sch Cyber Sci & Engn, Nanjing, Peoples R China.
   [Zhao, Hantao] Purple Mt Labs, Nanjing, Peoples R China.
C3 Tongji University; Southeast University - China
RP Jia, JY (corresponding author), Tongji Univ, Sch Software Engn, Jishi Bldg 4800 Caoan Rd, Shanghai, Peoples R China.
EM jyjia@tongji.edu.cn
RI zhao, hantao/GXN-1105-2022
OI Li, Ke/0000-0003-2497-8807
FU General Project of National Natural Science Foundation of China
   [6207071897]; Key Project of the National Natural Science Regional Joint
   Fund [U19A2063]; Fundamental Research Funds for the Central Universities
   of China [2242021R10093]; Shuangchuang Program of Jiangsu Province
   [JSSCBS20210148]
FX General Project of National Natural Science Foundation of China,
   Grant/Award Number: 6207071897; Key Project of the National Natural
   Science Regional Joint Fund, Grant/Award Number: U19A2063; Fundamental
   Research Funds for the Central Universities of China, Grant/Award
   Number: 2242021R10093; Shuangchuang Program of Jiangsu Province,
   Grant/Award Number: JSSCBS20210148
CR Auer M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7070279
   Brutzman D., 2020, PROC 25 INT C 3D WEB, P1
   Chakareski J, 2017, VR/AR NETWORK '17: PROCEEDINGS OF THE 2017 WORKSHOP ON VIRTUAL REALITY AND AUGMENTED REALITY NETWORK, P36, DOI 10.1145/3097895.3097902
   Chen HM, 2016, AUTOMAT CONSTR, V71, P34, DOI 10.1016/j.autcon.2016.03.002
   Chen K.-T., 2011, P 19 ACM INT C MULT, P1269
   Chittaro L, 2007, COMPUT EDUC, V49, P3, DOI 10.1016/j.compedu.2005.06.002
   Choy S, 2012, ANN WORK NETW
   Chuang T.-H., 2011, ISARC P, V201, p144?149, DOI 10.22260/ISARC2011/0023
   Crassin Cyril, 2013, Talks Proceedings, V21, P1, DOI [10.1145/2504459.2504485, DOI 10.1145/2504459.2504485]
   Crassin Cyril, 2013, Ppsloan Org
   Das M., 2015, Visualization in Engineering, V3, DOI DOI 10.1186/S40327-015-0022-6
   Ding LY, 2016, SAFETY SCI, V87, P202, DOI 10.1016/j.ssci.2016.04.008
   Engel K, 2000, IEEE VISUAL, P449, DOI 10.1109/VISUAL.2000.885729
   Erol-Kantarci M, 2018, L N INST COMP SCI SO, V223, P169, DOI 10.1007/978-3-319-74439-1_15
   ETSI, 2014, MOBILE EDGE COMPUTIN
   ETSI, 2018, MULT EDG COMP MEC
   Guo X., 2015, P 2015 IEEE GLOB WOR, P1
   Gupta S, 2019, IEEE INT WORKSH MULT
   Hamza-Lup FG., 2019, P 2019 INT C 3D IMM, P1
   Hou G., 2021, ARAB J SCI ENG, P1
   Hou X., 2017, Computer Communication and Networks (ICCCN), 2017 26th International Conference on, P1
   Hu Yonghao, 2017, P 22 INT C 3D WEB TE, P1
   Jia JY, 2014, J NETW COMPUT APPL, V42, P1, DOI 10.1016/j.jnca.2014.03.005
   Jiao Y, 2013, ADV ENG INFORM, V27, P173, DOI 10.1016/j.aei.2012.11.006
   Li X., 2012, INT J 3 D INF MODEL, V1, P37
   Liu C, 2017, SIGSIM-PADS'17: PROCEEDINGS OF THE 2017 ACM SIGSIM CONFERENCE ON PRINCIPLES OF ADVANCED DISCRETE SIMULATION, P221, DOI 10.1145/3064911.3064933
   Liu C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3206431
   Liu XJ, 2021, IEEE COMPUT GRAPH, V41, P48, DOI 10.1109/MCG.2021.3069856
   Liu XJ, 2016, GRAPH MODELS, V88, P40, DOI 10.1016/j.gmod.2016.06.001
   Lv ZH, 2020, IEEE T IND INFORM, V16, P2566, DOI 10.1109/TII.2019.2916689
   Satyanarayanan M, 2017, COMPUTER, V50, P30, DOI 10.1109/MC.2017.9
   Shea R, 2013, IEEE NETWORK, V27, P16, DOI 10.1109/MNET.2013.6574660
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Shikhare D., 2001, SIGNAL PROCESS, V19, P15
   Shkundalov D, 2020, ENVIRON ENG-VILNIUS, DOI 10.3846/enviro.2020.725
   Sikos LF., 2017, P 22 INT C 3D WEB TE, P1
   Sobhkhiz S, 2021, AUTOMAT CONSTR, V130, DOI 10.1016/j.autcon.2021.103842
   Taleb T, 2017, IEEE COMMUN SURV TUT, V19, P1657, DOI 10.1109/COMST.2017.2705720
   Tanyue Xu, 2019, 2019 IEEE/CIC International Conference on Communications in China (ICCC), P903, DOI 10.1109/ICCChina.2019.8855846
   Wang MF, 2016, COMPUT ANIMAT VIRT W, V27, P519, DOI 10.1002/cav.1670
   Wei H, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1388
   Wen L., 2014, P 13 ACM SIGGRAPH IN, P95
   Wen Laixiang, 2016, LNCS, V9517, P93, DOI [10.1007/978-3-319-27674-89, DOI 10.1007/978-3-319-27674-89]
   Won J, 2020, AUTOMAT CONSTR, V113, DOI 10.1016/j.autcon.2020.103144
   Zhou XP, 2019, MULTIMED TOOLS APPL, V78, P28575, DOI 10.1007/s11042-018-5820-0
NR 45
TC 4
Z9 4
U1 12
U2 27
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2022
VL 33
IS 2
AR e2039
DI 10.1002/cav.2039
EA JAN 2022
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0T8YJ
UT WOS:000747613000001
DA 2024-07-18
ER

PT J
AU Cui, DX
   Whittinghill, D
   Fukada, A
   Mousas, C
   Adamo, N
AF Cui, Dixuan
   Whittinghill, David
   Fukada, Atsushi
   Mousas, Christos
   Adamo, Nicoletta
TI Interacting with virtual instructors: The effect of gender and years of
   study on the perception of in-game instructors
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE game immersion; gender differences; language learning; serious games;
   virtual character interaction; virtual instructors
ID SOCIAL-INTERACTION; LANGUAGE; IMMERSION
AB Previous research has shown that student-instructor interaction is vital to motivating students to learn a second language. However, it is unclear whether learners' demographics affect in-game immersion and interactions with virtual instructors. This study's purpose is to investigate whether the number of years learning Japanese (foreign language familiarity) influences students' immersion levels in serious games and their interactions with virtual instructors. We developed a 3D animated Japanese roleplaying game with a virtual in-game instructor. Eighty-four college students enrolled in 200- and 300-level Japanese language courses voluntarily participated in the study. Participants played the game and then answered a questionnaire concerning virtual character appearance, attentiveness to the instructor, and immersion in the game. The findings indicated that gender and the number of years studying Japanese significantly impact multiple measurements.
C1 [Cui, Dixuan; Whittinghill, David; Mousas, Christos; Adamo, Nicoletta] Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
   [Fukada, Atsushi] Purdue Univ, Dept East Asian Languages, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University; Purdue University System;
   Purdue University
RP Mousas, C (corresponding author), Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
EM cmousas@purdue.edu
RI Mousas, Christos/AGV-3533-2022; Whittinghill, David/J-6434-2012
OI Mousas, Christos/0000-0003-0955-7959; Whittinghill,
   David/0000-0002-2011-7893; Adamo, Nicoletta/0000-0001-8311-5302; Cui,
   Dixuan/0000-0003-0114-042X
CR [Anonymous], 2006, 2006 6 INT C ADV LEA
   Baylor AL, 2004, LECT NOTES COMPUT SC, V3220, P592
   Berns A, 2013, COMPUT EDUC, V60, P210, DOI 10.1016/j.compedu.2012.07.001
   Cheng K.Cairns., 2005, ACM C HUMAN FACTORS, P1272, DOI [DOI 10.1145/1056808.1056894, 10.1145/1056808.1056894]
   Cui DX, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P401, DOI 10.1109/VRW52623.2021.00087
   Davis J.W., 1998, PROC WORKSHOP PERCEP, P13
   Desai N, 2017, IEEE T COMP INTEL AI, V9, P333, DOI 10.1109/TCIAIG.2016.2570006
   Froschauer J., 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P253, DOI 10.1109/VSMM.2010.5665978
   Groff JS, 2018, EUR J EDUC, V53, P188, DOI 10.1111/ejed.12270
   Hamari J, 2016, COMPUT HUM BEHAV, V54, P170, DOI 10.1016/j.chb.2015.07.045
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jiman J, 2004, ED-MEDIA 2004: World Conference on Educational Multimedia, Hypermedia & Telecommunications, Vols. 1-7, P753
   JOHNSON DM, 1983, TESOL QUART, V17, P55, DOI 10.2307/3586424
   Karaoglu S., 2008, COMPLEAT LINKS, V5, P134
   Kokkinara E., 2015, Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG'15, P221, DOI DOI 10.1145/2822013.2822035
   LaFortune J, 2018, J EXP PSYCHOL-APPL, V24, P521, DOI 10.1037/xap0000189
   Lassitter S.A., 2009, Distance Learning, V6, P53
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P625, DOI 10.1109/VR.2018.8446312
   Meng Chien Yang, 2019, 2019 8th International Congress on Advanced Applied Informatics (IIAI-AAI), P296, DOI 10.1109/IIAI-AAI.2019.00066
   Nicovich SG, 2005, J COMPUT-MEDIAT COMM, V10
   Podmore R., 2008, POW EN SOC GEN M CON, P1
   Rizvic Selma, 2015, P IEEE 7 INT C GAM V, P1, DOI [10.1109/VS- GAMES.2015.7295786, DOI 10.1109/VS-GAMES.2015.7295786]
   Shih YC, 2008, EDUC TECHNOL SOC, V11, P56
   Shin J. K., 2000, NAT GEOGRAPH LEARN, P1
   Tomlinson B, 2012, LANG TEACHING, V45, P143, DOI 10.1017/S0261444811000528
   van Lier L., 1998, LANG AWARE, V7, P128, DOI [10.1080/09658419808667105, DOI 10.1080/09658419808667105]
   Verga L, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00550
   Viant W, 2016, COMPUT SCI ELECTR, P136, DOI 10.1109/CEEC.2016.7835902
   Watanabe Y, 2007, LANG TEACH RES, V11, P121, DOI 10.1177/136216880607074599
   Wilson Erin, 2018, Adv Simul (Lond), V3, P21, DOI 10.1186/s41077-018-0080-7
   Woo JC, 2014, EDUC TECHNOL SOC, V17, P291
   Zheng DP, 2009, MOD LANG J, V93, P489, DOI 10.1111/j.1540-4781.2009.00927.x
NR 32
TC 1
Z9 1
U1 1
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2026
DI 10.1002/cav.2026
EA JUN 2021
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000657131100001
DA 2024-07-18
ER

PT J
AU Kim, J
   Seol, Y
   Kwon, T
AF Kim, Jongmin
   Seol, Yeongho
   Kwon, Taesoo
TI Interactive multicharacter motion retargeting
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human motion; mesh deformation; motion retargeting
AB A motion retargeting process is necessary as the body size and proportion of the actors are generally different from those of the target characters. However, the original spatial relationship between the multiple characters and the environment is easily broken when using previous motion retargeting methods, which are generally performed for each character independently. Therefore, time-consuming manual adjustments by animators are usually required to obtain satisfactory results. To address these issues, we present a novel multicharacter motion retargeting method that preserves various types of spatial relationships between characters and environments. We establish a unified deformation-based framework for the motion retargeting of multiple characters (more than two) or nonhuman characters with complex interactions. Also, an interactive motion editing interface with immediate feedback to the user is provided. We experimentally show that our method achieves a speedup when compared with previous motion retargeting methods.
C1 [Kim, Jongmin] Kangwon Natl Univ, Comp Sci & Engn, Chunchon, South Korea.
   [Seol, Yeongho] NVIDIA, Seoul, South Korea.
   [Kwon, Taesoo] Hanyang Univ, Dept Comp & Software, Seoul, South Korea.
C3 Kangwon National University; Hanyang University
RP Kwon, T (corresponding author), Hanyang Univ, Dept Comp & Software, Seoul, South Korea.
EM taesoobear@gmail.com
RI Seol, Yeongho/KIE-6801-2024
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2019R1F1A1063467, NRF-2020R1A2C1012847]
FX We thank the anonymous reviewers for their constructive comments. This
   work was supported by the National Research Foundation of Korea (NRF)
   grant funded by the Korea government (MSIT) (NRF-2019R1F1A1063467,
   NRF-2020R1A2C1012847). We thank Dexter Studio for modeling the character
   and rendering the scenes.
CR Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392462
   Al-Asqhar Rami Ali, 2013, P 12 ACM SIGGRAPHEUR, P45
   Botsch M., 2006, VISION MODELING VISU
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Buss S. R., 2005, Journal of Graphics Tools, V10, P37
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Ho ESL, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487274
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Kajita S, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P239, DOI 10.1109/IROS.2001.973365
   Kim J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601170
   Kim M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531385
   Kulpa R, 2005, IEEE-RAS INT C HUMAN, P38
   Kwon T, 2008, IEEE T VIS COMPUT GR, V14, P707, DOI 10.1109/TVCG.2008.22
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   Lee J, 2006, GRAPH MODELS, V68, P158, DOI 10.1016/j.gmod.2005.03.004
   Lee J, 1999, COMP GRAPH, P39
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Liu Karen, 2006, P 2006 ACM SIGGRAPHE, P215
   Shum HPH, 2012, IEEE T VIS COMPUT GR, V18, P741, DOI 10.1109/TVCG.2010.257
   Shum HPH, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409067
   Sorkine O, 2007, S GEOM PROC, V4, P109, DOI [10.1145/1073204.1073323, DOI 10.1145/1073204.1073323]
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Kim SU, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1947
   Villegas R, 2018, PROC CVPR IEEE, P8639, DOI 10.1109/CVPR.2018.00901
   Wampler K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805970
   Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507
   ZHAO JM, 1994, ACM T GRAPHIC, V13, P313, DOI 10.1145/195826.195827
NR 30
TC 5
Z9 5
U1 2
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2015
DI 10.1002/cav.2015
EA MAY 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000653837200001
DA 2024-07-18
ER

PT J
AU Zhu, J
   Li, SL
   Cai, RC
   Hao, ZF
   Huang, GH
   Sheng, B
   Wu, EH
AF Zhu, Jian
   Li, Silong
   Cai, Ruichu
   Hao, Zhifeng
   Huang, Guoheng
   Sheng, Bin
   Wu, Enhua
TI Compensating the vorticity loss during advection with an adaptive
   vorticity confinement force
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE adaptive; advection; detail enhancement; vorticity confinement;
   vorticity loss
ID FLUID; SIMULATION; TURBULENCE; SMOKE; FLIP
AB The advection step in grid-based fluid simulation is prone to numerical dissipation, which results in loss of detail. How to improve the advection accuracy to preserve more fluid details is still challenging. On the other hand, a common way to enhance smoke details is to use vorticity confinement. However, most of the previous methods simply used a fine-tuned scale factor epsilon to adjust the strength of the confinement force, which can only amplify existing vortex details and is easy to cause instability when epsilon is large. In this article, we proposed an adaptive vorticity confinement method, which does not suffer from the above problems, to compensate the vorticity loss during advection with little extra cost. The main idea is to first calculate a scale factor whose value depends on the vorticity loss during advection, and then use it to adaptively control the vorticity confinement force for vorticity compensation with high stability. The experiment results show the effectiveness and efficiency of our method.
C1 [Zhu, Jian; Li, Silong; Cai, Ruichu; Hao, Zhifeng; Huang, Guoheng] Guangdong Univ Technol, Sch Comp, Guangzhou, Peoples R China.
   [Hao, Zhifeng] Foshan Univ, Sch Math & Big Data, Foshan, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
C3 Guangdong University of Technology; Foshan University; Shanghai Jiao
   Tong University; Chinese Academy of Sciences; Institute of Software, CAS
RP Huang, GH (corresponding author), Guangdong Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Comp, Guangzhou, Peoples R China.
EM kevinwong@gdut.edu.cn
RI cai, ruichu/AAX-7200-2021
OI Zhu, Jian/0000-0002-2551-2024; Sheng, Bin/0000-0001-8678-2784; Sheng,
   Bin/0000-0001-8510-2556
FU National Key R&D Program of China [2017YFB1002701, 2017YFB1201203];
   National Natural Science Foundation of China [61702111, 61876043,
   61976052]; Natural Science Foundation of Guangdong Province
   [2016A030310342]; Science and Technology Planning Project of Guangdong
   Province [2017B010110007, 2017B010110015]
FX National Key R&D Program of China, Grant/Award Numbers: 2017YFB1002701,
   2017YFB1201203; National Natural Science Foundation of China,
   Grant/Award Numbers: 61702111, 61876043, 61976052; Natural Science
   Foundation of Guangdong Province, Grant/Award Number: 2016A030310342;
   Science and Technology Planning Project of Guangdong Province,
   Grant/Award Numbers: 2017B010110007, 2017B010110015
CR [Anonymous], 2008, P 2008 ACM SIGGRAPHE
   [Anonymous], 2012, Computer Animation 2012-ACM SIGGRAPH / Eurographics Symposium Proceedings, SCA
   Bender J, 2019, IEEE T VIS COMPUT GR, V25, P2284, DOI 10.1109/TVCG.2018.2832080
   BRACKBILL JU, 1986, J COMPUT PHYS, V65, P314, DOI 10.1016/0021-9991(86)90211-1
   Cornelis J, 2014, COMPUT GRAPH FORUM, V33, P255, DOI 10.1111/cgf.12324
   Costes M, 2016, COMPUT FLUIDS, V136, P132, DOI 10.1016/j.compfluid.2016.05.025
   Eberhardt S, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099569
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Fu CY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130878
   Golas A., 2012, ACM T GRAPHIC, V31, p148:1, DOI DOI 10.1145/2366145.2366167
   Harlow F.H., 1962, The Particle-In-Cell Method for Numerical Solution of Problems in Fluid Dynamics, DOI [DOI 10.2172/4769185, 10. 2172/4769185]
   He S, 2013, COMPUT GRAPH FORUM, V32, P27, DOI 10.1111/j.1467-8659.2012.03228.x
   He SF, 2011, COMPUT ANIMAT VIRT W, V22, P107, DOI 10.1002/cav.408
   Huang ZP, 2015, COMPUT ANIMAT VIRT W, V26, P141, DOI 10.1002/cav.1559
   Jang T, 2010, VISUAL COMPUT, V26, P873, DOI 10.1007/s00371-010-0487-1
   Jiang CG, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818077
   Kim A, 2005, ESSENT OPHTHALMOL, P51
   Kim B, 2007, IEEE T VIS COMPUT GR, V13, P135, DOI 10.1109/TVCG.2007.3
   Kim D, 2008, COMPUT GRAPH FORUM, V27, P467, DOI 10.1111/j.1467-8659.2008.01144.x
   Peer A, 2017, IEEE T VIS COMPUT GR, V23, P2656, DOI 10.1109/TVCG.2016.2636144
   Pfaff T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185608
   Qu ZY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322945
   Sato Takahiro, 2018, Computational Visual Media, V4, P223, DOI 10.1007/s41095-018-0117-9
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Stam J., 1999, P 26 ANN C COMP GRAP, P121
   Taekwon Jang, 2011, International Journal of Virtual Reality, V10, P21
   Takahashi T, 2003, COMPUT GRAPH FORUM, V22, P391, DOI 10.1111/1467-8659.00686
   Weissmann S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778852
   Xu YX, 2012, COMM COM INF SC, V346, P467
   Zehnder J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201324
   Zhang XX, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766982
   Zhu J, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1834
NR 33
TC 2
Z9 2
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2021
VL 32
IS 1
AR e1973
DI 10.1002/cav.1973
EA SEP 2020
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QP5QT
UT WOS:000573847700001
DA 2024-07-18
ER

PT J
AU Huang, YH
   Yu, YH
   Kanai, T
AF Huang, Yuhang
   Yu, Yonghang
   Kanai, Takashi
TI Predicting brittle fracture surface shape from a versatile database
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE boundary element method; brittle fracture; data-driven; regression
   forest
ID REAL-TIME SIMULATION; ANIMATION
AB In this paper, we propose a novel data-driven method that uses a machine learning scheme for formulating fracture simulation with the boundary element method (BEM) as a regression problem. With this method, the crack opening displacement (COD) of every correlation node is predicted at the next frame. In our naive prediction, we design a feature vector directly exploiting stress intensities and toughness at the current frame so that our method predicts the COD at the next frame more reliably. Thus, there is no need to solve the original linear BEM system to calculate displacements. This enables us to propagate crack fronts using the estimated stress intensities. There are existing works that use the machine learning approach to accelerate the speed of traditional physics-based simulations like smoke and fluid, but our work is the first to incorporate the machine learning scheme into BEM-based fracture simulations. Our implementation accelerates the acquisition of displacements in linear time over the number of crack fronts at each time step compared with the conventional solution whose time complexity grows exponentially based on the BEM linear system. The databases generated by our method are versatile and can be applied to general situations and different models.
C1 [Huang, Yuhang; Yu, Yonghang; Kanai, Takashi] Univ Tokyo, Grad Sch Arts & Sci, Tokyo 1538902, Japan.
C3 University of Tokyo
RP Kanai, T (corresponding author), Univ Tokyo, Grad Sch Arts & Sci, Tokyo 1538902, Japan.
EM kanai@graco.c.u-tokyo.ac.jp
OI Huang, Yuhang/0000-0002-3471-0794; Kanai, Takashi/0000-0002-1635-3818
CR [Anonymous], 2015, ACM T GRAPHIC
   [Anonymous], P GRAPH INT 2005 GI
   [Anonymous], RAND FOR REGR FOR
   [Anonymous], ACM SIGGRAPH ASIA 20
   [Anonymous], HYENA HYP ELL NUM AN
   [Anonymous], 2009, TIME DOMAIN SYMMETRI
   [Anonymous], 2016, ACM T GRAPHIC
   [Anonymous], P 1999 C GRAPH INT 9
   [Anonymous], FRACTUREBEM
   [Anonymous], P ACM SIGGRAPH 2002
   Bao ZS, 2007, IEEE T VIS COMPUT GR, V13, P370, DOI 10.1109/TVCG.2007.39
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Frangi A, 2002, COMPUT MECH, V28, P220, DOI 10.1007/S00466-001-0283-X
   Freund L.B., 1998, Dynamic Fracture Mechanics
   Glondu L, 2013, IEEE T VIS COMPUT GR, V19, P201, DOI 10.1109/TVCG.2012.121
   Hahn D, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766896
   Hirota K, 1998, VISUAL COMPUT, V14, P126, DOI 10.1007/s003710050128
   Ingraffea A.R., 2003, COMPREHENSIVE STRUCT, V3, P1
   Ladicky L, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818129
   Müller M, 2001, SPRING EUROGRAP, P113
   Müller M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461934
   Neff M, 1999, PROC GRAPH INTERF, P193
   Norton A., 1991, Visual Computer, V7, P210, DOI 10.1007/BF01900837
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   Terzopoulos D., 1988, Computer Graphics, V22, P269, DOI 10.1145/378456.378522
   Tompson J, 2017, P 34 INT C MACHINE L
   Yang C, 2016, COMPUT ANIMAT VIRT W, V27, P415, DOI 10.1002/cav.1695
NR 28
TC 0
Z9 0
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2019
VL 30
IS 6
AR e1865
DI 10.1002/cav.1865
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KD5NX
UT WOS:000507913800007
DA 2024-07-18
ER

PT J
AU Xie, XG
   Zhai, X
   Hou, F
   Hao, AM
   Qin, H
AF Xie, Xueguang
   Zhai, Xiao
   Hou, Fei
   Hao, Aimin
   Qin, Hong
TI Multitask learning on monocular water images: Surface reconstruction and
   image synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE image synthesis; multitask learning; water surface reconstruction
AB In this paper, we present a new strategy, a joint deep learning architecture, for two classic tasks in computer graphics: water surface reconstruction and water image synthesis. Modeling water surfaces from single images can be regarded as the inverse of image rendering, which converts surface geometries into photorealistic images. On the basis of this fact, we therefore consider these two problems as a cycle image-to-image translation and propose to tackle them together using a pair of neural networks, with the three-dimensional surface geometries being represented as two-dimensional surface normal maps. Furthermore, we also estimate the imaging parameters from the existing water images with a subnetwork to reuse the lighting conditions when synthesizing new images. Experiments demonstrate that our method achieves an accurate reconstruction of surfaces from monocular images efficiently and produces visually plausible new images under variable lighting conditions.
C1 [Xie, Xueguang] Beihang Univ, Qingdao Res Inst, Qingdao, Shandong, Peoples R China.
   [Xie, Xueguang; Zhai, Xiao; Hao, Aimin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Hou, Fei] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, 4 Southern Fourth St, Beijing 100190, Peoples R China.
   [Hou, Fei] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 Beihang University; Beihang University; Chinese Academy of Sciences;
   Institute of Software, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS; State University of New York (SUNY)
   System; State University of New York (SUNY) Stony Brook
RP Hou, F (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, 4 Southern Fourth St, Beijing 100190, Peoples R China.; Qin, H (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM houfei@ios.ac.cn; qin@cs.stonybrook.edu
OI Hou, Fei/0000-0001-8226-6635; Zhai, Xiao/0000-0001-8964-3704
FU National Natural Science Foundation of China [61872347, 61532002,
   61672149, 61672077, 61872020]; National Science Foundation [IIS-1715985,
   IIS-1812606]; Special Plan for the Development of Distinguished Young
   Scientists of the Institute of Software, Chinese Academy of Sciences
   [Y8RC535018]; Chinese Academy of Sciences Key Research Program of
   Frontier Sciences [QYZDY-SSW-JSC041]
FX National Natural Science Foundation of China, Grant/Award Number:
   61872347, 61532002, 61672149, 61672077, and 61872020; National Science
   Foundation, Grant/Award Number: IIS-1715985 and IIS-1812606; Special
   Plan for the Development of Distinguished Young Scientists of the
   Institute of Software, Chinese Academy of Sciences, Grant/Award Number:
   Y8RC535018; Chinese Academy of Sciences Key Research Program of Frontier
   Sciences, Grant/Award Number: QYZDY-SSW-JSC041
CR Agrawal A, 2006, LECT NOTES COMPUT SC, V3951, P578
   [Anonymous], J VISUALIZATION COMP
   [Anonymous], 2017, P 2017 IEEE C COMP V
   [Anonymous], ACM T GRAPHIC
   [Anonymous], COMPUTER GRAPHICS FO
   [Anonymous], 2001, SIGGRAPH 99 COURSE N
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Ashikhmin M, 2001, COMPUT GRAPH-UK, V25, P287, DOI 10.1016/S0097-8493(00)00131-X
   Bane C, 2017, INT CONF 3D VISION, P412, DOI 10.1109/3DV.2017.00054
   Ding YY, 2011, IEEE I CONF COMP VIS, P2478, DOI 10.1109/ICCV.2011.6126533
   Eckert ML, 2018, COMPUT GRAPH FORUM, V37, P47, DOI 10.1111/cgf.13511
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Fournier A., 1986, Computer Graphics, V20, P75, DOI 10.1145/15886.15894
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hu YH, 2006, COMPUT ANIMAT VIRT W, V17, P59, DOI 10.1002/cav.74
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kim T, 2017, PR MACH LEARN RES, V70
   Li C, 2013, IEEE T VIS COMPUT GR, V19, P1242, DOI 10.1109/TVCG.2012.302
   Nalbach O, 2017, COMPUT GRAPH FORUM, V36, P65, DOI 10.1111/cgf.13225
   Premoze S, 2001, COMPUT GRAPH FORUM, V20, P189, DOI 10.1111/1467-8659.00548
   Qian YM, 2017, PROC CVPR IEEE, P6650, DOI 10.1109/CVPR.2017.704
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Sato S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201398
   Schneider J., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P211
   Wang HM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531396
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Ye JW, 2012, PROC CVPR IEEE, P310, DOI 10.1109/CVPR.2012.6247690
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhu J.-Y., 2017, IEEE I CONF COMP VIS, P2223, DOI DOI 10.1109/ICCV.2017.244
NR 33
TC 4
Z9 4
U1 1
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1896
DI 10.1002/cav.1896
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400017
DA 2024-07-18
ER

PT J
AU Agil, U
   Güdükbay, U
AF Agil, Umut
   Gudukbay, Ugur
TI A group-based approach for gaze behavior of virtual crowds incorporating
   personalities
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; gaze behavior; gaze copy; interest point detection;
   perception; saliency
ID VISUAL-ATTENTION; INATTENTIONAL BLINDNESS; BOTTOM-UP; MODEL;
   REPRESENTATION; INTROVERSION; PERCEPTION; MOVEMENT; DYNAMICS; SALIENCY
AB Predicting interest points of virtual characters and accurately simulating their gaze behavior play a significant role for realistic crowd simulations. We propose a saliency model that enables virtual agents to produce plausible gaze behavior. The model measures the effects of distinct saliency features implemented by examining the state-of-the-art perception studies. When predicting an agent's interest point, we compute the saliency scores by using a weighted sum function for other agents and environment objects in the field of view of the agent for each frame. Then, we determine the most salient entity for each agent in the scene; thus, agents gain a visual understanding of their environment. Besides, our model introduces new aspects to crowd perception, such as perceiving characters as groups of people and applying social norms on crowd gaze behavior, effects of agent personality on gaze, gaze copy phenomena, and effects of agent velocity on attention. For evaluation, we compare the resulting saliency gaze model with real-world crowd behavior in captured videos. In the experiments, we simulate the gaze behavior in real crowds. The results show that the proposed approach generates plausible gaze behaviors and is easily adaptable to varying scenarios for virtual crowds.
C1 [Agil, Umut; Gudukbay, Ugur] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Güdükbay, U (corresponding author), Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM gudukbay@cs.bilkent.edu.tr
RI Gudukbay, Ugur/F-1012-2011
OI Gudukbay, Ugur/0000-0003-2462-6959
CR Alvarez GA, 2008, PSYCHOL SCI, V19, P392, DOI 10.1111/j.1467-9280.2008.02098.x
   Alvarez GA, 2011, TRENDS COGN SCI, V15, P122, DOI 10.1016/j.tics.2011.01.003
   Alvarez GA, 2009, P NATL ACAD SCI USA, V106, P7345, DOI 10.1073/pnas.0808981106
   [Anonymous], 2012, From Perception to Consciousness: Searching with Anne Treisman, DOI [10.1093/acprof:osobl/9780199734337.003.0030, DOI 10.1093/ACPROF:OSOBL/9780199734337.003.0030]
   [Anonymous], 1997, COMPUTER ANIMATION S, DOI DOI 10.1007/978-3-7091-6874-5_3
   [Anonymous], 1996, 5 FACTOR MODEL PERSO
   [Anonymous], 2016, UN GAM ENG
   [Anonymous], COMPUT ENTERTAIN
   [Anonymous], 2004, OPT SCI TECHNOL
   [Anonymous], 2008, COMPUTER GRAPHICS IN
   Ariely D, 2008, PERCEPT PSYCHOPHYS, V70, P1325, DOI 10.3758/PP.70.7.1325
   AVENI AF, 1977, SOCIOMETRY, V40, P96, DOI 10.2307/3033551
   Bailly G, 2010, SPEECH COMMUN, V52, P598, DOI 10.1016/j.specom.2010.02.015
   Cater K, 2003, P 14 EUR WORKSH REND
   Chabris CF, 2011, I-PERCEPTION, V2, P150, DOI 10.1068/i0436
   Chong SC, 2003, VISION RES, V43, P393, DOI 10.1016/S0042-6989(02)00596-5
   Chong SC, 2005, VISION RES, V45, P891, DOI 10.1016/j.visres.2004.10.004
   COLEMAN JS, 1961, SOCIOMETRY, V24, P36, DOI 10.2307/2785927
   Connor CE, 2004, CURR BIOL, V14, pR850, DOI 10.1016/j.cub.2004.09.041
   Dogbe C, 2012, J MATH ANAL APPL, V387, P512, DOI 10.1016/j.jmaa.2011.09.007
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Dutra TB, 2017, COMPUT GRAPH FORUM, V36, P337, DOI 10.1111/cgf.13130
   Fang Z, 2003, FIRE SAFETY J, V38, P271, DOI 10.1016/S0379-7112(02)00058-9
   Favaretto RM, 2016, P IEEE INT C IM PROC
   Ferwerda J. A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P249, DOI 10.1145/237170.237262
   Fontana FE, 2014, BRAZ J MOT BEHAV, V8
   Fridman N, 2012, P 11 INT C AUT AG MU, V3, P1343
   Furley P, 2010, ATTEN PERCEPT PSYCHO, V72, P1327, DOI 10.3758/APP.72.5.1327
   Gallup AC, 2012, P NATL ACAD SCI USA, V109, P7245, DOI 10.1073/pnas.1116141109
   Grillon H, 2009, COMPUT ANIMAT VIRT W, V20, P111, DOI 10.1002/cav.293
   Guy S., 2009, EUR ACM SIGGRAPH S C, P177
   Guy SJ, 2011, P ACM SIGGRAPH EUR S
   Hamilton J.R., 1937, Safe Driving: Human Limitations in Automobile Driving
   Hoyet L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925931
   Hüttermann S, 2012, PERCEPTION, V41, P963, DOI 10.1068/p7294
   IIZUKA Y, 1994, PERCEPT MOTOR SKILL, V78, P1259, DOI 10.2466/pms.1994.78.3c.1259
   IIZUKA Y, 1992, PERCEPT MOTOR SKILL, V74, P43, DOI 10.2466/PMS.74.1.43-50
   Itti L, 2005, VIS COGN, V12, P1093, DOI 10.1080/13506280444000661
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   James J, 1953, AM SOCIOL REV, V18, P569, DOI 10.2307/2087444
   John O. P., 1999, BIG 5 TRAIT TAXONOMY
   Judd T, 2009, INT C COMP VIS, P2016
   KENDON A, 1969, BRIT J PSYCHOL, V60, P481, DOI 10.1111/j.2044-8295.1969.tb01222.x
   Khullar SC, 2001, AUTON AGENT MULTI-AG, V4, P9, DOI 10.1023/A:1010010528443
   Kim Y., 2005, P C BEH REPR MOD SIM
   Kokkinara E, 2011, COMPUT ANIMAT VIRT W, V22, P361, DOI 10.1002/cav.425
   Kreyszig E., 1979, APPL MATH
   Lee S, 2009, IEEE T VIS COMPUT GR, V15, P6, DOI 10.1109/TVCG.2008.82
   Longhurst P, 2006, P 4 INT C COMP GRAPH
   McDonnell R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360625
   McNamara A, 2014, P ACM SIGGRAPH COURS
   MEYER GW, 1986, ACM T GRAPHIC, V5, P30, DOI 10.1145/7529.7920
   MOBBS NA, 1968, BRIT J SOC CLIN PSYC, V7, P305
   Moussaïd M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Narang S, 2016, P 22 ACM C VIRT REAL
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Oyekoya Oyewole., 2009, Proceedings of the 16th acm symposium on virtual reality software and technology, P199, DOI [10.1145/1643928.1643973, DOI 10.1145/1643928.1643973]
   Park SI, 2013, COMPUT ANIMAT VIRT W, V24, P155, DOI 10.1002/cav.1512
   Parkes L, 2001, NAT NEUROSCI, V4, P739, DOI 10.1038/89532
   Peters C, 2003, COMP ANIM CONF PROC, P111, DOI 10.1109/CASA.2003.1199311
   Qiu FS, 2010, SIMUL MODEL PRACT TH, V18, P190, DOI 10.1016/j.simpat.2009.10.005
   Queiroz R., 2008, P SBGAMES 08 COMP TR, P151
   Rancer A., 2006, ARGUMENTATIVE AGGRES
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rodrigues RA, 2010, APPL ARTIF INTELL, V24, P594, DOI 10.1080/08839514.2010.492167
   Ruhland K., 2014, EUROGRAPHICS STATE O, P69
   Sekuler R., 1984, ACM SIGGRAPH COMPUTE, V18, P24, DOI DOI 10.1145/988525.988533
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   Shi CL, 2012, SAFETY SCI, V50, P1319, DOI 10.1016/j.ssci.2010.07.017
   Strasburger H, 2011, J VISION, V11, DOI 10.1167/11.5.13
   Sundstedt V., 2008, P 5 S APPL PERC GRAP
   Sweeny TD, 2014, PSYCHOL SCI, V25, P1903, DOI 10.1177/0956797614544510
   Templeton A, 2015, REV GEN PSYCHOL, V19, P215, DOI 10.1037/gpr0000032
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Tunnard Christopher., 1963, Man-made America: Chaos or Control? An Inquiry into Selected Problems of Design in the Urbanized Landscape
   Wang YY, 2016, COMPUT ANIMAT VIRT W, V27, P369, DOI 10.1002/cav.1703
   WATAMANIUK SNJ, 1993, J OPT SOC AM A, V10, P16, DOI 10.1364/JOSAA.10.000016
   WATAMANIUK SNJ, 1992, VISION RES, V32, P931, DOI 10.1016/0042-6989(92)90036-I
   WIENS AN, 1980, J CLIN PSYCHOL, V36, P205, DOI 10.1002/1097-4679(198001)36:1<205::AID-JCLP2270360126>3.0.CO;2-A
NR 79
TC 7
Z9 8
U1 0
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2018
VL 29
IS 5
AR e1806
DI 10.1002/cav.1806
PG 26
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA GW0KS
UT WOS:000446555300002
DA 2024-07-18
ER

PT J
AU Zhu, Y
   Li, SY
   Luo, X
   Zhu, K
   Fu, Q
   Chen, XL
   Gong, HX
   Yu, JY
AF Zhu, Yu
   Li, Shiying
   Luo, Xi
   Zhu, Kang
   Fu, Qiang
   Chen, Xilin
   Gong, Huixing
   Yu, Jingyi
TI A shared augmented virtual environment for real-time mixed reality
   applications
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE calibration; Kinect; mixed reality; natural image matting; real time
ID IMAGE; CAMERA
AB Headsets for virtual reality such as head-mounted displays have become ubiquitous and bring immersive experiences to individual users. People who stand outside the virtual world may want to share the same scenes that are shown on the screen of the headset. It is therefore of great importance to merge real and virtual worlds into the same environment, where physical and virtual objects exist simultaneously and interact in real time. We propose shared augmented virtual environment (SAVE), a mixed reality (MR) system that overlays the virtual world with real objects captured by a Kinect depth camera. We refine the depth map and exploit a Graphics Processing Unit (GPU) based natural image matting method to obtain the real objects from cluttered scenes. In the synthetic MR world, we can render real and virtual objects in real time and handle the depth from both worlds properly. The advantage of our system is that we connect the virtual and real worlds with a bridge controller mounted on the Kinect and need to calibrate the whole system only once before use. Our results demonstrate that the proposed SAVE system is able to create high-quality 1080p live MR footage, enabling realistic virtual experiences to be shared among a number of people in potential applications such as education, design, and entertainment.
C1 [Zhu, Yu; Zhu, Kang] Chinese Acad Sci, Shanghai Inst Microsyst & Informat, Beijing, Peoples R China.
   [Zhu, Yu; Li, Shiying; Luo, Xi; Zhu, Kang; Fu, Qiang; Yu, Jingyi] ShanghaiTech Univ, Shanghai, Peoples R China.
   [Zhu, Yu] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Gong, Huixing] Chinese Acad Sci, Shanghai Inst Tech Phys, Beijing, Peoples R China.
C3 ShanghaiTech University; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute
   of Computing Technology, CAS; Chinese Academy of Sciences; Shanghai
   Institute of Technical Physics, CAS
RP Yu, JY (corresponding author), ShanghaiTech Univ, Ctr Virtual Intelligence, 393 Middle Huaxia Rd, Shanghai, Peoples R China.
EM yujingyi@shanghaitech.edu.cn
RI Fu, Qiang/AAN-3134-2020
OI Fu, Qiang/0000-0001-6395-8521; Luo, Xi/0000-0001-5329-0636
FU Science and Technology Commission of Shanghai Municipality [17XD1402900,
   17JC1403800]
FX Science and Technology Commission of Shanghai Municipality, Grant/Award
   Number: 17XD1402900, 17JC1403800
CR Altarteer S, 2016, P 21 INT C WEB3D TEC, P173, DOI [10.1145/2945292.2945317, DOI 10.1145/2945292.2945317]
   [Anonymous], 2012, AS C COMP VIS
   [Anonymous], 10 INT EUR PAR C AUG
   [Anonymous], 5 EUR C VIS MED PROD
   [Anonymous], 2008, PROC ACM SIGGRAPH PO
   [Anonymous], P INT C CONS EL
   Bai X, 2009, INT J COMPUT VISION, V82, P113, DOI 10.1007/s11263-008-0191-z
   Biocca Frank, 2013, COMMUNICATION AGE VI
   Cho D, 2016, LECT NOTES COMPUT SC, V9906, P626, DOI 10.1007/978-3-319-46475-6_39
   Comport AI, 2006, IEEE T VIS COMPUT GR, V12, P615, DOI 10.1109/TVCG.2006.78
   Gunther Tobias, 2015, 2015 IEEE Virtual Reality (VR), P327, DOI [10.1109/3DUI.2015.7131748, 10.1109/VR.2015.7223428]
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   He KM, 2010, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR.2010.5539896
   Kim YS, 2019, MULTIMED TOOLS APPL, V78, P28409, DOI 10.1007/s11042-017-5375-5
   Lensing P., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P261, DOI 10.1109/ISMAR.2011.6143892
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nguyen THD, 2005, IEEE T VIS COMPUT GR, V11, P706, DOI 10.1109/TVCG.2005.105
   Ohta Y., 2014, MIXED REALITY MERGIN
   Shahrian E, 2012, PROC CVPR IEEE, P718, DOI 10.1109/CVPR.2012.6247741
   Singaraju D, 2009, PROC CVPR IEEE, P659, DOI 10.1109/CVPRW.2009.5206491
   Suma E. A., 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P349, DOI 10.1109/ISVRI.2011.5759673
   Wang L, 2012, INT J COMPUT VISION, V97, P104, DOI 10.1007/s11263-011-0471-x
   Wexelblat A., 2014, VIRTUAL REALITY APPL
   Xu N., 2017, ARXIV170303872
   Zhang Shujun, 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P155, DOI 10.1109/ISVRI.2011.5759621
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao MY, 2015, IEEE J-STSP, V9, P449, DOI 10.1109/JSTSP.2014.2382476
   Zhu Y, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P13, DOI 10.1145/3013971.3013979
NR 29
TC 3
Z9 4
U1 2
U2 25
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2018
VL 29
IS 5
AR e1805
DI 10.1002/cav.1805
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GW0KS
UT WOS:000446555300001
DA 2024-07-18
ER

PT J
AU Chan, KH
   Ke, W
   Im, SK
AF Chan, Ka-Hou
   Ke, Wei
   Im, Sio-Kei
TI Particle-mesh coupling in the interaction of fluid and deformable bodies
   with screen space refraction rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE finite element method; particle-face interaction coupling; ray-traced
   collision detection; screen space refraction rendering; smoothed
   particle hydrodynamics
AB On the basis of the smoothed particle hydrodynamics and finite element method(FEM) model, we propose a method integrating several improvements for the real-time simulation of fluid interacting with deformable bodies. We improve the particle neighbor search in smoothed particle hydrodynamics, so that the predefined scene containers are no longer needed. This improvement can also be applied to the simulation of fluid interacting with other materials, such as rigid and soft bodies. We also propose a two-way coupling method for fluid and deformable bodies, where the particle-mesh interaction is obtained by the ray-traced collision detection method instead of the proxy/ghost particle generation. By using the forward ray-tracing method for both velocity and position, we are able to calculate the coupling forces based on the conservation of momentum and kinetic energy in the particle-mesh interaction. We use the screen space fluid rendering for fluid, and on the basis of that, we introduce a screen space refraction rendering method to improve the refraction effect. We implement our method in NVIDIA CUDA and OptiX to make use of the full computational power of a graphics processing unit. The simulation results are analyzed and discussed to show the efficiency of our method.
C1 [Chan, Ka-Hou; Im, Sio-Kei] Macau Polytech Inst, MPI QMUL Informat Syst Res Ctr, Macau, Peoples R China.
   [Ke, Wei] Macau Polytech Inst, Comp Program, Macau, Peoples R China.
C3 Macao Polytechnic University; Macao Polytechnic University
RP Chan, KH (corresponding author), Macau Polytech Inst, MPI QMUL Informat Syst Res Ctr, Macau, Peoples R China.
EM chankahou@ipm.edu.mo
RI Ke, Wei/JXM-8153-2024; Chan, Ka-Hou/JFS-2196-2023
OI Chan, Ka-Hou/0000-0002-0183-0685; Ke, Wei/0000-0003-0952-0961; IM, SIO
   KEI/0000-0002-5599-4300
FU Macao Science and Technology Development Fund [138/2016/A3]
FX Macao Science and Technology Development Fund, Grant/Award Number:
   138/2016/A3
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Akinci G, 2012, COMPUT GRAPH FORUM, V31, P1797, DOI 10.1111/j.1467-8659.2012.02096.x
   Akinci N, 2013, COMPUT ANIMAT VIRT W, V24, P195, DOI 10.1002/cav.1499
   Bavoil L., 2008, NVIDIA DEVELOPER INF
   Charypar D., 2003, P 2003 ACM SIGGRAPH
   Dalrymple RA, 2001, COASTAL DYNAMICS '01: PROCEEDINGS, P779
   Desbrun M., 1996, SMOOTHED PARTICLES N
   Dyken C, 2008, COMPUT GRAPH FORUM, V27, P2028, DOI 10.1111/j.1467-8659.2008.01182.x
   Goswami P, 2010, P 2010 ACM SIGGRAPH
   Green S., 2010, NVIDIA Whitepaper, V6, P121
   Harada T., 2007, P COMP GRAPH INT
   Hérault A, 2010, J HYDRAUL RES, V48, P74, DOI 10.1080/00221686.2010.9641247
   Ka-Hou Chan, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9219, P349, DOI 10.1007/978-3-319-21969-1_30
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Parker S. G., 2010, ACM T GRAPHIC, V29, P4
   Pfister H, 2000, COMP GRAPH, P335, DOI 10.1145/344779.344936
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Sio-Kei Im, 2016, International Journal of Modeling and Optimization, V6, P71, DOI 10.7763/IJMO.2016.V6.506
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   SOUSA T, 2005, GPU GEMS, V2, P295
   SWEGLE JW, 1995, J COMPUT PHYS, V116, P123, DOI 10.1006/jcph.1995.1010
   Tarini M, 2006, IEEE T VIS COMPUT GR, V12, P1237, DOI 10.1109/TVCG.2006.115
   van dersLaan WJ, 2009, P 2009 S INT 3D GRAP
   Wloka M, 2002, FRESNEL REFLECTION T
   Yang LP, 2012, COMPUT GRAPH FORUM, V31, P2037, DOI 10.1111/j.1467-8659.2012.03196.x
   Zemcik PT., 2003, SCCG '03: Proceedings of the 19th spring conference on Computer graphics, P165
   Zhang Yanci., 2008, Proceedings of the Fifth Euro- graphics / IEEE VGTC Conference on Point-Based Graphics, SPBG'08, P137
NR 30
TC 1
Z9 2
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2018
VL 29
IS 1
AR e1787
DI 10.1002/cav.1787
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FV0GZ
UT WOS:000424235300004
DA 2024-07-18
ER

PT J
AU Stüvel, SA
   van der Stappen, AF
   Egges, A
AF Stuvel, Sybren A.
   van der Stappen, A. Frank
   Egges, Arjan
TI Perception of collisions between virtual characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE perception; collision detection; virtual humans; believability;
   performance
AB With the growth in available computing power, we see increasingly crowded virtual environments. In densely crowded situations, collisions are likely to occur, and the choice in collision detection technique can impact the perceived realism of a real-time crowd. This paper presents an investigation into the accuracy of human observers with regard to the recognition of collisions between virtual characters. We show the result of two user studies, where participants classify scenarios as "colliding" or "not colliding"; a pilot study investigates the perception of static images, whereas the main study expands on this by employing animated videos. In the pilot experiment, we investigated the effect of two variables on the ability to recognize collisions: distance between the character meshes and visibility of the inter-character gap. In the main experiment, we investigate the angle between the character paths and the severity of the (near) collision. On average, respondents correctly classified 72% (static) and 68% (animated) of the scenarios. A notable result is that the maximum uncertainty in determining existence of collisions occurs when the characters are overlapping and that there is a significant bias towards answering "not colliding." We also discuss differences in bias in the recognition of upper-and lower-body collisions.
C1 [Stuvel, Sybren A.; van der Stappen, A. Frank; Egges, Arjan] Univ Utrecht, Virtual Human Technol Lab, Utrecht, Netherlands.
C3 Utrecht University
RP van der Stappen, AF (corresponding author), Univ Utrecht, Virtual Human Technol Lab, Utrecht, Netherlands.
EM a.f.vanderstappen@uu.nl
OI van der Stappen, Frank/0000-0001-7965-2818
CR [Anonymous], 2003, Level of detail for 3D graphics
   Cohen J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P119, DOI 10.1145/237170.237220
   DeLucia PR, 2013, CURR DIR PSYCHOL SCI, V22, P199, DOI 10.1177/0963721412471679
   Dingliana J, 2000, COMPUT GRAPH FORUM, V19, pC239, DOI 10.1111/1467-8659.00416
   Ennis C, 2013, P MOT GAM MIG 13
   Ennis C, 2010, ACM SIGGRAPH 2010 SI
   Fleiss J.L., 2004, Statistical Methods for Rates and Proportions, VThird, P1, DOI [10.1002/0471445428, DOI 10.1002/0471445428]
   Gauss CF, 1809, CAMBRIDGE LIB COLLEC
   Hausdorff F., 1914, GRUNDZUGE MENGENLEHR
   Hoyet L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185586
   Hubbard PM, 1994, THESIS
   Kulpa R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024172
   LAVALLE S.M., 2006, Planning algorithms, DOI DOI 10.1017/CBO9780511546877
   McDonnell R, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1609967.1609969
   O'Sullivan C, 2001, ACM T GRAPHIC, V20, P151, DOI 10.1145/501786.501788
   O'Sullivan C, 2002, COMPUT GRAPH FORUM, V21, P733, DOI 10.1111/1467-8659.00631
   O'Sullivan C, 1999, SPRING COMP SCI, P67
   Olivier A.-H., 2010, P 7 S APPL PERCEPTIO, P117
   Otaduy M. A., 2003, Symposium on Geometry Processing, P94
   Stüvel SA, 2014, COMPUT ANIMAT VIRT W, V25, P333, DOI 10.1002/cav.1592
   Stüvel SA, 2014, HANDBOOK OF DIGITAL GAMES, P146
   Wand M, 2002, COMPUT GRAPH FORUM, V21, P483, DOI 10.1111/1467-8659.t01-1-00608
   Yoon S., 2004, Eurographics Symposium on Geometry Processing, P136
NR 23
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2017
VL 28
IS 5
AR e1728
DI 10.1002/cav.1728
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9XG
UT WOS:000417251100003
OA Green Published
DA 2024-07-18
ER

PT J
AU Narang, S
   Best, A
   Feng, A
   Kang, SH
   Manocha, D
   Shapiro, A
AF Narang, Sahil
   Best, Andrew
   Feng, Andrew
   Kang, Sin-hwa
   Manocha, Dinesh
   Shapiro, Ari
TI Motion recognition of self and others on realistic 3D avatars
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE animation; avatar; gaint; perception; virtual reality
ID BIOLOGICAL MOTION; PERCEPTION
AB Current 3D capture and modeling technology can rapidly generate highly photo-realistic 3D avatars of human subjects. However, while the avatars look like their human counterparts, their movements often do not mimic their own due to existing challenges in accurate motion capture and retargeting. A better understanding of factors that influence the perception of biological motion would be valuable for creating virtual avatars that capture the essence of their human subjects. To investigate these issues, we captured 22 subjects walking in an open space. We then performed a study where participants were asked to identify their own motion in varying visual representations and scenarios. Similarly, participants were asked to identify the motion of familiar individuals. Unlike prior studies that used captured footage with simple point-light displays, we rendered the motion on photo-realistic 3D virtual avatars of the subject. We found that self-recognition was significantly higher for virtual avatars than with point-light representations. Users were more confident of their responses when identifying their motion presented on their virtual avatar. Recognition rates varied considerably between motion types for recognition of others, but not for self-recognition. Overall, our results are consistent with previous studies that used recorded footage and offer key insights into the perception of motion rendered on virtual avatars.
C1 [Narang, Sahil; Feng, Andrew; Kang, Sin-hwa] Univ Southern Calif, Inst Creat Technol, Los Angeles, CA USA.
   [Shapiro, Ari] Univ Southern Calif, Inst Creat Technol, Animat & Simulat Res Grp, Los Angeles, CA USA.
   [Narang, Sahil; Best, Andrew] Univ N Carolina, Chapel Hill, NC 27599 USA.
   [Manocha, Dinesh] Univ N Carolina, Comp Sci, Chapel Hill, NC USA.
C3 University of Southern California; University of Southern California;
   University of North Carolina; University of North Carolina Chapel Hill;
   University of North Carolina; University of North Carolina Chapel Hill
RP Narang, S (corresponding author), Univ N Carolina, Chapel Hill, NC 27599 USA.
EM sahil@cs.unc.edu
OI Narang, Sahil/0000-0002-2909-1570
FU Institute for Information & communications Technology Promotion (IITP) -
   Korea government (MSIP) [R0184-15-1030]; National Science Foundation
   [1305286]; ARO [W911NF-16-1-0085]; Division Of Computer and Network
   Systems; Direct For Computer & Info Scie & Enginr [1305286] Funding
   Source: National Science Foundation
FX This work was supported by Institute for Information & communications
   Technology Promotion (IITP) grant (No. R0184-15-1030, MR AvatarWorld
   Service and Platform Development using Structured Light Sensor) funded
   by the Korea government (MSIP), National Science Foundation award
   1305286 and ARO contract W911NF-16-1-0085.
CR [Anonymous], 2013, P 10 IEEE INT C WORK
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   BEARDSWORTH T, 1981, B PSYCHONOMIC SOC, V18, P19
   Chaminade T, 2007, SOC COGN AFFECT NEUR, V2, P206, DOI 10.1093/scan/nsm017
   Cook R, 2012, P ROY SOC B-BIOL SCI, V279, P669, DOI 10.1098/rspb.2011.1264
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   Feng A., 2014, P 7 INT C MOTION GAM, P49, DOI [10.1145/2668064.2668102, DOI 10.1145/2668064.2668102]
   Feng A, 2014, COMPUT ANIMAT VIRT W, V25, P3, DOI 10.1002/cav.1560
   Feng Andrew, 2015, P 8 ACM SIGGRAPH C M, P57
   Fox J., 2010, CyberTherapy Rehabil, V3, P16, DOI [10.1037/e530522011-003, DOI 10.1037/E530522011-003]
   Guo SH, 2015, VISUAL COMPUT, V31, P497, DOI 10.1007/s00371-014-0943-4
   Hodgins JK, 1998, IEEE T VIS COMPUT GR, V4, P307, DOI 10.1109/2945.765325
   Hoyet L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508367
   Jain E, 2016, ACM T APPL PERCEPT, V13, DOI 10.1145/2947616
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Jokisch D, 2006, PERCEPTION, V35, P911, DOI 10.1068/p5540
   Kokkinara E., 2015, Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG'15, P221, DOI DOI 10.1145/2822013.2822035
   Loula F, 2005, J EXP PSYCHOL HUMAN, V31, P210, DOI 10.1037/0096-1523.31.1.210
   Lucas G., 2016, Proceedings of the 9th International Conference on Motion in Games, P167, DOI DOI 10.1145/2994258.2994263
   McDonnell R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360625
   Straub J, 2014, TECHNOLOGIES, V2, P76, DOI 10.3390/technologies2020076
   Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2
   Wellerdiek AC, 2013, P ACM S APPL PERC SA, P138, DOI [10.1145/2492494.2501895, DOI 10.1145/2492494.2501895]
NR 23
TC 17
Z9 19
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1762
DI 10.1002/cav.1762
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200009
DA 2024-07-18
ER

PT J
AU Wang, YT
   Wang, LY
   Deng, ZG
   Jin, XG
AF Wang, Yutong
   Wang, Luyuan
   Deng, Zhigang
   Jin, Xiaogang
TI Topologically consistent leafy tree morphing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE shape morphing; special effects; topological consistency; tree modeling
AB We present a novel morphing technique to generate pleasing visual effects between 2 topologically varying trees while preserving the topological consistency and botanical meanings of any in-between shapes as natural trees. Specifically, we first efficiently convert leafy trees into botanically inspired chain-lobe representations in an automatic way. With the aid of branching-pattern aware, one-to-many correspondences between branches and leaves, we hierarchically interpolate branches of in-between trees while maintaining their topological consistencies. Finally, we simultaneously interpolate foliage, specifically every single leaf, during the morphing process, avoiding the generation of unpleasant floating leaves. We demonstrate the effectiveness of our approach by creating visually compelling tree morphing animations, even between cross-species.
C1 [Wang, Yutong; Wang, Luyuan; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 Zhejiang University; University of Houston System; University of Houston
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM jin@cad.zju.edu.cn
OI Deng, Zhigang/0000-0003-2571-5865; Deng, Zhigang/0000-0002-0452-8676;
   Jin, Xiaogang/0000-0001-7339-2920
FU National Natural Science Foundation of China [61472351]
FX National Natural Science Foundation of China, Grant/Award Number:
   61472351
CR Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575
   Alsweis M, 2015, P 21 ACM S VIRT REAL, P95
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Behrendt S, 2005, COMPUT GRAPH FORUM, V24, P507, DOI 10.1111/j.1467-8659.2005.00876.x
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carmel E, 1997, VISUAL COMPUT, V13, P465, DOI 10.1007/s003710050118
   Dirr M.A., 1990, MANUAL WOODY LANDSCA, P554
   Guo XK, 2016, COMPUT GRAPH FORUM, V35, P89, DOI 10.1111/cgf.12966
   Guo XK, 2014, GRAPH MODELS, V76, P376, DOI 10.1016/j.gmod.2014.03.019
   HOLTON M, 1994, COMPUT GRAPH FORUM, V13, P57, DOI 10.1111/1467-8659.1310057
   Jain A, 2012, COMPUT GRAPH FORUM, V31, P631, DOI 10.1111/j.1467-8659.2012.03042.x
   Kim YJ, 2015, COMPUT ANIMAT VIRT W, V26, P423, DOI 10.1002/cav.1661
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Liu LG, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P111
   Livny Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964948
   Mündermann L, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P60, DOI 10.1109/CGI.2003.1214448
   Palubicki W, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531364
   Pirk S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661252
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366188
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185546
   Shinozaki K., 1964, JAPANESE J ECOL, V14, P97, DOI [DOI 10.18960/SEITAI.14.3_97, 18960/seitai.14.397.353]
   Talton JO, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618513
   Wang Y, 2016, IEEE T VISUAL COMPUT
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Zhao YL, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461961
   Zhu XQ, 2015, VISUAL COMPUT, V31, P69, DOI 10.1007/s00371-013-0905-2
NR 26
TC 2
Z9 2
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1761
DI 10.1002/cav.1761
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200008
DA 2024-07-18
ER

PT J
AU Cui, DL
   Sheng, Y
   Zhang, GX
AF Cui, Dele
   Sheng, Yun
   Zhang, Guixu
TI Image-based embroidery modeling and rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE non-photorealistic rendering; stroke-based rendering; embroidery
   simulation
ID WOVEN CLOTH; KNITWEAR
AB Embroidery is a traditional handicraft of sewing stitches into fabric or other materials in different patterns, and this ancient non-photorealistic art form has not drawn enough attention thus far. In this paper, we present an image-based method to simulate the traditional embroidery art. The method combines stroke-based rendering techniques with the Phong lighting model to create picturesque embroidery-like images. We first build a 3D stitch model and derive some most commonly used stitch patterns from it. Then we preprocess the input image by segmenting it into regions, from which the parameters to specify stitch patterns are obtained. Finally, we apply stitches back onto the desired regions and render them under a virtual light source. Experimental results show that our method, different from the existing schemes, is capable of performing fine embroidery simulations with the effects of lighting and shading based on an input image. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Cui, Dele; Sheng, Yun; Zhang, Guixu] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai 200241, Peoples R China.
C3 East China Normal University
RP Sheng, Y (corresponding author), East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai 200241, Peoples R China.
EM ysheng@cs.ecnu.edu.cn
CR Adabala Neeharika, 2003, P ACM S VIRTUAL REAL, P41
   [Anonymous], THESIS
   Chen X., 2012, Proceedings of Graphics Interface 2012, P131, DOI DOI 10.5555/2305276.2305299
   Cirio G, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661279
   Durupinar F, 2007, COMPUT GRAPH-UK, V31, P778, DOI 10.1016/j.cag.2007.06.002
   Hegde S, 2013, COMPUT ANIMAT VIRT W, V24, P43, DOI 10.1002/cav.1435
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Hertzmann A, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P47, DOI 10.1109/CGI.2001.934657
   Hertzmann A., 1998, Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques, P453
   Hertzmann A., 2002, NPAR, P91, DOI 10.1145/508530.508546
   Irawan P., 2008, THESIS
   Irawan P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077352
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Lu JW, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461998
   Moh J., 1937, PRINCIPLES STITCHING
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   SHIRAISHI M, 2000, P 1 INT S NONPH AN R, P53, DOI DOI 10.1145/340916.340923
   Xu YQ, 2001, COMP GRAPH, P391
   Yang K., 2012, P 5 INT S VIS INF CO, P87
   Yoo T, 2006, ACM SIGGRAPH 2006, P33
NR 21
TC 6
Z9 6
U1 3
U2 30
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2017
VL 28
IS 2
AR e1725
DI 10.1002/cav.1725
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ER2AB
UT WOS:000398595200005
DA 2024-07-18
ER

PT J
AU Olivares, U
   Rodríguez, HG
   García, A
   Ramos, FF
AF Olivares, Ulises
   Rodriguez, Hector G.
   Garcia, Arturo
   Ramos, Felix F.
TI Efficient construction of bounding volume hierarchies into a complete
   octree for ray tracing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE Ray tracing; octree; SIMD extensions; binary partition; dynamic scenes
AB This paper proposes an efficient construction scheme for bounding volume hierarchies based on a complete tree. This construction offers up to 4x faster construction times than binned-surface area heuristic and offers competitive ray traversal performance. The construction is fully parallelized on x86 CPU architectures; it takes advantage of the eight-wide vector units and exploits the advance vector extensions available for current x86 CPU architectures. Additionally, this work presents a clustering algorithm for grouping primitives, which can be computed in linear time O(n). Furthermore, this construction uses the graphics processing unit to perform intensive operations efficiently. Copyright (C) 2016 JohnWiley & Sons, Ltd.
C1 [Olivares, Ulises] Univ Nacl Autonoma Mexico, Dept Computat Biol, Lab Nacl Anal & Sintesis Ecol, Escuela Nacl Estudios Super Unidad Morelia, Morelia, Michoacan, Mexico.
   [Olivares, Ulises; Rodriguez, Hector G.; Ramos, Felix F.] IPN, Ctr Invest & Estudios Avanzados, Dept Elect Engn & Comp Sci, Unidad Guadalajara, Guadalajara, Jalisco, Mexico.
   [Garcia, Arturo] Intel Guadalajara Design Ctr, Visual Parallel Comp Grp, Guadalajara, Jalisco, Mexico.
C3 Universidad Nacional Autonoma de Mexico; CINVESTAV - Centro de
   Investigacion y de Estudios Avanzados del Instituto Politecnico
   Nacional; Instituto Politecnico Nacional - Mexico; Intel Corporation
RP Olivares, U (corresponding author), Antigua Carretera Patzcuaro 8701, Morelia 58190, Michoacan, Mexico.
EM uolivares@enesmorelia.unam.mx
RI García-Gil, Alejandro/O-4034-2018; Olivares-Pinto, Ulises/IWM-6898-2023;
   Olivares-Pinto, Ulises/E-8954-2019
OI García-Gil, Alejandro/0000-0001-5835-6390; Olivares-Pinto,
   Ulises/0000-0002-2607-859X
CR [Anonymous], STANF 3D SCANN REP
   Appel A., 1968, P AFIPS FALL JOINT C, P37, DOI [DOI 10.1145/1468075.1468082, 10.1145/1468075.1468082]
   Crytek, 1999, 3D MOD REP
   DOANE DP, 1976, AM STAT, V30, P181, DOI 10.2307/2683757
   Fatahalian G., 2013, P 5 HIGH PERF GRAPH, P81, DOI 10.1145/2492045.2492054
   Garanzha K., 2011, P ACM SIGGRAPH S HIG, P59, DOI DOI 10.1145/2018323.2018333
   Garcia A, 2012, GPU PRO, V3, P353
   Garcia A, 2014, P 13 ACM SIGGRAPH IN, P151, DOI DOI 10.1145/2670473.2670488
   Harris M., 2008, TECHNICAL REPORTS
   HILLIS WD, 1986, COMMUN ACM, V29, P1170, DOI 10.1145/7902.7903
   Karras T., 2012, P 4 ACM SIGGRAPH EUR, P33, DOI [10.2312/EGGH/HPG12/033-037, DOI 10.2312/EGGH/HPG12/033-037]
   Karras Tero., 2013, Proceedings of the 5th High-Performance Graphics Conference, P89, DOI DOI 10.1145/2492045.2492055
   Lauterbach C, 2009, COMPUT GRAPH FORUM, V28, P375, DOI 10.1111/j.1467-8659.2009.01377.x
   MacDonald J. D., 1990, Visual Computer, V6, P153, DOI 10.1007/BF01911006
   Morton GM, 1966, TECHNICAL REPORTS
   Murguia L. R. Sergio, 2013, GPU PRO 4 ADV RENDER, P319
   Olivares U, 2015, SIGRAD 2015, P13
   Olivares U, 2014, P 13 ACM SIGGRAPH IN, P189
   Pantaleoni J., 2010, P C HIGH PERFORMANCE, P87
   Parker SG, 2013, COMMUN ACM, V56, P93, DOI [10.1145/2447976.2447997, 10.1145/2447876.2447997]
   Sturges HA, 1926, J AM STAT ASSOC, V21, P65, DOI 10.1080/01621459.1926.10502161
   Sulaiman HA, 2012, INT J NEW COMPUTER A, V1, P396
   Wald I., 2007, Proceedings of the Annual Conference of the European Association for Computer Graphics, P89
   Wald I, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186650
   Wald I, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P33, DOI 10.1109/RT.2007.4342588
   Wald I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601199
   Wald I, 2012, IEEE T VIS COMPUT GR, V18, P47, DOI 10.1109/TVCG.2010.251
   Walter B, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P81, DOI 10.1109/RT.2008.4634626
   WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882
   Wu ZF, 2013, 2013 INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND VISUALIZATION (ICVRV 2013), P49, DOI 10.1109/ICVRV.2013.16
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 31
TC 1
Z9 1
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 358
EP 368
DI 10.1002/cav.1716
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300020
DA 2024-07-18
ER

PT J
AU Senecal, S
   Cuel, L
   Aristidou, A
   Magnenat-Thalmann, N
AF Senecal, Simon
   Cuel, Louis
   Aristidou, Andreas
   Magnenat-Thalmann, Nadia
TI Continuous body emotion recognition system during theater performances
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE emotion recognition; Laban Movement Analysis; behavior; motion capture;
   animation; interaction; nonverbal communication
ID MODEL
AB Understanding emotional human behavior in its multimodal and continuous aspect is necessary for studying human machine interaction and creating constituent social agents. As a first step, we propose a system for continuous emotional behavior recognition expressed by people during communication based on their gesture and their whole body dynamical motion. The features used to classify the motion are inspired by the Laban Movement Analysis entities [11] and are mapped onto the well-known Russell Circumplex Model [4]. We choose a specific case study that corresponds to an ideal case of multimodal behavior that emphasizes the body motion expression: theater performance. Using a trained neural network and annotated data, our system is able to describe the motion behavior as trajectories on the Russell Circumplex Model diagram during theater performances over time. This work contributes to the understanding of human behavior and expression and is a first step through a complete continuous emotion recognition system whose next step will be adding facial expressions. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Senecal, Simon; Cuel, Louis; Magnenat-Thalmann, Nadia] Univ Geneva, MIRALab, Geneva, Switzerland.
   [Aristidou, Andreas] Univ Cyprus, Nicosia, Cyprus.
C3 University of Geneva; University of Cyprus
RP Senecal, S (corresponding author), Univ Geneva, MIRALab, Geneva, Switzerland.
EM senecal@miralab.ch
RI Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Nadia/0000-0002-1459-5960; Senecal, Simon/0000-0002-7505-0497;
   Aristidou, Andreas/0000-0001-7754-0791
CR [Anonymous], Environmental Psychology & Nonverbal Behavior
   [Anonymous], 2003, P 2 INT C MOBILE UBI
   Aristidou A., 2013, SIGGRAPH ASIA 2013 T, P1, DOI [10.1145/2522628.2522651, DOI 10.1145/2522628.2522651]
   Aristidou A, 2015, COMPUT GRAPH FORUM, V34, P262, DOI 10.1111/cgf.12598
   Bartenieff I., 1980, BODY MOVEMENT COPING
   Bouchard D., 2015, Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, P23, DOI DOI 10.1145/2822013.2822039
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   Fourati N, 2015, INT CONF AFFECT, P267, DOI 10.1109/ACII.2015.7344582
   Hartmann B, 2006, LECT NOTES ARTIF INT, V3881, P188
   Kim WH, 2013, ACMIEEE INT CONF HUM, P163, DOI 10.1109/HRI.2013.6483552
   Kipp M, 2009, P 3 INT C AFFF COMP
   Kitsikidis A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P789
   Levine DS, 2007, PHYS LIFE REV, V4, P37, DOI 10.1016/j.plrev.2006.10.001
   Lotfi E, 2014, NEURAL NETWORKS, V59, P61, DOI 10.1016/j.neunet.2014.06.012
   Luo P, 2012, P MOT HGAM MIG 12 RE, P254
   Masuda M, 2009, 12 INT C PRINC PRACT, P322
   Masuda M, 2010, 2010 IEEE RO-MAN, P324, DOI 10.1109/ROMAN.2010.5598692
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Morita J, 2013, AM M COGN SCI SOC, P1026
   Nakata T., 2001, J ROBOT SOC JAPAN, V19, P252
   Ortony A., 1994, The Cognitive Structure of Emotions
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Santos L, 2010, IFIP ADV INF COMM TE, V314, P187
   Shiratori T, 2006, COMPUT GRAPH FORUM, V25, P449, DOI 10.1111/j.1467-8659.2006.00964.x
   Stanislavski K., 1938, An actor's work: A student's diary
   Stanislavsky K., 1948, THEATER
   Thenius R., 2013, Advances in Artificial Life, ECAL 2013, V12, P830, DOI DOI 10.7551/978-0-262-31709-2-CH122
   Torresani L., 2006, Neural Information Processing Systems, NIPS, P1393
   Truong A, 2016, VISUAL COMPUT, V32, P83, DOI 10.1007/s00371-014-1057-8
   Valstar M., 2013, P 3 ACM INT WORKSHOP, DOI [10.1145/2512530.2512533, DOI 10.1145/2512530.2512533]
   von Laban Rudolf., 1988, MASTERY MOVEMENT
   Wakayama Y, 2010, LECT NOTES ARTIF INT, V6279, P251, DOI 10.1007/978-3-642-15384-6_27
   Zacharatos H, 2013, P MOT GAM MIG 13, P39, DOI DOI 10.1145/2522628.2522651
   Zhao LW, 2005, GRAPH MODELS, V67, P1, DOI 10.1016/j.gmod.2004.08.002
NR 35
TC 36
Z9 37
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 311
EP 320
DI 10.1002/cav.1714
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300015
DA 2024-07-18
ER

PT J
AU Mao, TL
   Wang, H
   Deng, ZG
   Wang, ZQ
AF Mao, Tianlu
   Wang, Hua
   Deng, Zhigang
   Wang, Zhaoqi
TI An efficient lane model for complex traffic simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE lane model; the Frenet frame; traffic simulation; lane-changes
AB Traffic simulation heavily relies on lane model. This paper presents a novel method to model lanes based on the road axis under the Frenet frame. The road axis is generated from the geographic information system data after curve approximation, discretization, and compression. This lane model couples mileage information with three-dimensional geometric information, so it offers an easy and fast position transformation from mileage to the Cartesian coordinate. It also keeps strictly consistent for mileage among neighboring lanes so that it facilitates lane-change processing. Compared with existing methods that depict lanes as simple polylines or curves, the proposed lane model is more functional and more efficient, especially for complex traffic simulation with a large number of lane-changes. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Mao, Tianlu; Wang, Zhaoqi] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing, Peoples R China.
   [Wang, Hua] Zhengzhou Univ Light Ind, Sch Comp & Commun Engn, Zhengzhou, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Zhengzhou University of Light Industry; University of Houston System;
   University of Houston
RP Mao, TL (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, 6 Ke Xue Yuan South Rd, Beijing, Peoples R China.
EM ltm@ict.ac.cn
RI Hua, Wang/JCD-6392-2023
OI Deng, Zhigang/0000-0003-2571-5865; Deng, Zhigang/0000-0002-0452-8676
FU National Natural Science Foundation of China [61402269, 61173053,
   61272322, 61328204]; National Key Technology R and D Program of China
   [2013AA013902]; State Key Lab of CAD and CG at Zhejiang University
   [A1423]; Joint Research Fund for Overseas Chinese, Hong Kong
FX This work is supported and funded by the National Natural Science
   Foundation of China (grant nos. 61402269, 61173053, and 61272322) and
   the National Key Technology R and D Program of China (grant no.
   2013AA013902). Z. D. was supported by the Open Project Program of the
   State Key Lab of CAD and CG at Zhejiang University (grant A1423) and the
   Joint Research Fund for Overseas Chinese, Hong Kong, and Macao Young
   Scientists of the National Natural Science Foundation of China (grant
   no. 61328204). We would like to thank the reviewers for their
   constructive comments and suggestions.
CR [Anonymous], 2011, VISS 5 30 05 US MAN, P11
   Ben-Akiva M, 2002, USERS GUIDE MITSIMLA, P2
   Guggenheimer H., 1989, Computer-Aided Geometric Design, V6, P77, DOI 10.1016/0167-8396(89)90008-3
   Klok F., 1986, Computer-Aided Geometric Design, V3, P217, DOI 10.1016/0167-8396(86)90039-7
   Lu X, 2014, COMPUTER ANIMATION V, V25, P85
   Lu XQ, 2014, COMPUT ANIMAT VIRT W, V25, P363, DOI 10.1002/cav.1575
   Quadstone Paramics, 2003, QUADST PAR V4 2 AN R, P3
   Saalfeld A., 1999, Cartogr. Geogr. Inf. Sci., V26, P7, DOI 10.1559/152304099782424901
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   SHARIPOV RA, 1996, COURSE DIFFERENTIAL
   Shen JJ, 2012, GRAPH MODELS, V74, P265, DOI 10.1016/j.gmod.2012.04.002
   Shifrin T, 2014, 1 COURSE CURVES SURF
   Siltanen P, 1992, COMPUT GRAPH FORUM, V11, P1992
   Wang H., 2002, P 5 INT C CURVES SUR, P387
   Wang H, 2014, COMPUT ANIMAT VIRT W, V25, P385, DOI 10.1002/cav.1576
   Wang WP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330513
   Werling M, 2010, IEEE INT CONF ROBOT, P987, DOI 10.1109/ROBOT.2010.5509799
   Wilkie D, 2012, IEEE T VIS COMPUT GR, V18, P890, DOI 10.1109/TVCG.2011.116
   Xu WD, 2011, IEEE INT CONF ROBOT, P2267, DOI 10.1109/ICRA.2011.5980101
   Yang Q, 1996, TRANSPORT RES C-EMER, V4, P113, DOI 10.1016/S0968-090X(96)00006-X
NR 20
TC 8
Z9 16
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 397
EP 403
DI 10.1002/cav.1642
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700021
DA 2024-07-18
ER

PT J
AU Zhang, XY
   Liu, SG
AF Zhang, Xiaoyong
   Liu, Shiguang
TI SPH fluid control with self-adaptive turbulent details
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE fluid simulation; shape control; curvature; turbulence; SPH
ID VORTEX PARTICLE METHOD; SMOKE; WATER
AB Smoothed particle hydrodynamics (SPH)-based fluid control is often involved in fluid animation. Because most of the existing SPH fluid control methods employ the strategy of control force to control fluid particles, the artificial viscosity introduced by control force would lead to the loss of fine-scale details. Although the introduction of the low-pass filter can add details, it may easily destroy the target shape. To remedy the previous problems, we sample the control particles with curvature information to represent the shape complexity. Because of the shape's complexity, we suppress the generation of turbulence in the high-curvature areas and promote turbulence in the low-curvature regions. Our self-adaptive way to randomly generate turbulence can effectively prevent the lack of fluid dynamics caused by the artificial viscosity. Our new method can improve the visual quality of the fluid animation, and the shape control result is consistent to the target shape. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Zhang, Xiaoyong; Liu, Shiguang] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Liu, Shiguang] Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM lsg@tju.edu.cn
FU Natural Science Foundation of China [61170118, 60803047]; Application
   Foundation Research Plan Project of Tianjin [14JCQNJC00100]
FX The authors would like to thank the anonymous reviewers for their
   insightful comments. This work was supported by the Natural Science
   Foundation of China under grant nos. 61170118 and 60803047 and the
   Application Foundation Research Plan Project of Tianjin under grant no.
   14JCQNJC00100.
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   [Anonymous], 2004, COMPUTER ANIMATION 2, DOI DOI 10.1145/1028523.1028549
   Baerentzens JA, 2002, 200221 TU DENM
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P178, DOI 10.1109/CGI.1997.601299
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   Huang RG, 2013, VISUAL COMPUT, V29, P751, DOI 10.1007/s00371-013-0798-0
   Huang Ruoguan., 2011, Proceedings of the 2011 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'11, P177, DOI DOI 10.1145/2019406.2019430
   Ihmsen Markus, 2014, P 35 ANN C EUR ASS C, DOI [10.2312/egst.20141034, DOI 10.2312/EGST.20141034]
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Llamas Ignacio., 2007, SIGGRAPH '07: SIGGRAPH Sketches, P18, DOI 10.1145/1278780.1278802
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Nielsen MB, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964978
   Nielsen MichaelB., 2009, SCA '09: Proc. of the 2009 ACM SIGGRAPH/Eurographics Symp. on Comput. Anim, P217
   Park S. I., 2005, Computer Animation, Conference Proceedings, P261, DOI [DOI 10.1145/1073368.1073406, 10.1145/1073368.1073406]
   Pfaff T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866196
   Rusinkiewicz S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P486, DOI 10.1109/TDPVT.2004.1335277
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Shao XQ, 2013, INT C COMP AID DES C, P252, DOI 10.1109/CADGraphics.2013.40
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Shi Lin., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '05, P229, DOI DOI 10.1145/1073368.1073401
   Solenthaler B, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964976
   Thürey N, 2009, GRAPH MODELS, V71, P221, DOI 10.1016/j.gmod.2008.12.007
   Yoon JC, 2009, COMPUT GRAPH FORUM, V28, P1853, DOI 10.1111/j.1467-8659.2009.01563.x
   Yuan Z, 2012, VISUAL COMPUT, V28, P435, DOI 10.1007/s00371-011-0626-3
NR 28
TC 7
Z9 9
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 357
EP 366
DI 10.1002/cav.1637
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700017
DA 2024-07-18
ER

PT J
AU Liang, D
   Park, K
AF Liang, Dongxue
   Park, Kyoungju
TI Pencil drawing animation from a video
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE pencil drawing; non-photorealistic animation; optical flow; temporal
   coherence
ID IMAGE
AB We present an automatic, efficient, and simple technique to create pencil drawing animation, starting from a video. We generate pencil drawing from a source frame based on stroke modeling, specifying the properties of strokes, in combination with layered lines, flow-guided difference-of-Gaussian (DoG) filter to several layers. Generated pencil strokes are translated and rotated because of forces exerted from the sequential frames using rigid body dynamics. Linear and angular forces acting on strokes are calculated according to the temporally filtered per-pixel optical flow vectors. Our framework effectively generates the coherent animation of pencil strokes preserving the structured appearance of charcoal or pastel, which is difficult to achieve with previous-abstraction based non-photorealistic animation. Moreover, our stroke simulation step is suitable for animating the different styles of strokes, such as oil painting and watercolor, and can be efficiently implemented to produce animation in relatively inexpensive manner. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Liang, Dongxue; Park, Kyoungju] Chung Ang Univ, Dept Image, Seoul 156756, South Korea.
C3 Chung Ang University
RP Park, K (corresponding author), Chung Ang Univ, Dept Image, Heukseok Ro 84, Seoul 156756, South Korea.
EM kjpark@cau.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF); Ministry of Education, Science and Technology
   [2009-0074861, 2010-0006676]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (2009-0074861 and 2010-0006676).
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P584, DOI 10.1145/1015706.1015764
   Agarwala A., P NPAR 2002, P139
   Baraff D, SIGGRAPH 1997
   Bousseau A, 2006, P NPAR 2006, P141
   Bousseau A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276507
   Cabral B, 1993, P CGI 1993, P263
   Collomosse JP, 2005, IEEE T VIS COMPUT GR, V11, P540, DOI 10.1109/TVCG.2005.85
   Hata M, 2012, VISUAL COMPUT, V28, P657, DOI 10.1007/s00371-012-0689-9
   Hays J, P NPAR 2004, P113
   Hedge S, 2012, COMPUTER ANIMATION V, V24, P43
   HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A, 2000, P 1 INT S NONPHOTORE, P7
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kyprianidis JE, 2011, COMPUT GRAPH FORUM, V30, P593, DOI 10.1111/j.1467-8659.2011.01882.x
   Lang M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185530
   Lin L, NPAR 2010, P73
   Lin L., 2010, Proc. NPAR '10, P73, DOI DOI 10.1145/1809939.1809948
   Litwinowicz P., P SIGGRAPH 1997, P407
   Lu C, P NPAR 2012, P65
   Lu J, P I3D 2010 ACM SIGGR, P127
   Lucas B. D., 1981, 7 INT JOINT C ART IN, V81, P674
   Maillot P.-G., 1990, Graphics Gems, P498
   Mao XY, 2001, CAD/GRAPHICS '2001: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN AND COMPUTER GRAPHICS, VOLS 1 AND 2, P240
   Matsui H, P CGI 2005, P148
   Matthias M, SIGGRAPH 2008
   Metaxas D.N., 1996, PHYS BASED DEFORMABL
   Park Y, 2006, GRAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P158
   Park Y, 2008, GRAPH MODELS, V70, P1, DOI 10.1016/j.gmod.2007.06.001
   Son M, PAC GRAPH 2007, P333
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Wang J, 2006, ACM T GRAPHIC, V25, P1221
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Xie DE, 2007, LECT NOTES COMPUT SC, V4847, P723
   Yamamoto S, 2004, I C COMP GRAPH IM VI, P251, DOI 10.1109/CGIV.2004.1323994
   Yamamoto S, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P329
   Yoon JC, 2012, IEEE T VIS COMPUT GR, V18, P58, DOI 10.1109/TVCG.2011.47
   Zhang SH, 2009, SCI CHINA SER F, V52, P162, DOI 10.1007/s11432-009-0035-7
   Zhao JX, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P466, DOI 10.1109/CISP.2008.250
NR 40
TC 2
Z9 3
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 307
EP 316
DI 10.1002/cav.1520
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500018
DA 2024-07-18
ER

PT J
AU Song, J
   Choi, B
   Seol, Y
   Noh, J
AF Song, Jaewon
   Choi, Byungkuk
   Seol, Yeongho
   Noh, Junyong
TI Characteristic facial retargeting
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE facial animation; motion retargeting; facial style transfer; machine
   learning
AB Facial motion retargeting has been developed mainly in the direction of representing high fidelity between a source and a target model. We present a novel facial motion retargeting method that properly regards the significant characteristics of target face model. We focus on stylistic facial shapes and timings that reveal the individuality of the target model well, after the retargeting process is finished. The method works with a range of expression pairs between the source and the target facial expressions and emotional sequence pairs of the source and the target facial motions. We first construct a prediction model to place semantically corresponding facial shapes. Our hybrid retargeting model, which combines the radial basis function (RBF) and kernel canonical correlation analysis (kCCA)-based regression methods copes well with new input source motions without visual artifacts. 1D Laplacian motion warping follows after the shape retargeting process, replacing stylistically important emotional sequences and thus, representing the characteristics of the target face. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Song, Jaewon; Choi, Byungkuk; Seol, Yeongho; Noh, Junyong] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Taejon 305701, South Korea.
   [Noh, Junyong] Korea Adv Inst Sci & Technol, Inst Entertainment Engn, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST)
RP Noh, J (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Room 2337,N5,291 Daehak Ro, Taejon 305701, South Korea.
EM junyongnoh@kaist.ac.kr
RI Noh, Junyong/C-1663-2011; Song, Jaewon/HMV-0601-2023; Seol,
   Yeongho/KIE-6801-2024
OI Song, Jaewon/0000-0002-1238-2435; 
CR Bickel B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239484
   CHUANG E., 2002, PERFORMANCE DRIVEN F
   Curio C., 2006, P 3 S APPL PERC GRAP, DOI 10.1145/1140491.1140508
   DENG Z, 2006, 13D 2006, P43
   Feng WW, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360690
   HAVALDAR P, 2006, ACM SIGGRAPH 2006
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Jun-yong Noh, 2001, P 28 ANN C COMP GRAP
   Lasseter John., 1987, Proceedings of the 14th annual conference on Computer graphics and interactive techniques, P35
   MEHRABIA.A, 1970, J CONSULT CLIN PSYCH, V35, P248, DOI 10.1037/h0030083
   Na K, 2004, COMPUT GRAPH FORUM, V23, P687, DOI 10.1111/j.1467-8659.2004.00801.x
   Pyun H., 2003, SIGGRAPH/EUROGRAPHICS Symposium on Computer Animation, P167
   Sorkine O., 2004, P EUR ASS COMP MACH, P175, DOI DOI 10.1145/1057432.1057456
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang J, 2006, ACM T GRAPHIC, V25, P1169, DOI 10.1145/1141911.1142010
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
   Witkin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P105, DOI 10.1145/218380.218422
NR 19
TC 16
Z9 17
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 187
EP 194
DI 10.1002/cav.414
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700014
DA 2024-07-18
ER

PT J
AU Deng, QQ
   Zhang, XP
   Yang, G
   Jaeger, M
AF Deng, Qingqiong
   Zhang, Xiaopeng
   Yang, Gang
   Jaeger, Marc
TI Multiresolution foliage for forest rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE tree foliage; level of detail; compression; multi-resolution; rendering;
   GPU-oriented
AB Plants are important objects in virtual environments. High complexity of shape structure is found in plant communities. Level of detail (LOD) of plant geometric models becomes important for interactive forest rendering. We emphasize three major problems in current research: the time consumption in LOD model construction and extraction, the balance between visual effect and data compression, and the time consumption in the communication between Central Processing Unit (CPU) and Graphics Processing Unit (GPU). We present a new foliage simplification framework for LOD model and forest rendering. By an uneven subdivision of the tree crown volume, the cost for LOD model construction is drastically reduced. With a GPU-oriented design of LOD storage structure for foliage, the costly hierarchical traversal of a binary tree is replaced by a sequential lookup of all array. The structure also decreases the communication between the CPU and the GPU in rendering. In addition, Leaf density is introduced to adapt compression to the local distribution of leaves, so that more visually relevant details are kept. According to foliage nature (broad leaves or needles), higher compression are finally reached using mixed polygon/line models. This framework is implemented on virtual scenes of simulated trees With high detail. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Zhang, Xiaopeng] Chinese Acad Sci, LIAMA Sino French Lab, NLPR, Inst Automat, Beijing 100190, Peoples R China.
   [Jaeger, Marc] Ecole Cent Paris, Paris, France.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Universite
   Paris Saclay
RP Zhang, XP (corresponding author), Chinese Acad Sci, LIAMA Sino French Lab, NLPR, Inst Automat, Room 1118,Bldg Automat,95 E Zhongguancun Rd, Beijing 100190, Peoples R China.
EM xpzhang@nlpr.ia.ac.cn
OI JAEGER, Marc/0000-0003-1742-6748
FU National Natural Science Foundation of China [60672148, 60872120];
   National High-Tech Research and Development 863 Plan of China
   [2006AA01Z301, 2008AA01Z301, 2008AA10Z218]; French National Research
   Agency [NATSIM ANR-05-MMSA-45]
FX All plant models in this paper are from the Output of AMAP-Genesis (TM).
   This work is supported by National Natural Science Foundation of China
   Projects No. 60672148, 60872120; National High-Tech Research and
   Development 863 Plan of China under Grant No. 2006AA01Z301,2008AA01Z301,
   and 2008AA10Z218; and the French National Research Agency within project
   NATSIM ANR-05-MMSA-45.
CR BEHRENDT C, 2005, P EUR 2005, P507
   Blinn J., 1988, IEEE Comput. Graph. Appl, V8, P82
   Bloomenthal J., 1985, Computer Graphics, V19, P305, DOI 10.1145/325165.325249
   Chang CF, 1999, COMP GRAPH, P291, DOI 10.1145/311535.311571
   Cignoni P, 1998, COMPUT GRAPH-UK, V22, P37, DOI 10.1016/S0097-8493(97)00082-4
   Dachsbacher C, 2003, ACM T GRAPHIC, V22, P657, DOI 10.1145/882262.882321
   de Reffye P., 1988, Computer Graphics, V22, P151, DOI 10.1145/378456.378505
   DECAUDIN P, 2004, P 2004 EUR WORKSH RE, P93
   DENG Q, 2007, P 2 INT C E LEARN GA, P33
   DENG Q, 2007, INT J VIRTUAL REALIT, V6, P77
   Deussen O, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P219, DOI 10.1109/VISUAL.2002.1183778
   DEUSSEN O, 1996, P TERN C COMP GRAPH, P130
   Fuhrmann A.L., 2005, Objavljeno v Proceedings of the First Eurographics Conference on Natural Phenomena, NPH'05, strani, P57
   Garland M., 1997, PROC 24 C COMPUTER G, P209, DOI DOI 10.1145/258734.258849
   GILET G, 2005, EUROGRAPHICS WORKSH, P67
   Guéziec A, 2001, IEEE T VIS COMPUT GR, V7, P136, DOI 10.1109/2945.928166
   HIDALGO J, 2006, P 6 IASTED INT C VIS, P130
   JAEGER M, 1992, J BIOSCIENCES, V17, P275, DOI 10.1007/BF02703154
   JAKULIN A, 2000, P EUR 2000 C SHORT P, P273
   LLUCH J, 2004, J WSCG 04, V12, P507
   Max N., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P165
   MAX N, 1999, P 1999 EUR WORKSH RE, P57
   Meyer A, 2001, SPRING EUROGRAP, P183
   Neyret F, 1998, IEEE T VIS COMPUT GR, V4, P55, DOI 10.1109/2945.675652
   PRUSINKIEWICZ OP, 1990, ALGORITHMIC BEAUTY P
   REBOLLO C, 2006, P 21 INT S COMP INF, P374
   REEVES WT, 1985, P SIGGRAPH 85, P313
   REEVES WT, 1987, COMPUTER GRAPHICS, P283
   REMOLAR C, 2003, P 11 INT C CENTR EUR, P370
   REMOLAR C, 2002, P EUR 2002 C SHORT P, P397
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Stamminger M, 2001, SPRING EUROGRAP, P151
   Zhang X., 2006, P ACM SIGGRAPH INT C, P331
   Zhang X., 2003, P 2003 INT S PLANT G, P217
NR 34
TC 12
Z9 15
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2010
VL 21
IS 1
BP 1
EP 23
DI 10.1002/cav.283
PG 23
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 560XD
UT WOS:000274937200002
DA 2024-07-18
ER

PT J
AU Jong, Y
   Ihm, I
AF Jong, Yoojin
   Ihm, Insung
TI Chemical kinetics-assisted, path-based smoke simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE fluid animation; path-based smoke simulation; chemical kinetics;
   particles; animation control
ID ANIMATION
AB Despite recent successes in physics-based fluid animation, generating desired fluid flow with intuitive control of its motion still remains a challenging problem in the special effects industry. In this paper, we propose a novel approach for path-based smoke simulation that explores the theory of chemical kinetics in an aim to provide a useful animation tool. By describing intended smoke effects through chemical reaction equations and adjusting their parameters, our method allows to easily create various interesting smoke effects that Were often hard to get With previous techniques. To demonstrate the effectiveness of the presented animation framework, we describe several examples of path-based smoke animations, generated with easily understandable reaction equations and control parameters. Copyright (C) 2009 John Wiley & Sons, Ltd.
RP Ihm, I (corresponding author), Sogang Univ, Dept Comp Sci & Engn, 1 Shinsu Dong, Seoul, South Korea.
EM ihm@sogang.ac.kr
CR Angelidis Alexis., 2006, S COMPUTER ANIMATION, P25
   Dobashi Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360693
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Foster N, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P178, DOI 10.1109/CGI.1997.601299
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   IHM I, 2004, ACM T GRAPHICS ACM S, P203
   KANG B, 2007, ACM T GRAPHICS ACM S, P199
   Kim B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239549
   Kim Y., 2006, P 2006 ACM SIGGRAPHE, P33
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Schpok J., 2005, P 2005 ACM SIGGRAPHE, P97, DOI [10.1145/1073368.1073381, DOI 10.1145/1073368.1073381]
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Shi Lin., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '05, P229, DOI DOI 10.1145/1073368.1073401
   Thurey N., 2006, Proceedings of the 2006 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'06, P7, DOI [10.5555/1218064.1218066, DOI 10.5555/1218064.1218066]
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
NR 18
TC 0
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 247
EP 256
DI 10.1002/cav.286
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700018
DA 2024-07-18
ER

PT J
AU Bender, J
AF Bender, Jan
TI Impulse-based dynamic simulation in linear time
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE linear-time dynamics; dynamic simulation; physically based animation;
   rigid bodies; articulated bodies
ID SYSTEMS
AB This paper describes an impulse-based dynamic simulation method for articulated bodies which has a linear time complexity. Existing linear-time methods are either based on a reduced-coordinate formulation or on Lagrange multipliers. The impulse-based simulation has advantages over these well-known methods. Unlike reduced-coordinate methods, it handles nonholonomic constraints like velocity-dependent ones and is very easy to implement. In contrast to Lagrange multiplier methods the impulse-based approach has no drift problem and an additional stabilisation is not necessary. The presented method computes a simulation step in O(n) time for acyclic multi-body systems containing equality constraints. Closed kinematic chains can be handled by dividing the model into different acyclic parts. Each of these parts is solved independently from each other. The dependencies between the single parts are solved by an iterative method. In the same way inequality constraints can be integrated in the simulation process in order to handle collisions and permanent contacts with dynamic and static friction. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Univ Karlsruhe, Inst Betriebs & Dialogsyt, Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Bender, J (corresponding author), Univ Karlsruhe, Inst Betriebs & Dialogsyt, Karlsruhe, Germany.
EM jbender@ira.uka.de
CR [Anonymous], SIGGRAPH 85
   ASCHER UM, 1995, MECH STRUCT MACH, V23, P135, DOI 10.1080/08905459508905232
   Baraff D., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P137, DOI 10.1145/237170.237226
   Baumgarte J., 1972, Computer Methods in Applied Mechanics and Engineering, V1, P1, DOI 10.1016/0045-7825(72)90018-7
   Bender J., 2006, P 19 INT C COMPUTER, P3
   BENDER J, 2005, P VIRT CONC 2005
   BENDER J, 2006, VIRTUAL REALITY INTE, P81
   Featherstone R., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P826, DOI 10.1109/ROBOT.2000.844153
   FEATHERSTONE R, 1987, DYNAMICS ALGORITHM
   Jalon J.G., 1994, Kinematic and dynamic simulation of multibody systems: the real time challenge
   Schenk O, 2004, FUTURE GENER COMP SY, V20, P475, DOI 10.1016/j.future.2003.07.011
   Schenk O., 2004, FAST FACTORIZATION P
   Schmitt A., 2005, 17 I BETR DIAL
   Weinstein R, 2006, IEEE T VIS COMPUT GR, V12, P365, DOI 10.1109/TVCG.2006.48
   Witkin A., 1990, Computer Graphics, V24, P243
NR 15
TC 11
Z9 16
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 225
EP 233
DI 10.1002/cav.179
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000002
DA 2024-07-18
ER

PT J
AU Zeng, YL
   Tan, CI
   Tai, WK
   Yang, MT
   Chiang, CC
   Chang, CC
AF Zeng, Ya-Lun
   Tan, Charlie Irawan
   Tai, Wen-Kai
   Yang, Mau-Tsuen
   Chiang, Cheng-Chin
   Chang, Chin-Chen
TI A momentum-based deformation system for granular material
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE computer animation; simulation; granular surface deformation; granular
   material; rigid body interaction
AB Computer graphics animation often lacks interaction between rigid object and granular material. In this paper, we propose a method for the deformation of the ground surface that consists of granular material when it is penetrated by a rigid body object in motion. Meanwhile, the motion of the rigid object is also affected due to the collision with the ground surface. Our simulation model concerns: updating the motion of object, the collision detection between the rigid object and the ground surface, the distribution of the ground granular material and the deformation of the ground surface. Our contribution is that we present a method to simulate the interaction between the ground granular material and the rigid body object in motion. Moreover, a render to texture method is presented to accelerate the ray casting collision detection between the ground surface and the object. And, our implementation for the method can be simulated at interactive frame rates. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Natl Dong Hwa Univ, Hualien 974, Taiwan.
C3 National Dong Hwa University
RP Tai, WK (corresponding author), Natl Dong Hwa Univ, 1,Sec 2 Da Hsueh Rd, Hualien 974, Taiwan.
EM wktai@mail.ndhu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
CR BELL N, 2005, SCA 05, P77
   Benes B, 2001, SPRING CONFERENCE ON COMPUTER GRAPHICS, PROCEEDINGS, P80, DOI 10.1109/SCCG.2001.945341
   BENES B, 2004, WSCG SHORT COMM PAP, P17
   BRACKBILL JU, 1986, J COMPUT PHYS, V65, P314, DOI 10.1016/0021-9991(86)90211-1
   CHANCLOU B., 1996, COMPUTER ANIMATION 9, P27
   Chowdhury R., 1978, Slope analysis
   Fearing P, 2000, COMP GRAPH, P37, DOI 10.1145/344779.344809
   HARLOW FH, 1963, EXPT ARITHMETIC HIGH, V15, P269
   Li X., 1993, P 20 ANN C COMPUTER, P361
   Musgrave F. K., 1989, Computer Graphics, V23, P41, DOI 10.1145/74334.74337
   Nishita T, 1997, COMPUT GRAPH FORUM, V16, pC357, DOI 10.1111/1467-8659.00173
   Onoue K, 2005, COMPUT GRAPH FORUM, V24, P51, DOI 10.1111/j.1467-8659.2005.00828.x
   Onoue K, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P252, DOI 10.1109/PCCGA.2003.1238267
   Onoue K, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P427, DOI 10.1109/PCCGA.2000.883978
   Sheffer A, 2001, ENG COMPUT-GERMANY, V17, P326, DOI 10.1007/PL00013391
   SUMNER RW, 1999, COMPUT GRAPH FORUM, V18, P3
   WROTEK P, 2004, P 31 ANN C COMP GRAP
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 18
TC 5
Z9 6
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 289
EP 300
DI 10.1002/cav.209
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000008
DA 2024-07-18
ER

PT J
AU Brown, E
   Barrett, N
AF Brown, Edward
   Barrett, Neil
TI A Wizard-of-Oz platform for embodied conversational agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE agent; conversational; prototyping; Wizard-of-Oz
AB A low-cost prototyping environment for experimenting with embodied conversational agents is discussed. The platform allows modeling and experimenting with different agent constructs and protocols prior to significant investment in the construction of the agent environment. Problems in the design of such a platform include the substantial number of agent controls needed and the flexibility required to represent the constructs of different theories, protocols and target environments as they are introduced and developed. These problems are addressed by augmenting a movie clip manager With a general drawing palette as a design tool. The result is a prototyping environment Which simulates multiple agents on a desktop while allowing arbitrary notational conventions. The current version does not render multiple agents in a shared virtual environment, but the protocol-based architecture is amenable to such extensions. In the meantime, valuable results regarding the social character Of multiple agent interaction call be explored with the existing tool. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1B 3X5, Canada.
C3 Memorial University Newfoundland
RP Barrett, N (corresponding author), Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1B 3X5, Canada.
EM brown@cs.mun.ca
CR [Anonymous], P 6 INT C MULT INT P
   Bailey BrianP., 2003, P C HUMAN FACTORS CO, P313, DOI DOI 10.1145/642611.642666
   Balci Koray., 2005, ICMI '05: Proceedings of the 7th international conference on Multimodal interfaces, P208
   EISENBERG M, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P431, DOI 10.1145/191666.191813
   Kelleher C, 2005, ACM COMPUT SURV, V37, P83, DOI 10.1145/1089733.1089734
   KLEIN F, 2005, P 4 WORKSH SOFTW ENG, P1
   Klemmer Scott R., 2000, P UIST C 2000, P1, DOI DOI 10.1145/354401
   KO AJ, 2005, 1 WORKSH END US SOFT, P1
   Maeder R. E., 2000, COMPUTER SCI MATH TH
   MAYA V, 2004, 3 INT JOINT C AUT AG, P1306
   Pelachaud C., 2005, 13th Annual ACM International Conference on Multimedia, P683, DOI 10.1145/1101149.1101301
   Sinha Anoop K., 2003, Proceedings of the International Conference on Multimodal Interfaces (ICMI), P117, DOI [10.1145/958432.958457, DOI 10.1145/958432.958457]
   WINOGRAD T, 1986, UNDERSTANDIGN COMPUT
NR 13
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 249
EP 257
DI 10.1002/cav.129
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400012
DA 2024-07-18
ER

PT J
AU Chen, Q
   Tian, F
   Seah, H
   Wu, ZK
   Qiu, J
   Konstantin, M
AF Chen, Quan
   Tian, Feng
   Seah, HockSoon
   Wu, Zhongke
   Qiu, Jie
   Konstantin, Melikhov
TI DBSC-based animation enhanced with feature and motion
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 2D animation; interpolation; B-spline curve; skeleton
AB Disk B-spline curve (DBSC) is previously proposed for drawing and animation. To generate inbetweens, linear interpolation is applied between points evenly taken in parametric domain of two DBSCs without incorporating characteristics of shape or motion, which results in distortion and unrealistic motion in animation. In this paper, more information in keyframes is extracted and utilized in inbetween generation. Points with high curvature are computed and corresponded between strokes in interpolation, Which preserves features of strokes in animation. In addition, global motion of a character or its various components is estimated and interpolated as well, Which retains the shapes during the motion. By applying the information to interpolation, the distortion is eliminated and smoother sequence of animation is achieved. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Nanyang Technol Univ, Ctr Adv Media Technol, Singapore, Singapore.
C3 Nanyang Technological University
RP Chen, Q (corresponding author), Nanyang Technol Univ, Ctr Adv Media Technol, Nanyang Ave, Singapore, Singapore.
EM chenquan@pmail.ntu.edu.sg
RI Seah, Hock Soon/A-3673-2011; Seah, Hock Soon/AAK-9900-2020
OI Seah, Hock Soon/0000-0003-2699-7147
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   ARREBOLA F, 2002, ELECTRON LETT, V38, P699
   BARTEL RH, 1989, P 1989 ACM SIGGRAPH, P167
   BURTNYK N, 1976, COMMUN ACM, V19, P564, DOI 10.1145/360349.360357
   CHEN Q, 2004, INT WORKSH ADV IM TE
   CHEN Q, 2006, INT WORKSH ADV IM TE
   Johan H, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P348, DOI 10.1109/PCCGA.2000.883958
   OWEN M, 1994, IEEE
   Piegl L, 1995, NURBS BOOK
   Qiu J, 2005, VISUAL COMPUT, V21, P928, DOI 10.1007/s00371-005-0307-1
   QUN L, 1998, COMPUT AIDED GEOM D, P721
   Rogers D.F., 1998, Procedural Elements for Computer Graphics, V2nd
   SEAH HS, 2005, ACM SIGCHI INT C ADV, P88
   SEAH HS, 1994, INSIGHT COMPUTER GRA, P62
   Sederberg T. W., 1993, Computer Graphics Proceedings, P15, DOI 10.1145/166117.166118
   SEDERBERG TW, 1992, COMP GRAPH, V26, P25, DOI 10.1145/142920.134001
   SEDERBERG TW, 1999, MATH METHODS CURVES, P497
   SHAPIRA M, 1995, COMPUTER GRAPHICS AP, P44
   SMITH SM, 1995, TR95SMS5 DEF RES AG
   TEH CH, P IEEE COMP SOC C CO
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   VANDENBERGH J, 2002, P 1 IB AM S COMP GRA, P315
   WU Z, 2004, C MULT ARTS PAC
   XIAO X, 2004, C MULT ARTS AS PAC
NR 24
TC 17
Z9 17
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 189
EP 198
DI 10.1002/cav.122
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400006
DA 2024-07-18
ER

PT J
AU García-Rojas, A
   Vexo, F
   Thalmann, D
   Raouzaiou, A
   Karpouzis, K
   Kollias, S
   Moccozet, L
   Magnenat-Thalmann, N
AF Garcia-Rojas, A.
   Vexo, F.
   Thalmann, D.
   Raouzaiou, A.
   Karpouzis, K.
   Kollias, S.
   Moccozet, L.
   Magnenat-Thalmann, N.
TI Emotional face expression profiles supported by virtual human ontology
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE ontology; MPEG-4 facial animation; emotion expression
AB Expressive facial animation synthesis of human like characters has had many approaches with good results. MPEG-4 standard has functioned as the basis of many of those approaches. In this paper we would like to lay out the knowledge of softie of those approaches inside all ontology in order to support the modeling of emotional facial animation in virtual humans (VH). Inside this ontology we will present MPEG-4 facial animation concepts and its relationship With emotion through expression profiles that utilize psychological models of emotions. The ontology allows storing, indexing and retrieving prerecorded synthetic facial animations that call express a given emotion. Also this ontology can be used a refined knowledge base in regards to the emotional facial animation creation. This ontology is made using Web Ontology Language and the results are presented as answered queries. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Ecole Polytech Fed Lausanne, VRLab, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP García-Rojas, A (corresponding author), Ecole Polytech Fed Lausanne, VRLab, CH-1015 Lausanne, Switzerland.
EM alejandra.garciarojas@epfl.ch
RI Karpouzis, Kostas/A-1792-2008; Thalmann, Nadia/AAK-5195-2021; Kollias,
   Stefanos/ACY-7285-2022; Karpouzis, Kostas/AAQ-8018-2020; MOCCOZET,
   Laurent/H-6472-2019; Thalmann, Daniel/A-4347-2008; Thalmann,
   Daniel/AAL-1097-2020
OI Thalmann, Nadia/0000-0002-1459-5960; Karpouzis,
   Kostas/0000-0002-4615-6751; MOCCOZET, Laurent/0000-0003-0333-1932;
   Thalmann, Daniel/0000-0002-0451-7491; Kollias,
   Stefanos/0000-0003-2899-0598
CR [Anonymous], 2002, JTC1SC29WG11 ISOIEC, pN4668
   Balci K, 2005, LECT NOTES COMPUT SC, V3638, P263
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   GRUBER TR, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P601
   Gutierrez M., 2005, P WORKSH SEM VIRT EN, P57
   Raouzaiou A, 2002, EURASIP J APPL SIG P, V2002, P1021, DOI 10.1155/S1110865702206149
   RAOUZAIOU A, 2005, INT WORKSH VLBV05 15
   Tekalp AM, 2000, SIGNAL PROCESS-IMAGE, V15, P387, DOI 10.1016/S0923-5965(99)00055-7
   Whissel C.M., 1989, Emotion: Theory, research and experience: Vol.4, V4
   Zaharia T, 2001, PROC SPIE, V4304, P133, DOI 10.1117/12.424969
   ZAHARIA T, 1999, JTC1SC29WG11 ISOIEC
NR 13
TC 17
Z9 18
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 259
EP 269
DI 10.1002/cav.130
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400013
OA Green Published
DA 2024-07-18
ER

PT J
AU Zhang, HS
   Hua, W
   Wang, Q
   Bao, HJ
AF Zhang, HS
   Hua, W
   Wang, Q
   Bao, HJ
TI Fast display of large-scale forest with fidelity
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE LOD; layered depth image (LDI); depth mosaic (DM); interactive rendering
ID TREES
AB We propose a new hierarchical representation for a forest model, namely hierarchical layered depth mosaics (HLDM). Each node in the HLDM comprises a number of discrete textured quadrilaterals, called depth mosaics (DMs). The DMs are generated from the sampled depth images of the polygonal tree models. Meanwhile, their textures are compressed by a new approach accounting for occlusion. Our rendering procedure traverses the HLDM and renders the appropriate nodes according to a view-dependent selection criterion. A blending scheme is adopted to mitigate the visual 'popping' caused by the transition of levels of detail. Vie experiment demonstrates that the viewer could interactively walk or fly above the forest with fidelity. Copyright (C) 2006 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD & CG, Coll Comp, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhejiang Univ, State Key Lab CAD & CG, Coll Comp, Hangzhou 310027, Peoples R China.
EM bao@cad.zju.edu.cn
CR Andújar C, 2000, COMPUT GRAPH FORUM, V19, pC499, DOI 10.1111/1467-8659.00442
   Chen YY, 2003, J VISUAL COMP ANIMAT, V14, P21, DOI 10.1002/vis.301
   Dachsbacher C, 2003, ACM T GRAPHIC, V22, P657, DOI 10.1145/882262.882321
   Decaudin P., 2004, EUR S REND, P93, DOI DOI 10.2312/EGWR/EGSR04/093-102
   Décoret X, 2003, ACM T GRAPHIC, V22, P689, DOI 10.1145/882262.882326
   DECORET X, 1999, COMPUT GRAPH FORUM, V18, P61
   DEUSSEN O, 1998, P SIGGRAPH 98, P275, DOI DOI 10.1145/280814.280898
   JAKULIN A, 2000, EUR 200 INT SWITZ
   Kraus Martin., 2002, Proceedings of the ACM SIGGRAPH/EUROGRAPHICS Conference on Graphics Hardware, HWWS '02, P7
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Max N., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P165
   MAX N., 1995, 6th Eurographics Workshop on Rendering, P45
   MAX N, 1999, EUR WORKSH REND, P57
   Meyer A, 2001, SPRING EUROGRAP, P183
   MEYER A, 1998, EUR REND WORKSH 1998, P157
   Neyret F, 1996, EUR REND WORKSH, P215
   Popescu V, 1998, VISUALIZATION '98, PROCEEDINGS, P211, DOI 10.1109/VISUAL.1998.745305
   Qin XY, 2003, COMPUT GRAPH FORUM, V22, P243, DOI 10.1111/1467-8659.00671
   Reche A, 2004, ACM T GRAPHIC, V23, P720, DOI 10.1145/1015706.1015785
   Remolar I, 2004, LECT NOTES COMPUT SC, V3039, P173
   REMOLAR I, 2002, EUROGRAPHICS SHORT P, P397
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   SHADE J, 1996, P SIGGRAPH 96, P75
   Stamminger M, 2001, SPRING EUROGRAP, P151
   Wand M, 2001, COMP GRAPH, P361, DOI 10.1145/383259.383299
   Weber J., 1995, Proceedings of the 22Nd Annual Conference on Computer Graphics and Interactive Techniques, P119, DOI DOI 10.1145/218380.218427
   Yamazaki S., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P169
NR 28
TC 2
Z9 3
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2006
VL 17
IS 2
BP 83
EP 97
DI 10.1002/cav.69
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040JO
UT WOS:000237375000002
DA 2024-07-18
ER

PT J
AU Ashdown, M
   Robinson, P
AF Ashdown, M
   Robinson, P
TI Remote collaboration on desk-sized displays
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE remote collaboration; large display; task space; person space
AB Work on remote collaboration has often focused on the person space created by a conventional videoconference where the participants see each other's faces, but we argue that a task space containing shared visual information is more important for most tasks. Trends in display technology mean that large visual task spaces can be created to maximize the shared context between collaborators. We have created a system called the Escritoire that presents users with a desk-sized projected display with bimanual input that allows documents and images to be arranged and modified by multiple remote collaborators. We describe the software architecture, the protocol that is used between the client and server programs, and the pen traces we have added to allow participants to gesture to each other in the large visual space to enrich their communication. Our user trials have shown that participants were able to use the system with a minimum of training, and found the traces useful in the collaborative setting. In future we will be connecting three or more sites together to explore the issues that arise with multi-party interaction on large shared desks. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Univ Cambridge, Comp Lab, Cambridge CB3 0FD, England.
C3 University of Cambridge
RP Univ Cambridge, Comp Lab, 15 JJ Thomson Ave, Cambridge CB3 0FD, England.
EM mark@ashdown.name
CR [Anonymous], P 14 ANN ACM S US IN
   [Anonymous], 2002, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/503376.503413
   ASHDOWN M, 2003, IEEE INT WORKSH PROJ
   ASHDOWN M, 2003, 1 RES WORKSH AUGM VI
   BAUDISCH P, 2003, P 9 IFIP INT C HUM C
   Baudisch Patrick., 2001, 14 ANN ACM S USER IN, P31, DOI DOI 10.1145/502348.502354
   Bly SaraA., 1988, P ACM C COMPUTER SUP, P250
   Buxton W. A. S., 1992, Proceedings. Graphics Interface '92, P123
   Czerwinski M., 2003, P INT, V3, P9
   Egido C., 1988, COMPUT SUPP COOP W J, P13, DOI DOI 10.1145/62266.62268
   Elrod S., 1992, PROC CHI 1992, P599
   Everitt K.M., 2003, PROC CHI 2003, P553
   Grudin J., 2001, P CHI 01 C HUMAN FAC, P458
   Gutwin C, 2002, PROC GRAPH INTERF, P43
   Gutwin C., 2002, Proc. of CSCW, P49
   HAYNE S, 1993, GROUPWARE REAL TIME, P63
   Kraut R.E., 2002, P 2002 ACM C COMPUTE, P31
   KRUEGER MW, 1993, COMMUN ACM, V36, P36, DOI 10.1145/159544.159563
   Mander Richard., 1992, P ACM C HUMAN FACTOR, P627
   REGAN T, 2003, MSRTR200313
   TAN D, 2003, CHI 2003 WORKSH PROV
   TANG JC, 1988, P CSCW 88, P244
   Trimintzios P, 2001, IEEE COMMUN MAG, V39, P80, DOI 10.1109/35.920861
   Wellner P., 1993, COMMUN ACM, V36, P87
   WOLF CG, 1993, C COMP INTERCHI 93, P137
   [No title captured]
   [No title captured]
NR 27
TC 3
Z9 4
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2005
VL 16
IS 1
BP 41
EP 51
DI 10.1002/cav.55
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 912IF
UT WOS:000228070300005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fukusato, T
   Shibata, R
   Noh, ST
   Igarashi, T
AF Fukusato, Tsukasa
   Shibata, Ryohei
   Noh, Seung-Tak
   Igarashi, Takeo
TI Interactive texture editing for garment line drawings
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE garment line drawings; interactive editing; texture mapping
ID DESIGN
AB Adding two-dimensional (2D) textures to garment line drawings (e.g., cartoon characters) remains challenging in the production pipeline of comics and illustrations since garment line drawings often have self-occluded wrinkles. Although several techniques that can automatically deform and map 2D texture patterns to 2D line drawings have been proposed, their qualities are insufficient for representing 3D-like realistic garment designs and manual editing of UV coordinates, which is labor-intensive. In this article, we introduce an interactive tool to efficiently edit UV coordinates of 2D garment line drawings on the modeling panel with curve and point handles. Our algorithm is simple to integrate into existing image authoring tools. We conduct a user study with novice users and confirm that the proposed tool can effectively handle texture mapping envisioned by the users.
C1 [Fukusato, Tsukasa; Shibata, Ryohei; Igarashi, Takeo] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138656, Japan.
   [Noh, Seung-Tak] Tokyo Univ Technol, Sch Media Sci, Tokyo, Japan.
C3 University of Tokyo; Tokyo University of Technology
RP Fukusato, T (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138656, Japan.
EM tsukasafukusato@is.s.u-tokyo.ac.jp
RI Igarashi, Takeo/ITT-5921-2023
OI Noh, Seung-Tak/0000-0002-7823-0864; Fukusato,
   Tsukasa/0000-0002-5090-1443
FU JSPS KAKENHI [JP19K20316]
FX This work was supported by JSPS KAKENHI Grant Number JP19K20316.
CR Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7
   Chen RJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130843
   Correa W. T., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P435, DOI 10.1145/280814.280949
   Crane K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516977
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Fang H, 2004, ACM T GRAPHIC, V23, P354, DOI 10.1145/1015706.1015728
   Gingold YotamI., 2008, UIST 2006: Proceedings of the 19th Annual ACM Symposium on User Interface Software and Technology, P23, DOI DOI 10.1145/1166253.1166259
   Hashimoto Miyu, 2020, SA '20: SIGGRAPH Asia 2020, DOI 10.1145/3410700.3425428
   He S., 2022, P IEEECVF C COMPUTER, P3470
   Hudon M, 2019, LECT NOTES COMPUT SC, V11131, P246, DOI 10.1007/978-3-030-11015-4_20
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Igarashi Y, 2009, COMPUT GRAPH FORUM, V28, P1965, DOI 10.1111/j.1467-8659.2009.01575.x
   Kraevoy V, 2003, ACM T GRAPHIC, V22, P326, DOI 10.1145/882262.882271
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Lévy B, 2001, COMP GRAPH, P417, DOI 10.1145/383259.383308
   Lewis KM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459884
   Liu YX, 2004, ACM T GRAPHIC, V23, P368, DOI 10.1145/1015706.1015731
   Ma YW, 2015, IEEE T VIS COMPUT GR, V21, P375, DOI 10.1109/TVCG.2014.2366101
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Noh ST, 2021, PROCEEDINGS OF SIGGRAPH ASIA 2021 TECHNICAL COMMUNICATIONS, DOI 10.1145/3478512.3488614
   Orzan A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360691
   ROUY E, 1992, SIAM J NUMER ANAL, V29, P867, DOI 10.1137/0729053
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Schüller C, 2013, COMPUT GRAPH FORUM, V32, P125, DOI 10.1111/cgf.12179
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Seo H, 2010, COMPUT GRAPH FORUM, V29, P160, DOI 10.1111/j.1467-8659.2009.01584.x
   Sheffer A, 2005, ACM T GRAPHIC, V24, P311, DOI 10.1145/1061347.1061354
   Songsathaporn K., 2011, P 27 SPRING C COMPUT, P43, DOI [10.1145/2461217.2461227, DOI 10.1145/2461217.2461227]
   Sorkine O, 2007, S GEOM PROC, V4, P109, DOI [10.1145/1073204.1073323, DOI 10.1145/1073204.1073323]
   Su WC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203186
   Sykora D., 2011, Proceedings of International Symposium on Non-Photorealistic Animation and Rendering, P75
   Tu PH, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417780
   Winnemöller H, 2009, COMPUT GRAPH FORUM, V28, P1091, DOI 10.1111/j.1467-8659.2009.01486.x
   Wolff K., 2019, 24 INT S VISION MODE, P11, DOI [10.2312/vmv.20191313, DOI 10.2312/VMV.20191313]
   Wolff K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322991
   Yan ZP, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073692
NR 36
TC 0
Z9 0
U1 2
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2022
VL 33
IS 6
AR e2117
DI 10.1002/cav.2117
EA AUG 2022
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6Z9LE
UT WOS:000843752100001
DA 2024-07-18
ER

PT J
AU Chambe, M
   Cozot, R
   Le Meur, O
AF Chambe, Mathieu
   Cozot, Remi
   Le Meur, Olivier
TI Deep learning for assessing the aesthetics of professional photographs
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE aesthetics assessment; deep learning; over-fitting; professional
   photography
ID IMAGE QUALITY ASSESSMENT
AB Aesthetic quality assessment for photographs is an important research topic since it can be used for a number of applications, such as image database management or image browsing. In 2012, the aesthetic visual analysis (AVA) dataset has been proposed. It has since then been used to train the majority of computational models of aesthetics assessment. We observe that AVA is mainly composed of competitive photographs which notion of aesthetics differs from other kinds of photographs, such as professional photographs. In this paper, we evaluate whether or not recent aesthetics assessment models generalize well and perform well over professional photographs. We noticed that the different models we tested behave differently on both categories, and therefore do not generalize well. Besides, we fine-tuned one of the tested model using professional photographs and the results show that this fine-tuning is effectively improving the coverage of the methods.
C1 [Chambe, Mathieu; Le Meur, Olivier] Univ Rennes, CNRS, IRISA, Rennes, France.
   [Cozot, Remi] Univ Littoral Cote dOpale, LISIC, Dunkerque, France.
C3 Universite de Rennes; Centre National de la Recherche Scientifique
   (CNRS); Universite du Littoral-Cote-d'Opale
RP Chambe, M (corresponding author), Univ Rennes, CNRS, IRISA, Rennes, France.
EM mathieu.chambe@irisa.fr
OI Chambe, Mathieu/0000-0002-7524-120X
CR Carballal A, 2019, COMPLEXITY, DOI 10.1155/2019/4659809
   Chen YL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P37, DOI 10.1145/3123266.3123274
   Deng YB, 2017, IEEE SIGNAL PROC MAG, V34, P80, DOI 10.1109/MSP.2017.2696576
   Florea C., 2021, P 2021 13 INT C ELEC, P1
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jin B, 2016, IEEE IMAGE PROC, P2291, DOI 10.1109/ICIP.2016.7532767
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40
   Manovich Lev., 2018, Exploring the Selfie: Historical, Theoretical, and Analytical Approaches to Digital Self-Photography, P167, DOI [10.1007/978-3-319-57949-8_8, DOI 10.1007/978-3-319-57949-8_8]
   MURRAY N, 2012, PROC CVPR IEEE, P2408, DOI DOI 10.1109/CVPR.2012.6247954
   Ren J, 2017, IEEE I CONF COMP VIS, P638, DOI 10.1109/ICCV.2017.76
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Reddy GV, 2020, IET IMAGE PROCESS, V14, P1561, DOI 10.1049/iet-ipr.2019.1300
   Wang WS, 2019, IET COMPUT VIS, V13, P749, DOI 10.1049/iet-cvi.2019.0361
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang ZH, 2022, IEEE T PATTERN ANAL, V44, P4577, DOI 10.1109/TPAMI.2021.3071759
   Wang Z, 2011, IEEE SIGNAL PROC MAG, V28, P137, DOI 10.1109/MSP.2011.942295
   Wang ZY, 2016, PR MACH LEARN RES, V48
   Wen L, 2019, INT C COMP SUPP COOP, P205, DOI [10.1109/cscwd.2019.8791884, 10.1109/CSCWD.2019.8791884]
   Zhang WX, 2023, IEEE T PATTERN ANAL, V45, P2864, DOI 10.1109/TPAMI.2022.3178874
   Zhang WX, 2021, IEEE T IMAGE PROCESS, V30, P3474, DOI 10.1109/TIP.2021.3061932
   Zhu H., 2020, P IEEE CVF C COMP VI, P14143
   Zhu HC, 2022, PATTERN RECOGN LETT, V155, P84, DOI 10.1016/j.patrec.2022.02.008
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 26
TC 1
Z9 1
U1 3
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2022
VL 33
IS 6
AR e2105
DI 10.1002/cav.2105
EA JUL 2022
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6Z9LE
UT WOS:000833976800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Yu, ZX
   Yang, G
   Xu, ZH
AF Yu, Zhaoxi
   Yang, Gang
   Xu, Zihui
TI Realistic simulation of hydraulic erosion on slope
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer graphics; hydraulic erosion; realistic simulation; slope
AB Hydraulic erosion plays an important role in the formation of landform. Influenced by runoff, soil is destroyed, denuded, and transported to form a specific landform. The simulation of erosion can not only be used for the construction of realistic terrain, but also for evaluation in soil and water conservation, which has important research and application value. We construct a hydraulic erosion simulation framework on the basis of soil and water conservation's theory, which considers various factors in erosion, including: water flow, infiltration, transportation, erosion, ditch widening, deposition, and soil sliding. It is the first time to consider the generation time of runoff, soil fixation of plant roots, and ditch widening phenomenon in simulation. Using this method, we can simulate ditch evolution process from rill, shallow ditch, cut ditch to gully, which consist with the real process. Compared with real photos and data, our method has authenticity in both visual and theoretical aspects.
C1 [Yu, Zhaoxi; Yang, Gang; Xu, Zihui] Beijing Forestry Univ, Sch Informat Sci & Technol, 35 Qinghua East Rd, Beijing, Peoples R China.
   [Yu, Zhaoxi; Yang, Gang; Xu, Zihui] Engn Res Ctr Forestry Oriented Intelligent Inform, Beijing, Peoples R China.
C3 Beijing Forestry University
RP Yang, G (corresponding author), Beijing Forestry Univ, Sch Informat Sci & Technol, 35 Qinghua East Rd, Beijing, Peoples R China.
EM yanggang@bjfu.edu.cn
OI Yu, Zhaoxi/0000-0002-3219-428X
FU Project of National Key R&D Program of China [2017YFC0504404]
FX This work is supported by the Project of National Key R&D Program of
   China (No. 2017YFC0504404).
CR Anh NH, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P257
   [Anonymous], 1979, AGR DICT AGR DICT
   Benes B, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P79
   Beyer H.T., 2015, Implementation of a method for hydraulic erosion
   Chiba N, 1998, J VISUAL COMP ANIMAT, V9, P185, DOI 10.1002/(SICI)1099-1778(1998100)9:4<185::AID-VIS178>3.0.CO;2-2
   Cordonnier G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073667
   Jianping Y., 1999, J MT SCI-ENGL, V03, P259
   Jinduo L., 2012, TEST SLOPE EROSION P
   Kristof P, 2009, COMPUT GRAPH FORUM, V28, P219, DOI 10.1111/j.1467-8659.2009.01361.x
   Musgrave F. K., 1989, Computer Graphics, V23, P41, DOI 10.1145/74334.74337
   Partheniades E., 1965, J Hydraul Eng Div ASCE, V91, P105139
   Wojtan Christopher., 2007, Eurographics Workshop on Natural Phenomena, P15, DOI DOI 10.2312/NPH/NPH07/015-022
   Xianmo, 1960, ACTA PEDOL SIN, V8, P110
   Yonghong Y., 2007, RES SOIL WATER CONSE, V14, P290
   Yunpeng L., 2021, SOIL WATER CONSERV C, V1, P6
   Zhijun J., 1987, SOIL WATER CONSERV C, V8, P27
NR 16
TC 0
Z9 0
U1 2
U2 28
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2080
DI 10.1002/cav.2080
EA MAY 2022
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000803712800001
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Chen, ZH
   Sheng, B
   Li, P
   Kim, J
   Wu, EH
AF Zhou, Yu
   Chen, Zhihua
   Sheng, Bin
   Li, Ping
   Kim, Jinman
   Wu, Enhua
TI AFF-Dehazing: Attention-based feature fusion network for low-light image
   Dehazing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE attention mechanism; image dehazing; low-light enhancement
ID RETINEX
AB Images captured in haze conditions, especially at nighttime with low light, often suffer from degraded visibility, contrasts, and vividness, which makes it difficult to carry out the following vision tasks. In this article, we propose an attention-based feature fusion network (AFF-Dehazing) for low-light image dehazing. Our method decomposes the low-light image dehazing into two task-independent streams containing four modules: image dehazing module, low-light feature extractor module, feature fusion module, and image restoration module. The basic block of these modules is the proposed attention-based residual dense block. Since the dual-branch are used, AFF-Dehazing can avoid learning the mixed degradation all-in-one and enhance the details of low-light haze images. Extensive experiments show that our method surpasses previous state-of-the-art image dehazing methods and low-light enhancement methods by a very large margin both quantitatively and qualitatively.
C1 [Zhou, Yu; Chen, Zhihua] East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
   [Kim, Jinman] Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Wu, Enhua] Univ Macau, Fac Sci & Technol, Macau, Peoples R China.
C3 East China University of Science & Technology; Shanghai Jiao Tong
   University; Hong Kong Polytechnic University; University of Sydney;
   Chinese Academy of Sciences; Institute of Software, CAS; University of
   Macau
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.; Wu, EH (corresponding author), Chinese Acad Sci, State Key Lab Comp Sci, Beijing, Peoples R China.
EM shengbin@sjtu.edu.cn; ehwu@um.edu.mo
RI Kim, Jin Man/HJO-8987-2023; Li, Ping/AAO-2019-2020; Kim,
   Jin/AAS-5810-2021
OI Li, Ping/0000-0002-1503-0240; Kim, Jin/0000-0002-7667-9588; Sheng,
   Bin/0000-0001-8678-2784
FU Hong Kong Polytechnic University [P0030419, P0030929, P0035358];
   National Natural Science Foundation of China [61572316, 61632003,
   61672228, 61872241, 61902126, 62072449]
FX Hong Kong Polytechnic University, Grant/Award Numbers: P0030419,
   P0030929, P0035358; National Natural Science Foundation of China,
   Grant/Award Numbers: 61572316, 61632003, 61672228, 61872241, 61902126,
   62072449
CR Ancuti C, 2020, IEEE T IMAGE PROCESS, V29, P6264, DOI 10.1109/TIP.2020.2988203
   Berman D, 2020, IEEE T PATTERN ANAL, V42, P720, DOI 10.1109/TPAMI.2018.2882478
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Tang QF, 2021, COMPUT VIS IMAGE UND, V202, DOI 10.1016/j.cviu.2020.103086
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang MM, 2018, IEEE T MULTIMEDIA, V20, P3008, DOI 10.1109/TMM.2018.2820327
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P2072, DOI 10.1109/TIP.2021.3050850
   Zha ZJ., 2020, P2355
   Zhang J, 2017, PROC CVPR IEEE, P7016, DOI 10.1109/CVPR.2017.742
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 23
TC 10
Z9 11
U1 17
U2 82
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2011
DI 10.1002/cav.2011
EA MAY 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000653157800001
DA 2024-07-18
ER

PT J
AU Krogmeier, C
   Mousas, C
AF Krogmeier, Claudia
   Mousas, Christos
TI Eye fixations and electrodermal activity during low-budget virtual
   reality embodiment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE body ownership; electrodermal activity; embodiment; eye fixations;
   low-budget; mirror; self-avatar; virtual reality
ID SOCIAL COMMUNICATION; BODY OWNERSHIP; GAZE
AB As motion-sensing devices become more accessible to consumers, it is important to understand how users experience embodiment when using these devices. In our 3x2 between-groups study, we explored eye fixations and electrodermal activity (EDA) in order to more objectively understand potential interaction effects between the self-avatar body, and the presence of a mirror within the context of low-budget embodiment. We developed six experimental conditions concerningBody(human, mannequin, and zombie self-avatars) andMirror(mirror and no mirror) factors, and presented participants with a virtual environment in which they could control their self-avatars by using HTC Vive controllers and trackers. In addition to eye fixations and EDA, we assessed self-reported data concerning body ownership, agency, self-location, as well as enjoyment of the experience. Our results suggest that theBodymay have been more influential in eliciting body ownership than theMirror, and that an interaction effect betweenGenderandBodymay influence eye gaze behavior. Additionally, female participants reported significantly higher agency than males. We consider logical next steps for similar research which might elaborate upon our findings.
C1 [Krogmeier, Claudia; Mousas, Christos] Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Mousas, C (corresponding author), Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
EM cmousas@purdue.edu
RI Mousas, Christos/AGV-3533-2022
OI Mousas, Christos/0000-0003-0955-7959
CR Arzy S, 2006, J NEUROSCI, V26, P8074, DOI 10.1523/JNEUROSCI.0745-06.2006
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bekele E, 2013, IEEE T VIS COMPUT GR, V19, P711, DOI 10.1109/TVCG.2013.42
   Bergström I, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148060
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Choi SH, 2010, J NERV MENT DIS, V198, P829, DOI 10.1097/NMD.0b013e3181f97c0d
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Hägni K, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003082
   Ito R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343139
   Jo D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141214
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim H, 2018, AUST NZ J PSYCHIAT, V52, P279, DOI 10.1177/0004867417714335
   Kim HK, 2016, COMPUT HUM BEHAV, V62, P186, DOI 10.1016/j.chb.2016.03.092
   KROGMEIER C, 2019, COMPUT ANIMAT VIRT W, V30, P3
   Lahiri U, 2015, J AUTISM DEV DISORD, V45, P919, DOI 10.1007/s10803-014-2240-5
   Latoschik ME, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P73, DOI 10.1145/2993369.2993399
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI [DOI 10.1145/2931002.2931006, 10.1145/2931002.2931006]
   LIN Q., 2013, P ACM S APPL PERCEPT, P107
   Lopez C, 2008, NEUROPHYSIOL CLIN, V38, P149, DOI 10.1016/j.neucli.2007.12.006
   Lopez S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300787
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   Marschner L, 2015, INT J PSYCHOPHYSIOL, V97, P85, DOI 10.1016/j.ijpsycho.2015.05.007
   Mousas C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P626, DOI [10.1109/VR46266.2020.00-19, 10.1109/VR46266.2020.1581211592060]
   Newport R, 2010, EXP BRAIN RES, V204, P385, DOI 10.1007/s00221-009-2104-y
   Norrholm SD, 2016, BEHAV RES THER, V82, P28, DOI 10.1016/j.brat.2016.05.002
   Presti C, 2015, SOCIEDADE BRASILEIRA, P1
   Schrammel F, 2009, PSYCHOPHYSIOLOGY, V46, P922, DOI 10.1111/j.1469-8986.2009.00831.x
   Schulze S, 2019, LECT NOTES COMPUT SC, V11574, P361, DOI 10.1007/978-3-030-21607-8_28
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Stevens M, 2000, PERCEPT MOTOR SKILL, V90, P601, DOI 10.2466/PMS.90.2.601-604
   Tajadura-Jiménez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09497-3
   Tieri G, 2015, SCI REP-UK, V5, DOI 10.1038/srep17139
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wilson G, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005510
   Yee Nick, 2006, P PRESENCE, V24, P26
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
NR 37
TC 7
Z9 8
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1941
DI 10.1002/cav.1941
EA SEP 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA OG1RS
UT WOS:000565425600001
DA 2024-07-18
ER

PT J
AU Wu, LY
   Wan, WG
   Yu, XQ
   Ye, CK
   Muzahid, AAM
AF Wu, Lianyao
   Wan, Wanggen
   Yu, Xiaoqing
   Ye, Chunkai
   Muzahid, A. A. M.
TI A novel augmented reality framework based on monocular semi-dense
   simultaneous localization and mapping
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE AR; monocular SLAM; semi-dense mapping; surface reconstruction
ID SLAM
AB Markerless tracking has been a trend in augmented reality (AR) applications nowadays, but it no longer satisfies users who want virtual characters to interact with the real world such as collision. Some sparse or dense simultaneous localization and mapping (SLAM) methods are proposed aiming to solve this problem. However, sparse methods only extract a plane from the sparse map, which cannot allow virtual characters to move realistically. Meanwhile, dense methods usually require powerful graphics processing unit (GPU) for dense mapping. In this paper, we present a real-time AR framework based on a semi-dense method with central processing unit (CPU). Specifically, the semi-dense method searches pixels with high gradients in each keyframe and estimates accurate depths by fusing matching pixels in other keyframes. We propose an outlier removal method that excludes three-dimensional points outside the camera trajectory. By integrating this method, our framework preserves clean edges of the real environment. The experimental results on the dataset show that our proposed framework has better surface reconstruction accuracy than other methods and our tracking thread runs in an acceptable speed when the semi-dense mapping thread runs backend. With the benefit of the robust camera tracking and the aligned surface, virtual characters of our AR application enable realistic movement and collision.
C1 [Wu, Lianyao; Wan, Wanggen; Yu, Xiaoqing; Ye, Chunkai; Muzahid, A. A. M.] Shanghai Univ, Sch Commun & Informat Engn, 99 Shangda Rd, Shanghai 200444, Peoples R China.
   [Wu, Lianyao; Wan, Wanggen; Yu, Xiaoqing; Ye, Chunkai; Muzahid, A. A. M.] Shanghai Univ, Inst Smart City, Shanghai, Peoples R China.
C3 Shanghai University; Shanghai University
RP Wu, LY (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, 99 Shangda Rd, Shanghai 200444, Peoples R China.
EM hi501@189.cn
RI Yu, Xiaoqing/E-2388-2013; Muzahid, A. A. M./ABE-6836-2021
OI Muzahid, A. A. M./0000-0003-2001-1922; Wu, Lianyao/0000-0003-2432-1995
FU project of Shanghai Science and Technology Committee [18510760300]
FX This paper is partially supported by the project of Shanghai Science and
   Technology Committee No.18510760300.
CR [Anonymous], 2007, Proc. CVWW '07
   [Anonymous], 2013, ITE TRANS MEDIA TECH, DOI DOI 10.3169/MTA.1.343
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Chen L, 2018, COMPUT METH PROG BIO, V158, P135, DOI 10.1016/j.cmpb.2018.02.006
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Fiala M, 2005, PROC CVPR IEEE, P590
   Gao X, 2018, IEEE INT C INT ROBOT, P2198, DOI 10.1109/IROS.2018.8593376
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Kawai N, 2017, IEEE T VIS COMPUT GR, V23, P2288, DOI 10.1109/TVCG.2016.2617325
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Klasing K, 2009, IEEE INT CONF ROBOT, P2011
   Klein George, 2007, P1
   Koch C, 2014, AUTOMAT CONSTR, V48, P18, DOI 10.1016/j.autcon.2014.08.009
   Korkalo O., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P247, DOI 10.1109/ISMAR.2010.5643590
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mur-Artal R, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schöps T, 2014, INT SYM MIX AUGMENT, P145, DOI 10.1109/ISMAR.2014.6948420
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Totz J, 2011, LECT NOTES COMPUT SC, V6891, P89, DOI 10.1007/978-3-642-23623-5_12
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
NR 30
TC 1
Z9 1
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2020
VL 31
IS 3
AR e1922
DI 10.1002/cav.1922
EA MAR 2020
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LY8SD
UT WOS:000517121300001
DA 2024-07-18
ER

PT J
AU Nunnari, F
   Heloir, A
AF Nunnari, Fabrizio
   Heloir, Alexis
TI Yet another low-level agent handler
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE agent framework; character creation pipeline; virtual human
AB YALLAH is a framework for the creation of real-time interactive virtual humans. Its production pipeline supports the continuous, parallel development of both the character and the software, and allows users for the deployment of a new character in a few hours of work. YALLAH is based on freely available software, mostly open-source, and its modular software architecture provides a framework for the seamless integration of new features. Finally, thanks to transpilation, the whole framework is conceived to accommodate multiple game engines.
C1 [Nunnari, Fabrizio] German Res Ctr Artificial Intelligence DFKI, Saarbrucken, Germany.
   [Heloir, Alexis] Univ Valenciennes, CNRS, UMR 8201, LAMIH, Le Mt Houy, France.
C3 German Research Center for Artificial Intelligence (DFKI); Centre
   National de la Recherche Scientifique (CNRS); Universite Polytechnique
   Hauts-de-France
RP Nunnari, F (corresponding author), German Res Ctr Artificial Intelligence DFKI, Saarbrucken, Germany.
EM fabrizio.nunnari@dfki.de
OI Nunnari, Fabrizio/0000-0002-1596-4043
FU Federal Ministry of Education and Research (BMBF) [16SV7768]
FX Federal Ministry of Education and Research (BMBF), Grant/Award Number:
   16SV7768, Intera-KT project
CR Cannasse N, 2008, ESSENTIAL GUIDE OPEN, P227
   Courgeon M, 2011, LECT NOTES ARTIFICIA
   De Paolis L.T., 2019, Augmented reality, virtual reality, and computer graphics: 6th International Conference, AVR 2019, Santa Maria al Bagno, Italy, June 24-27
   Gamma E., 1994, Design patterns: Elements of reusable object-oriented software
   Gris I, 2018, P 17 INT C AUT AG MU
   Hartholt Arno., 2013, Intelligent Virtual Agents
   Johnston PR, 2013, CLIN OPHTHALMOL, V7, P253, DOI 10.2147/OPTH.S39104
   Kopp S., 2006, Intelligent Virtual Agents
   LeMaguer S, 2017, 28 C EL SPEECH SIGN, P152
   Mancini M, 2007, INTELLIGENT VIRTUAL
   Mancini M, 2008, TROIS WORKSH AG CONV
   Mitsutake T, 2015, J PHYS THER SCI, V27, P2817, DOI 10.1589/jpts.27.2817
   Nunnari F, 2018, AUGMENTED REALITY VI
   Nunnari F, 2017, INTELLIGENT VIRTUAL
   Prange A, 2019, P 27 C US MO AD PERS
   Riviere J, 2011, INTELLIGENT VIRTUAL
   Sonntag D, 2018, INTERACTIVE COGNITIV
   Staudte M, 2014, COGNITION, V133, P317, DOI 10.1016/j.cognition.2014.06.003
   Thiebaux M, 2008, P 7 INT JOINT C AUT
   vanWelbergen H, 2012, INTELLIGENT VIRTUAL
NR 20
TC 5
Z9 5
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1891
DI 10.1002/cav.1891
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400014
DA 2024-07-18
ER

PT J
AU Zhao, MD
   Hao, XY
AF Zhao, Mandan
   Hao, Xiangyang
TI A novel refocusing distance measurement method using super-resolved
   light field images
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE depth information; focus ranging; light-field refocus; 3D measurement
ID CAMERA
AB This paper proposes a novel distance measurement method using superresolved light-field images. We first superresolve the light field using the hybrid cross-resolution input based on PatchMatch and convolutional neural network method, which combines and takes advantage of these two methods. In this way, we can explore the similarity between images and deal with challenging scenes effectively. The scaling factor is up to eight times, which is much larger than the ordinary superresolution scaling factor, and our superresolution method can also maintain a satisfactory accuracy. With the traditional idea of focus ranging, the light-field 3D measurement method is established. A proper definition evaluation function suitable for light-field data is selected to evaluate the imaging quality, and the triangle barycenter interpolation method is proposed to measure 3D scenes. Experimental results demonstrate that the proposed method not only improves the quality of the reconstructed high-resolution light field but also has the ability of the distance measurement. It indicates that the light-field imaging is a promising 3D measurement technique.
C1 [Zhao, Mandan] Zhengzhou Inst Surveying & Mapping, 62 Kexue Ave, Zhengzhou 450001, Henan, Peoples R China.
   [Hao, Xiangyang] Zhengzhou Inst Surveying & Mapping, Dept Photogrammetry & Remote Sensing, 62 Kexue Ave, Zhengzhou 450001, Henan, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Zhao, MD (corresponding author), Zhengzhou Inst Surveying & Mapping, 62 Kexue Ave, Zhengzhou 450001, Henan, Peoples R China.
EM mandanzhao@163.com
OI Zhao, Mandan/0000-0002-8719-3452
FU National key foundation for exploring scientific instrument
   [2013YQ140517]; NSF of China [61522111, 61531014]
FX National key foundation for exploring scientific instrument, Grant/Award
   Number: 2013YQ140517; NSF of China, Grant/Award Number: 61522111 and
   61531014
CR [Anonymous], COMPUT VIS MED
   [Anonymous], 2015, FOREIGN ELECT MEASUR
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], 2009, IEEE INT C COMP PHOT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], BMVC 2012 P BRIT MAC
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], 2009, TECHNICAL REPORT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], NEW STANDFORD LIGHT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], EUR C COMP VIS SEPT
   [Anonymous], SCI CHINA INFORM SCI
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 3D LIGHT FIELD CAMER
   Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168
   BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Cho D, 2013, IEEE I CONF COMP VIS, P3280, DOI 10.1109/ICCV.2013.407
   Cho S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185560
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Ihrke I, 2016, IEEE SIGNAL PROC MAG, V33, P59, DOI 10.1109/MSP.2016.2582220
   Kauvar I, 2015, ACM T GRAPHIC, V34, DOI [10.1145/2682631, 10.1145/2816795.2818070]
   Kim J, 2016, IEEE CONF COMPUT
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Levoy M, 2006, ACM T GRAPHIC, V25, P924, DOI 10.1145/1141911.1141976
   Lin X, 2015, BIOMED OPT EXPRESS, V6, P3179, DOI 10.1364/BOE.6.003179
   Liu JQ, 2017, IEEE ICC
   Marwah K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461914
   Roberts WA, 2017, AIAA J, V55, P435, DOI 10.2514/1.J055050
   Sardemann H, 2016, ISPRS J PHOTOGRAMM, V114, P1, DOI 10.1016/j.isprsjprs.2016.01.012
   Stentoumis C, 2014, ISPRS J PHOTOGRAMM, V91, P29, DOI 10.1016/j.isprsjprs.2014.02.006
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89
   Wang Y, 2016, IEEE T VIS COMPUT GR, V22, P359, DOI 10.1109/TVCG.2015.2467691
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Wetzstein G, 2012, IEEE COMPUT GRAPH, V32, P6, DOI 10.1109/MCG.2012.99
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Xiao Xiang-guo, 2008, Acta Photonica Sinica, V37, P2539
   Zeller N, 2016, ISPRS J PHOTOGRAMM, V118, P83, DOI 10.1016/j.isprsjprs.2016.04.010
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   [郑绍华 Zheng Shaohua], 2013, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V27, P241
NR 50
TC 1
Z9 1
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1828
DI 10.1002/cav.1828
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100019
DA 2024-07-18
ER

PT J
AU Valcik, J
   Sedmidubsky, J
   Zezula, P
AF Valcik, Jakub
   Sedmidubsky, Jan
   Zezula, Pavel
TI Assessing similarity models for human-motion retrieval applications
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human-motion retrieval; similarity model; effectiveness evaluation;
   motion capture data; action recognition
ID CAPTURE; RECOGNITION; WALKING
AB The development of motion capturing devices poses new challenges in the exploitation of human-motion data for various application fields, such as computer animation, visual surveillance, sports, or physical medicine. Recently, a number of approaches dealing with motion data have been proposed, suggesting characteristic motion features to be extracted and compared on the basis of similarity. Unfortunately, almost each approach defines its own set of motion features and comparison methods; thus, it is hard to fairly decide which similarity model is the most suitable for a given kind of human-motion retrieval application. To cope with this problem, we propose the human motion model evaluator, which is a generic framework for assessing candidate similarity models with respect to the purpose of the target application. The application purpose is specified by a user in form of a representative sample of categorized motion data. Respecting such categorization, the similarity models are assessed from the effectiveness and efficiency points of view using a set of space-complexity, information-retrieval, and performance measures. The usability of the framework is demonstrated by case studies of three practical examples of retrieval applications focusing on recognition of actions, detection of similar events, and identification of subjects. Copyright (C) 2015 John Wiley & Sons, Ltd.
C1 [Valcik, Jakub; Sedmidubsky, Jan; Zezula, Pavel] Masaryk Univ, Bot 68a, Brno 60200, Czech Republic.
C3 Masaryk University Brno
RP Sedmidubsky, J (corresponding author), Masaryk Univ, Bot 68a, Brno 60200, Czech Republic.
EM xsedmid@fi.muni.cz
RI Sedmidubsky, Jan/J-3195-2013; Cataldi, Antonio/AAM-7411-2021
OI Sedmidubsky, Jan/0000-0002-7668-8521; 
FU Czech Science Foundation (GACR) [P103/12/G084]
FX This research was supported by the Czech Science Foundation (GACR)
   project No. P103/12/G084.
CR [Anonymous], 2008, ACM INT C MULT INF R, DOI [10.1145/1460096.1460169, DOI 10.1145/1460096.1460169]
   [Anonymous], ACM SIGGRAPH EUR S C
   [Anonymous], 2004, P INT C VERY LARGE D
   [Anonymous], 2013, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'13
   Arikan O, 2006, ACM T GRAPHIC, V25, P890, DOI 10.1145/1141911.1141971
   Baumann J, 2014, 2014 PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS (GRAPP 2014), P325
   Behara A, 2013, INT C EL ENG COMP SC, P65
   Carlsson S., 1996, Object Representation in Computer Vision II. ECCV '96 International Workshop. Proceedings, P53
   Choensawat W, 2012, J ADV COMPUT INTELL, V16, P13, DOI 10.20965/jaciii.2012.p0013
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Fernandez-Baena A, 2012, 4 INT C INT NETW COL, P656
   Fu AWC, 2008, VLDB J, V17, P899, DOI 10.1007/s00778-006-0040-z
   Gong WJ, 2010, LECT NOTES COMPUT SC, V6169, P290, DOI 10.1007/978-3-642-14061-7_28
   Gu JX, 2010, IEEE T SYST MAN CY B, V40, P1021, DOI 10.1109/TSMCB.2010.2043526
   Josinski H, 2012, PRZ ELEKTROTECHNICZN, V88, P201
   Kang J, 2006, 6 INT C ROB CONTR MA, P62
   Kovac J, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/484320
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Kruger B, 2008, JVRB J VIRTUAL REALI, V5, P13
   Lan R, 2015, VISUAL COMPUT, V31, P0178
   Lau M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618517
   Liang Y, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P185, DOI 10.1109/CIS.2014.82
   Lin YC, 2011, J MED BIOL ENG, V31, P255, DOI 10.5405/jmbe.806
   Lustrek Mitja., 2009, INFORMATICA, V33, P205
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Maodi Hu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3679, DOI 10.1109/ICPR.2010.897
   Martin-Felez Raul, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3810, DOI 10.1109/ICPR.2010.928
   Müller M, 2008, LECT NOTES COMPUT SC, V5096, P365, DOI 10.1007/978-3-540-69321-5_37
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Muller M., 2007, TECHNICAL REPORTS U
   Park JP, 2011, COMPUT GRAPH FORUM, V30, P2183, DOI 10.1111/j.1467-8659.2011.01968.x
   Paul R.P., 1982, Robot Manipulators: Mathematics, Programming, and Control, V1st
   Preis J., 2012, 1 INT WORKSH KIN PER
   Qi T, 2013, COMPUT ANIMAT VIRT W, V24, P399, DOI 10.1002/cav.1505
   Reitsma PSA, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289609
   Reitsma PSA, 2003, ACM T GRAPHIC, V22, P537, DOI 10.1145/882262.882304
   Ren Ch., 2011, INT C VIRT REAL VIS, P70
   Ren L, 2005, ACM T GRAPHIC, V24, P1090, DOI 10.1145/1073204.1073316
   Rongyi Lan, 2013, Intelligent Science and Intelligent Data Engineering. Third Sino-foreign-interchange Workshop, IScIDE 2012. Revised Selected Papers, P72, DOI 10.1007/978-3-642-36669-7_10
   Sedmidubsky J, 2013, LECT NOTES COMPUT SC, V8192, P669, DOI 10.1007/978-3-319-02895-8_60
   Sedmidubsky J, 2013, LECT NOTES COMPUT SC, V8199, P325, DOI 10.1007/978-3-642-41062-8_33
   Sedmidubsky J, 2012, LECT NOTES COMPUT SC, V7432, P11, DOI 10.1007/978-3-642-33191-6_2
   Tang ZP, 2014, COMPUT ANIMAT VIRT W, V25, P273, DOI 10.1002/cav.1602
   Tautges J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966397
   Thanh TT, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P148, DOI 10.1109/SITIS.2013.35
   Valcik Jakub, 2012, Intelligence and Security Informatics. Proceedings Pacific Asia Workshop, PAISI 2012, P127, DOI 10.1007/978-3-642-30428-6_10
   Wang Pengjie., 2011, MM'11 Proceedings of the 19th ACM International Conference on Multimedia, P1337
   Wu S., 2009, P 16 ACM S VIRTUAL R, P207
   Xiao J, 2006, LECT NOTES COMPUT SC, V4035, P494
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Zhao XY, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P23, DOI 10.1109/FSKD.2013.6816160
NR 54
TC 14
Z9 15
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2016
VL 27
IS 5
BP 484
EP 500
DI 10.1002/cav.1674
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DZ1QS
UT WOS:000385614100003
DA 2024-07-18
ER

PT J
AU Jang, T
   Noh, J
AF Jang, Taekwon
   Noh, Junyong
TI A geometric approach to animating thin surface features in smoothed
   particle hydrodynamics water
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fluid animation; interparticle connection; smoothed particle
   hydrodynamics
AB We propose a geometric approach to animating thin surface features of smoothed particle hydrodynamics-based water. Explicit interparticle connections are created among smoothed particle hydrodynamics particles to approximate the geometries of thin surfaces while addressing the issue of unresolved surface areas. The deformations measured on the connections actuate the animations of the surfaces by disconnecting the stretched and bent connections. The reconstruction of thin surfaces and the accuracy of the animation are improved by adding auxiliary particles over the connections via Poisson-disk sampling. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Jang, Taekwon] Samsung Elect, Suwon, South Korea.
   [Noh, Junyong] Korea Adv Inst Sci & Technol, Taejon 305701, South Korea.
C3 Samsung Electronics; Samsung; Korea Advanced Institute of Science &
   Technology (KAIST)
RP Noh, J (corresponding author), Korea Adv Inst Sci & Technol, Taejon 305701, South Korea.
EM junyongnoh@kaist.ac.kr
RI Noh, Junyong/C-1663-2011
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Ando R., 2011, Proceedings-SCA 2011: ACM SIGGRAPH / Eurographics Symposium on Computer Animation, P7, DOI DOI 10.1145/2019406.2019408
   Ando R, 2012, IEEE T VIS COMPUT GR, V18, P1202, DOI 10.1109/TVCG.2012.87
   [Anonymous], 2007, P SIGGRAPH SKETCH SA
   Bhatacharya Haimasree., 2011, P 2011 ACM SIGGRAPH, P17
   Bodin K, 2012, IEEE T VIS COMPUT GR, V18, P516, DOI 10.1109/TVCG.2011.29
   Cleary PW, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239548, 10.1145/1276377.1276499]
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Grinspun E., 2005, P ACM SIGGRAPH 2005, P14
   Ihmsen M, 2011, GRAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P225
   Jang T, 2011, INT J VIRTUAL REALIT, V1
   Lenaerts T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360648
   Liu SG, 2011, VISUAL COMPUT, V27, P241, DOI 10.1007/s00371-010-0531-1
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Onderik J, 2011, P SPRING C COMP GRAP, P25
   Raveendran K., 2011, P 2011 ACM SIGGRAPHE, P33
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Solenthaler B., 2008, P 2008 ACM SIGGRAPH, P211, DOI 10.2312/SCA/SCA08/211-218
   SOLENTHALER B., 2007, Proceedings of Eurographics Symposium on Point-Based Graphics 2007, P65
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Solenthaler B, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964976
   Yu JH, 2012, COMPUT GRAPH FORUM, V31, P815, DOI 10.1111/j.1467-8659.2012.03062.x
   Yu Jihun., 2010, Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '10, P217
   Yuan Z, 2011, VISUAL COMPUT, V7, P1
   Zhang Yanci., 2008, Proceedings of the Fifth Euro- graphics / IEEE VGTC Conference on Point-Based Graphics, SPBG'08, P137
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 29
TC 2
Z9 3
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2015
VL 26
IS 2
BP 161
EP 172
DI 10.1002/cav.1568
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CG3GB
UT WOS:000353165400007
DA 2024-07-18
ER

PT J
AU Lopez, T
   Chevaillier, P
   Gouranton, V
   Evrard, P
   Nouviale, F
   Barange, M
   Bouville, R
   Arnaldi, B
AF Lopez, Thomas
   Chevaillier, Pierre
   Gouranton, Valerie
   Evrard, Paul
   Nouviale, Florian
   Barange, Mukesh
   Bouville, Rozenn
   Arnaldi, Bruno
TI Collaborative virtual training with physical and communicative
   autonomous agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE interaction for virtual humans; conversational agents; autonomous
   actors; avatars; virtual reality
AB Virtual agents are a real asset in collaborative virtual environment for training (CVET) as they can replace missing team members. Collaboration between such agents and users, however, is generally limited. We present here a whole integrated model of CVET focusing on the abstraction of the real or virtual nature of the actor to define a homogenous collaboration model. First, we define a new collaborative model of interaction. This model notably allows to abstract the real or virtual nature of a teammate. Moreover, we propose a new role exchange approach so that actors can swap their roles during training. The model also permits the use of physically based objects and characters animation to increase the realism of the world. Second, we design a new communicative agent model, which aims at improving collaboration with other actors using dialog to coordinate their actions and to share their knowledge. Finally, we evaluated the proposed model to estimate the resulting benefits for the users and we show that this is integrated in existing CVET applications. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Lopez, Thomas; Gouranton, Valerie; Nouviale, Florian; Bouville, Rozenn; Arnaldi, Bruno] IRISA Hybrid, Inst Natl Sci Appliquees RENNES INSA, Rennes, France.
   [Chevaillier, Pierre; Barange, Mukesh] ENIB Brest, Brest, France.
   [Evrard, Paul] CEA LIST Inst, Paris, France.
C3 Universite de Rennes; Ecole Nationale d'Ingenieurs de Brest (ENIB)
RP Lopez, T (corresponding author), IRISA Hybrid, Inst Natl Sci Appliquees RENNES INSA, Rennes, France.
EM tlopez@irisa.fr
OI Bruno, ARNALDI/0000-0002-2868-8826; Barange, Mukesh/0000-0003-1462-7034
CR [Anonymous], 2006, LIT REV TEAMWORK MOD
   Barot C, 2013, PRESENCE-TELEOP VIRT, V22, P1, DOI 10.1162/PRES_a_00134
   Bunt H, 2011, COMPUT SPEECH LANG, V25, P222, DOI 10.1016/j.csl.2010.04.006
   Buschmeier Hendrik, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P169, DOI 10.1007/978-3-642-23974-8_19
   Chevaillier P., 2012, 2012 5th Workshop on Software Engineering and Architectures for Realtime Interactive Systems, P1, DOI 10.1109/SEARIS.2012.6231174
   Cohen PhilipR., 1991, International Joint Conference on Artificial Intelligence, P951
   Dugdale J, 2004, P ISCRAM2004 BRUSS B
   Edward Lydie, 2008, International Journal of Virtual Reality, V7, P13
   Gerbaud S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P225
   Grosz BJ, 1996, ARTIF INTELL, V86, P269, DOI 10.1016/0004-3702(95)00103-4
   Le mann N, 2006, SITUATED COMMUNICATI
   Liu M., 2012, P 11 ACM SIGGRAPH EU, P155
   Liu MX, 2011, IEEE INT CONF ROBOT, P1676, DOI 10.1109/ICRA.2011.5980078
   Lok B, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.68
   Lopez T, 2014, IEEE T VIS COMPUT GR, V20, P644, DOI 10.1109/TVCG.2014.22
   Luna Andres Saraos, 2012, E-Learning and Games for Training, Education, Health and Sports. Proceedings of the 7th International Conference, Edutainment 2012 and 3rd International Conference, GameDays 2012, P1, DOI 10.1007/978-3-642-33466-5_1
   Mascardi V., 2005, Workshop From Objects to Agents WOA, P9
   Mollet N., 2007, IPT-EGVE the 13th Eurographics Symposium on Virtual Environments, P95
   Mollet N, 2006, LECT NOTES COMPUT SC, V3942, P334, DOI 10.1007/11736639_45
   Rao A. S., 1995, ICMAS-95 Proceedings. First International Conference on Multi-Agent Systems, P312
   Rich C, 2001, AI MAG, V22, P15
   Rickel J, 1999, FRONT ARTIF INTEL AP, V50, P578
   Swartout W, 2006, AI MAG, V27, P96
   Traum D, 2008, LECT NOTES COMPUT SC, V5208, P117
   TRAUM DR, 2003, CURRENT NEW DIRECTIO
   Yamane K, 2004, ACM T GRAPHIC, V23, P532, DOI 10.1145/1015706.1015756
NR 26
TC 7
Z9 9
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 487
EP 495
DI 10.1002/cav.1583
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300029
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, SC
   Yoo, I
   Benes, B
   Chen, G
AF Zhou, Shengchuan
   Yoo, Innfarn
   Benes, Bedrich
   Chen, Ge
TI A hybrid level-of-detail representation for large-scale urban scenes
   rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE massive urban models; hybrid rendering; level of detail
ID MODELS
AB A novel hybrid level-of-detail (LOD) algorithm is introduced. We combine point-based, line-based, and splat-based rendering to synthesize large-scale urban city images. We first extract lines and points from the input and provide their simplification encoded in a data structure that allows for a quick and automatic LOD selection. A screen-space projected area is used as the LOD selector. The algorithm selects lines for long-distance views providing high contrast and fidelity of the building silhouettes. For medium-distance views, points are added, and splats are used for close-up views. Our implementation shows a 10xspeedup as compared with the ground truth models and is about four times faster than geometric LOD. The quality of the results is indistinguishable from the original as confirmed by a user study and two algorithmic metrics. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Zhou, Shengchuan; Chen, Ge] Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266071, Peoples R China.
   [Yoo, Innfarn; Benes, Bedrich] Purdue Univ, Coll Technol, W Lafayette, IN 47906 USA.
C3 Ocean University of China; Purdue University System; Purdue University
RP Zhou, SC (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, 238 Songling Rd, Qingdao 266071, Peoples R China.
EM shc.zhou@gmail.com
RI Benes, Bedrich/A-8150-2016
OI Benes, Bedrich/0000-0002-5293-2112
FU NSFC [613111035]
FX The implementation of precision and recall algorithm is provided by the
   Work Group Computer Graphics and Media Design, University of Konstanz.
   This work was supported by Projects of International Cooperation and
   Exchanges NSFC (613111035).
CR Airey J. M., 1990, Computer Graphics, V24, P41, DOI 10.1145/91394.91416
   Andujar C., 2008, IEEE VIRT REAL WORKS
   Aydin TO, 2010, ACM T GRAPHIC
   BURR DC, 1989, VISION RES, V29, P419, DOI 10.1016/0042-6989(89)90006-0
   Cignoni P, 2007, COMPUT GRAPH FORUM, V26, P405, DOI 10.1111/j.1467-8659.2007.01063.x
   CLARK JH, 1976, COMMUN ACM, V19, P547, DOI 10.1145/360349.360354
   Cohen J., 2003, P VIS SEATTL WASH US, P85
   Cohen JD, 2001, IEEE VISUAL, P37, DOI 10.1109/VISUAL.2001.964491
   Connolly C, 1997, IEEE T IMAGE PROCESS, V6, P1046, DOI 10.1109/83.597279
   Day AM, 2005, COMPUT GRAPH-UK, V29, P109, DOI 10.1016/j.cag.2004.11.011
   Décoret X, 2003, ACM T GRAPHIC, V22, P689, DOI 10.1145/882262.882326
   Decoret X, 1999, COMPUT GRAPH FORUM, V18, pC61, DOI 10.1111/1467-8659.00328
   Deussen O, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P219, DOI 10.1109/VISUAL.2002.1183778
   Downs Laura., 2001, Proceedings of the 2001 Symposium on Interactive 3D Graphics, P121
   Gobbetti E, 2005, ACM T GRAPHIC, V24, P878, DOI 10.1145/1073204.1073277
   GUTHE M, 2004, RENDERING TECHNIQUES, P69
   Hamill J, 2005, COMPUT GRAPH FORUM, V24, P623, DOI 10.1111/j.1467-8659.2005.00887.x
   Hilbert K, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P274, DOI 10.1109/CGI.2004.1309221
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   JAMESON D, 1964, VISION RES, V4, P135, DOI 10.1016/0042-6989(64)90037-9
   JONES CB, 1971, COMPUT J, V14, P232, DOI 10.1093/comjnl/14.3.232
   Kopf J, 2006, ACM T GRAPHIC, V25, P509, DOI 10.1145/1141911.1141916
   Luebke D., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P105, DOI 10.1145/199404.199422
   Maciel P. W. C., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P95, DOI 10.1145/199404.199420
   Merhof D, 2006, IEEE T VIS COMPUT GR, V12, P1181, DOI 10.1109/TVCG.2006.151
   Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307
   Sillion F, 1997, COMPUT GRAPH FORUM, V16, pC207, DOI 10.1111/1467-8659.00158
   Teller SJ, 1991, COMPUTER GRAPHICS, V25, P61
   Varadhan G, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P69, DOI 10.1109/VISUAL.2002.1183759
   Wald I, 2005, ACM SIGGRAPH 2005 Courses. SIGGRAPH'05, P17, DOI [DOI 10.1145/1198555.1198756, 10.1145/1198555.1198756]
   Wald I, 2010, EUR S REND SAARBR GE
   Wimmer M, 2001, SPRING EUROGRAP, P163
   Yoon SE, 2005, IEEE T VIS COMPUT GR, V11, P369, DOI 10.1109/TVCG.2005.64
NR 33
TC 1
Z9 2
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 245
EP 255
DI 10.1002/cav.1582
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300006
DA 2024-07-18
ER

PT J
AU Kirmizibayrak, C
   Wakid, M
   Yim, Y
   Hristov, D
   Hahn, JK
AF Kirmizibayrak, Can
   Wakid, Mike
   Yim, Yeny
   Hristov, Dimitre
   Hahn, James K.
TI Interactive focus plus context medical data exploration and editing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE medical visualization; Magic Lens; volume editing; focus plus context;
   radiation therapy
ID VOLUME; VISUALIZATION; CT
AB Volumetric datasets are increasingly used in medical applications. In many of these applications, visualization and interaction is generally performed on cross-sectional two-dimensional (2D) views of three-dimensional (3D) imaging modalities. Displaying 3D volumetric medical datasets on traditional 2D screens can present problems such as occlusion and information overload, especially when multiple data sources are present. Displaying desired information while showing the relationship to the rest of the dataset(s) can be challenging. In this paper, we present an interactive focus+context visualization approach that uses the volumetric Magic Lens interaction paradigm. We propose to use the Magic Lens as a volumetric brush to perform volume editing tasks, therefore combining data exploration with volumetric editing. Polygon-assisted ray casting methods are used for real-time rendering and editing frame rates, while providing compact storage of editing states for undo/redo operations. We discuss the application of our methods to radiation therapy, which is an important cancer treatment modality. We envision that this approach will improve the treatment planning process by improving the therapists' understanding of information from various sources and will help identify if the alignment of the patient in the treatment room coincides with the prepared treatment plan. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Kirmizibayrak, Can; Wakid, Mike; Yim, Yeny; Hahn, James K.] George Washington Univ, Dept Comp Sci, Washington, DC 20052 USA.
   [Kirmizibayrak, Can; Hristov, Dimitre] Stanford Univ, Dept Radiat Oncol, Stanford, CA 94305 USA.
C3 George Washington University; Stanford University
RP Kirmizibayrak, C (corresponding author), George Washington Univ, Dept Comp Sci, Washington, DC 20052 USA.
EM kirmizi@gwmail.gwu.edu
RI Hahn, James/AAF-8272-2021
CR [Anonymous], 2012, CANC FACTS FIG 2012
   [Anonymous], 1980, 33 ICRU
   Bavoil L., 2008, ORDER INDEPENDENT TR
   Bethesda M, 1993, 50 ICRU
   Bier E. A., 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques
   Borst CW, 2009, REAL TIME RENDERING
   Borst CW, 2011, IEEE T VISUALIZATION, P99
   Bruckner S., 2005, VOLUMESHOP INTERACTI, P85
   Bürger K, 2008, IEEE T VIS COMPUT GR, V14, P1388, DOI 10.1109/TVCG.2008.120
   Caban JJ, 2008, IEEE T VIS COMPUT GR, V14, P1364, DOI 10.1109/TVCG.2008.169
   Correa CD, 2008, IEEE T VIS COMPUT GR, V14, P1380, DOI 10.1109/TVCG.2008.162
   Delaney G, 2005, CANCER-AM CANCER SOC, V104, P1129, DOI 10.1002/cncr.21324
   Heckel F, 2011, COMPUT GRAPH-UK, V35, P275, DOI 10.1016/j.cag.2010.12.006
   Jaffray DA, 2007, FRONT RADIAT THER ON, V40, P116, DOI 10.1159/000106031
   Joshi A, 2008, IEEE T VIS COMPUT GR, V14, P1587, DOI 10.1109/TVCG.2008.150
   Krüger J, 2006, IEEE T VIS COMPUT GR, V12, P941, DOI 10.1109/TVCG.2006.124
   Lattanzi J, 1999, INT J RADIAT ONCOL, V43, P719, DOI 10.1016/S0360-3016(98)00496-9
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Liu F, 2009, P C HIGH PERF GRAPH
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Mackie TR, 2003, INT J RADIAT ONCOL, V56, P89, DOI 10.1016/S0360-3016(03)00090-7
   Myers K., 2007, STENCIL ROUTED K BUF
   OsiriX F., 2011, F OSIRIX DICOM SAMPL
   Pouliot J, 2005, INT J RADIAT ONCOL, V61, P552, DOI 10.1016/j.ijrobp.2004.10.011
   Rautek P, 2008, COMPUT GRAPH FORUM, V27, P847, DOI 10.1111/j.1467-8659.2008.01216.x
   Rezk-Salama C, 2006, COMPUT GRAPH FORUM, V25, P597, DOI 10.1111/j.1467-8659.2006.00979.x
   Rieder C, 2008, COMPUT GRAPH FORUM, V27, P1055, DOI 10.1111/j.1467-8659.2008.01242.x
   Ropinski T., 2004, Real-time rendering of 3D magic lenses having arbitrary convex shapes
   Sholl MJ, 1997, J EXP PSYCHOL LEARN, V23, P1494, DOI 10.1037/0278-7393.23.6.1494
   Svakhine N, 2005, IEEE COMPUT GRAPH, V25, P31, DOI 10.1109/MCG.2005.60
   Trapp M., 2008, EG UK THEORY PRACTIC, P9
   Viega J., 1996, P 9 ANN ACM S US INT
   Wang LJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P367
   Weiskopf D, 2003, IEEE T VIS COMPUT GR, V9, P298, DOI 10.1109/TVCG.2003.1207438
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 35
TC 3
Z9 3
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2014
VL 25
IS 2
BP 129
EP 141
DI 10.1002/cav.1538
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AE8SY
UT WOS:000334273500004
DA 2024-07-18
ER

PT J
AU Xu, TC
   Wu, W
   Wu, EH
AF Xu, Tianchen
   Wu, Wen
   Wu, Enhua
TI Real-time generation of smoothed-particle hydrodynamics-based special
   effects in character animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE real-time visual effects; smoothed-particle hydrodynamics; character
   animation
AB In the previous works, the real-time fluid-character animation could hardly be achieved because of the intensive processing demand on the character's movement and fluid simulation. This paper presents an effective approach to the real-time generation of the fluid flow driven by the motion of a character in full 3D space, based on smoothed-particle hydrodynamics method. The novel method of conducting and constraining the fluid particles by the geometric properties of the character motion trajectory is introduced. Furthermore, the optimized algorithms of particle searching and rendering are proposed, by taking advantage of the graphics processing unit parallelization. Consequently, both simulation and rendering of the 3D liquid effects with realistic character interactions can be implemented by our framework and performed in real-time on a conventional PC. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Xu, Tianchen; Wu, Wen; Wu, Enhua] Univ Macau, Dept Comp & Informat Sci, Fac Sci & Technol, Macau, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, State Key Lab CS, Inst Software, Beijing, Peoples R China.
C3 University of Macau; Chinese Academy of Sciences; Institute of Software,
   CAS
RP Xu, TC (corresponding author), Univ Macau, Dept Comp & Informat Sci, Fac Sci & Technol, Macau, Peoples R China.
EM x-universe@live.com
RI Xu, Tianchen/T-9694-2019
FU University of Macau; National Fundamental Research Grant 973 Program
   [2009CB320802]; NSFC [61272326];  [MYRG202(Y1-L4)/FST11/WEH]; 
   [MYRG150(Y1-L2)/FST11/WW]
FX The authors would like to thank the editor and the referees for their
   valuable comments and suggestions to improve the quality of the
   manuscript. Their thanks also go to Ya-Dang Chen for providing the
   reconstructed 3D environment in Figure 12. The work was supported by the
   grants (MYRG202(Y1-L4)/FST11/WEH, MYRG150(Y1-L2)/FST11/WW) and the
   studentships of University of Macau, the National Fundamental Research
   Grant 973 Program (2009CB320802), and NSFC (61272326).
CR Adams B, 2007, ACM SIGGRAPH 2007 SI
   Amada T, 2004, P ACM WORKSH GEN PUR
   Bayraktar Serkan, 2009, Journal of Graphics Tools, V14, P31
   Chang Y., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, P111, DOI DOI 10.1145/1643928.1643954
   Goswami P., 2010, P 2010 ACM SIGGRAPHE, P55
   Harada T., 2007, P COMP GRAPH INT
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Kipfer P., 2004, HWWS 04, P115, DOI [10.1145/1058129.1058146, DOI 10.1145/1058129.1058146]
   Le Grand S., 2008, GPU GEMS, P697
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Pnueli D, 1997, FLUID MECH, P160
   Sander P-V, 2008, ACM SIGGRAPH AS 2008
   Schmid J, 2010, ACM SIGGRAPH 2010 SI, P57
   Solenthaler B., 2009, ACM SIGGRAPH 2009 PA, P40
   TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840
   Van der Laan W.J., 2009, P 2009 S INT 3D GRAP, P91, DOI [DOI 10.1145/1507149.1507164, 10.1145/1507149.1507164]
   Van Kooten K, 2008, GPU GEMS, P123
   Xu T-C, 2013, P 26 INT C COMP AN S, P7
   Xu T-C, 2011, P 10 INT C VIRT REAL, P307
   Zhao X., 2010, HICSS, P1
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 23
TC 3
Z9 5
U1 2
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2014
VL 25
IS 2
BP 185
EP 198
DI 10.1002/cav.1545
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AE8SY
UT WOS:000334273500008
DA 2024-07-18
ER

PT J
AU Shi, Y
   Ying, FT
   Chen, X
   Pan, ZG
   Yu, JH
AF Shi, Yan
   Ying, Fangtian
   Chen, Xuan
   Pan, Zhigeng
   Yu, Jinhui
TI Restoration of traditional Chinese shadow play-Piying art from tangible
   interaction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE culture preservation; shadow play; tangible interaction; kinect; bodily
   movement; field studies
ID VIRTUAL-REALITY
AB Piying, the world's intangible culture heritage, is a characteristic Chinese folk shadow play and one of the origins of modern movie. The spirit of traditional Piying is to express rich emotion and stories through impromptu action change by professional artists. Now Piying gradually fades away in people's lives, encountering the risk of extinction. We focus on transforming the traditional Piying play into an interactive system, which can be seamlessly performed by ordinary people and bring a strong sense of immersion to the users. Two interactive systems were developed, with Kinect-based interaction or sensors, users can create own digital Piying animations by employing their body movement as input. A field study was presented with 20 students in a primary school. The result showed that our system was far more effective in emotion induction and Piying understanding than traditional one. We demonstrated this system in a charitable foundation and a workshop of a tangible conference. It is also honored to be collected by China's intangible cultural heritage network. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Shi, Yan; Ying, Fangtian; Chen, Xuan] Zhejiang Univ, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Pan, Zhigeng] Hangzhou Normal Univ, Digital Media & HCI Res Ctr, Hangzhou, Peoples R China.
   [Yu, Jinhui] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Hangzhou Normal University; Zhejiang University
RP Shi, Y (corresponding author), Zhejiang Univ, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
EM hzshiyan@gmail.com
OI Pan, Zhi-geng/0000-0003-0717-5850
FU State Key Program of National Natural Science Foundation of China
   [60933007]; NSFC [61170318]; National Key Project [2013BAH24F00]
FX This work is supported by the State Key Program of National Natural
   Science Foundation of China (No. 60933007), NSFC project (No: 61170318)
   and National Key Project (No: 2013BAH24F00).
CR [Anonymous], 2004, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'04), DOI DOI 10.1145/985692.985774
   [Anonymous], P 19 ACM INT C MULT
   [Anonymous], 2003, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, DOI DOI 10.1145/642611.642709
   Bonanni Leonardo, 2010, International Journal of Creative Interfaces and Computer Graphics, V1, P54, DOI 10.4018/jcicg.2010010105
   Budd J., 2007, P 6 IDC INT C INTERA, P97
   Chen S, 2012, Lecture Notes in Computer Science, V7145, P180
   Chen WZ, 2010, IEEE COMPUT GRAPH, V30, P84, DOI 10.1109/MCG.2010.49
   Chi EH., 2004, P 17 ANN ACM S USER, P277, DOI [10.1145/1029632.1029680, DOI 10.1145/1029632.1029680]
   Chua PT, 2003, P IEEE VIRT REAL ANN, P87
   Frei P., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P129, DOI 10.1145/332040.332416
   Gudukbay U, 2000, LEONARDO, V33, P264, DOI 10.1162/leon.2000.33.4.264
   Gudukbay U, 2000, AN SYST SHAD THEATR
   Hamalainen Perttu., 2005, CHI 05, P781
   Hinske Steve, 2008, Proceedings of the 7th ACM Conference on Designing Interactive Systems. DIS 2008, P78, DOI 10.1145/1394445.1394454
   Höysniemi J, 2005, COMMUN ACM, V48, P44, DOI 10.1145/1039539.1039568
   Hsu SW, 2005, P COMP AN SOC AG
   Hsu SW, 2005, P SIGGRAPH 2005 C SK
   Ishii H, 2004, BT TECHNOL J, V22, P287, DOI 10.1023/B:BTTJ.0000047607.16164.16
   Ishii H., 1999, CHI'99 Proceedings, P394, DOI [10.1145/ 302979.303115, DOI 10.1145/302979.303115]
   Ishii H., 2008, Tangible bits: beyond pixels. In Proceedings of the 2nd international conference on Tangible and embedded interaction, pxv, DOI DOI 10.1145/1347390.1347392
   Li ZW, 2012, IEEE T VIS COMPUT GR, V18, P177, DOI 10.1109/TVCG.2011.26
   Liu Y, 2012, EXPERT SYST APPL, V39, P12071, DOI 10.1016/j.eswa.2012.04.026
   Mueller F., 2008, CHI'08 extended abstracts .., P2291, DOI DOI 10.1145/1358628.1358672
   Mueller F, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1539
   Öztürk S, 2006, ASIAN THEATRE J, V23, P292, DOI 10.1353/atj.2006.0027
   Pan ZG, 2009, IEEE COMPUT GRAPH, V29, P91, DOI 10.1109/MCG.2009.103
   Piper B., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P355, DOI 10.1145/503376.503439
   Sadoul G, 1946, MOVIE HIST
   SHI Y, 2010, P 4 INT C TANG EMB I, P375
   Tartaro Andrea., 2008, International Perspectives in the Learning Sciences: Creating a Learning World, Proceedings of the Eighth International Conference for the Learning Sciences, Utrecht, The Netherlands, 24-28 June 2008, P382
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Watson D., 1994, The PANASX: Manual for the positive and negative affect scheduleexpanded form, DOI DOI 10.17077/48VT-M4T2
   Zhang Jun-song, 2006, Journal of Zhejiang University (Science), V7, P1178, DOI 10.1631/jzus.2006.A1178
   Zhang JS, 2007, INT C COMP AID DES C, P219
   Zhigeng Pan, 2011, 2011 Second International Conference on Culture and Computing, P3, DOI 10.1109/Culture-Computing.2011.10
   Zhu JJ, 2011, IEEE T PATTERN ANAL, V33, P1400, DOI 10.1109/TPAMI.2010.172
   Zhu YB, 2003, ACM SIGGRAPH 2003 SK
NR 37
TC 5
Z9 6
U1 8
U2 93
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2014
VL 25
IS 1
BP 33
EP 43
DI 10.1002/cav.1530
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AA4LQ
UT WOS:000331067500004
DA 2024-07-18
ER

PT J
AU Zhu, YF
   Ramakrishnan, AS
   Hamann, B
   Neff, M
AF Zhu, Yuanfeng
   Ramakrishnan, Ajay Sundar
   Hamann, Bernd
   Neff, Michael
TI A system for automatic animation of piano performances
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE piano animation; fingering generation; optimization method
AB Playing the piano requires one to precisely position one's hand in order to strike particular combinations of keys at specific moments in time. This paper presents the first system for automatically generating three-dimensional animations of piano performance, given an input midi music file. A graph theory-based motion planning method is used to decide which set of fingers should strike the piano keys for each chord. As the progression of the music is anticipated, the positions of unused fingers are calculated to make possible efficient fingering of future notes. Initial key poses of the hands, including those for complex piano techniques such as crossovers and arpeggio, are determined on the basis of the finger positions and piano theory. An optimization method is used to refine these poses, producing a natural and minimal energy pose sequence. Motion transitions between poses are generated using a combination of sampled piano playing motion and music features, allowing the system to support different playing styles. Our approach is validated through direct comparison with actual piano playing and simulation of a complete music piece requiring various playing skills. Extensions of our system are discussed. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Zhu, Yuanfeng; Ramakrishnan, Ajay Sundar; Hamann, Bernd; Neff, Michael] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
C3 University of California System; University of California Davis
RP Zhu, YF (corresponding author), Univ Calif Davis, Dept Comp Sci, 1 Shields Ave, Davis, CA 95616 USA.
EM yuazhu@ucdavis.edu
CR [Anonymous], 2005, ACM SIGGRAPH EUR S C, DOI DOI 10.1145/1073368.1073413
   [Anonymous], 2005, Proceedings of the International Computer Music Conference
   Benward B., 1997, Music in Theory and Practice, V1
   ElKoura G., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P110
   Häger-Ross C, 2000, J NEUROSCI, V20, P8542, DOI 10.1523/JNEUROSCI.20-22-08542.2000
   Hart R, 2000, UNDERGRADUATE MATH I, V21, P67
   Heijink H, 2002, J MOTOR BEHAV, V34, P339, DOI 10.1080/00222890209601952
   Kasimi E, 2005, INT SOC MUS INF RETR
   Kim J, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P37, DOI 10.1109/CGI.2000.852318
   LEE KH, 1993, DESIGNING FOR DIVERSITY, VOLS 1 AND 2, P710
   Lin C.-C., 2006, Proceedings of the 2006 ACM International Conference on Virtual Reality Continuum and its Applications, P353
   Parncutt R, 1997, MUSIC PERCEPT, V14, P341
   Radicioni D., 2005, Proceedings of the International Computer Music Conference, P527
   Radicioni L, 2004, P C INT MUS GRAZ AUS
   Radisavljevic A, 2004, P INT COMP MUS C MIA
   SAYEGH SI, 1989, COMPUT MUSIC J, V13, P76, DOI 10.2307/3680014
   Tuohy DR., 2006, THESIS U GEORGIA
   Viana AB de dM., 2003, 9 BRAZ S COMP MUS CA
   Yasumuro Y, 1999, IMAGE VISION COMPUT, V17, P149, DOI 10.1016/S0262-8856(98)00118-8
   Yonebayashi Y, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2915
NR 20
TC 11
Z9 13
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2013
VL 24
IS 5
BP 445
EP 456
DI 10.1002/cav.1477
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 238UL
UT WOS:000325976300002
DA 2024-07-18
ER

PT J
AU Kang, D
   Ohn, Y
   Han, M
   Yoon, K
AF Kang, Dongwann
   Ohn, Yongjin
   Han, Myounghun
   Yoon, Kyunghyun
TI Generation of coherent mosaic animations: enhancement and evaluation of
   temporal coherence
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE non-photorealistic animation; temporal coherence; mosaic animation
AB Although the creation static mosaic-like images from non-mosaic input has been studied, satisfactory methods to maintain and evaluate the temporal coherence of tiles for mosaic animations have remained elusive. Here, we describe a method that successfully generates mosaic animations from videos by applying a temporally and spatially coherent tile-arrangement technique. We arrange tiles on the basis of the feature lines extracted from video input. We then animate the tiles along the motion of the video, add and delete tiles to preserve the tile density, and smooth tile color via frames. Finally, we propose indices to evaluate the temporal coherence of video-based animations, and show that our animations are temporally coherent. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Kang, Dongwann; Ohn, Yongjin; Han, Myounghun; Yoon, Kyunghyun] Chunag Ang Univ, Seoul, South Korea.
RP Yoon, K (corresponding author), Chunag Ang Univ, Seoul, South Korea.
EM khyoon@cau.ac.kr
FU National Research Foundation of Korea (NRF); Korean government (MEST)
   [20100018445]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean government (MEST) (no. 20100018445).
CR Battiato S, 2006, WSCG 2006: FULL PAPERS PROCEEDINGS, P133
   BREU H, 1995, IEEE T PATTERN ANAL, V17, P529, DOI 10.1109/34.391389
   Di Blasi G, 2005, VISUAL COMPUT, V21, P373, DOI 10.1007/s00371-005-0292-4
   Dobashi Y, 2002, EUGRAPHICS 02 SHORT
   Elber G, 2003, VISUAL COMPUT, V19, P67, DOI 10.1007/s00371-002-0175-x
   Haeberli P., 1990, Computer Graphics, V24, P207, DOI 10.1145/97880.97902
   Hausner A, 2001, COMP GRAPH, P573, DOI 10.1145/383259.383327
   Hays J., 2004, PROC NPAR 01, P113
   Hertzmann A., 2000, NPAR, P7
   Hoff KE, 1999, COMP GRAPH, P277, DOI 10.1145/311535.311567
   Kang D., 2011, Proc. NPAR '11, P157
   Kim D, 2008, COMPUT GRAPH FORUM, V27, P1209, DOI 10.1111/j.1467-8659.2008.01259.x
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Paris S, 2008, LECT NOTES COMPUT SC, V5303, P460, DOI 10.1007/978-3-540-88688-4_34
   Park Y, 2008, GRAPH MODELS, V70, P1, DOI 10.1016/j.gmod.2007.06.001
   Simoncelli E. P., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P310, DOI 10.1109/CVPR.1991.139707
   Smith K., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA '05, P201
   Wang J, 2004, LECT NOTES COMPUT SC, V3022, P238
   Yoon JC, 2012, IEEE T VIS COMPUT GR, V18, P58, DOI 10.1109/TVCG.2011.47
NR 20
TC 4
Z9 4
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 191
EP 202
DI 10.1002/cav.1437
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100007
DA 2024-07-18
ER

PT J
AU Sun, HQ
   Han, JQ
AF Sun, Hongquan
   Han, Jiqing
TI Particle-based realistic simulation of fluid-solid interaction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fluid-solid interaction; smoothed particle hydrodynamics; fluid
   simulation
ID ANIMATION
AB In this paper a novel method for simulating incompressible viscous fluid and solid coupling is presented. In the coupling model, a rigid object is treated as a special fluid constrained to rigid body motion. To animate the coupling model, the Smoothed Particle Hydrodynamics method is used for solving the fluid motion equations. For keeping the rigidity of rigid objects, the total force and total torque exerted on solids is first worked out according to the impulse-momentum theorem, and then the movement of these rigid bodies is restricted to translations and rotations. Moreover, in order to prevent the fluids particles leaking into solids, a detection and correction procedure is presented, and the velocities of fluid particles will be tuned if the penetration is detected in this procedure. The proposed method can be implemented easily by extending the existing fluid solvers, the experimental results show that this method is capable of animating the realistic solid and fluid coupling. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Sun, Hongquan] Harbin Inst Technol, Speech Proc Lab, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Sun, HQ (corresponding author), Harbin Inst Technol, Speech Proc Lab, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM hqsun@126.com
CR Carlson M, 2004, RIGID FLUID ANIMATIN, P377
   Carlson M, 2002, MELTING AND FLOWING, P167
   CHEN JX, 1995, GRAPH MODEL IM PROC, V57, P107, DOI 10.1006/gmip.1995.1012
   Desbrun Mathieu, 1996, SMOOTHED PARTICLES N, P61
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P178, DOI 10.1109/CGI.1997.601299
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Guendelman E, 2003, ACM T GRAPHIC, V22, P871, DOI 10.1145/882262.882358
   Hirt CW, 1997, J COMPUT PHYS, V135, P203, DOI 10.1006/jcph.1997.5702
   Lenaerts T, 2008, ACM SIGGRAPH 2008
   Li S., 2004, Meshfree Particle Method
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Losasso F, 2006, IEEE T VIS COMPUT GR, V12, P343, DOI 10.1109/TVCG.2006.51
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Muller M., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, P154
   Robinson-Mosher A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360645
   Singh P, 2003, INT J MULTIPHAS FLOW, V29, P495, DOI 10.1016/S0301-9322(02)00164-7
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stora D, 1999, PROC GRAPH INTERF, P203
   Tan J, 2009, SCI CHINA SER F, V52, P723, DOI 10.1007/s11432-009-0091-z
   Yngve GD, 2000, COMP GRAPH, P29, DOI 10.1145/344779.344801
   Zhong ZC, 2008, I C COMP AID DES CON, P523, DOI 10.1109/CAIDCD.2008.4730624
NR 26
TC 5
Z9 7
U1 2
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2010
VL 21
IS 6
BP 589
EP 595
DI 10.1002/cav.379
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 696EB
UT WOS:000285423600005
DA 2024-07-18
ER

PT J
AU de Melo, CM
   Kenny, P
   Gratch, J
AF de Melo, Celso M.
   Kenny, Patrick
   Gratch, Jonathan
TI Real-time expression of affect through respiration
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE respiration; affect; virtual humans; real-time
ID PATTERNS; EMOTION; RESPONSES; COMPONENTS; ATTENTION
AB Affect has been shown to influence respiration in people. This paper takes this insight and proposes a real-time model to express affect through respiration in virtual humans. Fourteen affective states are explored: excitement, relaxation, focus, pain, relief, boredom, anger, fear, panic, disgust, surprise, startle, sadness, and joy. Specific respiratory patterns are described from the literature for each of these affective states. Then, a real-time model of respiration is proposed that uses morphing to animate breathing and provides parameters to control respiration rate, respiration depth and the respiration cycle curve. These parameters are used to implement the respiratory patterns. Finally, a within-subjects study is described where subjects are asked to classify videos of the virtual human expressing each affective state with or without the specific respiratory patterns. The study was presented to 41 subjects and the results show that the model improved perception of excitement, pain, relief, boredom, anger, fear, panic, disgust, and startle. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [de Melo, Celso M.; Gratch, Jonathan] Univ So Calif, Inst Creat Technol, Marina Del Rey, CA 90292 USA.
   [Kenny, Patrick] Univ Michigan, AI Lab Res & Dev Cognit Robot Unmanned Ground V, Ann Arbor, MI 48109 USA.
   [Gratch, Jonathan] Univ So Calif, Computat Emot Grp, Marina Del Rey, CA 90292 USA.
C3 University of Southern California; University of Michigan System;
   University of Michigan; University of Southern California
RP de Melo, CM (corresponding author), Univ So Calif, Inst Creat Technol, 13274 Fiji Way, Marina Del Rey, CA 90292 USA.
EM demelo@usc.edu
CR ALLEN MT, 1986, PSYCHOPHYSIOLOGY, V23, P532, DOI 10.1111/j.1469-8986.1986.tb00669.x
   [Anonymous], 2018, Real-Time Rendering
   AX AF, 1953, PSYCHOSOM MED, V15, P433, DOI 10.1097/00006842-195309000-00007
   BARRY RJ, 1982, PSYCHOPHYSIOLOGY, V19, P28, DOI 10.1111/j.1469-8986.1982.tb02595.x
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   Blatz WE, 1925, J EXP PSYCHOL, V8, P109, DOI 10.1037/h0071039
   BLOCH S, 1991, INT J PSYCHOPHYSIOL, V11, P141, DOI 10.1016/0167-8760(91)90006-J
   BOITEN FA, 1994, INT J PSYCHOPHYSIOL, V17, P103, DOI 10.1016/0167-8760(94)90027-2
   Boiten FA, 1998, BIOL PSYCHOL, V49, P29, DOI 10.1016/S0301-0511(98)00025-8
   CABOT R, 1942, PHYS DIAGNOSIS
   Cacioppo J.T., 2000, Handbook of Emotions, P173
   Christie RV, 1935, Q J MED, V4, P427
   CLAUSEN J, 1951, Acta Psychiatr Neurol Suppl, V68, P1
   Cohen J., 1988, STAT POWER ANAL BEHA
   DARWIN C, 1892, EXPRESSION EMOTIONS
   de Graaf V., 2002, Human anatomy, V6th
   de Melo CM, 2009, LECT NOTES ARTIF INT, V5773, P188, DOI 10.1007/978-3-642-04380-2_23
   DiLorenzo PC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409078
   DUDLEY DL, 1964, PSYCHOSOM MED, V26, P46, DOI 10.1097/00006842-196401000-00007
   EKMAN P, 2003, HDB COGNITION EMOTIO
   FELEKY A, 1914, PSYCHOL REV, V1, P218
   Filippelli M, 2001, J APPL PHYSIOL, V90, P1441, DOI 10.1152/jappl.2001.90.4.1441
   Gomez P, 2005, BIOL PSYCHOL, V68, P223, DOI 10.1016/j.biopsycho.2004.06.003
   Gomez P, 2004, BIOL PSYCHOL, V67, P359, DOI 10.1016/j.biopsycho.2004.03.013
   Gomez P, 2004, INT J PSYCHOPHYSIOL, V53, P91, DOI 10.1016/j.ijpsycho.2004.02.002
   Gratch J, 2002, IEEE INTELL SYST, V17, P54, DOI 10.1109/MIS.2002.1024753
   HARVER A, 1987, PSYCHOPHYSIOLOGY, V24, P26, DOI 10.1111/j.1469-8986.1987.tb01855.x
   HORMBREY JM, 1976, B EUR PHYSIOPATHOL R, V22, P518
   JOHNSTON T, 1981, ILLUSION LIFE DISNEY
   KAYE J, 1998, MED IMAGE ANAL, V2, P165
   KEATINGE WR, 1965, J APPL PHYSIOL, V20, P65, DOI 10.1152/jappl.1965.20.1.65
   LANG PJ, 1990, PSYCHOL REV, V97, P377, DOI 10.1037/0033-295X.97.3.377
   Levenson RW, 2003, SER AFFECTIVE SCI, P212
   McFarland DH, 2001, J SPEECH LANG HEAR R, V44, P128, DOI 10.1044/1092-4388(2001/012)
   MINES AH, 1993, RESP PHYSL
   NEWSOMDAVIS J, 1975, J PHYSIOL-LONDON, V245, P481
   Promayon E, 1997, LECT NOTES COMPUT SC, V1205, P379, DOI 10.1007/BFb0029259
   PROVINE RR, 1986, B PSYCHONOMIC SOC, V24, P437
   Rainville P, 2006, INT J PSYCHOPHYSIOL, V61, P5, DOI 10.1016/j.ijpsycho.2005.10.024
   Ray N, 2003, IEEE T MED IMAGING, V22, P189, DOI 10.1109/TMI.2002.808354
   Rosenthal R., 1991, METAANALYTIC PROCEDU
   ROTH M, 1988, Journal of Psychiatric Research, V22, P33, DOI 10.1016/0022-3956(88)90068-4
   SANTIBANEZH G, 1986, PAVLOVIAN J BIOL SCI, V21, P108
   Segars WP, 2001, IEEE T NUCL SCI, V48, P89, DOI 10.1109/23.910837
   Skaggs EB, 1930, J COMP PSYCHOL, V10, P375, DOI 10.1037/h0071298
   SOKOLOV JY, 1963, PERCEPTION CONDITION
   Standring S., 2008, Gray's anatomy: the anatomical basis of clinical practice, V40th, DOI DOI 10.1016/J.JSS.2009.01.035
   SUESS WM, 1980, PSYCHOPHYSIOLOGY, V17, P535, DOI 10.1111/j.1469-8986.1980.tb02293.x
   SVEBAK S, 1982, BIOL PSYCHOL, V14, P113, DOI 10.1016/0301-0511(82)90019-9
   SVEBAK S, 1975, PSYCHOPHYSIOLOGY, V12, P62, DOI 10.1111/j.1469-8986.1975.tb03062.x
   TSUZUKI M, 2007, COMPUT AIDED DESIGN, V41, P573, DOI DOI 10.1016/J.CAD.2007.10.001
   TURNER JR, 1985, PSYCHOPHYSIOLOGY, V22, P261, DOI 10.1111/j.1469-8986.1985.tb01597.x
   WIENTJES C, 1993, THESIS CATHOLIC U TI
   WILLER JC, 1975, PHYSIOL BEHAV, V15, P411, DOI 10.1016/0031-9384(75)90206-1
   ZORDAN V., 2004, Proc. of the ACM SIGGMPH / Eurographics Symposium on Computer Animation, P29
NR 55
TC 12
Z9 13
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 225
EP 234
DI 10.1002/cav.349
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400010
DA 2024-07-18
ER

PT J
AU Li, XA
   Xu, J
   Ren, YC
   Geng, WD
AF Li, Xiang
   Xu, Jun
   Ren, Yangchun
   Geng, Weidong
TI Animating cartoon faces by multi-view drawings
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE facial animation; cartoon animation; sketch-based interfaces for
   modeling; view-dependent geometry; non-photorealistic rendering
ID SURFACES
AB In this paper, we present a novel framework for creating cartoon facial animation from multi-view hand-drawn sketches. The input sketches are first employed to construct a base mesh model by using a hybrid sketch-based method. The model is then deformed for each key viewpoint, yielding a set of models that closely match the corresponding sketches. We introduce a view-dependent facial expression space defined by the key viewpoints and the basic emotions to generate various facial expressions viewed from arbitrary angles. The output facial animation conforms to the input sketches and maintains frame-to-frame correspondence. We demonstrate the potential of our approach through an easy-to-use system, where the animating of cartoon faces is automated once the user accomplishes sketching and configuration. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Geng, Weidong] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Geng, Weidong] Hong Kong Polytech Univ, Multimedia Innovat Ctr, Hong Kong, Hong Kong, Peoples R China.
   [Ren, Yangchun] Zhejiang Univ, Dept Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Hong Kong Polytechnic University; Zhejiang
   University
RP Geng, WD (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM gengwd@zju.edu.cn
CR [Anonymous], P ACM MULT
   [Anonymous], CSTR200202 STANDF U
   Chaudhuri P, 2004, COMPUT GRAPH FORUM, V23, P411, DOI 10.1111/j.1467-8659.2004.00772.x
   Chaudhuri P, 2007, VISUAL COMPUT, V23, P707, DOI 10.1007/s00371-007-0130-y
   Chen BY, 2005, VISUAL COMPUT, V21, P551, DOI 10.1007/s00371-005-0333-z
   Di Fiore F, 2001, COMP ANIM CONF PROC, P192, DOI 10.1109/CA.2001.982393
   Di Fiore F, 2002, COMP ANIM CONF PROC, P183, DOI 10.1109/CA.2002.1017532
   DIFIORE F, 2005, P COMP AN SOC AG
   DIFIORE F, 2003, P 3 C COMP GRAPH INT
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Levin A, 1999, COMPUT AIDED GEOM D, V16, P345, DOI 10.1016/S0167-8396(98)00051-X
   LI Y, 2003, P ACM SIGGRAPH EUR S
   MAO X, 2005, P COMP GRAPH INT
   Nealen A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276429
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   Rademacher P, 1999, COMP GRAPH, P439, DOI 10.1145/311535.311612
   Ruttkay Z, 2003, COMPUT GRAPH FORUM, V22, P49, DOI 10.1111/1467-8659.t01-1-00645
   RUTTKAY Z, 2000, P 1 INT S NONPH AN R
   Sorkine O, 2006, COMPUT GRAPH FORUM, V25, P789, DOI 10.1111/j.1467-8659.2006.00999.x
   Strothotte T, 2002, NONPHOTOREALISTIC CO
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
NR 21
TC 5
Z9 11
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 193
EP 201
DI 10.1002/cav.344
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400007
DA 2024-07-18
ER

PT J
AU Park, H
   Oh, J
   Seo, BK
   Park, JI
AF Park, Hanhoon
   Oh, Jihyun
   Seo, Byung-Kuk
   Park, Jong-Il
TI Automatic confidence adjustment of visual cues in model-based camera
   tracking
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Virtual-Reality Continuum and its
   Applications in Industry
CY DEC 08-09, 2008
CL Singapore, SINGAPORE
SP ACM SIGGRAPH
DE automatic confidence adjustment; object-adaptive camera tracking; hybrid
   vision-based camera tracking; model-based camera tracking; augmented
   reality
ID POINT
AB Model-based camera tracking is a technology that estimates a precise camera pose based on visual cues (e.g., feature points, edges) extracted from camera images given a 3D scene model and a rough camera pose. This paper proposes an automatic method for flexibly adjusting the confidence of visual cues in model-based camera tracking. The adjustment is based on the conditions of the target object/scene and the reliability of the initial or previous camera pose. Under uncontrolled or less-controlled working environments, the proposed object-adaptive tracking method works flexibly at 20 frames per second on an ultra mobile personal computer (UMPC) with an average tracking error within 3 pixels when the camera image resolution is 320 by 240 pixels. This capability enabled the proposed method to be successfully applied to a mobile augmented reality (AR) guidance system for a museum. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Seo, Byung-Kuk; Park, Jong-Il] Hanyang Univ, Dept Elect & Comp Engn, Seoul 133791, South Korea.
C3 Hanyang University
RP Park, JI (corresponding author), Hanyang Univ, Dept Elect & Comp Engn, 17 Haengdang Dong, Seoul 133791, South Korea.
EM jipark@hanyang.ac.kr
CR [Anonymous], Open computer vision library
   Belta C, 2002, P I MECH ENG C-J MEC, V216, P47, DOI 10.1243/0954406021524909
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dornaika F, 1999, REAL-TIME IMAGING, V5, P215, DOI 10.1006/rtim.1997.0117
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Lepetit V, 2004, PROC CVPR IEEE, P244
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170
   Rigau Jaume., 2005, Proceedings of the First Eurographics conference on Computational Aesthetics in Graphics, Visualization and Imaging, P177, DOI [10.2312/COMPAESTH/COMPAESTH05/177-184, DOI 10.2312/COMPAESTH/COMPAESTH05/177-184, DOI 10.2312/COMPAESTH/COMPAESTH05/177184]
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53
   SNYDER JM, 1987, ACM SIGGRAPH COMPUTE, V21, P119
   Vacchetti L., 2005, P IEEE ACM INT S MIX, P62
NR 15
TC 3
Z9 3
U1 2
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2010
VL 21
IS 2
SI SI
BP 69
EP 79
DI 10.1002/cav.321
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 586CJ
UT WOS:000276878600002
DA 2024-07-18
ER

PT J
AU Bao, K
   Zhang, H
   Zheng, LL
   Wu, EH
AF Bao, Kai
   Zhang, Hui
   Zheng, Lili
   Wu, Enhua
TI Pressure corrected SPH for fluid animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE Smoothed Particle Hydrodynamics; pressure correction; fluid animation;
   equation of state
ID FLOWS; SIMULATION
AB We present a novel pressure correction scheme for the Smoothed Particle Hydrodynamics (SPH) for fluid animation. In the conventional SPH method, equations of state (EOS) are employed to relate the pressure to the particle density. To enforce the volume conservation, high speeds of sound are usually required, which leads to very small time steps and noisy pressure distribution. The problem remains one of the main reasons of numerical instability in SPH. In the paper, a new extra pressure correction scheme is proposed to transport the local pressure disturbance to the neighboring area and no solution of the Poisson equation is required. As a result, smoother pressure distribution and more efficient simulation are achieved. The proposed method has been used to simulate free surface problems. The results demonstrate the validation of the present SPH method. Surface tension and fluid fragmentation can be Well handled. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Bao, Kai] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
   [Zhang, Hui] Tsinghua Univ, Ctr Publ Safety Res, Beijing, Peoples R China.
   [Zheng, Lili] Tsinghua Univ, Sch Aerosp, Beijing, Peoples R China.
   [Wu, Enhua] Univ Macau, Taipa, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Tsinghua
   University; Tsinghua University; University of Macau
RP Bao, K (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, POB 8718, Beijing 100190, Peoples R China.
EM baokai@ios.ac.cn
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   [Anonymous], P ACM SIGGRAPH EUR S
   Batchelor G., 1967, INTRO FLUID DYNAMICS
   BRACKBILL JU, 1992, J COMPUT PHYS, V100, P335, DOI 10.1016/0021-9991(92)90240-Y
   Clavet S., 2005, SCA '05, P219, DOI DOI 10.1145/1073368.1073400
   Cleary PW, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239548, 10.1145/1276377.1276499]
   Colin F, 2006, J COMPUT PHYS, V217, P680, DOI 10.1016/j.jcp.2006.01.021
   Cummins SJ, 1999, J COMPUT PHYS, V152, P584, DOI 10.1006/jcph.1999.6246
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Keiser R., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P125, DOI 10.1109/PBG.2005.194073
   Lee ES, 2008, J COMPUT PHYS, V227, P8417, DOI 10.1016/j.jcp.2008.06.005
   Liu YQ, 2005, VISUAL COMPUT, V21, P727, DOI 10.1007/s00371-005-0314-2
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   MONAGHAN JJ, 1994, J COMPUT PHYS, V110, P399, DOI 10.1006/jcph.1994.1034
   Morris JP, 2000, INT J NUMER METH FL, V33, P333, DOI 10.1002/1097-0363(20000615)33:3<333::AID-FLD11>3.0.CO;2-7
   Morris JP, 1997, J COMPUT PHYS, V136, P214, DOI 10.1006/jcph.1997.5776
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Muller M., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, P154
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   Premoze S, 2003, COMPUT GRAPH FORUM, V22, P401, DOI 10.1111/1467-8659.00687
   Shao SD, 2003, ADV WATER RESOUR, V26, P787, DOI 10.1016/S0309-1708(03)00030-7
   Solenthaler B., 2008, P 2008 ACM SIGGRAPH, P211, DOI 10.2312/SCA/SCA08/211-218
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
NR 28
TC 9
Z9 14
U1 0
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 311
EP 320
DI 10.1002/cav.299
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700024
DA 2024-07-18
ER

PT J
AU Van Laerhoven, T
   Di Fiore, F
   Van Reeth, F
AF Van Laerhoven, Tom
   Di Fiore, Fabian
   Van Reeth, Frank
TI Hand-painted animation with intelligent brushes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE stylised animation; paint systems; painterly animation; interaction
   techniques; computer-assisted animation
AB In this paper we argue for the concept of brushes and pigments enhanced with behavioural intelligence as a complement to established 2D computer animation techniques. Our approach allows the user to enrich and animate interactively created images by semi-autonomously embedding procedural animation into them. This way, artistic skills of trained animators become within reach of everyone in the digital world, even to completely novice users. To exemplify this concept, we elaborate on several special-purpose brushes and animated pigment for painting with animation. These include a programmable semi-autonomous brush used to paint variations of strokes in successive frames (e.g. flames of fire), the moving-dab brush which enables dabs of paint to follow a user-defined path (e.g. smoke puffs) and animated pigment to produce secondary motion such as vibrant or waving paint textures. We believe our system offers a new fresh perspective on 2D computer aided animation production and associated tools. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Van Laerhoven, Tom] Hasselt Univ, Expertise Ctr Digital Media, TUL IBBT, B-3590 Diepenbeek, Belgium.
   [Di Fiore, Fabian] Univ Antwerp, B-2020 Antwerp, Belgium.
   [Van Reeth, Frank] Hasselt Univ, Expertise Ctr Digital Media EDM, B-3590 Diepenbeek, Belgium.
C3 Hasselt University; University of Antwerp; Hasselt University
RP Van Laerhoven, T (corresponding author), Hasselt Univ, Expertise Ctr Digital Media, TUL IBBT, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
EM tom.vanlaerhoven@uhasselt.be
OI VAN REETH, Frank/0000-0002-3705-7807; Di Fiore,
   Fabian/0000-0003-4908-0673
CR Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   *COR, 2008, COR PAINT X
   Kerlow IsaacVictor ., 2004, The art of 3D computer animation and effects
   ROZIN D, 1998, EASEL
   ROZIN D, 2003, PAINT CAM
   RYOKAI K, 2005, C HUM FACT COMP SYST, P1037
   Ryokai K., 2004, CHI 04, P303, DOI DOI 10.1145/985692.985731
   Tzafestas E. S., 2000, P 2000 ACM WORKSH MU, P39, DOI [10.1145/357744.357756, DOI 10.1145/357744.357756]
   Van Laerhoven T, 2005, COMPUT ANIMAT VIRT W, V16, P429, DOI 10.1002/cav.95
   Van Laerhoven T, 2007, VISUAL COMPUT, V23, P763, DOI 10.1007/s0037l-007-0158-z
   Whitaker H., 1981, Timing for Animation
   2008, ARTRANGE
   2008, PROJECT DOGWAFFLE
NR 13
TC 0
Z9 0
U1 6
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 365
EP 374
DI 10.1002/cav.257
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200019
DA 2024-07-18
ER

PT J
AU Hu, JW
   Liu, LG
   Wang, GZ
AF Hu, Jianwei
   Liu, Ligang
   Wang, Guozhao
TI Dual Laplacian morphing for triangular meshes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE mesh morphing; Laplacian coordinates; vertex path problem; dual mesh
AB Recently, animations with deforming objects have been frequently used in various computer graphics applications. Morphing of objects is one of the techniques which realize shape transformation between two or more existing objects. In this paper, we present a novel morphing approach for 3D triangular meshes with the same topology. The basic idea of our method is to interpolate the mean curvature flow of the input meshes as the curvature flow Laplacian operator encodes the intrinsic local information of the mesh. The in-between meshes are recovered from the interpolated mean curvature flow in the dual mesh domain due to the simplicity of the neighborhood structure of dual mesh vertices. Our approach can generate visual pleasing and physical plausible morphing sequences and avoid the shrinkage and kinks appeared in the linear interpolation method. Experimental results are presented to show the applicability and flexibility of our approach. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, Dept Math, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Liu, LG (corresponding author), Zhejiang Univ, Dept Math, Hangzhou 310027, Peoples R China.
EM ligangliu@zju.edu.cn
CR Alexa M, 2003, VISUAL COMPUT, V19, P105, DOI 10.1007/s00371-002-0180-0
   Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   Alexa M, 2000, VISUAL COMPUT, V16, P26, DOI 10.1007/PL00007211
   ALEXA M, 2002, COMPUT GRAPH FORUM, V21, P373
   AU OK, 2005, HKUSTCS0510 HONG KON
   Au OKC, 2006, IEEE T VIS COMPUT GR, V12, P386, DOI 10.1109/TVCG.2006.47
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   FRANCIS L, 1998, VISUAL COMPUT, V14, P373
   Fu H., 2005, PROC PACIFIC GRAPHIC, P100
   GAO P, 1993, P SIGGRAPH, P15
   GIUSEPPE P, 2003, IMA C MATH SURFACES, P111
   JONAS G, 1998, WARPING MORPHING GRA
   Kanai T, 2000, IEEE COMPUT GRAPH, V20, P62, DOI 10.1109/38.824544
   KENT JR, 1992, COMP GRAPH, V26, P47, DOI 10.1145/142920.134007
   Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811
   Lee AWF, 1999, COMP GRAPH, P343, DOI 10.1145/311535.311586
   Liu LG, 1999, COMPUT GRAPH-UK, V23, P535, DOI 10.1016/S0097-8493(99)00072-2
   Praun E, 2001, COMP GRAPH, P179, DOI 10.1145/383259.383277
   Schreiner J, 2004, ACM T GRAPHIC, V23, P870, DOI 10.1145/1015706.1015812
   SHAPIRA M, 1995, IEEE COMPUT GRAPH, V15, P44, DOI 10.1109/38.365005
   SHEFFER A, 2004, P INT S 3D DAT PROC
   Sorkine O, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P191, DOI 10.1109/SMI.2004.1314506
   Sorkine O., 2004, P 2004 EUR ACM SIGGR, P179
   Sun YM, 1997, J VISUAL COMP ANIMAT, V8, P81, DOI 10.1002/(SICI)1099-1778(199703)8:2<81::AID-VIS163>3.0.CO;2-W
   Surazhsky V., 2003, International Journal of Shape Modeling, V9, P191, DOI 10.1142/S0218654303000115
   Taubin G., 1995, P 22 ANN C COMP GRAP, P351, DOI DOI 10.1145/218380.218473
   XU D, 2005, P ACM S SOL PHYS MOD
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zhang L, 2006, LECT NOTES COMPUT SC, V4035, P160
   Zöckler M, 2000, VISUAL COMPUT, V16, P241, DOI 10.1007/PL00013396
NR 30
TC 21
Z9 22
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 271
EP 277
DI 10.1002/cav.182
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000006
DA 2024-07-18
ER

PT J
AU Guerra, G
   Aloimonos, Y
AF Guerra-Filho, Gutemberg
   Aloimonos, Yiannis
TI Understanding visuo-motor primitives for motion synthesis and analysis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE visuo-motor primitives; motion synthesis; compression
ID CAPTURE DATA
AB The problem addressed in this paper concerns the representation of human movement in terms of atomic visuo-motor primitives considering both generation and perception of movement. We introduce the concept of kinetology, the phonology of human movement, and five principles on which such a system should be based: compactness, view-invariance, reproducibility, selectivity, and reconstructivity. We propose visuo-motor primitives and demonstrate their kinetological properties. Further evaluation is accomplished with experiments on compression and decompression. Our long-term goal is to demonstrate that action has a space characterized by a visuo-motor language. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Univ Maryland, Dept Comp Sci, Comp Vis Lab, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Guerra, G (corresponding author), Univ Maryland, Dept Comp Sci, Comp Vis Lab, College Pk, MD 20742 USA.
EM guerra@cs.umd.edu
RI Aloimonos, Yiannis/AAI-2969-2020
OI Aloimonos, Yiannis/0000-0002-8152-4281
CR AHMED A, 2002, P EUROGRAPHICS C SAA
   [Anonymous], P AAAI 2005 FALL S A
   Assa J, 2005, ACM T GRAPHIC, V24, P667, DOI 10.1145/1073204.1073246
   Barbic J, 2004, PROC GRAPH INTERF, P185
   BILLARD A, 2001, ROBOTICS AUTONOMOUS, V41, P1
   CAELLI T, 2001, P INT WORKSH VIS FOR, P24
   Chenevière F, 2004, INT C PATT RECOG, P541, DOI 10.1109/ICPR.2004.1333829
   ETOU H, 2004, P IEEE INT C MULT EX, V2, P1435
   Fod A, 2002, AUTON ROBOT, V12, P39, DOI 10.1023/A:1013254724861
   Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593
   Glenberg AM, 2002, PSYCHON B REV, V9, P558, DOI 10.3758/BF03196313
   Ilg W., 2004, International Journal of Humanoid Robotics, V1, P613
   Kahol K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P883, DOI 10.1109/AFGR.2004.1301645
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   Lim IS, 2001, P ANN INT IEEE EMBS, V23, P1167
   Mataric MJ, 2002, FROM ANIM ANIMAT, P391
   MCGEE V, 1978, MULTIVARIATE BEHAV R, V23, P233
   Mezger J., 2005, P 2 S APPL PERCEPTIO, V95, P25, DOI DOI 10.1145/1080402.1080406
   Mori T, 2001, ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P200, DOI 10.1109/ROMAN.2001.981902
   Naka T., 1999, Proceedings VRML 99. Fourth Symposium on the Virtual Reality Modeling Language, P63, DOI 10.1145/299246.299264
   Nakazawa A, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2539, DOI 10.1109/IRDS.2002.1041652
   Nishitani N, 2005, PHYSIOLOGY, V20, P60, DOI 10.1152/physiol.00043.2004
   Rao C, 2001, PROC CVPR IEEE, P316
   Saux E, 1999, COMPUT AIDED DESIGN, V31, P507, DOI 10.1016/S0010-4485(99)00049-4
   Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3
   Sudarsky S, 1998, LECT NOTES ARTIF INT, V1537, P55
   Togawa H, 2005, 11TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS WORKSHOPS, VOL II, PROCEEDINGS,, P182
   Wang TS, 2001, LECT NOTES COMPUT SC, V2195, P174
NR 28
TC 16
Z9 17
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 207
EP 217
DI 10.1002/cav.124
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400008
DA 2024-07-18
ER

PT J
AU Zhu, HB
   Liu, XH
   Liu, YQ
   Wu, EH
AF Zhu, Hongbin
   Liu, Xuehui
   Liu, Youquan
   Wu, Enhua
TI Simulation of miscible binary mixtures based on lattice Boltzmann method
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE miscible binary mixture; lattice Boltzmann model; graphics processing
   unit; viscosity; diffusion
ID LIQUID-GAS
AB Miscible fluid mixtures, like pouring honey into water, Coca Cola into strong wine, are common phenomena in our daily life. While two miscible fluids are mixed together, their appearances in terms of colors and shapes will change due to their mixing interaction. The interaction between the mixture components could be regarded as a combination of the diffusing process and demixing process. If the former dominates the interaction, it is miscible; otherwise, it is immiscible. The complex microscopic interplay between the mixture components makes the simulation highly challenging. So far, there have been some dedicated research in computer graphics dealing With immiscible mixtures, but few works have been done focusing on miscible mixtures. In this paper, for the first time, we introduce a two-fluid lattice Boltzmann method (LBM), called TFLBM, applied to miscible binary mixtures. Different from other similar methods, the viscous and diffusing properties of the fluid in our work are considered separately, so that the physical insight is exposed more clearly and rationally. In addition, the operation of LBM is mostly a linear local computation, and graphics processing unit (GPU) has been utilized to achieve real-time simulation. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS
RP Zhu, HB (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100080, Peoples R China.
EM zhuhb@ios.ac.cn
RI Liu, Youquan/C-1628-2012; Lin, Fan/JZT-1441-2024
OI Lin, Fan/0000-0002-7330-3833
CR BHATNAGAR PL, 1954, PHYS REV, V94, P511, DOI 10.1103/PhysRev.94.511
   CHEN SY, 1994, LATTICE BOLTZMANN FL
   Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   FAN Z, 2005, ACM SIGGRAPH EUR S C, P245
   GUNSTENSEN AK, 1991, PHYS REV A, V43, P4320, DOI 10.1103/PhysRevA.43.4320
   Guo ZL, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.035302
   Guo ZL, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.026701
   Hong JM, 2003, COMPUT GRAPH FORUM, V22, P253, DOI 10.1111/1467-8659.00672
   HONG JM, 2005, P ACM SIGGRAPH 2005, P915
   HOU S, 1996, FIELDS I COMMUNICATI, V6
   HSU SH, 2005, GPGPU PROGRAMMING
   Junk M, 2000, SIAM J SCI COMPUT, V22, P1, DOI 10.1137/S1064827599357188
   Li W., 2005, GPU GEMS 2 CHAPTER 4, P747
   Liu Y, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P247
   Liu YQ, 2005, VISUAL COMPUT, V21, P727, DOI 10.1007/s00371-005-0314-2
   Luo LS, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.036302
   Mizuno R, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P440, DOI 10.1109/PCCGA.2003.1238291
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   PREMOZE S, 2003, EUROGRAPHICS, V22, P401
   SHAN XW, 1994, PHYS REV E, V49, P2941, DOI 10.1103/PhysRevE.49.2941
   Shan XW, 1996, PHYS REV E, V54, P3614, DOI 10.1103/PhysRevE.54.3614
   Swift MR, 1996, PHYS REV E, V54, P5041, DOI 10.1103/PhysRevE.54.5041
   THUREY N, 2004, WORKSH VIS MOD VIS V, P199
   Wei XM, 2004, IEEE T VIS COMPUT GR, V10, P164, DOI 10.1109/TVCG.2004.1260768
   Wei XM, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P227, DOI 10.1109/VISUAL.2002.1183779
   ZHAO Y, 2006, COMPUTERS GRAPHICS, V30
   ZOU Q, 1996, PHYS FLUIDS, V8, P2527
NR 28
TC 31
Z9 41
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 403
EP 410
DI 10.1002/cav.143
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400026
DA 2024-07-18
ER

PT J
AU Jang, KH
   Lee, DH
   Jung, SK
AF Jang, KH
   Lee, DH
   Jung, SK
TI A moving planar mirror based approach for cultural reconstruction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE cultural heritage; camera calibration; structure from motion; vanishing
   point; catadioptric stereo
AB Modelling from images is a cost-effective means of obtaining virtual cultural heritage models. These models can be effectively constructed from classical Structure from Motion algorithm. However, it's too difficult to reconstruct whole scenes using SFM method since general oriental historic sites contain a very complex shapes and brilliant colours. To overcome this difficulty, the current paper proposes a new reconstruction method based on a moving planar mirror. We devise the mirror posture instead of scene itself as a cue for reconstructing the geometry. That implies that the geometric cues are inserted into the scene by compulsion. With this method, we can obtain the geometrical details regardless of the scene complexity. For this purpose, we first capture image sequences through the moving mirror containing the interested scene, and then calibrate the camera through the mirror's posture. Since the calibration results are still inaccurate due to the detection error, the camera pose is revised using frame-correspondence of the corner points that are easily obtained using the initial camera posture. Finally, 3D information is computed from a set of calibrated image sequences. We validate our approach with a set of experiments on some cultural heritage objects. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Kyungpook Natl Univ, Dept CE, Taegu 1370, South Korea.
C3 Kyungpook National University
RP Kyungpook Natl Univ, Dept CE, Taegu 1370, South Korea.
EM khjang@vr.knu.ac.kr
RI Jung, Soon Ki/P-7687-2018
OI Jung, Soon Ki/0000-0003-0239-6785
CR [Anonymous], 1999, COMPUT GRAPH FORUM
   AYACHE N, 1988, P INT C PATT REC, P11
   Beardsley PA, 1997, INT J COMPUT VISION, V23, P235, DOI 10.1023/A:1007923216416
   CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813
   CIPOLLA R, 1999, P BRIT MACH VIS C, P382
   DIXON R, 1991, MATHOGRAPHICS
   Faugeras O. D., 1987, Proceedings of the International Workshop on Industrial Applications of Machine Vision and Machine Intelligence. Seiken Symposium (Cat. no. 87TH0166-9), P240
   GLUCKMAN J, 1999, P IEEE C COMP VIS PA
   Guillou E, 2000, VISUAL COMPUT, V16, P396, DOI 10.1007/PL00013394
   Haralick R.M., 1993, COMPUTER ROBOT VISIO, V2
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Klette R., 1998, COMPUTER VISION 3 DI, V1st
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705
   POLLEFEYS M, 2000, EUR C COMP VIS
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   WEISSTEIN EW, 1999, THALES THEOREM
NR 16
TC 19
Z9 19
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 415
EP 423
DI 10.1002/cav.45
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700032
DA 2024-07-18
ER

PT J
AU Park, MJ
   Shin, SY
AF Park, MJ
   Shin, SY
TI Example-based motion cloning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE character animation; motion cloning; scattered data interpolation;
   posture clustering
AB In this paper, we pose a motion cloning problem of retargeting the motion of a source character to a target character with a different structure. Based on scattered data interpolation, an example-based approach to motion cloning is proposed. Provided with a set Of example motions, our method automatically extracts a small number of representative postures called source key-postures. The animator then creates the corresponding key-postures of the target character, breathing his/her imagination and creativity into the output animation. Exploiting this correspondence, each input posture is cloned frame by frame to the target character to produce an initial animation, which is further adjusted in space and time for retargeting and timewarping and then finalized with some interactive fine tuning. With rich animation data available, our motion cloning method aims at rapid prototyping of an animation to verify an animator's concept at an early stage. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Korea Adv Inst Sci & Technol, Taejon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Korea Adv Inst Sci & Technol, Taejon, South Korea.
EM mjpark@jupiter.kaist.ac.kr
RI Shin, Sung Yong/C-1955-2011
CR ALLEN B, 2002, P 2001 S INT 3D GRAP, V36, P612
   [Anonymous], CSTR200202 STANF U
   [Anonymous], 2001, P 2001 S INTERACTIVE
   ARIKAN O, 2002, COMPUTER GRAPHICS, V36, P483
   ARIKAN O, 2003, COMPUTER GRAPHICS, V37, P402
   Berkhin P., 2002, SURVEY CLUSTERING DA
   BRAND M, 1999, COMPUTER GRAPHICS, V33, P78
   BREGLER C, 2002, COMPUTER GRAPHICS, V36, P399
   BUCK I, 2000, P S NONPH AN REND
   CHEN SE, 1993, COMPUTER GRAPHICS, V27, P279
   DONTCHEVA M, 2000, COMPUTER GRAPHICS, V37, P409
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   FIDALEO D, 2000, P INT WORKSH DIG COM
   Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578
   Gildfind A, 2000, J VISUAL COMP ANIMAT, V11, P169, DOI 10.1002/1099-1778(200009)11:4<169::AID-VIS217>3.0.CO;2-L
   GLEICHER M, 1998, COMPUTER GRAPHICS, V32, P33
   Jollife I., 1986, PRINCIPAL COMPONENT
   KALRA P, 1992, P EUROGRAPHICS, V92, P59
   KOVAR L, 2002, COMPUTER GRAPHICS, V36, P473
   KWATRA V, 2003, COMPUTER GRAPHICS, V37, P277
   Lee J, 1999, COMP GRAPH, P39
   LEE J, 2002, COMPUTER GRAPHICS, V36, P491
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   LIU CK, 2002, COMPUTER GRAPHICS, V36, P408
   NGO T, 2000, COMPUTER GRAPHICS, V34, P389
   NOH JY, 2001, P 2001 S INT 3D GRAP, V35, P277
   PARK SI, 2002, ACM S COMPUTER ANIMA, P73
   PIGHIN F, 1998, ANN C SERIES, V32, P75
   PYUN H, 2003, ACM SIGGRAPH EUR S C, P167
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   WEI LY, 2002, P 2001 S INT 3D GRAP, V34, P479
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
NR 34
TC 36
Z9 43
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 245
EP 257
DI 10.1002/cav.27
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700014
DA 2024-07-18
ER

PT J
AU Ferre, M
   Puig, A
   Tost, D
AF Ferre, Maria
   Puig, Anna
   Tost, Dani
TI A framework for fusion methods and rendering techniques of multimodal
   volume data
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE visualization; volume rendering; medical applications; multimodal data
AB Many different direct volume rendering methods have been developed to visualize 3D scalar fields on uniform rectilinear grids. However, little work has been done on rendering simultaneously various properties of the same 3D region measured with different registration devices or at different instants of time. The demand for this type of visualization is rapidly increasing in scientific applications such as medicine in which the visual integration of multiple modalities allows a better comprehension of the anatomy and a perception of its relationships with activity. This paper presents different strategies of direct multimodal volume rendering (DMVR). It is restricted to voxel models With a known 3D rigid alignment transformation. The paper evaluates at Which steps of the rendering pipeline the data fusion must be realized in order to accomplish the desired visual integration and to provide fast re-renders When sonic fusion parameters are modified. In addition, it analyses how existing monomodal visualization algorithms can be extended to multiple datasets and it compares their efficiency and their computational cost. Copyright (C) 2004 John Wiley & Sons, Ltd.
C1 [Ferre, Maria] URV, Dep Ingn Informat & Matemat, Tarragona 43007, Spain.
   [Puig, Anna; Tost, Dani] Polytech Univ Catalonia Barcelona, Comp Graph Sect, Barcelona, Spain.
C3 Universitat Rovira i Virgili; Universitat Politecnica de Catalunya
RP Ferre, M (corresponding author), URV, Dep Ingn Informat & Matemat, Av Paisos Catalans, Tarragona 43007, Spain.
EM mferre@etse.urv.es
RI Puig, Anna/ADI-9599-2022; Tost, Dani/H-6289-2015
OI Puig, Anna/0000-0002-2184-2800; Tost, Dani/0000-0001-9619-605X
FU Ministerio de Educacion v Ciencia;  [TIC 99-1230-C02-02]; 
   [MAT2002-04297-C03-02]
FX Contract/grant sponsor: Ministerio de Educacion v Ciencia.
   Contract/grant number: TIC 99-1230-C02-02. Contract/grant number:
   MAT2002-04297-C03-02.
CR Barra V, 2001, NEUROIMAGE, V13, P410, DOI 10.1006/nimg.2000.0707
   Cai WL, 1999, COMPUT GRAPH FORUM, V18, pC359, DOI 10.1111/1467-8659.00356
   CHEN M, 1996, 1 EUR WORKSH PAR GRA, P173
   Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484
   ECKEL G, 1999, OPENGL VOLUMIZER PRO
   Ferré M, 2001, METMBS'01: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MATHEMATICS AND ENGINEERING TECHNIQUES IN MEDICINE AND BIOLOGICAL SCIENCES, P73
   HAWKES DJ, 1990, NATO ADV SCI I F-COM, V60, P241
   Kreeger K. A., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P191, DOI 10.1109/VISUAL.1999.809887
   LACROUTE P, 1994, ACM COMPUTER GRAPHIC, V28, P451
   LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965
   Lichtenbelt Barthold, 1998, Introduction to Volume Rendering
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Meissner M., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P207, DOI 10.1109/VISUAL.1999.809889
   MEISSNER M, 2000, P 2000 IEEE S VOL VI, P81
   PELIZZARI CA, 1989, J COMPUT ASSIST TOMO, V13, P20, DOI 10.1097/00004728-198901000-00004
   Puig A, 2000, SPRING COMP SCI, P125
   SPETSIERIS PG, 1995, INTERACTIVE VISUALIZ, P58
   TIEDE U, P IEEE VIS 1998, P255
   TOST D, 2002, LSI0238R
   VANDERELSEN P, 1993, THESIS UTRECHT U
   VanGelder A, 1996, 1996 SYMPOSIUM ON VOLUME VISUALIZATION, PROCEEDINGS, P23, DOI 10.1109/SVV.1996.558039
   Westover L., 1990, Computer Graphics, V24, P367, DOI 10.1145/97880.97919
   WILHELMS J, 1991, COMP GRAPH, V25, P275, DOI 10.1145/127719.122758
   YAGEL R, 1992, IEEE COMPUT GRAPH, V12, P19, DOI 10.1109/38.156009
   Zuiderveld KJ, 1996, COMPUT GRAPH-UK, V20, P775, DOI 10.1016/S0097-8493(96)00050-7
NR 26
TC 13
Z9 24
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2004
VL 15
IS 2
BP 63
EP 77
DI 10.1002/cav.1
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA V10FD
UT WOS:000207449000002
DA 2024-07-18
ER

PT J
AU Xiong, Y
   Chen, T
   Li, TJ
   Zhou, Z
AF Xiong, Yuan
   Chen, Tong
   Li, Tianjing
   Zhou, Zhong
TI DreamWalk: Dynamic remapping and multiperspectivity for large-scale
   redirected walking
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dynamic mapping; locomotion; multiperspectivity; redirected walking;
   virtual reality
AB Redirected walking (RDW) provides an immersive user experience in virtual reality applications. In RDW, the size of the physical play area is limited, which makes it challenging to design the virtual path in a larger virtual space. Mainstream RDW approaches rigidly manipulate gains to guide the user to follow predetermined rules. However, these methods may cause simulator sickness, boundary collision, and reset. Static mapping approaches warp the virtual path through expensive vertex replacement in the stage of model pre-processing. They are restricted to narrow spaces with non-looping pathways, partition walls, and planar surfaces. These methods fail to provide a smooth walking experience for large-scale open scenes. To tackle these problems, we propose a novel approach that dynamically redirects the user to walk in a non-linear virtual space. More specifically, we propose a Bezier-curve-based mapping algorithm to warp the virtual space dynamically and apply multiperspective fusion for visualization augmentation. We conduct comparable experiments to show its superiority over state-of-the-art large-scale redirected walking approaches on our self-collected photogrammetry dataset.
C1 [Xiong, Yuan; Chen, Tong; Li, Tianjing; Zhou, Zhong] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Zhou, Zhong] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Zhou, Z (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM zz@buaa.edu.cn
OI Xiong, Yuan/0000-0002-7253-4998; chen, tong/0009-0009-2843-7283; Zhou,
   Zhong/0000-0002-5825-7517
FU Natural Science Foundation of China [62272018]
FX ACKNOWLEDGMENTS The authors thank Ligang Liu for his insightful feedback
   and comments. This work is supported by the Natural Science Foundation
   of China under grant no. 62272018.
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300589
   Azmandian M., 2016, 2016 IEEE S 3D US IN
   Barker S, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CONTROL, AND COMPUTING TECHNOLOGIES FOR SMART GRIDS (SMARTGRIDCOMM), DOI 10.1109/smartgridcomm.2019.8909725
   Bowman DA, 2002, PRESENCE-TELEOP VIRT, V11, P404, DOI 10.1162/105474602760204309
   Cao AL, 2020, IEEE INT CONF COMM, DOI 10.1109/iccworkshops49005.2020.9145063
   Chen SY, 2022, IEEE T VIS COMPUT GR, V28, P4685, DOI 10.1109/TVCG.2021.3099012
   Cheng LP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P359, DOI [10.1109/VR.2019.8798074, 10.1109/vr.2019.8798074]
   Cho YH., 2021, P 2021 IEEE VIRT REA
   Dong T., 2021, P 2021 IEEE VIRT REA
   DONG Z., 2017, ACM T GRAPHIC, V36, P1
   Dong ZC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3345554
   Feigl T, 2019, IEEE T VIS COMPUT GR, V25, P3146, DOI 10.1109/TVCG.2019.2932224
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Hu P, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356490
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim D, 2021, INT RELIAB PHY SYM, DOI 10.1109/IRPS46558.2021.9405109
   Korhonen J, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9455974
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Mingliang W., 2017, P 2017 IEEE TRANSPOR, DOI [10.1109/ITEC-AP.2017.8080799, DOI 10.1109/ITEC-AP.2017.8080799]
   Mortenson M. E., 1999, Mathematics for computer graphics applications
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Razzaque S., 2002, EGV 2
   Rietzler M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376821
   Serrano A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417773
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Sugamoto N., 2019, SA 19 EMERGING TECHN, P2
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Wang L., 2021, P 2021 IEEE VIRT REA
   Wang LL, 2019, IEEE T VIS COMPUT GR, V25, P2083, DOI 10.1109/TVCG.2019.2898782
   Xu SZ, 2022, IEEE T VIS COMPUT GR, V28, P3778, DOI 10.1109/TVCG.2022.3203095
   Xu SZ., 2022, 2022 IEEE C VIRT REA
   Yang J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1093, DOI 10.1145/3332165.3347875
   Zhang SH., 2023, IEEE T VIS COMPUT GR
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P2080, DOI 10.1109/TVCG.2021.3139990
NR 37
TC 0
Z9 0
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2196
EA JUL 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001022120500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shang, XM
   Xu, TY
   Karamouzas, I
   Kallmann, M
AF Shang, Xiumin
   Xu, Tengyu
   Karamouzas, Ioannis
   Kallmann, Marcelo
TI Constraint-based multi-agent reinforcement learning for collaborative
   tasks
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE collaborative tasks; multi-agent; reinforcement learning; tray balancing
   task; virtual human animation
AB In order to be successfully executed, collaborative tasks performed by two agents often require a cooperative strategy to be learned. In this work, we propose a constraint-based multi-agent reinforcement learning approach called constrained multi-agent soft actor critic (C-MSAC) to train control policies for simulated agents performing collaborative multi-phase tasks. Given a task with n$$ n $$ phases, the first n-1$$ n-1 $$ phases are treated as constraints for the final task phase objective, which is addressed with a centralized training and decentralized execution approach. We highlight our framework on a tray balancing task including two phases: tray lifting and cooperative tray control for target following. We evaluate our proposed approach and compare it against its unconstrained variant (MSAC). The performed comparisons show that C-MSAC leads to higher success rates, more robust control policies, and better generalization performance.
C1 [Shang, Xiumin; Kallmann, Marcelo] Univ Calif Merced, Sch Engn, Dept Comp Sci, Merced, CA 95343 USA.
   [Xu, Tengyu] Meta Platform Inc, Menlo Pk, CA USA.
   [Karamouzas, Ioannis] Clemson Univ, Sch Comp, Clemson, SC USA.
   [Kallmann, Marcelo] Amazon Robot, Boston, MA USA.
C3 University of California System; University of California Merced;
   Clemson University
RP Shang, XM (corresponding author), Univ Calif Merced, Sch Engn, Dept Comp Sci, Merced, CA 95343 USA.
EM xshang@ucmerced.edu
CR Achiam J., P 34 INT C MACH LEAR
   Andrychowicz M, 2020, INT J ROBOT RES, V39, P3, DOI 10.1177/0278364919887447
   Babadi A., P 12 ACM SIGGRAPH C
   Baker Bowen., 2019, Emergent Tool Use From Multi-Agent Autocurricula
   Bellemare MG, 2013, J ARTIF INTELL RES, V47, P253, DOI 10.1613/jair.3912
   Brockman G., OPENAI GYM ARXIV PRE
   Chen Z., 2016, SYNTH LECT ARTIF INT, V10, P1, DOI DOI 10.2200/S00737ED1V01Y201610AIM033
   Cheng ZP, 2022, COMPUT COMMUN, V192, P234, DOI 10.1016/j.comcom.2022.06.017
   Florensa C., STOCHASTIC NEURAL NE
   Foerster J., P 32 AAAI C ART INT
   García J, 2015, J MACH LEARN RES, V16, P1437
   Haarnoja T., P 35 INT C MACH LEAR
   Hundt A, 2020, IEEE ROBOT AUTOM LET, V5, P6724, DOI 10.1109/LRA.2020.3015448
   Iqbal S., Proceedings of the 36th international conference on machine learning
   Juliani A., 2018, ARXIV180902627
   Kucuk Serdar, 2006, Robot Kinematics: Forward and Inverse Kinematics, Industrial Robotics: Theory, Modelling and Control
   Kurach K., GOOGLE RES FOOTBALL
   Lowe R., P 31 C NEUR INF PROC
   Lu HF, 2020, IEEE ACCESS, V8, P202573, DOI 10.1109/ACCESS.2020.3036416
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Nachum O., P 32 C NEUR INF PROC
   Nachum O., MULTI AGENT MANIPULA
   OpenAI, 2020, Robogym
   Osborne Martin J, 1994, COURSE GAME THEORY
   Peng XB, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275014
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Rashid T., P 35 INT C MACH LEAR
   Schulman J., 2017, ARXIV
   Tampuu A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172395
   Tassa Y., Continuous Control with Deep Reinforcement Learning
   Turchetta M, 2016, ADV NEUR IN, V29
   Vrancx P, 2008, IEEE T SYST MAN CY B, V38, P976, DOI 10.1109/TSMCB.2008.920998
   Won J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459761
   Wu XW, 2021, IEEE T COMMUN, V69, P5886, DOI 10.1109/TCOMM.2021.3086535
   Xu T., P 38 INT C MACH LEAR
   Yang HY, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3320283
   Yang Y., P 35 INT C MACH LEAR
   Yu C., 2022, Advances in Neural Information Processing Systems, V35, P24611, DOI DOI 10.48550/ARXIV.2103.01955
NR 38
TC 0
Z9 0
U1 5
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2182
EA MAY 2023
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000993002300001
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, SG
   Yin, MX
   Li, M
   Li, GQ
   Chang, K
   Yang, F
AF Yang, Shigeng
   Yin, Mengxiao
   Li, Ming
   Li, Guiqing
   Chang, Kan
   Yang, Feng
TI 3D mesh pose transfer based on skeletal deformation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deep learning; pose transfer; skeleton extraction; skinning deformation
AB For 3D mesh pose transfer, the target model is obtained by transferring the pose of the reference mesh to the source mesh, where the shape and pose of the source are usually different from that of the reference. In this paper, pose transfer is considered as a deformation process of the source mesh, and we propose a 3D mesh pose transfer method based on skeletal deformation. First, we design a neural network based on the edge convolution operator to extract the skeleton of the 3D mesh and bind the rigid weights; then, we calculate the bone transformations between the two skeletons with different poses and use the diffusion equation to smooth the rigid weights; finally, the source mesh is deformed according to the bone transformations and the smooth weights to get the target mesh. Experiment results on different datasets show that the pose of the reference mesh can be effectively transferred to the source one while maintaining the shape and high-quality geometric details of the source mesh by using our method.
C1 [Yang, Shigeng; Yin, Mengxiao; Li, Ming; Chang, Kan; Yang, Feng] Guangxi Univ, Sch Comp Elect & Informat, Nanning, Guangxi, Peoples R China.
   [Yin, Mengxiao; Chang, Kan; Yang, Feng] Guangxi Univ, Guangxi Key Lab Multimedia Commun Network Technol, Nanning, Guangxi, Peoples R China.
   [Li, Guiqing] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
   [Yin, Mengxiao] Guangxi Univ, Sch Comp Elect & Informat, Nanning 530004, Guangxi, Peoples R China.
C3 Guangxi University; Guangxi University; South China University of
   Technology; Guangxi University
RP Yin, MX (corresponding author), Guangxi Univ, Sch Comp Elect & Informat, Nanning 530004, Guangxi, Peoples R China.
EM ymx@gxu.edu.cn
RI 常, 侃/AGP-4123-2022
OI 常, 侃/0000-0002-6587-0360; Yang, Shigeng/0009-0000-9062-6506
FU National Natural Science Foundation of China [61972160, 62171145]
FX ACKNOWLEDGMENTS This work has received partial support from the National
   Natural Science Foundation of China under Grants 61972160 and 62171145.
CR Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Basset J, 2021, INT CONF 3D VISION, P545, DOI 10.1109/3DV53792.2021.00064
   Basset J, 2020, COMPUT GRAPH-UK, V89, P11, DOI 10.1016/j.cag.2020.04.002
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   Le BH, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322982
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Cosmo Luca, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P19, DOI 10.1007/978-3-030-58580-8_2
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Jacobson A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964973
   Keyang Zhou, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P341, DOI 10.1007/978-3-030-58542-6_21
   Kovnatsky A, 2013, COMPUT GRAPH FORUM, V32, P439, DOI 10.1111/cgf.12064
   Kulpa R, 2005, COMPUT GRAPH FORUM, V24, P343, DOI 10.1111/j.1467-8659.2005.00859.x
   Le BH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601161
   Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66
   Li PZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459852
   Liao Z, 2022, LECT NOTES COMPUT SC, V13662, P640, DOI 10.1007/978-3-031-20086-1_37
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Magnenat-Thalmann N., 1989, P GRAPHICS INTERFACE, P26, DOI [10.5555/102313.102317, DOI 10.5555/102313.102317]
   Mancewicz Joe., 2014, Proceedings of the Fourth Symposium on Digital Production. DigiPro'14, P7, DOI DOI 10.1145/2633374.2633376
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pons-Moll G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766993
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Song CY, 2023, IEEE T PATTERN ANAL, V45, P10488, DOI 10.1109/TPAMI.2023.3259059
   Song Chaoyue, 2021, ADV NEURAL INF PROCE, P3108
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Wampler K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982433
   Wang JS, 2020, PROC CVPR IEEE, P5830, DOI 10.1109/CVPR42600.2020.00587
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Xu Z, 2020, Arxiv, DOI arXiv:2005.00559
   Yin MX, 2015, COMPUT AIDED GEOM D, V35-36, P82, DOI 10.1016/j.cagd.2015.03.016
   Yu Wang, 2021, ACM Transactions on Graphics, V40, DOI 10.1145/3450626.3459801
   Zuffi S, 2017, PROC CVPR IEEE, P5524, DOI 10.1109/CVPR.2017.586
NR 36
TC 1
Z9 1
U1 2
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2156
EA MAY 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000985795200001
DA 2024-07-18
ER

PT J
AU Wang, XK
   Wang, TC
   Wang, JM
   Xu, YR
   Ban, XJ
   Huang, HB
   Zhu, ZH
   Chang, J
   Zhang, JJ
AF Wang, Xiaokun
   Wang, Tiancheng
   Wang, Jiamin
   Xu, Yanrui
   Ban, Xiaojuan
   Huang, Houbin
   Zhu, Zhihong
   Chang, Jian
   Zhang, Jian Jun
TI Implicit smoothed particle hydrodynamics model for simulating
   incompressible fluid-elastic coupling
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE elastic simulation; fluid-solid coupling; multiple fluid interaction;
   particle systems; physically based animation
AB Fluid simulation has been one of the most critical topics in computer graphics for its capacity to produce visually realistic effects. The intricacy of fluid simulation manifests most with interacting dynamic elements. The coupling for such scenarios has always been challenging to manage due to the numerical instability arising from the coupling boundary between different elements. Therefore, we propose an implicit smoothed particle hydrodynamics fluid-elastic coupling approach to reduce the instability issue for fluid-fluid, fluid-elastic, and elastic-elastic coupling circumstances. By deriving the relationship between the universal pressure field with the incompressible attribute of the fluid, we apply the number density scheme to solve the pressure Poisson equation for both fluid and elastic material to avoid the density error for multi-material coupling and conserve the non-penetration condition for elastic objects interacting with fluid particles. Experiments show that our method can effectively handle the multiphase fluids simulation with elastic objects under various physical properties.
C1 [Wang, Xiaokun; Wang, Tiancheng; Wang, Jiamin; Xu, Yanrui; Ban, Xiaojuan] Univ Sci & Technol Beijing, Sch Intelligence Sci & Technol, Beijing, Peoples R China.
   [Wang, Xiaokun] Univ Sci & Technol Beijing, Beijing Key Lab Knowledge Engn Mat Sci, Beijing, Peoples R China.
   [Wang, Xiaokun; Chang, Jian; Zhang, Jian Jun] Bournemouth Univ, Natl Ctr Comp Animat, Poole, England.
   [Ban, Xiaojuan] Univ Sci & Technol Beijing, Beijing Adv Innovat Ctr Mat Genome Engn, Beijing, Peoples R China.
   [Ban, Xiaojuan] Univ Sci & Technol Beijing, Key Lab Percept & Control Intelligent Unmanned Sys, Minist Educ, Beijing, Peoples R China.
   [Huang, Houbin] Chinese Peoples Liberat Army Gen Hosp, Beijing, Peoples R China.
   [Zhu, Zhihong] Chinese Peoples Liberat Army Gen Hosp, Hainan Hosp, Sanya, Hainan, Peoples R China.
   [Ban, Xiaojuan] Univ Sci & Technol Beijing, Beijing, Peoples R China.
C3 University of Science & Technology Beijing; University of Science &
   Technology Beijing; Bournemouth University; University of Science &
   Technology Beijing; University of Science & Technology Beijing; Chinese
   People's Liberation Army General Hospital; Chinese People's Liberation
   Army General Hospital; University of Science & Technology Beijing
RP Chang, J (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole, England.; Ban, XJ (corresponding author), Univ Sci & Technol Beijing, Beijing, Peoples R China.
EM banxj@ustb.edu.cn; JChang@bournemouth.ac.uk
RI Xu, Yanrui/KHU-2854-2024; Wang, Xiaokun/AAH-6815-2021
OI Xu, Yanrui/0000-0002-2154-1178; Wang, Xiaokun/0000-0003-4148-5561; Wang,
   Xiaokun/0000-0002-4449-591X
FU Horizon 2020-Marie Sklodowska-Curie Action-Individual Fellowships
   [895941]; Guangdong Basic and Applied Basic Research Foundation
   [2023A1515030177]; Fundamental Research Funds for the Central
   Universities [QNXM20220043]; Key Research and Development Project of
   Hainan Province [ZDYF2020031]; Marie Curie Actions (MSCA) [895941]
   Funding Source: Marie Curie Actions (MSCA)
FX Horizon 2020-Marie Sklodowska-Curie Action-Individual Fellowships,
   Grant/Award Number: 895941; Guangdong Basic and Applied Basic Research
   Foundation, Grant/Award Number: 2023A1515030177; Fundamental Research
   Funds for the Central Universities, Grant/Award Number: QNXM20220043;
   Key Research and Development Project of Hainan Province, Grant/Award
   Number: ZDYF2020031
CR Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Alduán I, 2017, COMPUT GRAPH FORUM, V36, P32, DOI 10.1111/cgf.12992
   Bargteil AW., 2020, INTRO PHYS BASED ANI, P1
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J., 2015, P 14 ACM SIGGRAPH EU, P147, DOI DOI 10.1145/2786784.2786796
   Chen XS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417809
   Fang Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392438
   Ganzenmüller GC, 2015, COMPUT METHOD APPL M, V286, P87, DOI 10.1016/j.cma.2014.12.005
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Jiang CFF, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073623
   Jiang Y, 2020, COMPUT GRAPH FORUM, V39, P69, DOI 10.1111/cgf.14102
   Koschier D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073666
   Kugelstadt T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13520
   Kugelstadt T, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3480142
   Li XS, 2016, IEEE T VIS COMPUT GR, V22, P1973, DOI 10.1109/TVCG.2015.2476788
   Markus Becker, 2009, NPH, V9, P27, DOI [10.2312/EG/DL/conf/EG2009/nph/027-034, DOI 10.2312/EG/DL/CONF/EG2009/NPH/027-034]
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Ott F., 2003, A modified SPH approach for fluids with large density differences
   Peer A, 2018, COMPUT GRAPH FORUM, V37, P135, DOI 10.1111/cgf.13317
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Solenthaler B., 2008, EUR ACM SIGGRAPH S C, P211
   Teschner M, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P312, DOI 10.1109/CGI.2004.1309227
   Wang Xiaokun, 2016, Journal of Computer Aided Design & Computer Graphics, V28, P1497
   Yan X, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925897
   Yang LP, 2012, COMPUT GRAPH FORUM, V31, P2037, DOI 10.1111/j.1467-8659.2012.03196.x
   Yang M, 2019, IEEE T VIS COMPUT GR, V25, P2873, DOI 10.1109/TVCG.2018.2864283
NR 26
TC 1
Z9 1
U1 5
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2146
EA MAR 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000954544900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Yu, ZJ
   Tan, JY
   Li, S
AF Yu, Zhenjing
   Tan, Junyin
   Li, Sheng
TI Simulation of collective pursuit-evasion behavior with runtime
   situational awareness
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE collective behavior; perception; pursuit-evasion; situational awareness
ID SYSTEM; DYNAMICS; EMERGE; WOLVES; SHEEP; WOLF
AB We present a simulation method of pursuit-evasion behaviors between different herds with runtime situational awareness. We model the collective movement of predators and prey in the hunting process based on an improved Boid model and the finite state machine involving multiple perception factors about the situations. Taking wolves hunting caribous as an example, our method not only simulates the collective behavior, but also realizes individual intelligent behaviors consistent with the observations. We conducted intensive experiments, and the results show that our method can simulate more realistic pursuit-evasion behavior under different testing scenarios with a variety of parameters. Our method can be easily transferred to the theoretical study of collective behaviors of other herds.
C1 [Yu, Zhenjing; Tan, Junyin; Li, Sheng] Peking Univ, Sch Comp Sci, Beijing, Peoples R China.
   [Li, Sheng] Beijing Engn Technol Res Ctr Virtual Simulat & Vi, Beijing, Peoples R China.
C3 Peking University
RP Li, S (corresponding author), Peking Univ, Sch Comp Sci, Beijing, Peoples R China.
EM lisheng@pku.edu.cn
OI Li, Sheng/0000-0002-8901-2184
FU National Natural Science Foundation of China [62172013]
FX National Natural Science Foundation of China, Grant/Award Number:
   62172013
CR [Anonymous], 1998, VALVE HALF LIFE
   Aouaidjia K., 2019, IEEE T SYST MAN CYB, V51, P2774
   BBC,, WOLF HUNTS CARIBOU
   BREDER CM, 1954, ECOLOGY, V35, P361, DOI 10.2307/1930099
   Cassidy KA, 2015, BEHAV ECOL, V26, P1352, DOI 10.1093/beheco/arv081
   Czirok A, 1996, PHYS REV E, V54, P1791, DOI 10.1103/PhysRevE.54.1791
   de Berg M., 2000, COMPUTATIONAL GEOMET
   Delgado-Mata C, 2007, NEW GENERAT COMPUT, V25, P145, DOI 10.1007/s00354-007-0009-5
   Desai JP, 1998, IEEE INT CONF ROBOT, P2864, DOI 10.1109/ROBOT.1998.680621
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Gazi V, 2004, IEEE T SYST MAN CY B, V34, P539, DOI 10.1109/TSMCB.2003.817077
   Ge J, 2019, CHIN AUTOM CONGR, P967, DOI [10.1109/CAC48633.2019.8996742, 10.1109/cac48633.2019.8996742]
   Ginelli F, 2015, P NATL ACAD SCI USA, V112, P12729, DOI 10.1073/pnas.1503749112
   Grunbaum Daniel, 1994, Lecture Notes in Biomathematics, V100, P296
   GUTMAN S, 1987, COMPUT MATH APPL, V13, P83, DOI 10.1016/0898-1221(87)90095-2
   Hartman C, 2006, COMPUT ANIMAT VIRT W, V17, P199, DOI 10.1002/cav.123
   Hiestand L, 2011, BEHAV GENET, V41, P840, DOI 10.1007/s10519-011-9455-4
   Hsu SB, 2008, DISCRETE CONT DYN-B, V10, P857
   Ishiwaka Y, 2003, ROBOT AUTON SYST, V43, P245, DOI 10.1016/S0921-8890(03)00040-X
   Jadbabaie A, 2003, IEEE T AUTOMAT CONTR, V48, P988, DOI 10.1109/TAC.2003.812781
   Kamel A, 2019, INT J HUM-COMPUT INT, V35, P427, DOI 10.1080/10447318.2018.1543081
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Krieg M, 2010, IEEE T ROBOT, V26, P542, DOI 10.1109/TRO.2010.2046069
   Madden J. D., 2010, 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1043, DOI 10.1109/ROBIO.2010.5723472
   Morrell LJ, 2011, BEHAV ECOL, V22, P16, DOI 10.1093/beheco/arq157
   Muro C, 2011, BEHAV PROCESS, V88, P192, DOI 10.1016/j.beproc.2011.09.006
   Ni JJ, 2018, INT J FUZZY SYST, V20, P672, DOI 10.1007/s40815-017-0395-x
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Schlägel UE, 2017, ECOL EVOL, V7, P8388, DOI 10.1002/ece3.3176
   Tanner HG, 2007, IEEE T AUTOMAT CONTR, V52, P863, DOI 10.1109/TAC.2007.895948
   van den Berg Jur, 2011, IEEE International Conference on Robotics and Automation, P3475
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P535, DOI 10.1002/cav.1468
   VICSEK T, 1995, PHYS REV LETT, V75, P1226, DOI 10.1103/PhysRevLett.75.1226
   WARBURTON K, 1991, J THEOR BIOL, V150, P473, DOI 10.1016/S0022-5193(05)80441-2
   Weitzenfeld, BIOL INSPIRED WOLF P
   Wilensky U., 2015, An Introduction to Agent-Based Modeling: Modeling Natural, Social, and Engineered Complex Systems with NetLogo
   Wilensky U, 2006, COGNITION INSTRUCT, V24, P171, DOI 10.1207/s1532690xci2402_1
   Xiankun Sun, 2010, Proceedings of the 2010 International Conference on Machine Vision and Human-Machine Interface (MVHI 2010), P796, DOI 10.1109/MVHI.2010.67
   Zeghoud S, 2022, VISUAL COMPUT, V38, P1345, DOI 10.1007/s00371-021-02229-9
NR 39
TC 1
Z9 1
U1 2
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2022
VL 33
IS 5
AR e2124
DI 10.1002/cav.2124
EA SEP 2022
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5E9FV
UT WOS:000847982900001
DA 2024-07-18
ER

PT J
AU Huang, DJ
   Zhou, SH
   Zeng, ZY
   Shi, YS
AF Huang, Dongjin
   Zhou, Shuhua
   Zeng, Ziyang
   Shi, Yongsheng
TI Efficient angiography simulation for complex vessels
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE angiography simulation; boundary handling; smoothed particle
   hydrodynamics; vascular boundary
ID FLOW
AB Angiography simulation is a critical step in virtual interventional surgery. However, the blood vessels are always complex and irregular, which poses a significant challenge to the accuracy and efficiency of simulation. In this paper, we present a novel method to simulate contrast media propagation, which can efficiently and accurately deal with various complex vascular structures and the coupling between blood and contrast media. Our method represents the vascular structures by signed distance functions and to impose boundary conditions, and then we compute the boundary volume by Gauss-Kronrod quadrature, which yields more accurate results even in complex vessels. Furthermore, we improve the simulation's initialization efficiency and real-time force computational efficiency by precomputing the boundary volume values throughout the vascular structure and saving them to a volume map, which can be queried very efficiently during runtime. Moreover, we add term to the multiple-fluid model to handle the vascular viscosity, which achieves a more realistic effect. Experiments show that our method obtains more smooth and accurate particle states, and significantly improves initialization efficiency. Finally, we invited 12 clinicians to evaluate the algorithm and verify the clinical value of our algorithm.
C1 [Huang, Dongjin; Zhou, Shuhua; Zeng, Ziyang; Shi, Yongsheng] Shanghai Univ, Shanghai Film Acad, Shanghai 200072, Peoples R China.
C3 Shanghai University
RP Huang, DJ (corresponding author), Shanghai Univ, Shanghai Film Acad, Shanghai 200072, Peoples R China.
EM djhuang@shu.edu.cn
FU Shanghai Natural Science Foundation of China [19ZR1419100]; Shanghai
   talent development funding of China [2021016]
FX Shanghai Natural Science Foundation of China, Grant/Award Number:
   19ZR1419100; Shanghai talent development funding of China, Grant/Award
   Number: 2021016
CR Bender J, 2020, IEEE T VIS COMPUT GR, V26, P2982, DOI 10.1109/TVCG.2020.3004245
   Brummer AB, 2021, IEEE T MED IMAGING, V40, P297, DOI 10.1109/TMI.2020.3025467
   Cheema MN, 2021, IEEE T IND INFORM, V17, P7991, DOI 10.1109/TII.2021.3064369
   Damseh R, 2021, IEEE T MED IMAGING, V40, P381, DOI 10.1109/TMI.2020.3027500
   Gissler C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3284980
   Harada T., 2007, P 23 SPRING C COMPUT, P191
   Huang DJ, 2019, COMPUT GRAPH-UK, V80, P97, DOI 10.1016/j.cag.2019.03.012
   Huang DJ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030379
   Huang DJ, 2015, I C VIRTUAL REALITY, P286, DOI 10.1109/ICVRV.2015.25
   Koschier D., 2020, SMOOTHED PARTICLE HY
   Koschier D, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099565
   Kreiser K, 2019, ROFO-FORTSCHR RONTG, V191, P547, DOI 10.1055/a-0759-2248
   Lee J, 2018, IEEE ENG MED BIO, P5241, DOI 10.1109/EMBC.2018.8513410
   Lyu CY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480493
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Muller Matthias, 2004, Technol Health Care, V12, P25
   Nazir A, 2022, IEEE T AFFECT COMPUT, V13, P845, DOI 10.1109/TAFFC.2020.2970399
   Qin Y, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P2587, DOI 10.1109/FSKD.2015.7382364
   Ren B., 2021, IEEE T VIS COMPUT GR
   Ren B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459764
   Ren B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2645703
   Ruan LW, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459862
   Sauer TJ, 2022, MED PHYS, V49, P2938, DOI 10.1002/mp.15562
   Sheng B, 2019, IEEE T CYBERNETICS, V49, P2707, DOI 10.1109/TCYB.2018.2833963
   Wang F, 2007, P ANN INT IEEE EMBS, P1742, DOI 10.1109/IEMBS.2007.4352647
   Wang Y., 2009, THESIS IMPERIAL COLL
   Wu XL, 2007, LECT NOTES COMPUT SC, V4791, P557
   Yang T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130882
   Yang T, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818117
NR 30
TC 0
Z9 0
U1 2
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2022
VL 33
IS 6
AR e2118
DI 10.1002/cav.2118
EA AUG 2022
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6Z9LE
UT WOS:000842816300001
DA 2024-07-18
ER

PT J
AU Zhou, W
   Jiang, WY
   Jie, B
   Bian, WX
AF Zhou, Wen
   Jiang, Wenying
   Jie, Biao
   Bian, Weixin
TI Multiagent evacuation framework for a virtual fire emergency scenario
   based on generative adversarial imitation learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fire evacuation drills; generative adversarial imitation learning;
   leader-follower; multiagent evacuation; virtual reality
ID SOCIAL FORCE MODEL; CROWD; SIMULATION; BEHAVIOR; LEADERSHIP; SYSTEM
AB One of the most common solutions for the prevention of fire accidents is to conduct extensive fire evacuation drills in crowded places. However, there are multiple salient advantages to using virtual reality technology to simulate emergency solutions, for instance, saving costs and greatly decreasing uncertain risks or accidents. Therefore, in this article, a multiagent evacuation framework for complex virtual fire scenarios is proposed and effectively used to simulate a multiagent evacuation procedure to approximate the goal of fire drills in a less costly manner. Specifically, the concept of a multihierarchy agent group model is proposed; that is, the evacuation of multiple agents is separated into leader-follower and freedom modes. Additionally, several complex actions of individual humans in actual fire drills are fully considered, and a multiaction agent schema is presented to characterize the associated real effects. In addition, generative adversarial imitation learning is adopted to obtain the evacuation path of the leader-agent by training numerous learning epochs. Finally, extensive experiments are conducted to validate the feasibility of our proposed method. The results show that the proposed method is superior to other methods and that it realistically and reasonably shows the procedure of multiagent evacuation in complex fire emergency scenarios.
C1 [Zhou, Wen; Jiang, Wenying; Jie, Biao; Bian, Weixin] Anhui Normal Univ, Sch Comp & Informat, Wuhu, Anhui, Peoples R China.
C3 Anhui Normal University
RP Zhou, W (corresponding author), Anhui Normal Univ, Sch Comp & Informat, Wuhu, Anhui, Peoples R China.
EM w.zhou@ahnu.edu.cn
RI Alidadi, Mehdi/HJZ-0235-2023
OI Alidadi, Mehdi/0000-0001-5183-7829; jiang, wenying/0000-0001-7647-1202;
   ZHOU, WEN/0000-0002-1266-1864
FU National Natural Science Foundation of China [61902003, 61976006];
   Doctoral Scientific Research Foundation of Anhui Normal University
FX National Natural Science Foundation of China, Grant/Award Numbers:
   61902003, 61976006; Doctoral Scientific Research Foundation of Anhui
   Normal University
CR Bakar, 2017, P 2017 8 INT C INF T, P61
   Bakar, 2019, MATER SCI ENG, V551, P12
   Cao, 2011, P INT WORKSH ADV COM
   Chennoufi M, 2018, INT J AMBIENT COMPUT, V9, P43, DOI 10.4018/IJACI.2018010103
   Chi WQ, 2020, IEEE INT CONF ROBOT, P2414, DOI [10.1109/ICRA40945.2020.9196912, 10.1109/icra40945.2020.9196912]
   Choi S, 2021, TRANSPORT RES C-EMER, V128, DOI 10.1016/j.trc.2021.103091
   Chu ML, 2013, J COMPUT CIVIL ENG, V27, P699, DOI 10.1061/(ASCE)CP.1943-5487.0000313
   Drury J, 2018, EUR REV SOC PSYCHOL, V29, P38, DOI 10.1080/10463283.2018.1471948
   Farhan J, 2015, TRANSPORT RES C-EMER, V60, P189, DOI 10.1016/j.trc.2015.08.021
   Fu YW, 2014, I C VIRTUAL REALITY, P103, DOI 10.1109/ICVRV.2014.52
   Han YB, 2017, PHYSICA A, V469, P499, DOI 10.1016/j.physa.2016.11.014
   Ho J, 2016, ADV NEUR IN, V29
   Hou L, 2014, PHYSICA A, V400, P93, DOI 10.1016/j.physa.2013.12.049
   Kahn K, 2015, Physics Today, V68, DOI [10.1063/PT.3.2884, DOI 10.1063/PT.3.2884]
   Li, 2020, AUTOMAT CONSTR, P103
   Li G, 2020, IOP C SER EARTH ENV, V440, DOI 10.1088/1755-1315/440/5/052006
   Li WH, 2016, SIMUL MODEL PRACT TH, V60, P108, DOI 10.1016/j.simpat.2015.09.011
   Li Y, 2017, PHYSICA A, V473, P319, DOI 10.1016/j.physa.2017.01.008
   Li Y, 2019, PHYSICA A, V526, DOI 10.1016/j.physa.2019.03.117
   Lillicrap, 2015, ARXIV150902971, P1
   Liu H, 2018, INFORM SCIENCES, V436, P247, DOI 10.1016/j.ins.2018.01.023
   Liu SS, 2019, INT J SIMUL MODEL, V18, P86, DOI 10.2507/IJSIMM18(1)464
   Luo XN, 2019, IEEE T COMPUT SOC SY, V6, P277, DOI 10.1109/TCSS.2018.2877149
   Ma, 2019, PERS UBIQUIT COMPUT, V24, P111
   Ma Y, 2016, PHYSICA A, V450, P333, DOI 10.1016/j.physa.2015.12.103
   Miyagawa D, 2020, PHYSICA A, V549, DOI 10.1016/j.physa.2020.124376
   Pan X., 2006, Proceedings of the Joint International Conference on Computing and Decision Making in Civil and Building Engineering, P1206
   Pelechano N, 2006, IEEE COMPUT GRAPH, V26, P80, DOI 10.1109/MCG.2006.133
   Qiu F., 2006, SIMUL MODEL PRACT TH, V18, P190
   Shimada, 2017, P JSAI INT S ART INT, P67
   Song Jiaming, 2018, ARXIV PREPRINT ARXIV
   Tian ZN, 2020, KNOWL-BASED SYST, V208, DOI 10.1016/j.knosys.2020.106451
   Wagner N, 2014, EXPERT SYST APPL, V41, P2807, DOI 10.1016/j.eswa.2013.10.013
   Wang QQ, 2019, IEEE ACCESS, V7, P73841, DOI 10.1109/ACCESS.2019.2920913
   Xie W, 2021, SAFETY SCI, V133, DOI 10.1016/j.ssci.2020.105029
   Yang XX, 2016, PHYSICA A, V442, P397, DOI 10.1016/j.physa.2015.08.020
   Zhang H, 2018, PHYSICA A, V492, P1107, DOI 10.1016/j.physa.2017.11.041
   Zheng SF, 2019, IEEE ACCESS, V7, P147755, DOI 10.1109/ACCESS.2019.2946659
   Zheng X., 2019, BUILD ENVIRON, V44, P437
   Zhou M, 2019, IEEE T INTELL TRANSP, V20, P4476, DOI 10.1109/TITS.2018.2886415
NR 40
TC 3
Z9 3
U1 5
U2 44
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2022
VL 33
IS 1
AR e2035
DI 10.1002/cav.2035
EA NOV 2021
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH4XD
UT WOS:000713866500001
DA 2024-07-18
ER

PT J
AU Bai, ZC
   Yao, NM
   Mishra, N
   Chen, H
   Wang, HG
   Thalmann, NM
AF Bai, Zechen
   Yao, Naiming
   Mishra, Nidhi
   Chen, Hui
   Wang, Hongan
   Magnenat Thalmann, Nadia
TI Enhancing Emotional Experience by Building Emotional Virtual Characters
   in VR Volleyball Games
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE emotional experience; emotional virtual characters; sports games; VR
   volleyball games
ID MODEL
AB Virtual reality (VR) volleyball games can provide an immersive entertainment experience and facilitate users to get familiar with game rules. In real world, players often experience emotions from scores, strokes, passes, and the influence from their teammates or opponents, and so forth. However, seldom studies are carried out for this emotional experience in a virtual environment, as most VR volleyball games mainly concentrate on the game playing, such as body movements. In this article, we propose to enhance emotional experience by building emotional virtual characters in VR volleyball games. The virtual characters cannot only arouse their emotions but also express their facial expressions according to the game situation. Emotion patterns are learned from real-world volleyball matches. The results demonstrate that our framework has great potential to enhance the user's emotional experience and engagement.
C1 [Bai, Zechen; Yao, Naiming; Chen, Hui; Wang, Hongan] Chinese Acad Sci, Beijing Key Lab Human Comp Interact, Inst Software, Beijing 100190, Peoples R China.
   [Bai, Zechen; Chen, Hui; Wang, Hongan] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing, Peoples R China.
   [Mishra, Nidhi; Magnenat Thalmann, Nadia] Nanyang Technol Univ, Inst Media Innovat, Singapore, Singapore.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS; Nanyang
   Technological University
RP Chen, H (corresponding author), Chinese Acad Sci, Beijing Key Lab Human Comp Interact, Inst Software, Beijing 100190, Peoples R China.
EM chenhui@iscas.ac.cn
RI Mishra, Nidhi/AAK-1794-2020
OI Thalmann, Nadia/0000-0002-1459-5960; Bai, Zechen/0000-0001-5953-0442
FU National Key RD Program [2020YFC2004100]; National Natural Science
   Foundation of China [NSFC: 61661146002]; National Research Foundation,
   Singapore under its NRF-NSFC Joint Research Grant Call (Data Science)
   [NRF2016NRF-NSFC001-071]
FX This work was supported by National Key R&D Program (2020YFC2004100),
   National Natural Science Foundation of China (NSFC: 61661146002), and
   National Research Foundation, Singapore under its NRF-NSFC Joint
   Research Grant Call (Data Science) (NRF2016NRF-NSFC001-071).
CR Bideau B, 2003, PRESENCE-TELEOP VIRT, V12, P411, DOI 10.1162/105474603322391631
   Bideau B, 2010, IEEE COMPUT GRAPH, V30, P14, DOI 10.1109/MCG.2009.134
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Correia V, 2012, J SPORT EXERCISE PSY, V34, P305, DOI 10.1123/jsep.34.3.305
   Covaci A, 2015, IEEE COMPUT GRAPH, V35, P55, DOI 10.1109/MCG.2015.95
   Dias Joao, 2014, Emotion Modeling. Towards Pragmatic Computational Models of Affective Processes. LNCS 8750, P44, DOI 10.1007/978-3-319-12973-0_3
   Hai W, 2015, PROCEEDINGS OF THE 31ST INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2016), P7, DOI 10.1145/3205326.3205345
   Hong H., 2020, P IEEE CVF C COMP VI, P362
   Hudlicka E., 2009, 2009 3 INT C AFFECTI, DOI DOI 10.1109/ACII.2009.5349473
   Jain N, 2018, VISUAL COMPUT, V34, P887, DOI 10.1007/s00371-018-1539-1
   Lagos L., 2011, BIOFEEDBACK CLIN J, V39, P15, DOI [DOI 10.5298/1081-5937-39.1.11, DOI 10.5298/1081-5937-39.1]
   Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005
   MCCRAE RR, 1991, PERS SOC PSYCHOL B, V17, P227, DOI 10.1177/014616729101700217
   Popescu A, 2014, IEEE T AFFECT COMPUT, V5, P32, DOI 10.1109/T-AFFC.2013.24
   Ravenet B, 2016, SOCIO AFFECT COMPUT, P139, DOI 10.1007/978-3-319-41316-7_8
   Stinson C, 2014, IEEE T VIS COMPUT GR, V20, P606, DOI 10.1109/TVCG.2014.23
   Vernon PA, 2008, TWIN RES HUM GENET, V11, P524, DOI 10.1375/twin.11.5.524
NR 17
TC 5
Z9 6
U1 7
U2 49
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2008
DI 10.1002/cav.2008
EA MAY 2021
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000656263900001
DA 2024-07-18
ER

PT J
AU Huang, WR
   Wang, YZ
   Yi, XD
   Yang, XJ
AF Huang, Wanrong
   Wang, Yanzhen
   Yi, Xiaodong
   Yang, Xue-Jun
TI Distributed coordination with connectivity maintenance for nonholonomic
   robots
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE connectivity maintenance; distributed coordination; multirobot systems;
   nonholonomic robots
ID NETWORK CONNECTIVITY; FLOCKING; SYSTEMS
AB Multirobot systems have been studied extensively in the recent years. Maintaining connectivity has significant impacts on the stability and convergence of the multirobot systems. In this work, we design a three-layer framework for multirobot coordination. Furthermore, a novel distributed algorithm is proposed to achieve the navigation objective while satisfying connectivity maintenance and collision avoidance constraints. The algorithm is a hybrid of an rapidly exploring random tree-based planner and an extended distributed navigation function-based controller. The coordination framework and the distributed algorithm are demonstrated to be effective through a series of illustrative simulations. They outperform the current state-of-the-art method in terms of efficiency and applicability.
C1 [Huang, Wanrong; Wang, Yanzhen; Yi, Xiaodong] Natl Innovat Inst Def Technol, Artificial Intelligence Res Ctr, Beijing, Peoples R China.
   [Wang, Yanzhen; Yi, Xiaodong] Natl Univ Def Technol, Coll Comp, State Key Lab High Performance Comp, Changsha, Hunan, Peoples R China.
   [Yang, Xue-Jun] Natl Innovat Inst Def Technol, Beijing, Peoples R China.
C3 National University of Defense Technology - China
RP Wang, YZ (corresponding author), Natl Innovat Inst Def Technol, Artificial Intelligence Res Ctr, Beijing, Peoples R China.; Wang, YZ (corresponding author), Natl Univ Def Technol, Coll Comp, State Key Lab High Performance Comp, Changsha, Hunan, Peoples R China.
EM yanzhenwang@hotmail.com
RI YANG, Xue/HPI-0953-2023
OI Huang, Wanrong/0000-0001-5778-9055
FU National Natural Science Foundation of China [91648204, 61532007,
   61601486]; National Key Research and Development Program of China
   [2017YFB1001900]; National Science and Technology Major Project
FX National Natural Science Foundation of China, Grant/Award Number:
   91648204, 61532007, and 61601486; National Key Research and Development
   Program of China, Grant/Award Number: 2017YFB1001900; National Science
   and Technology Major Project
CR Cai ZX, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1777
   Chang XF, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1698, DOI 10.1109/ROBIO.2015.7419016
   Erfianto B, 2016, J ROBOT, V2016, DOI 10.1155/2016/8540761
   Etemadi S, 2012, SCI IRAN, V19, P1251, DOI 10.1016/j.scient.2012.06.029
   Falconi R, 2015, ROBOTICA, V33, P332, DOI 10.1017/S0263574714000368
   Giordano PR, 2011, P 2011 ROB SCI SYST
   Hauert S., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P5015, DOI 10.1109/IROS.2011.6048729
   Hung PD, 2015, 2013 INT C SOFT COMP, P327
   Ji M, 2007, IEEE T ROBOT, V23, P693, DOI 10.1109/TRO.2007.900638
   Kan Z, 2011, IEEE DECIS CONTR P, P2369, DOI 10.1109/CDC.2011.6160634
   Lee DJ, 2007, IEEE T AUTOMAT CONTR, V52, P1469, DOI 10.1109/TAC.2007.902752
   Li XP, 2013, AUTOMATICA, V49, P285, DOI 10.1016/j.automatica.2012.10.014
   Nestmeyer T, 2017, AUTON ROBOT, V41, P989, DOI 10.1007/s10514-016-9578-9
   Olfati-Saber R, 2006, IEEE T AUTOMAT CONTR, V51, P401, DOI 10.1109/TAC.2005.864190
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Tang M, 2013, SCI WORLD J, V12, P7
   Tang MS, 2016, IEEE T SYST MAN CY-S, V46, P1075, DOI 10.1109/TSMC.2015.2484281
   Vrohidis C, 2018, AUTON ROBOT, V42, P853, DOI 10.1007/s10514-017-9660-y
   Wu YL, 2016, IEEE WIREL COMMUN LE, V5, P568, DOI 10.1109/LWC.2016.2601612
   Yang P, 2010, AUTOMATICA, V46, P390, DOI 10.1016/j.automatica.2009.11.012
   Zavlanos MM, 2009, IEEE T AUTOMAT CONTR, V54, P2869, DOI 10.1109/TAC.2009.2033750
NR 21
TC 3
Z9 3
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1833
DI 10.1002/cav.1833
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100024
DA 2024-07-18
ER

PT J
AU Yang, X
   Su, WC
   Deng, J
   Jin, XG
   Tan, GZ
   Pan, ZG
AF Yang, Xin
   Su, Wanchao
   Deng, Jian
   Jin, Xiaogang
   Tan, Guozhen
   Pan, Zhigeng
TI Real-virtual fusion model for traffic animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fusion model; interactive simulation; traffic animation
ID KINEMATIC WAVES; SIMULATION; DYNAMICS
AB In this paper, we present an innovative, animated traffic simulation method that we designed to feature an enhanced sense of reality and diversity of traffic flows. Instead of the typical one-off initialization, our simulation method includes continuous, real trajectory data input providing an interactive control function that maximizes the characteristics of real-world traffic flows. Our fusion models represent a comprehensive integration of the interactions among real-data-driven and virtual vehicles, thus depicting accurately the irregularity of traffic flows. Test results showed that animations generated via our proposed method depict inverse and irregular vehicle driving behaviors throughout the entire traffic flow.
C1 [Yang, Xin; Deng, Jian] Dalian Univ Technol, Dept Comp Sci, Dalian, Peoples R China.
   [Tan, Guozhen] Dalian Univ Technol, Dalian, Peoples R China.
   [Su, Wanchao] City Univ Hong Kong, Sch Creat Media, Hong Kong, Hong Kong, Peoples R China.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
   [Pan, Zhigeng] Hangzhou Normal Univ, Digital Media & HCI Res Ctr, Hangzhou, Zhejiang, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology; City
   University of Hong Kong; Zhejiang University; Hangzhou Normal University
RP Tan, GZ (corresponding author), Dalian Univ Technol, Dalian, Peoples R China.
EM gztan@dlut.edu.cn
OI SU, Wanchao/0000-0002-7498-3033; Pan, Zhi-geng/0000-0003-0717-5850; ,
   Xin/0000-0002-8046-722X
FU NSFC Fundamental Research Funds for the Central Universities [61300084,
   61370141, 61300015, 61632006, 61300089, 61272298, 61332017, 91546123,
   DUT15QY41]
FX NSFC Fundamental Research Funds for the Central Universities,
   Grant/Award Number: 61300084, 61370141, 61300015, 61632006, 61300089,
   61272298, 61332017, 91546123 and DUT15QY41
CR [Anonymous], 2008, NGSIM NEXT GEN SIM P
   Aw A, 2000, SIAM J APPL MATH, V60, P916, DOI 10.1137/S0036139997332099
   BANDO M, 1995, PHYS REV E, V51, P1035, DOI 10.1103/PhysRevE.51.1035
   Cameron G., 1994, Proceedings Supercomputing '94 (Cat. No.94CH34819), P291, DOI 10.1109/SUPERC.1994.344292
   CHANDLER RE, 1958, OPER RES, V6, P165, DOI 10.1287/opre.6.2.165
   Chao QW, 2015, COMPUT ANIMAT VIRT W, V26, P405, DOI 10.1002/cav.1654
   Chao QW, 2013, GRAPH MODELS, V75, P305, DOI 10.1016/j.gmod.2013.07.003
   DAGANZO CF, 1995, TRANSPORT RES B-METH, V29, P79, DOI 10.1016/0191-2615(94)00022-R
   GAZIS DC, 1961, OPER RES, V9, P545, DOI 10.1287/opre.9.4.545
   Gerlough D.L., 1955, Simulation of Freeway Traffic on a General-purpose Discrete Variable Computer
   Helbing D, 2001, REV MOD PHYS, V73, P1067, DOI 10.1103/RevModPhys.73.1067
   Hidas P, 2005, TRANSPORT RES C-EMER, V13, P37, DOI 10.1016/j.trc.2004.12.003
   Kesting A., 2009, ARXIV09123613
   Kesting A, 2007, TRANSPORT RES REC, P86, DOI 10.3141/1999-10
   Lamarche F, 2004, CROWD VIRTUAL HUMANS, P509
   Lebacque J., 1997, TECHNICAL REPORT
   LIGHTHILL MJ, 1955, PROC R SOC LON SER-A, V229, P317, DOI 10.1098/rspa.1955.0089
   Lu XQ, 2014, COMPUT ANIMAT VIRT W, V25, P363, DOI 10.1002/cav.1575
   Mao TL, 2015, COMPUT ANIMAT VIRT W, V26, P397, DOI 10.1002/cav.1642
   NAGEL K, 1992, J PHYS I, V2, P2221, DOI 10.1051/jp1:1992277
   NELSON P, 1997, PROC 1997 IFAC MEETI, V2, P771
   NEWELL GF, 1993, TRANSPORT RES B-METH, V27, P281, DOI 10.1016/0191-2615(93)90038-C
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Payne H.J., 1971, SIMULATION COUNCILS, V1, P51
   Pipes LA, 1953, OPERATIONAL ANAL TRA
   PRIGOGINE I, 1960, OPER RES, V8, P789, DOI 10.1287/opre.8.6.789
   Redmill K. A., 1999, Proceedings 199 IEEE/IEEJ/JSAI International Conference on Intelligent Transportation Systems (Cat. No.99TH8383), P656, DOI 10.1109/ITSC.1999.821139
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   Sewall J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024169
   Sewall J, 2011, IEEE T VIS COMPUT GR, V17, P26, DOI 10.1109/TVCG.2010.27
   Shen JJ, 2012, GRAPH MODELS, V74, P265, DOI 10.1016/j.gmod.2012.04.002
   Shvetsov V, 1999, PHYS REV E, V59, P6328, DOI 10.1103/PhysRevE.59.6328
   Treiber M., 2001, Automatisierungstechnik, V49, P478, DOI 10.1524/auto.2001.49.11.478
   Whitham GB., 1975, PHYS TODAY, V28, P55
   Wilkie D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462021
   Zhang HM, 2002, TRANSPORT RES B-METH, V36, P275, DOI 10.1016/S0191-2615(00)00050-3
NR 36
TC 4
Z9 4
U1 0
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2017
VL 28
IS 6
AR e1740
DI 10.1002/cav.1740
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9YH
UT WOS:000417254100002
DA 2024-07-18
ER

PT J
AU Khorloo, O
   Altantsetseg, E
AF Khorloo, Oyundolgor
   Altantsetseg, Enkhbayar
TI Constructive approach for smoke plume animation using turbulent toroidal
   vortices
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE particle systems; smoke animation; toroidal vortices; wind field
ID SIMULATION
AB In this paper, we propose an efficient approach for generating plausible smoke animation at interactive rates. Among a wide range of smoke animation approaches, our proposed approach simulates the behavior of gaseous phenomena such as turbulent smoke from a steam locomotive. Our method uses existing techniques for simulating smoke animation based on a particle system and extends them by introducing a simple yet efficient toroidal vortex to describe a more complex and turbulent behavior. The key idea is that vortex flows generated by torus-type smoke primitives are passively advected in a wind field to describe the turbulent flow of smoke.
C1 [Khorloo, Oyundolgor] Natl Univ Mongolia, Sch Engn & Appl Sci, Dept Informat & Comp Sci, Ulaanbaatar, Mongolia.
   [Altantsetseg, Enkhbayar] Natl Univ Mongolia, Sch Engn & Appl Sci, Ulaanbaatar, Mongolia.
C3 National University of Mongolia; National University of Mongolia
RP Altantsetseg, E (corresponding author), Natl Univ Mongolia, Univ St 3, Ulaanbaatar 14200, Mongolia.
EM enkhbayar.a@seas.num.edu.mn
FU National University of Mongolia Research Grant [P2016-1221]
FX National University of Mongolia Research Grant/Award Number: P2016-1221.
CR Akhmetov DG, 2009, VORTEX RINGS, P1, DOI 10.1007/978-3-642-05016-9
   Angelidis Alexis., 2006, S COMPUTER ANIMATION, P25
   Cheng M, 2009, PHYS FLUIDS, V21, DOI 10.1063/1.3196903
   DIDDEN N, 1979, Z ANGEW MATH PHYS, V30, P101, DOI 10.1007/BF01597484
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P181, DOI 10.1145/258734.258838
   Gamito MN, 1995, 2 DIMENSIONAL SIMULA, P3
   Hadap S, 2001, COMPUT GRAPH FORUM, V20, pC329, DOI 10.1111/1467-8659.00525
   He S, 2013, COMPUT GRAPH FORUM, V32, P27, DOI 10.1111/j.1467-8659.2012.03228.x
   Huang ZP, 2015, MULTIMED TOOLS APPL, V74, P7569, DOI 10.1007/s11042-014-1992-4
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Khorloo Oyundolgor, 2011, International Journal of Virtual Reality, V10, P53
   Lugovtsov BA, 1979, DYN CONTIN DISCRET I, V38, P71
   MAGARVEY RH, 1964, CAN J PHYS, V42, P678, DOI 10.1139/p64-063
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Pfaff T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185608
   SAKAS G, 1990, EUROGRAPHICS 90, P519
   Shinya M., 1992, Computer Graphics Forum, V11, pC119, DOI 10.1111/1467-8659.1130119
   Sims K., 1990, Computer Graphics, V24, P405, DOI 10.1145/97880.97923
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P129, DOI 10.1145/218380.218430
   WEJCHERT J, 1991, COMP GRAPH, V25, P19, DOI 10.1145/127719.122719
   Wu XY, 2013, COMPUT GRAPH FORUM, V32, P389, DOI 10.1111/cgf.12059
   Yaeger L, 1986, COMBINING PHYS VISUA
NR 24
TC 1
Z9 1
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1772
DI 10.1002/cav.1772
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200018
DA 2024-07-18
ER

PT J
AU Kravchenko, B
   Baranoski, GVG
   Chen, TF
   Miranda, E
   Van Leeuwen, SR
AF Kravchenko, Boris
   Baranoski, Gladimir V. G.
   Chen, Tenn Francis
   Miranda, Erik
   Van Leeuwen, Spencer R.
TI High-fidelity iridal light transport simulations at interactive rates
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE biophysical phenomena; human iris; simulation; visualization
ID COLOR; MODEL
AB Predictive light transport models based on first-principles simulation approaches have been proposed for complex organic materials. The driving force behind these efforts has been the high-fidelity reproduction of material appearance attributes without one having to rely on the manipulation of ad hoc parameters. These models, however, are usually considered excessively time consuming for rendering and visualization applications requiring interactive rates. In this paper, we propose a strategy to address this open problem with respect to one of the most challenging of these organic materials, namely the human iris. More specifically, starting with the configuration of a predictive iridal light transport model on a parallel-computing platform, we analyze the sensitivity of iridal appearance attributes to key model running parameters in order to achieve an optimal balance between fidelity and performance. We believe that the proposed strategy represents a step toward the real-time and predictive synthesis of high-fidelity iridal images for rendering and visualization applications, and it can be extended to other organic materials.
C1 [Kravchenko, Boris; Baranoski, Gladimir V. G.; Chen, Tenn Francis; Miranda, Erik; Van Leeuwen, Spencer R.] Univ Waterloo, Nat Phenomena Simulat Grp, 200 Univ Ave West, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Baranoski, GVG (corresponding author), Univ Waterloo, Nat Phenomena Simulat Grp, 200 Univ Ave West, Waterloo, ON N2L 3G1, Canada.
EM gvgbaran@gmail.com
OI Baranoski, Gladimir/0000-0002-9215-2137
CR [Anonymous], 2003, FIELD GUIDE DIGITAL
   [Anonymous], 2015, TECHNICAL REPORT
   [Anonymous], 2015, Cuda C best practices guide
   Baranoski GVG, 2001, VISUAL COMPUT, V17, P506, DOI 10.1007/s003710100127
   Baranoski GVG, 2015, RITA, V22, P203
   Bérard P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661285
   Brainard D.H., 2003, The Science of Color, V2, P5
   Che S, 2008, J PARALLEL DISTR COM, V68, P1370, DOI 10.1016/j.jpdc.2008.05.014
   Chiang M, 2010, ICTTR012010 U SO CAL
   Deering MF, 2005, ACM T GRAPHIC, V24, P649, DOI 10.1145/1073204.1073243
   DELORI FC, 1991, INVEST OPHTH VIS SCI, V32, P1144
   Dorsey J., 2007, DIGITAL MODELING MAT
   Ellis S.R., 2004, Proceedings of the Human Factors and Ergonomics Society 48th annual meeting, P2632, DOI DOI 10.1177/154193120404802306
   Fournier A, 1999, WORKSH REND PERC MEA
   Francois G., 2007, ANATOMICALLY ACCURAT
   François G, 2009, IEEE T VIS COMPUT GR, V15, P815, DOI 10.1109/TVCG.2009.24
   GREENBERG DP, 1997, SIGGRAPH 97 C P, P477
   Gross D., 1999, Simulation Interoperability Workshop
   Hopfield JJ, 2001, PR S PHYS, P269
   Hunt RWG., 1991, Measuring colour, V2
   Jimenez J, 2012, ADV REAL TIME RENDER
   Kim MH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185534
   Kravchenko B, 2017, HIGH FIDELITY IRIDAL
   Kravchenko B, 2016, THESIS
   Lam MWY, 2006, COMPUT GRAPH FORUM, V25, P359, DOI 10.1111/j.1467-8659.2006.00955.x
   Lam MWY, 2006, THESIS
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Lefohn A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1242384
   MAHNY M, 1994, COLOR RES APPL, V19, P105
   Natural Phenomena Simulation Group (NPSG), 2013, RUN ILIT ONL
   Natural Phenomena Simulation Group (NPSG), 2016, HUM IR DAT
   Natural Phenomena Simulation Group (NPSG), 2016, RUN ILIT INT
   Pamplona VF, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559763
   Regan S, 1997, INVEST OPHTH VIS SCI, V38, P3771
   Sagar M. A., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P205, DOI 10.1145/192161.192200
   STOKES M, 1992, ACM T GRAPHIC, V11, P406, DOI 10.1145/146443.146482
   Watt A., 1992, ADV ANIMATION RENDER
   [No title captured]
NR 38
TC 2
Z9 2
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1755
DI 10.1002/cav.1755
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200002
DA 2024-07-18
ER

PT J
AU Zhang, YQ
   Liu, S
   Yang, XS
   Zhang, JJ
   Shi, DM
AF Zhang, Yongqiang
   Liu, Shuang
   Yang, Xiaosong
   Zhang, Jianjun
   Shi, Daming
TI Supervised coordinate descent method with a 3D bilinear model for face
   alignment and tracking
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE face alignment; face tracking; facial performance capture; supervised
   coordinate descent method
AB Face alignment and tracking play important roles in facial performance capture. Existing data-driven methods for monocular videos suffer from large variations of pose and expression. In this paper, we propose an efficient and robust method for this task by introducing a novel supervised coordinate descent method with 3D bilinear representation. Instead of learning the mapping between the whole parameters and image features directly with a cascaded regression framework in current methods, we learn individual sets of parameters mappings separately step by step by a coordinate descent mean. Because different parameters make different contributions to the displacement of facial landmarks, our method is more discriminative to current whole-parameter cascaded regression methods. Benefiting from a 3D bilinear model learned from public databases, the proposed method can handle the head pose changes and extreme expressions out of plane better than other 2D-based methods. We present the reliable result of face tracking under various head poses and facial expressions on challenging video sequences collected online. The experimental results show that our method outperforms state-of-art data-driven methods.
C1 [Zhang, Yongqiang] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
   [Shi, Daming] Harbin Inst Technol, Harbin, Peoples R China.
   [Liu, Shuang] Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
   [Yang, Xiaosong] Bournemouth Univ, Natl Ctr Comp Animat, Media Sch, Poole, Dorset, England.
   [Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Comp Graph, Poole, Dorset, England.
C3 Harbin Institute of Technology; Harbin Institute of Technology;
   Bournemouth University; Bournemouth University; Bournemouth University
RP Shi, DM (corresponding author), Harbin Inst Technol, Harbin, Peoples R China.
EM damingshi@hotmail.com
OI Yang, Xiaosong/0000-0003-3815-0584; Zhang, Yongqiang/0000-0001-5809-4829
CR [Anonymous], 2011, REAL TIME AVATAR ANI
   [Anonymous], 2011, ACM transactions on graphics (TOG), DOI DOI 10.1145/1964921.1964972
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cao C, 2014, TOG, V33
   Cao C, 2013, TOG, V32
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao X, 2012, US Patent App, Patent No. [13/728,584, 13728584]
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Danelljan M, 2014, BMVC
   Donner R, 2006, IEEE T PATTERN ANAL, V28, P1690, DOI 10.1109/TPAMI.2006.206
   Eckman P., 1978, FACIAL ACTION CODING
   Feng ZH, 2015, IEEE T IMAGE PROCESS, V24, P3425, DOI 10.1109/TIP.2015.2446944
   Gonzalez-Mora J, 2007, IEEE I CONF COMP VIS, P2776
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Huang G.B., 2008, PROC WORKSHOP FACES
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Lee HS, 2009, IEEE T PATTERN ANAL, V31, P1102, DOI 10.1109/TPAMI.2008.286
   Liu S. Y., 2017, RES CBR DECISION SYS, P1
   Liu S, 2016, COMPUT ANIMAT VIRT W, V27, P301, DOI 10.1002/cav.1697
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Tarres F., GTAV face database
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126
   Yang F, 2011, TOG, V30
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
NR 33
TC 1
Z9 1
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1773
DI 10.1002/cav.1773
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200019
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wen, LX
   Xie, N
   Jia, JY
AF Wen, Laixiang
   Xie, Ning
   Jia, Jinyuan
TI Fast accessing Web3D contents using lightweight progressive meshes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE lightweight progressive meshes (LPM); Web3D; lightweight model;
   progressive meshes; progressive transmission; lightweight scene graph
   (LSG)
ID SYMMETRY DETECTION; TRIANGLE MESHES; COMPRESSION; EDGEBREAKER; SEARCH
AB Accessing Web3D contents is relatively slow through Internet under limited bandwidth. Preprocessing of 3D models can certainly alleviate the problem, such as 3D compression and progressive meshes (PM). But none of them considers the similarity between components of a 3D model, so that we could take advantage of this to further improve the efficiency. This paper proposes a similarity-aware data reduction method together with PM, called lightweight progressive meshes (LPM). LPM aims to excavate similar components in a 3D model, generates PM representation of each component left after removing redundant components, and organizes all the processed data using a structure called lightweight scene graph. The proposed LPM possesses four significant advantages. First, it can minimize the file size of 3D model dramatically without almost any precision loss. Because of this, minimal data is delivered. Second, PM enables the delivery to be progressive, so called streaming. Third, when rendering at client side, due to lightweight scene graph, decompression is not necessary and instanced rendering is fully exerted. Fourth, it is extremely efficient and effective under very limited bandwidth, especially when delivering large 3D scenes. Performance on real data justifies the effectiveness of our LPM, which improves the state-of-the-art in accessing Web3D contents. Copyright (C) 2015 John Wiley & Sons, Ltd.
C1 [Wen, Laixiang] Tongji Univ, Sch Elect & Informat Engn, Shanghai, Peoples R China.
   [Xie, Ning; Jia, Jinyuan] Tongji Univ, Sch Software Engn, Shanghai, Peoples R China.
C3 Tongji University; Tongji University
RP Jia, JY (corresponding author), Tongji Univ, Sch Software Engn, Shanghai, Peoples R China.
EM jyjia@tongji.edu.cn
FU National Science Foundation of China [61272276]; National Twelfth
   Five-year Plan Major Science and Technology Project
   [2012BAC11B00-04-03]; Special Research Fund of Higher College Doctorate
   [20130072110035]; Key Science and Technology Project of Jilin
   [20140204088GX]
FX The research was supported jointly by the National Science Foundation of
   China (No. 61272276), the National Twelfth Five-year Plan Major Science
   and Technology Project (No. 2012BAC11B00-04-03), Special Research Fund
   of Higher College Doctorate (No. 20130072110035), and Key Science and
   Technology Project of Jilin (No. 20140204088GX). The authors are
   grateful to the people who helped do the measurement.
CR Alliez P, 2001, COMPUT GRAPH FORUM, V20, pC480, DOI 10.1111/1467-8659.00541
   [Anonymous], EUR WORKSH 3D OBJ RE, DOI DOI 10.2312/3DOR/3DOR08/009-016
   [Anonymous], 2000, P SPRING C COMP GRAP
   Attene M, 2003, ACM T GRAPHIC, V22, P982, DOI 10.1145/944020.944022
   Bokeloh M, 2009, COMPUT GRAPH FORUM, V28, P697, DOI 10.1111/j.1467-8659.2009.01410.x
   Bouras CJ, 2006, COMPUT ANIMAT VIRT W, V17, P127, DOI 10.1002/cav.112
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Cai K., 2009, P 8 INT C VIRT REAL, P145
   Chaouch M, 2009, GRAPH MODELS, V71, P63, DOI 10.1016/j.gmod.2008.12.006
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cheng Wei, 2008, P 18 INT WORKSH NETW, P9, DOI DOI 10.1145/1496046.1496049
   Coors V, 2004, VISUAL COMPUT, V20, P507, DOI 10.1007/s00371-004-0255-1
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Hoppe H., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P189, DOI 10.1145/258734.258843
   Johan H, 2011, VISUAL COMPUT, V27, P565, DOI 10.1007/s00371-011-0590-y
   Karni Z, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P347, DOI 10.1109/VISUAL.2002.1183794
   Kim J, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P209, DOI 10.1109/SMI.2004.1314508
   Li FWB, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000493
   Lian ZH, 2010, IEEE IMAGE PROC, P3181, DOI 10.1109/ICIP.2010.5654226
   Mitra NJ, 2006, ACM T GRAPHIC, V25, P560, DOI 10.1145/1141911.1141924
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   Peng JL, 2010, COMPUT GRAPH FORUM, V29, P2029, DOI 10.1111/j.1467-8659.2010.01789.x
   Peng JL, 2005, ACM T GRAPHIC, V24, P609, DOI 10.1145/1073204.1073237
   Podolak J, 2006, ACM T GRAPHIC, V25, P549, DOI 10.1145/1141911.1141923
   Qian Zhang, 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P212, DOI 10.1109/ISM.2010.38
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392
   Shikhare D., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P233
   Tam GKL, 2012, IEEE T PATTERN ANAL, V34, P2134, DOI 10.1109/TPAMI.2012.17
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   Tian J, 2012, VISUAL COMPUT, V28, P819, DOI 10.1007/s00371-012-0700-5
   To D, 2001, PRESENCE-TELEOP VIRT, V10, P62, DOI 10.1162/105474601750182324
   Valette S, 2004, IEEE T VIS COMPUT GR, V10, P123, DOI 10.1109/TVCG.2004.1260764
   Valette S, 2009, COMPUT GRAPH FORUM, V28, P1301, DOI 10.1111/j.1467-8659.2009.01507.x
   Vranic DV, 2004, THESIS
   Yang S, 2004, IEEE T CIRC SYST VID, V14, P1249, DOI 10.1109/TCSVT.2004.835153
   Yang Yu-Bin, 2004, Chinese Journal of Computers, V27, P1297
   Zhang L, 2015, COMPUT ANIMAT VIRT W, V26, P15, DOI 10.1002/cav.1562
   Zhang Q, 2011, P 4 EUR C 3D OBJ RET, P97
NR 46
TC 10
Z9 10
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2016
VL 27
IS 5
BP 466
EP 483
DI 10.1002/cav.1672
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DZ1QS
UT WOS:000385614100002
DA 2024-07-18
ER

PT J
AU Feng, A
   Huang, YZ
   Xu, YY
   Shapiro, A
AF Feng, Andrew
   Huang, Yazhou
   Xu, Yuyu
   Shapiro, Ari
TI Fast, automatic character animation pipelines
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation; graphics; system; retargeting
AB Humanoid three-dimensional (3D) models can be easily acquired through various sources, including through online marketplaces. The use of such models within a game or simulation environment requires human input and intervention in order to associate such a model with a relevant set of motions and control mechanisms. In this paper, we demonstrate a pipeline where humanoid 3D models can be incorporated within seconds into an animation system and infused with a wide range of capabilities, such as locomotion, object manipulation, gazing, speech synthesis and lip syncing. We offer a set of heuristics that can associate arbitrary joint names with canonical ones and describe a fast retargeting algorithm that enables us to instill a set of behaviors onto an arbitrary humanoid skeleton on-the-fly. We believe that such a system will vastly increase the use of 3D interactive characters due to the ease that new models can be animated.Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Feng, Andrew; Xu, Yuyu; Shapiro, Ari] USC Inst Creat Technol, Playa Vista, CA USA.
   [Huang, Yazhou] Univ Calif Merced, Merced, CA USA.
C3 University of California System; University of California Merced
RP Shapiro, A (corresponding author), USC Inst Creat Technol, Playa Vista, CA USA.
EM shapiro@ict.usc.edu
CR Amaya K, 1996, PROC GRAPH INTERF, P222
   [Anonymous], 2007, P 24 INT C MACHINE L, DOI DOI 10.1145/1273496.1273619
   Arikan Okan., 2011, Animeeple character animation tool
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Choi KJ, 2000, J VISUAL COMP ANIMAT, V11, P223, DOI 10.1002/1099-1778(200012)11:5<223::AID-VIS236>3.0.CO;2-5
   Feng Andrew, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P134, DOI 10.1007/978-3-642-34710-8_13
   Feng AndrewW., 2012, I3D, P95, DOI [DOI 10.1145/2159616.2159632, 10.1145/2159616.2159632]
   Glardon P, 2006, VISUAL COMPUT, V22, P194, DOI 10.1007/s00371-006-0376-9
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Heloir A, 2009, LECT NOTES ARTIF INT, V5773, P393, DOI 10.1007/978-3-642-04380-2_43
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Kallmann M, 2008, COMPUT ANIMAT VIRT W, V19, P79, DOI 10.1002/cav.176
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Kovar Lucas., 2002, SCA 2002: Proceedings of the 2002 ACM SIG-GRAPH/Eurographics Symposium on Computer Animation, P97
   Kulpa R, 2005, COMPUT GRAPH FORUM, V24, P343, DOI 10.1111/j.1467-8659.2005.00859.x
   Lee J, 1999, COMP GRAPH, P39
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   Miller C, 2011, IEEE T VIS COMPUT GR, V17, P1060, DOI 10.1109/TVCG.2011.39
   Min J., 2010, P 2010 ACM SIGGRAPH, DOI [10.1145/1730804.1730811, DOI 10.1145/1730804.1730811]
   MONZANI JS, 2000, COMPUTER GRAPHICS FO, V19
   Neff Michael., 2009, P ACM SIGGRAPHEUROGR, P103
   Niewiadomski Radoslaw., 2009, AAMAS'09: Proceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems, P1399, DOI DOI 10.1075/NLP.8.20BEV
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Shapiro Ari, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P98, DOI 10.1007/978-3-642-25090-3_9
   Shapiro A, 2006, PROC GRAPH INTERF, P33
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Thiebaux Marcus., 2008, P AAMAS 08, P151
   van Welbergen H, 2010, J MULTIMODAL USER IN, V3, P271, DOI 10.1007/s12193-010-0051-3
   Zordan V. B., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P245
NR 31
TC 7
Z9 8
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2014
VL 25
IS 1
BP 3
EP 16
DI 10.1002/cav.1560
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AA4LQ
UT WOS:000331067500002
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Pan, B
   Xiao, CX
   Peng, QS
AF Zhao, Yong
   Pan, Bin
   Xiao, Chunxia
   Peng, Qunsheng
TI Dual-domain deformation transfer for triangular meshes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE animation reuse; deformation transfer; dual domain; deformation
   visualization; deformation-aware propagation
AB Creating an attractive mesh animation is a laborious and time-consuming task. In this paper, we propose a practical deformation transfer algorithm to make it easier. To achieve a robust numerical solver, we perform the transfer process in the dual domain; that is, the deformations are transferred between the dual meshes of the source and target meshes. Firstly, the source animation is analyzed and visualized to help the user specify markers in the large deformation regions. Then, through respecting the coherence information, a fast and deformation-aware surface correspondence approach is presented to determine how the source animation is transferred. Finally, the transferred result can be reconstructed via dual Laplacian optimization. Various experimental results demonstrate the effectiveness and applicability of this paper. Moreover, a user study is carefully designed to perceptually validate our motivation and advantages. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Zhao, Yong] Ocean Univ China, Sch Math Sci, Qingdao, Peoples R China.
   [Pan, Bin] Liaoning Shihua Univ, Coll Sci, Fushun, Peoples R China.
   [Xiao, Chunxia] Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
   [Peng, Qunsheng] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Ocean University of China; Liaoning Petrochemical University; Wuhan
   University; Zhejiang University
RP Zhao, Y (corresponding author), Ocean Univ China, Sch Math Sci, Qingdao, Peoples R China.
EM zhaoyong@cad.zju.edu.cnaff
FU National Basic Research 973 Program of China [2012CB725303,
   2009CB320802]; National Natural Science Foundation of China [61070081]
FX This work is supported by the National Basic Research 973 Program of
   China (Nos. 2012CB725303 and 2009CB320802) and the National Natural
   Science Foundation of China (No. 61070081).
CR Au OKC, 2006, IEEE T VIS COMPUT GR, V12, P386, DOI 10.1109/TVCG.2006.47
   Baran I, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531342
   Ben-Chen Mirela, 2009, P 2009 ACM SIGGRAPH, P67
   Chang Y, 2006, P COMP GRAPH INT HAN, P66
   Chen L, 2010, COMPUT GRAPH-UK, V34, P107, DOI 10.1016/j.cag.2010.01.003
   Hu JW, 2007, COMPUT ANIMAT VIRT W, V18, P271, DOI 10.1002/cav.182
   Huang J, 2006, ACM T GRAPHIC, V25, P1126, DOI 10.1145/1141911.1142003
   Kim BU, 2010, VISUAL COMPUT, V26, P487, DOI 10.1007/s00371-010-0474-6
   Lee TY, 2006, VISUAL COMPUT, V22, P729, DOI 10.1007/s00371-006-0059-6
   Luo W, 2004, P INT COMP S TAIB TA
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Süssmuth J, 2010, COMPUT ANIMAT VIRT W, V21, P173, DOI 10.1002/cav.364
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Wang YS, 2008, VISUAL COMPUT, V24, P765, DOI 10.1007/s00371-008-0258-4
   Xian CH, 2012, VISUAL COMPUT, V28, P21, DOI 10.1007/s00371-011-0595-6
   Yan HB, 2008, IEEE T VIS COMPUT GR, V14, P693, DOI 10.1109/TVCG.2008.28
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zayer R, 2005, COMPUT GRAPH FORUM, V24, P601, DOI 10.1111/j.1467-8659.2005.00885.x
   Zhao Y, 2009, COMPUT ANIMAT VIRT W, V20, P301, DOI 10.1002/cav.302
   Zhou K, 2010, COMPUT GRAPH FORUM, V29, P319, DOI 10.1111/j.1467-8659.2009.01601.x
NR 20
TC 5
Z9 5
U1 0
U2 10
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 447
EP 456
DI 10.1002/cav.1466
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100031
DA 2024-07-18
ER

PT J
AU Musse, SR
   Cassol, VJ
   Jung, CR
AF Musse, Soraia R.
   Cassol, Vinicius J.
   Jung, Claudio R.
TI Towards a quantitative approach for comparing crowds
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; crowd comparison; histogram matching
ID COMPUTER VISION; SIMULATION; MOTION; MODEL
AB In this paper, we propose a new model to quantitatively compare global flow characteristics of two crowds. The proposed approach explores a 4-D histogram that contains information on the local velocity (speed and orientation) of each spatial position, and the comparison is made using histogram distances. The 4-D histogram also allows the comparison of specific characteristics, such as distribution of orientations only, speed only, relative spatial occupancy only, and combinations of such features. Experimental results indicate that the proposed quantitative metric correlates with visual inspection. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Musse, Soraia R.; Cassol, Vinicius J.] Pontificia Univ Catolica Rio Grande do Sul, Dept Comp Sci, Porto Alegre, RS, Brazil.
   [Jung, Claudio R.] Univ Fed Rio Grande do Sul, Inst Informat, BR-91501970 Porto Alegre, RS, Brazil.
C3 Pontificia Universidade Catolica Do Rio Grande Do Sul; Universidade
   Federal do Rio Grande do Sul
RP Musse, SR (corresponding author), Pontificia Univ Catolica Rio Grande do Sul, Dept Comp Sci, Av Ipiranga 6681, Porto Alegre, RS, Brazil.
EM soraia.musse@pucrs.br
RI Jung, Claudio R/G-2439-2012; Isec, Inct/I-2409-2013; Musse, Soraia
   Raupp/AAS-3787-2021; Cassol, Vinícius/GVU-7369-2022; Musse, Soraia Raupp
   R/G-4801-2012
OI Musse, Soraia Raupp/0000-0002-3278-217X
CR Banerjee B, LECT NOTES COMPUTER
   Bouvier E, 1997, J ELECTRON IMAGING, V6, P94, DOI 10.1117/12.261175
   Braun A., 2005, Proceedings of the ACM symposium on Virtual reality software and technology, P244
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Courty N, 2007, COMPUT ANIMAT VIRT W, V18, P361, DOI 10.1002/cav.199
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Helbing D., 1997, Self Organization of Complex Structure: From Individual to Collective Dynamics, P569
   Jung CR, 2008, IEEE T CIRC SYST VID, V18, P1565, DOI 10.1109/TCSVT.2008.2005600
   Kapadia M., 2016, SIMULATING HETEROGEN, P193
   Kapadia Mubbasir., 2009, SCA 09 P 2009 ACM SI, P209, DOI DOI 10.1145/1599470.1599497
   Knoblauch R. L., 1996, Transportation research record, V1538, P27, DOI [10.1177/0361198196153800104, DOI 10.3141/1538-04, DOI 10.1177/0361198196153800104]
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Mao T., 2010, INT J VIRTUAL REALIT, P27
   Musse SR, 2007, COMPUT ANIMAT VIRT W, V18, P83, DOI 10.1002/cav.163
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rodrigues RA, 2010, APPL ARTIF INTELL, V24, P594, DOI 10.1080/08839514.2010.492167
   Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934
   Jacques JCS, 2010, IEEE SIGNAL PROC MAG, V27, P66, DOI 10.1109/MSP.2010.937394
   Singh S, 2009, COMPUT ANIMAT VIRT W, V20, P533, DOI 10.1002/cav.277
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Xiaoyuan Tu, 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P43
NR 26
TC 16
Z9 18
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2012
VL 23
IS 1
BP 49
EP 57
DI 10.1002/cav.1423
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 897SH
UT WOS:000300675800006
DA 2024-07-18
ER

PT J
AU Cho, K
   Jung, J
   Lee, SW
   Lim, SO
   Yang, HS
AF Cho, Kyusung
   Jung, Jinki
   Lee, Sang-Wook
   Lim, Sang Ok
   Yang, Hyun Seung
TI Real-time recognition and tracking for augmented reality books
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality book; real-time recognition and tracking; generic
   randomized forest; markerless visual tracking; augmented reality
AB An augmented reality book (AR book) is an application in which such multimedia elements as virtual 3D objects, movie clips, or sound clips are augmented to a conventional book using augmented reality technology. It can provide better understanding about the contents and visual impressions for users. For AR books, this paper presents a markerless tracking method, which recognizes and tracks a large number of pages in real-time, even on PCs with low computation power. For fast recognition with respect to a large number of pages, we propose a generic randomized forest that is an extension of a randomized forest. In addition, we define the spatial locality of the subregions in an image to resolve the problem of a dropping recognition rate under a complex background. For tracking with minimal jittering, we also propose the adaptive keyframe-based tracking method, which automatically updates the current frame as a keyframe when it describes the page better than the existing one. Copyright (c) 2011 John Wiley & Sons, Ltd.
C1 [Cho, Kyusung; Jung, Jinki; Lee, Sang-Wook; Lim, Sang Ok; Yang, Hyun Seung] Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Yang, HS (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.
EM yang@paradise.kaist.ac.kr
RI Yang, Hyun Seung/C-1984-2011
FU National Research Foundation of Korea (NRF); Ministry of Education,
   Science and Technology [2011-0018291]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (2011-0018291).
CR Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   [Anonymous], 2007, P 13 INT C VIRT SYST
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   CHO K, 2009, P JOINT VIRT REAL C, P13
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   HARTLEY R, 2003, MULTIPLE VIEW GEOMET, P616
   Juan M.C., 2005, P ACM SIGCHI INT C A, P379, DOI DOI 10.1145/1178477.1178558
   Kim K, 2010, VISUAL COMPUT, V26, P1145, DOI 10.1007/s00371-010-0490-6
   Klein George, 2007, P1
   Lee SH, 2009, IEEE T CONSUM ELECTR, V55, P883, DOI 10.1109/TCE.2009.5174470
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nister David, 2006, CVPR
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   OH J, 2008, P IEEE INT S CONS EL, P14
   Pilet J, 2010, P IEEE VIRT REAL ANN, P71, DOI 10.1109/VR.2010.5444811
   Rosten E., 2006, P 2006 9 EUR C COMP, P430, DOI DOI 10.1007/11744023_34
   Scherrer C, 2008, INT SYM MIX AUGMENT, P163, DOI 10.1109/ISMAR.2008.4637347
   TAKETA N, 2007, P C HUM INT, P475
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
   Wagner D, 2009, INT SYM MIX AUGMENT, P57, DOI 10.1109/ISMAR.2009.5336497
   Wagner D, 2008, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2008.4637338
NR 24
TC 7
Z9 12
U1 0
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2011
VL 22
IS 6
BP 529
EP 541
DI 10.1002/cav.431
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856IA
UT WOS:000297631200006
DA 2024-07-18
ER

PT J
AU Rodriguez, I
   Puig, A
   Esteva, M
AF Rodriguez, Inmaculada
   Puig, Anna
   Esteva, Marc
TI Cross-platform management of intelligent objects behaviors in serious
   virtual environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE serious virtual environments; intelligent objects; interactive
   environments
AB In this paper, we present a generic interaction framework that controls intelligent objects' actions in different virtual world (VW) platforms. These actions are based on the state of external platform-independent artificial intelligence-based systems such as multi-agent and rule-based systems. We have evaluated the proposed framework by means of two intelligent objects, a door and a noticeboard, incorporating them in Second Life and OpenWonderland VWs. These objects allow to work along three advanced aspects of a serious virtual environment: it is a dynamic space where participants are synchronously informed about activities evolution inside the virtual space, it can integrate processes and information coming from the real world, and it needs norms to organize participants actions, to define actions consequences, and to prevent undesired participants behaviors. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Rodriguez, Inmaculada] Univ Barcelona, Dept Appl Math, WAI Volume Visualizat & Artificial Intelligence R, Barcelona, Spain.
   [Esteva, Marc] UAB, Artificial Intelligence Res Inst, Cerdanyola Del Valles, Catalonia, Spain.
C3 University of Barcelona; Autonomous University of Barcelona; Consejo
   Superior de Investigaciones Cientificas (CSIC); CSIC - Instituto de
   Investigacion en Inteligencia Artificial (IIIA)
RP Rodriguez, I (corresponding author), Univ Barcelona, Dept Appl Math, WAI Volume Visualizat & Artificial Intelligence R, Barcelona, Spain.
EM inma@maia.ub.es
RI Puig, Anna/ADI-9599-2022; Rodriguez, Inmaculada/H-9298-2015
OI Puig, Anna/0000-0002-2184-2800; Rodriguez,
   Inmaculada/0000-0001-5931-7713
FU EVE [TIN2009-14702-C02-01/02]; AT(CONSOLIDER) [CSD2007-0022]; CICYT
   [TIN2008-02903]; Generalitat de Catalunya [2005-SGR-00093]; Spanish
   Government
FX Research partially funded by projects EVE (TIN2009-14702-C02-01/02),
   AT(CONSOLIDER CSD2007-0022), CICYT TIN2008-02903, and by the Generalitat
   de Catalunya under grant 2005-SGR-00093. M. Esteva enjoys a Ramon y
   Cajal contract from the Spanish Government.
CR Abaci T, 2005, P WORKSH SEM VIRT EN, P121
   Arcos JL, 2005, ENG APPL ARTIF INTEL, V18, P191, DOI 10.1016/j.engappai.2004.11.019
   Brota D., 2009, Proceedings of the 2009 International Conference on Computer Graphics & Virtual Reality. CGVR 2009, P151
   de Freitas S, 2009, COMPUT EDUC, V52, P343, DOI 10.1016/j.compedu.2008.09.010
   Gutierrez M, 2005, INT J COMPUT APPL T, V23, P229, DOI 10.1504/IJCAT.2005.006484
   Jorissen P, 2005, IEEE T VIS COMPUT GR, V11, P649, DOI 10.1109/TVCG.2005.100
   Kallmann M, 1999, SPRING COMP SCI, P73
   KALLMANN M, 2000, 11 EUR WORKSH AN SIM
   Kapahnke P, 2010, LECT NOTES COMPUT SC, V6497, P161, DOI 10.1007/978-3-642-17749-1_11
   Nakanishi H, 2003, DIGITAL CITIES 3 INF, V3081, P204
   Peters C., 2003, P INT C CENTR EUR CO
   Simpson J, 2005, GAM DEV C
   Smith R, 2010, SIMULAT GAMING, V41, P6, DOI 10.1177/1046878109334330
   Taboada GL, 2009, P 7 INT C PRINC PRAC, P30, DOI [10.1145/1596655.1596661, DOI 10.1145/1596655.1596661]
   VANACKEN L., 2007, Proceedings of the 2007 workshop on Multimodal interfaces in semantic interaction, P17
   Vijaykar S, 2009, 2009 6TH IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE, VOLS 1 AND 2, P186
   Wright T., 2010, Int. J. Virtual Reality, V9, P61
NR 17
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL-AUG
PY 2011
VL 22
IS 4
BP 343
EP 350
DI 10.1002/cav.423
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 825OW
UT WOS:000295290400003
DA 2024-07-18
ER

PT J
AU Pan, J
   Wang, JM
   Cao, ST
   Luo, XN
AF Pan, Jun
   Wang, Jian-min
   Cao, Shun-ting
   Luo, Xiao-nan
TI Interactive sign language synthesis based on adaptive display resolution
   visibility for ubiquitous devices
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE ubiquitous devices; CSL; display resolution visibility factor; synthesis
ID CHINESE
AB This paper presents a novel framework that synthesize Chinese sign language (CSL) animation on ubiquitous platform-independent devices with consideration of the self-adaptive rendering capability of the device display screen. The display resolution visibility (DRV) factor is introduced here as the measurement of the system's adaptability. Both the 3D virtual human model and sign animation scripts are simplified according to the DRV Factor of the ubiquitous device. Consequently, a real-time transmission scheme is proposed for sign language animation over a heterogeneous network. Simulations results show that these innovations significantly reduce the transmission bandwidth and work very well on the ubiquitous devices. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Pan, Jun; Wang, Jian-min; Cao, Shun-ting; Luo, Xiao-nan] Sun Yat Sen Univ, Sch Informat Sci & Technol, Natl Engn Res Ctr Digital Life, Guangzhou 510275, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Wang, JM (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Natl Engn Res Ctr Digital Life, Guangzhou 510275, Guangdong, Peoples R China.
EM mcswjm@mail.sysu.edu.cn
RI Pan, Jun/GQQ-7313-2022; wang, jian/GVS-0711-2022; cao,
   shun/GZL-9022-2022
OI wang, jianmin/0000-0001-8703-8973
CR Akenine-Möller T, 2003, ACM T GRAPHIC, V22, P801, DOI 10.1145/882262.882348
   CAO S, 2008, THESIS S YATSEN U
   CHEN Y, 2002, ASIA PACIFIC HUMAN C, V1, P636
   Chiu YH, 2007, IEEE T PATTERN ANAL, V29, P28, DOI 10.1109/TPAMI.2007.250597
   DARRAGH JJ, 1992, CAMBRIDGE SERIES HUM
   *DEP ED CHIN ASS D, 2003, CHIN SIGN LANG
   Garland M., 1997, P 24 ANN C COMP GRAP
   Garland M., 1999, THESIS CARNEGIE MELL
   Heloir A, 2006, LECT NOTES ARTIF INT, V3881, P168
   Karpouzis K, 2007, COMPUT EDUC, V49, P54, DOI 10.1016/j.compedu.2005.06.004
   Lee J., 1999, International Journal of Modelling and Simulation, V19, P24
   NORIKO T, 2000, P TECHN PERS DIS C 2
   SHANTZ M, 1982, BEHAV RES METH INSTR, V14, P467, DOI 10.3758/BF03203314
   WU F, 2007, EUROGRAPHICS 2007
   Xu L, 2000, J COMPUT SCI TECHNOL, V15, P485, DOI 10.1007/BF02950413
   [颜庆聪 Yan Qingcong], 2009, [计算机研究与发展, Journal of Computer Research and Development], V46, P1893
   Ye KJ, 2009, COMPUT ANIMAT VIRT W, V20, P237, DOI 10.1002/cav.307
NR 17
TC 0
Z9 1
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 213
EP 220
DI 10.1002/cav.409
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700017
DA 2024-07-18
ER

PT J
AU Peng, YJ
   Jia, RS
   Wang, YH
   Zhang, MM
AF Peng, Yanjun
   Jia, Ruisheng
   Wang, Yuanhong
   Zhang, Mingmin
TI A virtual endoscopy system for virtual medicine
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE virtual endoscopy; path planning; ray casting
ID ALGORITHM
AB Virtual endoscopy is a technique to explore hollow organs and anatomical cavities using 3D medical imaging and computer graphics. In this paper, boundary model and local feature structure are used to realize tissue segmentation, and a new efficient algorithm is presented to solve path planning. As to real-time processing, a frame in virtual endoscopy is divided into near viewpoint part and far viewpoint part based on volume data characteristics in our method. In the aspect of scene rendering, a ray casting algorithm based on the boundary voxel is proposed. Thus the voyage images can be rendered in real time with high quality in virtual endoscopy system by using these techniques. The experiments show that application results of our algorithm in tissue segmentation, path planning, scene rendering are better than other algorithms. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Zhang, Mingmin] Zhejiang Univ, Sch CS & T, Comp & Engn Dept, Hangzhou 310003, Zhejiang, Peoples R China.
   [Peng, Yanjun; Jia, Ruisheng; Wang, Yuanhong] Shandong Univ Sci & Technol, Coll Informat Sci & Engn, Dept Comp Sci, Qingdao, Peoples R China.
C3 Zhejiang University; Shandong University of Science & Technology
RP Zhang, MM (corresponding author), Zhejiang Univ, Sch CS & T, Comp & Engn Dept, Hangzhou 310003, Zhejiang, Peoples R China.
EM zmm@cad.zju.edu.cnl
RI Zhang, Miao/JXY-8985-2024; zhang, mm/IWV-4201-2023; Jia,
   Rui-Sheng/D-4460-2015
OI Jia, Rui-Sheng/0000-0003-1612-4764
CR BERNHARD P, 2007, VISUALIZATION MED, V34, P499
   BERNHARD P, 2007, VISUALIZATION MED, V34, P83
   CHAO Y, 2008, J CHINA U MINING TEC, V18, P33
   DAVID D, 2009, ARTIF INTELL, V46, P111
   Gordon K, 2006, IEEE S VOL REND PROC, P79
   Hong L., 1997, SIGGRAPH97, P27
   JINMAN K, 2008, BIOMEDICAL INFORM TE, V5, P211
   KANAV K, 2009, J BIOMEDICAL INFORM, V42, P593
   Liang RH, 2008, J DISP TECHNOL, V4, P431, DOI 10.1109/JDT.2008.2002223
   MARK WB, 2008, SEMINARS COLON RECTA, V19, P90
   Martin L B, 1998, IEEE T VISUALIZATION, V4, P243
   MICHAEL WL, 2006, COMPUT HUM BEHAV, V22, P412
   Palágyi K, 2002, PATTERN RECOGN LETT, V23, P663, DOI 10.1016/S0167-8655(01)00142-8
   Pan Z, 2007, COMPUT SCI ENG, V9, P32, DOI 10.1109/MCSE.2007.67
   Sato Y, 2000, IEEE T VIS COMPUT GR, V6, P160, DOI 10.1109/2945.856997
   SATO Y, 2007, MED IMAGE ANAL, V22, P143
   Smith GG, 2009, COMPUT EDUC, V52, P201, DOI 10.1016/j.compedu.2008.07.011
   Sramek M, 2000, IEEE T VIS COMPUT GR, V6, P236, DOI 10.1109/2945.879785
   SVJETLANA M, 2007, J NEUROSCI METH, V16, P32
   WANG Q, 2007, IEEE COMPUTING SCI E, V9, P32
   Zhou Y, 1999, IEEE T VIS COMPUT GR, V5, P196, DOI 10.1109/2945.795212
NR 21
TC 4
Z9 5
U1 0
U2 10
PU WILEY-BLACKWELL
PI MALDEN
PA COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 277
EP 284
DI 10.1002/cav.418
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700024
DA 2024-07-18
ER

PT J
AU Yu, QZ
   Neyret, F
   Steed, A
AF Yu, Qizhi
   Neyret, Fabrice
   Steed, Anthony
TI Feature-based vector simulation of water waves
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE water waves; real-time simulation; procedural methods
ID MESHES
AB We present a method for simulating local water waves caused by obstacles in water streams for real-time graphics applications. Given a low-resolution water surface and velocity field, our method is able to decorate the input water surface with high resolution detail for the animated waves around obstacles. We construct and animate a vector representation of the waves. It is then converted to feature-aligned meshes for capturing the surfaces of the waves. Results demonstrate that our method has the benefits of real-time performance and easy controllability. The method also fits well into a state-of-the-art river animation system. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Yu, Qizhi; Neyret, Fabrice] LJK INRIA Grenoble, Grenoble, France.
   [Steed, Anthony] UCL, Dept Comp Sci, Virtual Environms & Comp Graph Grp, London WC1E 6BT, England.
C3 University of London; University College London
RP Yu, QZ (corresponding author), LJK INRIA Grenoble, Grenoble, France.
EM q.yu@cs.ucl.ac.uk
OI Steed, Anthony/0000-0001-9034-3020
CR Botsch M, 2001, COMPUT GRAPH FORUM, V20, pC402, DOI 10.1111/1467-8659.00533
   BRIDSON R, 2008, FLUID SIM COMP GRAPH
   Bridson R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276435, 10.1145/1239451.1239497]
   CHENTANEZ N, 2010, P EUR ACM SIGGRAPH S
   Fedorov AV, 1998, J FLUID MECH, V354, P1, DOI 10.1017/S0022112097007453
   Fournier A., 1986, Computer Graphics, V20, P75, DOI 10.1145/15886.15894
   Glassner A, 2002, IEEE COMPUT GRAPH, V22, P88, DOI 10.1109/MCG.2002.1016702
   JACKSON RG, 1976, J FLUID MECH, V77, P531, DOI 10.1017/S0022112076002243
   Kass M., 1990, P SIGGRAPH, P49
   Kipfer P, 2006, PROC GRAPH INTERF, P41
   Kobbelt LP, 2000, COMPUT GRAPH FORUM, V19, pC249, DOI 10.1111/1467-8659.00417
   Layton AT, 2002, VISUAL COMPUT, V18, P41, DOI 10.1007/s003710100131
   Lee H, 2010, VISUAL COMPUT, V26, P865, DOI 10.1007/s00371-010-0439-9
   Neyret F, 2001, SPRING EUROGRAP, P53
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   STOKER JJ, 1957, PURE APPL MATH, V4
   TESSENDORF J, 2004, SIGGRAPH 2004 COURSE, V31
   Thürey N, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P39, DOI 10.1109/PG.2007.33
   Vallé BL, 2006, J GEOPHYS RES-EARTH, V111, DOI 10.1029/2004JF000140
   WEJCHERT J, 1991, COMP GRAPH, V25, P19, DOI 10.1145/127719.122719
   Wu WM, 2004, J HYDRAUL ENG-ASCE, V130, P1013, DOI 10.1061/(ASCE)0733-9429(2004)130:10(1013)
   Yu Q, 2010, IEEE ICC
   Yu QZ, 2009, COMPUT GRAPH FORUM, V28, P239, DOI 10.1111/j.1467-8659.2009.01363.x
   Yuksel C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239550
NR 24
TC 5
Z9 5
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 91
EP 98
DI 10.1002/cav.391
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lee, J
   Kim, MS
   Yoon, SH
AF Lee, Jieun
   Kim, Myung-Soo
   Yoon, Seung-Hyun
TI Patches: character skinning with local deformation layer
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE Skinning; shape deformation; local shape control; surface-oriented
   deformation; muscle deformation; elastic deformation; direct
   manipulation
AB We present a layered geometric approach to the skinning of character animation. Oil top of a global shape deformation, B-spline surface patches are attached to various body parts for local control. The patches are directly manipulated so as to generate example local shapes at some important poses. During character animation, the B-spline control points move continuously by kinematically interpolating a set of example patches, and at the same time they can also move dynamically by elastic simulation. The movement of control points changes the shape of a local patch, and consequently skin vertices Move according to the patch deformation, finally generating the desired local deformation. We demonstrate the effectiveness of our approach by generating natural local details at various poses including muscular effects and elastic deformation. Moreover, dealing With only a small number of control points, the proposed method is very efficient, While generating hundreds to thousands frames per second. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Kim, Myung-Soo] Seoul Natl Univ, Seoul 151, South Korea.
C3 Seoul National University (SNU)
RP Yoon, SH (corresponding author), Dongguk Univ, Seoul 100715, South Korea.
EM shyun@dongguk.edu
RI LEE, JIEUN/HTN-1777-2023; LEE, YU/JXY-2338-2024; Lee,
   Eun-ju/JAN-8749-2023; Lee, Jieun/J-3909-2016
OI Lee, Jieun/0000-0001-5692-9263
CR Albrecht Irene., 2003, P 2003 ACM SIGGRAPHE, P98
   Alexa M, 2002, ACM T GRAPHIC, V21, P380, DOI 10.1145/566570.566592
   Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626
   [Anonymous], 2005, P 2005 S INTERACTIVE, DOI [DOI 10.1145/1053427.10534294, DOI 10.1145/1053427.1053429]
   [Anonymous], 2001, P 2001 S INTERACTIVE
   [Anonymous], 1987, Algorithms for Approximation
   [Anonymous], 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'02
   Capell S, 2002, ACM T GRAPHIC, V21, P586, DOI 10.1145/566570.566622
   Chadwick J. E., 1989, Computer Graphics, V23, P243, DOI 10.1145/74334.74358
   Choi MG, 2005, IEEE T VIS COMPUT GR, V11, P91
   Hyun DE, 2005, VISUAL COMPUT, V21, P542, DOI 10.1007/s00371-005-0343-x
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Lee J, 2006, COMPUT ANIMAT VIRT W, V17, P479, DOI 10.1002/cav.150
   LEWIS JP, P ACM SIGGRAPH 2000, P165
   Magnenat-Thalmann N, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P201
   Magnenat-Thalmann Nadia., 2004, HDB VIRTUAL HUMANS
   MAGNENATTHALMAN.N, P GRAPH INT 1988, P26
   Merry B, 2006, ACM T GRAPHIC, V25, P1400, DOI 10.1145/1183287.1183294
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Piegl L, 1995, NURBS BOOK
   Platt S. M., 1981, Computer Graphics, V15, P245, DOI 10.1145/965161.806812
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Wang RY, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239524, 10.1145/1276377.1276468]
   WANG XC, P 2002 ACM SIGGRAPH, P129
   Waters K., 1991, Journal of Visualization and Computer Animation, V2, P123, DOI 10.1002/vis.4340020405
   Waters K., 1987, ACM SIGGRAPH Comput. Graph., V21, P17
   Weber J, 2000, P GAM DEV C
   Yoon SH, 2006, COMPUT GRAPH FORUM, V25, P487, DOI 10.1111/j.1467-8659.2006.00968.x
NR 30
TC 1
Z9 1
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 321
EP 331
DI 10.1002/cav.308
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700025
DA 2024-07-18
ER

PT J
AU Xu, JY
   Jin, XG
   Yu, YZ
   Shen, T
   Zhou, MD
AF Xu, Jiayi
   Jin, Xiaogang
   Yu, Yizhou
   Shen, Tian
   Zhou, Mingdong
TI Shape-constrained flock animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE flock animation; shape constraint; fuzzy control; Kalman filter; global
   path control
AB We propose a novel shape-constrained flock animation system for interactively controlling flock navigation in virtual environments. This system is capable of making the spatial distribution of a flock meet static or deforming shape constraints While performing flock simulation. Such a capability can find many applications in the entertainment industry. Given a 3D constraining shape, our system first draws a set of uniform sample points through a 3D surface mosaicing process or a stratified point sampling strategy. Once correspondences between flock members and sample points have been established, points on the target shape are used as homing destinations to guide flock migration. Under a global path control scheme, an effective fuzzy control logic, Which dynamically adjusts steering forces and control forces, has been developed to create visually pleasing shape-constrained flock animations. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
EM jin@cad.zju.edu.cn
RI YU, YIZHOU/D-1603-2013; /F-3345-2010
OI /0000-0002-0470-5548; Zhou, Mingdong/0000-0003-4380-8758
CR Anderson M., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA'03, P286
   [Anonymous], 2004, PROC EUROGRAPHICS S, DOI DOI 10.2312/SPBG/SPBG04/049-056
   Bayazit OB, 2005, LECT NOTES COMPUT SC, V3342, P112
   Bayazit OB, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P104, DOI 10.1109/PCCGA.2002.1167844
   Chenney Stephen., 2004, Proceedings of the 2004 ACM SIGGRAPH/Euro- graphics symposium on Computer animation, P233, DOI [10.1145/1028523.1028553, DOI 10.1145/1028523.1028553.]
   ERRA U, 2004, P VIS MOD VIS C, P233
   Hartman C, 2006, COMPUT ANIMAT VIRT W, V17, P199, DOI 10.1002/cav.123
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Lai Yu-Chi., 2005, SCA 2005: Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P281, DOI DOI 10.1145/1073368.1073409
   Lai YK, 2006, VISUAL COMPUT, V22, P604, DOI 10.1007/s00371-006-0047-x
   Lien JM, 2005, IEEE INT CONF ROBOT, P3402
   Lien JM, 2004, IEEE INT CONF ROBOT, P4159
   Olfati-Saber R, 2006, IEEE T AUTOMAT CONTR, V51, P401, DOI 10.1109/TAC.2005.864190
   Reynolds C. W., 1999, P GAM DEV C, P763
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Sakuma T, 2005, COMPUT ANIMAT VIRT W, V16, P343, DOI 10.1002/cav.105
   SKRBA L, 2006, EUROGRAPHICS IRELAND, P7
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   TU X., 1994, P ACM SIGGRAPH 94, P43, DOI DOI 10.1145/192161.192170
   TURK G, 1992, COMP GRAPH, V26, P55, DOI 10.1145/142920.134008
   Ulicny Branislav, 2004, SCA'04'- Proc. of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P243, DOI [DOI 10.2312/SCA/SCA04/243-252, 10.1145/1028523.1028555, DOI 10.1145/1028523.1028555]
   Watt A., 1992, ADV ANIMATION RENDER
   Wojtan C., 2006, P 2006 ACM SIGGRAPHE, P15
   XIAO D, 1998, P ACM CHI 98 C HUM F, V1, P179
NR 24
TC 20
Z9 28
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 319
EP 330
DI 10.1002/cav.231
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200015
DA 2024-07-18
ER

PT J
AU Ting, SP
   Zhou, SP
AF Ting, Shang-Ping
   Zhou, Suiping
TI <i>Quartz</i>:: an autonomous navigation system for MOUT simulations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE qualitative spatial reasoning; virtual environments; military operations
   on urbanized terrain (MOUT)
AB Autonomous navigation systems are important to Military Operations on Urbanized Terrain (MOUT) simulations for generating realistic tactical behaviours for the non-player characters (or bots). In this paper, we describe our work on Quartz, an autonomous navigation system for MOUT simulations. Novel features of Quartz include qualitative spatial representation and hierarchical spatial reasoning which enables fast situation analysis and human-like path planning in a dynamic environment. To assess the effectiveness of Quartz, we have integrated it into Twilight City, a virtual environment for MOUT simulations. Experimental results show that Quartz is very effective for quick tactical path generation in dynamic MOUT environments. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Modelling & Simulat Def Sci & Technol Agency, Singapore 109679, Singapore.
RP Ting, SP (corresponding author), Modelling & Simulat Def Sci & Technol Agency, Singapore 109679, Singapore.
EM tshngpi@dsta.gov.sg
CR [Anonymous], 1971, Problem solving methods in artificial intelligence
   Ballard John R., 2006, Fighting for Fallujah: A New Dawn for Iraq
   CHAIMOWICZ L, 2005, P 2005 INT WORKSH MU, P223
   COHN AG, 1996, INT C ART INT SYMB M
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Crino ST, 2001, WSC'01: PROCEEDINGS OF THE 2001 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P715, DOI 10.1109/WSC.2001.977359
   *DEP ARM, 2003, 306 FM HEADQ DEP ARM
   FORBUS K, 2001, 15 INT WORKSH QUAL R
   KAMPHUIS A, 2005, INT WORKSH CROWD SIM
   Knauff M., 1995, P 17 ANN C COGN SCI, P200
   *MOUT, 1979, 9010 DEP ARM
   Penn A, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P99
   REECE D, 2000, P 9 C COMP GEN FORC
   ROOK M, 2005, EUR ACM SIGGRAPH S C
   SCHUSSMAN S, 2000, P VISSYM 00
   Stacey C.P., 1960, OFFICIAL HIST CANADI, V3
   Turner A, 2002, ENVIRON PLANN B, V29, P473, DOI 10.1068/b12850
   WRAY RE, 2002, P I ITSEC
   ZHOU SP, IN PRESS INT J COMPU
   Zimmermann K, 1996, APPL INTELL, V6, P49, DOI 10.1007/BF00117601
   1910, ART WAR
NR 21
TC 1
Z9 1
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 383
EP 394
DI 10.1002/cav.196
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000017
DA 2024-07-18
ER

PT J
AU Ahn, J
   Oh, S
   Wohn, K
AF Ahn, Junghyun
   Oh, Seungwoo
   Wohn, Kwangyun
TI Optimized motion simplification for crowd animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion LoD; crowd animation; level-of-detail; skinning animation
AB Simulating a huge number of articulate figures in a real-time application is one of the challenging research topics in character animation. Several researchers have tried to improve the performance of animation using the image-based technique such as 'impostor.' This method improved the speed of the animation; however, the accuracy, memory, and interactivity problems related to motion remain to be resolved. In this regard, a 'motion simplification' framework for an articulate figure is proposed, which not only improves the speed of the animation but also conserves the features of the original motion. First, the motion sequence is analyzed using mean shift clustering for the purpose of extracting key postures and automatically generating the priority of joint reductions. These motion analysis results are directly utilized as the input of the proposed posture optimization. The least square method is applied in order to minimize the error between the original and the simplified posture. Finally, how to apply the proposed simplified motion in a real-time application without decreasing the visual quality of the scene is shown. The experimental result shows that the proposed motion simplification can be successfully applied in a real-time animation system. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Korea Adv Inst Sci & Technol, VR Lab, CS Div, EECS Dept, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Ahn, J (corresponding author), Korea Adv Inst Sci & Technol, VR Lab, CS Div, EECS Dept, Taejon 305701, South Korea.
EM chocchoggi@vr.kaist.ac.kr
RI Wohn, Kwangyun/C-2013-2011
CR AHN J, 2004, CASA, P129
   Aubel A, 2000, IEEE T CIRC SYST VID, V10, P207, DOI 10.1109/76.825720
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DOBBYN S, 2005, 13D, V13, P95
   Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   OH S, VISUAL COMPUTER, V21, P522
   Ohshima T, 1996, P IEEE VIRT REAL ANN, P103, DOI 10.1109/VRAIS.1996.490517
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   Pullen K, 2002, ACM T GRAPHIC, V21, P501
   Redon S, 2005, ACM T GRAPHIC, V24, P936, DOI 10.1145/1073204.1073294
   SHOEMAKE K, 1992, GRAPHICS INTERFACE, P245
   Tecchia F, 2002, IEEE COMPUT GRAPH, V22, P36, DOI 10.1109/38.988745
NR 18
TC 10
Z9 11
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 155
EP 165
DI 10.1002/cav.119
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400003
DA 2024-07-18
ER

PT J
AU Hartman, C
   Benes, B
AF Hartman, Christopher
   Benes, Bedrich
TI Autonomous boids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE flock; boid; computer animation; artificial life; procedural animation;
   particle system
AB Die classical work of bird-like objects of Reynolds simulates polarized motion of groups of oriented particles, bird-like objects, or simply boids. To do this, three steering vectors are introduced. Cohesion is the tendency of boids to stay in the center of the flock, alignment smoothes their velocities to similar values, and separation helps them to avoid mutual collisions. If no impetus is introduced the boids wander somewhat randomly so apt external leading force is necessary for the correct flock behavior. As call be observed during the bird flocking in the fall, birds sometimes move in a Way that is not captured by the above described framework. Some of the birds, typically the ones on the edge of the flock, suddenly shoot-off. The flock then pursues this leader. In the original Work by Reynolds the cohesion and separation are two complementary steers. We introduce a complementary force to the alignment that we call the change of leadership. This steer defines the chance of the boid to become a leader and try to escape. The leadership is derived from the boid position and the flock eccentricity. If a boid is oil the front edge of the flock it has a higher chance to escape. Escaping from the flock is simulated as a sequence of velocity increases that are added to the current velocity of the boid. The entire system is easy to implement, is efficient, and runs simulations of hundreds of holds oil a standard computer at 30 frames per second. Our system is aimed to real-time simulations and has the potential to be used in games, crowd simulations, etc. Copyright (c) 2006 Joint Wiley & Sons, Ltd.
C1 Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Benes, B (corresponding author), Purdue Univ, Dept Comp Graph Technol, Knoy Hall Technol,401 N Grant St, W Lafayette, IN 47907 USA.
EM bbenes@purdue.edu
RI Benes, Bedrich/A-8150-2016
OI Benes, Bedrich/0000-0002-5293-2112
CR ANDERSON M, 2003, SCA 03 P 2003 ACM SI, P28
   [Anonymous], SCA 05 P 2005 ACM SI
   Go J., 2004, S COMPUTER ANIMATION, P9
   LIEKENS A, 2002, ARTIFICIAL LIFE
   MUSSE SR, 1998, VRST 98, P115
   REYNOLDS CW, WEB PAGE RELATED BOI
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   RYDER G, 2004, VAST, P29
   TU X, 1994, SIGGRAPH 94, P43
   Ulicny B., 2004, EUR SIGGRAPH S COMP, P243
   Wu JC, 2003, ACM T GRAPHIC, V22, P888, DOI 10.1145/882262.882360
NR 11
TC 55
Z9 58
U1 2
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 199
EP 206
DI 10.1002/cav.123
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400007
DA 2024-07-18
ER

PT J
AU Heloir, A
   Courty, N
   Gibet, S
   Multon, F
AF Heloir, Alexis
   Courty, Nicolas
   Gibet, Syvie
   Multon, Franck
TI Temporal alignment of communicative gesture sequences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation; conversational agents; gestural communication; style
   translation
AB In this paper we address the problem of temporal alignment applied to capture communicative gestures conveying different styles. We propose a representation space that may be considered as robust to the spatial variability induced by style. By extending a multilevel dynamic time warping algorithm, we show how this extension can fulfil the goals of time correspondence between gesture sequences While preventing jerkiness introduced by standard time warping methods. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Lab Valoria, F-56000 Vannes, France.
RP Heloir, A (corresponding author), Lab Valoria, Campus Tohann, F-56000 Vannes, France.
EM alexis.heloir@univ-ubs.fr
OI Multon, Franck/0000-0003-2690-0077
CR Amaya K, 1996, PROC GRAPH INTERF, P222
   [Anonymous], 2004, KDD WORKSHOP MINING
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   BREGLER C, 2002, P PAC GRAPH
   Bruderlin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P97, DOI 10.1145/218380.218421
   CAO Y, 2003, P ACM SIGGRAPH EUR S, P225
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   Forbes K., 2005, Dans SCA '05, P67
   FU WC, 2005, VLDB 05, P649
   Gibet S, 2001, J VISUAL LANG COMPUT, V12, P657, DOI 10.1006/jvlc.2001.0202
   Glardon P, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P292, DOI 10.1109/CGI.2004.1309224
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Johnson M.P., 2003, Ph.D. thesis
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar Lucas., 2003, Flexible Automatic Motion Blending with Registration Curves
   Laban Rudolf., 1988, MASTERY MOVEMENT
   LEE J, 2002, P SIGGRAPH 2002
   MYERS CS, 1981, AT&T TECH J, V60, P1389, DOI 10.1002/j.1538-7305.1981.tb00272.x
   PELACHAUD C, 2006, LNAI
   Prillwitz S., 1989, Hamburg Notation System for Sign Languages
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Shapiro A, 2006, PROC GRAPH INTERF, P33
   SHUM HY, 2002, P ACM SIGGRAPH, P465
   Unuma Munetoshi, 1995, SIGGRAPH, P91
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   WITKIN A, 1995, COMPUTER GRAPHICS, V29, P105
   Zwitserlood I., 2004, Proceedings of the Conference and Workshop on Assistive Technologies for Vision and Hearing Impairment
NR 29
TC 21
Z9 21
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 347
EP 357
DI 10.1002/cav.138
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400021
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Schmidl, H
   Lin, MC
AF Schmidl, H
   Lin, MC
TI Geometry-driven physical interaction between avatars and virtual
   environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE virtual reality; inverse kinematics; dynamics; simulation; animation
ID INVERSE KINEMATICS PROBLEM
AB We present an interactive technique on virtual contact handling for avatars in virtual environments using geometry-driven physics. If a contact has occurred between an articulated avatar and a virtual environment, the global penetration depth and contact points are estimated based on a fast local penetration depth computation for decomposed convex pieces. The penetration depth and contact information are then used to resolve overlap between the avatar and the virtual environment. If applicable, joint angles for an articulated body are computed using an inverse kinematics approach based on cyclic coordinate descent. Resulting dynamic response with friction is modeled with impulse-based dynamics under the Coulomb friction law. We demonstrate the algorithm on a modestly complex virtual environment. The resulting system is able to maintain an interactive frame rate of 30-60 Hz. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 N Carolina Cent Univ, Dept Math & Comp Sci, Durham, NC USA.
C3 University of North Carolina; North Carolina Central University
RP N Carolina Cent Univ, Dept Math & Comp Sci, Durham, NC USA.
EM hschmidl@wpo.nccu.edu
CR Arnaldi B., 1989, State-of-the-Art in Computer Animation. Proceedings of Computer Animation '89, P113
   Baerlocher P, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P323, DOI 10.1109/IROS.1998.724639
   Boulic, 1995, INVERSE KINETICS CTR
   Boulic R., 1992, Computer Graphics Forum, V11, P189, DOI 10.1111/1467-8659.1140189
   Cameron S, 1997, IEEE INT CONF ROBOT, P3112, DOI 10.1109/ROBOT.1997.606761
   Cohen J. D., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P189, DOI 10.1145/199404.199437
   DOBKIN D, 1993, ALGORITHMICA, V9, P518, DOI 10.1007/BF01190153
   Ehmann S., 2000, Swift: Accelerated proximity queries between convex polyhedra by multilevel voronoi marching
   EHMANN S, 2001, COMPUTER GRAPHICS FO, V20
   KIM Y, 2002, P IEEE C ROB AUT
   Kim Y., 2002, ACM S COMPUTER ANIMA
   LIN MC, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1008, DOI 10.1109/ROBOT.1991.131723
   Milenkovic VJ, 2001, COMP GRAPH, P37, DOI 10.1145/383259.383263
   MIRITICH B, 1995, P 1995 S INT 3D GRAP, P181
   MONZANI JS, 2000, P EUR 2000
   NOVAKOVIC ZR, 1990, IEEE T ROBOTIC AUTOM, V6, P247, DOI 10.1109/70.54740
   Schmidl H, 2004, IEEE T VIS COMPUT GR, V10, P189, DOI 10.1109/TVCG.2004.1260770
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   WANG LCT, 1991, IEEE T ROBOTIC AUTOM, V7, P489, DOI 10.1109/70.86079
   Wilhelms J., 2001, Journal of Graphics Tools, V6, P27, DOI 10.1080/10867651.2001.10487539
   ZHAO JM, 1994, ACM T GRAPHIC, V13, P313, DOI 10.1145/195826.195827
NR 21
TC 2
Z9 2
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 229
EP 236
DI 10.1002/cav.25
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700012
DA 2024-07-18
ER

PT J
AU Wu, W
   Heng, PA
AF Wu, W
   Heng, PA
TI A hybrid condensed finite element model with GPU acceleration for
   interactive 3D soft tissue cutting
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE surgical simulation; soft tissue cutting and deformation; the GPU
   computation; the hybrid condensed finite element model
ID SURGERY SIMULATION
AB To meet the requirement of computer-aided medical operations, apart from the real-time deformation, it is also necessary in the design to simulate the tissue cutting and suturing in a surgery simulation. In this paper, we present a model on topology change and deformation of soft tissue, referred to as the hybrid condensed finite element model, based on the volumetric finite element method. The most important advantage of our model is its ability to achieve an interactive frame rate for the topology change in surgical simulation on standard PC platform. This is achieved through two innovations. One is to apply the condensation technique, by fully calculating the volumetric deformation in the operation part while only calculating the surface nodes in the non-operation part. Secondly, the major calculation work in the Conjugate Gradient solver for cutting and deformation is migrated from the CPU to the contemporary GPU to promote the calculation. Test examples have been given to show the feasibility and efficiency of the model. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
EM wwu1@cse.cuhk.edu.hk
OI Heng, Pheng Ann/0000-0003-3055-5034
CR AGARWAL P, 2002, STREAMING GEOMETRIC
   [Anonymous], 2001, Proceedings of the 2001 ACM/IEEE Conference on Supercomputing, SC '01, New York, NY, USA
   BOLZ J, 2003, P SIGGRAPH
   Bro-Nielsen M, 1998, P IEEE, V86, P490, DOI 10.1109/5.662874
   Bro-Nielsen M., 1996, Computer Graphics Forum, V15, pC57, DOI 10.1111/1467-8659.1530057
   BUCK I, 2003, GRAPHICS HARDWARE 20
   Cotin S, 1999, IEEE T VIS COMPUT GR, V5, P62, DOI 10.1109/2945.764872
   DELINGETTE H, 1994, P SOC PHOTO-OPT INS, V2359, P607
   DELINGETTE H, 1998, P IEEE SPEC ISS SURG, P521
   Fung YC, 1993, BIOMECHANICS MECH PR
   Gibson S.F. F., 1997, SURVEY DEFORMABLE MO
   GOVINDARAJU N, 2003, P GRAPH HARDW
   HARRIS MJ, 2003, P EUR SIGGRAPH WORKS
   Kardestuncer H., 1987, FINITE ELEMENT HDB
   KIM T, 2003, P ACM SIGGRAPH EUR S
   KRUGER J, 2003, P SIGGRAPH
   MORELAND K, 2003, P GRAPH HARDW
   Picinbono G., 2000, 4018 INRIA
NR 18
TC 60
Z9 71
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 219
EP 227
DI 10.1002/cav.24
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700011
DA 2024-07-18
ER

PT J
AU Barszcz, M
   Dziedzic, K
   Skublewska-Paszkowska, M
   Powroznik, P
AF Barszcz, Marcin
   Dziedzic, Krzysztof
   Skublewska-Paszkowska, Maria
   Powroznik, Pawel
TI 3D scanning digital models for virtual museums
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D scanning; 3D models; virtual museum; virtual reality
ID RECONSTRUCTION; REALITY
AB A great number of virtual museums exhibit archaeological artifacts in an interactive form using 3D digital models to disseminate them to as many users as possible. Currently, 3D models obtained as a result of scanning museum objects have gained a great popularity. This technique allows to faithfully reproduce objects and to expose artifacts too delicate and precious to be presented in the real world. The aim of this article is to create a virtual museum in the VR world using 3D models obtained by 3D scanning with structured light. The advantages of optimizing mesh models for their use in virtual exhibitions are discussed. Unity and Unreal Engine, were used to create virtual museums in the VR world. Two twin test applications were prepared. This allowed to compare the performance of the developed applications (processor, graphics card, and RAM load). A survey was also conducted among the users of the implemented virtual museum application. For immersion in the world of VR, a low-cost solution was used, involving the use of cheap VR frames, a smartphone, and a computer. The frames together with the smartphone were used to display the image, while the entire rendering process was performed on the computer.
C1 [Barszcz, Marcin; Dziedzic, Krzysztof; Skublewska-Paszkowska, Maria; Powroznik, Pawel] Lublin Univ Technol, Dept Comp Sci, Lublin, Poland.
C3 Lublin University of Technology
RP Barszcz, M (corresponding author), Lublin Univ Technol, Dept Comp Sci, Lublin, Poland.
EM m.barszcz@pollub.pl
RI Powroznik, Pawel/J-2165-2016; Barszcz, Marcin/D-2045-2017; Powroznik,
   Pawel/AAF-3445-2021; Yang, Li/JMP-4403-2023; Skublewska-Paszkowska,
   Maria/B-9761-2017
OI Powroznik, Pawel/0000-0002-5705-4785; Powroznik,
   Pawel/0000-0002-5705-4785; Skublewska-Paszkowska,
   Maria/0000-0002-0760-7126
CR Adams JW, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139800
   Anastasovitis E., 2023, DIGIT APPL ARCHAEOL, V28
   Arayaphan Watsaporn, 2022, Digital Applications in Archaeology and Cultural Heritage, DOI 10.1016/j.daach.2022.e00233
   Barszcz M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125321
   Besoain F, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031341
   Chen TL, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.565075
   Duran Z, 2012, J CULT HERIT, V13, P352, DOI 10.1016/j.culher.2011.12.006
   Graciano A, 2017, VIRTUAL ARCHAEOL REV, V8, P49, DOI 10.4995/var.2016.4650
   Gutowski Piotr, 2020, Procedia Comput Sci, V176, P2375, DOI 10.1016/j.procs.2020.09.303
   Kamariotou V., 2021, Digital Applications in Archaeology and Cultural Heritage, V21, pe00183, DOI [DOI 10.1016/J.DAACH.2021.E00183, 10.1016/j.daach.2021.e00183]
   Kesik J, 2017, ADV SCI TECHNOL-RES, V11, P87, DOI 10.12913/22998624/69419
   Kotsopoulos K., P 14 WSEAS INT C COM
   Kudaibergenova Diana T., 2017, Journal of Eurasian Studies, V8, P31
   Lee H, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.103229
   Lepouras G., 2004, Virtual Reality, V8, P927, DOI DOI 10.1007/S10055-004-0141-1
   Li J, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0261607
   Carvajal DAL, 2020, J CULT HERIT, V45, P234, DOI 10.1016/j.culher.2020.04.013
   Milosz Marek, 2022, Digital Applications in Archaeology and Cultural Heritage, DOI 10.1016/j.daach.2022.e00230
   Montusiewicz Jerzy, 2023, Learning in the Age of Digital and Green Transition: Proceedings of the 25th International Conference on Interactive Collaborative Learning (ICL2022). Lecture Notes in Networks and Systems (634), P1032, DOI 10.1007/978-3-031-26190-9_105
   Montusiewicz J., P 12 INT TECHN ED DE
   Montusiewicz J, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122311910
   Montusiewicz J, 2022, ADV SCI TECHNOL-RES, V16, P211, DOI 10.12913/22998624/152822
   Montusiewicz J, 2019, ADV SCI TECHNOL-RES, V13, P255, DOI 10.12913/22998624/113276
   Skamantzari M, 2016, INT ARCH PHOTOGRAMM, V41, P961, DOI 10.5194/isprsarchives-XLI-B5-961-2016
   Skulimowski S, 2019, IOP CONF SER-MAT SCI, V710, DOI 10.1088/1757-899X/710/1/012015
   Trunfio M, 2022, INFORM MANAGE-AMSTER, V59, DOI 10.1016/j.im.2022.103698
   Wachowiak MJ, 2009, J AM INST CONSERV, V48, P141, DOI 10.1179/019713609804516992
   Wei OC, 2019, INT ARCH PHOTOGRAMM, V42-2, P763, DOI 10.5194/isprs-archives-XLII-2-W9-763-2019
NR 28
TC 6
Z9 6
U1 17
U2 32
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2154
EA MAY 2023
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000997623000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wei, R
   Wang, PJ
AF Wei, Ran
   Wang, Pengjie
TI SeTGAN: Semantic-text guided face image generation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE face image generation; generative adversarial networks; joint
   representations; multi-modal generation
AB In this article, we propose a method to jointly control face image generation through semantic segmentation maps and text. Existing semantic segmentation maps lack detailed face attributes such as beards, and it is difficult to explicitly represent the gender of the target person by virtue of the semantic maps. State-of-the-art face image generation methods guided by semantic segmentation maps mostly solved this by introducing the original image for supervision, which cannot accurately control the detailed attributes of the target face. At the same time, the text-guided image generation method perform poorly in controlling the front and side of the face pose. Therefore, we propose an idea that the semantic segmentation map controls the coarse content of the target image and the text controls the fine details of the target image. Through the well-designed mapping network and content mixing mechanism, the model in this article flexibly draws on the advantages of the two modes, and can generate high-resolution images that are diverse, high-quality, and more faithful to the target in detail attributes than most of previous methods. Extensive experiments demonstrate the superior performance of the proposed method in terms of accuracy and fidelity.
C1 [Wei, Ran; Wang, Pengjie] Dalian Minzu Univ, Sch Comp Sci, Dalian, Peoples R China.
   [Wang, Pengjie] Dalian Minzu Univ, Sch Comp Sci, Dalian 116600, Peoples R China.
C3 Dalian Minzu University; Dalian Minzu University
RP Wang, PJ (corresponding author), Dalian Minzu Univ, Sch Comp Sci, Dalian 116600, Peoples R China.
EM pengjiewang@qq.com
RI Wang, Pengjie/KHE-3288-2024
OI Wang, Pengjie/0000-0003-1276-9776; wei, ran/0000-0001-7150-620X
FU Natural Science Foundation of Liaoning Province [2023-MS-133]; Dalian
   Minzu University [140140, 110222]
FX Natural Science Foundation of Liaoning Province, Grant/Award
   Number:2023-MS-133; Dalian Minzu University, Grant/Award Numbers:
   110222, 140140
CR [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], High-resolution image synthesis and semantic manipulation with conditional GANs
   Collins E, 2020, PROC CVPR IEEE, P5770, DOI 10.1109/CVPR42600.2020.00581
   Deng J., ARCFACE ADDITIVE ANG
   Ghosh A, 2019, IEEE I CONF COMP VIS, P1171, DOI 10.1109/ICCV.2019.00126
   Goetschalckx L, 2019, IEEE I CONF COMP VIS, P5743, DOI 10.1109/ICCV.2019.00584
   Goodfellow I., GENERATIVE ADVERSARI
   Heusel M., P 31 INT C NEUR INF
   Jahanian A., 2020, STEERABILITY GENERAT
   Karras T., P 2019 IEEE CVF C CO
   Li B., CONTROLLABLE TEXT TO
   Nam S., 2018, Advances in Neural Information Processing Systems, P42
   Patashnik O., P 2021 IEEE CVF INT
   Radford Alec, LEARNING TRANSFERABL
   Reed S., Generative adversarial text to image synthesis
   Richardson E., 2020, ENCODING STYLE STYLE
   Shen Y., P 2020 IEEE CVF C CO
   Tao M., DF GAN DEEP FUSION G
   Tao X., P 2018 IEEE CVF C CO
   Wei T., 2021, P 2022 IEEECVF C COM, P18051
   Xia W., TEDIGAN TEXT GUIDED
   Xia W., 2019, CALI SKETCH STROKE C
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu M., P 2019 IEEE CVF C CO
NR 24
TC 2
Z9 2
U1 3
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2155
EA MAY 2023
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000993003200001
DA 2024-07-18
ER

PT J
AU Mailee, H
   Sonlu, S
   Güdükbay, U
AF Mailee, Hamila
   Sonlu, Sinan
   Gudukbay, Ugur
TI Personality expression in cartoon animal characters using Sasang
   typology
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cartoon animation; Laban movement analysis; personality expression;
   Sasang typology
ID MOVEMENT; TRAITS
AB The movement style is an adequate descriptor of different personalities. While many studies investigate the relationship between apparent personality and high-level motion qualities in humans, similar research for animal characters still needs to be done. The variety in animals' skeletal configurations and texture complicates their pose estimation process. Our affect analysis framework includes a workflow for pose extraction in animal characters and a parameterization of the high-level animal motion descriptors inspired by Laban movement analysis. Using a data set of quadruped walk cycles, we prove the display of typologies in cartoon animal characters, reporting the point-biserial correlation between our motion parameters and the Sasang categories that reflect different personalities.
C1 [Mailee, Hamila] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
   [Sonlu, Sinan; Gudukbay, Ugur] Bilkent Univ, Dept Comp Engn, Ankara, Turkiye.
   [Gudukbay, Ugur] Bilkent Univ, Dept Comp Engn, Ankara, Turkiye.
C3 Sharif University of Technology; Ihsan Dogramaci Bilkent University;
   Ihsan Dogramaci Bilkent University
RP Güdükbay, U (corresponding author), Bilkent Univ, Dept Comp Engn, Ankara, Turkiye.
OI Mailee, Hamila/0000-0001-8762-055X; Sonlu, Sinan/0000-0002-9743-6833
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [122E123]
FX The Scientific and Technological Research Council of Turkey (TUBITAK),
   Grant/Award Number: 122E123
CR Aberman K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322999
   [Anonymous], 2016, Tensorpack
   Aristidou A, 2015, ACM J COMPUT CULT HE, V8, DOI 10.1145/2755566
   Aslan S, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104163
   Augereau O, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070087
   Cao JK, 2019, IEEE I CONF COMP VIS, P9497, DOI 10.1109/ICCV.2019.00959
   Chae H, 2003, J ALTERN COMPLEM MED, V9, P519, DOI 10.1089/107555303322284811
   Chae H, 2009, EVID-BASED COMPL ALT, V6, P21, DOI 10.1093/ecam/nep079
   Chen YC, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102897
   Chu WT, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P417, DOI 10.1145/3078971.3079031
   Delp SL, 2000, COMPUT SCI ENG, V2, P46, DOI 10.1109/5992.877394
   Durupinar F, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983620
   Erkoc Z, 2022, UNDERSTANDING SOCIAL, V173, P74
   Ferres K, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14040097
   Foroud A, 2003, DEV PSYCHOBIOL, V42, P35, DOI 10.1002/dev.10088
   Fritz RG, 2020, BRAIN BEHAV, V10, DOI 10.1002/brb3.1752
   Graving JM, 2019, ELIFE, V8, DOI 10.7554/eLife.47994
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hogan R, 2020, PERS INDIV DIFFER, V152, DOI 10.1016/j.paid.2019.109561
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jiang L, 2022, COMPUT VIS IMAGE UND, V222, DOI 10.1016/j.cviu.2022.103483
   Jung AB, 2020, IMGAUG PYTHON LIB AU
   Khungurn P, 2016, P 1 INT WORKSH COM A, P1
   Liu XL, 2021, FRONT CELL NEUROSCI, V15, DOI 10.3389/fncel.2021.621252
   Mathis A, 2021, DEEPLABCUT SOFTWARE
   Mathis A, 2020, NEURON, V108, P44, DOI 10.1016/j.neuron.2020.09.017
   Nath T, 2019, NAT PROTOC, V14, P2152, DOI 10.1038/s41596-019-0176-0
   Pereira TD, 2022, NAT METHODS, V19, P486, DOI 10.1038/s41592-022-01426-1
   Pereira TD, 2019, NAT METHODS, V16, P117, DOI 10.1038/s41592-018-0234-5
   Siarohin A, 2019, PROC CVPR IEEE, P2372, DOI 10.1109/CVPR.2019.00248
   Smith HJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073697
   Spiegel O, 2017, ECOL LETT, V20, P3, DOI 10.1111/ele.12708
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang WW, 2010, GEOGR COMPASS, V4, pCP7, DOI 10.1111/j.1749-8198.2010.00337.x
   Weiss A, 2018, J PERS, V86, P12, DOI 10.1111/jopy.12310
   Whan Oh Sung, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P1066
   Willett NS, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P88, DOI 10.1145/3377325.3377505
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yang C, 2020, FRONT MAR SCI, V7, DOI 10.3389/fmars.2020.00032
   Yiannakides A, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1887
   Yoon YJ, 2017, INTEGR MED RES, V6, P156, DOI 10.1016/j.imr.2017.02.002
NR 41
TC 0
Z9 0
U1 2
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2164
EA MAY 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000989814600001
DA 2024-07-18
ER

PT J
AU Che, AL
   Yang, JH
   Guo, C
   Dai, HN
   Xie, HR
   Li, P
AF Che, Aolin
   Yang, Jing-Hua
   Guo, Cai
   Dai, Hong-Ning
   Xie, Haoran
   Li, Ping
TI AEGAN: Generating imperceptible face synthesis via autoencoder-based
   generative adversarial network
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE autoencoder; face image protection; face recognition; multi-head
   attention
AB Face recognition (FR) systems based on convolutional neural networks have shown excellent performance in human face inference. However, some malicious users may exploit such powerful systems to identify others' face images disclosed by victims' social network accounts, consequently obtaining private information. To address this emerging issue, synthesizing face protection images with visual and protective effects is essential. However, existing face protection methods encounter three critical problems: poor visual effect, limited protective effect, and trade-off between visual and protective effects. To address these challenges, we propose a novel face protection approach in this article. Specifically, we design a generative adversarial network (GAN) framework with an autoencoder (AEGAN) as the generator to synthesize the protection images. It is worth noting that we introduce an interpolation upsampling module in the decoder in order to let the synthesized protection images evade recognition by powerful convolution-based FR systems. Furthermore, we introduce an attention module with a perceptual loss in AEGAN to enhance the visual effects of synthesized images by AEGAN. Extensive experiments have shown that AEGAN not only can maintain the comfortable visual quality of synthesized images but also prevent the recognition of commercial FR systems, including Baidu and iKLYTEK.
C1 [Che, Aolin; Yang, Jing-Hua] Macau Univ Sci & Technol, Fac Innovat Engn, Macau, Peoples R China.
   [Guo, Cai] Hanshan Normal Univ, Sch Comp & Informat Engn, Chaozhou, Peoples R China.
   [Dai, Hong-Ning] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China.
   [Xie, Haoran] Lingnan Univ, Dept Comp & Decis Sci, Hong Kong, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Sch Design, Hong Kong, Peoples R China.
C3 Macau University of Science & Technology; Hanshan Normal University;
   Hong Kong Baptist University; Lingnan University; Hong Kong Polytechnic
   University; Hong Kong Polytechnic University
RP Xie, HR (corresponding author), Lingnan Univ, Dept Comp & Decis Sci, Hong Kong, Peoples R China.; Li, P (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.; Li, P (corresponding author), Hong Kong Polytech Univ, Sch Design, Hong Kong, Peoples R China.
EM hrxie@ln.edu.hk; p.li@polyu.edu.hk
RI Dai, Hong-Ning/B-1931-2012; Li, Ping/AAO-2019-2020; Xie,
   Haoran/AFS-3515-2022
OI Dai, Hong-Ning/0000-0001-6165-4196; Li, Ping/0000-0002-1503-0240; Xie,
   Haoran/0000-0003-0965-3617; Guo, Cai/0000-0001-7524-2272
FU Hong Kong Polytechnic University [P0030419, P0042740, P0044520,
   P0043906, P0035358]
FX ACKNOWLEDGMENTS This work was supported by The Hong Kong Polytechnic
   University under Grants P0030419, P0042740, P0044520, P0043906, and
   P0035358.
CR Alipour B., P INT C TRUST PRIV D
   [Anonymous], 2017, IEEE C COMP VIS PATT
   Deb D., P INT JOINT C BIOM
   Deng J., ARCFACE ADDITIVE ANG
   Gafni O., P IEEE CVF INT C COM
   Gatys LA., P IEEE C COMP VIS PA
   Guo MH., VISUAL ATTENTION NET
   Hu S., P IEEE CVF C COMP VI
   Huang GaryB., 2007, Labeled faces in the wild: A database for studying face recognition in unconstrained environments
   Jing YH, 2021, IEEE T CYBERNETICS, V51, P568, DOI 10.1109/TCYB.2019.2904768
   Johnson J., Perceptual losses for real-time style transfer and super-resolution
   Jung SG., P INT C EL BUS
   Jung SG., P INT AAAI C WEB SOC
   Komkov S, 2021, INT C PATT RECOG, P819, DOI 10.1109/ICPR48806.2021.9412236
   Lin JC, 2021, NEURAL NETWORKS, V133, P132, DOI 10.1016/j.neunet.2020.09.001
   Liu J, 2023, INDOOR BUILT ENVIRON, V32, P1638, DOI 10.1177/1420326X231158020
   Lucas A, 2019, IEEE T IMAGE PROCESS, V28, P3312, DOI 10.1109/TIP.2019.2895768
   Mirjalili V, 2018, INT CONF BIOMETR, P82, DOI 10.1109/ICB2018.2018.00023
   Neto PC, 2022, IEEE WINT CONF APPL, P390, DOI 10.1109/WACVW54805.2022.00045
   Nousi P., 2020, SIGNAL PROCESS-IMAGE, V81, P1
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Schroff F., FaceNet: A Unified Embedding for Face Recognition and Clustering
   Shopon M., 2021, Journal of Cybersecurity and Privacy, V1, P470
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang R., P ACM INT JOINT C PE
   Wang Y, 2018, J PERS SOC PSYCHOL, V114, P246, DOI 10.1037/pspa0000098
   Wu X., RESPONSES CRITIQUES
   Yang X., P IEEE CVF INT C COM
   You QZ, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1026, DOI 10.1109/ICDMW.2014.93
   Zhong YY, 2021, IEEE T INF FOREN SEC, V16, P1452, DOI 10.1109/TIFS.2020.3036801
   Zhu X., P IEEE CVF INT C COM
NR 32
TC 1
Z9 1
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2160
EA MAY 2023
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000983936300001
DA 2024-07-18
ER

PT J
AU Ysique-Neciosup, J
   Mercado-Chavez, N
   Ugarte, W
AF Ysique-Neciosup, Jose
   Mercado-Chavez, Nilton
   Ugarte, Willy
TI DeepHistory: A convolutional neural network for automatic animation of
   museum paintings
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE convolutional neural network; image animation; keypoints; U-Net; video
   super-resolution
AB Deep learning models have shown that it is possible to train neural networks to dispense, to a lesser or greater extent, with the need for human intervention for the task of image animation, which helps to reduce not only the production time of these audiovisual pieces, but also presents benefits with respect to the economic investment they require to be made. However, these models suffer from two common problems: the animations they generate are of very low resolution and they require large amounts of training data to generate good results. To deal with these issues, this article introduces the architectural modification of a state-of-the-art image animation model integrated with a video super-resolution model to make the generated videos more visually pleasing to viewers. Although it is possible to train the animation models with higher resolution images, the time it would take to train them would be much longer, which does not necessarily benefit the quality of the animation, so it is more efficient to complement it with another model focused on improving the animation resolution of the generated video as we demonstrate in our results. We present the design and implementation of a convolutional neural network based on an state-of-art model focused on the image animation task, which is trained with a set of facial data from videos extracted from the YouTube platform. To determine which of all the modifications to the selected state-of-the-art model architecture is better, the results are compared with different metrics that evaluate the performance in image animation and video quality enhancement tasks. The results show that modifying the architecture of the model focused on the detection of characteristic points significantly helps to generate more anatomically and visually attractive videos. In addition, perceptual testing with users shows that using a super-resolution video model as a plugin helps generate more visually appealing videos.
C1 [Ysique-Neciosup, Jose; Mercado-Chavez, Nilton; Ugarte, Willy] Univ Peruana Ciencias Aplicadas UPC, Comp Sci, Lima, Peru.
C3 Universidad Peruana de Ciencias Aplicadas (UPC)
RP Ugarte, W (corresponding author), Univ Peruana Ciencias Aplicadas UPC, Comp Sci, Lima, Peru.
EM willy.ugarte@upc.pe
CR [Anonymous], 2016, ACCURATE IMAGE SUPER
   [Anonymous], 2017, Int. J. Rough Sets Data Anal., DOI 10.4018/ijrsda.2017070105
   Bian SJ, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010027
   Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304
   Cheung, 2021, CORR
   Chu MY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392457
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Efraty B. A., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P278, DOI 10.1109/FG.2011.5771411
   Fu C., 2021, IEEE T INF FORENS SE, V16
   Geng JH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275043
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Khan N, 2020, INT J COMPUT VISION, V128, P1433, DOI 10.1007/s11263-019-01256-3
   Khan S., 2018, Synth. Lect. Comput. Vis., V8, P1, DOI [DOI 10.2200/S00822ED1V01Y201712COV015, 10.1007/978-3-031-01822-0]
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu, 2020, CORR
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Otberdout N, 2022, IEEE T PATTERN ANAL, V44, P848, DOI 10.1109/TPAMI.2020.3002500
   Ouanan H, 2016, COLLOQ INF SCI TECH, P487, DOI 10.1109/CIST.2016.7805097
   Pumarola, 2020, INT J COMP VIS, V128
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Siarohin A., 2019, ANIMATING ARBITRARY
   Siarohin Aliaksandr, 2019, NeurIPS
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8
   Wang LG, 2020, IEEE T IMAGE PROCESS, V29, P4323, DOI 10.1109/TIP.2020.2967596
   Wang LD, 2018, IEEE ENG MED BIO, P514, DOI 10.1109/EMBC.2018.8512300
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wiles O., 2018, ECCV, P690
   Wiles O, 2018, LECT NOTES COMPUT SC, V11217, P690, DOI 10.1007/978-3-030-01261-8_41
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhang, 2020, NEUROCOMPUTING, V398
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201285
NR 43
TC 1
Z9 1
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2022
VL 33
IS 5
AR e2110
DI 10.1002/cav.2110
EA AUG 2022
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5E9FV
UT WOS:000847283100001
DA 2024-07-18
ER

PT J
AU Ma, SJ
   Wu, HZ
   Ren, Z
   Zhou, K
AF Ma, Shengjie
   Wu, Hongzhi
   Ren, Zhong
   Zhou, Kun
TI A multiresolution network architecture for deferred neural lighting
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation; complex appearance; multiresolution; relighting
ID APPEARANCE
AB We present a novel multiresolution network architecture for deferred neural lighting. The key idea is to explicitly separate the processing of appearance at different spatial resolutions, leading to considerably improved high-frequency details as well as temporal stability in animation sequences with varying view conditions. Moreover, our network is only half the size of the original one, and requires less training data to converge to satisfactory results. The network is tested over five captured datasets from deferred neural lighting and may be extended to other neural appearance techniques, such as NeRF or neural textures.
C1 [Ma, Shengjie; Wu, Hongzhi; Ren, Zhong; Zhou, Kun] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
   [Ma, Shengjie; Wu, Hongzhi; Ren, Zhong; Zhou, Kun] ZJU FaceUnity Joint Lab Intelligent Graph, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Zhou, K (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
EM kunzhou@acm.org
RI Kun, Zhou/GMX-1497-2022
OI Ma, Shengjie/0000-0001-9204-1624
FU Zhejiang Provincial Key RD Program [2022C01057]; NSF China [61890954,
   62022072]
FX Zhejiang Provincial Key R&D Program, Grant/Award Number: 2022C01057; NSF
   China, Grant/Award Numbers: 61890954, 62022072; XPLORER PRIZE
CR Bi S., 2020, DEEP 3D CAPTURE GEOM, P5960
   Chen AP, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203192
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Deschaintre V, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13765
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Eslami SMA, 2018, SCIENCE, V360, P1204, DOI 10.1126/science.aar6170
   Gao D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417767
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   Haber T, 2009, PROC CVPR IEEE, P627, DOI 10.1109/CVPRW.2009.5206753
   Hedman P, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275084
   Holroyd M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778836
   Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Kang KZ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356492
   Kang KZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201279
   Karras T., 2018, PROGRESSIVE GROWING
   Kingma D. P., 2014, arXiv
   Kulkarni TD, 2015, ADV NEUR IN, V28
   Kuznetsov A, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459795
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li X, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073641
   Li ZQ, 2018, LECT NOTES COMPUT SC, V11207, P74, DOI 10.1007/978-3-030-01219-9_5
   Li Zi-xin, 2018, Advanced Technology of Electrical Engineering and Energy, V37, P1, DOI 10.12067/ATEEE1712020
   Meka A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323027
   Meshry M, 2019, PROC CVPR IEEE, P3871, DOI 10.1109/CVPR.2019.00704
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Nam G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275017
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Peers P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477929
   Philip J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323013
   Ren PR, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766899
   Srinivasan PP., LEARNING SYNTHESIZE, P2243
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Sun TC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323008
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Vlasic Daniel, 2009, ACM TRANSACTIONS ON GRAPHICS, V28, P2, DOI [DOI 10.1145/1618452.1618520, 10.1145/1618452.1618520]
   Weinmann Michael, 2015, SIGGRAPH ASIA COURSE, P1
   Wood DN, 2000, COMP GRAPH, P287, DOI 10.1145/344779.344925
   Xia R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980248
   Xu ZX, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323007
   Xu ZX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201313
   Ye WJ, 2018, COMPUT GRAPH FORUM, V37, P201, DOI 10.1111/cgf.13560
   Yu PP, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-021-3282-4
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang Xiuming, 2021, ARXIV210601970
NR 49
TC 0
Z9 0
U1 1
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2060
DI 10.1002/cav.2060
EA JUN 2022
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000810258900001
DA 2024-07-18
ER

PT J
AU Botha, BS
   de Wet, L
   Botma, Y
AF Botha, Benjamin S.
   de Wet, Lizette
   Botma, Yvonne
TI Experts' review of a virtual environment for virtual clinical simulation
   in South Africa
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Review
DE human&#8208; computer interaction; virtual reality; virtual worlds
ID HEALTH-SCIENCES; REALITY; STUDENTS
AB Virtual reality (VR) is becoming ever more used within the field of education. During this study, the researchers created a virtual environment (VE) for use in Southern Africa, where students could practice managing a young adult with a foreign object in the airway. The aim of the VE was to determine whether a viable, "home-made" solution could be created which could also be expanded later on to incorporate more scenarios. This was due to the expensive nature of existing systems for virtual clinical simulation. To determine whether the VE is usable, two expert review panels assisted in testing the VE. The first-panel being Computer Science experts and the second Health Science (HS) experts. Each panel evaluated the environment and the scenario using heuristic evaluation and cognitive walkthroughs. The recommendations made during each of the expert reviews were implemented to improve the VE, thus enabling students to experience an accurate, virtual scenario that could positively influence their learning experience. The findings and recommendations made during the expert reviews are presented in this paper to assist in improving future developments within the field of VR in HS education, especially for developing countries in Africa.
C1 [Botha, Benjamin S.; Botma, Yvonne] Univ Free State, Sch Nursing, ZA-9300 Bloemfontein, South Africa.
   [de Wet, Lizette] Univ Free State, Dept Comp Sci & Informat, Bloemfontein, South Africa.
C3 University of the Free State; University of the Free State
RP Botha, BS (corresponding author), Univ Free State, Sch Nursing, ZA-9300 Bloemfontein, South Africa.
EM bothabs@ufs.ac.za
RI Botha, Benjamin Stephanus/AFO-0359-2022; De+Wet, Lizette/AGZ-8577-2022
OI Botha, Benjamin Stephanus/0000-0002-3769-4507; De+Wet,
   Lizette/0000-0001-6819-6984
CR Albert W. S., 2013, US PROF ASS 12 ANN C
   Alfadil MM, 2017, THESIS, P138
   [Anonymous], 2015, Interaction design: Beyond human-computer interaction
   Bellou J., 2006, IADIS INT C E SOC 20, V1, P122
   Birt J, 2017, AUSTRALAS J EDUC TEC, V33, P69, DOI 10.14742/ajet.3596
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Butt AL, 2018, CLIN SIMUL NURS, V16, P25, DOI 10.1016/j.ecns.2017.09.010
   De Oliveira Malaquias F.F., 2017, TECHNOL DISABIL, V28, P133
   Dooley K, 2017, STUD AUSTRALAS CINE, V11, P161, DOI 10.1080/17503175.2017.1387357
   Dubovi I, 2017, COMPUT EDUC, V113, P16, DOI 10.1016/j.compedu.2017.05.009
   Green J, 2014, COLLEGIAN, V21, P135, DOI 10.1016/j.colegn.2013.11.004
   Hui Z, 2017, INT J MIN SCI TECHNO, V27, P717, DOI 10.1016/j.ijmst.2017.05.005
   Johnson C.M., 2009, Journal of Virtual Worlds Research, V2, P4, DOI DOI 10.4101/JVWR.V2I2.699
   Kleinert R, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.5035
   Kugler L, 2017, COMMUN ACM, V60, P15, DOI 10.1145/3105444
   Lazar J., 2010, Research Methods in Human-Computer Interaction
   Lessick S, 2017, J MED LIBR ASSOC, V105, P407, DOI 10.5195/jmla.2017.329
   Lewis RJ., 1991, ACM SIGCHI B, V23, P79, DOI [10.1145/126729.1056077, DOI 10.1145/126729.1056077]
   McKerlich R., 2011, MERLOT Journal of Online Learning and Teaching, V7, P324
   Moro C, 2017, ANAT SCI EDUC, V10, P549, DOI 10.1002/ase.1696
   Nielsen J., 1994, Heuristic evaluation. Usability inspection methods, V17, P25
   NKaoua, 2012, ACM S VIRTUAL REALIT, P113, DOI [10.1145/2407336.2407359, DOI 10.1145/2407336.2407359]
   Oculus, 2019, OC RIFT S
   Stein C, 2016, MEDIA TROPES, V6, P52
   Stretton T, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2131
   Unity, 2018, UN OC DEV
   Verkuyl M, 2016, NURS EDUC TODAY, V46, P81, DOI 10.1016/j.nedt.2016.08.024
NR 27
TC 2
Z9 2
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2021
VL 32
IS 2
AR e1983
DI 10.1002/cav.1983
EA DEC 2020
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RK2HP
UT WOS:000595102700001
DA 2024-07-18
ER

PT J
AU Li, YR
   Qiu, LT
   Wang, L
   Liu, FD
   Wang, Z
   Poiana, SI
   Yang, XS
   Zhang, JJ
AF Li, Yanran
   Qiu, Lingteng
   Wang, Li
   Liu, Fangde
   Wang, Zhao
   Poiana, Sebastian Iulian
   Yang, Xiaosong
   Zhang, Jianjun
TI Densely connected GCN model for motion prediction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE densely; GCN; motion prediction; Spatial temporal
AB Human motion prediction is a fundamental problem in understanding human natural movements. This task is very challenging due to the complex human body constraints and diversity of action types. Due to the human body being a natural graph, graph convolutional network (GCN)-based models perform better than the traditional recurrent neural network (RNN)-based models on modeling the natural spatial and temporal dependencies lying in the motion data. In this paper, we develop the GCN-based models further by adding densely connected links to increase their feature utilizations and address oversmoothing problem. More specifically, the GCN block is used to learn the spatial relationships between the nodes and each feature map of the GCN block propagates directly to every following block as input rather than residual linked. In this way, the spatial dependency of human motion data is exploited more sufficiently and the features of different level of scale are fused more efficiently. Extensive experiments demonstrate our model achieving the state-of-the-art results on CMU dataset.
C1 [Li, Yanran; Wang, Li; Yang, Xiaosong; Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
   [Qiu, Lingteng] Harbin Inst Technol, Shenzhen, Peoples R China.
   [Liu, Fangde] SurgicalAI Cn, Shenzhen, Peoples R China.
   [Wang, Zhao] China Horizon Robot, Nanjing, Peoples R China.
   [Poiana, Sebastian Iulian] Bournemouth Univ, Natl Ctr Internet Things IoT Cyber Secur, Poole, Dorset, England.
C3 Bournemouth University; Harbin Institute of Technology; Bournemouth
   University
RP Yang, XS (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
EM xyang@bournemouth.ac.uk
RI Wang, Li/JDD-5101-2023
OI Wang, Li/0000-0002-5793-2437; Li, Yanran/0000-0003-1385-7604
FU EU H2020 under the REA grant agreement [691215]; SouthWest Creative
   Technology Network; Key Laboratory of Agricultural Internet of Things,
   Ministry of Agriculture and Rural Affairs, Yangling, Shaanxi, China
   [2018AIOT-09]
FX EU H2020 under the REA grant agreement, Grant/Award Number: 691215; the
   Automation Fellow in the SouthWest Creative Technology Network; the Key
   Laboratory of Agricultural Internet of Things, Ministry of Agriculture
   and Rural Affairs, Yangling, Shaanxi 712100, China, Grant/Award Number:
   2018AIOT-09
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   [Anonymous], 2017, PROC IEEE C COMPUT V
   [Anonymous], 2018, P 32 AAAI C ART INT
   Bhattacharyya A, 2018, PROC CVPR IEEE, P4194, DOI 10.1109/CVPR.2018.00441
   Bütepage J, 2017, PROC CVPR IEEE, P1591, DOI 10.1109/CVPR.2017.173
   Chen S., 2020, ARXIV200300601
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Gaur U, 2011, IEEE I CONF COMP VIS, P2595, DOI 10.1109/ICCV.2011.6126548
   Ghosh P, 2017, INT CONF 3D VISION, P458, DOI 10.1109/3DV.2017.00059
   Gui L.-Y., 2018, P EUR C COMP VIS ECC, P786
   Gui LY, 2018, IEEE INT C INT ROBOT, P562, DOI 10.1109/IROS.2018.8594452
   Guo X, 2019, AAAI CONF ARTIF INTE, P2580
   Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Kipf T. N., 2016, SEMISUPERVISED CLASS, P1
   Koppula Hema, 2013, P ICML, P792
   Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335
   Kundu JN, 2019, AAAI CONF ARTIF INTE, P8553
   Li C, 2018, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2018.00548
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li YR, 2019, VISUAL COMPUT, V35, P1143, DOI 10.1007/s00371-019-01692-9
   Mao W, 2019, IEEE I CONF COMP VIS, P9488, DOI 10.1109/ICCV.2019.00958
   Pavllo Dario, 2018, BRIT MACHINE VISION, V41
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
NR 27
TC 1
Z9 1
U1 8
U2 36
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1958
DI 10.1002/cav.1958
EA AUG 2020
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000563751100001
OA Green Accepted, hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Favaretto, RM
   dos Santos, RR
   Musse, SR
   Vilanova, F
   Costa, AB
AF Favaretto, Rodolfo Migon
   dos Santos, Roberto Rosa
   Musse, Soraia Raupp
   Vilanova, Felipe
   Costa, Angelo Brandelli
TI Investigating cultural aspects in the fundamental diagram using
   convolutional neural networks and virtual agent simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE convolutional neural networks; cultural aspects; group behaviors;
   virtual human simulation
ID PEOPLE
AB This paper presents a study, organized in two phases, regarding group behavior in a controlled experiment focused on differences in an important attribute that vary across cultures-personal spaces. First, we want to study and compare the spatial behavior different populations adopt with respect to their personal space. Second, we want to use simulation of virtual agents to artificially generate movements of people in similar situations and validate them using real video sequences. Our main goal is to be able to extract from video sequences and then simulate variations in populations in a coherent way with literature that studies cultural aspects. In addition to the cultural aspects, we also investigate the personality model in the studied videos using OCEAN (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism). Finally, we propose a way to simulate the fundamental diagram experiment from other countries using the OCEAN psychological trait model as input. Results indicate that the simulated countries have consistent characteristics with the expected literature.
C1 [Favaretto, Rodolfo Migon; dos Santos, Roberto Rosa; Musse, Soraia Raupp] Pontifical Catholic Univ Rio Grande Sul PUCRS, Grad Program Comp Sci, Virtual Humans Simulat Lab VHLab, Porto Alegre, RS, Brazil.
   [Vilanova, Felipe; Costa, Angelo Brandelli] Pontifical Catholic Univ Rio Grande Sul PUCRS, Grad Program Psychol, Porto Alegre, RS, Brazil.
C3 Pontificia Universidade Catolica Do Rio Grande Do Sul; Pontificia
   Universidade Catolica Do Rio Grande Do Sul
RP Favaretto, RM (corresponding author), Pontificia Univ Catolica Rio Grande do Sul, Sch Technol, Virtual Humans Simulat Lab VHLab, Ipiranga Ave 6681, BR-90619900 Porto Alegre, RS, Brazil.
EM rodolfo.favaretto@edu.pucrs.br
RI Brandelli Costa, Angelo/E-6988-2015; Musse, Soraia Raupp/AAS-3787-2021;
   Vilanova, Felipe/JAN-6367-2023; Musse, Soraia Raupp R/G-4801-2012;
   Vilanova, Felipe/Y-4861-2019
OI Brandelli Costa, Angelo/0000-0002-0742-8152; Vilanova,
   Felipe/0000-0002-2516-9975; Vilanova, Felipe/0000-0002-2516-9975; Migon
   Favaretto, Rodolfo/0000-0002-8940-7813
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior [001];
   Office of Naval Research Global; Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico; Fundacao de Amparo a Pesquisa do Estado do Rio
   Grande do Sul
FX Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior, Grant/Award
   Number: 001; Office of Naval Research Global; Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico; Fundacao de Amparo a Pesquisa
   do Estado do Rio Grande do Sul
CR Aiello J.R. T., 1980, PERSONAL SPACE CROWD
   [Anonymous], 2002, 5 FACTOR MODEL PERSO
   [Anonymous], 2013, J. Postdr. Res
   [Anonymous], LECT NOTES COMPUTER
   BAXTER JC, 1970, SOCIOMETRY, V33, P444, DOI 10.2307/2786318
   Bicho AD, 2012, COMPUT GRAPH-UK, V36, P70, DOI 10.1016/j.cag.2011.12.004
   Cai ZB, 2014, C IND ELECT APPL, P1841, DOI 10.1109/ICIEA.2014.6931467
   Cao SC, 2018, PHYSICA A, V506, P661, DOI 10.1016/j.physa.2018.04.084
   Cao SC, 2017, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/aa620d
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chattaraj U, 2009, ADV COMPLEX SYST, V12, P393, DOI 10.1142/S0219525909002209
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Dyaram L, 2005, J Soc Sci, V10, P185, DOI [DOI 10.1080/09718923.2005.11892479, 10.1080/09718923.2005.11892479]
   Evans GW, 2007, J ENVIRON PSYCHOL, V27, P90, DOI 10.1016/j.jenvp.2006.10.002
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Favaretto R. M., 2018, MACH VISION APPL, P1
   Favaretto R, 2017, SIBGRAPI, P223, DOI 10.1109/SIBGRAPI.2017.36
   Favaretto RM, 2016, IEEE IMAGE PROC, P2936, DOI 10.1109/ICIP.2016.7532897
   Favaretto RM, 2016, SIBGRAPI, P201, DOI [10.1109/SIBGRAPI.2016.036, 10.1109/SIBGRAPI.2016.34]
   Feng LA, 2015, IEEE J-STSP, V9, P317, DOI 10.1109/JSTSP.2014.2365765
   Flötteröd G, 2015, TRANSPORT RES B-METH, V71, P194, DOI 10.1016/j.trb.2014.11.001
   Fridman N., 2013, AAMAS, P143
   GOLDBERG LR, 1990, J PERS SOC PSYCHOL, V59, P1216, DOI 10.1037/0022-3514.59.6.1216
   Hall Edward Twitchell, 1966, HIDDEN DIMENSION
   Hofstede G., 2011, DIMENSIONALIZING CUL, DOI DOI 10.9707/2307-0919.1014
   Jelic A, 2012, PHYS REV E, V85, DOI 10.1103/PhysRevE.85.036111
   Jr PTC, 2007, NEO PI R INVENTARIO
   Lang N., 1987, Collectivity in social group work: concept and practice
   Le Bon Gustave., 2006, CROWD STUDY POPULAR
   Predtechenskii V.M., 1978, Planning for Foot Traffic Flow in Buildings
   Redmon A., 2017, P IEEE C COMP VIS PA, P7263, DOI 10.1109/cvpr.2017.690
   Seyfried A, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/10/P10002
   Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285
   Jacques JCS, 2007, PATTERN ANAL APPL, V10, P321, DOI 10.1007/s10044-007-0070-1
   Sommer R., 1969, Personal Space: Behavioural Basis of Design
   Sorokowska A, 2017, J CROSS CULT PSYCHOL, V48, P577, DOI 10.1177/0022022117698039
   Vilanova F, 2017, COGENT PSYCHOL, V4, DOI 10.1080/23311908.2017.1308104
   Walters ML, 2009, PROCS NEW FRONTIERS
   Weidmann U., 1993, Transporttechnik der Fussganger - Transporttechnische Eigenschaften des FuSSgangerverkehrs (Literaturauswertung) / IVT der ETHZurich
   Wu N, 2002, TRANSPORT RES A-POL, V36, P867, DOI 10.1016/S0965-8564(01)00043-X
   Zhang J, 2012, SCHRIFTEN FORSCHUNGS, V14
   Zhou BL, 2014, IEEE T PATTERN ANAL, V36, P1586, DOI 10.1109/TPAMI.2014.2300484
NR 42
TC 4
Z9 4
U1 2
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1899
DI 10.1002/cav.1899
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400010
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Nevelsteen, KJL
AF Nevelsteen, Kim J. L.
TI Virtual world, defined from a technological perspective and applied to
   video games, mixed reality, and the Metaverse
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE definition; mixed reality; Metaverse; MANet; virtual world; video games
AB There is no generally accepted definition for a virtual world, with many complimentary terms and acronyms having emerged implying a virtual world. Advances in networking techniques such as host migration of instances, mobile ad hoc networking, and distributed computing, bring in to question whether architectures can actually support a virtual world. Without a concrete definition, controversy ensues and it is problematic to design an architecture for a virtual world. Several researchers provided a definition but aspects of each definition are still problematic and simply can not be applied to contemporary technologies. The approach of this article is to sample technologies using grounded theory and to obtain a definition for a virtual world that is directly applicable to technology. The obtained definition is compared with related work and used to classify advanced technologies such as a pseudo-persistent video game, a MANet, virtual and mixed reality, and the Metaverse. The results of this article include a break down of which properties set apart the various technologies; a definition that is validated by comparing it with other definitions; an ontology showing the relation of the different complimentary terms and acronyms; and the usage of pseudo-persistence to categories those technologies, which only mimic persistence.
C1 [Nevelsteen, Kim J. L.] Stockholm Univ, Dept Comp & Syst Sci, Immers Networking, NOD Bldg,Borgarfjordsgatan 12, S-16455 Kista, Sweden.
C3 Stockholm University
RP Nevelsteen, KJL (corresponding author), Stockholm Univ, Dept Comp & Syst Sci, Immers Networking, NOD Bldg,Borgarfjordsgatan 12, S-16455 Stockholm, Sweden.
EM kim.nevelsteen@acm.org
OI Nevelsteen, Kim JL/0000-0002-4065-5322
FU Swedish Governmental Agency for Innovation Systems
FX Swedish Governmental Agency for Innovation Systems to the Mobile Life
   Vinn Excellence Center
CR Aarseth Espen., 2001, CYBERTEXT YB 2000, P152
   [Anonymous], 1993, DOOM
   [Anonymous], CIV 5
   [Anonymous], 1996, DIABL
   [Anonymous], 2009, LEAGUE LEGENDS VIDEO
   [Anonymous], 2004, WORLD WARCRAFT 2004
   Autodesk Inc, 2010, MAYA
   Bartle R., 2003, Designing Virtual Worlds
   Bartle RA, 2010, INTERNATIONAL HANDBOOK OF INTERNET RESEARCH, P23, DOI 10.1007/978-1-4020-9789-8_2
   Bell M., 2008, J VIRTUAL WORLDS RES, V1, DOI [10.4101/jvwr.v1i1.283, DOI 10.4101/JVWR.V1I1.283]
   Bell M.W., 2008, EXPANDED DEFINITION
   Benford S., 1998, ACM Transactions on Computer-Human Interaction, V5, P185, DOI 10.1145/292834.292836
   BigWorld, 2002, BIGWORLD TECHN
   Brennan S, 2009, REDEFINING MMOS PESK
   Brothers Wachowski, 1999, The Matrix
   Brown E., 2004, CHI 04 HUM FACT COMP, P1297, DOI DOI 10.1145/985921.986048
   Bungie, 2014, DEST
   Cawley C, 2010, WHY YOURE PLAYING CI
   CCP Games, 2003, Video Games, PC
   Combs N, 2004, VIRTUAL WORLD ANY OT
   Coquillart S, 2011, VIRTUAL REALITY DAGS, pv
   Creswell J. W., 2016, Qualitative Inquiry & Research Design Choosing Among Five Aproaches, DOI DOI 10.1089/TMJ.2009.0067
   Demeure I, 2008, INT S COLLAB TECHNOL, P221, DOI 10.1109/CTS.2008.4543935
   desVelde WV, 1995, BIOL TECHNOLOGY INTE, P197, DOI [10. 1007/978-3-642-79629-6_8., DOI 10.1007/978-3-642-79629-6_8]
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Drain B, 2008, EVE EVOLVED EVE ONLI
   Emilsson K, 2010, INFINITE SPACE ARGUM
   Frontier Developments, 2014, EL DANG
   Girvan C, 2013, TECHNICAL REPORT
   Google, 2015, LIM ON SHAR
   Google, 2007, GOODL DOCS
   Hi Rez Studios, 2014, SMIT
   Johannesson P., 2014, An Introduction to Design Science, DOI [10.1007/978-3-319-10632-8, DOI 10.1007/978-3-319-10632-8]
   Kalt C., 2000, Internet relay chat: Architecture
   Keegan M, 1997, J VIRTUAL ENVIRON JO, V2
   Lankoski Petri, 2004, P 3 NORD C HUM COMP, P413, DOI DOI 10.1145/1028014.1028083
   Linden Lab, 2003, 2 LIFE
   Liu HY, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333116
   *MICR, 1983, WORD
   Milgram P, 1999, MIXED REALITY, P5
   Murphy IP, 2014, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION, 2013, VOL 4A
   Nevelsteen KJL, 2017, SPATIOTEMPORAL MODEL
   Nevelsteen KJL, 2016, ENCY COMPUTER GRAPHI, P1, DOI 10. 1007/978-3-319-08234-9_72-2.
   Nevelsteen KJL, 2015, SURVEY CHARACTERISTI, V5
   Origin Systems, 1997, ULTIMA ONL
   Paroux G, 2007, 7 INT WORKSH APPL SE
   PhyberBX Apatrix Jolo, 2014, IRC NETWORKS SERVER
   Pingdom, 2010, EXPL SOFTW FAC WORLD
   Quiring Tyler., 2015, Journal For Virtual Worlds Research, V8, DOI [10.4101/jvwr.v8i1.7122, DOI 10.4101/JVWR.V8I1.7122]
   Qvortrup L, 2001, VIRTUAL INTERACTION: INTERACTION IN VIRTUAL INHABITED 3D WORLDS, P1
   Qvortrup L, 2002, VIRTUAL SPACE SPATIA, DOI [10. 1007/978-1-4471-0225-0., DOI 10.1007/978-1-4471-0225-0]
   Russell S., 2010, ARTIF INTELL, V3rd
   Schroeder R., 2008, Journal of Virtual Worlds Research: Past, Present Future, V1, P2, DOI 10.4101/jvwr.v1i1.294
   Shoham Y., 1997, SOFTWARE AGENTS, P271
   Singhal S., 1999, Networked Virtual Environments
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Soderlund T, 2009, DIGITAL CITYSCAPES M, P217
   Spence J., 2008, J VIRTUAL WORLDS RES, V1, P2
   Supnik R, 2003, DUNGEON V3 2B ZORK
   Texas Instruments Inc, 1993, TI 36X SOL
   Texas Instruments Inc, 2004, TI 84 PLUS
   Todd Sundsted, 2012, STUNT
   Trubshaw Roy, 1978, MUD
   Truman J, 2015, GDC VAULT GAM DEV C
   Waggoner Z., 2009, My Avatar, My Self: Identity in Video Role-Playing Games
   Wikipedia, 2015, TURNS ROUNDS TIM KEE
   WowWikicom, 2015, MULT
   Yahyavi A, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522977
   Zagal JoseP., 2007, Situated play, proceedings of DiGRA 2007 conference, P516
NR 69
TC 76
Z9 81
U1 15
U2 501
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2018
VL 29
IS 1
AR e1752
DI 10.1002/cav.1752
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FV0GZ
UT WOS:000424235300007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Berseth, G
   Kapadia, M
   Faloutsos, P
AF Berseth, Glen
   Kapadia, Mubbasir
   Faloutsos, Petros
TI ACCLMesh: curvature-based navigation mesh generation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE navigation mesh; crowd simulation; curvature
AB The proposed method computes a navigation mesh for arbitrary and dynamic 3D environments based on curvature and is robust and efficient. This method addresses a number of known limitations in state-of-the-art techniques to produce navigation meshes that are tightly coupled to the original geometry, incorporate geometric details that are crucial for movement decisions, can robustly handle complex surfaces and can efficiently repair the navigation mesh to accommodate dynamically changing environments. The method is integrated into a standard navigation and collision avoidance system to simulate thousands of agents on complex 3D surfaces in real time. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Berseth, Glen] Univ British Columbia, Dept Comp Sci, Vancouver, BC, Canada.
   [Kapadia, Mubbasir] Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ USA.
   [Faloutsos, Petros] York Univ, Dept Comp Sci & Engn, Toronto, ON, Canada.
C3 University of British Columbia; Rutgers University System; Rutgers
   University New Brunswick; York University - Canada
RP Berseth, G (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM gberseth@cs.ubc.ca
CR Akaydin A, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.2.027002
   [Anonymous], 2014, ACM SIGGRAPH 2014 CO
   Arikan O, 2001, SPRING EUROGRAP, P151
   Geraerts R, 2010, IEEE INT CONF ROBOT, P1997, DOI 10.1109/ROBOT.2010.5509263
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Jorgensen Carl-Johan, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P353, DOI 10.1007/978-3-642-25090-3_30
   Kallmann M., 2010, P 2010 ACM SIGGRAPH, P159
   Kallmann M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2580947
   Lamarche F, 2009, COMPUT GRAPH FORUM, V28, P649, DOI 10.1111/j.1467-8659.2009.01405.x
   MEMONONEN M., 2014, RECAST NAVIGATION ME
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Oliva R, 2013, COMPUT GRAPH-UK, V37, P403, DOI 10.1016/j.cag.2013.03.004
   Oliva Ramon, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P328, DOI 10.1007/978-3-642-25090-3_28
   Pearl J., 1984, Heuristics: Intelligent Search Strategies for Computer Problem Solving
   Pelechano N., 2008, Synthesis Lectures on Computer Graphics and Animation, V3, P1, DOI DOI 10.2200/S00123ED1V01Y200808CGR008
   Ricks BC, 2014, IEEE T VIS COMPUT GR, V20, P159, DOI 10.1109/TVCG.2013.110
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Sud A, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P99
   Torchelsen RafaelP., 2010, Proceedings of the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, P47
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   van Toll W, 2011, IEEE INT C INT ROBOT, P3526, DOI 10.1109/IROS.2011.6048397
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P535, DOI 10.1002/cav.1468
   Wardhana NM, 2013, VISUAL COMPUT, V29, P1051, DOI 10.1007/s00371-013-0837-x
   Ying X, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508379
NR 24
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 195
EP 204
DI 10.1002/cav.1710
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300003
DA 2024-07-18
ER

PT J
AU Kumar, A
   Ojha, A
AF Kumar, Amit
   Ojha, Aparajita
TI Anticipated velocity based guidance strategy for wheeled mobile evader
   amidst stationary and moving obstacles in bounded environment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE pursuit-evasion game; proportional navigation; robot motion planning;
   collision avoidance
ID PURSUIT-EVASION; PROPORTIONAL NAVIGATION; ROBOTIC INTERCEPTION; GAMES
AB This paper is concerned with a class of pursuit-evasion game problems amidst stationary and moving obstacles in a bounded environment. We concentrate on evader's strategy taking into account the following challenges: (i) pursuer and evader are nonholonomic wheeled mobile robots and the evader is slower than the pursuer; (ii) pursuer follows a proportional navigation law; and (iii) geometry of the environment is not known to the players, a priori. We propose an efficient evader-centric anticipated velocity based guidance strategy. Pursuer's trajectory is anticipated at each step by the evader using quadratic polynomial interpolation. The aim of the evader is to escape interception with the pursuer for maximum possible time. To deal with static obstacles, a technique based on a well-known tangent bug algorithm is presented. While dealing with dynamic obstacles, a recently introduced reciprocal orientation method is employed to avoid collision in situations when the dynamic obstacle also cooperates in the process. In case dynamic obstacles do not participate in the process of collision avoidance, a well-known velocity obstacle method is employed for planning safe collision-free paths. Efficiency of the proposed algorithms is analyzed with respect to the interception time and the distance traveled by the players. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Kumar, Amit; Ojha, Aparajita] PDPM Indian Inst Informat Technol Design & Mfg Ja, Comp Sci & Engn, Jabalpur, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Kumar, A (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg Ja, Comp Sci & Engn, Jabalpur, India.
EM amitku@iiitdmj.ac.in
RI Ojha, Aparajita/Q-3902-2016
OI Ojha, Aparajita/0000-0003-1567-8378
CR AlDahak A, 2004, IEEE SYS MAN CYBERN, P1996
   [Anonymous], 2013, 2013 4 INT C COMP CO
   Bakolas E, 2012, AUTOMATICA, V48, P2213, DOI 10.1016/j.automatica.2012.06.003
   Bakolas E, 2010, AUTOMATICA, V46, P2059, DOI 10.1016/j.automatica.2010.09.003
   Bhadauria D, 2012, INT J ROBOT RES, V31, P1176, DOI 10.1177/0278364912452894
   Britnell JR, 2013, ELECTRON J COMB, V20, P25, DOI DOI 10.37236/2296
   Burgard W., 2005, Principles of Robot Motion: Theory, Algorithms, and Implementations
   CHODUN W, 1989, J MATH ANAL APPL, V142, P370, DOI 10.1016/0022-247X(89)90007-3
   Chung TH, 2011, AUTON ROBOT, V31, P299, DOI 10.1007/s10514-011-9241-4
   Di Marco M, 2003, IEEE T ROBOTIC AUTOM, V19, P238, DOI 10.1109/TRA.2003.808849
   Durham JW, 2012, AUTON ROBOT, V32, P81, DOI 10.1007/s10514-011-9260-1
   Farin G., 2001, Curves and Surfaces for CAGD: A Practical Guide, Vfifth
   Fiorini P, 1998, INT J ROBOT RES, V17, P760, DOI 10.1177/027836499801700706
   FLYNN J, 1974, SIAM J CONTROL, V12, P581, DOI 10.1137/0312043
   GHOSE D, 1994, IEEE T AERO ELEC SYS, V30, P229, DOI 10.1109/7.250423
   Gu Jiali, 2012, P 16 INT C SYST THEO, P1
   Huang HM, 2011, IEEE DECIS CONTR P, P4835, DOI 10.1109/CDC.2011.6161237
   Ibragimov GI, 2012, EUR J OPER RES, V218, P505, DOI 10.1016/j.ejor.2011.11.026
   Isaacs R, 1965, DIFFERENTIAL GAMES M
   Isler V, 2005, IEEE T ROBOT, V21, P875, DOI 10.1109/TRO.2005.851373
   Jin SY, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P3184, DOI 10.1109/WCICA.2010.5553770
   Keshmiri M, 2010, 2010 15TH INTERNATIONAL CONFERENCE ON METHODS AND MODELS IN AUTOMATION AND ROBOTICS (MMAR), P212, DOI 10.1109/MMAR.2010.5587234
   Kumar A, 2014, ADV INTELL SYST, V248, P789, DOI 10.1007/978-3-319-03107-1_87
   Kung C.C., 2011, WORLD ACAD SCI ENG T, P136
   Liu SY, 2013, P AMER CONTR CONF, P5368
   Mahadevan A, 2012, IEEE INT CONF ROBOT, P3192, DOI 10.1109/ICRA.2012.6225217
   Mehrandezh M, 1999, ROBOT AUTON SYST, V28, P295, DOI 10.1016/S0921-8890(99)00044-5
   Mehrandezh M, 2000, IEEE T SYST MAN CY A, V30, P238, DOI 10.1109/3468.844351
   Meschler P. A., 1970, IEEE Transactions on Automatic Control, VAC-15, P576, DOI 10.1109/TAC.1970.1099558
   Rashid AT, 2012, ROBOT AUTON SYST, V60, P1221, DOI 10.1016/j.robot.2012.07.006
   RZYMOWSKI W, 1986, J MATH ANAL APPL, V120, P89, DOI 10.1016/0022-247X(86)90206-4
   Song YY, 2012, APPL MECH MATER, V110-116, P5249, DOI 10.4028/www.scientific.net/AMM.110-116.5249
   Vidal R, 2001, IEEE INT CONF ROBOT, P2948, DOI 10.1109/ROBOT.2001.933069
NR 33
TC 1
Z9 1
U1 0
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2015
VL 26
IS 5
BP 495
EP 507
DI 10.1002/cav.1609
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS5NU
UT WOS:000362125800002
DA 2024-07-18
ER

PT J
AU Zhang, L
   Dou, F
   Zhou, Z
   Wu, W
AF Zhang, Lin
   Dou, Fei
   Zhou, Zhong
   Wu, Wei
TI Streaming 3D deforming surfaces with dynamic resolution control
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE streaming media; 3D shape deformation; distributed virtual environment;
   multi-resolution; point-sampled surface; progressive surface
ID COMPRESSION
AB Real-time streaming of shape deformations in a shared distributed virtual environment is a challenging task due to the difficulty of transmitting large amounts of 3D animation data to multiple receiving parties at a high frame rate. In this paper, we present a framework for streaming 3D shape deformations, which allows shapes with multi-resolutions to share the same deformations simultaneously in real time. The geometry and motion of deforming mesh or point-sampled surfaces are compactly encoded, transmitted, and reconstructed using the spectra of the manifold harmonics. A receiver-based multi-resolution surface reconstruction approach is introduced, which allows deforming shapes to switch smoothly between continuous multi-resolutions. On the basis of this dynamic reconstruction scheme, a frame rate control algorithm is further proposed to achieve rendering at interactive rates. We also demonstrate an efficient interpolation-based strategy to reduce computing of deformation. The experiments conducted on both mesh and point-sampled surfaces show that our approach achieves efficient performance even if deformations of complex 3D surfaces are streamed. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Zhang, Lin; Dou, Fei; Zhou, Zhong; Wu, Wei] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Zhang, Lin; Dou, Fei; Zhou, Zhong; Wu, Wei] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Zhou, Z (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM zz@vrlab.buaa.edu.cn
OI Zhang, Lin/0000-0003-1989-6102
FU Natural Science Foundation of China [61170188]; Specialized Research
   Fund for the Doctoral Program of Higher Education of China
   [20121102130004]; National Key Technology R&D Program of China
   [2012BAI06B01]
FX Our thanks to Dr. Gregorij Kurillo for the recommendation and paper
   polishing. This work is supported by the Natural Science Foundation of
   China under Grant No. 61170188, the Specialized Research Fund for the
   Doctoral Program of Higher Education of China under Grant No.
   20121102130004, and the National Key Technology R&D Program of China
   under Grant No. 2012BAI06B01.
CR Alexa M, 2003, VISUAL COMPUT, V19, P105, DOI 10.1007/s00371-002-0180-0
   Alexa M, 2001, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2001.964489
   Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   Alregib G, 2005, ACM T GRAPHIC, V24, P182, DOI 10.1145/1061347.1061349
   Belkin M, 2009, PROCEEDINGS OF THE TWENTIETH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1031
   Botsch M, 2006, Vision, modeling & visualization, P357
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Cheng Wei, 2007, P AUGSBURG GERMANY 1, P737, DOI [10.1145/1291233.1291399, DOI 10.1145/1291233.1291399]
   Chew BS, 2011, IEEE T BROADCAST, V57, P636, DOI 10.1109/TBC.2011.2151590
   DeCoro C, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P363, DOI 10.1109/VISUAL.2002.1183796
   Dong S, 2006, ACM T GRAPHIC, V25, P1057, DOI 10.1145/1141911.1141993
   El-Sana J, 2000, COMPUT GRAPH FORUM, V19, pC139, DOI 10.1111/1467-8659.00406
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Guan W, 2008, IEEE T MULTIMEDIA, V10, P724, DOI 10.1109/TMM.2008.922785
   He Y., 2009, Proceeding of ACM international conference on Multimedia, P431
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Jacobson A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964973
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Kircher S., 2005, ACM SIGGRAPH EUROGRA, P191
   Kobbelt L, 1999, COMP GEOM-THEOR APPL, V14, P5, DOI 10.1016/S0925-7721(99)00032-2
   LI H, 2008, ACM MM 08 VANC BC CA, P501
   Linsen L, 2001, TECHNICAL REPORT
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Liu Y, 2012, IEEE T VIS COMPUT GR, V18, P1693, DOI 10.1109/TVCG.2011.152
   Liu Y, 2010, COMPUT GRAPH FORUM, V29, P2039, DOI 10.1111/j.1467-8659.2010.01790.x
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Rivers AR, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239533
   Rong G, 2008, CASA, P17
   Rong GD, 2008, VISUAL COMPUT, V24, P787, DOI 10.1007/s00371-008-0260-x
   Sorkine O, 2006, COMPUT GRAPH FORUM, V25, P789, DOI 10.1111/j.1467-8659.2006.00999.x
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tang Z, 2011, P 19 ACM INT C MULT, P1009
   Tang ZY, 2010, P IEEE VIRT REAL ANN, P183, DOI 10.1109/VR.2010.5444793
   Taubin G., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P123, DOI 10.1145/280814.280834
   Vallet B, 2008, COMPUT GRAPH FORUM, V27, P251, DOI 10.1111/j.1467-8659.2008.01122.x
   Yan ZD, 2001, IEEE T CIRC SYST VID, V11, P860, DOI 10.1109/76.931112
   Zhao Q, 2009, SCI CHINA SER F, V52, P348, DOI 10.1007/s11432-009-0066-0
NR 40
TC 1
Z9 1
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2015
VL 26
IS 1
BP 15
EP 28
DI 10.1002/cav.1562
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CC1LW
UT WOS:000350103200003
DA 2024-07-18
ER

PT J
AU Yang, C
   Li, S
   Wang, LL
   Hao, AM
   Qin, H
AF Yang, Chen
   Li, Shuai
   Wang, Lili
   Hao, Aimin
   Qin, Hong
TI Real-time physical deformation and cutting of heterogeneous objects via
   hybrid coupling of meshless approach and finite element method
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE physical simulation; heterogeneous objects; FEM; meshless coupling
ID SIMULATION
AB This paper advocates a method for real-time physical deformation and arbitrary cutting simulation of heterogeneous objects with multi-material distribution, whose originality centers on the tight coupling of domain-specific finite element method (FEM) and material distance-aware meshless approach in a CUDA-centric parallel simulation framework. We employ hierarchical hexahedron serving as basic building blocks for accurate material-aware FEM simulation. Meanwhile, local meshless systems are designed to support cross-FEM-domain coupling and material-sensitive propagation while respecting the regularity of finite elements. Directly benefiting from the structural regularity and uniformity of finite elements, our hybrid solution enables the local stiffness matrix pre-computation and dynamic assembling, adaptive topological updating and precise cutting reconstruction. Moreover, our mathematically-rigorous solver guarantees unconditional stableness. Experiments demonstrate the superiorities of our system. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Yang, Chen; Li, Shuai; Wang, Lili; Hao, Aimin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   SUNY Stony Brook, Stony Brook, NY 11790 USA.
C3 Beihang University; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook
RP Li, S (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM ls@vrlab.buaa.edu.cn
RI wang, lili/HJP-8047-2023
FU National Natural Science Foundation of China [61190120, 61190121,
   61190125, 61300067]; National Science Foundation of USA [IIS-0949467,
   IIS-1047715, IIS-1049448]
FX This research is supported in part by the National Natural Science
   Foundation of China (No. 61190120, 61190121, 61190125, and 61300067) and
   National Science Foundation of USA (No. IIS-0949467, IIS-1047715, and
   IIS-1049448). We would like to thank the anonymous reviewers for their
   very constructive comments and suggestions that help greatly improve
   this paper's quality.
CR [Anonymous], 2008, VCBM 2008 1 EG WORKS, DOI DOI 10.31729/JNMA.634
   Barbi J, 2011, ACM T GRAPHICS TOG, V30, P91
   Belytschko T, 1995, COMPUT MECH, V17, P186
   Bosman J., 2013, VRIPHYS 13: 10th Workshop on Virtual Reality Interaction and Physical Simulation, P41
   Chao I, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778775
   Dick C, 2011, IEEE T VIS COMPUT GR, V17, P1663, DOI 10.1109/TVCG.2010.268
   Dick C, 2011, SIMUL MODEL PRACT TH, V19, P801, DOI 10.1016/j.simpat.2010.11.005
   Dionne Olivier., 2013, P 12 ACM SIGGRAPH EU, P173, DOI DOI 10.1145/2485895.2485919
   Faure F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964968
   Fierz B, 2012, IEEE T VIS COMPUT GR, V18, P717, DOI 10.1109/TVCG.2011.105
   Fierz Basil, 2011, Proceedings of the 2011 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P257
   Forest C, 2002, ESAIM P, P34
   Georgii J, 2006, COMPUT GRAPH-UK, V30, P408, DOI 10.1016/j.cag.2006.02.016
   Jerábková L, 2010, PROG BIOPHYS MOL BIO, V103, P217, DOI 10.1016/j.pbiomolbio.2010.09.012
   Kim T, 2012, IEEE T VIS COMPUT GR, V18, P1228, DOI 10.1109/TVCG.2012.78
   Miller K, 2007, COMMUN NUMER METH EN, V23, P121, DOI 10.1002/cnm.887
   Müller M, 2004, PROC GRAPH INTERF, P239
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Noe KO, 2010, LECT NOTES COMPUT SC, V5958, P59, DOI 10.1007/978-3-642-11615-5_7
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Rabczuk T, 2006, COMMUN NUMER METH EN, V22, P1031, DOI 10.1002/cnm.871
   Steinemann D., 2006, PROC ACM SIGGRAPHEUR, P63
   Taylor ZA, 2009, MED IMAGE ANAL, V13, P234, DOI 10.1016/j.media.2008.10.001
   Wicke M, 2007, COMPUT GRAPH FORUM, V26, P355, DOI 10.1111/j.1467-8659.2007.01058.x
   Wu XL, 2004, LECT NOTES COMPUT SC, V3078, P92
   Yang Y, 2013, IEEE T VIS COMPUT GR, V19, P1633, DOI 10.1109/TVCG.2013.12
   [No title captured]
NR 27
TC 11
Z9 13
U1 2
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 423
EP 435
DI 10.1002/cav.1594
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300023
DA 2024-07-18
ER

PT J
AU Kang, YM
   Cho, CS
AF Kang, Young-Min
   Cho, Chang-Sik
TI Photorealistic cloth in real-time applications
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE real-time cloth animation; geometrically complex mass-spring; harmonic
   motion; cloth rendering
ID INTERACTIVE ANIMATION; REFLECTION; TEXTURE
AB In this paper, we propose an efficient and stable animation and rendering method for complex mass-spring-based cloth model for interactive applications. Although the mass-spring model can be easily constructed and simulated, it is well known that the model suffers from the instability problem. The method proposed in this paper employs the harmonic oscillation model and analytically integrates the force for better stability and accuracy while keeping the integration scheme still explicit. As the integration scheme is explicit, the method can be easily parallelized, and the performance improvement can be easily obtained by exploiting the parallelism in the graphics processing unit. For the realistic representation of virtual clothes, we also proposed an efficient and effective rendering method for woven surfaces on the basis of alternating anisotropic reflectance and microfacet distribution function rotation. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Kang, Young-Min] Tongmyong Univ, Dept Game Engn, Pusan, South Korea.
   [Cho, Chang-Sik] ETRI, Multimedia Res Team, Taejon, South Korea.
C3 Tongmyong University; Electronics & Telecommunications Research
   Institute - Korea (ETRI)
RP Kang, YM (corresponding author), Tongmyong Univ, Dept Game Engn, Pusan, South Korea.
EM ymkang@tu.ac.kr
RI Kang, Young-Min/R-5960-2019
FU SW computing R&D program of MKE/KEIT [10035184]; Ministry of Knowledge
   Economy (MKE), Korea, under the Information Technology Research Center
   (ITRC) [NIPA-2011-(C-1090-1021-0006)]
FX This work was supported in part by the SW computing R&D program of
   MKE/KEIT [10035184], "Game Service Technology Based on Realtime
   Streaming", and also in part by the Ministry of Knowledge Economy (MKE),
   Korea, under the Information Technology Research Center (ITRC) support
   program supervised by the National IT Industry Promotion Agency (NIPA)
   (NIPA-2011-(C-1090-1021-0006)).
CR Adabala N., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P178
   Adabala Neeharika, 2003, P ACM S VIRTUAL REAL, P41
   [Anonymous], 1993, P 4 EUR WORKSH REND
   [Anonymous], J WSCG
   [Anonymous], 1989, P 16 ANN C COMP GRAP
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], P ACM INT C VIRT REA
   [Anonymous], 1977, P 4 ANN C COMPUTER G, DOI DOI 10.1145/965141.563893
   Ashikhmin M., 2000, Journal of Graphics Tools, V5, P25, DOI 10.1080/10867651.2000.10487522
   Ashikhmin M, 2000, COMP GRAPH, P65, DOI 10.1145/344779.344814
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   BLINN JF, 1976, COMMUN ACM, V19, P542, DOI 10.1145/965143.563322
   Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Daubert K, 2001, SPRING EUROGRAP, P63
   Daubert K, 2002, COMPUT GRAPH FORUM, V21, P575, DOI 10.1111/1467-8659.t01-1-00708
   Desbrun M, 1999, PROC GRAPH INTERF, P1
   Groller E., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P205
   Groller E, 1995, IEEE T VIS COMPUT GR, V1, P302, DOI 10.1109/2945.485617
   Heidrich W, 1999, COMP GRAPH, P171, DOI 10.1145/311535.311554
   Holly E., 1997, P EUROGRAPHICS WORKS, P35
   Lawrence J, 2006, ACM T GRAPHIC, V25, P735, DOI 10.1145/1141911.1141949
   McAllister DavidK., 2002, PROC ACM GRAPH HARDW, P79
   Meissner M, 1998, COMPUT GRAPH FORUM, V17, pC355, DOI 10.1111/1467-8659.00282
   Meyer M, 2001, J VISUAL COMP ANIMAT, V12, P1, DOI 10.1002/vis.244
   Pharr M., 2004, Physically Based Rendering: From Theory to Implementation
   Poulin P., 1990, Computer Graphics, V24, P273, DOI 10.1145/97880.97909
   Sattler M., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P167
   Szirmay-Kalos L, 2009, COMPUT GRAPH FORUM, V28, P1586, DOI 10.1111/j.1467-8659.2009.01350.x
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105
   Volino P., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P137, DOI 10.1145/218380.218432
   Wang J, 2009, P ACM SIGGRAPH ASIA, P1
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078
   Xu YQ, 2001, COMP GRAPH, P391
   YASUDA T, 1992, IEEE COMPUT GRAPH, V12, P15, DOI 10.1109/38.163621
   Zinke A, 2007, IEEE T VIS COMPUT GR, V13, P342, DOI 10.1109/TVCG.2007.43
NR 38
TC 4
Z9 5
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 253
EP 265
DI 10.1002/cav.1456
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100013
DA 2024-07-18
ER

PT J
AU Casas, D
   Tejera, M
   Guillemaut, JY
   Hilton, A
AF Casas, Dan
   Tejera, Margara
   Guillemaut, Jean-Yves
   Hilton, Adrian
TI Parametric animation of performance-captured mesh sequences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; 3D video; performance-based animation; surface
   motion capture
AB In this paper, we introduce an approach to high-level parameterisation of captured mesh sequences of actor performance for real-time interactive animation control. High-level parametric control is achieved by non-linear blending between multiple mesh sequences exhibiting variation in a particular movement. For example, walking speed is parameterised by blending fast and slow walk sequences. A hybrid non-linear mesh sequence blending approach is introduced to approximate the natural deformation of non-linear interpolation techniques whilst maintaining the real-time performance of linear mesh blending. Quantitative results show that the hybrid approach gives an accurate real-time approximation of offline non-linear deformation. An evaluation of the approach shows good performance not only for entire meshes but also with specific mesh areas. Results are presented for single and multi-dimensional parametric control of walking (speed/direction), jumping (height/distance) and reaching (height) from captured mesh sequences. This approach allows continuous real-time control of high-level parameters such as speed and direction whilst maintaining the natural surface dynamics of captured movement. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Casas, Dan; Tejera, Margara; Guillemaut, Jean-Yves; Hilton, Adrian] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
C3 University of Surrey
RP Casas, D (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
EM d.casasguix@surrey.ac.uk
RI Casas, Dan/AAF-9801-2019; Casas, Dan/P-2111-2017; Guillemaut,
   Jean-Yves/N-7739-2014; Hilton, Adrian/N-3736-2014
OI Casas, Dan/0000-0002-3664-089X; Guillemaut,
   Jean-Yves/0000-0001-8223-5505; Hilton, Adrian/0000-0003-4223-238X
FU EPSRC [EP/F02827X/1] Funding Source: UKRI
CR [Anonymous], ACM S INT 3D GRAPH
   [Anonymous], P ACM SIGGRAPH
   [Anonymous], CVPR COL SPRINGS COL
   [Anonymous], 2003, ACM SIGGRAPH
   [Anonymous], 2009, ACM SIGGRAPH 2009 PA
   [Anonymous], P ACM SIGGRAPH LOS A
   [Anonymous], ACM S INT 3D GRAPH B
   [Anonymous], P INT C 3D IM MOD PR
   [Anonymous], C COMP VIS PATT REC
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Bruderlin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P97, DOI 10.1145/218380.218421
   Cagniart C, 2010, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2010.5539814
   Casas Dan, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P242, DOI 10.1007/978-3-642-25090-3_21
   Chong KW, 2001, J ACM, V48, P297, DOI 10.1145/375827.375847
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Huang P, 2009, PROC CVPR IEEE, P1478, DOI 10.1109/CVPRW.2009.5206626
   Huang P, 2010, INT J COMPUT VISION, V89, P362, DOI 10.1007/s11263-010-0319-9
   Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394
   Kircher S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1356682.1356685
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lee J, 1999, COMP GRAPH, P39
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Sorkine O, 2006, COMPUT GRAPH FORUM, V25, P789, DOI 10.1111/j.1467-8659.2006.00999.x
   Starck J., 2005, SCA 05, P49, DOI DOI 10.1145/1073368.1073375
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Stoll C, 2010, ACM SIGGRAPH ASIA, P1
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Vedula S, 2005, IEEE T PATTERN ANAL, V27, P475, DOI 10.1109/TPAMI.2005.63
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wand M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1516522.1516526
   Wiley DJ, 1997, P IEEE VIRT REAL ANN, P156, DOI 10.1109/VRAIS.1997.583065
   Witkin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P105, DOI 10.1145/218380.218422
   Xu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964927
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 39
TC 0
Z9 2
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2012
VL 23
IS 2
BP 101
EP 111
DI 10.1002/cav.1430
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 926VJ
UT WOS:000302859700005
OA Bronze
DA 2024-07-18
ER

PT J
AU Xiao, J
   Feng, YF
   Hu, WY
AF Xiao, Jun
   Feng, Yinfu
   Hu, Wenyuan
TI Predicting missing markers in human motion capture using
   <i>l</i>1-sparse representation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE l1-sparse representation; human motion capture; missing data prediction
AB Missing marker problem is very common in human motion capture. In contrast to most current methods which handle this problem based on trying to learn a reliable predictor from the observations, we consider it from the perspective of sparse representation and propose a novel method which is named l1-sparse representation of missing markers prediction (L1-SRMMP). We assume that the incomplete pose can be represented by a linear combination of a few poses from the training set and the representation is sparse. Therefore, we cast the predicting missing markers as finding a sparse representation of the observable data of the incomplete pose, and then we use it to predict the missing data. In order to get a sparse representation, we employ l1-norm in our objective function. Moreover, we propose presentation coefficient weighted update (PCWU) algorithm to mitigate the limited capacity problem of the training set. Experimental results demonstrate the effectiveness and efficiency of our method to predict the missing markers in human motion capture. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Xiao, Jun; Feng, Yinfu; Hu, Wenyuan] Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Feng, YF (corresponding author), Zhejiang Univ, Inst Artificial Intelligence, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM fyf200502@hotmail.com
OI FENG, yinfu/0000-0001-9136-0965
CR [Anonymous], 2003, ACM S VIRT REAL SOFT
   [Anonymous], P 20 ANN C NEUR INF
   ARISTIDOU A, 2008, BIOINFORMATICS B MAY, P1343
   Candes E., 2005, l1-magic: Recovery of sparse signals via convex programming
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Courty N, 2010, COMPUT ANIMAT VIRT W, V21, P443, DOI 10.1002/cav.374
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   HERDA L, 2002, P COMP AN, P77
   Huang Ke, 2006, NIPS
   Koh KM, 2007, J MACH LEARN RES, V8, P1519
   LI L, 2010, SCA 10, P125
   Li L, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P507
   Liu GD, 2006, VISUAL COMPUT, V22, P721, DOI 10.1007/s00371-006-0080-9
   Lou H, 2010, IEEE T VIS COMPUT GR, V16, P870, DOI 10.1109/TVCG.2010.23
   Piazza T, 2009, LECT NOTES COMPUT SC, V5903, P125, DOI 10.1007/978-3-642-10470-1_11
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Taylor GW, 2010, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.2010.5540157
   van Rhijn A, 2006, P IEEE VIRT REAL ANN, P135, DOI 10.1109/VR.2006.104
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiang S, 2010, LECT NOTES ARTIF INT, V6230, P304, DOI 10.1007/978-3-642-15246-7_29
   Yang A. Y., 2007, Tech. Rep. UCB/EECS-2007-99
   Zhang Yin, 2006, TR0615 CAAM
NR 23
TC 28
Z9 29
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 221
EP 228
DI 10.1002/cav.413
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700018
DA 2024-07-18
ER

PT J
AU Vasilakis, AA
   Fudos, I
AF Vasilakis, Andreas A.
   Fudos, Ioannis
TI GPU rigid skinning based on a refined skeletonization method
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE skeleton extraction; rigid skinning; character animation; re-meshing;
   GPU implementation; real time
ID ANIMATION; SPACE
AB In this paper, we present a skeletal rigid skinning approach. First, we describe a skeleton extraction technique that produces refined skeletons appropriate for animation from decomposed character models. Then, to avoid the artifacts generated in previous skinning approaches and the associated high training costs, we develop an efficient and robust rigid skinning technique that applies blending patches around joints. To achieve real time animation, we have adapted all steps of our rigid skinning algorithm so that they are performed efficiently on the GPU. Finally, we present an evaluation of our methods against four criteria: efficiency, quality, scope, and robustness. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Vasilakis, Andreas A.; Fudos, Ioannis] Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece.
C3 University of Ioannina
RP Fudos, I (corresponding author), Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece.
EM fudos@cs.uoi.gr
OI Vasilakis, Andreas A./0000-0001-6895-3324
CR ANDERSEN K, 2007, SPHERICAL BLEND SKIN
   [Anonymous], 2001, P 2001 S INTERACTIVE
   [Anonymous], 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'02
   [Anonymous], 2002, P 2002 ACM SIGGRAPHE
   Attene M, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P142, DOI 10.1109/SMA.2001.923385
   Aujay G, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P151
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   *BIOV, BVH FORM
   *BLEND FDN, BLEND OP SOURC 3D CO
   Buchart C, 2008, COMPUT GRAPH FORUM, V27, P807, DOI 10.1111/j.1467-8659.2008.01211.x
   Chaudhuri P, 2008, VISUAL COMPUT, V24, P525, DOI 10.1007/s00371-008-0233-0
   CMU Graphics Lab, MOT CAPT DAT
   Cordier F, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P257, DOI 10.1109/PCCGA.2004.1348356
   Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0
   Dey TamalK., 2003, SM 03 P 8 ACM S SOLI, P127, DOI DOI 10.1145/781606.781627
   *E FRONT INC, POS 7 3D FIG DES AN
   Fernando R., 2004, GPU Gems: Programming Techniques, Tips and Tricks for Real-Time Graphics
   Fudos I, 1996, COMPUT AIDED DESIGN, V28, P91, DOI 10.1016/0010-4485(95)00037-2
   GOTTSCHALK SA, 2000, THESIS N CAROLINA CH
   HEJL J, 2004, GAME PROGRAMMING GEM, V4
   Hétroy F, 2009, GRAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P259
   Jacka D, 2007, AFRIGRAPH 2007: 5TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY, COMPUTER GRAPHICS, VISUALIZATION AND INTERACTION IN AFRICA, P177
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   James DougL., 2002, SIGGRAPH 02, P582
   KAVAN L, 2005, 2005 ACM SIGGRAPH S, P9
   Kavan L., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games. I3D '09, P49, DOI 10.1145/1507149.1507157
   Kavan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409627
   Kavan L, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P53
   Kwatra N, 2010, IEEE T VIS COMPUT GR, V16, P70, DOI 10.1109/TVCG.2009.66
   Lai YK, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P183
   LAPERRIERE R, 1988, P GRAPH INT CAN INF, P26
   Larboulette Caroline., 2005, Proceedings of the 21st spring conference on Computer graphics, P87, DOI DOI 10.1145/1090122.10901384
   LEE M, 2007, P GAMEFEST MICR GAM
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lien J, 2006, P 2006 ACM S SOL PHY, P219
   LUTTGENS K, 1997, SCI BASIS HUMAN MOTI
   Ma WC, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P207
   Merry B, 2006, ACM T GRAPHIC, V25, P1400, DOI 10.1145/1183287.1183294
   MOHR A, 2003, SIGGRAPH 03, P562
   NVIDIA Corporation, 2008, NVIDIA OPENGL EXT SP
   *PLANIT 3D, ULT POS HORS MORPH S
   SHI X, 2008, SIGGRAPH 08 ACM SIGG, P1
   SMITH ML, GPGPU OPENGL VISUAL
   Vasilakis A, 2009, GRAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P302
   Verroust A, 1999, SHAPE MODELING INTERNATIONAL '99 - INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P194, DOI 10.1109/SMA.1999.749340
   Wade L, 2002, VISUAL COMPUT, V18, P97, DOI 10.1007/s003710100139
   Wang RY, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239524, 10.1145/1276377.1276468]
   WATT A, 2003, 3D GAMES, V2
   WEBER J, 2000, GAME DEV C
   Yoshizawa S, 2007, COMPUT GRAPH FORUM, V26, P255, DOI 10.1111/j.1467-8659.2007.01047.x
   Yuksel Can, 2007, Symposium on Geometry Processing, P153, DOI DOI 10.2312/SGP/SGP07/153-162
NR 52
TC 2
Z9 3
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2011
VL 22
IS 1
BP 27
EP 46
DI 10.1002/cav.382
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 727SD
UT WOS:000287820600004
DA 2024-07-18
ER

PT J
AU Lee, Y
   Kim, YJ
AF Lee, Youngeun
   Kim, Young J.
TI Simple and parallel proximity algorithms for general polygonal models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE collision detection; distance calculation; penetration depth; parallel
   algorithm
ID DEPTH
AB We present simple and fast parallel proximity algorithms for rigid polygonal models. Given two polygon-soup models in space, if they overlap, our algorithm can find all the intersected primitives between them; otherwise, it reports their Euclidean minimum distance. Our algorithm is performed in a parallel fashion and shows scalable performance in terms of the number of available computing cores. The key ingredient of our algorithm is a simple load-balancing metric based on the penetration depth (PD) (for collision detection) and approximate Euclidean distance (for Euclidean distance computation) between bounding volumes. To compute the PD between oriented bounding boxes (OBBs), we present a novel algorithm based on the well-known separating axis theorem (SAT) and also shows that the PD can be trivially obtained as a byproduct of SAT. We have implemented these algorithms on a commodity PC with eight cores and benchmarked their performance on complicated geometric models. In practice, the performance of our algorithm shows up to 5 and 9.7 times improvement for collision and distance queries, respectively, compared to single core computation. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Kim, Young J.] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Kim, YJ (corresponding author), Ewha Womans Univ, Seoul, South Korea.
EM kimy@ewha.ac.kr
OI Kim, Young J./0000-0003-2159-4832
CR [Anonymous], SIGGRAPH 05 ACM SIGG
   [Anonymous], P 2007 EUR S PAR GRA
   [Anonymous], 2004, Dark Victory: How a Government Lied Its Way to Political Triumph
   Blumofe RD, 1999, J ACM, V46, P720, DOI 10.1145/324133.324234
   DOBKIN D, 1993, ALGORITHMICA, V9, P518, DOI 10.1007/BF01190153
   Ericson C., 2005, Real-time collision detection
   FIGUEIREDO M, 2004, ICPADS 04 P PAR DIST
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Grinberg I, 2007, IASTED INT CONF SIGN, P380
   Hughes CJ, 2007, CONF PROC INT SYMP C, P220, DOI 10.1145/1273440.1250690
   KIM D, 2009, COMPUTER GRAPHICS FO
   Kim YJ, 2004, IEEE T VIS COMPUT GR, V10, P152, DOI 10.1109/TVCG.2004.1260767
   Larsen E., 2000, P IEEE INT C ROB AUT
   LAUTERBACH C, 2009, P EUR
   LAWLOR OS, 2002, ICS 02, P285
   LEE Y, 2010, CSETR201001 EWH WOM
   Lin M.C., 2004, HDB DISCRETE COMPUTA, Vsecond, P787
   Tang M., 2009, 2009 SIAM/ACM Joint Conference on Geometric and Physical Modeling. SPM'09, P355
   TESCHNER M, 2004, COLLISION DETECTION, P119
   Wald I, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P33, DOI 10.1109/RT.2007.4342588
   Wan HG, 2001, CAD/GRAPHICS '2001: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN AND COMPUTER GRAPHICS, VOLS 1 AND 2, P521
   WEI Z, 2008, SYST SIM SCI COMP 20, P786
   YOON S, 2004, EUR S GEOM PROC
NR 23
TC 5
Z9 7
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 365
EP 374
DI 10.1002/cav.359
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400023
DA 2024-07-18
ER

PT J
AU Oh, S
   Baek, W
   Woo, W
AF Oh, Sejin
   Baek, Woonhyuk
   Woo, Woontack
TI Synthetic vision-based perceptual attention for augmented reality agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE augmented reality agent; memory; perceptual attention; synthetic vision
ID MEMORY
AB We describe our model for synthetic vision-based perceptual attention for autonomous agents in augmented reality (AR) environments. Since virtual and physical objects coexist in their environment, such agents must adaptively perceive and attend to objects relevant to their goals. To enable agents to perceive their surroundings, our approach allows the agents to determine currently visible objects from the scene description of what virtual and physical objects are configured in the camera's viewing area. In our model, a degree of attention is assigned to each perceived object based on its similarity to target objects related to an agent's goals. The agent can thus focus on a reduced set of perceived objects with respect to the estimated degree of attention. Moreover, by continuously and smartly updating the perceptual memory, it eliminates the processing loads associated to previously observed objects. To demonstrate the effectiveness of our approach, we implemented an animated character that was overlaid over a miniature version of campus in real-time and that attended to building blocks relevant to given tasks. Experiments showed that our model could reduce a character's perceptual load at any time, even when surroundings change. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Baek, Woonhyuk; Woo, Woontack] GIST, Dept Informat & Commun, U VR Lab, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Woo, W (corresponding author), GIST, Dept Informat & Commun, U VR Lab, Kwangju 500712, South Korea.
EM wwoo@gist.ac.kr
RI Woo, Woontack/C-3696-2012
OI Woo, Woontack/0000-0002-5501-4421
CR [Anonymous], Cal3D, in
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Balcisoy S, 1997, COMP ANIM CONF PROC, P31, DOI 10.1109/CA.1997.601037
   Barakonyi I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P141, DOI 10.1109/ISMAR.2004.11
   Barakonyi I, 2008, COMPUT ANIMAT VIRT W, V19, P23, DOI 10.1002/cav.220
   CASTIELLO U, 1992, J EXP PSYCHOL HUMAN, V18, P837, DOI 10.1037/0096-1523.18.3.837
   Conde T, 2004, COMPUT ANIMAT VIRT W, V15, P311, DOI 10.1002/cav.34
   HEWETT MS, 2001, THESIS U TEXAS AUSTI
   Hill R., 1999, P 8 C COMP GEN FORC, P563
   Kuffner JJ, 1999, COMP ANIM CONF PROC, P118, DOI 10.1109/CA.1999.781205
   Liew PS, 2009, COMPUT ANIMAT VIRT W, V20, P257, DOI 10.1002/cav.316
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   NOSER H, 1995, COMPUT GRAPH, V19, P7, DOI 10.1016/0097-8493(94)00117-H
   Peters C, 2003, COMP ANIM CONF PROC, P111, DOI 10.1109/CASA.2003.1199311
   PETERSON LR, 1959, J EXP PSYCHOL, V58, P193, DOI 10.1037/h0049234
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   POSNER MI, 1976, PSYCHOL REV, V83, P157, DOI 10.1037/0033-295X.83.2.157
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   Rosten E., 2006, P 2006 9 EUR C COMP, P430, DOI DOI 10.1007/11744023_34
   Wagner D., 2006, ACE 06, P57, DOI [DOI 10.1145/1178823.1178891, 10.1145/1178823.1178891]
   Wolfe J.M., 2000, SEEING, P335, DOI DOI 10.1016/B978-012443760-9/50010-6
NR 22
TC 0
Z9 0
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 463
EP 472
DI 10.1002/cav.368
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400032
OA Bronze
DA 2024-07-18
ER

PT J
AU Fei, GZ
   Lee, WS
   Xin, ZJ
   Dong, HK
   Joslin, C
AF Fei, Guangzheng
   Lee, Won-Sook
   Xin, Zijun
   Dong, Huikai
   Joslin, Chris
TI PASCAL: physics augmented space canvases for animating locomotion
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Virtual-Reality Continuum and its
   Applications in Industry
CY DEC 08-09, 2008
CL Singapore, SINGAPORE
SP ACM SIGGRAPH
DE space canvas; physical simulation; free-form deformation; inverse
   kinematics
AB We describe an animation creation system called PASCAL that supports sketch-based modeling and physics augmented locomotion simultaneously. The system uses sketches and reconfigurable space canvases as basic modeling primitives and uses physics to improve the expressiveness and efficiency of several animation techniques to obtain controllable and plausible locomotion animation. The usability evaluation of the system was conducted both with professional and novice animators. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Fei, Guangzheng] Commun Univ China, Animat Sch, Beijing, Peoples R China.
   [Lee, Won-Sook] Univ Ottawa, Fac Engn, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
   [Xin, Zijun; Dong, Huikai] Commun Univ China, Comp Sch, Beijing, Peoples R China.
   [Joslin, Chris] Carleton Univ, Sch Informat Technol, Ottawa, ON K1S 5B6, Canada.
C3 Communication University of China; University of Ottawa; Communication
   University of China; Carleton University
RP Fei, GZ (corresponding author), Commun Univ China, Animat Sch, Beijing, Peoples R China.
EM guangzfei@gmail.com
CR [Anonymous], P SPRING JOINT COMP
   Bourguignon D, 2001, COMPUT GRAPH FORUM, V20, pC114, DOI 10.1111/1467-8659.00504
   Chenney S., 2002, INT S NONPHOTOREALIS, P133, DOI DOI 10.1145/508530.508553
   Coquillart S., 1990, J. Computer Graphics, V24, P187, DOI DOI 10.1145/97880.97900
   Davis J., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P320
   Davis R.C., 2008, PROCEEDING 26 ANN SI, P413
   Dorsey J, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P201, DOI 10.1109/PG.2007.64
   Faloutsos P, 1997, IEEE T VIS COMPUT GR, V3, P201, DOI 10.1109/2945.620488
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Kallio Kiia, 2005, P SBIM 05, P73
   PLASS M, 1983, P SIGGRAPH 83, P229
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Sumi F, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P282, DOI 10.1109/CGI.2003.1214483
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Weng YL, 2006, VISUAL COMPUT, V22, P653, DOI 10.1007/s00371-006-0054-y
NR 15
TC 0
Z9 0
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2010
VL 21
IS 2
SI SI
BP 81
EP 89
DI 10.1002/cav.323
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 586CJ
UT WOS:000276878600003
DA 2024-07-18
ER

PT J
AU Baxter, W
   Barla, P
   Anjyo, K
AF Baxter, William
   Barla, Pascal
   Anjyo, Ken
TI <i>N</i>-way morphing for 2D animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE rigid interpolation; multi-way interpolation; morphing; deformation;
   pose-space; 2D animation
AB We present a novel approach to the creation of varied animations from a small set of simple 2D input shapes. Instead of providing a new 2D shape for each keyframe of an animation sequence, we interpolate between a few example shapes in a reduced pose-space. Similar approaches have been presented in the past, but Were restricted in the types of input or range of deformations allowed. In order to address these limitations, We reformulate the problem as all N-way morphing process on 2D input bitmap or vector graphics. Our formulation includes all N-way mapping technique, all efficient, rigidity preserving nonlinear blending function, improved extrapolation and a novel scattered data interpolation technique to manage the reduced pose-space. The resulting animations are correlated to paths in the reduced pose-space, allowing Users to intuitively and interactively control temporal behaviours with simple gestures. We demonstrate our techniques in several example animations. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Baxter, William] OLM Digital Inc, R&D Grp, Setagaya Ku, Tokyo 1540023, Japan.
   [Barla, Pascal] INRIA Bordeaux Sud Ouest, IPARLA Team, Bordeaux, France.
   [Anjyo, Ken] OLM Digital Inc, Div Res & Dev, Tokyo 1540023, Japan.
RP Baxter, W (corresponding author), OLM Digital Inc, R&D Grp, Setagaya Ku, 1-8-8-302 Wakabayashi, Tokyo 1540023, Japan.
EM wbaxter@gmail.com
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   ALEXA M, 1999, P WSCG 99, P329
   [Anonymous], 2001, The animator's survival kit
   [Anonymous], 2001, P 2001 S INTERACTIVE
   BAXTER W, 2008, P NONPH AN REND
   BAXTER W, 2009, IEEE T VISUALIZATION
   Baxter W, 2006, COMPUT GRAPH FORUM, V25, P477, DOI 10.1111/j.1467-8659.2006.00967.x
   BREGLER C, 2002, SIGGRAPH 02, P399
   Grace, 1990, SPLINE MODELS OBSERV
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   IGARASHI T, 2005, SCA 05, P107
   KOVAR L, 2001, UIST 01 P 14 ANN ACM, P163
   Shewchuk J. R., 1996, LECT NOTES COMPUTER, P203, DOI DOI 10.1007/BFB0014497
   SHOEMAKE K, 1992, P GRAPH INT
   SUMNER RW, 2005, COMPUTATIONAL GEOMET, P488
   Surazhsky V, 2004, ENG COMPUT-GERMANY, V20, P147, DOI 10.1007/s00366-004-0282-6
   Wendland H., 2004, Scattered data approximation
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Xu DH, 2005, SOUTHEAST SYMP SYSTE, P267, DOI 10.1145/1060244.1060274
NR 19
TC 9
Z9 13
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 79
EP 87
DI 10.1002/cav.310
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Beato, N
   Zhang, YJ
   Colbert, M
   Yamazawa, K
   Hughes, CE
AF Beato, Nicholas
   Zhang, Yunjun
   Colbert, Mark
   Yamazawa, Kazumasa
   Hughes, Charles E.
TI Interactive chroma keying for mixed reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE mixed reality; chroma keying; GPU; shader; blue screening; matting;
   video processing; real-time
AB In Mixed Reality (MR) applications, immersion of virtual objects in captured video contributes to the perceived unification of two worlds, one real, one synthetic. Since virtual actors and surround may appear both closer and farther than real objects, compositing must consider spatial relationships in the resulting world. Chroma keying, often called blue screening or green screening, is one common solution to this problem. This method is under-constrained and most commonly addressed through a combination of environment preparation and commercial products. In interactive MR domains that impose restrictions oil the video camera hardware, such as in experiences using video see-through (VST) head-mounted displays (HMD), chroma keying becomes even more difficult due to the relatively low camera quality, the use of multiple camera sources (one per eye), and the required processing speed. Dealing with these constraints requires a fast and affordable solution. In our approach, we precondition the chroma key by using principal component analysis (PCA) to obtain usable alpha mattes from video streams in real-time oil commodity graphics processing units (GPUs). In addition, we demonstrate how our method compares to off-line commercial keying tools and how it performs with respect to signal noise within the video stream. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Beato, Nicholas; Hughes, Charles E.] Univ Cent Florida, Sch EECS, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Beato, N (corresponding author), Univ Cent Florida, Sch EECS, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.
EM nbeato@eecs.ucf.edu
OI Hughes, Charles/0000-0002-2528-3380
FU Directorate For Engineering; Div Of Industrial Innovation & Partnersh
   [0750551] Funding Source: National Science Foundation
CR CHOANG YY, 2002, SIGGRAPH 02, P243
   Figl M, 2008, LECT NOTES COMPUT SC, V5128, P202, DOI 10.1007/978-3-540-79982-5_23
   Grundhöfer A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409104
   Hughes CE, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.139
   Kim H, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P169, DOI 10.1109/ISMAR.2003.1240700
   Kim H, 2003, P SOC PHOTO-OPT INS, V5006, P544, DOI 10.1117/12.473879
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Levin A., 2006, Proceedings of the International Conference on Computer Vision and Pattern Recognition, P61, DOI [10.1109/CVPR.2006.18, DOI 10.1109/TPAMI.2007.1177]
   MCGUIRE M, 2005, SIGGRAPH 05, P567
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   MISHIMA Y, SOFTWARE CHROMAKEYER, P44
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SMITH AR, 1996, SIGGRAPH 96, P259
   State A, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P28
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   SUN J, 2006, SIGGRAPH 06, P772
   Uchiyama S, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P246, DOI 10.1109/ISMAR.2002.1115095
   VANDENBERGH F, 1999, S AFRICAN COMPUTER J, V24, P155
   Vlahos P., 1978, U.S. Patent, Patent No. [4,100,569, 4100569]
NR 19
TC 5
Z9 7
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 405
EP 415
DI 10.1002/cav.305
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700033
DA 2024-07-18
ER

PT J
AU Park, A
   Calvert, T
AF Park, Andrew
   Calvert, Tom
TI A social agent pedestrian model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE pedestrian models; social agents; virtual environments; CPTED; fear of
   crime
ID CRIME; FEAR; RISK
AB This paper presents a social agent pedestrian model based on experiments with human subjects. Research studies of criminology and environmental psychology show that certain features of the urban environment generate fear in people, causing them to take alternate routes. The Crime Prevention Through Environmental Design (CPTED) strategy has been implemented to reduce fear of crime and crime itself. Our initial prototype of a pedestrian model was developed based out these findings of criminology research. In the course of validating our model, we constructed a virtual environment (VE) that resembles a well-known fear-generating area where several decision points were set up. 60 human subjects were invited to navigate the VE and their choices of routes and comments during the post interviews Were analyzed using statistical techniques and content analysis. Through our experimental results, we gained new insights into pedestrians' behavior and suggest a new enhanced and articulated agent model of a pedestrian. Our research not only provides a realistic pedestrian model, but also a new methodology for criminology research. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Park, Andrew; Calvert, Tom] Simon Fraser Univ, Sch Interact Arts & Technol, Surrey, BC V3T 0A3, Canada.
C3 Simon Fraser University
RP Park, A (corresponding author), Simon Fraser Univ, Sch Interact Arts & Technol, 250-13450 102 Ave, Surrey, BC V3T 0A3, Canada.
EM aparkd@sfu.ca
CR BRANTINGHAM PJ, 1981, ENV CRIMINOLOGY SAGE, V39
   COZENS P., 2003, Facilities, volume 21, V7, P188, DOI [DOI 10.1108/02632770310489936, 10.1108/02632770310489936]
   Donaldson T, 2004, LECT NOTES ARTIF INT, V3060, P31
   Evans Karen., 1997, CONTESTED COMMUNITIE, P33
   Fasli M, 2003, LECT NOTES ARTIF INT, V2691, P111
   FERRARO KF, 1987, SOCIOL INQ, V57, P70, DOI 10.1111/j.1475-682X.1987.tb01181.x
   FISHER BS, 1992, ENVIRON BEHAV, V24, P35, DOI 10.1177/0013916592241002
   FONER LN, 2000, HUMAN COGNITION SOCI, P323
   GAROFALO J, 1981, J CRIM LAW CRIM, V72, P839, DOI 10.2307/1143018
   Goffman E., 1971, Relations in Public, DOI 10.1038/229103a0 16059101
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Herzog TR, 2001, ENVIRON BEHAV, V33, P653, DOI 10.1177/00139160121973179
   Jacobs Jane, 1961, The Death and life of Great American Cities
   JEFFERY CR, 1971, CRIME PREVENTION THR
   KRIPPENDORFF K, 2004, CONTENT ANAL INTR ME
   LAGRANGE RL, 1992, J RES CRIME DELINQ, V29, P311, DOI 10.1177/0022427892029003004
   Magnenat-Thalmann N, 2005, VISUAL COMPUT, V21, P997, DOI 10.1007/s00371-005-0363-6
   Newman Oscar., 1972, DEFENSIBLE SPACE CRI
   Ortony A., 1988, COGNITIVE STRUCTURE
   PARK A, 2007, COMPUTER ANIMATION S, P11
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Silverman BarryG., 2002, COGNITIVE SCI Q, V2, P273
   SKOGAN WG, 1987, CRIME DELINQUENCY, V33, P135, DOI 10.1177/0011128787033001008
   Whyte W., 2001, SOCIAL LIFE SMALL UR
   Wilcox P, 2003, J RES CRIME DELINQ, V40, P322, DOI 10.1177/0022427803253801
   WILL JA, 1995, J CRIM JUST, V23, P163, DOI 10.1016/0047-2352(95)00004-A
NR 26
TC 7
Z9 8
U1 0
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 331
EP 340
DI 10.1002/cav.243
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200016
DA 2024-07-18
ER

PT J
AU Maciel, A
   De, S
AF Maciel, Anderson
   De, Suvranu
TI An efficient dynamic point algorithm for line-based collision detection
   in real time virtual environments involving haptics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer graphics; interaction techniques; simulation and modeling;
   haptic I/O
AB In real time computer graphics, "interactivity" is limited to a display rate of 30 frames per second. However, in multimodal virtual environments involving haptic interactions, a much higher update rate of about 1 kHz is necessary to ensure continuous interactions and smooth transitions. The simplest and most efficient interaction paradigm in such environments is to represent the haptic cursor as a point. However, in many situations, such as those in the development of real time medical simulations involving the interactions of long slender surgical tools with soft deformable organs, such a paradigm is nonrealistic and at least a line-based interaction is desirable. While such paradigms exist, the main impediment to their widespread use is the associated computational complexity. In this paper, we introduce, for the first time, an efficient algorithm for computing the interaction of a line-shaped haptic cursor and polygonal surface models which has a near constant complexity. The algorithm relies on space-time coherence, topological information, and the properties of lines in 3D space to maintain proximity information between a line segment and triangle meshes. For interaction with convex objects, the line is represented by its end points and a dynamic point, which is the closest point on the line to any potentially colliding triangle. To deal with multiple contacts and non-convexities, the line is decomposed into segments and a dynamic point is used for each segment. The algorithm may be used to compute collision detection and response with rigid as well as deformable objects with no performance penalty. Realistic examples are presented to demonstrate the effectiveness of our approach. Copyright (c) 2008 John Wiley & Sons, Ltd.
C1 [Maciel, Anderson] Univ Fed Rio Grande do Sul, Inst Informat, Dept Appl Informat, BR-91501970 Porto Alegre, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP Maciel, A (corresponding author), Univ Fed Rio Grande do Sul, Inst Informat, Dept Appl Informat, Caixo Postal 15064, BR-91501970 Porto Alegre, RS, Brazil.
EM amaciel@inf.ufrgs.br
RI Maciel, Anderson/F-7734-2012
OI Maciel, Anderson/0000-0002-0780-6555
FU NIBIB NIH HHS [R01 EB005807, R21 EB003547] Funding Source: Medline
CR [Anonymous], 1996, TR96024 UNC DEP COMP
   Barbic J, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P171
   BASCLOGAN C, 2004, IEEE COMPUT GRAPH, V24, P56
   CHEN H, 2004, VRST 04, P201
   Cohen J. D., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P189, DOI 10.1145/199404.199437
   COLGATE J, 1995, P INT C INT ROB SYST
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Govindaraju NK, 2005, ACM T GRAPHIC, V24, P991, DOI 10.1145/1073204.1073301
   Gregory A, 2000, COMP GEOM-THEOR APPL, V15, P69, DOI 10.1016/S0925-7721(99)00041-3
   Guéziec A, 2001, IEEE T VIS COMPUT GR, V7, P47, DOI 10.1109/2945.910820
   Ho CH, 1999, PRESENCE-VIRTUAL AUG, V8, P477, DOI 10.1162/105474699566413
   Ho CH, 2000, INT J ROBOT RES, V19, P668, DOI 10.1177/027836490001900704
   JAMES DL, 2004, ACM T GRAPHICS S AUG, V23
   JINMEZ P, 2001, COMPUT GRAPH-UK, V25, P269
   Joukhadar A., 1996, Proceedings. Computer Animation '96, P126, DOI 10.1109/CA.1996.540495
   Kim YJ, 2003, PRESENCE-VIRTUAL AUG, V12, P277, DOI 10.1162/105474603765879530
   Lin M.C., 1998, PROC IMA C MATH SURF, P37
   LIN MC, 1994, THESIS U CALIFORNIA
   Lombardo JC, 1999, COMP ANIM CONF PROC, P82, DOI 10.1109/CA.1999.781201
   Mark W.R., 1996, Proceedings of SIGGRAPH on Computer Graphics, P447, DOI DOI 10.1145/237170.237284
   MASSIE TH, 1994, S HAPTIC INTERFACES
   Mirtich B, 1998, ACM T GRAPHIC, V17, P177, DOI 10.1145/285857.285860
   Moller T., 1997, J. Graph. Tools, V2, P25, DOI [DOI 10.1080/10867651.1997.10487472, 10.1080/10867651.1997.10487472]
   ORTEGA M, 2006, VR 06, P27
   Otaduy MiguelA., 2006, High Fidelity Haptic Rendering
   Picinbono G, 2002, J VISUAL COMP ANIMAT, V13, P147, DOI 10.1002/vis.257
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Zilles C., 1995, INT C INTELLIGENT RO, P3146
NR 28
TC 8
Z9 10
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2008
VL 19
IS 2
BP 151
EP 163
DI 10.1002/cav.224
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 296PY
UT WOS:000255559500006
PM 35910783
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhang, L
   Zhang, Y
   Jiang, ZD
   Li, LY
   Chen, W
   Peng, QS
AF Zhang, Long
   Zhang, Yubo
   Jiang, Zhongding
   Li, Luying
   Chen, Wei
   Peng, Qunsheng
TI Precomputing data-driven tree animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE precomputation; data-driven; motion reuse; physically based modeling;
   tree animation
AB We present a data-driven approach that synthesizes tree animations from a set Of pre-computed motion data. Our approach improves previous motion synthesis algorithms for character animation in several aspects. We first introduce a simple yet effective sampling scheme to generate a rich and reusable motion database for each tree model. We also propose a novel technique to generate a fine set of transitions that are uniformly distributed in the motion database. The transition lengths are adaptively determined according to the similarity of the transiting frame pairs. In the runtime, we employ a greedy searching algorithm to synthesize smooth tree animations under an adjustable wind condition. Experimental results show that our approach achieves comparable quality to physically based methods, while in orders of magnitude faster performance. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM chenwei@cad.zju.edu.cn
RI Chen, Wei/AAR-9817-2020
CR AONO M, 1984, IEEE COMPUT GRAPH, V4, P10, DOI 10.1109/MCG.1984.276141
   ARIKAN O, 2002, P 29 ANN C COMP GRAP, P483
   BEAUDOIN J, 2004, EUR SIGGRAPH S COMP, P297
   de Reffye P., 1988, Computer Graphics, V22, P151, DOI 10.1145/378456.378505
   Di Giacomo T, 2001, SPRING EUROGRAP, P65
   Diener Julien., 2006, Proceedings of the Eurographics Symposium on Computer Animation, P187
   *INT DAT VIS INC, SPEED TREE US MAN
   JAMES DL, 2003, P ACM SIGGRAPH 2003, P879
   JAMES DL, SIGGRAPH 2006 TECHNI, P69
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar Lucas., 2002, SCA 2002: Proceedings of the 2002 ACM SIG-GRAPH/Eurographics Symposium on Computer Animation, P97
   Lai Yu-Chi., 2005, SCA 2005: Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P281, DOI DOI 10.1145/1073368.1073409
   Lee Jehee., 2002, Proceedings of the 29th annual conference on Computer graphics and interactive techniques, P491, DOI DOI 10.1145/566570.566607
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   MIZUGUCHI M, 2001, EUR 2001 SHORT PRES
   NEYRET F, 1995, EUR WORKSH REND 96, P97
   Oppenheimer P. E., 1986, Computer Graphics, V20, P55, DOI 10.1145/15886.15892
   Ota S, 2004, VISUAL COMPUT, V20, P613, DOI 10.1007/s00371-004-0266-y
   Prusinkiewicz P., 1990, ALGORITHMIC BEAUTY P
   SAKAGUCHI T, 1999, P ACM S VIRT REAL SO, P139
   SAKAGUCHI T, 1997, EUR WORKSH AN SIM 19, P149
   SETAS MN, 1995, P 1 WORKSH SIM INT V
   SHINYA M, 1992, P EUR 92, P119
   STTAM J, 1997, P EUR 1997, P159
   Sun M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P96
   SUNG M., 2005, SCA 05, P291
   VANHAEVRE W, 2006, P EUR WORKSH NAT PHE, P75, DOI DOI 10.1007/978-90-368-1100-2_6
   Weber J., 1995, Proceedings of the 22Nd Annual Conference on Computer Graphics and Interactive Techniques, P119, DOI DOI 10.1145/218380.218427
   Wu EH, 1999, SPRING COMP SCI, P157
NR 29
TC 14
Z9 18
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 371
EP 382
DI 10.1002/cav.205
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000016
DA 2024-07-18
ER

PT J
AU Hung, SS
   Liu, DSM
AF Hung, Shao-Shin
   Liu, Damon Shing-Min
TI Using prefetching to improve walkthrough latency
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE prefetching; walkthrough; mining; clustering; pattern growth; latency
AB Object correlations are common semantic patterns in walkthrough (WT) systems. They can be exploited for improving the effectiveness of storage caching, prefecthing, data layout, and minimization of query-response times. Previous approaches for reducing I/O access time are seldom investigated. On the other side, data mining techniques extract implicit, previously unknown and potentially useful information from the databases. However, those methods are presented for typical data mining datasets and not suitable for our lVF system datasets. This paper proposes a class of novel and efficient pattern-growth method for mining various frequent sequential traversal patterns in the WT. Our pattern-growth method adopts a divide-and-conquer approach to decompose both the mining tasks and the databases. The frequent sequential traversal patterns are used to predict the user navigation behavior and help to reduce disk access time With proper placement patterns into disk blocks. We also define the terminologies such as paths, views, and objects used in the model. We have done extensive experiments to demonstrate how these proposed techniques not only significantly cut down disk access time, but also enhance the accuracy of data prefetching. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 62117, Taiwan.
C3 National Chung Cheng University
RP Hung, SS (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, 168 Univ Rd, Chiayi 62117, Taiwan.
EM hss@cs.ccu.edu.tw
CR AGRAWAL R, 1995, 11 INT C DAT ENG MON, V25, P1
   [Anonymous], 2003, P 2 USENIX C FIL STO
   Chakrabarti S., 2003, Mining the Web: Discovering Knowledge from Hypertext Data
   Chen MS, 1998, IEEE T KNOWL DATA EN, V10, P209, DOI 10.1109/69.683753
   CLARK JH, 1976, COMMUN ACM, V19, P547, DOI 10.1145/360349.360354
   Han Jiawei., 2000, Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, P355
   JOSHI A, 2000, P SIGKDD WORKSH RES
   Kaufman L., 2009, FINDING GROUPS DATA
   Ohbuchi E, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P190, DOI 10.1109/CGI.2003.1214465
   Pei Jian, 2001, P INT C DAT ENG ICDE, P3
   Smith A. J., 1978, ACM Transactions on Database Systems, V3, P223, DOI 10.1145/320263.320276
   Srikant Ramakrishnan., 1996, EDBT, P3, DOI 10.1007/BFb0014140
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   ZAKI M, 1996, P 1996 ACM SIGMOD IN, P103
   Zhu YC, 2005, IEEE T VIS COMPUT GR, V11, P306, DOI 10.1109/TVCG.2005.50
   [No title captured]
NR 16
TC 6
Z9 6
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 469
EP 478
DI 10.1002/cav.149
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400032
DA 2024-07-18
ER

PT J
AU Yang, XS
   Somasekharan, A
   Zhang, JJ
AF Yang, Xiaosong
   Somasekharan, Arun
   Zhang, Jian J.
TI Curve skeleton skinning for human and creature characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE skeleton; curve-skeleton; deformation
AB The skeleton driven skinning technique is still the most popular method for animating deformable human and creature characters. Albeit all industry de facto due to its computational performance and intuitiveness, it suffers from problems like collapsing elbow and candy wrapper joint. To remedy these problems, one needs to formulate the non-linear relationship between the skeleton and the skin shape of a character properly, Which however proves mathematically very challenging. Placing additional joints Where the skin bends increases the sampling rate and is all ad hoc Way of approximating this non-linear relationship. In this paper, we propose a method that is able to accommodate the inherent non-linear relationships between the movement of the skeleton and the skin shape. We use the so-called curve skeletons along With the joint-based skeletons to animate the skin shape. Since the deformation follows the tangent of the curve skeleton and also due to higher sampling rates received from the curve points, collapsing skin and other undesirable skin deformation problems are avoided. The curve skeleton retains the advantages of the current skeleton driven skinning. It is easy to use and allows full control over the animation process. As a further enhancement, it is also fairly simple to build realistic muscle and fat bulge effect. A practical implementation in the form of a Maya plug-in is created to demonstrate the viability of the technique. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Bournemouth Univ, Bournemouth Media Sch, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University
RP Zhang, JJ (corresponding author), Bournemouth Univ, Bournemouth Media Sch, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
EM jzhang@bournemouth.ac.uk
OI Yang, Xiaosong/0000-0003-3815-0584
CR Allen B, 2002, ACM T GRAPHIC, V21, P612, DOI 10.1145/566570.566626
   [Anonymous], 2005, P 2005 S INTERACTIVE, DOI [DOI 10.1145/1053427.10534294, DOI 10.1145/1053427.1053429]
   AUBEL A, 2001, P COMP AN
   CAHDWICK J, SIGGRAPH89 P, P243
   CAPELL S, 2005, P 2005 ACM SIGGR EUR
   Cornea ND, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P95
   Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0
   Hyun DE, 2005, VISUAL COMPUT, V21, P542, DOI 10.1007/s00371-005-0343-x
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Mohr A, 2003, ACM T GRAPHIC, V22, P562, DOI 10.1145/882262.882308
   Singh K., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P405, DOI 10.1145/280814.280946
   Singh K, 2000, PROC GRAPH INTERF, P35
   TURNER R, 1993, P COMP GRAPH INT 93, P399
   Wang QMJ, 2004, MOL CANCER RES, V2, P129
   Weber J, 2000, P GAM DEV C
   YANG X, 2005, 3 TECHN SESS COMP GR
NR 16
TC 19
Z9 24
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 281
EP 292
DI 10.1002/cav.132
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400015
DA 2024-07-18
ER

PT J
AU Dequidt, B
   Marchal, D
   Grisoni, L
AF Dequidt, B
   Marchal, D
   Grisoni, L
TI Time-critical animation of deformable solids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE octree simulation; time-critical animation; FEM
ID COLLISION DETECTION
AB This article presents a model for handling multi-resolution animation of complex deformable models. An octree-based animation and algorithmic tools are introduced to provide real-time interaction on complex objects. Some efficient collision detection scheme is also described for deformable models. A method is also presented for time-guaranteed mechanical simulation: It allows an automatic tuning of the octree resolution to match some external performance constraints, such as a pre-defined CPU consumption limit. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Univ Lille 1, Lab LIFL, F-59655 Villeneuve Dascq, France.
C3 Universite de Lille
RP Univ Lille 1, Lab LIFL, Batiment M3, F-59655 Villeneuve Dascq, France.
EM jeremie.dequidt@lifl.fr
RI Marchal, Damien/KDN-9387-2024
CR Aliaga DG, 1999, COMP GRAPH, P307, DOI 10.1145/311535.311574
   [Anonymous], P ACM SIGGRAPH C AUG
   [Anonymous], 1997, J GRAPH TOOLS, DOI DOI 10.1080/10867651.1997.10487480
   BRADSHAW G, 2002, THESIS TRINITY COLL
   Capell S., 2002, P 2002 ACM SIGGRAPHE, P41
   Carlson DA, 1997, PROC GRAPH INTERF, P1
   COHEN JD, 1995, ACM INT 3D GRAPH C, P189
   Debunne G, 2000, COMP ANIM CONF PROC, P15, DOI 10.1109/CA.2000.889022
   DEBUNNE G, COMP GRAPH ANN C SER
   Dingliana J, 2000, COMPUT GRAPH FORUM, V19, pC239, DOI 10.1111/1467-8659.00416
   DINGLIANA J, 2003, THESIS TRINITY COLL
   Etzmuss O, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P244, DOI 10.1109/PCCGA.2003.1238266
   Felippa Carlos A, 2000, CUCAS0003 CTR AER ST
   Grinspun E, 2002, ACM T GRAPHIC, V21, P281, DOI 10.1145/566570.566578
   HUBBARD PM, 1995, IEEE T VIS COMPUT GR, V1, P218, DOI 10.1109/2945.466717
   James DL, 2004, ACM T GRAPHIC, V23, P393, DOI 10.1145/1015706.1015735
   LARSSON T, 2001, EACG C EUR
   MACIEL PWC, 1995, S INT 3D GRAPH, P95
   Morton G. M., 1966, COMPUTER ORIENTED GE
   Müller M, 2004, PROC GRAPH INTERF, P239
   Muller M., 2002, ACM SIGGRAPH EUR S C
   MULLER M, 2004, COMPUTER GRAPHICS IN
   SCHRACK G, 1992, COMPUTER VISION GRAP, P221
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   TESCHNER M, 2004, P EUR EUR ASS
   Wu XL, 2001, COMPUT GRAPH FORUM, V20, pC349
NR 26
TC 5
Z9 6
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 177
EP 187
DI 10.1002/cav.110
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000005
DA 2024-07-18
ER

PT J
AU Yoon, BC
   Lee, IK
   Choi, JJ
AF Yoon, BC
   Lee, IK
   Choi, JJ
TI Editing noise
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE noise; Perlin noise; animation control
AB Noise is used to create realistic animations that look like natural phenomena as well as procedural textures and shapes by adding randomness to graphical applications. In this paper, we suggest a method to edit noise values to satisfy the constraints that reflect the user's demands while maintaining the inherent statistical features of the noise function. Noise editing uses optimization to minimize the difference between the statistical characteristics of the ideal and edited versions of a noise source. Using our editing method, detailed control of animation and shape data that include noise is possible. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Ajou Univ, Div Med, Suwon 442749, South Korea.
C3 Ajou University
RP Ajou Univ, Div Med, Suwon 442749, South Korea.
EM media19@ajou.ac.kr
RI Lee, In-Kwon/AGP-6124-2022
OI Lee, In-Kwon/0000-0002-1534-1882
NR 0
TC 4
Z9 4
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 277
EP 287
DI 10.1002/cav.30
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700017
DA 2024-07-18
ER

PT J
AU Zhao, J
   Li, L
AF Zhao, J
   Li, L
TI Human motion reconstruction from monocular images using genetic
   algorithms
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE posture recovery; human animation; energy function; genetic algorithm
AB This paper proposed an optimization approach for human motion recovery from the uncalibrated monocular images containing unlimited human movements. A 3D skeleton human model based on anatomy knowledge is employed with encoded biomechanical constraints for the joints. Energy Function is defined to represent the deviations between projection features and extracted image features. Reconstruction procedure is developed to adjust joints and segments of the human body into their proper positions. Genetic Algorithms are adopted to find the optimal solution effectively in the high dimensional parameter space by simultaneously considering all the parameters of the human model. The experimental results are analysed by Deviation Penalty. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM p14967181@ntu.dedu.sg
RI zhu, yujie/KBC-4009-2024
OI Li, Ling/0000-0001-9722-9503
CR Aggarwal JK, 1998, COMPUT VIS IMAGE UND, V70, P142, DOI 10.1006/cviu.1997.0620
   AIZAWA K, 1995, P IEEE, V83, P259, DOI 10.1109/5.364463
   [Anonymous], 1985, South African Journal of Photogrammetry, Remote Sensing and Cartography
   Barron C, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P53, DOI 10.1109/HUMO.2000.897371
   CEDRAS C, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P214, DOI 10.1109/CVPR.1994.323832
   DAPUZZO N, 1999, P ELECT IMAGING
   Davidor Y., 1991, Genetic Algorithms and Robotics: A heuristic strategy for optimization
   FABIO R, 2002, INT ARCH PHOTOGRAMME, V34, P363
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   GONCALVES L, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P764, DOI 10.1109/ICCV.1995.466861
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Pina A, 2000, COMPUT GRAPH-UK, V24, P297, DOI 10.1016/S0097-8493(99)00165-X
   ROMER R, 2000, P WORKSH HUM MOT, P19
   Taylor CJ, 2000, COMPUT VIS IMAGE UND, V80, P349, DOI 10.1006/cviu.2000.0878
   Winter G., 1995, GENETIC ALGORITHMS E
   Zheng JY, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P209, DOI 10.1109/CGI.2000.852336
NR 16
TC 9
Z9 13
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 407
EP 414
DI 10.1002/cav.44
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700031
DA 2024-07-18
ER

PT J
AU Miao, ZZ
   Zhang, Y
   Piao, XL
   Chu, Y
   Yin, BC
AF Miao, Zhuangzhuang
   Zhang, Yong
   Piao, Xinglin
   Chu, Yi
   Yin, Baocai
TI Region feature smoothness assumption for weakly semi-supervised crowd
   counting
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd counting; hypergraph; semi-supervised; social security
AB Crowd counting is a hot issue in visual data processing. It also plays an important role in the field of video surveillance, social security, and traffic control. However, most of the existing crowd counting methods always adopt a mount of training data or point-level annotation to learn the mapping relationships between images and density maps, which would cost much human labor. In this paper, we propose a new weakly semi-supervised crowd counting method which uses less count-level data for data training. In particular, we extend the classical smoothness assumption and design a many-to-many Region Feature Smoothness Assumption to deal with the uneven density distribution problem within crowd region. Further, we adopt hypergraph representation to explore the complex high-order relationship for different crowd regions. Besides, we design a multi-scale dynamic hypergraph convolutional module and hyperedge contrastive loss. Extensive experiments have been conducted on five public datasets. The experimental results show that the proposed method outperforms the state-of-the-art ones.
C1 [Miao, Zhuangzhuang; Zhang, Yong; Piao, Xinglin; Yin, Baocai] Beijing Univ Technol, Beijing Inst Artificial Intelligence, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing, Peoples R China.
   [Chu, Yi] China Elect Technol Grp Taiji Co Ltd, Beijing, Peoples R China.
C3 Beijing University of Technology
RP Piao, XL (corresponding author), Beijing Univ Technol, Beijing Inst Artificial Intelligence, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing, Peoples R China.
EM 1107300132@qq.com; zhangyong2010@bjut.edu.cn; piaoxl@bjut.edu.cn;
   Chuyi@mail.taiji.com.cn
RI Zhang, Yong/AAW-8880-2021
OI Zhang, Yong/0000-0001-6650-6790
FU National Key R&D Program of China [2021ZD0111902]; National Natural
   Science Foundation of China [U21B2038, U19B2039, 62072015]; Beijing
   Natural Science Foundation [4222021]; R&D Program of Beijing Municipal
   Education Commission [KZ202210005008]
FX National Key R&D Program of China, Grant/Award Number: No.
   2021ZD0111902; National Natural Science Foundation of China, Grant/Award
   Numbers: No.U21B2038, 62072015, U19B2039; Beijing Natural Science
   Foundation, Grant/Award Number: No.4222021; R&D Program of Beijing
   Municipal Education Commission, Grant/Award Number:No.KZ202210005008
CR Chapelle O., 2006, SEMISUPERVISED LEARN
   Chu X., P ADV NEUR INF PROC
   Ding XH, 2021, IEEE T INTELL TRANSP, V22, P4776, DOI 10.1109/TITS.2020.2983475
   Feng Y., P AAAI C ART INT HON
   Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006
   Gao JQ, 2023, Arxiv, DOI [arXiv:2201.04819, DOI 10.48550/ARXIV.2201.04819]
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Guo D., ACM INT C MULT NEW Y
   Idrees H., P EUR C COMP VIS MUN
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Kipf TN., SEMI SUPERVISED CLAS
   Lei YJ, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107616
   Li Y., P 2018 IEEE CVF C CO
   Liang DK, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3445-y
   Lin H., IEEE INT C MULT TAIP
   Liu X., 2018 IEEE CVF C COMP
   Liu Y., P EUR C COMP VIS
   Liu Z., P IEEE INT C COMP VI
   Luo A., P AAAI C ART INT NEW
   Ma Z., P IEEE INT C COMP VI
   Meng YD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15529, DOI 10.1109/ICCV48922.2021.01526
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Sindagi VA., P EUR C COMP VIS
   Sindagi VA, 2022, IEEE T PATTERN ANAL, V44, P2594, DOI 10.1109/TPAMI.2020.3035969
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Tarvainen A., P INT C LEARN REPR T
   Tian Y, 2021, Arxiv, DOI [arXiv:2109.14483, DOI 10.48550/ARXIV.2109.14483]
   Vaswani A., ATTENTION IS ALL YOU
   Wan J, 2019, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2019.00416
   Wang Fusen, 2022, arXiv
   Wang HK, 2020, ELECTRON LETT, V56, P709, DOI 10.1049/el.2020.0746
   Wang Q, 2022, IEEE T INTELL TRANSP, V23, P15233, DOI 10.1109/TITS.2021.3138896
   Wu Z., 2022, IEEE T CIRCUITS SYST, p30(1):228
   Yang Y., P EUR C COMP VIS
   Zhang A., P IEEE INT C COMP VI
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhou Q, 2019, IEEE T INTELL TRANSP, V20, P1728, DOI 10.1109/TITS.2018.2829987
NR 37
TC 1
Z9 1
U1 4
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2173
EA MAY 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000992282300001
DA 2024-07-18
ER

PT J
AU Sharma, R
   Kallmann, M
AF Sharma, Ritesh
   Kallmann, Marcelo
TI Spatially distributed lane planning for navigation in 3D environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D path planning; max flows; medial axis; path dispersion
ID CROWD SIMULATION
AB This article introduces the new problem of planning spatially distributed lanes for supporting multi-agent navigation applications in 3D environments. Our proposed approach computes the max-flow of a 3D medial axis representation of the environment in order to globally compute collision-free lanes exploring the entire free space of the volumetric scene. Our method addresses agent clearance and path dispersion in order to provide a comprehensive solution to globally compute lanes to be used by multiple agents in 3D environments. By selecting the desired lane dispersion our approach offers an intuitive and powerful way to explore variations in the computed collections of lanes. Dispersion is addressed with a combination of new techniques based on max flow computation, clearance-based path separation, and adaptive shortcut-based smoothing.
C1 [Sharma, Ritesh; Kallmann, Marcelo] Univ Calif Merced, Elect Engn & Comp Sci, Merced, CA USA.
   [Sharma, Ritesh] Univ Calif Merced, Sci & Engn II Bldg,Room 213F, Merced, CA 95340 USA.
C3 University of California System; University of California Merced;
   University of California System; University of California Merced
RP Sharma, R (corresponding author), Univ Calif Merced, Sci & Engn II Bldg,Room 213F, Merced, CA 95340 USA.
EM rsharma39@ucmerced.edu
OI Kallmann, Marcelo/0000-0001-5138-0603; Sharma,
   Ritesh/0000-0003-1160-3918
FU Army Research Office [W911NF-17-1-0463]
FX ACKNOWLEDGMENTS This research was partially sponsored by the Army
   Research Office under Grant number W911NF-17-1-0463. The views and
   conclusions contained in this document are those of the authors and
   should not be interpreted as representing the official policies, either
   expressed or implied, of the Army Research Office or the U.S.
   Government.
CR [Anonymous], PROXIMITY QUERY PACK
   Barnett A, 2016, COMPUT GRAPH FORUM, V35, P120, DOI 10.1111/cgf.12735
   Culver T, 2004, COMPUT AIDED GEOM D, V21, P65, DOI 10.1016/j.cagd.2003.07.008
   EDMONDS J, 1972, J ACM, V19, P248, DOI 10.1145/321694.321699
   Hang Ma, 2017, AI Matters, V3, P15, DOI 10.1145/3137574.3137579
   Ho F, 2023, AUTON AGENT MULTI-AG, V37, DOI 10.1007/s10458-022-09593-3
   Hönig W, 2018, IEEE T ROBOT, V34, P856, DOI 10.1109/TRO.2018.2853613
   Jalba AC, 2013, IEEE T PATTERN ANAL, V35, P1495, DOI 10.1109/TPAMI.2012.212
   Kallmann M., 2016, Geometric and Discrete Path Planning for Interactive Virtual Worlds
   Kallmann M., COMP STUDY NAVIGATIO
   Kallmann M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2580947
   Karamouzas I, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275079
   LAVALLE S.M., 2006, Planning algorithms, DOI DOI 10.1017/CBO9780511546877
   Ma H, 2016, AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1144
   Paden B, 2016, IEEE T INTELL VEHICL, V1, P33, DOI 10.1109/TIV.2016.2578706
   Rahman M, 2022, IEEE ACCESS, V10, P22226, DOI 10.1109/ACCESS.2022.3151092
   Rahmani V, 2020, COMPUT GRAPH-UK, V86, P1, DOI 10.1016/j.cag.2019.10.006
   Rycroft CH, 2009, CHAOS, V19, DOI 10.1063/1.3215722
   Sharma R, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P214, DOI 10.1109/AIVR50618.2020.00044
   Sharon G, 2015, ARTIF INTELL, V219, P40, DOI 10.1016/j.artint.2014.11.006
   Solovey K., MOTION PLANNING UNLA
   Svancara J, 2017, ICAART: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P451, DOI 10.5220/0006184504510458
   Toll WV., 2018, ACM T SPAT ALGORITHM, V4, p2:1
   Weiss T, 2019, COMPUT GRAPH-UK, V78, P12, DOI 10.1016/j.cag.2018.10.008
   Xu ML, 2014, J COMPUT SCI TECH-CH, V29, P799, DOI 10.1007/s11390-014-1469-y
   Yan YJ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201396
   Yu J., 2012, Planning Optimal Paths for Multiple Robots on Graphs
   Yu J., 2013, ALGORITHMIC FDN ROBO, P157
   Zhang H., HIERARCHICAL APPROAC
NR 29
TC 0
Z9 0
U1 2
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2162
EA MAY 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000987549200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Mazala, D
   Esperança, C
   Marroquim, R
AF Mazala, Diego
   Esperanca, Claudio
   Marroquim, Ricardo
TI Laplacian face blending
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE detail transfer; digital humans; face modeling
ID MORPHABLE MODEL; MESH; RECONSTRUCTION
AB Designing realistic tridimensional facial models is a challenging task, not only due to the effort and artistic abilities required but also because human visual perception is very tuned to the processing of facial features. For this reason, rather than creating face models from scratch, artists usually start from a scanned model of a real person. In this work, we present a novel method for blending human faces in order to create a new one. In a nutshell, our proposal uses Laplacian smoothing to segregate layers of details from one or more faces, which are then integrated into a base face with the help of an interactive and visual editor. In particular, our method supports blending multiple faces and multiple sub-regions in those faces. Since our approach is intuitive and relatively easy to implement, it can be integrated into artistic pipelines aiming at designing human face models from preexisting ones.
C1 [Mazala, Diego; Esperanca, Claudio] Univ Fed Rio de Janeiro, Syst Engn & Comp Sci, Rio De Janeiro, Brazil.
   [Marroquim, Ricardo] Delft Univ Technol, INSY, Delft, Netherlands.
C3 Universidade Federal do Rio de Janeiro; Delft University of Technology
RP Marroquim, R (corresponding author), Delft Univ Technol, INSY, Delft, Netherlands.
EM r.marroquim@tudelft.nl
RI Marroquim, Ricardo/A-8474-2010
OI Marroquim, Ricardo/0000-0001-8299-7067
CR Agisoft, 2021, Agisoft metashape user manual: standard edition version 1.7
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   Beeler T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964970
   Biancolini M., 2011, MESH MORPHING SMOOTH, V15, P347
   Bjorck A ., 1996, NUMERICAL METHODS LE, DOI DOI 10.1137/1.9781611971484
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   BUELL WR, 1973, J ENG IND-T ASME, V95, P332, DOI 10.1115/1.3438132
   Canann SA, 1998, P 7 INT MESH ROUNDT, P479
   Chen LG, 2007, LECT NOTES COMPUT SC, V4487, P318
   Cignoni P, 1998, COMPUT GRAPH-UK, V22, P37, DOI 10.1016/S0097-8493(97)00082-4
   Cignoni P., 2008, P EUR IT CHAPT C, P129, DOI [DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136, 10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/129-136]
   Dai P, 2018, MULTIMED TOOLS APPL, V77, P939, DOI 10.1007/s11042-016-4325-y
   de Boer A, 2007, COMPUT STRUCT, V85, P784, DOI 10.1016/j.compstruc.2007.01.013
   Egger B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3395208
   FIELD DA, 1988, COMMUN APPL NUMER M, V4, P709, DOI 10.1002/cnm.1630040603
   Freitag L., 1995, EFFICIENT PARALLEL A, P47
   Freitag LA., 1999, COMBINING LAPLACIAN, P220
   Fyffe G, 2017, COMPUT GRAPH FORUM, V36, P295, DOI 10.1111/cgf.13127
   Fyffe G, 2016, COMPUT GRAPH FORUM, V35, P353, DOI 10.1111/cgf.12837
   Groth C, 2018, PROCEDIA STRUCT INTE, V8, P379, DOI 10.1016/j.prostr.2017.12.038
   Guo YD, 2019, IEEE T PATTERN ANAL, V41, P1294, DOI 10.1109/TPAMI.2018.2837742
   Knipping J., 2020, COMP WAVELETS ADAPTI
   Lee S, 1997, IEEE T VIS COMPUT GR, V3, P228, DOI 10.1109/2945.620490
   Lewis JP, 2014, State of the Art Reports, V1, P2, DOI DOI 10.2312/EGST.20141042
   Li RL, 2020, PROC CVPR IEEE, P3407, DOI 10.1109/CVPR42600.2020.00347
   Lin KC, 2016, MULTIMED TOOLS APPL, V75, P11469, DOI 10.1007/s11042-015-2864-2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma W.-C., 2012, P DIG PROD S NEW YOR, P21
   Ma WC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409074
   Parthasarathy V. N., 1991, Finite Elements in Analysis and Design, P309, DOI 10.1016/0168-874X(91)90004-I
   Pixologic, 2021, ZBRUSH
   Ploumpis S, 2019, PROC CVPR IEEE, P10926, DOI 10.1109/CVPR.2019.01119
   Rhee T., 2011, Proceedings of the 2011 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '11, P215
   Romeiro R, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P266, DOI 10.1109/SIBGRAPI.2014.25
   Seidel H.-P, 2004, 2 EUROGRAPHICS S GEO, P175, DOI DOI 10.1145/1057432.1057456
   Shimada K, 2000, INT J COMPUT GEOM AP, V10, P417, DOI 10.1142/S0218195900000243
   Shin IK., 2014, PAC C COMP GRAPH APP, P113
   Statham N, 2020, GAMES CULT, V15, P289, DOI 10.1177/1555412018786415
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Tian L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030459
   Vartziotis D, 2008, COMPUT METHOD APPL M, V197, P3760, DOI 10.1016/j.cma.2008.02.028
   Vollmer J, 1999, COMPUT GRAPH FORUM, V18, pC131, DOI 10.1111/1467-8659.00334
   Weisstein E.W., 2021, Least Squares Fitting
   Yoon SH, 2017, IEEE COMPUT GRAPH, V37, P65, DOI 10.1109/MCG.2017.4031069
   Zhang Y, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P399, DOI 10.1109/IM.2001.924487
   Zhu XY, 2014, INT C PATT RECOG, P4044, DOI 10.1109/ICPR.2014.693
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
NR 50
TC 2
Z9 2
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2023
VL 34
IS 2
AR e2044
DI 10.1002/cav.2044
EA MAR 2022
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D7UU4
UT WOS:000771679800001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Koilias, A
   Nelson, MG
   Anagnostopoulos, CN
   Mousas, C
AF Koilias, Alexandros
   Nelson, Michael G.
   Anagnostopoulos, Christos-Nikolaos
   Mousas, Christos
TI Immersive walking in a virtual crowd: The effects of the density, speed,
   and direction of a virtual crowd on human movement behavior
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE human-crowd interaction; movement behavior; virtual crosswalk; virtual
   crowd; virtual reality
ID REALITY; COORDINATION; PEDESTRIANS; DISTANCE; MOTION
AB We investigated the movement behavior of participants walking within a virtual crowd in an immersive virtual environment. We investigated three different parameters that characterize a moving virtual crowd: density, speed, and direction. An immersive road-crossing scenario that took place in a virtual metropolitan city was created. In this scenario, the participants were instructed to walk toward the opposite sidewalk. Three measurements (speed, deviation, and trajectory length) were used to evaluate the impact of the parameters assigned to the virtual crowd on the movement behavior of the participants. Significant results were found for both the main and interaction effects. The results suggested that the high density, low speed, and diagonal direction situations associated with the virtual crowd had the greatest impacts on the speed, deviation, and trajectory lengths of participants when they walked in a virtual environment and were surrounded by a moving virtual population.
C1 [Koilias, Alexandros; Anagnostopoulos, Christos-Nikolaos] Univ Aegean, Dept Cultural Technol & Commun, Mitilini, Greece.
   [Nelson, Michael G.; Mousas, Christos] Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
C3 University of Aegean; Purdue University System; Purdue University
RP Mousas, C (corresponding author), Purdue Univ, Dept Comp Graph Technol, W Lafayette, IN 47907 USA.
EM cmousas@purdue.edu
RI Anagnostopoulos, Christos-Nikolaos/AAR-2988-2021; Mousas,
   Christos/AGV-3533-2022
OI Anagnostopoulos, Christos-Nikolaos/0000-0002-4496-275X; Mousas,
   Christos/0000-0003-0955-7959
CR Abernethy B, 1995, ADV PSYCHOL, V111, P171
   Ahn Junghyun., 2012, P 11 ACM SIGGRAPH IN, P231
   [Anonymous], 1984, AM J PHYSIOL, DOI DOI 10.1152/AJPREGU.1984.246.6.R1000
   Babu SV, 2011, IEEE T VIS COMPUT GR, V17, P14, DOI 10.1109/TVCG.2009.211
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Berton F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P717, DOI [10.1109/VR.2019.8798204, 10.1109/vr.2019.8798204]
   Bischof WF, 2003, CYBERPSYCHOL BEHAV, V6, P487, DOI 10.1089/109493103769710514
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   Chihak BJ, 2010, J EXP PSYCHOL HUMAN, V36, P1535, DOI 10.1037/a0020560
   Cirio G, 2013, IEEE T VIS COMPUT GR, V19, P671, DOI 10.1109/TVCG.2013.34
   Dickinson P, 2019, VIRTUAL REAL-LONDON, V23, P19, DOI 10.1007/s10055-018-0365-0
   Ducourant T, 2005, NEUROSCI LETT, V389, P6, DOI 10.1016/j.neulet.2005.06.052
   Faria JJ, 2010, BEHAV ECOL, V21, P1236, DOI 10.1093/beheco/arq141
   *FED HIGHW ADM, 2003, US MAN UN TRAFF CONT
   FELL A, 2003, STUDY MODELING CROWD
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Freeman D, 2003, J NERV MENT DIS, V191, P509, DOI 10.1097/01.nmd.0000082212.83842.fe
   Ghasemi A, 2012, INT J ENDOCRINOL MET, V10, P486, DOI 10.5812/ijem.3505
   Grechkin TY, 2013, J EXP PSYCHOL HUMAN, V39, P23, DOI 10.1037/a0029716
   Guéguen N, 2001, J SOC PSYCHOL, V141, P413, DOI 10.1080/00224540109600562
   Helbing D, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.046109
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P290, DOI 10.1162/pres.1996.5.3.290
   HUERRE S, 2010, ACM SIGGRAPH ASIA CO, P13
   Jiang Y., 2016, P ACM S APPL PERCEPT, P57, DOI [DOI 10.1145/2931002.2931003, 10.1145/2931002.2931003, DOI 10.1145/2931002]
   Jiang YY, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3147884
   Karamouzas I., 2010, Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology, VRST '10, P183, DOI DOI 10.1145/1889863
   Keedwell AD, 2015, LATIN SQUARES AND THEIR APPLICATIONS, 2ND EDITION, P1
   KROGMEIER C, 2019, COMPUT ANIMAT VIRT W, V30, P3
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   LATOSCHIK ME, 2017, VRST17 P 23 ACM S
   LEFKOWITZ M, 1955, J Abnorm Psychol, V51, P704, DOI 10.1037/h0042000
   Lemercier S, 2012, COMPUT GRAPH FORUM, V31, P489, DOI 10.1111/j.1467-8659.2012.03028.x
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Luo LB, 2008, COMPUT ANIMAT VIRT W, V19, P271, DOI 10.1002/cav.238
   MCDONNELL R, 2012, ACM T GRAPHIC, V31
   McDonnell R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360625
   Miller RH, 2012, P ROY SOC B-BIOL SCI, V279, P1498, DOI 10.1098/rspb.2011.2015
   Mousas C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P626, DOI [10.1109/VR46266.2020.00-19, 10.1109/VR46266.2020.1581211592060]
   Mousas C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P726, DOI [10.1109/VR.2019.8798043, 10.1109/vr.2019.8798043]
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   Nelson M, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365709
   Olivier Anne-Helene, 2018, IEEE Transactions on Visualization and Computer Graphics, V24, P2251, DOI 10.1109/TVCG.2017.2714665
   Olivier AH, 2014, TRANSP RES PROC, V2, P114, DOI 10.1016/j.trpro.2014.09.015
   Pan XN, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032931
   Pelechano N., 2008, Proceedings of Autonomous Agents and Multiagent Systems, P136
   Perrinet J, 2013, P ACM S APPL PERC, P59
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Peters C, 2009, IEEE COMPUT GRAPH, V29, P54, DOI 10.1109/MCG.2009.69
   Plamondon R, 2003, BIOL CYBERN, V89, P126, DOI 10.1007/s00422-003-0407-9
   Randhavane T, 2019, IEEE T VIS COMPUT GR, V25, P3135, DOI 10.1109/TVCG.2019.2932235
   Rio KW, 2018, P ROY SOC B-BIOL SCI, V285, DOI 10.1098/rspb.2018.0611
   Rio KW, 2014, J VISION, V14, DOI 10.1167/14.2.4
   ROS A, 2018, FOLLOWER BEHAV VIRTU
   Serafin G., 2004, SOUND DESIGN ENHANCE
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stevens E, 2013, J PEDIATR PSYCHOL, V38, P285, DOI 10.1093/jpepsy/jss116
   Still GK, 2014, INTRODUCTION TO CROWD SCIENCE, P1, DOI 10.1201/b17097
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   Warren WH, 2018, CURR DIR PSYCHOL SCI, V27, P232, DOI 10.1177/0963721417746743
   Wilcox Laurie M., 2006, ACM Trans. on Perception, V3, P412, DOI [DOI 10.1145/1190036.1190041, 10.1145/1190036.1190041]
NR 62
TC 17
Z9 18
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2020
VL 31
IS 6
AR e1928
DI 10.1002/cav.1928
EA JUN 2020
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA PE8AF
UT WOS:000536774600001
DA 2024-07-18
ER

PT J
AU Kim, J
   Seol, Y
   Kim, H
   Kwon, T
AF Kim, Jongmin
   Seol, Yeongho
   Kim, Hoemin
   Kwon, Taesoo
TI Interactive character posing with efficient collision handling
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE collision handling; human motion; interactive editing
ID INVERSE KINEMATICS
AB An interactive interface for character posing is important in the field of computer graphics, games, and virtual reality. The inverse kinematics (IK) solver is the most popular approach that satisfies both the kinematic equations and the user-defined position and orientation constraints on the end-effectors. In this article, we present a novel interactive IK framework that efficiently handles various types of collisions and the spatial relationship constraints during the character posing process. Based on our method, a desired human pose can be easily obtained while resolving a collision with the environment and maintaining the spatial relationship of body parts. In addition, the character pose is smoothly updated throughout the user manipulation.
C1 [Kim, Jongmin] Kangwon Natl Univ, Dept Comp Sci, Chunchon, South Korea.
   [Seol, Yeongho] NVIDIA, Graph AI, Seoul, South Korea.
   [Kim, Hoemin; Kwon, Taesoo] Hanyang Univ, Dept Comp Sci, Seoul, South Korea.
C3 Kangwon National University; Hanyang University
RP Kwon, T (corresponding author), Hanyang Univ, Dept Comp Sci, Seoul, South Korea.
EM taesoobear@gmail.com
RI Seol, Yeongho/KIE-6801-2024
CR Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Aristidou A, 2011, GRAPH MODELS, V73, P243, DOI 10.1016/j.gmod.2011.05.003
   Baerlocher P, 2004, VISUAL COMPUT, V20, P402, DOI 10.1007/s00371-004-0244-4
   Bertram D, 2006, IEEE INT CONF ROBOT, P1874
   Buss S. R., 2004, IEEE J ROBOTIC AUTOM, V17, P16
   Erleben K, 2017, MIG'17: PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON MOTION IN GAMES, DOI 10.1145/3136457.3136464
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Harish P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2887740
   Ho ESL, 2013, IEEE INT CONF ROBOT, P3813, DOI 10.1109/ICRA.2013.6631113
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Ho ESL, 2007, IEEE-RAS INT C HUMAN, P507, DOI 10.1109/ICHR.2007.4813918
   Johnson S., 2017, The NLopt nonlinear-optimization package
   Kallmann M, 2008, COMPUT ANIMAT VIRT W, V19, P79, DOI 10.1002/cav.176
   Kim J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601170
   Kim M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531385
   Lee J, 1999, COMP GRAPH, P39
   Lee Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866160
   LIBCCD, 2013, LIB COLL DET CONV SH
   MEREDITH M, 2004, P INT C COMP GAM ART, P81
   Mukundan R, 2009, INT J COMPUT APPL T, V34, P303, DOI 10.1504/IJCAT.2009.024084
   O'Sullivan C, 1999, SPRING COMP SCI, P67
   Peinado M, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P89
   Ren J, 2010, P 2010 2 INT C ED TE, V3, pV3
   Rose C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P147, DOI 10.1145/237170.237229
   Schmidl H., 2004, Journal of Graphics Tools, V9, P1, DOI 10.1080/10867651.2004.10504891
   Unzueta L, 2008, GRAPH MODELS, V70, P87, DOI 10.1016/j.gmod.2008.03.002
   WANG LCT, 1991, IEEE T ROBOTIC AUTOM, V7, P489, DOI 10.1109/70.86079
   ZHAO JM, 1994, ACM T GRAPHIC, V13, P313, DOI 10.1145/195826.195827
NR 28
TC 2
Z9 2
U1 2
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2020
VL 31
IS 3
AR e1923
DI 10.1002/cav.1923
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LY8SD
UT WOS:000540797600002
DA 2024-07-18
ER

PT J
AU Lin, XX
   Wang, X
   Li, FWB
   Li, JY
   Yang, BL
   Zhang, KL
   Wei, TX
AF Lin, Xianxuan
   Wang, Xun
   Li, Frederick W. B.
   Li, Jinyu
   Yang, Bailin
   Zhang, Kaili
   Wei, Tianxiang
TI Example-based image recoloring in an indoor environment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE coloring expectation; color migration; color structure; interactive
   operation; home scene image
ID COLOR TRANSFER; SEGMENTATION
AB Color structure of a home scene image closely relates to the material properties of its local regions. Existing color migration methods typically fail to fully infer the correlation between the coloring of local home scene regions, leading to a local blur problem. In this paper, we propose a color migration framework for home scene images. It picks the coloring from a template image and transforms such coloring to a home scene image through a simple interaction. Our framework comprises three main parts. First, we carry out an interactive segmentation to divide an image into local regions and extract their corresponding colors. Second, we generate a matching color table by sampling the template image according to the color structure of the original home scene image. Finally, we transform colors from the matching color table to the target home scene image with the boundary transition maintained. Experimental results show that our method can effectively transform the coloring of a scene matching with the color composition of a given natural or interior scenery.
C1 [Lin, Xianxuan; Wang, Xun; Yang, Bailin; Zhang, Kaili; Wei, Tianxiang] Zhejiang Gongshang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
   [Li, Frederick W. B.] Univ Durham, Durham, England.
   [Li, Jinyu] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University; Durham University; Zhejiang University
RP Yang, BL (corresponding author), Zhejiang Gongshang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
EM ybl@mail.zjgsu.edu.cn
RI Li, Frederick W. B./AAM-6662-2021
OI lin, xianxuan/0000-0002-3417-6915; Li, Frederick W.
   B./0000-0002-4283-4228; Li, Jinyu/0000-0002-5206-8600; Yang,
   Bolin/0009-0006-0499-1202; Wei, Tianxiang/0000-0001-6399-176X; Yang,
   Bailin/0000-0003-1754-5595
FU National Key Program of China [2018YFB1403200]; National Natural Science
   Foundation of China [U1609215, 61472363]; Key Program Project of
   Zhejiang Province [2019c01004]
FX National Key Program of China, Grant/Award Number: 2018YFB1403200;
   National Natural Science Foundation of China, Grant/Award Number:
   U1609215 and 61472363; Key Program Project of Zhejiang Province,
   Grant/Award Number: 2019c01004
CR [Anonymous], 1973, The Art of Color: The Subjective Experience and Objective Rationale of Color
   [Anonymous], 1981, PATTERN RECOGN
   [Anonymous], 2005, Computational Aesthetics in Graphics, Visualization and Imaging, DOI [DOI 10.2312/COMPAESTH/COMPAESTH05/111-122, 10.2312/COMPAESTH/COMPAESTH05/111-122]
   Birren F., 1969, A grammar of color; a basic treatise on the color system of albert H. munsell
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Chen GM, 2016, COMPUT GRAPH-UK, V60, P34, DOI 10.1016/j.cag.2016.08.009
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Huang FC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766922
   Lin S., 2013, P ACM SIGCHI C HUM F, P3101
   Nguyen RMH, 2014, COMPUT GRAPH FORUM, V33, P319, DOI 10.1111/cgf.12500
   O'Donovan P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964958
   Ou LC, 2006, COLOR RES APPL, V31, P191, DOI 10.1002/col.20208
   Papadakis N, 2011, IEEE T IMAGE PROCESS, V20, P1682, DOI 10.1109/TIP.2010.2095869
   Peters G, 2007, IEEE INT CONF INF VI, P316
   Pitié F, 2007, COMPUT VIS IMAGE UND, V107, P123, DOI 10.1016/j.cviu.2006.11.011
   Pouli T, 2011, COMPUT GRAPH-UK, V35, P67, DOI 10.1016/j.cag.2010.11.003
   Price BL, 2010, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR.2010.5540079
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Tai YW, 2005, PROC CVPR IEEE, P747
   Tanaka G, 2010, J ADV COMPUT INTELL, V14, P185, DOI 10.20965/jaciii.2010.p0185
   Wang XH, 2012, J COMPUT SCI TECH-CH, V27, P1119, DOI 10.1007/s11390-012-1290-4
   Weeks AR, 1997, P SOC PHOTO-OPT INS, V3026, P143, DOI 10.1117/12.271117
   Xiao Xuezhong, 2006, PACM INT C VIRT REAL, P305, DOI DOI 10.1145/1128923.1128974
   Zhang SY, 2017, VISUAL COMPUT, V33, P925, DOI 10.1007/s00371-017-1394-5
   Zhu J, 2018, IEEE T VIS COMPUT GR, V24, P2473, DOI 10.1109/TVCG.2017.2753255
   Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146
NR 26
TC 2
Z9 2
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2020
VL 31
IS 2
AR e1917
DI 10.1002/cav.1917
EA DEC 2019
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LC0VU
UT WOS:000501356800001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Demsar, J
   Blewitt, W
   Bajec, IL
AF Demsar, Jure
   Blewitt, Will
   Bajec, Iztok Lebar
TI A hybrid model for simulating grazing herds in real time
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animal groups; collective animal behaviour; crowd simulation; hybrid
   model; sheep herds
ID PREDATOR ATTACKS; BEHAVIOR; TRANSITION
AB Computer simulations of animal groups are usually performed via individual-based modelling, where simulated animals are designed on the level of individuals. With this approach, developers are able to capture behavioural nuances of real animals. However, modelling each individual as its own entity has the downside of having a high computational cost, meaning that individual-based models are usually not suitable for real-time simulations of very large groups. A common alternative approach is flow-based modelling, where the dynamics of animal congregations are designed on the group level. This enables researchers to create real-time simulations of massive phenomena at the cost of biological authenticity. A novel approach called hybrid modelling tries to mix the best of both worlds-precision of individual-based models and speed of flow-based ones. An unknown surrounding hybrid model is the question of their biological authenticity and relevance. In this study, we develop a hybrid model for the simulation of herds of grazing sheep. Through Bayesian data analysis, we show that such an approach can encompass several aspects of real-world sheep behaviour. Our hybrid model is also extremely efficient, capable of simulating herds of more than 1,000 individuals in real time without resorting to graphics processing unit execution.
C1 [Demsar, Jure; Bajec, Iztok Lebar] Univ Ljubljana, Fac Comp & Informat Sci, SI-1000 Ljubljana, Slovenia.
   [Blewitt, Will] Coventry Univ, Sch Comp Elect & Maths, Coventry, W Midlands, England.
C3 University of Ljubljana; Coventry University
RP Demsar, J (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, SI-1000 Ljubljana, Slovenia.
EM jure.demsar@fri.uni-lj.si
OI Demsar, Jure/0000-0001-6080-149X
FU Slovenian Research Agency (ARRS) [P2-0395]
FX Slovenian Research Agency (ARRS), Grant/Award Number: P2-0395
CR Andreev D, 2010, P ACM SIGGRAPH 2010
   [Anonymous], J ROYAL SOC INTERFAC
   [Anonymous], PLOS ONE
   [Anonymous], 2017, UN GAM ENG
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Bajec IL, 2009, ANIM BEHAV, V78, P777, DOI 10.1016/j.anbehav.2009.07.007
   Bayazit O.B., 2002, P 8 INT C ARTIFICIAL, P362
   Becco C, 2006, PHYSICA A, V367, P487, DOI 10.1016/j.physa.2005.11.041
   Bicho AD, 2012, COMPUT GRAPH-UK, V36, P70, DOI 10.1016/j.cag.2011.12.004
   Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01
   Couzin ID, 2002, J THEOR BIOL, V218, P1, DOI 10.1006/jtbi.2002.3065
   Creel S, 2005, ANIM BEHAV, V69, P1181, DOI 10.1016/j.anbehav.2004.07.022
   Deisboeck TS, 2009, BIOESSAYS, V31, P190, DOI 10.1002/bies.200800084
   Demar J, 2017, THESIS
   Demsar J, 2016, SCI REP-UK, V6, DOI 10.1038/srep39428
   Demsar J, 2015, ECOL MODEL, V304, P22, DOI 10.1016/j.ecolmodel.2015.02.018
   Demsar J, 2014, ARTIF LIFE, V20, P343, DOI 10.1162/ARTL_a_00135
   FREEDMAN HI, 1986, B MATH BIOL, V48, P493, DOI 10.1016/S0092-8240(86)90004-2
   Gelman A, 2006, BAYESIAN ANAL, V1, P515, DOI 10.1214/06-BA117A
   Ginelli F, 2015, P NATL ACAD SCI USA, V112, P12729, DOI 10.1073/pnas.1503749112
   Golas A, 2014, IEEE T VIS COMPUT GR, V20, P1022, DOI 10.1109/TVCG.2013.235
   Goodwin RA, 2006, ECOL MODEL, V192, P197, DOI 10.1016/j.ecolmodel.2005.08.004
   Hayward A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MANAGEMENT OF INNOVATION AND TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P11
   Hein AM, 2015, ELIFE, V4, DOI 10.7554/eLife.10955
   HEPPNER F, 1990, UBIQUITY OF CHAOS, P233
   Hildenbrandt H, 2010, BEHAV ECOL, V21, P1349, DOI 10.1093/beheco/arq149
   Hughes RL, 2003, ANNU REV FLUID MECH, V35, P169, DOI 10.1146/annurev.fluid.35.101101.161136
   Husselmann A.V., 2011, Proceedings of the IASTED International Conference on Parallel and Distributed Computing and Systems, P100
   Ijaz K., 2015, 17 UKSIMAMSS INT C M, P111, DOI [10.1109/UKSim.2015.46, DOI 10.5555/2867552.2868182]
   Kruschke J., 2014, JAGS STAN
   Kruschke JK, 2013, J EXP PSYCHOL GEN, V142, P573, DOI 10.1037/a0029146
   LIND J, 1999, MASSIVE SOFTWARE ENG
   Morini F, 2007, 2007 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P144, DOI 10.1109/CW.2007.23
   Olson RS, 2016, ARTIF LIFE, V22, P299, DOI 10.1162/ARTL_a_00206
   Park S.I., 2011, MOTION GAMES
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Sumpter DJT, 2006, PHILOS T R SOC B, V361, P5, DOI 10.1098/rstb.2005.1733
   Tener J. S., 1965, MUSKOXEN CANADA BIOL
   Tomazella GG, 2009, PROTEOME SCI, V7, DOI 10.1186/1477-5956-7-32
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Tunstrom K, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002915
   Vermeulen JL, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1775
   VICSEK T, 1995, PHYS REV LETT, V75, P1226, DOI 10.1103/PhysRevLett.75.1226
   Wang XJ, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12277
   Xu ML, 2014, J COMPUT SCI TECH-CH, V29, P799, DOI 10.1007/s11390-014-1469-y
   Zhou SP, 2010, ACM T MODEL COMPUT S, V20, DOI 10.1145/1842722.1842725
NR 46
TC 1
Z9 1
U1 1
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2020
VL 31
IS 1
AR e1914
DI 10.1002/cav.1914
EA AUG 2019
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KR0SC
UT WOS:000481096800001
OA Bronze
DA 2024-07-18
ER

PT J
AU Oshita, M
AF Oshita, Masaki
TI Agent navigation using deep learning with agent space heat map for crowd
   simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE agent navigation; crowd simulation; deep learning; neural network
ID MODEL
AB We propose a novel method of crowd simulation that employs a deep learning technique for controlling individual agents. We use a convolutional neural network to learn agent space heat maps that are generated from example crowd animations. A heat map contains the positions and speeds of nearby agents and the temporary target position that indicates an appropriate heading direction for the agent to reach the final target position efficiently. When controlling an agent, an agent space heat map that contains possible temporary target positions is estimated from the trained model and the agent space heat map that contains only the positions and speeds of nearby agents. In addition, evaluation functions are used to choose a temporary target position from the estimated heat map. Individual agents are controlled using a force-based model so that they move toward the estimated temporary target position. Our approach realizes human-like navigation by combining the intuitive and logical aspects of decision-making.
C1 [Oshita, Masaki] Kyushu Inst Technol, 680-4 Kawazu, Iizuka, Fukuoka 8208502, Japan.
C3 Kyushu Institute of Technology
RP Oshita, M (corresponding author), Kyushu Inst Technol, 680-4 Kawazu, Iizuka, Fukuoka 8208502, Japan.
EM oshita@ces.kyutech.ac.jp
RI Alidadi, Mehdi/HJZ-0235-2023
OI Alidadi, Mehdi/0000-0001-5183-7829; Oshita, Masaki/0000-0001-9844-7713
FU  [15H02704]
FX Grant-in-Aid for Scientific Research, Grant/Award Number: 15H02704
CR [Anonymous], 2009, P 2009 S INTERACTIVE, DOI DOI 10.1145/1507149.1507184
   Bera A, 2015, P 41 GRAPH INT C, P65
   Best A., 2014, S COMP AN, P97
   Boatright CD, 2015, COMPUT ANIMAT VIRT W, V26, P483, DOI 10.1002/cav.1572
   Bruneau J, 2017, COMPUT GRAPH FORUM, V36, P108, DOI 10.1111/cgf.13066
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Guy S.J., 2011, P 2011 ACM SIGGRAPH, P43, DOI [10.1145/2019406.2019413, DOI 10.1145/2019406.2019413]
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hughes R, 2014, P ACM SIGGRAPH EUR S, P203
   Kapadia M., 2013, P 12 ACM SIG GRAPHEU, P115, DOI DOI 10.1145/2485895.2485909
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Lee JC, 2018, PROCEEDINGS OF 2018 2ND INTERNATIONAL CONFERENCE ON SOFTWARE AND E-BUSINESS (ICSEB 2018), P1, DOI 10.1145/3301761.3301762
   Lee SJ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778859
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Shamsul M, 2016, P 15 ACM SIGGRAPH C, P281
   Sud A, 2008, IEEE T VIS COMPUT GR, V14, P526, DOI 10.1109/TVCG.2008.27
   Tokui S., 2015, Chainer: a Next-Generation Open Source Framework for Deep Learning
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
NR 21
TC 11
Z9 11
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1878
DI 10.1002/cav.1878
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400009
DA 2024-07-18
ER

PT J
AU Dupre, R
   Argyriou, V
AF Dupre, Rob
   Argyriou, Vasileios
TI A human and group behavior simulation evaluation framework utilizing
   composition and video analysis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE composition; crowd analysis evaluation; human behavior simulation
ID OPTICAL-FLOW; MOTION; MODEL; MIXTURE
AB In this work, we present the modular crowd simulation evaluation through composition framework, which provides a quantitative comparison between different pedestrian and crowd simulation approaches. Evaluation is made based on the comparison of source footage against synthetic video created through novel composition techniques. The proposed framework seeks to reduce the complexity of simulation evaluation and provide a platform from which the comparison of differing simulation algorithms and parametric tuning can be conducted to improve simulation accuracy or provide measures of similarity between crowd simulation algorithms and source data. Through the use of features designed to mimic the human visual system, specific simulation properties can be evaluated relative to sample footage. Validation was performed on a number of popular crowd data sets and through comparisons of multiple pedestrian and crowd simulation algorithms.
C1 [Dupre, Rob; Argyriou, Vasileios] Kingston Univ, Kingston Upon Thames KT1 1LQ, Surrey, England.
   [Argyriou, Vasileios] Penrhyn Rd, Kingston Upon Thames KT1 2EE, Surrey, England.
C3 Kingston University
RP Argyriou, V (corresponding author), Kingston Univ, Kingston Upon Thames KT1 1LQ, Surrey, England.; Argyriou, V (corresponding author), Penrhyn Rd, Kingston Upon Thames KT1 2EE, Surrey, England.
EM Vasileios.Argyriou@kingston.ac.uk
OI Argyriou, Vasileios/0000-0003-4679-8049
CR Allain Pierre, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P279
   [Anonymous], 1834, PULSU ABSORTIONE AUD
   [Anonymous], 2008, 2008 IEEE C COMP VIS
   [Anonymous], 2012, P ACM SIGGRAPH S INT
   Argyriou V, 2007, IEEE T MULTIMEDIA, V9, P1147, DOI 10.1109/TMM.2007.898926
   Argyriou V, 2011, IEEE T IMAGE PROCESS, V20, P110, DOI 10.1109/TIP.2010.2057438
   Asano M, 2010, TRANSPORT RES C-EMER, V18, P842, DOI 10.1016/j.trc.2010.01.005
   Asano M, 2009, TRANSPORTATION AND TRAFFIC THEORY 2009: GOLDEN JUBILEE, P559, DOI 10.1007/978-1-4419-0820-9_28
   Banerjee B., 2011, AGENTS GAMES SIMULAT, VII, P53
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Bloom V, 2015, LECT NOTES COMPUT SC, V8925, P698, DOI 10.1007/978-3-319-16178-5_49
   Bloom V, 2014, INT C PATT RECOG, P3963, DOI 10.1109/ICPR.2014.679
   Charalambous P, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12472
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Clarke TL, 2007, P EUR MOD SIM S EMSS
   Crompton D., 1979, Proceedings of PTRC Summer Annual Meeting, P275
   Do Y, 2013, 2013 10 IEEE INT C C, P712
   Duives DC, 2013, TRANSPORT RES C-EMER, V37, P193, DOI 10.1016/j.trc.2013.02.005
   Ferryman J., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P143, DOI 10.1109/AVSS.2010.90
   Guo S, 2014, 2014 INT C INF SCI A, P3
   Guy SJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366209
   Helbing D, 1998, PREPRINT
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu M, 2004, INT C PATT RECOG, P724, DOI 10.1109/ICPR.2004.1334361
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Jablonski K, 2014, TRANSP RES PROC, V2, P412, DOI 10.1016/j.trpro.2014.09.046
   Kapadia M., 2016, SIMULATING HETEROGEN, P193
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Khoong WL, 2011, P 3 2011 CUTSE INT C
   Klügl F, 2009, LECT NOTES ARTIF INT, V5803, P631, DOI 10.1007/978-3-642-04617-9_79
   Lakoba TI, 2005, SIMUL-T SOC MOD SIM, V81, P339, DOI 10.1177/0037549705052772
   Lerner A, 2010, COMPUT GRAPH FORUM, V29, P2197, DOI 10.1111/j.1467-8659.2010.01808.x
   Lerner A, 2009, LECT NOTES COMPUT SC, V5884, P75, DOI 10.1007/978-3-642-10347-6_7
   Loy CC, 2013, IEEE I CONF COMP VIS, P2256, DOI 10.1109/ICCV.2013.270
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Makris D, 2002, IMAGE VISION COMPUT, V20, P895, DOI 10.1016/S0262-8856(02)00098-7
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   Munder S, 2008, IEEE T INTELL TRANSP, V9, P333, DOI 10.1109/TITS.2008.922943
   Musse SR, 2012, COMPUT ANIMAT VIRT W, V23, P49, DOI 10.1002/cav.1423
   Papadimitriou E, 2009, TRANSPORT RES F-TRAF, V12, P242, DOI 10.1016/j.trf.2008.12.004
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Portz A., 2010, PEDESTRIAN EVACUATIO, P577
   Qiao G, 2017, PREPRINT
   Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42
   Reynolds C., STEERING BEHAV AUTON
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P1235, DOI 10.1109/ICCV.2011.6126374
   Simonnet D., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P174, DOI 10.1109/ICSIPA.2011.6144127
   Singh S, 2009, COMPUT ANIMAT VIRT W, V20, P533, DOI 10.1002/cav.277
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Wang H, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P49, DOI 10.1145/2856400.2856410
   Wang Q, 2012, IEEE IMTC P, P2022
   Wharton E, 2008, IEEE SYS MAN CYBERN, P685, DOI 10.1109/ICSMC.2008.4811357
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Xi H., 2011, Human-in-the-Loop Simulations, P69, DOI [DOI 10.1007/978-0-85729-883-6_4, 10.1007/978-0-85729-883-6_4]
   ZANKER JM, 1995, PERCEPTION, V24, P363, DOI 10.1068/p240363
   Zanlungo F, 2014, TRANSP RES PROC, V2, P149, DOI 10.1016/j.trpro.2014.09.020
   Zeisl B, 2015, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2015.310
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 61
TC 4
Z9 5
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2019
VL 30
IS 1
AR e1844
DI 10.1002/cav.1844
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8YF
UT WOS:000458275000005
OA Green Accepted, Bronze
DA 2024-07-18
ER

PT J
AU Schröder, M
   Waltemate, T
   Maycock, J
   Röhlig, T
   Ritter, H
   Botsch, M
AF Schroeder, Matthias
   Waltemate, Thomas
   Maycock, Jonathan
   Roehlig, Tobias
   Ritter, Helge
   Botsch, Mario
TI Design and evaluation of reduced marker layouts for hand motion capture
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; geometric modeling; hand tracking; motion capture
ID REGISTRATION; MODELS
AB We present a method for automatically generating reduced marker layouts for marker-based optical motion capture of human hands. The employed motion reconstruction method is based on subspace-constrained inverse kinematics, which allows recovery of realistic hand movements even from sparse input data. We additionally present a user-specific hand model calibration procedure that fits an articulated hand model to point cloud data of the user's hand. Our marker layout optimization is sensitive to the kinematic structure and the subspace representations of hand articulations utilized in the reconstruction method, in order to generate sparse marker configurations that are optimal for solving the constrained inverse kinentatics problem. We propose specific quality criteria for reduced marker sets that combine numerical stability with geometric feasibility of the resulting layout. These criteria are combined in an objective function that is minimized using a specialized surface-constrained particle swarm optimization scheme, which generates marker layouts bound to the surface of an animated hand model. Our method provides a principled way for determining reduced marker layouts based on subspace representations of hand articulations. We demonstrate the effectiveness of our motion reconstruction and model calibration methods in a thorough evaluation.
C1 [Schroeder, Matthias; Waltemate, Thomas; Botsch, Mario] Bielefeld Univ, Cognit Interact Technol CITEC, Comp Graph & Geometry Proc Grp, D-33619 Bielefeld, Germany.
   [Schroeder, Matthias; Maycock, Jonathan; Roehlig, Tobias; Ritter, Helge] Bielefeld Univ, Cognit Interact Technol CITEC, Neuroinformat Grp, Inspirat 1, D-33619 Bielefeld, Germany.
C3 University of Bielefeld; University of Bielefeld
RP Schröder, M (corresponding author), Bielefeld Univ, Cognit Interact Technol CITEC, Neuroinformat Grp, Inspirat 1, D-33619 Bielefeld, Germany.
EM matthias.schroeder@uni-bielefeld.de
OI Botsch, Mario/0000-0001-9954-120X
FU CITEC; DFG
FX CITEC; DFG
CR Achenbach J, 2015, Accurate face reconstruction through anisotropic fitting and eye correction, P1
   Albrecht I., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P98
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   [Anonymous], P ACM MOT GAM LISB P
   [Anonymous], P ACM MOT GAM DUBL I
   [Anonymous], 2009, THESIS
   [Anonymous], 2008, MoCap for Artists: Workflow and Techniques for Motion Capture
   [Anonymous], 1995, 1995 IEEE INT C
   [Anonymous], 2011, BMVC
   Bernshtein N.A., 1967, The co-ordination and regulation of movements
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Buss Samuel R., 2004, TECHNICAL REPORT
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Chang Lillian Y., 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2944, DOI 10.1109/IROS.2007.4399115
   CUTKOSKY MR, 1989, IEEE T ROBOTIC AUTOM, V5, P269, DOI 10.1109/70.34763
   EDMONDS J, 1972, J ACM, V19, P248, DOI 10.1145/321694.321699
   Floater MS, 2005, COMPUT AIDED GEOM D, V22, P623, DOI 10.1016/j.cagd.2005.06.004
   Guerra-Filho G.B., 2005, J THEORETICAL APPL I, VRITA 12, P61
   Hasler N, 2009, COMPUT GRAPH FORUM, V28, P337, DOI 10.1111/j.1467-8659.2009.01373.x
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Hoyet L., 2012, P ACM SIGGRAPH S INT, P79, DOI DOI 10.1145/2159616.2159630.6,17
   Jacka D, 2007, AFRIGRAPH 2007: 5TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY, COMPUTER GRAPHICS, VISUALIZATION AND INTERACTION IN AFRICA, P177
   Kang Chris, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P244, DOI 10.1007/978-3-642-34710-8_23
   Kato Makoto., 2006, J MULTIMED, V1, P52
   Kennedy J., 2001, Swarm Intelligence
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Le BH, 2013, IEEE T VIS COMPUT GR, V19, P1859, DOI 10.1109/TVCG.2013.84
   Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Liu G., 2006, P 2006 S INTERACTIVE, P35, DOI [DOI 10.1145/1111411.1111418, 10.1145/1111411.1111418.]
   Loper M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661273
   Maycock J, 2015, IEEE-RAS INT C HUMAN, P461, DOI 10.1109/HUMANOIDS.2015.7363590
   Mulatto S, 2013, IEEE T HAPTICS, V6, P106, DOI [10.1109/TOH.2012.13, 10.1109/ToH.2012.13]
   Qian C, 2014, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2014.145
   Rhee Taehyun., 2006, Human Hand Modeling from Surface Anatomy, DOI DOI 10.1145/1111411.1111417
   Schlomer T., 2011, P ACM SIGGRAPH S HIG, P135, DOI DOI 10.1145/2018323.2018345
   Schröder M, 2014, IEEE INT CONF ROBOT, P5447, DOI 10.1109/ICRA.2014.6907660
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Tagliasacchi A, 2015, COMPUT GRAPH FORUM, V34, P101, DOI 10.1111/cgf.12700
   Tan DJ, 2016, PROC CVPR IEEE, P5610, DOI 10.1109/CVPR.2016.605
   Taylor J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925965
   Taylor J, 2014, PROC CVPR IEEE, P644, DOI 10.1109/CVPR.2014.88
   Thiery JM, 2012, COMPUT GRAPH FORUM, V31, P2303, DOI 10.1111/j.1467-8659.2012.03159.x
   Wheatland N, 2015, COMPUT GRAPH FORUM, V34, P735, DOI 10.1111/cgf.12595
   Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P426, DOI 10.1109/ICCV.2001.937656
   Zhu LF, 2015, COMPUT GRAPH FORUM, V34, P459, DOI 10.1111/cgf.12575
NR 47
TC 8
Z9 8
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2018
VL 29
IS 6
AR e1751
DI 10.1002/cav.1751
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HH9VW
UT WOS:000456089800007
DA 2024-07-18
ER

PT J
AU Liu, CX
   Shen, YY
   Shao, YQ
   Zhao, JW
   Wang, X
AF Liu, Chunxiao
   Shen, Yiyun
   Shao, Yaqi
   Zhao, Jinwei
   Wang, Xun
TI Sky detection- and texture smoothing-based high-visibility haze removal
   from images and videos
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE atmospheric light; haze removal; sky detection; temporal coherence;
   texture smoothing; transmission
ID REAL-TIME IMAGE
AB To address the gloomy sky and the low contrast caused by the left fog in the existing image dehazing methods, we propose a robust haze removal algorithm for images and videos. First, a sky detection-based adaptive atmospheric light estimation method is designed for brighter and cleaner restoration results for the sky regions. Second, in order to reconstruct a transmission map in line with the depth variation, we preprocess the input image with texture smoothing to keep the color consistency inside the same planar object and devise a texture smoothing-based robust transmission estimation method, with which the contrast and color saturation of fog-free image are greatly promoted. Finally, the restored results are post-processed with the joint bilateral filter for the purpose of noise removal. What's more, a guided filter-based temporally coherent atmospheric light smoothing strategy and a Gaussian filter-based spatial-temporally coherent transmission smoothing strategy are put forward for video dehazing, which can ensure the spatial as well as temporal continuity of the haze-free videos. Experimental results show that the recovered haze-free images and videos have high contrast and color saturation with cleaner sky regions, and the haze-free videos are free of jittering and flickering phenomena.
C1 [Liu, Chunxiao; Shen, Yiyun; Shao, Yaqi; Zhao, Jinwei; Wang, Xun] Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University
RP Liu, CX (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Informat Engn, Hangzhou, Zhejiang, Peoples R China.
EM cxliu@mail.zjgsu.edu.cn
RI Zhao, Jinwei/IQU-0651-2023; Liu, Chunxiao/D-7975-2016
OI Liu, Chunxiao/0000-0002-0645-8771
FU Zhejiang Provincial Natural Science Foundation of China [LY14F020004];
   National Natural Science Foundation of China [61003188, 61379075,
   U1609215]; Talent Young Foundation of Zhejiang Gongshang University
   [QZ13-9]; National Key Technology RD Program [2014BAK14B01]; Zhejiang
   Provincial Commonweal Technology Applied Research Projects of China
   [2015C33071]; State Key Lab of Virtual Reality Technology and Systems at
   Beihang University [BUAA-VR-13KF-2013-3]; Zhejiang Provincial Key
   Laboratory of Electronic Commerce and Logistics Information Technology
   [2011E10005]; Zhejiang Provincial Research Center of Intelligent
   Transportation Engineering and Technology [2015ERCITZJ- KF1]
FX Zhejiang Provincial Natural Science Foundation of China, Grant/Award
   Number: LY14F020004; National Natural Science Foundation of China,
   Grant/Award Number: 61003188, 61379075 and U1609215; Talent Young
   Foundation of Zhejiang Gongshang University, Grant/Award Number: QZ13-9;
   National Key Technology R&D Program, Grant/Award Number: 2014BAK14B01;
   Zhejiang Provincial Commonweal Technology Applied Research Projects of
   China, Grant/Award Number: 2015C33071; State Key Lab of Virtual Reality
   Technology and Systems at Beihang University, Grant/Award Number:
   BUAA-VR-13KF-2013-3; Zhejiang Provincial Key Laboratory of Electronic
   Commerce and Logistics Information Technology, Grant/Award Number:
   2011E10005; Zhejiang Provincial Research Center of Intelligent
   Transportation Engineering and Technology, Grant/Award Number:
   2015ERCITZJ- KF1
CR [Anonymous], P OCEANS SEP
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Lai YH, 2015, IEEE T CIRC SYST VID, V25, P1, DOI 10.1109/TCSVT.2014.2329381
   [刘兴云 Liu Xingyun], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P1453
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Shiau YH, 2013, IEEE T CIRC SYST VID, V23, P1369, DOI 10.1109/TCSVT.2013.2243650
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Tan R.T, 2008, P IEEE C COMP VIS PA, P1956
   [邢晓敏 Xing Xiaomin], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P1440
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   [赵锦威 Zhao Jinwei], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P1221
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 19
TC 3
Z9 5
U1 1
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1776
DI 10.1002/cav.1776
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200022
DA 2024-07-18
ER

PT J
AU Sato, S
   Mizutani, K
   Dobashi, Y
   Nishita, T
   Yamamoto, T
AF Sato, Syuhei
   Mizutani, Keisuke
   Dobashi, Yoshinori
   Nishita, Tomoyuki
   Yamamoto, Tsuyoshi
TI Feedback control of fire simulation based on computational fluid
   dynamics
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE editing shape and motion; fire simulation; grid-based simulation;
   PI-control
ID ANIMATION; FLAMES
AB Visual simulation of fire plays an important role in many applications, such as movies and computer games. In these applications, artists are often requested to synthesize realistic fire with a particular behavior. To meet such requirement, we present a feedback control method for fire simulations. The user can design the shape of fire by placing a set of control points. Our method generates a force field and automatically adjusts a temperature at a fire source, based on user specified control points. Experimental results show that our method can control the fire shape.
C1 [Sato, Syuhei] DWANGO Co Ltd, UEI Res, Tokyo, Japan.
   [Mizutani, Keisuke] Hokkaido Univ, Sapporo, Hokkaido, Japan.
   [Yamamoto, Tsuyoshi] Hokkaido Univ, Informat Sci & Technol, Sapporo, Hokkaido, Japan.
   [Dobashi, Yoshinori] Hokkaido Univ, UEI Res, Sapporo, Hokkaido, Japan.
   [Nishita, Tomoyuki] Hiroshima Shudo Univ, UEI Res, Hiroshima, Japan.
C3 Hokkaido University; Hokkaido University; Hokkaido University
RP Sato, S (corresponding author), DWANGO Co Ltd, UEI Res, Bunkyo Ku, KADOKAWA Hongo Bldg 5-24-5 Hongo, Tokyo 1130033, Japan.
EM syuheisato0918@gmail.com
OI Sato, Syuhei/0009-0007-9270-7335
FU JSPS KAKENHI [JP15H05924]
FX JSPS KAKENHI, Grant/Award Number: JP15H05924
CR [Anonymous], 2008, Fluid Simulation for Computer Graphics
   Bangalore A., 2012, Proceedings of the Eighth Annual Symposium on Computational Aesthetics in Graphics, Visualization, and Imaging, CAe '12, P45
   Beaudoin P., 2001, P GRAPH INTERFACE, P159
   Dobashi Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360693
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Fuller AR, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P175
   Hong JM, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239498
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   Hong Y, 2010, VISUAL COMPUT, V26, P1217, DOI 10.1007/s00371-009-0403-8
   Horvath C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531347
   Kim T, 2016, VISUAL COMPUT, V32, P871, DOI 10.1007/s00371-016-1267-3
   Kim Y., 2006, P 2006 ACM SIGGRAPHE, P33
   Lamorlette A, 2002, ACM T GRAPHIC, V21, P729, DOI 10.1145/566570.566644
   Lever J, 2012, VISUAL COMPUT, V28, P691, DOI 10.1007/s00371-012-0684-1
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   Raveendran Karthik., 2012, Controlling liquids using meshes, P255
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Shi Lin., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '05, P229, DOI DOI 10.1145/1073368.1073401
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Thurey N., 2006, Proceedings of the 2006 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'06, P7, DOI [10.5555/1218064.1218066, DOI 10.5555/1218064.1218066]
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Yi Zhang, 2011, 2011 IEEE Electrical Power & Energy Conference (EPEC), P187, DOI 10.1109/EPEC.2011.6070193
NR 26
TC 4
Z9 4
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1766
DI 10.1002/cav.1766
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200012
DA 2024-07-18
ER

PT J
AU Wei, LY
AF Wei, Ling-yu
TI A faster triangle-to-triangle intersection test algorithm
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE triangle-to-triangle intersection; case-depending; partial cross product
AB The triangle-to-triangle intersection test is the most basic component of collision detection. And our algorithm, which firstly computes the line segment between triangle A and the plane of triangle B and uses a new method to detect the intersection between this line and triangle B, can reduce about 10% of time on average, compared with the previous fastest algorithm. Our new method divides the plane of triangle B into four quarter planes by two edges of B, and detects intersection depending on the location of the two endpoints of the segment. After using some techniques like avoiding division and projecting the segment and triangle B on XY, YZ, or ZX plane, the total number of arithmetic operations is reduced to at most 87, which is less than any existing algorithms. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Wei, LY (corresponding author), Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing 100084, Peoples R China.
EM cosimo.dw@gmail.com
RI Wei, Lingyu/N-4040-2018
OI Wei, Lingyu/0000-0001-7278-4228
FU National Basic Research Program of China [2007CB807900, 2007CB807901];
   National Natural Science Foundation of China [61073174, 61033001,
   61061130540]
FX This work was supported in part by the National Basic Research Program
   of China Grant 2007CB807900, 2007CB807901 and the National Natural
   Science Foundation of China Grant 61073174, 61033001, 61061130540.
CR [Anonymous], COMPUTER GRAPHICS FO
   Eberlys D., 2007, INTERSECTION CONVEX
   GOTTSCHALK S, 1996, ACM SIGGRAPH, P171
   Guigue P., 2003, Journal of Graphics Tools, V8, P25
   Lins MC, 1995, P ACM INT 3D GRAPH C
   Moller T., 1997, J. Graph. Tools, V2, P25, DOI [DOI 10.1080/10867651.1997.10487472, 10.1080/10867651.1997.10487472]
   Raabes A, 2008, THESIS BONN
   SHEN H, 2003, J GRAPHICS TOOLS, V8, P3
   Tropp O, 2006, COMPUT ANIMAT VIRT W, V17, P527, DOI 10.1002/cav.115
NR 9
TC 6
Z9 9
U1 0
U2 18
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2014
VL 25
IS 5-6
BP 553
EP 559
DI 10.1002/cav.1558
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AR9DE
UT WOS:000343871000005
DA 2024-07-18
ER

PT J
AU Shao, XQ
   Zhou, Z
   Wu, W
AF Shao, Xuqiang
   Zhou, Zhong
   Wu, Wei
TI Particle-based simulation of bubbles in water-solid interaction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE bubbles; water-solid interaction; particle-based method; smoothed
   particle hydrodynamics
ID ANIMATION
AB In this paper, a particle-based multiphase method for creating realistic animations of bubbles in watersolid interaction is presented. To generate bubbles from gas dissolved in the water on the fly, we propose an approximate model for the creation of bubbles, which takes into account the influence of gas concentration in the water, the solid material, and watersolid velocity difference. As the air particle on the bubble surface is treated as a virtual nucleation site, the bubble absorbs air from surrounding water and grows. The density and pressure forces of air bubbles are computed separately using smoothed particle hydrodynamics; then, the two-way coupling of bubbles with water and solid is solved by a new drag force, so the generated bubbles flow on the surface of solid and the deformation in the rising process can be simulated. Additionally, touching bubbles merge together under the cohesion forces weighted by the smoothing kernel and velocity difference. The experimental results show that this method is capable of simulating bubbles in watersolid interaction under different physical conditions. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Shao, Xuqiang; Zhou, Zhong; Wu, Wei] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University
RP Shao, XQ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM shaoxuqiang@gmail.com
FU National 973 Program of China [2009CB320805]; Natural Science Foundation
   of China [61073070]; National 863 Program of China [2012AA011803];
   Fundamental Research Funds for the Central Universities of China
FX This work is supported by the National 973 Program of China (grant no.
   2009CB320805), the Natural Science Foundation of China (grant no.
   61073070), the National 863 Program of China (grant no. 2012AA011803),
   and Fundamental Research Funds for the Central Universities of China.
CR Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Cleary P, 2007, ACM T GRAPHIC, V26, P555
   Enright D, 2002, J COMPUT PHYS, V183, P83, DOI 10.1006/jcph.2002.7166
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Greenwood S., 2004, Proceedings of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P287
   Hong JS, 2008, 2008 IEEE MIT-S INTERNATIONAL MICROWAVE WORKSHOP SERIES ON ART OF MINIATURIZING RF AND MICROWAVE PASSIVE COMPONENTS, P1, DOI [10.1109/PLASMA.2008.4591036, 10.1109/IMWS.2008.4782247]
   Hong JM, 2005, ACM T GRAPHIC, V24, P915, DOI 10.1145/1073204.1073283
   Hong JM, 2003, COMPUT GRAPH FORUM, V22, P253, DOI 10.1111/1467-8659.00672
   Ihmsen M, 2011, P 2011 INT C COMP GR
   Iwasaki K, 2010, COMPUT GRAPH FORUM, V29, P2215, DOI 10.1111/j.1467-8659.2010.01810.x
   Keiser R., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P125, DOI 10.1109/PBG.2005.194073
   Kim D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778807
   Kück H, 2002, PROC GRAPH INTERF, P81
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   Mihalef V., 2009, Proceedings of Eurographics, V2009, P28
   Mihalef V, 2006, P 2006 EUR ACM SIGGR
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Patankar N.A., 2001, CTR TURBULENCE RES A, P185
   Shao XQ, 2011, P 2011 COMP GRAPH IN
   Solenthaler B., 2008, P 2008 ACM SIGGRAPH, P211, DOI 10.2312/SCA/SCA08/211-218
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Song OY, 2005, ACM T GRAPHIC, V24, P81, DOI 10.1145/1037957.1037962
   Sun HQ, 2010, COMPUT ANIMAT VIRT W, V21, P589, DOI 10.1002/cav.379
   Thürey N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P191
   Zheng W., 2006, Proc. of the ACM Siggraph/Eurographics Symposium on Computer Animation, P325
NR 27
TC 9
Z9 12
U1 0
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2012
VL 23
IS 5
BP 477
EP 487
DI 10.1002/cav.438
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 021ZW
UT WOS:000309925700004
DA 2024-07-18
ER

PT J
AU Lopez, T
   Lamarche, F
   Li, TY
AF Lopez, Thomas
   Lamarche, Fabrice
   Li, Tsai-Yen
TI Space-time planning in changing environments: using dynamic objects for
   accessibility
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE path planning; motion planning; dynamic environments; autonomous agents;
   accessibility
ID COLLISION DETECTION; MOTION; OBSTACLES
AB Navigation is a critical task for agents populating virtual worlds. In the last years, numerous solutions have been proposed to solve the path planning problem in order to enhance the autonomy of virtual agents. Those solutions mainly focused on static environments, eventually populated with dynamic obstacles. However, dynamic objects are usually more than just obstacles as they can be used by an agent to reach new locations. In this paper, we propose an online path planning algorithm in dynamically changing environments with unknown evolution such as physically based-environments. Our method represents objects in terms of obstacles but also in terms of navigable surfaces. This representation allows our algorithm to find temporal paths through disconnected and moving platforms. We will also show that the proposed method also enables several kinds of adaptations such as avoiding moving obstacles or adapting the agent postures to environmental constraints. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Lopez, Thomas] Univ Rennes 1, IRISA, MimeTIC, Rennes, France.
   [Li, Tsai-Yen] Natl Chengchi Univ, Dept Comp Sci, Taipei 116, Taiwan.
C3 Universite de Rennes; National Chengchi University
RP Lopez, T (corresponding author), Univ Rennes 1, IRISA, MimeTIC, Rennes, France.
EM lopezthom@gmail.com
CR [Anonymous], 1979, 20 ANN S FDN COMP SC, DOI [10. 1109/sfcs.1979.10, DOI 10.1109/SFCS.1979.10]
   [Anonymous], 2012, Robot Motion Planning
   [Anonymous], 2005, P ACM SIGGRAPH EUR S
   Avril Q., 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P41, DOI 10.1109/ISVRI.2011.5759599
   Canny J., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, P460, DOI 10.1145/62212.62257
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Devaurs D, 2011, IEEE INT CONF ROBOT, P2261
   Gayle R, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3783
   Hoff K. E., 1999, COMPUTER GRAPHICS, P375
   Jaillet L., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P1606
   Kallmann M, 2004, IEEE INT CONF ROBOT, P4399, DOI 10.1109/ROBOT.2004.1302410
   Kallmann M, 2003, GEOMETRIC MODELLING, V3, P1
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Kuffner J. J.  Jr., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P995, DOI 10.1109/ROBOT.2000.844730
   Kuffner JJ, 1998, LECT NOTES ARTIF INT, V1537, P171
   Lamarche F, 1928, COMPUT GRAPH FORUM, V28, P649
   LaValle S. M., 2006, Planning algorithms
   LaValle SM, 1998, RAPIDLY EXPLORING RA, P995
   Levine S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966402
   Li TY, 2004, IEEE INT CONF ROBOT, P3195
   Pabst S, 2010, COMPUT GRAPH FORUM, V29, P1605, DOI 10.1111/j.1467-8659.2010.01769.x
   Pan J., 2010, AAAI C ARTIFICIAL IN, P1245
   Phillips M., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P5628, DOI 10.1109/ICRA.2011.5980306
   Rusu RB, 2009, J FIELD ROBOT, V26, P841, DOI 10.1002/rob.20313
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Shiller Z, 2001, IEEE INT CONF ROBOT, P1, DOI 10.1109/ROBOT.2001.932521
   Stilman M, 2008, INT J ROBOT RES, V27, P1295, DOI 10.1177/0278364908098457
   Sud A, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P99
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van den Berg J, 2006, IEEE INT CONF ROBOT, P2366, DOI 10.1109/ROBOT.2006.1642056
   Zucker M, 2007, IEEE INT CONF ROBOT, P1603, DOI 10.1109/ROBOT.2007.363553
NR 32
TC 8
Z9 9
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2012
VL 23
IS 2
BP 87
EP 99
DI 10.1002/cav.1428
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 926VJ
UT WOS:000302859700004
DA 2024-07-18
ER

PT J
AU Singh, S
   Kapadia, M
   Reinman, G
   Faloutsos, P
AF Singh, Shawn
   Kapadia, Mubbasir
   Reinman, Glenn
   Faloutsos, Petros
TI Footstep navigation for dynamic crowds
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE crowds; footprints; footsteps; navigation; steering
ID WALKING
AB The majority of steering algorithms output only a force or velocity vector to an animation system, without modeling the constraints and capabilities of human-like movement. This simplistic approach lacks control over how a character should navigate. This paper proposes a steering method that uses footsteps to navigate characters in dynamic crowds. Instead of an oriented particle with a single collision radius, we model a character's center of mass and footsteps using a 2D approximation of an inverted spherical pendulum model of bipedal locomotion. We use this model to generate a timed sequence of footsteps that existing animation techniques can follow exactly. Our approach not only constrains characters to navigate with realistic steps but also enables characters to intelligently control subtle navigation behaviors that are possible with exact footsteps, such as side-stepping. Our approach can navigate crowds of hundreds of individual characters with collision-free, natural steering decisions in real-time. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Singh, Shawn; Faloutsos, Petros] Univ Calif Los Angeles, Dept Comp Sci, Graph Lab, Los Angeles, CA 90095 USA.
   [Reinman, Glenn] Univ Calif Los Angeles, MARS Lab, Los Angeles, CA 90095 USA.
C3 University of California System; University of California Los Angeles;
   University of California System; University of California Los Angeles
RP Singh, S (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Graph Lab, Boelter Hall 4531F, Los Angeles, CA 90095 USA.
EM shawnsin@cs.ucla.edu
CR [Anonymous], 2000, THESIS U TOKYO
   [Anonymous], 1997, COMPUTER ANIMATION S
   BADLER N, 2008, VIRTUAL CROWDS METHO, DOI DOI 10.2200/S00123ED1V01Y200808CGR008
   Boulic R, 2008, LECT NOTES COMPUT SC, V5277, P176
   Chestnutt J., 2005, ICRA
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Chung SK, 1999, COMP ANIM CONF PROC, P4, DOI 10.1109/CA.1999.781194
   Coros S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409066
   Gayle R, 2009, IEEE T VIS COMPUT GR, V15, P34, DOI 10.1109/TVCG.2008.84
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kapadia M., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games, I3D '09, P215
   Kuffner J., 2003, P IEEE INT C ROB AUT
   KUFFNER JJ, 2001, INT ROB SYST 2001 P, V1, P500
   Kuo AD, 2007, HUM MOVEMENT SCI, V26, P617, DOI 10.1016/j.humov.2007.04.003
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   LAU M, 2006, SCA 06, P299
   LI T, 2003, INT C ROB AUT SEPT 1, V3, P3421
   NISHIWAKI KH, 2001, ICRA, V4, P4110
   Paris S, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.58
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Reynolds C. W., 1999, P GAM DEV C, P763
   SHAO W, 2005, SCA 05, P19
   SINGH S, 2011, P ACM SIGGRAPH S INT
   van Basten BJH, 2009, LECT NOTES COMPUT SC, V5884, P182, DOI 10.1007/978-3-642-10347-6_17
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   VANBASTEN BJH, 2010, COMPUTER ANIMATION V, V21
   vandePanne M, 1997, COMPUT GRAPH FORUM, V16, P211, DOI 10.1111/1467-8659.00181
   Wu CC, 2008, LECT NOTES COMPUT SC, V5358, P97
   Wu JC, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778809
   Zhang LJ, 2009, LECT NOTES COMPUT SC, V5884, P138, DOI 10.1007/978-3-642-10347-6_13
   [No title captured]
NR 32
TC 34
Z9 40
U1 4
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 151
EP 158
DI 10.1002/cav.403
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700010
OA Bronze
DA 2024-07-18
ER

PT J
AU Ma, CY
   Chen, G
   Han, Y
   Qi, YY
   Chen, Y
AF Ma, Chunyong
   Chen, Ge
   Han, Yong
   Qi, Yongyang
   Chen, Yong
TI An integrated VR-GIS navigation platform for city/region simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE VR-GIS; urban simulation; massive data; natural simulation
AB This paper introduces a virtual city oriented VR-GIS platform which synthesizes several latest information technologies including virtual reality, 3D geographical information system, remote sensing, and multi-dimensional visualization. The platform is a seamless integration of VR functions and GIS analysis methods, which can be used to organize and present massive spatial data. It also supplies 3D spatial analysis functions, 3D visualization for spatial process and natural simulation, and serves as an engine platform for digital city. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Chen, Ge; Han, Yong] Ocean Univ China, Key Lab Ocean Remote Sensing, Minist Educ, Qingdao, Peoples R China.
   [Ma, Chunyong] Ocean Univ China, Marine Informat Technol Lab, Qingdao, Peoples R China.
   [Chen, Yong] Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
C3 Ocean University of China; Ocean University of China; Ocean University
   of China
RP Chen, G (corresponding author), Ocean Univ China, Key Lab Ocean Remote Sensing, Minist Educ, 238 Songling Rd, Qingdao, Peoples R China.
EM gechen@public.qd.sd.cn
FU Natural Science Foundation of China [40730530, 40675016, 60873170]
FX This research was supported by the Natural Science Foundation of China
   under Projects 40730530, 40675016, and 60873170.
CR Ahn M, 2006, IEEE T VIS COMPUT GR, V12, P1221, DOI 10.1109/TVCG.2006.169
   Aila T, 2004, IEEE COMPUT GRAPH, V24, P86, DOI 10.1109/MCG.2004.1274066
   Asirvatham A., 2005, GPU GEMS 2, V2, P27
   Huang B, 2001, INT J GEOGR INF SCI, V15, P439, DOI 10.1080/13658810110046574
   Ishida T, 2002, COMMUN ACM, V45, P76, DOI 10.1145/514236.514238
   Koller D, 1995, VISUALIZATION '95 - PROCEEDINGS, P94, DOI 10.1109/VISUAL.1995.480800
   Losasso F, 2004, ACM T GRAPHIC, V23, P769, DOI 10.1145/1015706.1015799
   Moon B, 2001, IEEE T KNOWL DATA EN, V13, P124, DOI 10.1109/69.908985
   Peng JL, 2005, ACM T GRAPHIC, V24, P609, DOI 10.1145/1073204.1073237
   Roth M, 2004, COMPUT GRAPH-UK, V28, P63, DOI 10.1016/j.cag.2003.10.004
   Vitter JS, 2001, ACM COMPUT SURV, V33, P209, DOI 10.1145/384192.384193
NR 11
TC 9
Z9 10
U1 0
U2 35
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2010
VL 21
IS 5
BP 499
EP 507
DI 10.1002/cav.322
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 672VP
UT WOS:000283615300003
DA 2024-07-18
ER

PT J
AU Wang, YM
   Zheng, JM
AF Wang, Yimin
   Zheng, Jianmin
TI Tubular triangular mesh parameterization and applications
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Virtual-Reality Continuum and its
   Applications in Industry
CY DEC 08-09, 2008
CL Singapore, SINGAPORE
SP ACM SIGGRAPH
DE triangular meshes; tubular shapes; parameterization; surface fitting;
   texture mapping
AB Triangular meshes are a popular geometric representation for 3D models used in computer graphics. Parameterization is a process that establishes a mapping between the surface of a model and a suitable domain. This paper considers the problem of parameterizing triangular meshes that have tubular shapes. Unlike an open mesh that is of plane topological type, a tubular mesh gives rise to some special issues in parameterization due to its mesh structure. This paper presents an edge-based parameterization method, in which the edges rather than the vertices of the mesh are treated as the target for parameterization. It first parameterizes the edges on the two boundaries of the tubular mesh, then parameterizes the internal edges based on the mean value coordinates, and finally computes the parameters of the mesh vertices. The method does not need cutting of the mesh. It improves conventional cutting-based algorithms, which cut the mesh to make it a disk topologically, and overcomes the problems of cutting paths that are the zigzag paths leading to suboptimal parameterizations and the difficulty in finding good cutting paths. Some applications such as surface fitting and texture mapping are also provided. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Wang, Yimin; Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Zheng, Jianmin] Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.
   [Zheng, Jianmin] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Nanyang Technological University; Brigham Young University; Zhejiang
   University
RP Wang, YM (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Block N4,Nanyang Ave, Singapore 639798, Singapore.
EM wang0066@ntu.edu.sg
RI Zheng, Jianmin/A-3717-2011
OI Zheng, Jianmin/0000-0002-5062-6226
CR Clarenz U, 2004, COMPUT AIDED GEOM D, V21, P727, DOI 10.1016/j.cagd.2004.07.005
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Degener P, 2003, IMR, P201
   Desbrun M, 2002, COMPUT GRAPH FORUM, V21, P209, DOI 10.1111/1467-8659.00580
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Floater MS, 1997, COMPUT AIDED GEOM D, V14, P231, DOI 10.1016/S0167-8396(96)00031-3
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   HUYSMANS T, 2005, J WSCG, V13, P97
   LIU Q, 2005, WEB3D, P123
   MAILLOT J, 1993, SIGGRAPH 93, P27
   Press W. H., 1988, Numerical Recipes
   Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307
   Sederberg TN, 2003, ACM T GRAPHIC, V22, P477, DOI 10.1145/882262.882295
   Sederberg TW, 2004, ACM T GRAPHIC, V23, P276, DOI 10.1145/1015706.1015715
   Sheffer A, 2005, ACM T GRAPHIC, V24, P311, DOI 10.1145/1061347.1061354
   Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011
   TOLEDO C, TAUCS LIB SPARSE LIN
   VANDERVORST HA, 1992, SIAM J SCI STAT COMP, V13, P631, DOI 10.1137/0913035
   Wang Y., 2007, P 6 INT C INF COMM S, P1
   WEILER K, 1985, IEEE COMPUT GRAPH, V5, P21, DOI 10.1109/MCG.1985.276271
   ZHENG J, 2005, GRAPHITE, P405
   Zöckler M, 2000, VISUAL COMPUT, V16, P241, DOI 10.1007/PL00013396
NR 22
TC 3
Z9 3
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2010
VL 21
IS 2
SI SI
BP 91
EP 102
DI 10.1002/cav.325
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 586CJ
UT WOS:000276878600004
DA 2024-07-18
ER

PT J
AU Multon, F
   Kulpa, R
   Hoyet, L
   Komura, T
AF Multon, Franck
   Kulpa, Richard
   Hoyet, Ludovic
   Komura, Taku
TI Interactive animation of virtual humans based on motion capture data
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE virtual human; real-time animation; kinematics; dynamics; real-time
   controller design
ID INVERSE; LOCOMOTION; COMPLEX
AB This paper presents a novel, parameteric framework for synthesizing new character motions from existing motion capture data. Our framework call conduct morphological adaptation as well as kinematic and physically-based corrections. All these solvers are organized in layers in order to be easily combined together. Given locomotion as all example, the system automatically adapts the motion data to the size of the synthetic figure and to its environment, the character will correctly step over complex ground shapes and counteract with external forces applied to the body. Our framework is based on a frame-based solver. This ensures animating hundreds of humanoids with different morphologies in real-time. It is particularly suitable for interactive applications such as video games and virtual reality where a user interacts in all unpredictable way. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Multon, Franck; Kulpa, Richard] Univ Rennes 2, Lab M2S, F-35044 Rennes, France.
   [Kulpa, Richard] IRISA INRIA Rennes Res Inst, Bunraku Team, Rennes, France.
   [Hoyet, Ludovic] INRIA, Rennes, France.
   [Komura, Taku] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
   [Komura, Taku] City Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
   [Komura, Taku] RIKEN, Wako, Saitama, Japan.
C3 Universite de Rennes; Universite Rennes 2; Universite de Rennes; Inria;
   University of Edinburgh; City University of Hong Kong; RIKEN
RP Multon, F (corresponding author), Univ Rennes 2, Lab M2S, Ave Charles Tillon, F-35044 Rennes, France.
EM Franck.Multon@uhb.fr
RI Hoyet, Ludovic/IWU-9100-2023
OI Hoyet, Ludovic/0000-0002-7373-6049; Multon, Franck/0000-0003-2690-0077
FU EGIDE Alliance program
FX This paper was partially funded by the EGIDE Alliance program (project
   "VirtualSPortsTrainer").
CR ABE Y, 2004, P ACM SIGGRAPH EUR S, P173
   [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   Arikan Okan., 2005, SCA 2005: Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P59
   Baerlocher P, 2004, VISUAL COMPUT, V20, P402, DOI 10.1007/s00371-004-0244-4
   Boulic R., 1990, Visual Computer, V6, P344, DOI 10.1007/BF01901021
   Boulic R, 1996, COMPUT GRAPH, V20, P693, DOI 10.1016/S0097-8493(96)00043-X
   Bruderlin A, 1996, PROC GRAPH INTERF, P213
   CALLENNEC BL, 2004, P 2004 ACM SIGGRAPH, P163
   Chai JX, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239459
   Glardon P, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P292, DOI 10.1109/CGI.2004.1309224
   Gleicher M., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P139, DOI 10.1145/253284.253321
   Ko H, 1996, IEEE COMPUT GRAPH, V16, P50, DOI 10.1109/38.486680
   Kovar L., 2002, ACM SIGGR S COMP AN
   Kulpa R, 2005, IEEE-RAS INT C HUMAN, P38
   Kulpa R, 2005, COMPUT GRAPH FORUM, V24, P343, DOI 10.1111/j.1467-8659.2005.00859.x
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   Lee J, 1999, COMP GRAPH, P39
   Liu CK, 2002, ACM T GRAPHIC, V21, P408, DOI 10.1145/566570.566596
   MAJKOWSKA A, 2007, P EUR ACM SIGGRAPH S
   McCane B, 2006, J BIOMECH, V39, P2703, DOI 10.1016/j.jbiomech.2005.09.015
   MULTON F, 2007, P IEEE HUM 2007 DEC
   Multon F, 2008, PRESENCE-VIRTUAL AUG, V17, P17, DOI 10.1162/pres.17.1.17
   Newel Allen., 1990, UNIFIED THEORIES COG
   SHIN H, 2003, P PAC GRAPH ALB CAN
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Sok KW, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276511, 10.1145/1239451.1239558]
   Sulejmanpasic A, 2005, ACM T GRAPHIC, V24, P165, DOI 10.1145/1037957.1037966
   Sun HC, 2001, COMP GRAPH, P261, DOI 10.1145/383259.383288
   Tak S, 2005, ACM T GRAPHIC, V24, P98, DOI 10.1145/1037957.1037963
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   WITKIN A, 1988, P SIGGRAPH 88, P159
   Yamane K, 2003, IEEE T ROBOTIC AUTOM, V19, P421, DOI 10.1109/TRA.2003.810579
   Yamane K, 2003, IEEE T VIS COMPUT GR, V9, P352, DOI 10.1109/TVCG.2003.1207443
   Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556
   Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249
NR 35
TC 11
Z9 15
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2009
VL 20
IS 5-6
SI SI
BP 491
EP 500
DI 10.1002/cav.281
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 516RI
UT WOS:000271559700002
DA 2024-07-18
ER

PT J
AU Zhao, HL
   Fan, R
   Wang, CCL
   Jin, XG
   Meng, YW
AF Zhao, Hanli
   Fan, Ran
   Wang, Charlie C. L.
   jin, Xiaogang
   Meng, Yuwei
TI Fireworks controller
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE particle system; shape constraint; iterative clustering; dual depth
   peeling; GPU
AB This paper presents the fireworks controller, a novel real-time shape-constrained fireworks animation system. We depict the shape of a firework by a 3D mesh. In order to approximate the mesh using evenly distributed points, we propose a fast point sampling method by extending the dual depth peeling algorithm. The samples are then taken as input to shape-constrained fireworks whose physically plausible animations are based on inverse dynamics. We present a highly parallel iterative clustering algorithm to support multi-level fireworks explosion. In order to simulate natural fuzzy fireworks, We impose extra random particles with a parallel random number generator. Several novel intuitive user interfaces are introduced to improve the usability of the system. Experimental results demonstrate the prettiness and efficiency of the proposed approach. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Zhao, Hanli; Fan, Ran; jin, Xiaogang; Meng, Yuwei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM hanljzhao@gmajl.com; ran1029@gmail.com; cwang@mae.cuhk.edu.hk;
   jin@cad.zju.edu.cn; mengyuwei@cad.zju.edu.cn
RI Wang, Charlie C. L./B-3730-2010
OI Wang, Charlie C. L./0000-0003-4406-8480
CR Anderson M., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA'03, P286
   [Anonymous], 2004, PROC EUROGRAPHICS S, DOI DOI 10.2312/SPBG/SPBG04/049-056
   [Anonymous], P ACM WORKSH GEN PUR
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   Bavoil L., 2008, NVIDIA OpenGL SDK
   BLYTHE D, 2006, P ACM SIGGRAPH, P724
   DOBASHI Y, 2008, P ACM SIGGRAPH 08
   Everitt C, 2001, INTERACTIVE ORDER IN
   FATTAL R, 2004, P ACM SIGGRAPH 04, P264
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Kipfer P., 2004, HWWS 04, P115, DOI [10.1145/1058129.1058146, DOI 10.1145/1058129.1058146]
   Kolb A., 2004, P ACM SIGGRAPHEUROGR, P123
   Lai YK, 2006, VISUAL COMPUT, V22, P604, DOI 10.1007/s00371-006-0047-x
   Lamorlette A, 2002, ACM T GRAPHIC, V21, P729, DOI 10.1145/566570.566644
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   McAllister D., 2000, The design of an api for particle systems
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   SIMS K, 1990, P 17 ANN C COMP GRAP, P405
   TREUILLE A, 2003, P SIGGRAPH 2003, P716
   Tzeng S, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P79
   Wojtan C., 2006, P 2006 ACM SIGGRAPHE, P15
   Xu JY, 2008, COMPUT ANIMAT VIRT W, V19, P319, DOI 10.1002/cav.231
   ZHOU K, 2008, P ACM SIGGRAPH AS 08
NR 25
TC 3
Z9 3
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 185
EP 194
DI 10.1002/cav.287
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700012
DA 2024-07-18
ER

PT J
AU Wang, LY
   Hua, W
   Bao, HJ
AF Wang, Liying
   Hua, Wei
   Bao, Hujun
TI Procedural modeling of urban zone by optimization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE urban procedural modeling; constrained layout optimization; particle
   swarm optimization; path planning; spatial pattern
AB Procedural modeling technology may be applied for constructing a large-scale urban scene. Most of the previous studies have exploited a grammar-based modeling method to generate models. Nevertheless, we formulate the urban planning as a constrained layout optimization problem, propose an algorithm to solve the problem, and procedurally generate models of the urban zone. It produces an extensive urban virtual environment for computer games and simulations at low cost. We optimize a cost function to distribute buildings and roads subject to some urban planning constraints. We employ particle swarm optimization and two-step path planning to find the optimal solution, which is further interpreted as the 2D blueprint of the urban zone. During the optimization, we adopt the spatial pattern tree structure to reduce the combinational search space greatly. 3D city models in large scale are then assembled according to the 2D blueprints. Experimental results prove that our method can efficiently produce the virtual urban scene similar to that designed by urban planners. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Hua, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Hua, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM huawei@cad.zju.edu.cn
FU National Basic Research Program of China [2002CB312102]; National
   Natural Science Foundation of China [60773184]
FX This research work is supported by the National Basic Research Program
   (973 Program) of China (No. 2002CB312102) and the National Natural
   Science Foundation of China (No. 60773184). We appreciate all those who
   gave us a lot of support in constructing and rendering 3D models. We
   thank the reviewers who give helpful advices.
CR Chen Yong, 2003, Journal of Computer Aided Design & Computer Graphics, V15, P598
   COYNE B, P ACM SIGGRAPH 2001, P487
   GRIMSDALE RL, P WSCG 1997, P153
   LARIVE M, P WSCG 2005, P9
   [雷开友 Lei Kaiyou], 2006, [计算机研究与发展, Journal of Computer Research and Development], V43, P1724, DOI 10.1360/crad20061008
   LI D, 2001, URBAN PLANNING THEOR
   MECH R, P ACM SIGGRAPH 1996, P397
   Müller P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276484, 10.1145/1239451.1239536]
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   PARISH YIH, P ACM SIGGRAPH 2001, P301
   PRZEMYSLAW P, P ACM SIGGRAPH 1994, P351
   Sun J., 2004, INT J IMAGE GRAPH, V4, P701
   WAN SH, 2004, URBAN SPATIAL STRUCT
   WATSON B, COURS NOT ACM SIGGRA
   WONKA P, P ACM SIGGRAPH 2003, P669
   WONKA P, COURS NOT ACM SIGGRA
NR 16
TC 2
Z9 2
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2008
VL 19
IS 5
BP 569
EP 578
DI 10.1002/cav.229
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 377KO
UT WOS:000261250300004
OA Bronze
DA 2024-07-18
ER

PT J
AU Liu, GD
   Pan, ZG
   Lin, ZY
AF Liu, Gengdai
   Pan, Zhigeng
   Lin, Zuoyan
TI Style subspaces for character animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE motion capture; style; independent feature subspaces analysis
AB In this paper, we present a hovel method for editing stylistic human motions. We represent styles as differences between stylistic and introduced neutral motions, including timing differences and spatial differences. Tinting differences are defined its time alignment curves, while spatial differences are found by a machine learning technique: independent feature subspaces analysis, which is the combination of multidimensional independent component analysis and invariant feature subspaces. This technique is used to decompose two motions into several subspaces. One of these subspaces call be defined as style subspace that describes the style aspects of the stylistic motion. In order to find the style subspace, we compare norms of the projections of two motions oil each subspace. Once the time alignment curves and style subspaces of several motion clips are obtained, animators call tone, transfer, and merge the style subspaces to synthesize new mortion clips With various styles. Our method is easy to use since manual manipulations and large training data sets are riot necessary. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Liu, Gengdai; Lin, Zuoyan] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Pan, Zhigeng] Zhejiang Univ, Comp & Engn Dept, Hangzhou 310027, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Liu, GD (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM liugengdai@cad.zju.edu.cn
CR Amaya K, 1996, PROC GRAPH INTERF, P222
   [Anonymous], P INT C ART NEUR NET
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Bruderlin Armin., 1995, Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH '95, P97, DOI DOI 10.1145/218380.218421
   CAO Y, 2003, P ACM SIGGRAPH EUR S, P225
   *CMU, 2008, CMU GRAPH LAB MOT CA
   Elgammal A, 2004, PROC CVPR IEEE, P478
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Hyvärinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Kawasaki R, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P306, DOI 10.1109/CGI.2003.1214487
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   KOVAR L, 2003, P ACM SIGGRAPH EUR S, P214
   Liu CK, 2005, ACM T GRAPHIC, V24, P1071, DOI 10.1145/1073204.1073314
   Neff M., 2005, Proceedings of ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P161
   PERLIN K, 1995, IEEE T VIS COMPUT GR, V1, P5, DOI 10.1109/2945.468392
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Shapiro A, 2006, PROC GRAPH INTERF, P33
   Tak S, 2000, COMPUT GRAPH FORUM, V19, pC437, DOI 10.1111/1467-8659.00436
   TERASAKI T, 2006, P INT C COMP AN SOC, P243
   TORRESANI L, 2007, ADV NEURAL INFORM PR, V19, P1393
   Unuma M., 1995, P 22 ANN C COMPUTER, P91, DOI DOI 10.1145/218380.218419
   Urtasun R, 2004, COMPUT GRAPH FORUM, V23, P799, DOI 10.1111/j.1467-8659.2004.00809.x
NR 23
TC 8
Z9 13
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 199
EP 209
DI 10.1002/cav.254
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200005
DA 2024-07-18
ER

PT J
AU Lu, DF
   Ye, XZ
   Zhou, GM
AF Lu, Difei
   Ye, Xiuzi
   Zhou, Guomin
TI Animating by example
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE sketch; animation; deformations; mean value coordinates; interactive
   animating tools
ID INTERFACE
AB In this paper, we propose an example-driven synthesis approach to create 3D animation of a target character. Our approach consists of the following steps: (a) a sketch-based mapping between parts of the sources and corresponding portions of the target; (b) calculating the affine matrix of the source mesh for each vertex; W deforming the target based on the deformations of the corresponding parts of the sources by means of mean value coordinates. We provide new research contributions on all these topics and integrate them into our newly developed prototype animating system. Our approach is general and does not require the sources and target to share the same number of vertices or triangles, or to have matching connectivity. In our system, source animations can be any 3D animations and the target can even be unstructured or point cloud. Our approach is intuitive and is able to produce highly authentic 3D animations. We demonstrate our approach by constructing a full angel animation video from parts of kid and dolphin animations. Other animating examples produced from our prototype system are also given in the paper to illustrate our approach. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Lu, DF (corresponding author), Zhejiang Univ, Hangzhou 310027, Peoples R China.
EM ludf@sindyware.com
CR Alexa M, 2002, ACM T GRAPHIC, V21, P380, DOI 10.1145/566570.566592
   Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   COHEN M, 2000, KEYNOTE TALK CHINA G
   DAVIS TA, 2003, UMFPACT VERSION 4 1
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   KHO Y., 2005, I3D 05, P147, DOI DOI 10.1145/1053427.1053452
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Nealen A, 2005, ACM T GRAPHIC, V24, P1142, DOI 10.1145/1073204.1073324
   Shoemake K., 1992, Proceedings. Graphics Interface '92, P258
   SUMMER RW, 2004, ACM T GRAPHIC, V24, P561
   Sumner RW, 2005, ACM T GRAPHIC, V24, P488, DOI 10.1145/1073204.1073218
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Yoshizawa Shin., 2003, P 8 ACM S SOLID MODE, P247, DOI DOI 10.1145/781606.781643
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
NR 16
TC 0
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 247
EP 257
DI 10.1002/cav.180
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000004
DA 2024-07-18
ER

PT J
AU Park, MJ
   Cho, J
AF Park, Min Je
   Cho, Jieun
TI Organizing motions with a nominal description
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE motion classification; data organization; computer animation
ID MODEL
AB Due to the success of motion capture technologies, large motion capture data become available. Although organizing large databases has been widely researched for various purposes, there is little attention to motion capture data. In this paper, we propose an effective scheme to organize large motion databases according to its nominal features. To do this, we first define a set of attributes and its corresponding values to form a set of attribute-value pairs. Each attribute represents a visual characteristic of human motion. We adopt machine learning algorithms to assign a specific value to the attribute. Then, we categorize all motions in database according to the set of attribute-value pairs. Since attributes define nominal properties rather than numerical ones, we adopt a conceptual clustering algorithm based on formal concept analysis (FCA). After clustering, we can acquire a clustering dendrogram called classification tree that characterizes each cluster with a probabilistic description. We present experimental results to show the effectiveness of our scheme for organizing large motion database. Copyright (c) 2007 John Wiley & Sons, Ltd.
RP Park, MJ (corresponding author), 605 Korea Design Ctr 344-1 Yatak-dong Bungdang-g, Songnam, South Korea.
EM mjpark@macrograph.co.kr
CR Ahn J, 2006, COMPUT ANIMAT VIRT W, V17, P155, DOI 10.1002/cav.119
   [Anonymous], 2005, Formal Concept Analysis: Foundations and Applications
   Aubel A, 2000, IEEE T CIRC SYST VID, V10, P207, DOI 10.1109/76.825720
   CARDIE M, 2003, ACM SIGGRAPH 2003 SK
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fisher D., 1987, Knowledge acquisition via incremental conceptual clustering
   HUTCHINSON A, 1991, SYSTEM ANAL RECORDIN
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   KOEGH EJ, 2004, P 30 VLDB C TOR, P780
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Li Y, 2002, ACM T GRAPHIC, V21, P465
   Michalski R. S., 1980, International Journal of Policy Analysis and Information Systems, V4, P219
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Soatto S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICCV.2001.937658
NR 15
TC 0
Z9 0
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 311
EP 318
DI 10.1002/cav.184
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000010
DA 2024-07-18
ER

PT J
AU Aron, M
   Simon, G
   Berger, MO
AF Aron, Michael
   Simon, Gilles
   Berger, Marie-Odile
TI Use of inertial sensors to support video tracking
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; camera tracking; sensor fusion
AB One of the biggest obstacles to building effective augmented reality (AR) systems is the lack Of accurate sensors that report the location of the user in an environment during arbitrary long periods of movements. In this paper, we present an effective hybrid approach that integrates inertial and vision-based technologies. This work is motivated by the need to explicitly take into account the relatively poor accuracy of inertial sensors and thus to define an efficient strategy for the collaborative process between the vision-based system and the sensor. The contributions of this papers are threefold: (i) our collaborative strategy fully integrates the sensitivity error of the sensor: the sensitivity is practically studied and is propagated into the collaborative process, especially in the matching stage (ii) we propose an original online synchronization process between the vision-based system and the sensor. This process allows us to use the sensor only when needed. (iii) an effective AR system using this hybrid tracking is demonstrated through an e-commerce application in unprepared environments. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Inria Lorraine, Magrit Team, Loria, France.
   Univ Nancy 1, F-54013 Nancy, France.
C3 Universite de Lorraine; Universite de Lorraine
RP Aron, M (corresponding author), Nancy Univ, INRIA Lorraine, 615 Rue Jardin Bot, F-54602 Villers Les Nancy, France.
EM michael.aron@loria.fr
CR [Anonymous], P BRIT MACH VIS C
   Azuma R., 2001, IEEE COMPUT GRAPH, P34
   Borenstein J, 1996, IEEE INT CONF ROBOT, P423, DOI 10.1109/ROBOT.1996.503813
   Chia KW, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P305, DOI 10.1109/ISMAR.2002.1115123
   Foxlin E, 2003, P IEEE VIRT REAL ANN, P199, DOI 10.1109/VR.2003.1191139
   HARRIS CJ, 1992, ACTIVE VISION, pCH4
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Jiang BL, 2004, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2004.1310049
   PARK FC, 1994, IEEE T ROBOTIC AUTOM, V10, P717, DOI 10.1109/70.326576
   PRAGER RW, 1998, STRADX REAL TIME ACQ
   Satoh K, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P67, DOI 10.1109/ISAR.2001.970516
   Simon G, 2002, IEEE COMPUT GRAPH, V22, P46, DOI 10.1109/MCG.2002.1046628
   State A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P429, DOI 10.1145/237170.237282
   VIEVILLE T, 1993, P IEEE INT C INTELLI
NR 14
TC 21
Z9 25
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2007
VL 18
IS 1
BP 57
EP 68
DI 10.1002/cav.161
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 149ML
UT WOS:000245150900006
DA 2024-07-18
ER

PT J
AU Kunii, TL
   Ohmori, K
AF Kunii, Tosiyasu L.
   Ohmori, Kenji
TI A kaleidoscope as a cyberworld and its animation: Linear architecture
   and modeling based on an incrementally modular abstraction hierarchy
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE homotopy lifting property; homotopy extension property; fiber bundle;
   adjunction space; cyberworld; kaleidoscope
AB An incrementally modular abstraction hierarchy is known to effectively linearize cyberworlds and virtual worlds, which are combinatorially exploding and hardly managed. It climbs down from general level to specific model preserving the higher level modules as invariants. It not only prevents the combinatorial explosion but also benefits the reuse, development, testing and validation of cyberworld resources. By applying this incrementally modular abstraction hierarchy to a kaleidoscope animation, its architecture and modeling is also specified in this paper as a typical case of cyberworlds. In particular, a homotopy lifting property and a homotopy extension property, Which satisfy a duality relation, are also described to show how a kaleidoscope world is systematically created top-down from the Whole system and bottom-up from the components. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Kanazawa Inst Technol, IT Inst, Shinjuku Ku, Tokyo 1500001, Japan.
RP Kunii, TL (corresponding author), Kanazawa Inst Technol, IT Inst, Shinjuku Ku, 1-5-13 Jingumae, Tokyo 1500001, Japan.
EM tosi@kunii.info
CR ALLAN JS, 1992, INTRO TOPOLOGY HOMOT
   Allen H., 2002, Algebraic Topology
   [Anonymous], 1997, A User's Guide to Algebraic Topology (Mathematics and Its Applications)
   DAVID AB, 1998, GEOMETRY, P319
   FRITSCH F, 1990, CELL STRUCTURES TOPO
   KENJI O, 2000, P COMP GRAPH INT 200, P117
   KNEJI O, 2001, P INT C SHAP MOD APP, P126
   Kunii TL, 2005, IEICE T INF SYST, VE88D, P790, DOI 10.1093/ietisy/e88-d.5.790
   Spanier Edwin H., 1966, ALGEBRAIC TOPOLOGY
   TOSIYASU K, 2003, P INT C CYB 3 5 DEC, pR20
   TOSIYASU L, 1998, CYBERWORLDS, P5
   TOSIYASU LK, 2 ANN INT FEST NEW M
   TOSIYASU LK, 2004, P INT C CYB 18 20 NO, P2
   TOSIYASU LK, 1999, P COMP GRAPH INT 99, P130
   TOSIYASU LK, 1988, PAX JAPONICA
   TOSIYASU LK, 1989, P 7 ANN C AUSTR SOC, P28
   TOSIYASU LK, 1999, P 1999 INT S DAT APP, P19
   TOSIYASU LK, IN PRESS VISUAL COMP
   TOSIYASU LK, 2002, LECT NOTES COMPUTER, P58
   TOSIYASU LK, 1969, J MATH SCI, P54
   TOSIYASU LK, 2005, LECT NOTES COMPUTER, P204
   TOSIYASU LK, 1985, C REC DALI2001 DIG A
   TOSIYASU LK, 2002, P 1 INT S CYB WORLDS, P3
   TOSIYASU LK, 2003, LECT NOTES COMPUTER, P86
   TOSIYASU LK, 2003, IEICE T INF SYST, V86, P1181
   TOSIYASU LK, 1989, CYBERWORLDS, P5
   TOSIYASU LK, 2005, P INT C CYB CW2005 2, P3
   TOSIYASU LK, 1999, INT J SHAPE MODELING, V5, P123
   Whitehead J.H.C., 1950, Proceedings of the International Congress of Mathematicians, V2, P354
NR 29
TC 8
Z9 8
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 145
EP 153
DI 10.1002/cav.118
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400002
DA 2024-07-18
ER

PT J
AU Alankus, G
   Bayazit, AA
   Bayazit, OB
AF Alankus, G
   Bayazit, AA
   Bayazit, OB
TI Automated motion synthesis for dancing characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE motion interpolation; virtual choreography; motion analysis; motion
   synthesis; beat analysis
AB In this paper, we present a technique to automatically synthesize dancing motions for arbitrary songs with dance beats. Our technique is based on analysing a musical tune (can be a song or melody) and synthesizing a motion for the virtual character where the character's movement synchronizes to the musical beats. In order to analyse beats of the tune, we developed a fast algorithm. Our motion synthesis algorithm analyses library of stock motions and generates new sequences of movements that were not described in the library. We show that our motion synthesis algorithm is better than previous dance generation techniques. We also present two algorithms to synchronize dance moves and musical beats: a fast greedy algorithm, and a genetic algorithm. Our experimental results show that we can generate new sequences of dance figures in which the dancer reacts to music and dances in synchronization with the music. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Washington Univ, Dept Comp Sci & Engn, St Louis, MO 63130 USA.
C3 Washington University (WUSTL)
RP Washington Univ, Dept Comp Sci & Engn, 1 Brookings Dr,Campus Box 1045, St Louis, MO 63130 USA.
EM bayazit@cse.wustl.edu
RI Alankuş, Gazihan/AAE-4840-2022
CR [Anonymous], SIGGRAPH 85
   ARIKAN O, 2002, P 29 ANN C COMP GRAP, P483
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Bruderlin Armin., 1995, Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH '95, P97, DOI DOI 10.1145/218380.218421
   DOUGLAS JW, 1997, IEEE COMPUT GRAPH, V17, P39
   HAINSWORTH S, 2003, IEEE WORKSH APPL SIG, P245
   HARPER R, 2004, ACOUSTICS SPEECH SIG, P245
   HODGINS JK, 1998, ROB RES 8 INT S BERL
   JEHAN T, 2003, P SIGGR 2003 C SKETC
   JENSEN K, 2003, IEEE WORKSH APPL SIG, P19
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Koga Y., 1995, Proc. ACM SIGGRAPH, P395
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   KOVAR L, 2003, SCA 03, P214
   Kovar Lucas., 2002, SCA 2002: Proceedings of the 2002 ACM SIG-GRAPH/Eurographics Symposium on Computer Animation, P97
   Kuffner JJ, 2002, AUTON ROBOT, V12, P105, DOI 10.1023/A:1013219111657
   Laroche J, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P135, DOI 10.1109/ASPAA.2001.969561
   MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417
   Nakaoka S, 2003, IEEE INT CONF ROBOT, P3905
   Oppenheim A. V., 1997, SIGNALS SYSTEMS
   PETTRE J, 2003, P 2003 ACM SIGGRAPH, P258
   PULLEN K, 2002, P 29 ANN C COMP GRAP, P501
   Safonova A., 2003, 2 INT S AD MOT AN MA
   Scheirer ED, 1998, J ACOUST SOC AM, V103, P588, DOI 10.1121/1.421129
   WANG J, 2003, P 2003 ACM SIGGR EUR, P282
NR 26
TC 16
Z9 18
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 259
EP 271
DI 10.1002/cav.99
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000012
OA Bronze
DA 2024-07-18
ER

PT J
AU Thüring, S
   Herwig, J
   Schmitt, A
AF Thüring, S
   Herwig, J
   Schmitt, A
TI Silhouette-based motion capture for interactive VR-systems including a
   rear projection screen
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE background subtraction; dynamic background; silhouette extraction;
   markerless; optical tracking; skeleton fitting
AB Markerless optical motion tracking is still a challenging task; especially applied for interactive environment there real-time is required. Tracking methods based on silhouette extraction seem to have the ability for robust real-time detection. But most background subtraction methods are unable to adapt their background model to the fast changing unpredictable images shown on a projection screen. This restriction makes them unusable for applications involving spatially immersive displays (SID) where users are interacting in front of projection screens. This paper describes an approach to solve this challenging problem. Based on a client-server architecture it makes use of frame buffer and screen timing information delivered by the presentation computer and standard digital cameras attached to the tracking computer. The system requires no special hardware; therefore it is comparatively cheap and furthermore fast and reliable. Sufficiently accurate algorithms for segmentation and skeleton fitting are used, allowing usage in a real-time system. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Univ Karlsruhe, Inst Betriebs & Dialogsyst, D-76128 Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Univ Karlsruhe, Inst Betriebs & Dialogsyst, Fasanengarten 5, D-76128 Karlsruhe, Germany.
EM thuering@ira.uka.de
CR [Anonymous], 457 MIT MED LAB
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Dyer Charles R., 2001, Foundations ofImage Understanding, chapter Volumetric Scene Reconstruction from Multiple Views, P469
   FAUTZ M, 2002, 7 ABW WORKSH 3D BILD
   FAUTZ M, 2002, THESIS U KARLSRUHE
   FINKENZELLER D, 2003, VIRTUAL CONCEPT
   GROSS M, 2003, ACM T GRAPHICS N JUL, V22
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Shu C., 2003, NRC46497ERB1104
   VIGNOLA J, 2003, P 16 C VIS INT
NR 11
TC 2
Z9 2
U1 0
U2 1
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 245
EP 257
DI 10.1002/cav.102
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000011
DA 2024-07-18
ER

PT J
AU Adzhiev, V
   Comninos, P
   Kazakov, M
   Pasko, A
AF Adzhiev, V
   Comninos, P
   Kazakov, M
   Pasko, A
TI Functionally based augmented sculpting
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE virtual sculpting; augmented reality; function representation;
   volumetric models; animation; metamorphosis
AB In this paper we describe an approach to computer-aided sculpting concerned with the creation and modification of digital models based on physical abstract sculptures. We begin by presenting a survey of current methods for the creation of computer-aided sculptured artefacts. Then we proceed to present some original methods and tools based on the function representation of geometric models. We introduce a specialized computer language, named HyperFun, which facilitates the modelling of complex objects. As well as presenting computer-generated animated models of pre-existing sculptures by Russian artist Igor Seleznev, we also show how some interesting novel shapes can be generated using the HyperFun system. Finally we outline two advanced projects concerned with creating a sculpture-based augmented reality which allows for the interactive participation of the observer. In this paper, we present experimental results, which hopefully have some artistic appeal. These results were produced by an international team of researchers and students collaborating through the Internet. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University
RP Bournemouth Univ, Natl Ctr Comp Animat, Talbot Campus, Poole BH12 5BB, Dorset, England.
EM vadzhiev@bournemouth.ac.uk
RI Pasko, Alexander/H-9344-2017
OI Pasko, Alexander/0000-0002-4785-7066
CR Adzhiev V, 2003, LEONARDO, V36, P211, DOI 10.1162/002409403321921433
   Adzhiev V, 1999, MULTIMEDIA MODELING, P39
   Avila RS, 1996, IEEE VISUAL, P197, DOI 10.1109/VISUAL.1996.568108
   BARENTZEN JA, 1998, P IEEE VISUALIZATION, P9
   Barr A. H., 1984, Computers & Graphics, V18, P21
   BLOOMENTHAL J, 1991, COMP GRAPH, V25, P251, DOI 10.1145/127719.122757
   CHANG YK, 1994, P SIGGRAPH 94, P257
   Coquillart S., 1990, J. Computer Graphics, V24, P187, DOI DOI 10.1145/97880.97900
   Dickson S., 1999, International Journal of Shape Modeling, V5, P23, DOI 10.1142/S0218654399000058
   FATH M, EXPRESSION CONSTRUCT
   Fausett E, 2000, COMP ANIM CONF PROC, P140, DOI 10.1109/CA.2000.889070
   Ferguson C., 1994, HELAMAN FERGUSON MAT
   Ferley E, 2000, VISUAL COMPUT, V16, P469, DOI 10.1007/PL00007216
   Forsey D. R., 1988, Computer Graphics, V22, P205, DOI 10.1145/378456.378512
   GALYEAN T, 1991, P SIGGRAPH 91, P138
   HSU WM, 1992, COMP GRAPH, V26, P177, DOI 10.1145/142920.134036
   HUGHES J, 1992, P ACM SIGGRAPH 92, P43
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Kazakov M, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P104, DOI 10.1109/SMA.2001.923381
   KAZAKOV M, 2003, P INT C COMP GRAPH I, P103
   Keskeys D. J., 1994, Computer Graphics, V28, P255, DOI 10.1145/193234.193240
   Lerios A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P449, DOI 10.1145/218380.218502
   MacCracken Ron., 1996, SIGGRAPH, P181, DOI DOI 10.1145/237170.237247
   Massie T, 1998, IEEE COMPUT GRAPH, V18, P62, DOI 10.1109/38.674973
   McCormack J, 1998, COMPUT GRAPH FORUM, V17, P113, DOI 10.1111/1467-8659.00232
   McDonnell KT, 2002, VISUAL COMPUT, V18, P81, DOI 10.1007/s003710100138
   Mizuno S, 1998, VISUAL COMPUT, V14, P39, DOI 10.1007/s003710050122
   PASKO A, 1995, VISUAL COMPUT, V11, P429, DOI 10.1007/BF02464333
   Pasko A, 2001, GRAPH MODELS, V63, P413, DOI 10.1006/gmod.2001.0560
   Pasko A, 2001, COMPUT AIDED DESIGN, V33, P379, DOI 10.1016/S0010-4485(00)00129-9
   Pasko A., 1999, EUROGRAPHICSACM SIGG, P59
   ROSSIGNAC J, 1994, ACM T GRAPHIC, V13, P101
   ROSSIGNAC J, 2003, P SHAP MOD INT 03 SE
   Rowland D, 2002, LEONARDO, V35, P193, DOI 10.1162/00240940252940586
   Schmitt B, 2001, J VISUAL COMP ANIMAT, V12, P297, DOI 10.1002/vis.267
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Sederberg TN, 2003, ACM T GRAPHIC, V22, P477, DOI 10.1145/882262.882295
   Séquin CH, 2001, COMPUT AIDED DESIGN, V33, P345, DOI 10.1016/S0010-4485(00)00126-3
   SINGH K., 1998, SIGGRAPH 98, P405, DOI DOI 10.1145/280814.280946
   Sourin A, 2001, VISUAL COMPUT, V17, P258, DOI 10.1007/s003710100109
   Todd S., 1992, Evolutionary art and computers
   WANG W, 1995, P S INT 3D GRAPH P A, P151
   WYWILL G, 1996, INT J SHAPE MODELING, V2, P275
   Zeleznik R. C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P163, DOI 10.1145/237170.237238
NR 44
TC 1
Z9 1
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2005
VL 16
IS 1
BP 25
EP 39
DI 10.1002/cav.54
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 912IF
UT WOS:000228070300004
DA 2024-07-18
ER

PT J
AU Conde, T
   Thalmann, D
AF Conde, T
   Thalmann, D
TI An artificial life environment for autonomous virtual agents with
   multi-sensorial and multi-perceptive features
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE artificial life; perception; virtual sensors; virtual environment;
   virtual autonomous agents
AB Our approach is based on the multi-sensory integration of the standard theory of neuroscience, where signals of a single object coming from distinct sensory systems are combined. The acquisition steps of signals, filtering, selection and simplification intervening before proprioception, active and predictive perception are integrated into virtual sensors and a virtual environment. We will focus on two aspects: 1) the assignment problem: determining which sensory stimuli belong to the same virtual object and (2) the sensory recoding problem: recoding signals in a common format before combining them. We have developed three novel methodologies to map the information coming from the virtual sensors of vision, audition and touch as well as that of the virtual environment in the form of a 'cognitive map'. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Swiss Fed Inst Technol, EPFL, Virtual Real Lab, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Swiss Fed Inst Technol, EPFL, Virtual Real Lab, CH-1015 Lausanne, Switzerland.
EM daniel.thalmann@epfl.ch
RI Thalmann, Daniel/AAL-1097-2020; Thalmann, Daniel/A-4347-2008
OI Thalmann, Daniel/0000-0002-0451-7491; 
CR BERSINI H, 1994, P 3 INT C SIM AD BEH, P325
   BORDEUX C, 1999, P EUR 99 MIL IT, P23
   CAROLLO C, 2002, ION STORM
   CONDE T, INTEGRATED PERCEPTIO
   ELFES G, 1990, 6 C UNC AI
   Huang Zhiyong, 1995, COMPUT GRAPHICS-US, P235
   Hudson T.C., 1997, Proceedings of the 2nd Symposium of Virtual Reality Modeling Language, V1997, P119
   Karabassi E.-A., 1999, Journal of Graphics Tools, V4, P5, DOI 10.1080/10867651.1999.10487510
   Kuffner JJ, 1999, COMP ANIM CONF PROC, P118, DOI 10.1109/CA.1999.781205
   linas R.R., 2001, I of the vortex: from neurons to self, V1st
   Mitchell T. M., 1997, MACHINE LEARNING
   NOSER H, 1995, COMPUT GRAPH, V19, P7, DOI 10.1016/0097-8493(94)00117-H
   NOSER H, 1995, P EUR 1995 C MAASTR, P325
   Pouget A, 2002, NAT REV NEUROSCI, V3, P741, DOI 10.1038/nrn914
   Renault O., 1990, Journal of Visualization and Computer Animation, V1, P18, DOI 10.1002/vis.4340010106
   REYNOLDS CW, 1993, COM ADAP SY, P384
   SOWA JF, 1964, CONCEPTUAL STRUCTURE
   Strösslin T, 2002, LECT NOTES COMPUT SC, V2415, P87
   TU X, 1994, PACIFIC GRAPHICS
   Wenzel E.M., 1992, PRESENCE, V1, P80
   YVANOV YA, 2002, THESIS MIT
NR 21
TC 12
Z9 14
U1 0
U2 1
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 311
EP 318
DI 10.1002/cav.34
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700021
OA Green Published
DA 2024-07-18
ER

PT J
AU Wang, HX
   Che, XP
   Chang, EY
   Qu, CX
   Luo, Y
   Wei, ZL
AF Wang, Haoxiang
   Che, Xiaoping
   Chang, Enyao
   Qu, Chenxin
   Luo, Yao
   Wei, Zhenlin
TI How to set safety boundary in virtual reality: A dynamic approach based
   on user motion prediction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Safety boundary; user experience; virtual reality
AB Virtual reality (VR) interaction safety is a prerequisite for all user activities in the virtual environment. While seeking a deep sense of immersion with little concern about surrounding obstacles, users may have limited ability to perceive the real-world space, resulting in possible collisions with real-world objects. Nowadays, recent works and rendering techniques such as the Chaperone can provide safety boundaries to users but confines them in a small static space and lack of immediacy. To solve this problem, we propose a dynamic approach based on user motion prediction named SCARF, which uses Spearman's correlation analysis, rule learning, and few-shot learning to achieve prediction of user movements in specific VR tasks. Specifically, we study the relationship between user characteristics, human motion, and categories of VR tasks and provides an approach that uses biomechanical analysis to define the interaction space in VR dynamically.We report on a user study with 58 volunteers and establish a three dimensional kinematic dataset from a VR game. The experiments validate that our few-shot learning model is effective and can improve the performance of motion prediction. Finally, we implement SCARF in VR environment for dynamic safety boundary adjustment.
C1 [Wang, Haoxiang; Wei, Zhenlin] Beijing Jiaotong Univ, Sch Traff & Transportat, Beijing, Peoples R China.
   [Che, Xiaoping; Chang, Enyao; Qu, Chenxin; Luo, Yao] Beijing Jiaotong Univ, Sch Software Engn, Beijing, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Che, XP (corresponding author), Beijing Jiaotong Univ, Sch Software Engn, Beijing, Peoples R China.
EM xpche@bjtu.edu.cn
OI Chang, Enyao/0009-0006-3037-6254
FU Fundamental Research Funds for the Central Universities [T22YJS00010]
FX ACKNOWLEDGMENTS This work was supported by the Fundamental Research
   Funds for the Central Universities (T22YJS00010).
CR Altae-Tran H, 2017, ACS CENTRAL SCI, V3, P283, DOI 10.1021/acscentsci.6b00367
   Byczkowski T, 2009, 2009 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, P221, DOI 10.1109/CRV.2009.40
   Deng SM, 2020, AAAI CONF ARTIF INTE, V34, P13773
   Effertz J, 2012, EXPERIENCE FROM THE DARPA URBAN CHALLENGE, P209, DOI 10.1007/978-0-85729-772-3_9
   Faltaous Sarah, 2020, MUM 2020: 19th International Conference on Mobile and Ubiquitous Multimedia, P254, DOI 10.1145/3428361.3428389
   Finn C, 2017, PR MACH LEARN RES, V70
   Haiwei Chen, 2018, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P523, DOI 10.1109/VR.2018.8446563
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   Hirt C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P573, DOI 10.1109/VR.2018.8446262
   Huang SY, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P528, DOI 10.1145/3292147.3292241
   Kanamori K, 2018, INT SYM MIX AUGMENT, P80, DOI 10.1109/ISMAR.2018.00033
   Kloiber S, 2020, VISUAL COMPUT, V36, P1937, DOI 10.1007/s00371-020-01942-1
   Kudo Yoshiki, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3486950
   Marwecki S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173815
   Medeiros D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P21, DOI 10.1109/VR50410.2021.00022
   Pfeuffer K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300340
   Posada-Gomez R., 2011, 2011 21st International Conference on Electrical Communications and Computers (CONIELECOMP 2011), P284, DOI 10.1109/CONIELECOMP.2011.5749375
   Robitaille P, 2019, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2019), DOI 10.1145/3306131.3317022
   Snell J, 2017, ADV NEUR IN, V30
   Tao Y., 2022, P 35 ANN ACM S USER, P1
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   von Willich J, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P487, DOI 10.1145/3322276.3322334
   Wang TW, 2019, PATTERN RECOGN LETT, V125, P821, DOI 10.1016/j.patrec.2019.08.005
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wozniak P, 2020, ADV INTELL SYST, V973, P271, DOI 10.1007/978-3-030-20476-1_28
   Yu Q, 2018, IEEE ACCESS, V6, P49067, DOI 10.1109/ACCESS.2018.2859440
   Zappella L, 2008, FRONT ARTIF INTEL AP, V184, P398, DOI 10.3233/978-1-58603-925-7-398
NR 27
TC 0
Z9 0
U1 6
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2210
EA AUG 2023
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IX7V0
UT WOS:001051434400001
DA 2024-07-18
ER

PT J
AU Li, TM
   Zhu, YY
AF Li, Tiemeng
   Zhu, Yangyang
TI Functional narrative animation as visual feedback for interactions in 3D
   visualization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE data visualization; interaction technique; narrative animation; virtual
   environment; visual feedback
AB Visual feedback can help users understand the function, state, and outcome of a system during the pre-, mid-, and post-interaction phases. Current visual feedback in 3D visualization scenarios takes less account of information transfer in terms of appearance design and dynamic behavior, which results in visual feedback being presented in a more engineered form and conveying simple information. For these issues, we proposed the concept and method of functional narrative animation as visual feedback for interactions in 3D visualization. We also provided a set of Unity-based animation library and a plugin tool for configuring the animations. Finally, through user experiments and interviews, we analyzed the role of functional narrative animation as in the interactive visual feedback for 3D visualizations and make corresponding design recommendations.
C1 [Li, Tiemeng; Zhu, Yangyang] Beijing Univ Posts & Telecommun, Sch Digital Media & Design Arts, Beijing 100876, Peoples R China.
   [Li, Tiemeng] Beijing Key Lab Network Syst & Network Culture, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Li, TM (corresponding author), 264 MailBox,10 Xitucheng Rd, Beijing 100876, Peoples R China.
EM tiemeng2000@gmail.com
OI LI, Tiemeng/0000-0001-5507-0397
FU National Natural Science Foundation of China [61702042]
FX National Natural Science Foundation of China, Grant/Award Number:
   61702042
CR Baecker R., 1990, ART HUMAN COMPUTER I
   Bellotti V, 2001, HUM-COMPUT INTERACT, V16, P193, DOI 10.1207/S15327051HCI16234_05
   Chang B.-W., 1993, P 6 ANN ACM S USER I, P45, DOI DOI 10.1145/168642.168647
   Chevalier N. H., 2016, P INT WORK C ADV VIS, P280
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Delamare William., 2016, Proceedings of the International Working Conference on Advanced Visual Interfaces, P152, DOI DOI 10.1145/2909132.2909260
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Djajadiningrat Tom, 2002, P 4 C DES INT SYST P, P285, DOI 10.1145/
   Dong Y., 2019, P INT C HUMAN COMPUT, P514
   Gotz D, 2009, INFORM VISUAL, V8, P42, DOI 10.1057/ivs.2008.31
   Guillon M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2777, DOI 10.1145/2702123.2702375
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Jankowski J., 2013, EUROGRAPHICS 2013 ST
   Li Y., 2021, ARXIV PREPRINT ARXIV
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P25, DOI 10.1007/978-3-030-01388-2_2
   Prachyabrued M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P19, DOI 10.1109/3DUI.2014.6798835
   Rees D, 2020, IEEE INT CONF INF VI, P28, DOI 10.1109/IV51561.2020.00015
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi Y., 2021, UNDERSTANDING DESIGN
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
NR 22
TC 1
Z9 1
U1 6
U2 27
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2086
DI 10.1002/cav.2086
EA JUN 2022
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000811889200001
DA 2024-07-18
ER

PT J
AU Guo, C
   Wang, Q
   Dai, HN
   Li, P
AF Guo, Cai
   Wang, Qian
   Dai, Hong-Ning
   Li, Ping
TI VDN: Variant-depth network for motion deblurring
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion deblurring; scale-invariant input; variant-depth network
ID DARK
AB Motion deblurring is a challenging task in vision and graphics. Recent researches aim to deblur by using multiple sub-networks with multi-scale or multi-patch inputs. However, scaling or splitting operations on input images inevitably loses the spatial details of the images. Meanwhile, their models are usually complex and computationally expensive. To address these problems, we propose a novel variant-depth scheme. In particular, we utilize the multiple variant-depth sub-networks with scale-invariant inputs to combine into a variant-depth network (VDN). In our design, different levels of sub-networks accomplish progressive deblurring effects without transforming the inputs, thereby effectively reducing the computational complexity of the model. Extensive experiments have shown that our VDN outperforms the state-of-the-art motion deblurring methods while maintaining a lower computational cost. The source code is publicly available at: .
C1 [Guo, Cai; Wang, Qian] Macau Univ Sci & Technol, Sch Comp Sci & Engn, Taipa, Macao, Peoples R China.
   [Guo, Cai] Hanshan Normal Univ, Network & Educ Technol Ctr, Chaozhou, Peoples R China.
   [Wang, Qian; Li, Ping] Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.
   [Dai, Hong-Ning] Lingnan Univ, Dept Comp & Decis Sci, Tuen Mun, Hong Kong, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Sch Design, Kowloon, Hong Kong, Peoples R China.
C3 Macau University of Science & Technology; Hanshan Normal University;
   Hong Kong Polytechnic University; Lingnan University; Hong Kong
   Polytechnic University
RP Li, P (corresponding author), Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.; Dai, HN (corresponding author), Lingnan Univ, Dept Comp & Decis Sci, Tuen Mun, Hong Kong, Peoples R China.; Li, P (corresponding author), Hong Kong Polytech Univ, Sch Design, Kowloon, Hong Kong, Peoples R China.
EM hndai@ieee.org; p.li@polyu.edu.hk
RI Guo, Cai/HZI-6956-2023; Li, Ping/AAO-2019-2020; Dai,
   Hong-Ning/B-1931-2012
OI Li, Ping/0000-0002-1503-0240; Dai, Hong-Ning/0000-0001-6165-4196; Guo,
   Cai/0000-0001-7524-2272
FU Hong Kong Polytechnic University [P0030419, P0030929, P0035358]; Hong
   Kong Institute of Business Studies Research Seed Fund [HKIBS
   RSF-212-004]
FX This work was supported in part by The Hong Kong Polytechnic University
   under Grant P0030419, Grant P0030929, and Grant P0035358, and in part by
   the Hong Kong Institute of Business Studies Research Seed Fund under
   Grant HKIBS RSF-212-004.
CR Cai JR, 2020, IEEE T IMAGE PROCESS, V29, P6885, DOI 10.1109/TIP.2020.2995048
   Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14
   Gao HY, 2019, PROC CVPR IEEE, P3843, DOI 10.1109/CVPR.2019.00397
   Goyal Priya, 2017, CoRR abs/1706.02677
   Hu XB, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4278, DOI 10.1109/ICCV48922.2021.00426
   Kim TH, 2013, IEEE I CONF COMP VIS, P3160, DOI 10.1109/ICCV.2013.392
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Li J., 2021, P IEEE CVF INT C COM, P4116
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804
   Pan JS, 2019, IEEE T PATTERN ANAL, V41, P1412, DOI 10.1109/TPAMI.2018.2832125
   Pan JS, 2013, SIGNAL PROCESS-IMAGE, V28, P1156, DOI 10.1016/j.image.2013.05.001
   Paszke A, 2019, ADV NEUR IN, V32
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Shen ZY, 2019, IEEE I CONF COMP VIS, P5571, DOI 10.1109/ICCV.2019.00567
   Sheng B, 2020, IEEE T CIRC SYST VID, V30, P955, DOI 10.1109/TCSVT.2019.2901629
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Yu X, 2014, IEEE T MULTIMEDIA, V16, P1510, DOI 10.1109/TMM.2014.2321734
   Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613
   Zhao HT, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102921
NR 25
TC 4
Z9 4
U1 0
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2066
DI 10.1002/cav.2066
EA MAY 2022
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000803490600001
DA 2024-07-18
ER

PT J
AU Huang, YJ
AF Huang, Yi-Jheng
TI Detecting color boundaries on 3D surfaces by applying edge-detection
   image filters on a quad-remeshing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer graphics; edge detection; mesh editing; quad mesh; texture
   editing
ID BAS-RELIEF GENERATION
AB Edge detection is a common image-processing technique that has numerous applications. In this article, we propose an algorithm for detecting edges based on the color of a mesh surface. We name the edges the color boundaries. Our approach is based on the data structure of a quad mesh, which makes the data structure of 3D meshes resemble the data structure of images. As a result, image-processing methods can be applied on the 3D meshes. In this article, six classical edge detection filters are implemented on the 3D meshes. The experimental results demonstrate that our method can identify areas of high color gradient on 3D meshes. A comparison with two other methods for detecting color boundaries on 3D meshes reveals that our method is more effective at detecting boundaries. Lastly, we propose two novel applications that utilize the information of color boundaries on a 3D mesh surface.
C1 [Huang, Yi-Jheng] Yuan Ze Univ, Dept Comp Sci & Engn, 135 Yuan Tung Rd, Taoyuan 32003, Taiwan.
C3 Yuan Ze University
RP Huang, YJ (corresponding author), Yuan Ze Univ, Dept Comp Sci & Engn, 135 Yuan Tung Rd, Taoyuan 32003, Taiwan.
EM yjhuang@saturn.yzu.edu.tw
OI Huang, Yi-Jheng/0000-0003-3036-1483
FU Ministry of Science and Technology, Taiwan [MOST110-2221-E-155-042-MY3]
FX Ministry of Science and Technology, Taiwan, Grant/Award Number:
   MOST110-2221-E-155-042-MY3
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   Adams B., 2004, INTERACTIVE 3D PAINT, P57
   [Anonymous], 2018, ARXIV180608485
   [Anonymous], 2012, P INT C RECONFIGURAB
   Bähnisch C, 2009, LECT NOTES COMPUT SC, V5748, P111, DOI 10.1007/978-3-642-03798-6_12
   Bommes D, 2013, COMPUT GRAPH FORUM, V32, P51, DOI 10.1111/cgf.12014
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cignoni P., 2008, VCGLIB
   Dischler JM, 2006, VISUAL COMPUT, V22, P926, DOI 10.1007/s00371-006-0077-4
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Dolonius D, 2019, IEEE T VIS COMPUT GR, V25, P1270, DOI 10.1109/TVCG.2017.2741480
   Ferraris J, 2012, COMPUT ANIMAT VIRT W, V23, P435, DOI 10.1002/cav.1460
   Guan Y, 2006, COMPUT ANIMAT VIRT W, V17, P573, DOI 10.1002/cav.156
   Guingo G, 2020, COMPUT GRAPH-UK, V91, P95, DOI 10.1016/j.cag.2020.07.006
   Gupta R., 2017, INDIAN J SCI TECHNOL, V10, DOI [10.17485/ijst/2017/v10i31/113894, DOI 10.17485/ijst/2017/v10i4/108963]
   Hu Jingqiao, 2016, Journal of Computer Aided Design & Computer Graphics, V28, P2128
   Huang YJ, 2018, IEEE T VIS COMPUT GR, V24, P1114, DOI 10.1109/TVCG.2017.2657751
   HUMMEL RA, 1987, COMPUT VISION GRAPH, V38, P66, DOI 10.1016/S0734-189X(87)80153-6
   Jakob W, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818078
   Ji ZP, 2014, IEEE T VIS COMPUT GR, V20, P675, DOI 10.1109/TVCG.2013.267
   Kaehler A., 2016, Learning OpenCV 3
   Kolomenkin M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409110
   Le T, 2020, IEEE ACCESS, V8, P90153, DOI [10.1109/access.2020.2994160, 10.1109/ACCESS.2020.2994160]
   Li TT, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1815
   Lin WC., 2006, QUANTITATIVE EVALUAT, V1, P427
   Mao JH, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2012
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Meinhardt E, 2009, J MATH IMAGING VIS, V34, P1, DOI 10.1007/s10851-008-0118-x
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Ohtake Y, 2004, ACM T GRAPHIC, V23, P609, DOI 10.1145/1015706.1015768
   Prada F, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201317
   Prewitt J. M., 1970, Picture processing and psychopictorics, V10, P15
   Ratcliffe CP, 1997, J SOUND VIB, V204, P505, DOI 10.1006/jsvi.1997.0961
   Roberts L.G., 1965, OPTICAL ELECTRO OPTI, P159
   Romanengo C, 2020, COMPUT GRAPH-UK, V89, P105, DOI 10.1016/j.cag.2020.05.012
   Sobel I., 1968, STANF ART PROJ, P271
   Suzuki R., 2018, P PACIFIC C COMPUTER, P29
   Wang Ao-yu, 2004, Proceedings. Third International Conference on Image and Graphics, P434
   Wang ML, 2021, NEUROCOMPUTING, V453, P825, DOI 10.1016/j.neucom.2020.06.130
   Wu CH, 2019, ASIAN TEST SYMPOSIUM, P1, DOI [10.1109/ats47505.2019.000-9, 10.1109/ieee-iws.2019.8804124, 10.1109/ATS47505.2019.000-9]
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Zhang YW, 2019, COMPUT GRAPH FORUM, V38, P521, DOI 10.1111/cgf.13655
   Zhang YW, 2013, GRAPH MODELS, V75, P2, DOI 10.1016/j.gmod.2012.10.003
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
NR 45
TC 3
Z9 3
U1 2
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2023
VL 34
IS 2
AR e2051
DI 10.1002/cav.2051
EA MAY 2022
PG 28
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D7UU4
UT WOS:000795781400001
DA 2024-07-18
ER

PT J
AU Mao, JH
   Li, TT
   Zhang, FY
   Wang, ML
   Chang, J
   Lu, XQ
AF Mao, Jiahui
   Li, Tingting
   Zhang, Feiyu
   Wang, Meili
   Chang, Jian
   Lu, Xuequan
TI Bas-relief layout arrangement via automatic method optimization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE bas-relief layout; combinatorial optimization problem; simulated
   annealing
AB It is significant to achieve automatic arrangement for bas-relief layout which can be noticeably more efficient than the time-consuming manual process. In fact, nearly none work has been reported in terms of bas-relief layout arrangement. In this paper, we propose a novel approach to tackle this problem. Specifically, we first identify the evaluation indicators to account for different aesthetic factors, and model the goodness of each indicator. We then cast the bas-relief layout as a combinatorial optimization problem based on those evaluation indicators and a geometric mean model. The contribution of this paper is to propose an objective function for bas-relief layout and apply simulated annealing algorithm for optimization. Experiments show that our method is effective, in terms of layout arrangement for bas-relief generation. In addition, this method can synthesize a few models arrangement and investigate which evaluation indicators will affect the aesthetic perception of the bas-relief.
C1 [Mao, Jiahui; Zhang, Feiyu; Wang, Meili] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Li, Tingting; Chang, Jian] Bournemouth Univ, NCCA, Poole, Dorset, England.
   [Lu, Xuequan] Deakin Univ, Sch Informat Technol, Waurn Ponds, Australia.
C3 Northwest A&F University - China; Bournemouth University; Deakin
   University
RP Wang, ML (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
EM wml@nwsuaf.edu.cn
RI zhang, feiyu/KRP-6203-2024; zhang, luyu/JJC-4227-2023
OI Lu, Xuequan/0000-0003-0959-408X
FU Key Laboratory of Agricultural Internet of Things, Ministry of
   Agriculture and Rural Affairs [2018AIOT-09]; National Natural Science
   Foundation of China [61702433]; Key Research and Development Project of
   Shaanxi Province [2019NY-167]
FX Key Laboratory of Agricultural Internet of Things, Ministry of
   Agriculture and Rural Affairs, Grant/Award Number: 2018AIOT-09; National
   Natural Science Foundation of China, Grant/Award Number: 61702433; The
   Key Research and Development Project of Shaanxi Province, Grant/Award
   Number: 2019NY-167
CR Cohen-Steiner D., 2003, P 19 ANN S COMP GEOM, P312, DOI DOI 10.1145/777792.777839
   Fisher M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818057
   Fu Q, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130805
   Ji Z, 2018, ARXIV GRAPHICS
   Ji ZP, 2021, COMPUT AIDED DESIGN, V130, DOI 10.1016/j.cad.2020.102928
   Ji ZP, 2014, IEEE T VIS COMPUT GR, V20, P675, DOI 10.1109/TVCG.2013.267
   Kán P, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139135
   Laarhoven P. J. M., 1987, Simulated Annealing, DOI [10.1007/978-94-015-7744-1, DOI 10.1007/978-94-015-7744-1_2]
   Li TT, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1815
   Merrell P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866203
   Savva M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925867
   Schüller C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661267
   Wang M., 2020, NEUROCOMPUTING
   Wei MQ, 2019, IEEE T VIS COMPUT GR, V25, P1651, DOI 10.1109/TVCG.2018.2818146
   Yang Y, 2018, PROC CVPR IEEE, P3926, DOI 10.1109/CVPR.2018.00413
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Zhang SH, 2019, J COMPUT SCI TECH-CH, V34, P594, DOI 10.1007/s11390-019-1929-5
   Zhang YD, 2014, LECT NOTES COMPUT SC, V8694, P668, DOI 10.1007/978-3-319-10599-4_43
   Zhang YW, 2020, IEEE T VIS COMPUT GR, V26, P2659, DOI 10.1109/TVCG.2019.2892439
   Zhang YW, 2019, COMPUT GRAPH FORUM, V38, P521, DOI 10.1111/cgf.13655
   Zhang YW, 2013, GRAPH MODELS, V75, P2, DOI 10.1016/j.gmod.2012.10.003
NR 21
TC 1
Z9 1
U1 2
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2012
DI 10.1002/cav.2012
EA JUN 2021
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000663874200001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Guo, H
   Zou, SC
   Lai, CY
   Zhang, HX
AF Guo, Hong
   Zou, Shanchen
   Lai, Chuying
   Zhang, Hongxin
TI PhyCoVIS: A visual analytic tool of physical coordination for cheer and
   dance training
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cheer and dance; physical coordination; pose estimation on videos; pose
   similarity
ID HUMAN POSE
AB Processing and analyzing dance videos are important in the application of online cheer leading and dance training for physical coordination measurement. However, it is challenging for users to evaluate a massive amount of uploaded video, to precisely quantize and compare dance moves, and to visualize training results. To overcome these challenges, we propose a visualization-driven approach for analyzing dance videos. We first encode extracted video frames into a set of heat maps via neural network, which calculates a skeleton structure for pose estimation with enhanced post-processing to help capture dance moves. A subsequent pose similarity method allows users to quantize differences between student training videos and the standard one. Finally, an interactive visualization tool enables users and domain experts to interactively analyze the quality of dance moves along the time line. We demonstrate the applicability and effectiveness of our proposed tool using case studies involving physical coordination research.
C1 [Guo, Hong; Lai, Chuying] Zhejiang Univ, Dept Publ Phys & Art Educ, Hangzhou, Peoples R China.
   [Zou, Shanchen; Zhang, Hongxin] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Zhang, HX (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
EM zhx@cad.zju.edu.cn
RI Zhang, Hongxin/T-3714-2019
FU National Natural Science Foundation of China [U1909204]; National Key
   Research and Development Program of China [2017YFC0804401]
FX National Natural Science Foundation of China, Grant/Award Number:
   U1909204; National Key Research and Development Program of China,
   Grant/Award Number: 2017YFC0804401
CR Agarwal A, 2006, LECT NOTES COMPUT SC, V3851, P50
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Belongie S, 2001, ADV NEUR IN, V13, P831
   Bissacco A., 2007, P IEEE COMPUTER SOC, P1, DOI DOI 10.1109/CVPR.2007.383129
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Luo Y, 2018, PROC CVPR IEEE, P5207, DOI 10.1109/CVPR.2018.00546
   Masliak I, 2019, J PHYS ED SPORT, V19, P178
   Newell A., 2017, ADV NEUR IN, P2171
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Raaj Y, 2019, PROC CVPR IEEE, P4615, DOI 10.1109/CVPR.2019.00475
   Urtasun R, 2008, PROC CVPR IEEE, P149
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   ZAJAC FE, 1993, J BIOMECH, V26, P109, DOI 10.1016/0021-9290(93)90083-Q
NR 22
TC 6
Z9 6
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2021
VL 32
IS 1
AR e1975
DI 10.1002/cav.1975
EA NOV 2020
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QP5QT
UT WOS:000588706500001
DA 2024-07-18
ER

PT J
AU Ertugrul, E
   Zhang, H
   Zhu, F
   Lu, P
   Li, P
   Sheng, B
   Wu, EH
AF Ertugrul, Egemen
   Zhang, Han
   Zhu, Fang
   Lu, Ping
   Li, Ping
   Sheng, Bin
   Wu, Enhua
TI Embedding 3D models in offline physical environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D data compression; augmented reality; autoencoders; human-computer
   interaction; robotics and vision; ubiquitous computing; volume rendering
ID OCTREE
AB This article introduces a novel approach for embedding 3D models in offline physical environments using quick response (QR) codes. Unlike conventional methods, we consider settings where 3D models cannot be retrieved from a remote server. Our method involves generating octree models from voxelized 3D models and storing them in QR codes using a space-efficient data structure. This allows storing 3D models that are both intelligible and purposeful on standard QR codes while addressing the major storage constraint that is present in offline situations. Furthermore, we explore 3D convolutional neural networks (CNN) and autoencoders (AE) to compress 3D models with high resolutions where using octrees alone does not suffice. To the best of our knowledge, our AE network is the first to employ octrees to further compress its encoded data. Through user-friendly desktop and mobile applications, we allow users to encode, decode and visualize 3D models in augmented reality (AR) using QR codes, thus experiment with our methods. The proposed approach enables unique applications and future research in ubiquitous computing, 3D data compression and transmission, 3D AEs, AR and Virtual Reality, low-cost autonomous robots, and 3D printing.
C1 [Ertugrul, Egemen; Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Zhang, Han; Zhu, Fang; Lu, Ping] ZTE Corp, Shenzhen, Guangdong, Peoples R China.
   [Zhang, Han; Zhu, Fang; Lu, Ping] State Key Lab Mobile Network & Mobile Multimedia, Chongqing, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Wu, Enhua] Univ Macau, Fac Sci & Technol, Macau, Peoples R China.
C3 Shanghai Jiao Tong University; ZTE; Hong Kong Polytechnic University;
   Chinese Academy of Sciences; Institute of Software, CAS; University of
   Macau
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
EM shengbin@sjtu.edu.cn
RI Li, Ping/AAO-2019-2020
OI Li, Ping/0000-0002-1503-0240; Sheng, Bin/0000-0001-8678-2784; Sheng,
   Bin/0000-0001-8510-2556
FU National Natural Science Foundation of China [61872241, 61572316]; Hong
   Kong Polytechnic University [P0030419, P0030929]
FX The authors would like to thank Berkay Adanali, Martin Pellon Consunji,
   and Qiaofeng Liu for their support during the development of this work.
   This work was supported in part by the National Natural Science
   Foundation of China under Grant 61872241 and Grant 61572316, and in part
   by The Hong Kong Polytechnic University under Grant P0030419 and Grant
   P0030929.
CR [Anonymous], 2013, DENSO WAVE QR CODE F
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 1996, RFC 1951, DOI [10.17487/RFC1951, DOI 10.17487/RFC1951]
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Chae S, 2016, IEEE SYS MAN CYBERN, P2598, DOI 10.1109/SMC.2016.7844630
   Chang Angel X., 2015, arXiv
   Chollet F, 2015, KERAS
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Cruz L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P169, DOI 10.1109/AIVR.2018.00036
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dean T, 2012, QUICK LAYERED RESPON, V2
   Deutsch P, 1996, 1952 RFC IETF
   Diederik P, 2013, KINGMA MAX WELLING A
   Gervautz M, 1988, NEW TRENDS COMPUTER, P219, DOI DOI 10.1007/978-3-642-83492-920
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han TD, 2002, Japan Patent, Patent No. 3336311
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   ISO, 247782008 ISO ISOIEC
   ISO, 2020, 160232000 ISO ISOIEC
   ISO, 2020, 160222006 ISO ISOIEC
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kan Tai-Wei, 2009, Proceedings of the 8th International Conference on Virtual Reality Continuum and its Applications in Industry, P253, DOI [10.1145/1670252.1670305, DOI 10.1145/1670252.1670305]
   Laine S, 2011, IEEE T VIS COMPUT GR, V17, P1048, DOI 10.1109/TVCG.2010.240
   Langlotz T, 2007, UNSYNCHRONIZED 4D BA
   Lerner Adam., 2015, P 13 ANN INT C MOBIL, P359, DOI DOI 10.1145/2742647.2742650
   Li Y, 2016, ABS160506240 ARXIV
   Lubke D, 2012, LEVEL DETAIL 3D GRAP
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Meagher DJR, 1980, ELECT SYSTEMS ENG
   Min P., 2004, Binvox, a 3d mesh voxelizer
   Nooruddin FS, 2003, IEEE T VIS COMPUT GR, V9, P191, DOI 10.1109/TVCG.2003.1196006
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Rohs M, 2004, INT S UB COMP SYST
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Savva M, 2017, 3DOR, DOI [10.2312/3DOR.20171050, DOI 10.2312/3DOR.20171050]
   Schnabel R, 2006, OCTREE BASED POINT C
   STORER JA, 1982, J ACM, V29, P928, DOI 10.1145/322344.322346
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Wang PS, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275050
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Whang KY, 1995, IEEE T VIS COMPUT GR, V1, P343, DOI 10.1109/2945.485621
   Zeiler Matthew D, 2012, ARXIV12125701
   Zeng M, 2013, GRAPH MODELS, V75, P126, DOI 10.1016/j.gmod.2012.09.002
NR 45
TC 7
Z9 7
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1959
DI 10.1002/cav.1959
EA SEP 2020
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000565349300001
DA 2024-07-18
ER

PT J
AU Krogmeier, C
   Mousas, C
   Whittinghill, D
AF Krogmeier, Claudia
   Mousas, Christos
   Whittinghill, David
TI Human-virtual character interaction: Toward understanding the influence
   of haptic feedback
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE galvanic skin response; haptic feedback; haptic vest; virtual bump;
   virtual characters; virtual reality
ID ENVIRONMENTS
AB In this study, we compare haptic feedback and nonhaptic feedback conditions in which virtual characters bump into the participant who is immersed in a virtual environment. A questionnaire was developed to determine the influence of haptic feedback on a number of concepts (presence, embodiment, positive and negative affect, interaction realism with virtual character, and haptic feedback realism). Physiological data were also collected using galvanic skin response (GSR) to investigate the influence of haptic feedback on physiological arousal during human-virtual character interaction. Five conditions were developed (no haptic feedback, full intensity, half intensity, incorrect position, and delayed timing) to determine which aspects of haptic feedback are most important in influencing participant responses. Significant differences were found in embodiment, realism of virtual character interaction, and haptic feedback realism. In addition, significant differences were found in GSR amplitude after the first interaction with the virtual character. Implications for further research are discussed.
C1 [Krogmeier, Claudia; Mousas, Christos; Whittinghill, David] Purdue Univ, Purdue Polytech Inst, Dept Comp Graph Technol, 401 N Grant St, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Mousas, C (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM cmousas@purdue.edu
RI Mousas, Christos/AGV-3533-2022; Whittinghill, David/J-6434-2012
OI Mousas, Christos/0000-0003-0955-7959; Whittinghill,
   David/0000-0002-2011-7893
CR [Anonymous], 2017, GALV SKIN RESP COMPL
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Fox J, 2015, HUM-COMPUT INTERACT, V30, P401, DOI 10.1080/07370024.2014.921494
   Frohner J, 2019, IEEE T HAPTICS
   García-Valle G, 2018, IEEE ACCESS, V6, P7224, DOI 10.1109/ACCESS.2017.2782254
   Giannopoulos E, 2011, BRAIN RES BULL, V85, P276, DOI 10.1016/j.brainresbull.2010.11.012
   Gobron SC, 2015, INT C AUGM VIRT REAL
   Goedschalk L., 2017, Benelux Conference on Artificial Intelligence, P61
   Hou X, 2014, 2014 INT C CYB OCT 6
   Israr A, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2641570
   Jones LA, 2004, 12 INT S HAPT INT VI
   Kappers AML, 2011, PHILOS T R SOC B, V366, P3106, DOI 10.1098/rstb.2011.0171
   Lazzaro M., 2008, GAME USABILITY ADVIC
   Lee J, 2017, IEEE T HUM-MACH SYST, V47, P101, DOI 10.1109/THMS.2016.2599492
   Moll J, 2010, INTERACT COMPUT, V22, P544, DOI 10.1016/j.intcom.2010.06.001
   Mousas C, 2019, IEEE C VIRT REAL 3D
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Murray CD, 2000, PRESENCE-TELEOP VIRT, V9, P137, DOI 10.1162/105474600566682
   Naveteur J, 2013, TRANSPORT RES F-TRAF, V18, P58, DOI 10.1016/j.trf.2012.12.008
   Otaduy MA, 2016, SIGGRAPH 16 ACM SIGG
   Popov A, 2016, AEROSP CONF PROC
   Ramsamy P, 2006, INT C COMP SCI MAY 2
   Robles-De-La-Torre G., 2010, INT SOC HAPTICS HAPT
   Salamon N, 2018, ACTA ASTRONAUT, V146, P117, DOI 10.1016/j.actaastro.2018.02.034
   Serafin S., 2004, ICAD
   Singer MJ, 1999, PRESENCE-TELEOP VIRT, V8, P566, DOI 10.1162/105474699566486
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Tsalamlal MY, 2015, J MULTIMODAL USER IN, V9, P69, DOI 10.1007/s12193-014-0162-3
   vander Meulen E, 2016, 2016 IEEE INT S MIX
   von der Pütten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zhao S, 2015, P 14 INT C INT DES C
NR 33
TC 46
Z9 50
U1 1
U2 27
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1883
DI 10.1002/cav.1883
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400006
DA 2024-07-18
ER

PT J
AU Yiannakides, A
   Aristidou, A
   Chrysanthou, Y
AF Yiannakides, Anastasios
   Aristidou, Andreas
   Chrysanthou, Yiorgos
TI Real-time 3D human pose and motion reconstruction from monocular RGB
   videos
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE monocular video; motion reconstruction; estimation openPose; 3D pose
ID ARTICULATED OBJECTS; CAPTURE
AB Real-time three-dimensional (3D) pose estimation is of high interest in interactive applications, virtual reality, activity recognition, and most importantly, in the growing gaming industry. In this work, we present a method that captures and reconstructs the 3D skeletal pose and motion articulation of multiple characters using a monocular RGB camera. Our method deals with this challenging, but useful, task by taking advantage of the recent development in deep learning that allows two-dimensional (2D) pose estimation of multiple characters and the increasing availability of motion capture data. We fit 2D estimated poses, extracted from a single camera via OpenPose, with a 2D multiview joint projections database that is associated with their 3D motion representations. We then retrieve the 3D body pose of the tracked character, ensuring throughout that the reconstructed movements are natural, satisfy the model constraints, are within a feasible set, and are temporally smooth without jitters. We demonstrate the performance of our method in several examples, including human locomotion, simultaneously capturing of multiple characters, and motion reconstruction from different camera views.
C1 [Yiannakides, Anastasios; Aristidou, Andreas; Chrysanthou, Yiorgos] Univ Cyprus, Dept Comp Sci, CY-1678 Nicosia, Cyprus.
   [Yiannakides, Anastasios; Aristidou, Andreas; Chrysanthou, Yiorgos] RISE Res Ctr, Nicosia, Cyprus.
C3 University of Cyprus
RP Yiannakides, A (corresponding author), Univ Cyprus, Dept Comp Sci, CY-1678 Nicosia, Cyprus.
EM tasyiann@gmail.com
OI Aristidou, Andreas/0000-0001-7754-0791; Yiannakidis,
   Anastasios/0000-0002-3721-6548
FU RESTART Programmes for Technological Development and Innovation
   [P2P/JPICH_DH/0417/0052]; European Union [739578,
   H2020-WIDESPREAD-01-2016-2017-T]
FX RESTART 2016-2020 Programmes for Technological Development and
   Innovation, Grant/Award Number: P2P/JPICH_DH/0417/0052; European Union's
   Horizon 2020 Research and Innovation Programme, Grant/Award Number:
   739578, RISE-Call: H2020-WIDESPREAD-01-2016-2017-T
CR Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P297, DOI 10.1111/cgf.13362
   Aristidou A, 2016, COMPUT ANIMAT VIRT W, V27, P35, DOI 10.1002/cav.1630
   Aristidou A, 2013, VISUAL COMPUT, V29, P7, DOI 10.1007/s00371-011-0671-y
   Baak A, 2011, IEEE I CONF COMP VIS, P1092, DOI 10.1109/ICCV.2011.6126356
   Berger K., 2011, VISION MODELING VISU, P317
   Biswas A, 2019, P INT C ROB AUT ICRA
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Cao Zhangjie, 2018, P IEEE C COMP VIS PA
   Carnegie Mellon University, 2019, MOCAP LIB
   Carreno-Medrano P., 2016, CASA 16 P 29 INT C C, P157
   Casiez G., 2012, P SIGCHI C HUM FACT, P2527, DOI DOI 10.1145/2207676.2208639
   Cheung GKM, 2003, PROC CVPR IEEE, P77
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   desAguiar E, 2008, ACM T GRAPH, V27
   Dieudonne Atrevi Fabrice, 2016, VISIGRAPP 2016. 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications. Proceedings: VISAPP 2016, P361
   Forbes N, 2005, IMITATION OF LIFE: HOW BIOLOGY IS INSPIRING COMPUTING, P67
   Gall J, 2010, LECT NOTES COMPUT SC, V6313, P425
   Ghezelghieh MF, 2016, P 4 INT C 3D VIS 3DV
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Lassner C., 2017, PROC CVPR IEEE, V2, P3, DOI DOI 10.1109/CVPR.2017.500
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Liu YB, 2013, IEEE T PATTERN ANAL, V35, P2720, DOI 10.1109/TPAMI.2013.47
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Orfanidis S. J., 1995, Introduction to signal processing
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   PhaseSpace Inc, 2019, OPT MOCAP SYST
   Radzikowski K, 2019, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-018-0146-4
   Rhodin H, 2018, LECT NOTES COMPUT SC, V11214, P765, DOI 10.1007/978-3-030-01249-6_46
   Rhodin H, 2018, PROC CVPR IEEE, P8437, DOI 10.1109/CVPR.2018.00880
   Root Motion, 2019, FINAL IK
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Seber G A., 2009, Multivariate observations, DOI DOI 10.1002/9780470316641
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Simo-Serra E, 2013, PROC CVPR IEEE, P3634, DOI 10.1109/CVPR.2013.466
   Slyper R, 2008, P 2008 ACM SIGGRAPHE, P193
   Tautges J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966397
   Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664
   Vicon, 2019, VIC MOT CAPT SYST
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Vlasic Daniel, 2009, ACM TRANSACTIONS ON GRAPHICS, V28, P2, DOI [DOI 10.1145/1618452.1618520, 10.1145/1618452.1618520]
   Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wei XL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366207
   Xsens Technologies BV, 2019, MOT CAPT SYST
   Xu WP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181973
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Ye M, 2014, PROC CVPR IEEE, P2353, DOI 10.1109/CVPR.2014.301
   Zhou XW, 2019, IEEE T PATTERN ANAL, V41, P901, DOI 10.1109/TPAMI.2018.2816031
   Zimmermann C, 2018, IEEE INT CONF ROBOT, P1986, DOI 10.1109/ICRA.2018.8462833
NR 56
TC 11
Z9 11
U1 2
U2 30
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1887
DI 10.1002/cav.1887
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400024
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Castillo, S
   Legde, K
   Cunningham, DW
AF Castillo, S.
   Legde, K.
   Cunningham, D. W.
TI The semantic space for motion-captured facial expressions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE animation; emotional models; facial expressions; motion capture
ID COMMUNICATION; MODEL
AB We cannot not communicate! During our daily lives, we convey information verbally and nonverbally. Most of the affective meaning of a message is transferred with the help of facial expressions, and thereby, when trying to establish a realistic human-like virtual character, we should pay close attention to the animation. Motion capture is one of the most common techniques, but due to the wide range of expressions humans use, the recording time and data needed are vast. To address this problem, we propose the use of semantic spaces as they help in characterizing and positioning expressions by finding a correlation between them. In this paper, we extend prior research by providing the semantic spaces underlying real videos and motion capture data for a total of 62 conversational expressions. Our results highly correlate with previous work, showing that our new expressions were correctly recognized. Moreover, our results can be used in future work to directly project potential new recordings of these 62 expressions on the found spaces.
C1 [Castillo, S.; Legde, K.; Cunningham, D. W.] Brandenburg Univ Technol Cottbus Senftenberg, Fak Math Informat Nat Wissensch Tech MINT 1, Chair Graph Syst, Cottbus, Germany.
C3 Brandenburg University of Technology Cottbus
RP Castillo, S (corresponding author), Brandenburg Univ Technol Cottbus Senftenberg, Cottbus, Germany.
EM castillo@b-tu.de
RI Castillo, Susana/U-6432-2019
OI Castillo, Susana/0000-0003-1245-4758
FU German Research Council [150/2-1]
FX German Research Council, Grant/Award Number: 150/2-1
CR Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Castillo S, 2014, COMPUT ANIMAT VIRT W, V25, P225, DOI 10.1002/cav.1593
   Cunningham D.W., 2004, P 1 S APPL PERCEPTIO, V73, P143
   Cunningham D. W., 2005, ACM T APPL PERCEPT, V2, P251, DOI DOI 10.1145/1077399.1077404
   Cunningham Douglas W, 2011, EXPT DESIGN USER STU
   Deng ZG, 2006, LECT NOTES ARTIF INT, V4133, P107
   ELLSWORTH PC, 1972, J COMMUN, V22, P375, DOI 10.1111/j.1460-2466.1972.tb00164.x
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Kaulard K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032321
   Kleiner M, 2007, 30 EUR C VIS PERC EC
   Lee C, 2007, RO MAN 2007 16 IEEE
   MEHRABIAN A, 1967, J CONSULT PSYCHOL, V31, P248, DOI 10.1037/h0024648
   Mullins-Sweatt SN, 2006, ASSESSMENT, V13, P119, DOI 10.1177/1073191106286748
   Nusseck M, 2008, J VISION, V8, DOI 10.1167/8.8.1
   Osgood C. E., 1957, The measurement of meaning
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Peres-Neto PR, 2001, OECOLOGIA, V129, P169, DOI 10.1007/s004420100720
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Sokolov EN, 2000, INTEGR PHYS BEH SCI, V35, P81, DOI 10.1007/BF02688770
NR 19
TC 1
Z9 2
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1823
DI 10.1002/cav.1823
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100014
DA 2024-07-18
ER

PT J
AU Huang, PH
   Wong, SK
AF Huang, Po-Han
   Wong, Sai-Keung
TI Emotional virtual crowd on task completion in virtual markets
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE emotional crowd; interaction; mood modeling; task completion; virtual
   agents; virtual reality
ID PERSONALITY; SIMULATION; MODEL
AB This paper studies the effects of a virtual crowd with emotion on task completion in a virtual market. The users have to interact with the virtual agents so that the virtual agents are willing to lead the users to specific vendors. Then, the users can buy the required items. The users communicate with the virtual agents via a conversation dialog. The emotional agents' moods are affected by their own interaction (e.g., collision) while they are walking. Furthermore, their moods are also affected by the conversational responses of the users. We adopt a simple 2D mood model and use icons to represent the mood states of the agents. The mood model supports four mood states, which are Excitement, Anger, Sadness, and Neutral. We conducted a user study to evaluate the effects of the emotional virtual agents in different aspects, including task completion, time spent in conversation, following distance, and realism of the emotional virtual crowd.
C1 [Huang, Po-Han; Wong, Sai-Keung] Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Wong, SK (corresponding author), Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
EM wingo.wong@gmail.com
FU Ministry of Science and Technology of the ROC [MOST
   104-2221-E-009-051-MY3, MOST 106-2221-E-009-161-MY2]
FX Ministry of Science and Technology of the ROC, Grant/Award Number: MOST
   104-2221-E-009-051-MY3 and MOST 106-2221-E-009-161-MY2
CR Amaoka T, 2009, INT C CYBERWORLDS 20
   Andre E., 2000, INTEGRATING MODELS P, P150, DOI DOI 10.1007/10720296_11
   [Anonymous], 2005, TECHNICAL REPORT
   [Anonymous], 2005, INT JOINT C AUTONOMO, DOI DOI 10.1145/1082473.1082478
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Collins A, 1990, The cognitive structure of emotions
   Damian Ionut, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P15, DOI 10.1007/978-3-642-25090-3_2
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Egges A, 2004, COMPUT ANIMAT VIRT W, V15, P1, DOI 10.1002/cav.3
   Han MJ, 2013, IEEE T CYBERNETICS, V43, P1290, DOI 10.1109/TSMCB.2012.2228851
   Jan D, 2009, LECT NOTES ARTIF INT, V5773, P372, DOI 10.1007/978-3-642-04380-2_40
   Kim S., 2012, P ACM SIGGRAPH S INT, P55, DOI [DOI 10.1145/2159616.2159626, 10.1145/2159616.2159626]
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   MCCRAE RR, 1987, J PERS SOC PSYCHOL, V52, P81, DOI 10.1037/0022-3514.52.1.81
   Mehrabian A, 1996, AUST J PSYCHOL, V48, P86, DOI 10.1080/00049539608259510
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Narang S, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P91, DOI 10.1145/2993369.2993378
   Olivier AH, 2014, TRANSP RES PROC, V2, P114, DOI 10.1016/j.trpro.2014.09.015
   RUSSELL JA, 1985, J PERS SOC PSYCHOL, V48, P1290, DOI 10.1037/0022-3514.48.5.1290
   Vieira JB, 2017, HUM BRAIN MAPP, V38, P1492, DOI 10.1002/hbm.23467
NR 21
TC 6
Z9 8
U1 2
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1818
DI 10.1002/cav.1818
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100009
DA 2024-07-18
ER

PT J
AU Xiao, XY
   Yang, C
   Yang, XB
AF Xiao, Xiangyun
   Yang, Cheng
   Yang, Xubo
TI Adaptive learning-based projection method for smoke simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE deep neural network; fluid simulation; incremental learning
ID SOLVER
AB Traditional Eulerian-based fluid simulations require much time and computational resources to solve the projection step, especially the large linear system produced by the Poisson equation. In this paper, we propose an adaptive machine-learning-based projection method combining deep neural network and incremental learning technique. We provide two modes: Fast Mode and Normal Mode to solve the most time-consuming projection step and deal with various simulation scenes largely different from the training data set. We introduce patch-based feature vectors to represent the whole velocity field and a loss function to keep the divergence-free constraint. We have demonstrated the acceleration and extrapolation ability of our method by testing various smoke scenes far different from our training data set.
C1 [Xiao, Xiangyun; Yang, Cheng; Yang, Xubo] Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, XB (corresponding author), Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.
EM yangxubo@sjtu.edu.cn
FU National Natural Science Foundation of China [61772329]
FX National Natural Science Foundation of China, Grant/Award Number:
   61772329
CR [Александрова Мария Викторовна Aleksandrova M.], 2010, [Проблемы Дальнего Востока, Problemy Dal'nego Vostoka], P65
   Ando R, 2015, COMPUT GRAPH FORUM, V34, P473, DOI 10.1111/cgf.12576
   [Anonymous], ARXIV170404456
   [Anonymous], ACM T GRAPH
   [Anonymous], ACM T GRAPH
   [Anonymous], 2015, ACM T GRAPH
   [Anonymous], 2008, Fluid Simulation for Computer Graphics
   [Anonymous], TECHNOMETRICS
   Chu JY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3092818
   Chu MY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073643
   Da F, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925899
   Diehl CP, 2003, IEEE IJCNN, P2685
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ladicky L, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818129
   Liu HX, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982430
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Raveendran K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601126
   Ristin M, 2016, IEEE T PATTERN ANAL, V38, P490, DOI 10.1109/TPAMI.2015.2459678
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shen FR, 2006, NEURAL NETWORKS, V19, P90, DOI 10.1016/j.neunet.2005.04.006
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Tompson J., 2016, CoRR
   Treuille A, 2006, ACM T GRAPHIC, V25, P826, DOI 10.1145/1141911.1141962
   Wicke M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531345
   Yang C, 2016, COMPUT ANIMAT VIRT W, V27, P415, DOI 10.1002/cav.1695
   Zhu B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461999
NR 28
TC 7
Z9 11
U1 1
U2 20
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1837
DI 10.1002/cav.1837
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100028
DA 2024-07-18
ER

PT J
AU Feng, A
   Rosenberg, ES
   Shapiro, A
AF Feng, Andrew
   Rosenberg, Evan Suma
   Shapiro, Ari
TI Just-in-time, viable, 3-D avatars from scans
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE 3-D scanning; avatar; character
AB We demonstrate a system that can generate a photorealistic, interactive 3-D character from a human subject that is capable of movement, emotion, speech, and gesture in less than 20 min without the need for 3-D artist intervention or specialized technical knowledge through a near automatic process. Our method uses mostly commodity or off-the-shelf hardware. We demonstrate the just-in-time use of generating such 3-D models for virtual and augmented reality, games, simulation, and communication. We anticipate that the inexpensive generation of such photorealistic models will be useful in many venues where a just-in-time 3-D reconstructions of digital avatars that resemble particular human subjects is necessary.
C1 [Feng, Andrew; Shapiro, Ari] Univ Southern Calif, Inst Creat Technol, Los Angeles, CA 90089 USA.
   [Rosenberg, Evan Suma] Univ Southern Calif, Inst Creat Technol, MxR Lab, Los Angeles, CA USA.
C3 University of Southern California; University of Southern California
RP Shapiro, A (corresponding author), Univ Southern Calif, Inst Creat Technol, Los Angeles, CA 90089 USA.
EM shapiro@ict.usc.edu
CR Albrecht I., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P98
   Alexander Oleg, 2013, ACM SIGGRAPH 2013 PO, P1
   [Anonymous], ACM T GRAPHICS P SIG
   [Anonymous], 2013, ACM T GRAPHIC
   Aymerich-Franch L., 2014, Proceedings of the International Society for Presence Research, P173
   Baltrusaitis T, 2014, LECT NOTES COMPUT SC, V8692, P593, DOI 10.1007/978-3-319-10593-2_39
   Bouaziz S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461976
   Cao C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925873
   Casas D, 2015, ACM SIGGRAPH 2015 TA
   Casas D, 2014, COMPUT GRAPH FORUM, V33, P371, DOI 10.1111/cgf.12296
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   ElKoura G., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P110
   Feng A, 2014, COMPUT ANIMAT VIRT W, V25, P3, DOI 10.1002/cav.1560
   Feng Andrew, 2015, P 8 ACM SIGGRAPH C M, P57
   Fox J., 2010, CyberTherapy Rehabil, V3, P16, DOI [10.1037/e530522011-003, DOI 10.1037/E530522011-003]
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Guerra RS, 2014, EUR J CLIN NUTR, V68, P229, DOI 10.1038/ejcn.2013.220
   Huang P, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2699643
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jin SAA, 2009, CYBERPSYCHOL BEHAV, V12, P761, DOI 10.1089/cpb.2009.0130
   Jörg S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366208
   Kurihara Tsuneya, 2004, P 2004 ACM SIGGRAPHE, P355
   Lucas G., 2016, Proceedings of the 9th International Conference on Motion in Games, P167, DOI DOI 10.1145/2994258.2994263
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Perry TS, 2014, IEEE SPECTRUM, V51, P48, DOI 10.1109/MSPEC.2014.6821621
   Rhee Taehyun., 2006, Human Hand Modeling from Surface Anatomy, DOI DOI 10.1145/1111411.1111417
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Straub J, 2014, TECHNOLOGIES, V2, P76, DOI 10.3390/technologies2020076
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Xu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964927
   YE YT, 2012, ACM T GRAPHIC, V31, DOI DOI 10.1145/2185520.2185537
   Zhao Wenping, 2012, Proceedings of the ACM SIGGRAPH/eurographics symposium on computer animation. Eurographics Association, P33, DOI [10.2312/SCA/SCA12/033-042, DOI 10.2312/SCA/SCA12/033-042]
   Zollhöfer M, 2014, COMPUT ANIMAT VIRT W, V25, P213, DOI 10.1002/cav.1584
NR 33
TC 12
Z9 13
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1769
DI 10.1002/cav.1769
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200015
DA 2024-07-18
ER

PT J
AU Laraba, S
   Brahimi, M
   Tilmanne, J
   Dutoit, T
AF Laraba, Sohaib
   Brahimi, Mohammed
   Tilmanne, Joelle
   Dutoit, Thierry
TI 3D skeleton-based action recognition by representing motion capture
   sequences as 2D-RGB images
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE action recognition; convolutional neural networks; 3D data
   representation
AB In recent years, 3D skeleton-based action recognition has become a popular technique of action classification, thanks to development and availability of cheaper depth sensors. State-of-the-art methods generally represent motion sequences as high dimensional trajectories followed by a time-warping technique. These trajectories are used to train a classification model to predict the classes of new sequences. Despite the success of these techniques in some fields, particularly when the data used are captured by a high-precision motion capture system, action classification is still less successful than the field of image classification, especially with the advance of deep learning. In this paper, we present a new representation of motion sequences (Seq2Im-for sequence to image), which projects motion sequences onto the RGB domain. The 3D coordinates of joints are mapped to red, green, and blue values, and therefore, action classification becomes an image classification problem and algorithms for this field can be applied. This representation was tested with basic image classification algorithms (namely, support vector machine, k-nearest neighbor, and random forests) in addition to convolutional neural networks. Evaluation of the proposed method on standard 3D human action recognition datasets shows its potential for action recognition and outperforms most of the state-of-the-art results.
C1 [Laraba, Sohaib; Tilmanne, Joelle; Dutoit, Thierry] Univ Mons, Numediart Inst, TCTS Lab, Mons, Belgium.
   [Brahimi, Mohammed] USTHB Univ, Dept Comp Sci, Algiers, Algeria.
   [Brahimi, Mohammed] Mohamed El Bachir El Ibrahimi Univ, Dept Comp Sci, Bordj Bou Arreridj, Algeria.
C3 University of Mons; University Science & Technology Houari Boumediene
RP Laraba, S (corresponding author), Univ Mons, Numediart Inst, TCTS Lab, Mons, Belgium.
EM sohaib.laraba@umons.ac.be
RI Laraba, Sohaib/HHR-8810-2022
OI Laraba, Sohaib/0000-0002-7937-4149; Brahimi,
   Mohammed/0000-0003-2034-644X
FU Numediart and Infortech of the University of Mons (UMONS); EU; Wallonia
   [600676]
FX Numediart and Infortech of the University of Mons (UMONS); EU; Wallonia,
   Grant/Award Number: n 600676
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   [Anonymous], 2016, REV FACULTAD INGENIE
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], ARXIV161205877
   [Anonymous], 2012, J Comput Vis Image Process
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, ARXIV160804233
   [Anonymous], 2014, ARXIV14033369
   [Anonymous], 2013, P 21 ACM INT C MULT
   [Anonymous], 2013, IJCAI
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2007, Computer Graphics Technical Report CG-2007-2
   Bloom V., 2012, 2012 IEEE COMP SOC C, P7, DOI [DOI 10.1109/CVPRW.2012.6239175, 10.1109/CVPRW.2012.6239175]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Jia XF, 2012, INT C PATT RECOG, P3001
   Laraba S, 2016, COMPUT ANIMAT VIRT W, V27, P321, DOI 10.1002/cav.1715
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   MARTENS J, 2011, P 28 INT C MACH LEAR, P1033
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prashanth H. S., 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, & Telecommunication Technologies (ACT 2009), P859, DOI 10.1109/ACT.2009.218
   Sempena Samsu., 2011, P INT C EL ENG INF, P1, DOI DOI 10.1109/ICEEI.2011.6021605
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
NR 34
TC 37
Z9 39
U1 2
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1782
DI 10.1002/cav.1782
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200027
DA 2024-07-18
ER

PT J
AU Yun, J
   Son, M
   Choi, B
   Kim, T
   Yoon, SE
AF Yun, Jeongsu
   Son, Myungbae
   Choi, Byungyoon
   Kim, Theodore
   Yoon, Sung-Eui
TI Physically inspired, interactive lightning generation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE interactivity; lightning; rendering
ID ANIMATION
AB We present an interactive technique for generating realistic lightning. Our method captures the main characteristics of the dielectric breakdown model, a physical model for lightning formation. Our algorithm uses a distance-based approximation to quickly compute the electric potentials of different charge types. In particular, we use a rational function in lieu of summed potentials to better produce interesting lightning patterns. We also propose to use the waypoints commonly available in many game scenes to guide lightning shapes in complex scenes. We found that our algorithm is 2 times faster than the state-of-the art method with better controls on lighting shapes, and can generate realistic lightning shapes interactively.
C1 [Yun, Jeongsu; Son, Myungbae; Choi, Byungyoon; Yoon, Sung-Eui] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
   [Kim, Theodore] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
C3 Korea Advanced Institute of Science & Technology (KAIST); University of
   California System; University of California Santa Barbara
RP Yoon, SE (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
EM sungeui@kaist.edu
RI Yoon, Sung-eui/C-1678-2011; kim, Theodore/HLQ-4764-2023
FU MSIP/IITP [R0126-17-1108]; MSIP/NRF [2011-0030079]
FX MSIP/IITP, Grant/Award Number: R0126-17-1108; MSIP/NRF, Grant/Award
   Number: 2011-0030079
CR Bickel B, 2006, ADAPTIVE SIMULATION
   Cui X, 2011, INT J COMPUT SCI NET, V11, P125
   Dobashi Y, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P390, DOI 10.1109/PCCGA.2001.962896
   Glassner A, 2000, IEEE COMPUT GRAPH, V20, P89, DOI 10.1109/38.824552
   Griffiths DavidJeffrey., 1999, Introduction to electrodynamics, V3
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Kim T, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P267, DOI 10.1109/PCCGA.2004.1348357
   Kim T, 2007, IEEE COMPUT GRAPH, V27, P68, DOI 10.1109/MCG.2007.33
   Kim T, 2007, IEEE T VIS COMPUT GR, V13, P390, DOI 10.1109/TVCG.2007.38
   Matsuyama K, 2006, VISUAL COMPUT, V22, P761, DOI 10.1007/s00371-006-0061-z
   Mitchell J. L., 2004, SHADERX2, P439
   Narasimhan S G., 2003, Shedding light on the weather
   NIEMEYER L, 1984, PHYS REV LETT, V52, P1033, DOI 10.1103/PhysRevLett.52.1033
   Reed T., 1994, Proceedings of the 21st annual conference on Computer graphics and interactive techniques, P359
   SHEWCHUK J, INTRO CONJUGATE GRAD
   Sosorbaram B, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P89, DOI 10.1109/CGI.2001.934662
   Xu Ling., 2009, Artificial Intelligence Techniques for Computer Graphics, P83
NR 17
TC 2
Z9 2
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1760
DI 10.1002/cav.1760
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200007
DA 2024-07-18
ER

PT J
AU Chung, SJ
   Pollard, N
AF Chung, Se-Joon
   Pollard, Nancy
TI Predictable behavior during contact simulation: a comparison of selected
   physics engines
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE predictability; physics engine comparison; physics simulation; virtual
   worlds
AB Contact behaviors in physics simulations are important for real-time interactive applications, especially in virtual reality applications where user's body parts are tracked and interact with the environment via contact. For these contact simulations, it is ideal to have small changes in initial condition yield predictable changes in the output. Predictable simulation is key for success in iterative learning processes as well, such as learning controllers for manipulations or locomotion tasks. Here, we present an extensive comparison of contact simulations using Bullet Physics, Dynamic Animation and Robotics Toolkit (DART), MuJoCo, and Open Dynamics Engine, with a focus on predictability of behavior. We first tune each engine to match an analytical solution as closely as possible and then compare the results for a more complex simulation. We found that in the commonly available physics engines, small changes in initial condition can sometimes induce different sequences of contact events to occur and ultimately lead to a vastly different result. Our results confirmed that parameter settings do matter a great deal and suggest that there may be a trade-off between accuracy and predictability. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Chung, Se-Joon] Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.
   [Pollard, Nancy] Carnegie Mellon Univ, Dept Comp Sci, Inst Robot, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University; Carnegie Mellon University
RP Chung, SJ (corresponding author), Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.
EM sejoonc@cs.cmu.edu
OI Pollard, Nancy/0000-0001-6464-839X
FU Direct For Computer & Info Scie & Enginr; Div Of Information &
   Intelligent Systems [1218182] Funding Source: National Science
   Foundation
CR Boeing A, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P281
   Drumwright E, 2012, IEEE INT C INT ROBOT, P5034, DOI 10.1109/IROS.2012.6385974
   Drumwright E, 2011, IEEE INT CONF ROBOT, P1695
   Erez T, 2015, IEEE INT CONF ROBOT, P4397, DOI 10.1109/ICRA.2015.7139807
   Featherstone R., 2007, RIGID BODY DYNAMICS
   Hummel J, 2012, LECT NOTES COMPUT SC, V7432, P346, DOI 10.1007/978-3-642-33191-6_34
   Ivaldi S, 2014, IEEE-RAS INT C HUMAN, P842, DOI 10.1109/HUMANOIDS.2014.7041462
   MCGEER T, 1990, INT J ROBOT RES, V9, P62, DOI 10.1177/027836499000900206
   Seugling A, 2006, THESIS
   Todorov E, 2014, IEEE INT CONF ROBOT, P6054, DOI 10.1109/ICRA.2014.6907751
NR 10
TC 17
Z9 21
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 262
EP 270
DI 10.1002/cav.1712
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300010
DA 2024-07-18
ER

PT J
AU Guo, JX
   Yuan, ZY
   Liao, XY
   Bai, YY
   Lai, QF
AF Guo, Jiaxiang
   Yuan, Zhiyong
   Liao, Xiangyun
   Bai, Yaoyi
   Lai, Qianfeng
TI GPU-assisted real-time coupling of blood flow and vessel wall
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE fluid-solid coupling; blood vessel; smoothed particle hydrodynamics;
   mixed particles
ID SHEAR-STRESS; CEREBRAL ANEURYSM; HEMODYNAMICS; FLUIDS
AB The vessel wall and the blood flow interact and influence each other, and real-time coupling between them is of great importance to the virtual surgery as well as the research and diagnosis of vascular disease. On the basis of smoothed particle hydrodynamics (SPH), we present a new approach to solve non-Newtonian viscous force of blood and a parallel mixed particles-based coupling method for blood flow and vessel wall. Meanwhile, we also design a proxy particle-based vessel wall force visualization method. Our method is as follows. Firstly, we solve the non-Newtonian viscous forces of blood through the SPH method to discretize the Casson equation. Secondly, in each time step, we combine blood particles and sampling proxy particles on the blood vessel wall to form mixed particles and calculate the interaction forces through the SPH method between every pair of the neighboring mixed particles inside the graphics processing unit. Thirdly, the forces of the proxy particles will be mapped to the color display of the proxy particle. Experimental results demonstrate that our method is able to implement real-time sizeable coupling of blood flow and vessel wall while mainly ensuring physical authenticity and it can also provide real-time and obvious information about vessel wall force distribution. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Guo, Jiaxiang; Yuan, Zhiyong; Liao, Xiangyun; Bai, Yaoyi; Lai, Qianfeng] Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
C3 Wuhan University
RP Yuan, ZY (corresponding author), Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
EM zhiyongyuan@whu.edu.cn
FU National Basic Research Program of China [2011CB707904]; National
   Natural Science Foundation of China [61372107, 61272276, 61190125];
   State Key Laboratory of Virtual Technology and Systems, Beihang
   University [BUAA-VR-13KF-15]
FX This work was supported by the National Basic Research Program of China
   (2011CB707904), the National Natural Science Foundation of China
   (61372107, 61272276, and 61190125), and the Open Funding Project of
   State Key Laboratory of Virtual Technology and Systems, Beihang
   University (BUAA-VR-13KF-15).
CR Akinci N, 2013, COMPUT ANIMAT VIRT W, V24, P195, DOI 10.1002/cav.1499
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bernsdorf J, 2009, COMPUT MATH APPL, V58, P1024, DOI 10.1016/j.camwa.2009.02.019
   Boussel L, 2008, STROKE, V39, P2997, DOI 10.1161/STROKEAHA.108.521617
   Cassons N, 1959, FLOW EQUATION PIGMEN
   Cebral JR, 2005, IEEE T MED IMAGING, V24, P457, DOI 10.1109/TMI.2005.844159
   Cleary PW, 1998, APPL MATH MODEL, V22, P981, DOI 10.1016/S0307-904X(98)10031-8
   Crosetto P, 2011, COMPUT FLUIDS, V43, P46, DOI 10.1016/j.compfluid.2010.11.032
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Ihmsen M, 2011, COMPUT GRAPH FORUM, V30, P99, DOI [10.1111/j.1467-8659.2010.01832.x, 10.1111/j.1467-8659.2010.01834.x]
   Ihmsen Markus, 2014, P 35 ANN C EUR ASS C, DOI [10.2312/egst.20141034, DOI 10.2312/EGST.20141034]
   Kondo S, 1997, STROKE, V28, P398, DOI 10.1161/01.STR.28.2.398
   LEVESQUE MJ, 1986, ARTERIOSCLEROSIS, V6, P220, DOI 10.1161/01.ATV.6.2.220
   LOU Z, 1993, J BIOMECH, V26, P37, DOI 10.1016/0021-9290(93)90611-H
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Muller Matthias, 2004, Technol Health Care, V12, P25
   Park J, 2013, COMPUT ANIMAT VIRT W, V24, P317, DOI 10.1002/cav.1510
   Qin J., 2010, P 2010 S INFORM COMM, P128, DOI DOI 10.1145/1852611.1852636
   Shojima M, 2004, STROKE, V35, P2500, DOI 10.1161/01.STR.0000144648.89172.0f
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Talbots H, 2013, STUD HLTH TECHNOL IN, V196, P423
   Yamaguchi T, 2010, ANN BIOMED ENG, V38, P1225, DOI 10.1007/s10439-010-9904-x
   Yang LP, 2012, COMPUT GRAPH FORUM, V31, P2037, DOI 10.1111/j.1467-8659.2012.03196.x
   Yureidini A, 2012, LECT NOTES COMPUT SC, V7510, P553, DOI 10.1007/978-3-642-33415-3_68
NR 26
TC 1
Z9 2
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 337
EP 345
DI 10.1002/cav.1641
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700015
OA Bronze
DA 2024-07-18
ER

PT J
AU Yasmin, S
   Du, N
   Chen, J
   Feng, YS
AF Yasmin, Shamima
   Du, Nan
   Chen, James
   Feng, Yusheng
TI A haptic-enabled novel approach to cardiovascular visualization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE visualization; IVUS images; coronary artery; 3D modeling; haptic
ID SEGMENTATION; IMAGE
AB Intravascular ultra sound (IVUS) imaging technique is widely used for the detection of plaque deposit inside coronary artery wall. Adequate detection of plaque deposit is necessary for further treatment of the patient, but image by image analysis, nevertheless, is cumbersome. In this paper, we proposed a fully automatic novel method for coronary artery visualization, which takes as an input a number of intravascular ultrasound images to construct the 3D model of coronary artery wall where the plaque deposit is demarcated in a rapid 3D rendering environment. This 3D visualization of coronary artery model has been enhanced in a haptic environment where the user is not only able to visualize the fatty plaque deposit but is also able to feel and differentiate stiffness of plaque deposit as well as soft, elastic property of normal artery through a virtual tour along the artery pathway. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Yasmin, Shamima] Arizona State Univ, Tempe, AZ 85287 USA.
   [Du, Nan] Univ Texas San Antonio, Dept Elect & Comp Engn ECE, Digital Image Proc Lab, San Antonio, TX USA.
   [Du, Nan] Univ Texas San Antonio, Dept ECE, San Antonio, TX USA.
   [Chen, James] Univ Colorado, Dept Med, Div Cardiol, Denver, CO USA.
   [Feng, Yusheng] Univ Texas San Antonio, San Antonio, TX USA.
C3 Arizona State University; Arizona State University-Tempe; University of
   Texas System; University of Texas at San Antonio (UTSA); University of
   Texas System; University of Texas at San Antonio (UTSA); University of
   Colorado System; University of Colorado Denver; University of Colorado
   Anschutz Medical Campus; University of Texas System; University of Texas
   at San Antonio (UTSA)
RP Yasmin, S (corresponding author), Arizona State Univ, Tempe, AZ 85287 USA.
EM shamima.yasmin@asu.edu
FU National Science Foundation grant NSF/HRD-CREST [0932339]; Direct For
   Education and Human Resources; Division Of Human Resource Development
   [0932339] Funding Source: National Science Foundation
FX This work is supported by the National Science Foundation grant
   NSF/HRD-CREST#0932339.
CR Brusseau E, 2004, IEEE T MED IMAGING, V23, P554, DOI 10.1109/TMI.2004.825602
   Cardinal MHR, 2006, IEEE T MED IMAGING, V25, P590, DOI 10.1109/TMI.2006.872142
   Koga T, 2010, ADV INTEL SOFT COMPU, V75, P139
   Mendizabal-Ruiz EG, 2011, UHCS1102
   Moraes MC, 2010, COMPUT CARDIOL CONF, V37, P389
   Papadogiorgaki M, 2008, ULTRASOUND MED BIOL, V34, P1482, DOI 10.1016/j.ultrasmedbio.2008.01.022
   RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039
   Taki A, 2008, INT J COMPUT ASS RAD, V3, P347, DOI 10.1007/s11548-008-0235-4
   Unal G, 2006, P 1 INT WORKSH COMP, P50
   Wennogle M, 2009, LECT NOTES COMPUT SC, V5627, P772, DOI 10.1007/978-3-642-02611-9_76
NR 10
TC 1
Z9 1
U1 0
U2 4
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 257
EP 271
DI 10.1002/cav.1586
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300007
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Dong, JY
   Pan, B
   Xiao, CX
AF Zhao, Yong
   Dong, Junyu
   Pan, Bin
   Xiao, Chunxia
TI Hierarchical mesh deformation with shape preservation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE mesh deformation; hierarchical approach; shape preservation;
   as-rigid-as-possible optimization
ID SPACE DEFORMATIONS
AB It is very difficult to deform flexible objects in computer animation. This paper presents a novel approach to address this problem. A detail-sensitive and deformation-sensitive simplification is first conducted on the original mesh. The simplified mesh is then deformed, and this deformation is transferred to the original mesh to produce an initial result. Because of the discontinuity between some vertices, an as-rigid-as-possible optimization is employed to prevent the shape distortion and control the surface stiffness. Various experimental data demonstrate that our algorithm is intuitive, efficient, and effective in deforming large meshes. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Zhao, Yong] Ocean Univ China, Sch Math Sci, Qingdao, Peoples R China.
   [Dong, Junyu] Ocean Univ China, Dept Comp Sci, Qingdao, Peoples R China.
   [Pan, Bin] Liaoning Shihua Univ, Coll Sci, Fushun, Peoples R China.
   [Xiao, Chunxia] Wuhan Univ, Sch Comp, Wuhan, Peoples R China.
C3 Ocean University of China; Ocean University of China; Liaoning
   Petrochemical University; Wuhan University
RP Zhao, Y (corresponding author), Ocean Univ China, Sch Math Sci, Qingdao, Peoples R China.
EM yongzhao.ouc@gmail.com
RI yang, zhou/KBB-6972-2024; wang, shuo/KCL-3379-2024
OI Dong, Junyu/0000-0001-7012-2087
FU National Natural Science Foundation of China [61303145, 61271405];
   Research Award Fund for Excellent Young and Middle-aged Scientists of
   Shandong Province [BS2012DX043]; Shandong Province Science and
   Technology Research Projects [2012GHY11524]; PhD Program Foundation of
   Ministry of Education of China [20120132110018]; Program for New Century
   Excellent Talents in University [NCET-13-0411]; Qingdao Science and
   Technology Plan Projects [12-1-4-1-(8)-jch]; Fundamental Research Funds
   for the Central Universities [201313005, 201362033]; State Key Lab of
   CAD&CG, Zhejiang University [A1308, A1312]
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61303145 and 61271405), the Research Award Fund for
   Excellent Young and Middle-aged Scientists of Shandong Province (No.
   BS2012DX043), the Shandong Province Science and Technology Research
   Projects (No. 2012GHY11524), the PhD Program Foundation of Ministry of
   Education of China (No. 20120132110018), the Program for New Century
   Excellent Talents in University (No. NCET-13-0411), the Qingdao Science
   and Technology Plan Projects (No. 12-1-4-1-(8)-jch), the Fundamental
   Research Funds for the Central Universities (Nos. 201313005 and
   201362033), and the Open Project of the State Key Lab of CAD&CG,
   Zhejiang University (Nos. A1308 and A1312).
CR Au O.K.C., 2005, P S GEOM PROC
   Au OKC, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239534, 10.1145/1276377.1276481]
   Ben-Chen M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531340
   Botsch M, 2003, COMPUT GRAPH FORUM, V22, P483, DOI 10.1111/1467-8659.00696
   Botsch M., 2006, SGP 06, P11
   Botsch M, 2007, COMPUT GRAPH FORUM, V26, P339, DOI 10.1111/j.1467-8659.2007.01056.x
   Cohen-Or D, 2009, J COMPUT SCI TECH-CH, V24, P2, DOI 10.1007/s11390-009-9200-0
   García FG, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487232
   Guskov I, 1999, COMP GRAPH, P325, DOI 10.1145/311535.311577
   Huang J, 2006, ACM T GRAPHIC, V25, P1126, DOI 10.1145/1141911.1142003
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Kavan L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366215
   Kobbelt L., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P105, DOI 10.1145/280814.280831
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Rivers AR, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239533
   Sauvage B, 2007, COMPUT GRAPH FORUM, V26, P275, DOI 10.1111/j.1467-8659.2007.01049.x
   Shi XH, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360628
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Sorkine O., 2004, P 2004 EUR ACM SIGGR, P179
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Vaillant R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461960
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zhou K, 2005, ACM T GRAPHIC, V24, P496, DOI 10.1145/1073204.1073219
   ZORIN D, 1997, P SIGGRAPH 97, P259
NR 30
TC 1
Z9 1
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 413
EP 422
DI 10.1002/cav.1596
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300022
DA 2024-07-18
ER

PT J
AU Chen, FB
   Wang, CB
   Xie, BY
   Qin, H
AF Chen, Feibin
   Wang, Changbo
   Xie, Buying
   Qin, Hong
TI Flexible and rapid animation of brittle fracture using the smoothed
   particle hydrodynamics formulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents Conference (CASA)
CY 2013
CL Istanbul, TURKEY
DE animation; smoothed particles hydrodynamics (SPH); brittle fracture
ID SIMULATION; TIME
AB This paper presents a hybrid animation approach to the flexible and rapid crack simulation of brittle material. At the physical level, the local stress tensors induced by collision are analyzed by using the smoothed particle hydrodynamics (SPH) formulation. Specifically, in order to determine the internal stress when rigid bodies collide with each other or neighboring environments, we treat all of them as completely rigid body that has infinite stiffness and then evaluate virtual displacement for colliding particles. At the geometric level, in order to faithfully maintain the fracture interface during the crack simulation, we utilize an efficient shape representation of solid based on the tetrahedral decomposition of the original solid geometry. This novel hybrid approach resorts to local particle models, whose goal is to avoid heavy computational burden during crack interface updating and topological changing, and meanwhile, it facilitates the user-initiated interactive control during the crack generation and propagation. Our animation experiments demonstrate the effectiveness of our novel particle-based method to simulate the crack of brittle material. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Chen, Feibin; Xie, Buying] Tongji Univ, Coll Civil Engn, Shanghai 200092, Peoples R China.
   [Wang, Changbo] E China Normal Univ, Inst Software Engn, Shanghai 200062, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 Tongji University; East China Normal University; State University of New
   York (SUNY) System; State University of New York (SUNY) Stony Brook
RP Wang, CB (corresponding author), E China Normal Univ, Inst Software Engn, Shanghai 200062, Peoples R China.
EM cbwang@sei.ecnu.edu.cn
FU Natural Science Foundation of China [61070128, 61272199]; National
   Natural Science Foundation of China [61190120, 61190121, 61190125];
   National Science Foundation of USA [IIS0949467, IIS1047715, IIS1049448];
   Innovation Program of the Shanghai Municipal Education Commission
   [12ZZ042]; Fundamental Research Funds for the Central Universities;
   Shanghai Knowledge Service Platform for Trustworthy Internet of Things
   [ZF1213]; Div Of Information & Intelligent Systems; Direct For Computer
   & Info Scie & Enginr [1049448, 1047715] Funding Source: National Science
   Foundation
FX This paper was partially supported by the Natural Science Foundation of
   China (Grant No. 61070128, 61272199), the National Natural Science
   Foundation of China (Grants No. 61190120, 61190121, and 61190125), the
   National Science Foundation of USA (Grants No. IIS0949467, IIS1047715,
   and IIS1049448), the Innovation Program of the Shanghai Municipal
   Education Commission (Grant No. 12ZZ042), the Fundamental Research Funds
   for the Central Universities, and Shanghai Knowledge Service Platform
   for Trustworthy Internet of Things (Grant No. ZF1213).
CR Bao ZS, 2007, IEEE T VIS COMPUT GR, V13, P370, DOI 10.1109/TVCG.2007.39
   Bender J, 2007, COMPUT ANIMAT VIRT W, V18, P225, DOI 10.1002/cav.179
   Fung Y.C., 1969, A first course in continuum mechanics
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Liu MB, 2010, ARCH COMPUT METHOD E, V17, P25, DOI 10.1007/s11831-010-9040-7
   Liu N, 2011, COMPUT ANIMAT VIRT W, V22, P115, DOI 10.1002/cav.412
   LUCY LB, 1977, ASTRON J, V82, P1013, DOI 10.1086/112164
   Markus Becker, 2009, NPH, V9, P27, DOI [10.2312/EG/DL/conf/EG2009/nph/027-034, DOI 10.2312/EG/DL/CONF/EG2009/NPH/027-034]
   Molino N, 2004, ACM T GRAPHIC, V23, P385, DOI 10.1145/1015706.1015734
   Müller M, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P26, DOI 10.1109/CGI.2004.1309189
   Müller M, 2001, SPRING EUROGRAP, P113
   Muller M., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, P154
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   Norton A., 1991, Visual Computer, V7, P210, DOI 10.1007/BF01900837
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   Parker E.G., 2009, PROC S COMP ANIM, P165, DOI DOI 10.1145/1599470.1599492.
   Paul WC, 2008, IUTAM S THEOR COMP M, V11, P287
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Peter K, 2008, P 2008 ACM SIGGRAPH, P105
   Rankine W.M. J., 1857, PHILOSOPHIC T ROYAL, P9, DOI DOI 10.1098/RSTL.1857.0003
   Smith J, 2001, COMPUT GRAPH FORUM, V20, P81, DOI 10.1111/1467-8659.t01-1-00202
   Steinemann D, 2009, GRAPH MODELS, V71, P209, DOI 10.1016/j.gmod.2008.12.004
   Tanaka M, 2006, ACM SIGGRAPH 2006 RE
   Terzopoulos D., 1988, Proceedings of the 15th annual conference on Computer graphics and interactive techniques, P269
   VLADIMIR EC, 2002, ACM SIGKDD EXPLORATI, V4, P65
   [No title captured]
NR 27
TC 10
Z9 15
U1 0
U2 16
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 215
EP 224
DI 10.1002/cav.1514
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 145GP
UT WOS:000319003500009
DA 2024-07-18
ER

PT J
AU Allen, BF
   Magnenat-Thalmann, N
   Thalmann, D
AF Allen, Brian F.
   Magnenat-Thalmann, Nadia
   Thalmann, Daniel
TI Politeness improves interactivity in dense crowds
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE virtual environments; user prediction; games; interaction; crowd
   simulation
ID MODEL
AB Traversing dense crowds can be challenging, but it is especially difficult in a virtual environment where the user is limited to simple input devices. Predicting near-future user movements with a hidden Markov model allows nearby autonomous agents to react politely, that is, to specifically avoid impeding the movement of the user. This predictive model and simple avoidance scheme are tested by six subjects in 360 short interactive games and by a 10-participant two-alternative forced choice questionnaire. Polite agents are found to significantly improve the player's ability to navigate quickly and without collision, and the resulting character movements showed increased naturalness for two of the three game scenarios. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Allen, Brian F.; Magnenat-Thalmann, Nadia; Thalmann, Daniel] Nanyang Technol Univ, Inst Media Innovat, Singapore, Singapore.
C3 Nanyang Technological University
RP Allen, BF (corresponding author), Nanyang Technol Univ, Inst Media Innovat, Singapore, Singapore.
EM vector@acm.org
RI Thalmann, Daniel/AAL-1097-2020; Thalmann, Daniel/A-4347-2008; Thalmann,
   Nadia/AAK-5195-2021
OI Thalmann, Daniel/0000-0002-0451-7491; Thalmann,
   Nadia/0000-0002-1459-5960
CR [Anonymous], ACM T GRAPHICS TOG
   [Anonymous], WORKSH 7 ART INT INT
   [Anonymous], P C FDN DIG GAM FDG
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Beckhaus S., 2007, Concepts and technologies for pervasive games: a reader for pervasive gaming research, V1, P231
   Doirado Eurico., 2010, Proceedings Of The 9th International Conference On Autonomous Agents and Multiagent Systems, AAMAS'10, V1, P83
   Drachen Anders, 2009, 2009 IEEE Symposium on Computational Intelligence and Games (CIG), P1, DOI 10.1109/CIG.2009.5286500
   Guy S., 2009, EUR ACM SIGGRAPH S C, P177
   Guy S.J., 2010, P 9 INT C AUTONOMOUS, V2, P575
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Lopes R, 2011, IEEE T COMP INTEL AI, V3, P85, DOI 10.1109/TCIAIG.2011.2152841
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   Merritt Tim R., 2011, Proceedings of the ACM 2011 conference on Computer supported cooperative work, P685, DOI DOI 10.1145/1958824.1958945
   Pair J, 2006, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2006.23
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Singh S, 2009, LECT NOTES COMPUT SC, V5884, P158, DOI 10.1007/978-3-642-10347-6_15
   Trautman P, 2010, IEEE INT C INT ROBOT, DOI 10.1109/IROS.2010.5654369
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
NR 25
TC 7
Z9 7
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2012
VL 23
IS 6
BP 569
EP 578
DI 10.1002/cav.1472
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 051NL
UT WOS:000312134000006
OA Bronze
DA 2024-07-18
ER

PT J
AU Jung, H
   Lee, DY
AF Jung, Hoeryong
   Lee, Doo Yong
TI Real-time cutting simulation of meshless deformable object using dynamic
   bounding volume hierarchy
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE meshless method; cutting simulation; surgery simulation; bounding volume
   hierarchy
ID FINITE-ELEMENT-METHOD; TOPOLOGY; MODEL
AB This paper proposes a novel method for a real-time cutting simulation of deformable objects using meshless method. The method utilizes a rapid refinement of topological relations among the simulation nodes of meshless deformable objects. Topological relations are defined as an undirected graph based on a visibility criterion. The graph connects the adjacent nodes that lie within a support of each node. The topological relations are refined by removing the edges of the graph that is intersected by the cut surface during the cutting simulation. Our approach utilizes a bounding volume hierarchy (BVH) to accelerate the computation of the intersection test. The BVH reconstruction algorithm is proposed to account for the cases where pieces of the object are completely cut out from the object. Algorithms to examine the connectivity among simulation nodes and accordingly reconstructing the BVH using two-level BVH are presented. The proposed approach achieves real-time cutting simulation of deformable objects through the rapid refinement of the topological relation. In addition, the computational performance of the cutting procedure is preserved during the entire simulation, thanks to the real-time reconstruction of the BVH. Copyright (c) 2012 John Wiley & Sons, Ltd.
C1 [Jung, Hoeryong; Lee, Doo Yong] Korea Adv Inst Sci & Technol, Div Mech Engn, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, DY (corresponding author), Korea Adv Inst Sci & Technol, Div Mech Engn, 291 Daehak Ro Yuseong Gu, Taejon 305701, South Korea.
EM leedy@kaist.ac.kr
RI Lee, Doo Yong/C-1534-2011
OI Lee, Doo Yong/0000-0003-4769-1331; , Hoeryong/0000-0001-7080-6630
FU International Research & Development Program of the National Research
   Foundation of Korea (NRF); Ministry of Education, Science and
   Technology(MEST) of Korea [D00005]
FX This research was supported by the International Research & Development
   Program of the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education, Science and Technology(MEST) of Korea (grant
   number: D00005).
CR Belytschko T, 2000, INT J NUMER METH ENG, V48, P1359, DOI 10.1002/1097-0207(20000730)48:9<1359::AID-NME829>3.0.CO;2-U
   Belytschko T, 1996, J COMPUT APPL MATH, V74, P111, DOI 10.1016/0377-0427(96)00020-9
   BELYTSCHKO T, 1994, INT J NUMER METH ENG, V37, P229, DOI 10.1002/nme.1620370205
   Belytschko T, 1996, COMPUT METHOD APPL M, V139, P3, DOI 10.1016/S0045-7825(96)01078-X
   Bessette GC, 2003, COMPUT METHOD APPL M, V192, P1649, DOI 10.1016/S0045-7825(02)00657-6
   Bielser D, 2004, GRAPH MODELS, V66, P398, DOI 10.1016/j.gmod.2004.05.009
   Bielser D, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P116, DOI 10.1109/PCCGA.2000.883933
   Bielser D, 1999, COMPUT GRAPH FORUM, V18, pC31, DOI 10.1111/1467-8659.00325
   Choi C, 2009, INT J MED ROBOT COMP, V5, P257, DOI 10.1002/rcs.256
   Cotin S, 2000, VISUAL COMPUT, V16, P437, DOI 10.1007/PL00007215
   Forest C, 2005, MED IMAGE ANAL, V9, P113, DOI 10.1016/j.media.2004.11.003
   Guo XH, 2006, IEEE T VIS COMPUT GR, V12, P375, DOI 10.1109/TVCG.2006.52
   Guo XH, 2005, COMPUT ANIMAT VIRT W, V16, P189, DOI 10.1002/cav.98
   Jerabkova L, 2009, IEEE COMPUT GRAPH, V29, P61, DOI 10.1109/MCG.2009.32
   Jung H, 2010, LECT NOTES COMPUT SC, V6191, P262, DOI 10.1007/978-3-642-14064-8_38
   Kaufmann P, 2009, GRAPH MODELS, V71, P153, DOI 10.1016/j.gmod.2009.02.002
   Liu N, 2011, COMPUT ANIMAT VIRT W, V22, P115, DOI 10.1002/cav.412
   Martin S, 2008, COMPUT GRAPH FORUM, V27, P1521, DOI 10.1111/j.1467-8659.2008.01293.x
   Molino N, 2004, ACM T GRAPHIC, V23, P385, DOI 10.1145/1015706.1015734
   Nienhuys H.W., 2001, Supporting cuts and finite element deformation in interactive surgery simulation
   Nienhuys Han-Wen., 2000, EUROGRAPH SHORT PRES, P43
   Organ D, 1996, COMPUT MECH, V18, P225
   Otaduy MA, 2007, IEEE VIRT REAL C
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Pietroni N, 2009, VISUAL COMPUT, V25, P227, DOI 10.1007/s00371-008-0216-1
   Steinemann D, 2009, GRAPH MODELS, V71, P209, DOI 10.1016/j.gmod.2008.12.004
   Thomas L, 2006, COMPUTER GRAPHICS, V30, P450
   Wicke M, 2007, COMPUT GRAPH FORUM, V26, P355, DOI 10.1111/j.1467-8659.2007.01058.x
   Wu W, 2004, COMPUT ANIMAT VIRT W, V15, P219, DOI 10.1002/cav.24
   Yoon SE, 2007, P EUR S REND
NR 30
TC 14
Z9 16
U1 2
U2 12
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2012
VL 23
IS 5
BP 489
EP 501
DI 10.1002/cav.1485
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 021ZW
UT WOS:000309925700005
DA 2024-07-18
ER

PT J
AU Choi, A
   De Melo, C
   Woo, W
   Gratch, J
AF Choi, Ahyoung
   De Melo, Celso
   Woo, Woontack
   Gratch, Jonathan
TI Affective engagement to emotional facial expressions of embodied social
   agents in a decision-making game
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE affective engagement; physiological signal analysis; emotional facial
   expressions of agents; decision-making game
ID DILEMMA
AB Previous research illustrates that people can be influenced by the emotional displays of computer-generated agents. What is less clear is if these influences arise from cognitive or affective process (i.e., do people use agent displays as information or do they provoke user emotions). To unpack these processes, we examine the decisions and physiological reactions of participants (heart rate and electrodermal activity) when engaged in a decision task (prisoner's dilemma game) with emotionally expressive agents. Our results replicate findings that people's decisions are influenced by such emotional displays, but these influences differ depending on the extent to which these displays provoke an affective response. Specifically, we show that an individual difference known as electrodermal lability predicts the extent to whether people will engage affectively or strategically with such agents, thereby better predicting their decisions. We discuss implications for designing agent facial expressions to enhance social interaction between humans and agents. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Choi, Ahyoung; De Melo, Celso; Gratch, Jonathan] Univ So Calif, Inst Creat Technol, Los Angeles, CA 90094 USA.
   [Woo, Woontack] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Taejon 305701, South Korea.
C3 University of Southern California; Korea Advanced Institute of Science &
   Technology (KAIST)
RP Gratch, J (corresponding author), Univ So Calif, Inst Creat Technol, 12015 Waterfront Dr, Los Angeles, CA 90094 USA.
EM gratch@ict.usc.edu
RI Woo, Woontack/C-3696-2012; CHOI, AHYOUNG/T-5490-2019
OI Woo, Woontack/0000-0002-5501-4421; 
FU Global Frontier R&D Program on Human-Centered Interaction for
   Coexistence; NRF/MEST, Korea [NRF-M1AXA003-2011-0028361]; Air Force
   Office of Scientific Research [AFOSR FA9550-09-1-0507]
FX This work was supported by the Global Frontier R&D Program on
   Human-Centered Interaction for Coexistence funded by the NRF/MEST, Korea
   (NRF-M1AXA003-2011-0028361), and the Air Force Office of Scientific
   Research under grant AFOSR FA9550-09-1-0507. We especially thank Sin-hwa
   Kang and Peter Khooshabeh for their contribution on the usability
   testing and the psychological advice for this paper.
CR Arellano D, 2008, COMPUT ANIMAT VIRT W, V19, P259, DOI 10.1002/cav.234
   Barrett LF, 1998, J PERS SOC PSYCHOL, V74, P967, DOI 10.1037/0022-3514.74.4.967
   Beale R, 2009, INT J HUM-COMPUT ST, V67, P755, DOI 10.1016/j.ijhcs.2009.05.001
   Bechara A, 2000, CEREB CORTEX, V10, P295, DOI 10.1093/cercor/10.3.295
   Bechara A, 2005, GAME ECON BEHAV, V52, P336, DOI 10.1016/j.geb.2004.06.010
   Bente G, 1996, J NONVERBAL BEHAV, V20, P213, DOI 10.1007/BF02248674
   Dawson ME., 2017, Handbook of Psychophysiology, V4, P217, DOI [DOI 10.1017/9781107415782, 10.1017/9781107415782.010]
   de Melo CM, 2011, PRESENCE-TELEOP VIRT, V20, P449, DOI 10.1162/PRES_a_00062
   de Melo CelsoM., 2011, 10 INT C AUTONOMOUS, V3, P937
   Frank R., 2004, FEELINGS EMOTIONS, P422
   Gradley MM, 2000, EMOTION MOTIVATION, P602
   HARUNO M, 2009, NAT NEUROSCI, V13, P160, DOI DOI 10.1038/NN.2468
   Hudlicka E, 2003, INT J HUM-COMPUT ST, V59, P1, DOI 10.1016/S1071-5819(03)00047-8
   KATKIN ES, 1985, PSYCHOPHYSIOLOGY, V22, P125, DOI 10.1111/j.1469-8986.1985.tb01573.x
   Kiesler S, 1996, J PERS SOC PSYCHOL, V70, P47, DOI 10.1037/0022-3514.70.1.47
   Kopelman S, 2006, ORGAN BEHAV HUM DEC, V99, P81, DOI 10.1016/j.obhdp.2005.08.003
   Osumi T, 2009, INT J PSYCHOPHYSIOL, V74, P74, DOI 10.1016/j.ijpsycho.2009.07.007
   Pelachaud C, 2002, J VISUAL COMP ANIMAT, V13, P301, DOI 10.1002/vis.299
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Pillutla MM, 1996, ORGAN BEHAV HUM DEC, V68, P208, DOI 10.1006/obhd.1996.0100
   Prendinger H, 2005, INT J HUM-COMPUT ST, V62, P231, DOI 10.1016/j.ijhcs.2004.11.009
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Riegelsberger J, 2003, INT J HUM-COMPUT ST, V58, P759, DOI 10.1016/S1071-5819(03)00042-9
   Rilling JK, 2008, NEUROPSYCHOLOGIA, V46, P1256, DOI 10.1016/j.neuropsychologia.2007.11.033
   Sanfey AG, 2003, SCIENCE, V300, P1755, DOI 10.1126/science.1082976
   Scharlemann JPW, 2001, J ECON PSYCHOL, V22, P617, DOI 10.1016/S0167-4870(01)00059-9
   Van Kleef GA, 2010, ADV EXP SOC PSYCHOL, V42, P45, DOI 10.1016/S0065-2601(10)42002-X
   van't Wout M, 2006, EXP BRAIN RES, V169, P564, DOI 10.1007/s00221-006-0346-5
   Vanhala T, 2010, COMPUT ANIMAT VIRT W, V21, P215, DOI 10.1002/cav.366
   Yuasa Masahide., 2007, CHI'07 Extended Abstracts on Human Factors in Computing Systems, P2795
NR 30
TC 11
Z9 14
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 331
EP 342
DI 10.1002/cav.1458
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100020
DA 2024-07-18
ER

PT J
AU Xu, J
   Li, X
   Ren, YC
   Geng, WD
AF Xu, Jun
   Li, Xiang
   Ren, Yangchun
   Geng, Weidong
TI Performance-driven animation of hand-drawn cartoon faces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE facial animation; animation from motion/video data; animation system;
   computer-aided inbetweening; non-photorealistic animation
AB We present a novel performance-driven approach to animating cartoon faces starting from pure 2D drawings. A 3D approximate facial model automatically built from front and side view master frames of character drawings is introduced to enable the animated cartoon faces to be viewed from angles different from that in the input video. The expressive mappings are built by artificial neural network (ANN) trained from the examples of the real face in the video and the cartoon facial drawings in the facial expression graph for a specific character. The learned mapping model makes the resultant facial animation to properly get the desired expressiveness, instead of a mere reproduction of the facial actions in the input video sequence. Furthermore, the lit sphere, capturing the lighting in the painting artwork of faces, is utilized to color the cartoon faces in terms of the 3D approximate facial model, reinforcing the hand-drawn appearance of the resulting facial animation. We made a series of comparative experiments to test the effectiveness of our method by recreating the facial expression in the commercial animation. The comparison results clearly demonstrate the superiority of our method not only in generating high quality cartoon-style facial expressions, but also in speeding up the animation production of cartoon faces. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Xu, Jun; Li, Xiang; Ren, Yangchun; Geng, Weidong] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Geng, WD (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM gengwd@zju.edu.cn
RI xiang, li/JDN-4098-2023; Xiang, Li/JQI-6805-2023; Li,
   Mengqi/AAG-6804-2021; xiang, li/JAN-7100-2023
FU NSFC [60633070, 60773183]; National 863 High-Tech Program [2006AA01Z313,
   2006AA01Z335]; National Key Technology R&D Program of China
   [2007BAH11B02, 2007BAH11B03];  [NCET-07-0743];  [PCSIRT 0652]
FX This work was partly supported by NSFC 60633070 and 60773183, National
   863 High-Tech Program (grant no: 2006AA01Z313 and 2006AA01Z335), and
   National Key Technology R&D Program of China (grant no: 2007BAH11B02 and
   2007BAH11B03). It is also supported by NCET-07-0743 and PCSIRT 0652.
CR ABRANTES GA, 1999, CIRCUITS SYSTEMS VID, P290
   Alexa M, 2003, VISUAL COMPUT, V19, P105, DOI 10.1007/s00371-002-0180-0
   [Anonymous], P ACM MULT
   [Anonymous], P 1 INT S NON PHOT A
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   BOUGUET YJ, 2002, PYRAMIDAL IMPLEMENTA
   BUCK I, 2002, 1 INT S NONPH AN REN
   Chai Jin-xiang., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. SCA'03, P193
   Chen H, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE 11TH USENIX SECURITY SYMPOSIUM, P171
   CHUANG E., 2002, PERFORMANCE DRIVEN F
   Di Fiore F, 2001, COMP ANIM CONF PROC, P192, DOI 10.1109/CA.2001.982393
   Di Fiore F, 2002, COMP ANIM CONF PROC, P183, DOI 10.1109/CA.2002.1017532
   DIFIORE F, 2005, P COMP AN SOC AG CAS, P73
   DIFIORE F, 2003, P 1 INT C COMP GRAPH, P21
   DYN N, 1990, ACM T GRAPHIC, V9, P160, DOI 10.1145/78956.78958
   ERSOTELOS N, 2007, INT J COMPUTER GRAPH, V24, P13
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Kouadio C, 1998, COMP ANIM CONF PROC, P128, DOI 10.1109/CA.1998.681917
   Liang L, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P386, DOI 10.1109/PCCGA.2002.1167882
   Liu JF, 2005, LECT NOTES COMPUT SC, V3768, P1027
   Luo, 2006, INT C COMP GRAPH IM, P514
   Milborrow S., 2007, THESIS
   Peter-Pike J.Sloan., 2001, PROC GRAPH INTERFACE, P143
   Qiu J, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P175
   Rumelhart D.E., 1988, Nature, P696
   THRISSON KR, 1996, TOONFACE SYSTEM CREA
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   WONSOOK L, 2006, HDB VIRTUAL HUMANS, P26
   ZHU L, 2006, COMPUTER ANIMATION S
NR 32
TC 1
Z9 1
U1 0
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2011
VL 22
IS 5
BP 471
EP 483
DI 10.1002/cav.372
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856HY
UT WOS:000297631000007
DA 2024-07-18
ER

PT J
AU van Basten, BJH
   Egges, A
   Geraerts, R
AF van Basten, B. J. H.
   Egges, A.
   Geraerts, R.
TI Combining path planners and motion graphs
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; distance metrics; motion capture; motion synthesis;
   path planning
ID PERCEPTION; ANIMATION
AB Natural locomotion of virtual characters is very important in games and simulations. The naturalness of the total motion strongly depends on both the path the character chooses and the animation of the walking character. Therefore, much work has been done on path planning and generating walking animations. However, the combination of both fields has received less attention. Combining path planning and motion synthesis introduces several problems. In this paper, we will identify two problems and propose possible solutions. The first problem is selecting an appropriate distance metric for locomotion synthesis. When concatenating clips of locomotion, a distance metric is required to detect good transition points. We have evaluated three common distance metrics both quantitatively (in terms of footskating, path deviation and online running time) and qualitatively (user study). Based on our observations, we propose a set of guidelines when using these metrics in a motion synthesizer. The second problem is the fact that there is no single point on the body that can follow the path generated by the path planner without causing unnatural animations. This raises the question how the character should follow the path. We will show that enforcing the pelvis to follow the path will lead to unnatural animations and that our proposed solution, which uses path abstractions, generates significantly better animations. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [van Basten, B. J. H.; Egges, A.; Geraerts, R.] Univ Utrecht, Ctr Adv Gaming & Simulat, NL-3508 TB Utrecht, Netherlands.
C3 Utrecht University
RP van Basten, BJH (corresponding author), Univ Utrecht, Ctr Adv Gaming & Simulat, POB 80-089, NL-3508 TB Utrecht, Netherlands.
EM basten@cs.uu.nl
RI Geraerts, Roland/B-3859-2016
OI Geraerts, Roland/0000-0002-8161-579X
FU Netherlands Organization for Scientific Research (NWO); Netherlands ICT
   Research and Innovation Authority (ICT Regie); Metaverse1 project
FX This research has been supported by the GATE project, funded by the
   Netherlands Organization for Scientific Research (NWO) and the
   Netherlands ICT Research and Innovation Authority (ICT Regie). Part of
   this research has been funded by the Metaverse1 project.
CR [Anonymous], 4 INT C FDN DIG GAM
   [Anonymous], IEEE INT S INT CONTR
   [Anonymous], 2012, Robot Motion Planning
   ARECHAVALETA G, 2006, INT C BIOM ROB BIOM, P158
   ARIKAN O, 2002, SIGGRAPH 02, P483
   Barraquand J, 1997, INT J ROBOT RES, V16, P759, DOI 10.1177/027836499701600604
   Barraquand Jerome., 1991, Automatic motion planning of complex articulated bodies
   Boulic R., 1990, Visual Computer, V6, P344, DOI 10.1007/BF01901021
   Boulic R, 2008, LECT NOTES COMPUT SC, V5277, P176
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Chua PT, 2003, P IEEE VIRT REAL ANN, P87
   Egges A, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P121, DOI 10.1109/PCCGA.2004.1348342
   FORBES K, 2005, ACM SIGGRAPH EUR S C
   Geraerts R, 2007, INT J ROBOT RES, V26, P845, DOI 10.1177/0278364907079280
   Geraerts R, 2007, COMPUT ANIMAT VIRT W, V18, P107, DOI 10.1002/cav.166
   GLEICHER M, 2001, I3D 01, P195
   Grassia F. S., 1998, J. Graph. Tools, V6, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Hodgin Jessica K., 1995, Proceedings of the ACM SIGCHI Conference on Computer Graphics and Interactive Techniques, P71
   Hodgins JK, 1998, IEEE T VIS COMPUT GR, V4, P307, DOI 10.1109/2945.765325
   Ikemoto L, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P145
   Ikemoto Leslie, 2006, P 2006 S INT 3D GRAP, P49
   Kamphuis A., 2004, SCA '04: Proceedings of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P19
   KAMPHUIS A, 2005, P EUR ACM SIGGRAPH S, P8
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar Lucas., 2002, SCA 2002: Proceedings of the 2002 ACM SIG-GRAPH/Eurographics Symposium on Computer Animation, P97
   Kuffner J. J.  Jr., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P995, DOI 10.1109/ROBOT.2000.844730
   KWON T., 2005, SCA 05, P29
   Lamouret A., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P199
   Lau M., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA '05, P271
   Lau Manfred., 2006, P ACM SIGGRAPHEUROGR, P299
   Lee J.J., 2002, P491
   LI L, 2008, P EUROGRAPHICS
   LOWE DG, 1988, P 2 INT C COMP VIS, P558
   MATSUNAGA M, 2007, COMPUTER GRAPHICS IN
   Multon F, 1999, J VISUAL COMP ANIMAT, V10, P39, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<39::AID-VIS195>3.0.CO;2-2
   *OGRE, 2008, OP SOURC 3D GRAPH EN
   Park SI., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. SCA2, P105, DOI DOI 10.1145/545261.545279
   Pettré J, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P3048, DOI 10.1109/IRDS.2002.1041736
   PETTRE J, 2003, P 2003 ACM SIGGRAPH, P258
   Pettré J, 2006, COMPUT ANIMAT VIRT W, V17, P445, DOI 10.1002/cav.147
   Reitsma PSA, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289609
   Reitsma PSA, 2003, ACM T GRAPHIC, V22, P537, DOI 10.1145/882262.882304
   Ren L, 2005, ACM T GRAPHIC, V24, P1090, DOI 10.1145/1073204.1073316
   ROSE C, 1996, SIGGRAPH 96, P147
   ROSIN PL, 1992, PATTERN RECOGN, V25, P1315, DOI 10.1016/0031-3203(92)90144-8
   Safonova A., 2005, Dans SCA '05, P171
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   SAUNDERS JBDM, 1953, J BONE JOINT SURG AM, V35-A, P543, DOI 10.2106/00004623-195335030-00003
   Singh S, 2009, COMPUT ANIMAT VIRT W, V20, P533, DOI 10.1002/cav.277
   So CKF, 2005, COMPUT ANIMAT VIRT W, V16, P225, DOI 10.1002/cav.107
   Srinivasan Madhusudhanan., 2005, P GRAPHICS INTERFACE, P51
   SUNG M., 2005, SCA 05, P291
   Tang JKT, 2008, COMPUT ANIMAT VIRT W, V19, P211, DOI 10.1002/cav.260
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
   van Basten Ben JH, 2009, P 4 INT C FDN DIGITA, P199
   VANWELBERGEN H, 2009, REAL TIME ANIMATION, P45
   Wang J., 2003, Dans SCA '03, P232
   WANG J, 2004, 2004 ACM SIGGRAPH EU, P337
   Wiley DJ, 1997, IEEE COMPUT GRAPH, V17, P39, DOI 10.1109/38.626968
   YOSHIDA E, 2008, MOTION GAMES, P221
   *YOYO GAM, GAM MAK
   Zhang LJ, 2009, LECT NOTES COMPUT SC, V5884, P138, DOI 10.1007/978-3-642-10347-6_13
NR 66
TC 1
Z9 1
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2011
VL 22
IS 1
BP 59
EP 78
DI 10.1002/cav.387
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 727SD
UT WOS:000287820600006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU van Vugt, HC
   Hoorn, JF
   Konijn, EA
AF van Vugt, H. C.
   Hoorn, J. F.
   Konijn, E. A.
TI Interactive engagement with embodied agents: an empirically validated
   framework
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE embodied agents; virtual characters; user engagement; use intentions;
   end-user satisfaction; empirical researsch
ID USER ACCEPTANCE; BEAUTIFUL
AB This paper presents an empirically tested theoretical framework to explain user engagement and end-user satisfaction with interactive agents. Such a framework is not only important from a scientific point of view; application designers may find a set of dos and don'ts that help them create more satisfying embodied agents in different task domains and social settings. From a multidisciplinary perspective, we have conducted a series of experiments to verify underlying mechanisms in the processes of interacting and engaging With embodied agents in various task domains. Our results show that the most commonly held views art, not always tenable; sometimes other factors provide better explanations for liking an embodied agent or end-user satisfaction. For example, it is not realism but rather affordances and ethics that are key for understanding user responses, and a beautiful design is not always the most preferable. Front our results, guidelines for designers and future research are reflected upon. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Hoorn, J. F.] Vrije Univ Amsterdam, CAMeRA, NL-1081 HV Amsterdam, Netherlands.
   [van Vugt, H. C.] Philips Res, User Experiences Dept, Eindhoven, Netherlands.
   [van Vugt, H. C.] Vrije Univ Amsterdam, Dept Commun Sci, NL-1081 HV Amsterdam, Netherlands.
   [van Vugt, H. C.] Vrije Univ Amsterdam, Dept Comp Sci, NL-1081 HV Amsterdam, Netherlands.
   [van Vugt, H. C.] Univ Utrecht, NL-3508 TC Utrecht, Netherlands.
C3 Vrije Universiteit Amsterdam; Philips; Philips Research; Vrije
   Universiteit Amsterdam; Vrije Universiteit Amsterdam; Utrecht University
RP Hoorn, JF (corresponding author), Vrije Univ Amsterdam, CAMeRA, Boelelaan 1081, NL-1081 HV Amsterdam, Netherlands.
EM jf.hoorn@camera.vu.nl
RI Konijn, Elly A./L-8729-2013
OI Hoorn, Johan/0000-0002-3427-5681; Camera, Franco/0000-0003-1731-4834
CR CACIOPPO JT, 1994, PSYCHOL BULL, V115, P401, DOI 10.1037/0033-2909.115.3.401
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dehn DM, 2000, INT J HUM-COMPUT ST, V52, P1, DOI 10.1006/ijhc.1999.0325
   DION K, 1972, J PERS SOC PSYCHOL, V24, P285, DOI 10.1037/h0033731
   ETKOFF N, 1999, SURVIVAL PRETTIEST S
   Han SH, 2003, ERGONOMICS, V46, P1441, DOI 10.1080/00140130310001610928
   Harris LT, 2008, SOC COGNITION, V26, P210, DOI 10.1521/soco.2008.26.2.210
   HOORN JF, 2003, UPGRADE HUMAN COMPUT, V4, P18
   Klohnen EC, 2003, J PERS SOC PSYCHOL, V85, P709, DOI 10.1037/0022-3514.85.4.709
   Konijn EA, 2005, MEDIA PSYCHOL, V7, P107, DOI 10.1207/S1532785XMEP0702_1
   Konijn EA, 2007, MEDIA PSYCHOL, V9, P157, DOI 10.1080/15213260709336807
   LARKIN JC, 1979, SOCIOL WORK OCCUP, V6, P312, DOI 10.1177/073088847900600303
   MCGRENERE J, P GRAPH INT 2000, P179
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Newton Kenneth., 2007, The_Oxford_Handbook_of_Political_Behavior, P343
   Norman D., 2002, INTERACTIONS, V9, P36, DOI [10.1145/543434.543435, DOI 10.1145/543434.543435]
   Stunkard A.J., 1983, GENETICS NEUROLOGICA, P115
   Tractinsky N, 2000, INTERACT COMPUT, V13, P127, DOI 10.1016/S0953-5438(00)00031-X
   Tractinsky N., 2004, P 25 ANN INT C INFOR, P771
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   van Vugt HC, 2007, INTERACT COMPUT, V19, P267, DOI 10.1016/j.intcom.2006.08.005
   van Vugt HC, 2006, INT J HUM-COMPUT ST, V64, P874, DOI 10.1016/j.ijhcs.2006.04.008
   VANVUGT HC, 2009, T COMPUTER HUMAN INT
   VANVUGT HC, 2009, INT J HUMAN COMPUTER
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 26
TC 21
Z9 21
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 195
EP 204
DI 10.1002/cav.312
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700013
DA 2024-07-18
ER

PT J
AU Lai, CH
   Wu, JL
AF Lai, Chao-Hung
   Wu, Jiunn-Lin
TI Temporal texture synthesis by patch-based sampling and morphing
   interpolation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE minimum error cut; temporal texture synthesis; morphing interpolation;
   color transfer
ID VIDEO SYNTHESIS
AB We present a new algorithm for synthesizing temporal textures, which is simple and requires only a static texture image as input to produce a continuous varying stream of realistic images. We first introduce the basis sequence generation procedure in which the chosen patches from the input texture image are stitched on the output frame via blended alpha mattes formed by minimum error cuts. All the frames in the generated basis sequence are toroidal. We then employ the probabilities of similarity and transition links to generate an inexhaustible sequence with quasi-periodic quality. To ensure the smoothness of frame-to-frame transition, we interpolate natural metamorphosis in each transition link using the efficient automatic morphing technique which solves the problem of morphing between chaotic textures with obscure features. In addition, the proposed method allows users to simply and promptly control the motion parameters and interactively render the landscape animations. We combine the proposed approach with the color transfer technique to augment the visual gratification. Several examples including scenes for cloud, fire, and water are presented to demonstrate that the proposed algorithm is simple, efficient, and controllable for synthesizing temporal textures. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 402, Taiwan.
C3 National Chung Hsing University
RP Lai, CH (corresponding author), Natl Chung Hsing Univ, Dept Comp Sci & Engn, No 250 Kuang Rd, Taichung 402, Taiwan.
EM phd9415@cs.nchu.edu.tw
OI Wu, Jiunn-Lin/0000-0003-4046-8196
CR Bhat KS, 2004, ACM T GRAPHIC, V23, P360, DOI 10.1145/1015706.1015729
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   JOSEPH ZB, 2001, IEEE T VIS COMPUTER, V7, P120
   KANG T, 1999, MSRTR9980
   Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lai CH, 2006, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER SCIENCE AND TECHNOLOGY, P180
   Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787
   Liu ZQ, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P184, DOI 10.1109/PCCGA.2002.1167854
   Matusik W, 2005, ACM T GRAPHIC, V24, P787, DOI 10.1145/1073204.1073262
   Nealen A, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P582, DOI 10.1109/CGI.2004.1309268
   Perlin K, 2002, ACM T GRAPHIC, V21, P681, DOI 10.1145/566570.566636
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Shirley P., 2000, REALISTIC RAY TRACIN
   Tessendorf J., 2001, Simulating Nature: Realistic and Interactive Techniques. SIGGRAPH 2001 Course Notes 47
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Wei XM, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P227, DOI 10.1109/VISUAL.2002.1183779
   Wu Q, 2004, ACM T GRAPHIC, V23, P364, DOI 10.1145/1015706.1015730
NR 22
TC 3
Z9 4
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 415
EP 428
DI 10.1002/cav.195
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000020
DA 2024-07-18
ER

PT J
AU Peng, JY
   Lin, IC
   Chao, JH
   Chen, YJ
   Juang, GH
AF Peng, Jen-Yu
   Lin, I-Chen
   Chao, Jui-Hsiang
   Chen, Yan-Ju
   Juang, Gwo-Hao
TI Interactive and flexible motion transition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE motion synthesis; motion capture; transition
AB In this paper, we present an example-based motion synthesis technique. Users can interactively control the virtual character to perform desired actions in any order. The desired action can be not only recorded or pre-computed motion, but also parametric synthesized one to attain the precise control of avatars. Moreover, a user can change their commands any time to switch to another action according to the instant response of opponents infighting. The quality transition motions between consecutive actions are rapidly synthesized through traversing a simple graph structure which represents the transition relationships between different poses. The graph is constructed according to clustering on frames in a corpus of motion capture data. With the pre-computation of path finding, our approach can also be applied to real-time applications. Besides, this pre-computed graph structure can be used to transit those motions not included in the database. Furthermore, our approach is automatic without any human intervention. The final results demonstrate the potential of our algorithm. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lin, IC (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM ichenlin@cs.nctu.edu.tw
OI Lin, I-Chen/0000-0001-9924-4723
CR [Anonymous], 2007, P S INT 3D GRAPH GAM
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   GLARDON P, 2004, COMPUTER ANIMATION S, P73
   GLEICHER M, 2003, ACM S INT 3D GRAPH, P181
   IKEMOTO L, 2006, ACM S INT 3D GRAPH, P49
   IKEMOTO L, 2007, P S INT 3D GRAPH GAM
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Kovar Lucas., 2002, SCA 2002: Proceedings of the 2002 ACM SIG-GRAPH/Eurographics Symposium on Computer Animation, P97
   LEE J, 1979, P S COMP AN
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Park SI, 2004, COMPUT ANIMAT VIRT W, V15, P125, DOI 10.1002/cav.15
   REITSMA PSA, 2004, P 2004 ACM SIGGRAPH, P89
   Ren L, 2005, ACM T GRAPHIC, V24, P1090, DOI 10.1145/1073204.1073316
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Safonova A., 2005, Dans SCA '05, P171
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Shin H.J., 2006, Proceedings of ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P291
   Unuma M., 1995, P 22 ANN C COMPUTER, P91, DOI DOI 10.1145/218380.218419
   WANG J, 2003, P S COMP AN, P234
   Wang JC, 2004, IEEE SENSOR, P337, DOI 10.1109/ICSENS.2004.1426171
   Wiley DJ, 1997, IEEE COMPUT GRAPH, V17, P39, DOI 10.1109/38.626968
NR 25
TC 5
Z9 6
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 549
EP 558
DI 10.1002/cav.208
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000033
DA 2024-07-18
ER

PT J
AU Bouras, CJ
   Panagopoulos, A
   Tsiatsos, T
AF Bouras, CJ
   Panagopoulos, A
   Tsiatsos, T
TI Implementation of 3D mesh streaming and compression techniques in NVEs
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D streaming; spatial partitioning; compression; networked virtual
   environments; high performance 3D graphics for distributed environments
AB In this paper, we present a framework that integrates three-dimensional OD) mesh streaming and compression techniques and algorithms into our EVE-II networked virtual environments (NVEs) platform, in order to offer support for large-scale environments as well as highly complex world geometry. This framework allows the partial and progressive transmission of 3D worlds as well as of separate meshes, achieving reduced waiting times for the end-user and improved network utilization. We also present a 3D mesh compression method focused on network communication, which is designed to support progressive mesh transmission, offering a fast and effective means of reducing the storage and transmission needs for geometrical data. This method is integrated in the above framework and utilizes prediction to achieve efficient lossy compression of 3D geometry. Copyright (C) 2006 John Wiley & Sons, Ltd.
C1 Res Acad Comp Technol Inst, Res Unit 6, Patras, Greece.
   Univ Patras, Comp Engn & Informat Dept, GR-26110 Patras, Greece.
C3 University of Patras
RP Bouras, CJ (corresponding author), Res Acad Comp Technol Inst, Res Unit 6, Patras, Greece.
EM bouras@cti.gr
RI Tsiatsos, Thrasyvoulos/W-5386-2019
OI Tsiatsos, Thrasyvoulos/0000-0002-4946-9585
CR Alliez P, 2001, COMP GRAPH, P195, DOI 10.1145/383259.383281
   Bouras C, 2004, J NETW COMPUT APPL, V27, P91, DOI 10.1016/j.jnca.2003.10.002
   BOURAS C, 2004, P 10 INT C DISTR MUL
   BOURAS C, 2006, IN PRESS INT J MULTI
   Cohen-Or D., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P67
   DEERING M, 1995, ACM SIGGRAPH, P13
   Diehl S., 2001, DISTRIBUTED VIRTUAL
   Guéziec A, 1999, IEEE COMPUT GRAPH, V19, P68, DOI 10.1109/38.749125
   GUMHOLD S, 1998, SIGGRAPH 98 C P, P133, DOI DOI 10.1145/280814.280836
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Isenburg M, 2005, COMPUT AIDED DESIGN, V37, P869, DOI 10.1016/j.cad.2004.09.015
   Isenburg M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P141, DOI 10.1109/VISUAL.2002.1183768
   ISENBURG M, 2005, UCRLCONF201992 LAWR
   KARNI Z, 2002, IEEE VIS C P
   Kronrod B, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P602, DOI 10.1109/TDPVT.2002.1024124
   LEE H, 2002, EUR 02 C P, P383
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   SORKINE O, 2003, P EUR S GEOM PROC
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   TAUBIN G, 1996, RC20340 IBM
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
NR 21
TC 3
Z9 3
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2006
VL 17
IS 2
BP 127
EP 140
DI 10.1002/cav.112
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040JO
UT WOS:000237375000005
DA 2024-07-18
ER

PT J
AU Wang, CB
   Wang, ZY
   Zhou, Q
   Song, CF
   Guan, Y
   Peng, QS
AF Wang, CB
   Wang, ZY
   Zhou, Q
   Song, CF
   Guan, Y
   Peng, QS
TI Dynamic modeling and rendering of grass wagging in wind
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE grass wagging in wind; dynamic modeling; skeleton line; real time;
   collision detection
AB Simulation of dynamic natural scene is one of the most challenging tasks in computer graphics. In this paper, we propose a new approach to dynamic modeling and rendering of grasses wagging in wind. Through length preserving free-form deformation of the 3D skeleton lines of each grass blade and using the alpha test to implement transparent texture mapping, we successfully model grasses of different shapes with rich details. To simulate the real time waggle of grasses, the grasses of a meadow are represented in LOD, while their skeleton lines are dynamically deformed according to some physical models. Simplification technique is also employed to accelerate the collision detection between neighboring grasses. Experiments show that our method can realistically render the animated grass scenes under wind of different speeds and types in real time. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM cbwang@cad.zju.edu.cn
RI Zhou, Hong/JKJ-1067-2023
CR BAKAY B, 2002, P EUR 2002, P52
   Coquillart S., 1990, J. Computer Graphics, V24, P187, DOI DOI 10.1145/97880.97900
   DEUSSEN O, 1998, P SIGGRAPH 98, P275, DOI DOI 10.1145/280814.280898
   DEUSSEN O, 2002, P IEEE VIS 2002, P120
   GUERRAZ S, 2003, P COMP AN SOC AG, V25, P73
   HART J, 2001, COMPUTER GRAPHICS, V25, P91
   Kajiya J. T., 1989, Computer Graphics, V23, P271, DOI 10.1145/74334.74361
   Lindholm E, 2001, COMP GRAPH, P149, DOI 10.1145/383259.383274
   MEYER A, 1998, EUR REND WORKSH 1998, P157
   Neyret F, 1996, EUR REND WORKSH, P215
   Perbet F., 2001, Objavljeno v Proceedings of the 2001 Symposium on Interactive 3D Graphics, I3D'01, strani, P103
   Reeves W. T., 1985, Computer Graphics, V19, P313, DOI 10.1145/325165.325250
   STAM J, 1997, STOCH DYNAM, V16, P159
NR 13
TC 8
Z9 10
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 377
EP 389
DI 10.1002/cav.91
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000022
DA 2024-07-18
ER

PT J
AU Yu, T
   Shen, XJ
   Li, QL
   Geng, WD
AF Yu, T
   Shen, XJ
   Li, QL
   Geng, WD
TI Motion retrieval based on movement notation language
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE motion retrieval; character animation; movement notation
AB With the increased availability of motion capture data, the volume of motion library grows so large that it is difficult for animators to manually browse the dataset to search desired motions for reuse. To address this issue, we implement a framework, which allows the user to retrieve motions via Labanotation. For each motion clip in the library, we generate a corresponding Labanotation sequence as additional motion property. A similarity metric for Labanotation sequences is proposed and used to search the motions that have similar Laban descriptions. Our search algorithm is able to retrieve motion segments that only match part of the query Laban sequence. Then based on dynamic programming, these segments are stitched together to form a smooth output motion that is in an optimal sense of matching query Laban sequence. Experimental results demonstrate our method could effectively improve the utilization of motion data. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, Coll Comp Sci, Dept Comp Sci & Technol, Hangzhou 310027, Peoples R China.
   Zhejiang Univ, Dept Comp Sci, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Zhejiang Univ, Coll Comp Sci, Dept Comp Sci & Technol, Hangzhou 310027, Peoples R China.
EM gengwd@zju.edu.cn
CR ARIKAN O, 2003, P ACM SIGGRAPH, P402
   ARIKAN O, 2002, P 29 ANN C COMP GRAP, P483
   Calvert T, 2005, IEEE COMPUT GRAPH, V25, P6, DOI 10.1109/MCG.2005.33
   Chao SP, 2004, COMPUT ANIMAT VIRT W, V15, P259, DOI 10.1002/cav.28
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Guest Ann Hutchinson, 1987, LABANOTATION SYSTEM
   Hachimura K, 2001, ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P122, DOI 10.1109/ROMAN.2001.981889
   Hsu Eugene, 2004, P ACM SIGGRAPH EUR S, P69, DOI DOI 10.1145/1028523.1028534
   Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   PULLEN K, 2002, P 29 ANN C COMP GRAP, P501
   SAKAMOTO Y, 2004, P 2004 ACM SIGGRAPH, P259
   SAKOE H, 1998, IEEE T ACOUSTICS SPE, V11, P43
   YAMANE K, 2004, P SIGGR 04, P532
NR 14
TC 23
Z9 26
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 273
EP 282
DI 10.1002/cav.89
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000013
DA 2024-07-18
ER

PT J
AU De Silva, PR
   Bianchi-Berthouze, N
AF De Silva, PR
   Bianchi-Berthouze, N
TI Modeling human affective postures: an information theoretic
   characterization of posture features
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
ID BASIC EMOTIONS
AB One of the challenging issues in affective computing is to give a machine the ability to recognize the mood of a person. Efforts in that direction have mainly focused on facial and oral cues. Gestures have been recently considered as well, but with less success. Our aim is to fill this gap by identifying and measuring the saliency of posture features that play a role in affective expression. As a case study, we collected affective gestures from human subjects using a motion capture system. We first described these gestures with spatial features, as suggested in studies on dance. Through standard statistical techniques, we verified that there was a statistically significant correlation between the emotion intended by the acting subjects, and the emotion perceived by the observers. We used Discriminant Analysis to build affective posture predictive models and to measure the saliency of the proposed set of posture features in discriminating between 4 basic emotional states: angry, fear, happy, and sad. An information theoretic characterization of the models shows that the set of features discriminates well between emotions, and also that the models built over-perform the human observers. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Aizu, Database Syst Lab, Aizu Wakamatsu 9658580, Japan.
C3 University of Aizu
RP Univ Aizu, Database Syst Lab, Aizu Wakamatsu 9658580, Japan.
EM nadia@u-aizu.ac.jp
OI Berthouze, Nadia/0000-0001-8921-0044
CR [Anonymous], IEEE WORKSH COMP VIS
   Beintema JA, 2002, P NATL ACAD SCI USA, V99, P5661, DOI 10.1073/pnas.082483699
   BIANCHIBERTHOUZ.N, 2004, CONNECT SCI, V1, P259
   Coulson M, 2004, J NONVERBAL BEHAV, V28, P117, DOI 10.1023/B:JONB.0000023655.25550.be
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   KIMIHIRO S, 2003, J NONVERBAL BEHAV, V27, P43
   Lachenbruch P.A., 1975, DISCRIMINANT ANAL
   NEAGLE RJ, 2003, P VIS VID GRAPH C VV, P181
   PANKSEPP J, 1992, PSYCHOL REV, V99, P554, DOI 10.1037/0033-295X.99.3.554
   PATERSON HM, 2000, P 23 ANN C COGN SCI
   Santello M, 1998, J NEUROSCI, V18, P10105
   SHANNON CE, 1948, BELL SYST TECH J, V27, P1137
   von Laban R., MASTERY MOVEMENT
   WOO W, 2000, P JCIS CVPRIP 00, V2, P374
   2002, P INT IEEE C AUT FAC
NR 15
TC 64
Z9 72
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 269
EP 276
DI 10.1002/cav.29
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700016
DA 2024-07-18
ER

PT J
AU Wu, EH
   Liu, YQ
   Liu, XH
AF Wu, EH
   Liu, YQ
   Liu, XH
TI An improved study of real-time fluid simulation on GPU
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE graphics hardware; GPLF; programmability; NSEs; fluid simulation;
   real-time
AB Taking advantage of the parallelism and programmability of GPU, we solve the fluid dynamics problem completely on GPU. Different from previous methods, the whole computation is accelerated in our method by packing the scalar and vector variables into four channels of texels. In order to be adaptive to the arbitrary boundary conditions, we group the grid nodes into different types according to their positions relative to obstacles and search the node that determines the value of the current node. Then we compute the texture coordinates offsets according to the type of the boundary condition of each node to determine the corresponding variables and achieve the interaction of flows with obstacles set freely by users. The test results prove the efficiency of our method and exhibit the potential of GPU for general-purpose computations. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Chinese Acad Sci, Comp Sci Lab, Inst Software, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS
RP Chinese Acad Sci, Comp Sci Lab, Inst Software, Beijing, Peoples R China.
EM ehwu@umac.mo
RI Liu, Youquan/C-1628-2012
CR [Anonymous], P C GRAPH HARDW
   [Anonymous], P ACM SIGGRAPH EUROG
   [Anonymous], P 20 ANN C COMP GRAP
   Bolz J, 2003, ACM T GRAPHIC, V22, P917, DOI 10.1145/882262.882364
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   FOSTER N, 1996, P SIGGRAPH, P23
   Harris M., 2002, ACM SIGGRAPHEUROGRAP, P109
   Harris M. J., 2003, THESIS
   Kim T, 2003, P 2003 ACM SIGGRAPH, P86
   Krüger J, 2003, ACM T GRAPHIC, V22, P908, DOI 10.1145/882262.882363
   Lefohn AE, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P75, DOI 10.1109/VISUAL.2003.1250357
   Li W, 2003, VISUAL COMPUT, V19, P444, DOI 10.1007/s00371-003-0210-6
   MACEDONIA M, 2003, IEEE COMPUT, P106
   Rasmussen N, 2003, ACM T GRAPHIC, V22, P703, DOI 10.1145/882262.882335
   RUMPF M, 2001, P VIIP, P98
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
NR 18
TC 31
Z9 41
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 139
EP 146
DI 10.1002/cav.16
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700003
OA Bronze
DA 2024-07-18
ER

PT J
AU Yuan, ML
   Ong, SK
   Nee, AYC
AF Yuan, ML
   Ong, SK
   Nee, AYC
TI The virtual interaction panel: an easy control tool in augmented reality
   systems
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE augmented reality; tracking; RCE neural network; interaction
AB In this paper, we propose and develop an easy control tool called Virtual Interaction Panel (VirIP) for Augmented Reality (AR) systems, which can be used to control AR systems. This tool is composed of two parts: the design of the VirIPs and the tracking of an interaction pen using a Restricted Coulomb Energy (RCE) neural network. The VirIP is composed of some virtual buttons, which have meaningful information that can be activated by an interaction pen during the augmentation process. The interaction pen is a general pen-like object with a certain color distribution. It is tracked using a RCE network in real-time and used to trigger the VirIPs for AR systems. In our system, only one camera is used for capturing the real world. Therefore, 2D information is used to trigger the virtual buttons to control the AR systems. The proposed method is real-time because the RCE-based image segmentation for a small region is fast. It can be used to control AR systems quite easily without any annoying sensors attached to entangling cables. This proposed method has good potential in many AR applications in manufacturing, such as assembly without the need for object recognition, collaborative product design, system control, etc. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Fac Engn, Dept Mech Engn, Singapore 117576, Singapore.
RP Fac Engn, Dept Mech Engn, 9 Engn Dr 1, Singapore 117576, Singapore.
EM smayml@nus.edu.sg
RI Nee, Andrew, Y.C./C-9974-2009; Ong, SK/AAP-2918-2021
OI Ong, SK/0000-0002-9569-3350
CR Abe K, 2002, IEEE T SYST MAN CY A, V32, P536, DOI 10.1109/TSMCA.2002.804821
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   DORFMULLERULHAA.K, 2001, P 2 ACM IEEE INT S A, P29
   Gervautz M., 2008, COMPUT GRAPH FORUM, V16, P335
   Kohtake N., 2001, Personal and Ubiquitous Computing, V5, P264, DOI 10.1007/s007790170005
   LEE MY, 2003, ICAT 2003       1203
   MCDONALD C, 2003, THESIS OTTAWA CARLET
   Raghavan V, 1999, IEEE T ROBOTIC AUTOM, V15, P435, DOI 10.1109/70.768177
   REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211
   Ye GQ, 2003, IEEE SYS MAN CYBERN, P3425
   Yin XM, 2001, ROBOT AUTON SYST, V34, P235, DOI 10.1016/S0921-8890(00)00125-1
NR 12
TC 17
Z9 17
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 425
EP 432
DI 10.1002/cav.46
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700033
DA 2024-07-18
ER

PT J
AU Pan, ZG
   Wang, ZH
   Yuan, QS
   Meng, QY
   Liu, JX
   Shou, KL
   Sun, XY
AF Pan, Zhigeng
   Wang, Zihan
   Yuan, Qingshu
   Meng, Qianyu
   Liu, Jiaxin
   Shou, Kailiang
   Sun, Xiaoyan
TI A spatial augmented reality based circuit experiment and comparative
   study with the conventional one
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE circuit experiment; experimental learning; spatial augmented reality;
   virtual experiment
AB How to intuitively illustrate phenomena while retaining good operation experiences is a key issue in experimental learning. Virtual experiments with desktop environments, handheld devices, or headsets can show invisible phenomena for students. However, they are either visuo-tactile inconsistent in space or with heavy physical burdens, causing bad experiences. A spatial augmented reality (SAR) based circuit experiment is developed. It allows students to interact with 3D (three dimensional) printed tangible objects without wearing any devices, having low physical burdens. Objects' poses are tracked using Microsoft Azure Kinect and inertial measurement unit. Virtual phenomena are projected onto the tangible objects and tabletop accordingly. Physical input and virtual output space are completely fused from students' view. It also offers efficient operation manners to students. A questionnaire comparing user experiences between the SAR and conventional experiment reveals that the former has a better learning experience.
C1 [Pan, Zhigeng; Wang, Zihan; Meng, Qianyu; Liu, Jiaxin] Hangzhou Normal Univ, Alibaba Business Sch, Hangzhou, Peoples R China.
   [Yuan, Qingshu; Shou, Kailiang; Sun, Xiaoyan] Hangzhou Normal Univ, Sch Informat Sci & Technol, Hangzhou 311121, Peoples R China.
C3 Hangzhou Normal University; Hangzhou Normal University
RP Yuan, QS (corresponding author), Hangzhou Normal Univ, Sch Informat Sci & Technol, Hangzhou 311121, Peoples R China.
EM yuanqs@hznu.edu.cn
OI Yuan, Qingshu/0000-0002-9781-8057; wang, zihan/0000-0002-0662-5971
FU National Key Research and Development Program of China [2018YFB1004901];
   Natural Science Foundation of Zhejiang Province [LY19F020020]; National
   Natural Science Foundation of China [61902103]; Teaching Construction
   and Reform Project of Hangzhou Normal University [2021]
FX National Key Research and Development Program of China, Grant/Award
   Number: 2018YFB1004901; Natural Science Foundation of Zhejiang Province,
   Grant/Award Number: LY19F020020; National Natural Science Foundation of
   China, Grant/Award Number: 61902103; Teaching Construction and Reform
   Project of Hangzhou Normal University, Grant/Award Number: 2021
CR Alvarez-Marín A, 2021, IEEE REV IBEROAM TEC, V16, P187, DOI 10.1109/RITA.2021.3089917
   [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   [Anonymous], 2016, BEIJING LEBEAU ED TE
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   De Raffaele C, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON TEACHING, ASSESSMENT, AND LEARNING FOR ENGINEERING (TALE), P194, DOI 10.1109/TALE.2016.7851794
   Duan XY, 2020, KSII T INTERNET INF, V14, P1673, DOI 10.3837/tiis.2020.04.014
   Fan M, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188576
   Fleck S., 2016, FRONT ICT, V3, DOI [https://doi.org/10.3389/fict.2016.00030, DOI 10.3389/FICT.2016.00030]
   Gardeli A, 2019, INT CONF GAMES VIRTU, P1, DOI 10.1109/vs-games.2019.8864603
   Haoyuan Liu, 2019, 2019 IEEE International Conference on Computer Science and Educational Informatization (CSEI), P329
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   LaViola J., 2018, P 2018 3 INT C INFOR, P1
   Likert R., ARCH PSYCHOL, P1
   Nuanmeesri S, 2019, INT J ONLINE BIOMED, V15, P28, DOI 10.3991/ijoe.v15i05.9653
   [潘志庚 Pan Zhigeng], 2021, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V33, P655
   Prattico FG, 2019, IEEE ICCE, P205, DOI [10.1109/ICCE-Berlin47944.2019.8966135, 10.1109/icce-berlin47944.2019.8966135]
   Restivo MT, 2014, 2014 INTERNATIONAL CONFERENCE ON INTERACTIVE COLLABORATIVE LEARNING (ICL), P884, DOI 10.1109/ICL.2014.7017890
   Suh H, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3988, DOI 10.1145/2858036.2858448
   Sun BW, 2013, INT CONF MEASURE, P594, DOI 10.1109/MIC.2013.6758034
   Ukil M, 2014, IEEE STUDENT TECHNOL, P218, DOI 10.1109/TechSym.2014.6808050
   Valdenegro-Toro M., 2017, MOBILE ROBOTS ECMR 2, P1
   Xiangdong C., 2014, CHINA ED TECHNOL, V2014, P105
   Zacharia ZC, 2014, COGNITION INSTRUCT, V32, P101, DOI 10.1080/07370008.2014.887083
NR 23
TC 1
Z9 1
U1 0
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2069
DI 10.1002/cav.2069
EA JUN 2022
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000805663000001
DA 2024-07-18
ER

PT J
AU Khorloo, O
   Ulambayar, E
   Altantsetseg, E
AF Khorloo, Oyundolgor
   Ulambayar, Erdenebat
   Altantsetseg, Enkhbayar
TI Virtual reconstruction of the ancient city of Karakorum
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D reconstruction; cultural heritage; immersive exploration; virtual
   city; virtual reality
AB Ruins of ancient cities hold valuable information for historians and archeologists and it allows them to learn about the society and culture of these cities. This paper explores the first attempt to virtually rebuild the historic city of Karakorum based on ruins and archeological findings from the 13th century AD. Further, the analytical and practical methods used to discover its unique urban planning and architectural form by reconstructing the city using various resources from archeological documents to historical science documents are introduced. We explore a digitized version of Karakorum city in an immersive and embodied manner because of the latest technological advances in virtual reality, and this allows us to conserve and visualize its cultural heritage. The research objectives of this study are to (1) create a three-dimensional visual model of the Karakorum city as close as possible to its real counterpart, and (2) use a game engine as a development platform for integration and interactive visualization.
C1 [Khorloo, Oyundolgor; Ulambayar, Erdenebat; Altantsetseg, Enkhbayar] Natl Univ Mongolia, Univ St 3, Ulaanbaatar 14200, Mongolia.
C3 National University of Mongolia
RP Altantsetseg, E (corresponding author), Natl Univ Mongolia, Univ St 3, Ulaanbaatar 14200, Mongolia.
EM enkhbayar.a@seas.num.edu.mn
RI Erdenebat, Ulambayar/HPH-3733-2023
OI Erdenebat, Ulambayar/0000-0003-0867-3691
FU National University of Mongolia [P2018-3603]
FX National University of Mongolia, Grant/Award Number: P2018-3603
CR Albourae AT, 2017, INT ARCH PHOTOGRAMM, V42-2, P7, DOI 10.5194/isprs-archives-XLII-2-W5-7-2017
   [Anonymous], 2016, POSTCARBON CITIES
   [Anonymous], 2015, P 32 CIB W78 C
   Bemmann J., 2021, ASIAN ARCHAEOLOGY, V4, P121, DOI [10.1007/s41826-020-00039-x, DOI 10.1007/S41826-020-00039-X]
   Bemmann J, 2022, ANTIQUITY, V96, P159, DOI [10.15184/aqy.2021.153, 10.15184/agy.2021.153]
   Bemmann Jan., 2010, Mongolian-German Karakorum Expedition. Forschungen Zur Archaologie Aussereuropaischer Kulturen
   Ch'ng E, 2017, PRESENCE-VIRTUAL AUG, V26, pIII, DOI 10.1162/pres_e_00302
   Del Giudice M, 2014, ECPPM 2014 C VIENN S
   Dylla K., 2010, Computer Graphics World, Vol, V37, P62
   Erdenebat U, 2020, QARAQORUM ANCIENT CA
   Fan LB, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661265
   Ferwati MS, 2021, DIGIT APPL ARCHAEOL, V21
   Franken C, 2021, CAPITAL MONGOL EMPIR
   Grellert M, 2016, Virtual Palaces, Lost Palaces and their Afterlife. Virtual Reconstruction between Science and Media, V3, P119, DOI [10.11588/arthistoricum.83.79, DOI 10.11588/ARTHISTORICUM.83.79]
   Huang X, EXPLOITING GAME DEV
   Jackson P ., 2017, MISSION FRIAR WILLIA
   Kim S, 2020, VISUAL COMPUT, V36, P911, DOI 10.1007/s00371-019-01701-x
   Koehler T, 2008, EVALUATION CONT GAME
   Lipp M, 2011, COMPUT GRAPH FORUM, V30, P345, DOI 10.1111/j.1467-8659.2011.01865.x
   Lynch J., 2020, DIGIT APPL ARCHAEOL, V17
   Ma YP, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052101
   Soto-Martin O, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020597
   Volk R, 2014, AUTOMAT CONSTR, V38, P109, DOI 10.1016/j.autcon.2013.10.023
   Yang YL, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508405
   Youn HC, 2021, BUILDINGS-BASEL, V11, DOI 10.3390/buildings11110561
NR 25
TC 8
Z9 8
U1 4
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2087
DI 10.1002/cav.2087
EA JUN 2022
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000804470600001
DA 2024-07-18
ER

PT J
AU Kumar, PB
   Parhi, DR
   Sethy, M
AF Kumar, Priyadarshi B.
   Parhi, Dayal R.
   Sethy, Mukesh
TI Humanoid navigation: A firefly based approach
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer vision; FA; NAO; navigation; open CV; V-REP
ID MOBILE ROBOT; ALGORITHM; OPTIMIZATION; PATH
AB Humanoid navigation has been the center of attraction among robotic researchers since many years by virtue of their increasing use in industrial automation and smart manufacturing. In the current research, a firefly based computer vision integrated navigational analysis has been performed on humanoid robots for smooth movement by negotiation with obstacles present in complicated terrains. Here, the logic of the firefly algorithm has been used to design the controller by careful consideration of the navigational parameters. A computer vision based method is integrated along with the developed controller to resolve some conflicting situations that may arise by encountering large sized obstacle or detection of an obstacle exactly in front of the robot where the robot becomes confused regarding the direction of turn. The developed navigational model has been tested in simulation environments by considering NAO robot as the humanoid platform. The simulation results are also verified through an experimental platform developed under research laboratory conditions. The data obtained from both the platforms are compared in terms of navigational parameters and are found to be in close proximity to each other. Finally, the developed navigational model is also authenticated against other existing models for validating better efficiency.
C1 [Kumar, Priyadarshi B.] Natl Inst Technol Hamirpur, Mech Engn Dept, Hamirpur 177005, Himachal Prades, India.
   [Parhi, Dayal R.; Sethy, Mukesh] Natl Inst Technol Rourkela, Mech Engn Dept, Rourkela, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; National Institute of Technology (NIT System);
   National Institute of Technology Rourkela
RP Kumar, PB (corresponding author), Natl Inst Technol Hamirpur, Mech Engn Dept, Hamirpur 177005, Himachal Prades, India.
EM p.biplabkumar@gmail.com
RI Parhi, Dayal/M-7935-2018
OI Parhi, Dayal/0000-0002-2073-7136; Kumar, Priyadarshi
   Biplab/0000-0002-6495-3228
CR Ali N., 2014, ARPN journal of engineering and applied sciences, V9, P1732
   Apostolopoulos T., 2010, International Journal of Combinatorics, V2011, P1, DOI [10.1155/2011/523806, DOI 10.1155/2011/523806]
   Ariyaratne M. K., 2014, IACSIT International Journal of Engineering and Technology, V4, P611
   Babaoglu O, 2007, FIRST IEEE INTERNATIONAL CONFERENCE ON SELF-ADAPTIVE AND SELF-ORGANIZING SYSTEMS, P77, DOI 10.1109/SASO.2007.25
   BIN W, 2020, COMPUT ANIMAT VIRT W, V31, pE1885
   BORENSTEIN J, 1991, IEEE T ROBOTIC AUTOM, V7, P278, DOI 10.1109/70.88137
   Brand M, 2013, INT CONF MACH LEARN, P1028, DOI 10.1109/ICMLC.2013.6890747
   Chang Liu, 2012, 2012 Fifth International Joint Conference on Computational Sciences and Optimization (CSO), P775, DOI 10.1109/CSO.2012.174
   Christensen AL, 2009, IEEE T EVOLUT COMPUT, V13, P754, DOI 10.1109/TEVC.2009.2017516
   Coelho LD, 2011, IEEE C EVOL COMPUTAT, P517
   Cui L, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 1, PROCEEDINGS, P451, DOI 10.1109/HIS.2009.93
   Duchon F, 2014, PROCEDIA ENGINEER, V96, P59, DOI 10.1016/j.proeng.2014.12.098
   Dupre R, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1844
   Fadzli SA, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND SECURITY (ICISS), P143
   Farahani SM., 2011, INT J MACH LEARN COM, V1, P448, DOI [10.7763/ijmlc.2011.v1.67, DOI 10.7763/IJMLC.2011.V1.67, 10.7763/IJMLC.2011.V1.67]
   Fister I, 2013, SWARM EVOL COMPUT, V13, P34, DOI 10.1016/j.swevo.2013.06.001
   Gandomi AH, 2011, COMPUT STRUCT, V89, P2325, DOI 10.1016/j.compstruc.2011.08.002
   He W, 2017, IEEE T SYST MAN CY-S, V47, P45, DOI 10.1109/TSMC.2016.2557227
   Hereid A, 2016, IEEE INT CONF ROBOT, P1447, DOI 10.1109/ICRA.2016.7487279
   Hidalgo-Paniagua A, 2017, SOFT COMPUT, V21, P949, DOI 10.1007/s00500-015-1825-z
   Huang Q, 2001, IEEE T ROBOTIC AUTOM, V17, P280, DOI 10.1109/70.938385
   Kim JY, 2007, J INTELL ROBOT SYST, V48, P457, DOI 10.1007/s10846-006-9107-8
   Kofinas N, 2015, J INTELL ROBOT SYST, V77, P251, DOI 10.1007/s10846-013-0015-4
   Krishnanand KN, 2006, IEEE INT CONF ROBOT, P958, DOI 10.1109/ROBOT.2006.1641833
   Krishnanand KN, 2005, 2005 IEEE SWARM INTELLIGENCE SYMPOSIUM, P84
   Kumar A, 2018, ARAB J SCI ENG, V43, P7655, DOI 10.1007/s13369-018-3157-7
   Kumar PB, 2020, SCI IRAN, V27, P262, DOI 10.24200/sci.2018.50018.1466
   Kumar PB, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106088
   Kumar PB, 2020, ROBOTICA, V38, P565, DOI 10.1017/S0263574719000869
   Liu C, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/561394
   Mandersloot T, 2006, IEEE-RAS INT C HUMAN, P124, DOI 10.1109/ICHR.2006.321373
   Munk, 2015, ADV CONTR BIPED ROBO
   Nakhaei Alireza., 2008, IEEE-RAS International Conference on Humanoid Robots, P197
   Nandy S., 2012, Int. J. Computer Applications, V43, P8, DOI DOI 10.5120/6401-8339
   Nava G, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P680, DOI 10.1109/IROS.2016.7759126
   Osaba E, 2016, STUDIES COMPUTATIONA
   Oshita M, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1878
   Pandey A, 2017, DEF TECHNOL, V13, P47, DOI 10.1016/j.dt.2017.01.001
   Patle BK, 2017, WORLD J ENG, V14, P65, DOI 10.1108/WJE-11-2016-0133
   Patle BK, 2017, J COMPUT, V12, P135, DOI 10.17706/jcp.12.2.135-142
   Reher J, 2016, IEEE INT CONF ROBOT, P1794, DOI 10.1109/ICRA.2016.7487325
   Sabe K, 2004, IEEE INT CONF ROBOT, P592, DOI 10.1109/ROBOT.2004.1307213
   Sahu C, 2018, INT J ARTIF INTELL T, V27, DOI 10.1142/S021821301850015X
   Sahu C, 2018, J BIONIC ENG, V15, P623, DOI 10.1007/s42235-018-0051-7
   Saputra AA, 2016, IEEE T SYST MAN CY-S, V46, P898, DOI 10.1109/TSMC.2015.2497250
   SinghPal N., 2013, INT J COMPUTER APPL, V83, P5
   Wang G-G., 2012, INT J HYBRID INF TEC, V5, P123, DOI DOI 10.14257/IJHIT.2012.5.3.11
   Wehner S., 2009, ECMR, P277
   Xiang W, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1867
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Yiannakides A, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1887
   Zhang LN, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163230
NR 52
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2021
VL 32
IS 5
AR e1969
DI 10.1002/cav.1969
EA JUN 2021
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WJ5HR
UT WOS:000663274800001
DA 2024-07-18
ER

PT J
AU Lei, SZ
   Dong, BH
   Li, YG
   Xiao, F
   Tian, F
AF Lei, Songze
   Dong, Baihua
   Li, Yonggang
   Xiao, Feng
   Tian, Feng
TI Iris recognition based on few-shot learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE few-shot learning; iris recognition; L2 regularization; meta learning
AB Iris recognition is a popular research field in the biometrics, and it plays an important role in automatic recognition. Given sufficient training data, some deep learning-based approaches have achieved good performance on iris recognition. However, when the training data are limited, overfitting may occur. To address this issue, in this paper, we proposed a few-shot learning approach for iris recognition, based on model-agnostic meta-learning (MAML). To our best knowledge, we are the first to apply few-shot learning for iris recognition. Our experiments on the benchmark datasets have demonstrated that the proposed approach can achieve higher performance than the original MAML, and it is competitive to deep learning-based approaches.
C1 [Lei, Songze; Dong, Baihua; Li, Yonggang; Xiao, Feng] Xian Technol Univ, Sch Comp Sci & Engn, 2 XueFu Middle Rd, Xian, Shaanxi, Peoples R China.
   [Tian, Feng] Bournemouth Univ, Fac Sci & Technol, Poole, Dorset, England.
C3 Xi'an Technological University; Bournemouth University
RP Lei, SZ (corresponding author), Xian Technol Univ, Sch Comp Sci & Engn, 2 XueFu Middle Rd, Xian, Shaanxi, Peoples R China.
EM lei_sz@xatu.edu.cn
OI Dong, Baihua/0000-0001-9466-0752
FU National Joint Engineering Laboratory of New Network and Detection
   Foundation [GSYSJ2016008]; Shaanxi Science and Technology Plan Project
   [2020GY-066]
FX This work was supported by National Joint Engineering Laboratory of New
   Network and Detection Foundation (grant no. GSYSJ2016008), Shaanxi
   Science and Technology Plan Project (grant no. 2020GY-066). Portions of
   the research in this paper use the CASIA-Iris collected by the Chinese
   Academy of Sciences 'Institute of Automation (CASIA) and JLU-V1.0 of
   Research Institute of Biometrics and Information Security Technology,
   Jilin University. Reference: "JLU Iris Image Database,
   http://biis.jlu.edu.cn/irisdatabase/".
CR Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Davson Hugh, 1990, PHYSL EYE
   Finn C, 2017, PR MACH LEARN RES, V70
   Gangwar A, 2016, IEEE IMAGE PROC, P2301, DOI 10.1109/ICIP.2016.7532769
   Geoffrey EHinton., 2012, Improving neural networks by preventing co-adaptation of feature detectors
   Hajari K., 2015, Int J Eng Adv Technol, V4, P108
   Ibrahim MT, 2012, OPT LASER ENG, V50, P645, DOI 10.1016/j.optlaseng.2011.11.008
   Lim S, 2001, ETRI J, V23, P61, DOI 10.4218/etrij.01.0101.0203
   Ma L, 2002, INT C PATT RECOG, P414, DOI 10.1109/ICPR.2002.1048327
   Minaee S., 2016, IEEE Region, P1
   Nagem, 2017, PATTERN ANAL APPL, V4, P1
   Othman N, 2016, PATTERN RECOGN LETT, V82, P124, DOI 10.1016/j.patrec.2015.09.002
   Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240
   Sutra G., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P310, DOI 10.1109/ICB.2012.6199825
   Vatsa Mayank, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1314, DOI 10.1109/ICPR.2010.327
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang, 2000, P 15 INT C PATT REC, V2
   Wang K, 2019, PATTERN RECOGN, V86, P85, DOI 10.1016/j.patcog.2018.08.010
   Zhang, 2016, P 2016 INT C BIOM IC, P1
   Zhang, 2018, CHINESE J IMAGE GRAP, V23, P28
   Zhang C., 2020, ARXIV200902653
   Zhang WQ, 2017, INT CONF SYST INFORM, P1169, DOI 10.1109/ICSAI.2017.8248462
   Zhao TM, 2019, IEEE ACCESS, V7, P49691, DOI 10.1109/ACCESS.2019.2911056
NR 25
TC 3
Z9 3
U1 2
U2 37
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2018
DI 10.1002/cav.2018
EA MAY 2021
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000656287900001
DA 2024-07-18
ER

PT J
AU Zhu, J
   Li, SL
   Cai, RC
   Hao, ZF
   Huang, GH
   Sheng, B
   Wu, EH
AF Zhu, Jian
   Li, Silong
   Cai, Ruichu
   Hao, Zhifeng
   Huang, Guoheng
   Sheng, Bin
   Wu, Enhua
TI Animating turbulent fluid with a robust and efficient high-order
   advection method
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE constrained interpolation profile; fluid simulation; high-order
   advection; Taylor expansion
ID CUBIC-POLYNOMIAL INTERPOLATION; HYPERBOLIC-EQUATIONS; UNIVERSAL SOLVER;
   DISSIPATION; SMOKE
AB The accuracy of advection has a great influence on the visual effect of fluid simulation. Constrained interpolation profile (CIP) method has been an important advection scheme because of its third-order accuracy and the fact that it only needs to be performed over a compact stencil, but extending it to high-dimensional advection equations is not easy, because it involves complex calculations and large memory overheads, and is usually unstable. In this article, we propose a stable and efficient three-dimensional (3D) CIP scheme which can maintain high accuracy but requires low computation and memory cost. We first construct an efficient two-dimensional (2D) CIP scheme based on dimensional splitting and local Taylor expansions, and then propose an effective way to extend it for 3D applications without decreasing the computational accuracy or affecting the stability. The experimental results show the advantages of our method over the state-of-the-art advection schemes.
C1 [Zhu, Jian; Li, Silong; Cai, Ruichu; Hao, Zhifeng; Huang, Guoheng] Guangdong Univ Technol, Sch Comp, Guangzhou, Peoples R China.
   [Hao, Zhifeng] Foshan Univ, Sch Math & Big Data, Foshan, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
C3 Guangdong University of Technology; Foshan University; Shanghai Jiao
   Tong University; Chinese Academy of Sciences; Institute of Software, CAS
RP Huang, GH (corresponding author), Guangdong Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Comp, Guangzhou, Peoples R China.
EM kevinwong@gdut.edu.cn
RI cai, ruichu/AAX-7200-2021
OI Sheng, Bin/0000-0001-8678-2784; Sheng, Bin/0000-0001-8510-2556
FU National Key Research and Development Programof China [2017YFB1002701,
   2017YFB1201203]; National Natural Science Foundation of China [61672502,
   61702111, 61876043, 61976052]; Natural Science Foundation of Guangdong
   Province [2016A030310342]; Science and Technology Planning Project of
   Guangdong Province [2017B010110007, 2017B010110015]
FX National Key Research and Development Programof China, Grant/Award
   Numbers: 2017YFB1002701, 2017YFB1201203; National Natural Science
   Foundation of China, Grant/Award Numbers: 61672502, 61702111, 61876043,
   61976052; Natural Science Foundation of Guangdong Province, Grant/Award
   Number: 2016A030310342; Science and Technology Planning Project of
   Guangdong Province, Grant/Award Numbers: 2017B010110007, 2017B010110015
CR Aanjaneya M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073625
   [Anonymous], 2020, SCI CHINA INFORM SCI, DOI DOI 10.1007/S11432-018-9889-8
   [Anonymous], 2015, GRAPH MODELS, DOI DOI 10.1016/J.GMOD.2014.12.002
   [Anonymous], 2018, ACM T GRAPHIC, DOI DOI 10.1145/3197517.3201324
   Bridson R, 2015, FLUID SIMULATION COM
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Fukumitsu K, 2015, J COMPUT PHYS, V286, P62, DOI 10.1016/j.jcp.2014.12.045
   Huang ZP, 2015, COMPUT ANIMAT VIRT W, V26, P141, DOI 10.1002/cav.1559
   Kim BM, 2005, P 1 EUR C NAT PHEN D, P51
   Kim B, 2007, IEEE T VIS COMPUT GR, V13, P135, DOI 10.1109/TVCG.2007.3
   Kim D, 2008, COMPUT GRAPH FORUM, V27, P467, DOI 10.1111/j.1467-8659.2008.01144.x
   Kim ST, 2013, VISUAL COMPUT, V29, P1293, DOI 10.1007/s00371-012-0770-4
   Li X, 2015, P ACM S VIRT REAL SO, P113
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Molemaker J, 2008, P S COMP AN DUBL IR, V2008
   Narain R, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340257
   Qu ZY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322945
   Sato Takahiro, 2018, Computational Visual Media, V4, P223, DOI 10.1007/s41095-018-0117-9
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Song OY, 2005, ACM T GRAPHIC, V24, P81, DOI 10.1145/1037957.1037962
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Takahashi T, 2003, COMPUT GRAPH FORUM, V22, P391, DOI 10.1111/1467-8659.00686
   Wang ZJ, 2013, INT J NUMER METH FL, V72, P811, DOI 10.1002/fld.3767
   Xiao F, 1996, COMPUT PHYS COMMUN, V93, P1, DOI 10.1016/0010-4655(95)00124-7
   YABE T, 1991, COMPUT PHYS COMMUN, V66, P219, DOI 10.1016/0010-4655(91)90071-R
   Yabe T, 2001, J COMPUT PHYS, V169, P556, DOI 10.1006/jcph.2000.6625
   YABE T, 1991, COMPUT PHYS COMMUN, V66, P233, DOI 10.1016/0010-4655(91)90072-S
NR 27
TC 2
Z9 2
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1951
DI 10.1002/cav.1951
EA AUG 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000562929600001
DA 2024-07-18
ER

PT J
AU Choi, MG
   Lee, JH
   Ha, W
   Lee, KH
AF Choi, Myung Geol
   Lee, Ji Hye
   Ha, Wansu
   Lee, Kang Hoon
TI Optimal close-up views for precise 3D manipulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE automatic camera control; auxiliary view; bisector surface; virtual
   reality; 3D manipulation
ID CAMERA CONTROL
AB Direct manipulation can be used as an intuitive interface for spatial interaction with multiple objects in virtual environments. However, users often have difficulties in precisely manipulating objects in the 3D space; this is mainly because the user is not provided with enough visual information to sufficiently recognize the spatial relationships among objects. We present a new method for improving the preciseness of object manipulation in the 3D space by providing the user with an auxiliary view that is consistently retargeted to closely highlight the spatial relationship between the manipulated object and the object nearest to it. Both the target and the position of the auxiliary camera are computed efficiently using the bisector surface of the two involved objects. The viewing target is set to the center of the closest area between the two objects, and the camera position is optimized under an objective function primarily measuring the visual clarity of the auxiliary view. We demonstrate the usefulness of our method through various experiments based on practical usage scenarios.
C1 [Choi, Myung Geol; Lee, Ji Hye] Catholic Univ Korea, Digital Media Dept, Bucheon, South Korea.
   [Ha, Wansu; Lee, Kang Hoon] Kwangwoon Univ, Dept Comp Sci, Seoul, South Korea.
C3 Catholic University of Korea; Kwangwoon University
RP Lee, KH (corresponding author), Kwangwoon Univ, Seoul 139701, South Korea.
EM kang@kw.ac.kr
FU National Research Foundation of Korea (NRF) [2016R1D1A1B03930472];
   Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA); Culture Technology (CT) Research & Development Program
   2018; Catholic University of Korea; Kwangwoon University
FX National Research Foundation of Korea (NRF), Grant/Award Number:
   2016R1D1A1B03930472; Ministry of Culture, Sports and Tourism (MCST);
   Korea Creative Content Agency (KOCCA); Culture Technology (CT) Research
   & Development Program 2018; The Catholic University of Korea Research
   Fund 2018; Kwangwoon University Research Grant 2017
CR Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Christie M., 2009, ACM SIGGRAPH ASIA 2009 Courses, SIGGRAPH ASIA '09
   DRUCKER SM, 1994, GRAPH INTER, P190
   Elber G, 1998, ACM T GRAPHIC, V17, P32, DOI 10.1145/269799.269801
   Frees S, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1229855.1229857
   Grandi JG, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P49, DOI 10.1109/VR.2018.8446295
   Grandi JG, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5881, DOI 10.1145/3025453.3025935
   Hand C, 1997, COMPUT GRAPH FORUM, V16, P269, DOI 10.1111/1467-8659.00194
   Hinckley K, 1996, THESIS
   Hu RZ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925870
   Johnson Timothy E., 1963, P SPRING JOINT COMP, P347
   Madsen DavidA., 2016, ENG DRAWING DESIGN
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Ortega M, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2047, DOI 10.1145/2556288.2557242
   Peternell M, 2000, GRAPH MODELS, V62, P202, DOI 10.1006/gmod.1999.0521
   Phillips CaryB., 1992, Proceedings of the 1992 symposium on Interactive 3D graphics, P71
   Wu S, 2015, P 21 ACM S VIRT REAL, P59, DOI [10.1145/2821592.2821606, DOI 10.1145/2821592.2821606]
   Yeh IC, 2012, IEEE T VIS COMPUT GR, V18, P1496, DOI 10.1109/TVCG.2011.273
   Zhao X, 2017, COMPUT GRAPH FORUM, V36, P119, DOI 10.1111/cgf.13112
   Zhao XF, 2014, J EXP CLIN CANC RES, V33, DOI 10.1186/1756-9966-33-3
NR 20
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1884
DI 10.1002/cav.1884
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400005
DA 2024-07-18
ER

PT J
AU Kumar, PB
   Mohapatra, S
   Parhi, DR
AF Kumar, Priyadarshi Biplab
   Mohapatra, Saktiswarup
   Parhi, Dayal R.
TI An intelligent navigation of humanoid NAO in the light of classical
   approach and computational intelligence
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fuzzy logic; humanoid NAO; obstacle avoidance; regression analysis
ID MOTION; OPTIMIZATION; MANIPULATION; NETWORK; WALKING
AB The development of robotics research toward industrialization has created an enhanced demand for modernization of the automation industry. Humanoid robots being advanced than other forms of robots bear a large resemblance to humans and are very much helpful in replacing humans in tedious and repetitive tasks. Therefore, the navigation and path planning of the humanoids bear a large importance in robotics research. The current investigation deals with the path planning of NAO humanoid robots. In the present work, a classical method of regression analysis and an artificial intelligence technique of fuzzy logic are implemented separately for the purpose of obstacle avoidance during the motion of humanoid NAOs toward respective targets. The simulation analysis of the proposed techniques is carried out using V-REP software. The experiments are performed in laboratory conditions with a proper environment for working of the humanoid NAOs. Finally, a comparison has been made between the simulation and experimental results. The results obtained from the simulation and experimental analyses are in good agreement with each other, which suggest that the proposed methodologies can be used as methods of robust control for the navigation of humanoids.
C1 [Kumar, Priyadarshi Biplab; Mohapatra, Saktiswarup; Parhi, Dayal R.] Natl Inst Technol Rourkela, Mech Engn Dept, Robot Lab, Rourkela 769008, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Kumar, PB (corresponding author), Natl Inst Technol Rourkela, Mech Engn Dept, Robot Lab, Rourkela 769008, India.
EM p.biplabkumar@gmail.com
RI Parhi, Dayal/M-7935-2018
OI Parhi, Dayal/0000-0002-2073-7136; Kumar, Priyadarshi
   Biplab/0000-0002-6495-3228
CR [Anonymous], 2013, 13th International Conference on Autonomous Robot Systems (Robotica)
   [Anonymous], 1987, The complexity of robot motion planning
   Armstrong J., 2011, ILLUSIONS REGRESSION
   Asano T., 1985, 26th Annual Symposium on Foundations of Computer Science (Cat. No.85CH2224-4), P155, DOI 10.1109/SFCS.1985.65
   Benamati L, 2005, 2005 12TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS, P103
   Bouyarmane K, 2018, IEEE T AUTOMAT CONTR, V63, P1632, DOI 10.1109/TAC.2017.2752085
   Bouyarmane K, 2012, ADV ROBOTICS, V26, P1099, DOI 10.1080/01691864.2012.686345
   Canny J., 1985, Proceedings. 1985 IEEE International Conference on Robotics and Automation, V2, P530
   Carriker W. F., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P204, DOI 10.1109/ROBOT.1990.125973
   Clever D, 2016, ROB SCI SYST ANN ARB
   Clever D, 2016, ROBOT AUTON SYST, V83, P287, DOI 10.1016/j.robot.2016.06.001
   Dalibard S, 2013, INT J ROBOT RES, V32, P1089, DOI 10.1177/0278364913481250
   De Magistris G, 2017, ROBOT AUTON SYST, V95, P52, DOI 10.1016/j.robot.2017.05.006
   Fakoor Mahdi, 2016, J. appl. res. technol, V14, P300
   Hodgins JK, 1996, IEEE INT CONF ROBOT, P3271, DOI 10.1109/ROBOT.1996.509211
   Inaba M, 2000, INT J ROBOT RES, V19, P933, DOI 10.1177/02783640022067878
   JANABISHARIFI F, 1993, PROCEEDINGS OF THE 1993 IEEE INTERNATIONAL SYMPOSIUM ON INTELLIGENT CONTROL, P536, DOI 10.1109/ISIC.1993.397640
   Kim D, 2016, IEEE T ROBOT, V32, P1362, DOI 10.1109/TRO.2016.2597314
   Kim KS, 2018, ARXIV180301484
   Lee KB, 2015, IEEE T IND ELECTRON, V62, P5586, DOI 10.1109/TIE.2015.2405901
   Luo J, 2017, P IEEE INT C ROB BIO, P5
   Luo JR, 2017, AUTON ROBOT, V41, P1447, DOI 10.1007/s10514-017-9629-x
   Maier D, 2013, IEEE INT C INT ROBOT, P2658, DOI 10.1109/IROS.2013.6696731
   Mohanta JC, 2018, ARAB J SCI ENG, V43, P1395, DOI 10.1007/s13369-017-2899-y
   Mohanty PK, 2016, J EXP THEOR ARTIF IN, V28, P35, DOI 10.1080/0952813X.2014.971442
   Mohanty PK, 2014, APPL MATH INFORM SCI, V8, P2527, DOI 10.12785/amis/080551
   Mohanty PK, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P136, DOI 10.1109/ICACCCT.2012.6320757
   Moro FL, 2016, HUMANOID ROBOTICS RE, P1
   Nishiwaki Koichi, 2009, 2009 9th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2009), P535, DOI 10.1109/ICHR.2009.5379519
   Okada K, 2004, IEEE INT CONF ROBOT, P3207, DOI 10.1109/ROBOT.2004.1308748
   Osswald Stefan, 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P4844, DOI 10.1109/IROS.2011.6048209
   Panda MR, 2018, ARAB J SCI ENG, V43, P4029, DOI 10.1007/s13369-017-2794-6
   Paolillo A, 2018, IEEE ROBOT AUTOM LET, V3, P2746, DOI 10.1109/LRA.2018.2835515
   Paolillo A, 2018, J FIELD ROBOT, V35, P169, DOI 10.1002/rob.21731
   Parhi DR, 2010, P I MECH ENG C-J MEC, V224, P1369, DOI 10.1243/09544062JMES1751
   Parhi DR, 2005, J INTELL ROBOT SYST, V42, P253, DOI 10.1007/s10846-004-7195-x
   Park MG, 2002, SICE 2002: PROCEEDINGS OF THE 41ST SICE ANNUAL CONFERENCE, VOLS 1-5, P2190
   Peterson J.L., 1981, Petri Net Theory and the Modeling of Systems
   Pham DT, 2003, ROBOTICA, V21, P79, DOI [10.1017/S0263574704526, 10.1017/S0263574702004526]
   Piriyakumar JEL, 2015, INT RES J ENG TECHNO, V2, P208
   Raibert M. H., 1986, LEGGED ROBOTS BALANC, DOI DOI 10.1109/MEX.1986.4307016
   Ryu SH, 2013, IEEE T CYBERNETICS, V43, P217, DOI 10.1109/TSMCB.2012.2203357
   Sethian J., 1999, LEVEL SET METHODS FA
   Singh MB, 2009, PUBLIC HEALTH NUTR, V12, P624, DOI 10.1017/S1368980008002395
   STILMAN B, 1993, COMPUT MATH APPL, V26, P51, DOI 10.1016/0898-1221(93)90331-O
   TAKAHASHI O, 1989, IEEE T ROBOTIC AUTOM, V5, P143, DOI 10.1109/70.88035
   Takano W, 2016, ROBOT AUTON SYST, V75, P260, DOI 10.1016/j.robot.2015.09.021
   Wang SH, 2017, 2017 IEEE-RAS 17TH INTERNATIONAL CONFERENCE ON HUMANOID ROBOTICS (HUMANOIDS), P454, DOI 10.1109/HUMANOIDS.2017.8246912
   Yelamarthi K, 2012, MIDWEST SYMP CIRCUIT, P562, DOI 10.1109/MWSCAS.2012.6292082
   Yoo JK, 2015, IEEE-ASME T MECH, V20, P2425, DOI 10.1109/TMECH.2014.2382633
   Zacksenhouse M., 1988, Proceedings of the 27th IEEE Conference on Decision and Control (IEEE Cat. No.88CH2531-2), P324, DOI 10.1109/CDC.1988.194321
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   ZELINSKY A, 1994, INT J ROBOT RES, V13, P315, DOI 10.1177/027836499401300403
   Zhang YJ, 2014, IEEE INT CONF ROBOT, P2086, DOI 10.1109/ICRA.2014.6907139
NR 54
TC 11
Z9 11
U1 0
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2019
VL 30
IS 2
AR e1858
DI 10.1002/cav.1858
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR7XB
UT WOS:000463367400004
DA 2024-07-18
ER

PT J
AU Frädrich, L
   Nunnari, F
   Staudte, M
   Heloir, A
AF Fraedrich, Laura
   Nunnari, Fabrizio
   Staudte, Maria
   Heloir, Alexis
TI (Simulated) listener gaze in real-time spoken interaction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE embodied conversational agents; eye-tracking; joint attention;
   (listener) gaze; speaker behavior
ID HUMAN-ROBOT INTERACTION; JOINT ATTENTION
AB Gaze is an important aspect of social communication. Previous research has concentrated mainly on the role of speaker gaze and listener gaze in isolation, neglecting the effect of the listener's gaze behavior on the speaker's behavior. This paper presents an exploratory eye-tracking study involving an interactive human-like agent following participants' gaze. This study demonstrates that a rather simple gaze-following mechanism convincingly simulates active listening behavior engaging the speaker. The study also highlights how speakers rely on their interlocutors' gaze when establishing common references.
C1 [Fraedrich, Laura; Staudte, Maria] Saarland Univ, Embodied Spoken Interact Grp, Saarbrucken, Germany.
   [Nunnari, Fabrizio; Heloir, Alexis] German Res Ctr Artificial Intelligence, Sign Language Synth & Interact Grp, Saarbrucken, Germany.
   [Heloir, Alexis] Univ Valenciennes & Hainaut Cambresis, CNRS, Lab Ind & Human Automat Control Mech Engn & Comp, UMR 8201,LAMIH, Valenciennes, France.
C3 Saarland University; Centre National de la Recherche Scientifique
   (CNRS); Universite Polytechnique Hauts-de-France
RP Nunnari, F (corresponding author), German Res Ctr Artificial Intelligence, Sign Language Synth & Interact Grp, Saarbrucken, Germany.
EM fabrizio.nunnari@dfki.de
OI Nunnari, Fabrizio/0000-0002-1596-4043; Staudte,
   Maria/0009-0006-1232-643X
FU "Multimodal Computing and Interaction" Cluster of Excellence at Saarland
   University
FX The research reported in this paper was supported by the "Multimodal
   Computing and Interaction" Cluster of Excellence at Saarland University.
CR Andrist S, 2014, ACMIEEE INT CONF HUM, P25, DOI 10.1145/2559636.2559666
   [Anonymous], 1991, PERSPECTIVES SOCIALL, DOI DOI 10.1037/10096-006
   BENTE G, 2007, 10 ANN INT WORKSH PR
   Brown-Schmidt S, 2012, LANG COGNITIVE PROC, V27, P62, DOI 10.1080/01690965.2010.543363
   Cassell J, 1999, SPRING INT SER ENG C, V511, P143
   Colburn A, 2000, SIGGRAPH 00 P 27 INT
   Courgeon M, 2011, 24 AUSTR JOINT C PER
   Courgeon M, 2014, IEEE T AFFECT COMPUT, V5, P238, DOI 10.1109/TAFFC.2014.2335740
   Frädrich L, 2017, LECT NOTES ARTIF INT, V10498, P156, DOI 10.1007/978-3-319-67401-8_17
   Grice H. P., 1975, SYNTAX SEMANTICS, V3, P41, DOI DOI 10.1163/9789004368811_003
   Hakkani-Tur Dilek, 2014, P 16 INT C MULTIMODA, P263, DOI 10.1145/2663204.2663277
   Hanna JE, 2007, J MEM LANG, V57, P596, DOI 10.1016/j.jml.2007.01.008
   Heylen DKJ, 2005, CONTROLLING GAZE CON, P245
   Ioannou S, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00845
   Koda Tomoko, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P404, DOI 10.1007/978-3-642-33197-8_41
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Kuznetsova A., 2016, J STAT SOFTW, V82
   Mancini M, 2007, LECT NOTES ARTIF INT, V4722, P112
   MANSKI CF, 1993, REV ECON STUD, V60, P531, DOI 10.2307/2298123
   Mutlu B., 2012, ACM T INTERACT INTEL, V1, P1, DOI [10.1145/2070719.2070725, DOI 10.1145/2070719.2070725]
   Pelachaud C, 2003, LECT NOTES ARTIF INT, V2792, P93
   Skantze G, 2014, SPEECH COMMUN, V65, P50, DOI 10.1016/j.specom.2014.05.005
   Staudte M, 2014, COGNITION, V133, P317, DOI 10.1016/j.cognition.2014.06.003
   Staudte M, 2011, COGNITION, V120, P268, DOI 10.1016/j.cognition.2011.05.005
   Thiebaux Marcus., 2008, P AAMAS 08, P151
   van Welbergen Herwin, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P175, DOI 10.1007/978-3-642-33197-8_18
   Vidal M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P115, DOI 10.1145/2702123.2702163
NR 27
TC 4
Z9 4
U1 2
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1831
DI 10.1002/cav.1831
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100022
DA 2024-07-18
ER

PT J
AU Jensen, JA
   Burton, RP
AF Jensen, Justin A.
   Burton, Robert P.
TI Fourveo: Integration of 4D animation into conventional 3D animation
   workflows
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE 4D animation; four-dimensional geometry; general-purpose animation
   system
AB We have developed a software package that facilitates general-purpose animation in four spatial dimensions. Standard features from popular 3D animation software have been included and adapted, where appropriate. Many adaptations are trivial; some have required novel solutions. Several features that are possible only in four or more dimensions have been included. The graphical user interface has been designed to be familiar to experienced 3D animators. Keyframe animation is provided by using a set of curves that defines movement in each dimension or rotation plane. An interactive viewport offers multiple visualization methods including slicing and projection. The viewport allows for both manipulation of 4D objects and navigation through virtual 4D space.
C1 [Jensen, Justin A.] Brigham Young Univ, Comp Sci, Provo, UT 84602 USA.
   [Burton, Robert P.] Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.
C3 Brigham Young University; Brigham Young University
RP Jensen, JA (corresponding author), Brigham Young Univ, Provo, UT 84602 USA.
EM jensen.a.justin@gmail.com
RI Jensen, Justin/JCD-6516-2023
OI Jensen, Justin/0000-0002-6494-8154
FU Department of Computer Science; College of Physical & Mathematical
   Sciences at Brigham Young University
FX Department of Computer Science; College of Physical & Mathematical
   Sciences at Brigham Young University
CR Abbot E, 2006, FLATLAND ROMANCE MAN
   [Anonymous], 1999, TECHNICAL REPORT
   Autodesk, 2014, SOFT US GUID
   Autodesk, 2014, MAY US GUID
   Autodesk, 2013, 3DS MAX HELP
   Blender Foundation, 2015, BLEND MAN CONT
   Bourke P, 1990, HYPERSPACE USER MANU
   Britton EdwardG., 1978, ACM SIGGRAPH Computer Graphics, V12, P222
   Chu A, 2009, IEEE T VIS COMPUT GR, V15, P1587, DOI 10.1109/TVCG.2009.147
   Hollasch SR, 1991, THESIS
   Isaacson PL, 1984, THESIS
   Kindlmann G, 2000, POLYTOPE VISUALIZATI
   Manning H.P., 1960, 4 DIMENSION SIMPLY E
   MathWorks, 2015, MATLAB DOC
   Maxon, 2015, CIN 4D QUICKST DOC
   Munroe R, 2010, FLATLAND
   NOLL AM, 1967, COMMUN ACM, V10, P469, DOI 10.1145/363534.363544
   Noll AM, 1968, AFIPS 68 P FALL JO 2, P1279
   POV Ray, 2013, POV RAY UN VERS 3 7
   SideEffects Software, 2015, HOUD 14 0
   The Foundry, 2015, MOD ONL HELP
   Webb R, 2014, STELLA4D MANUAL
   Wilding D, 2007, THESIS
   Wolfram, 2015, WOLFR LANG SYST DOC
NR 24
TC 0
Z9 0
U1 2
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1816
DI 10.1002/cav.1816
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100007
DA 2024-07-18
ER

PT J
AU Dhiman, A
   Solanki, D
   Bhasin, A
   Das, A
   Lahiri, U
AF Dhiman, Ashish
   Solanki, Dhaval
   Bhasin, Ashu
   Das, Abhijit
   Lahiri, Uttama
TI An intelligent, adaptive, performance-sensitive, and virtual
   reality-based gaming platform for the upper limb
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE physiology; stroke; upper limb; virtual reality
ID MOTOR REHABILITATION; STROKE REHABILITATION; FUNCTIONAL RECOVERY; SYSTEM
AB Stroke is a leading cause of adult disability, characterized by a spectrum of muscle weakness and movement abnormalities related to the upper limb. About 80% of individuals who had a stroke suffer from upper limb dysfunction. Conventional rehabilitation aims to improve one's ability to use paralyzed limbs through repetitive exercise under one-on-one supervision by physiotherapists. This poses difficulty given the limited availability of healthcare resources and the high cost of availing specialized services at healthcare centers, particularly in developing countries like India. Thus, the design of cost-effective, home-based, and technology-assisted individualized rehabilitation platform that can deliver real-time feedback on one's skill progress is critical. This paper describes the design of a novel, multimodal, virtual reality (VR)-based, and performance-sensitive exercise platform that can intelligently adapt its task presentation to one's performance. Here, we aim to address unilateral shoulder abduction and adduction that are essential for the performance of daily living activities. We designed an experimental study in which six individuals who had chronic stroke (post-stroke period: >6months) participated. While they interacted with our VR-based tasks, we recorded their physiological signals in a synchronized manner. Preliminary results indicate the potential of our VR-based, adaptive individualized system in the performance of individuals who had a stroke suffering from upper limb movement disorders.
C1 [Dhiman, Ashish; Solanki, Dhaval; Lahiri, Uttama] Indian Inst Technol Gandhinagar, Dept Elect Engn, Gandhinagar 382355, Gujarat, India.
   [Bhasin, Ashu] All India Inst Med Sci, Dept Neurol, New Delhi 110029, India.
   [Das, Abhijit] AMRI Inst Neurosci, Dept Neurorehabil, Kolkata 700099, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Gandhinagar; All India Institute of Medical Sciences
   (AIIMS) New Delhi
RP Dhiman, A (corresponding author), Indian Inst Technol Gandhinagar, Dept Elect Engn, Gandhinagar 382355, Gujarat, India.
EM ashish.dhiman1@gmail.com
RI Solanki, Dhaval J./GWQ-5044-2022; Das, Abhijit/IYT-3303-2023; Dhiman,
   Ashish/AAC-9961-2022; Das, Abhijit/AAQ-1729-2020
OI Dhiman, Ashish/0000-0002-6168-7868; Solanki, Dhaval/0000-0003-4039-4406
FU Department of Science and Technology, Ministry of Science and Technology
   [RES/DST-SEED/EE/UL/201314-049]
FX Department of Science and Technology, Ministry of Science and
   Technology, Grant/Award Number: RES/DST-SEED/EE/UL/201314-049
CR Adams RJ, 2015, IEEE T NEUR SYS REH, V23, P287, DOI 10.1109/TNSRE.2014.2360149
   Ballester BR, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0039-z
   Blennerhassett J, 2004, AUST J PHYSIOTHER, V50, P219, DOI 10.1016/S0004-9514(14)60111-2
   Booth T.L., 1967, Sequential machines and automata theory, V3
   Broeren J., 2002, P 4 INT C DISABILITY, P71
   Clarkson AN, 2010, NATURE, V468, P305, DOI 10.1038/nature09511
   COTTER JD, 1995, EUR J APPL PHYSIOL O, V71, P549, DOI 10.1007/BF00238559
   Cameirao MDS, 2011, RESTOR NEUROL NEUROS, V29, P287, DOI 10.3233/RNN-2011-0599
   Dhiman A, 2016, 6 IEEE INT C BIOM RO
   Ellis MD, 2009, NEUROREHAB NEURAL RE, V23, P862, DOI 10.1177/1545968309332927
   Sucar LE, 2014, IEEE T NEUR SYS REH, V22, P634, DOI 10.1109/TNSRE.2013.2293673
   Feigin VL, 2007, LANCET NEUROL, V6, P94, DOI 10.1016/S1474-4422(07)70007-8
   Feys P, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0043-3
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Jack K, 2010, MANUAL THER, V15, P220, DOI 10.1016/j.math.2009.12.004
   Jouven X, 2005, NEW ENGL J MED, V352, P1951, DOI 10.1056/NEJMoa043012
   Kaur G, 2012, STROKE RES TREAT, V2012, DOI 10.1155/2012/820673
   Khor KX, 2014, IEEE HAPTICS SYM, P421
   Krebs HI, 2003, AUTON ROBOT, V15, P7, DOI 10.1023/A:1024494031121
   Kumar D, 2015, 2015 7 INT IEEE EMBS
   Kumar D, 2016, JOVE-J VIS EXP, DOI 10.3791/52394
   Kuriakose S, 2015, IEEE T NEUR SYS REH, V23, P665, DOI 10.1109/TNSRE.2015.2393891
   Langhorne P, 2011, LANCET, V377, P1693, DOI 10.1016/S0140-6736(11)60325-5
   Levin MF, 2015, IEEE T NEUR SYS REH, V23, P1047, DOI 10.1109/TNSRE.2014.2387412
   Levin MF, 2015, PHYS THER, V95, P415, DOI 10.2522/ptj.20130579
   Lovquist E, 2006, P 6 INT C DIS VIRT R, P18
   Luke LM, 2004, SYNAPSE, V54, P187, DOI 10.1002/syn.20080
   Maciejasz P, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-3
   Metzger JC, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-154
   Pandian JD, 2013, J STROKE, V15, P128
   Rizzo A, 2011, J CLIN PSYCHOL MED S, V18, P176, DOI 10.1007/s10880-011-9247-2
   Ballester BR, 2012, PRESENCE-TELEOP VIRT, V21, P490, DOI 10.1162/PRES_a_00129
   Santisteban L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154792
   Saposnik G, 2010, STROKE, V41, P1477, DOI 10.1161/STROKEAHA.110.584979
   Soares Antonio Vinicius, 2014, Fisioter. mov., V27, P309, DOI 10.1590/0103-5150.027.003.AO01
   Song ZB, 2011, C HUM SYST INTERACT, P352, DOI 10.1109/HSI.2011.5937391
   Squeri V, 2014, IEEE T NEUR SYS REH, V22, P312, DOI 10.1109/TNSRE.2013.2250521
   Standen P, 2015, PHYS THER, V95, P350, DOI 10.2522/ptj.20130564
   Thayer JF, 2012, NEUROSCI BIOBEHAV R, V36, P747, DOI 10.1016/j.neubiorev.2011.11.009
   Turolla A, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-85
   Warburton DER, 2007, APPL PHYSIOL NUTR ME, V32, P655, DOI 10.1139/H07-038
   Ward NS, 2013, J NEUROL NEUROSUR PS, V84, P237, DOI 10.1136/jnnp-2013-304886
   Winstein CJ, 2016, STROKE, V47, pE98, DOI 10.1161/STR.0000000000000098
   Yeh S, 2005, P ACM S VIRT REAL SO, P59
   Young Brittany Mei, 2014, Front Neuroeng, V7, P25, DOI 10.3389/fneng.2014.00025
   Zhang C., 2016, INT J REHABIL RES
   Zhang JJ, 2015, IEEE T ROBOT, V31, P233, DOI 10.1109/TRO.2015.2392451
NR 47
TC 10
Z9 12
U1 2
U2 48
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2018
VL 29
IS 2
AR e1800
DI 10.1002/cav.1800
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GD0DX
UT WOS:000430170900002
DA 2024-07-18
ER

PT J
AU Haworth, B
   Usman, M
   Berseth, G
   Khayatkhoei, M
   Kapadia, M
   Faloutsos, P
AF Haworth, Brandon
   Usman, Muhammad
   Berseth, Glen
   Khayatkhoei, Mahyar
   Kapadia, Mubbasir
   Faloutsos, Petros
TI CODE: Crowd-optimized design of environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE architectural optimization; crowd simulation; user-in-the-loop design
ID ARCHITECTURAL DESIGN
AB We present crowd-optimized design of environments (CODE): a crowd-aware computational tool for designing environments (e.g., building floor plans). Our system analyses the impact of newly added environment elements (e.g., pillars or doorways) on the resulting crowd flow, using current-generation crowd simulators. The results of the simulation are used to provide feedback to the designer in terms of aggregate statistics and heat maps. Additionally, our system is able to automatically optimize the placement of environment elements to maximize crowd flow in egress scenarios, while satisfying constraints that are imposed by the designer. Using CODE, architects and environment designers can iteratively refine upon their original design to quickly accommodate the dynamic properties of crowd simulations in an interactive fashion. CODE is modular and flexible so that designers may build environments, select from different crowd simulators, and specify varying crowd configurations.
C1 [Haworth, Brandon; Usman, Muhammad] York Univ, Elect Engn & Comp Sci, Toronto, ON, Canada.
   [Berseth, Glen] Univ British Columbia, Comp Sci, Vancouver, BC, Canada.
   [Khayatkhoei, Mahyar; Kapadia, Mubbasir] Rutgers Univ New Brunswick, Dept Comp Sci, New Brunswick, NJ USA.
   [Faloutsos, Petros] York Univ, Comp Sci & Engn, Toronto, ON, Canada.
C3 York University - Canada; University of British Columbia; Rutgers
   University System; Rutgers University New Brunswick; York University -
   Canada
RP Haworth, B (corresponding author), York Univ, Elect Engn & Comp Sci, Toronto, ON, Canada.
EM brandon@cse.yorku.ca
OI Berseth, Glen/0000-0001-7351-8028; Khayatkhoei,
   Mahyar/0000-0002-7326-861X; Usman, Muhammad/0000-0003-2059-7206;
   Haworth, Brandon/0000-0001-8134-0047
FU NSERC
FX NSERC
CR [Anonymous], 2007, Pedestrian and evacuation dynamics 2005, DOI DOI 10.1007/978-3-540-47064-9
   Arvin SA, 2002, AUTOMAT CONSTR, V11, P213, DOI 10.1016/S0926-5805(00)00099-6
   B HAWORTH., 2015, P 8 ACM SIGGRAPH C M, P91
   Bassuet A, 2014, BUILD ACOUST, V21, P75, DOI 10.1260/1351-010X.21.1.75
   BERGER MJ, 1989, J COMPUT PHYS, V82, P64, DOI 10.1016/0021-9991(89)90035-1
   Berseth G, 2015, COMPUT ANIMAT VIRT W, V26, P377, DOI 10.1002/cav.1652
   Berseth Glen., 2014, Proceedings of the 7th International Conference on Motion in Games, P153, DOI DOI 10.1145/2668084.2668100
   Berseth Glen., 2014, Proceedings of the ACM SIGGRAPH / Eurographics Symposium on Computer Animation, P113
   Block Philippe., 2014, ADV ARCHITECTURAL GE
   Caldas LG, 2002, AUTOMAT CONSTR, V11, P173, DOI 10.1016/S0926-5805(00)00096-0
   CURTIS S., 2015, Menge: A modular framework for simulating crowd movement
   Golaem, 2016, GOL CROWD
   Guy SJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366209
   Helbing D, 2005, TRANSPORT SCI, V39, P1, DOI 10.1287/trsc.1040.0108
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   INCONTROLSimulation S, 2016, INCONTROLSIMULATION
   Jiang L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115463
   Merrell P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866203
   Michalek JJ, 2002, ENG OPTIMIZ, V34, P461, DOI 10.1080/03052150214016
   Pelechano Nuria., 2008, Virtual Crowds: Methods, Simulation, and Control
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Pottmann H, 2015, COMPUT GRAPH-UK, V47, P145, DOI 10.1016/j.cag.2014.11.002
   Shi X, 2013, AUTOMAT CONSTR, V32, P125, DOI 10.1016/j.autcon.2013.01.015
   Singh S, 2009, LECT NOTES COMPUT SC, V5884, P158, DOI 10.1007/978-3-642-10347-6_15
   Singh Shawn., 2011, ACM SIGGRAPH I3D, P141
   Software O, 2016, MASSMOTION CROWD SIM
   Thalmann Daniel., 2013, Crowd Simulation, VSecond
   Turrin M, 2011, ADV ENG INFORM, V25, P656, DOI 10.1016/j.aei.2011.07.009
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Yi H., 2014, P 2014 ASHRAE IBPSA, P292
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
NR 32
TC 13
Z9 14
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2017
VL 28
IS 6
AR e1749
DI 10.1002/cav.1749
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9YH
UT WOS:000417254100005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Liang, H
   Chang, J
   Deng, SJ
   Chen, C
   Tong, RF
   Zhang, JJ
AF Liang, Hui
   Chang, Jian
   Deng, Shujie
   Chen, Can
   Tong, Ruofeng
   Zhang, Jian Jun
TI Exploitation of multiplayer interaction and development of virtual
   puppetry storytelling using gesture control and stereoscopic devices
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE children learning; gesture-based control; interactive storytelling;
   stereoscopic; virtual puppetry; virtual reality
ID COORDINATION; HEAD; ENVIRONMENTS; CHILDREN; EYE
AB With the rapid development of human-computer interaction technologies, the new media generation demands novel learning experiences with natural interaction and immersive experience. Considering that digital storytelling is a powerful pedagogical tool for young children, in this paper, we design an immersive storytelling environment that allows multiple players to use naturally interactive hand gestures to manipulate virtual puppetry for assisting narration. A set of multimodal interaction techniques is presented for a hybrid user interface that integrates existing 3D visualization and interaction devices including head-mounted displays and depth motion sensor. In this system, the young players could intuitively use hand gestures to manipulate virtual puppets to perform a story and interact with props in a virtual stereoscopic environment. We have conducted a user experiment with four young children for pedagogical evaluation, as well as system acceptability and interactivity evaluation by postgraduate students. The results show that our framework has great potential to stimulate learning abilities of young children through collaboration tasks. The stereoscopic head-mounted display outperformed the traditional monoscopic display in a comparison between the two.
C1 [Liang, Hui; Chang, Jian; Deng, Shujie; Zhang, Jian Jun] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
   [Chen, Can] Changzhou Univ, Changzhou 213164, Peoples R China.
   [Tong, Ruofeng] Zhejiang Univ, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Bournemouth University; Changzhou University; Zhejiang University
RP Chang, J (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
EM jchang@bournemouth.ac.uk
OI Chang, Jian/0000-0003-4118-147X; Zhang, Jian/0000-0002-7069-5771
FU European Union [623883]; project Dr Inventor [FP7-ICT-611383]; AniNex
   [FP7-IRSES-612627]; National High-Tech Research and Development Program
   of China [2013AA013903]
FX The research leading to these results has received funding from the
   People Programme (Marie Curie Actions) of the European Union's Seventh
   Framework Programme FP7/2007-2013/ under REA grant agreement number
   [623883] -"AniM". The authors acknowledge partial support from project
   Dr Inventor (FP7-ICT-611383) and AniNex (FP7-IRSES-612627). The project
   is partially supported by the National High-Tech Research and
   Development Program of China (No. 2013AA013903).
CR [Anonymous], 2014, CHI 14 EXTENDED ABST, DOI [DOI 10.1145/2559206.2574827, 10.1145/2559206.2574827]
   Arora N, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P398, DOI 10.1145/2818567.2818681
   Barnes K., 2007, INNOVATE J ONLINE ED, V3, P1
   Boulanger C, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P350, DOI 10.1145/1409635.1409683
   Cairns P, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P371, DOI 10.1145/2556288.2557065
   Cheng LP, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3463, DOI 10.1145/2556288.2557101
   Cox A., 2012, Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, pages, P79, DOI [DOI 10.1145/2207676.2207689, 10.1145/2207676.2207689]
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Dufour T., 2014, P 1 ACM SIGCHI ANN S, P335
   Franceschini S, 2012, CURR BIOL, V22, P814, DOI 10.1016/j.cub.2012.03.013
   Garzotto F., 2006, P 2006 C INTERACTION, P113, DOI DOI 10.1145/1139073.1139102
   Garzotto F, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P356
   Greer R.D., 2002, Designing teaching strategies: An applied behavior analysis systems approach
   Hofer M., 2006, Society for Information Technology Teacher Education International Conference 2006, V1, P679
   IJsselsteijn W.A., 2007, INT C ADV COMPUTER E, V2, P27
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jonassen D.H., 2000, COMPUTERS MIND TOOLS
   Juanes JA, 2015, THIRD INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ECOSYSTEMS FOR ENHANCING MULTICULTURALITY, PROCEEDINGS TEEM'15, P19, DOI 10.1145/2808580.2808584
   Kelleher C., 2006, CMUCS06171 CARN MELL
   Liang H, 2015, GAM VIRT WORLDS SER, P1
   Llorach Gerard., 2014, P 20 ACM S VIRTUAL R, P137, DOI DOI 10.1145/2671015.2671120
   Lu F, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1919
   McKinley B., 2008, Proceeding of the twenty-sixth annual CHI conference extended abstracts on Human factors in computing systems - CHI'08, P3219, DOI DOI 10.1145/1358628.1358834
   More C, 2008, INTERV SCH CLIN, V43, P168, DOI 10.1177/1053451207312919
   Pelz J, 2001, EXP BRAIN RES, V139, P266, DOI 10.1007/s002210100745
   Psomos P, 2012, PROCD SOC BEHV, V46, P1213, DOI 10.1016/j.sbspro.2012.05.277
   Rheiner M., 2014, ACM SIGGRAPH 2014 Emerging Technologies, P3, DOI DOI 10.1145/2614066.2614101
   Russell A, 2010, TEI 2010, P271
   Skinner B.F., 1968, The technology of teaching
   Skinner RA, 2001, HUM MOVEMENT SCI, V20, P73, DOI 10.1016/S0167-9457(01)00029-X
   Smeets E, 2005, COMPUT EDUC, V44, P343, DOI 10.1016/j.compedu.2004.04.003
   Song J, 2014, COMPUT AIDED DESIGN, V46, P239, DOI 10.1016/j.cad.2013.08.039
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   Tan C.T., 2015, P CHI PLAY 15, P253
   Thompson P, 2013, COMPUT EDUC, V65, P12, DOI 10.1016/j.compedu.2012.12.022
   Vargas E.A., 1991, J BEHAV EDUC, V1, P235, DOI DOI 10.1007/BF00957006
   Wai J, 2009, J EDUC PSYCHOL, V101, P817, DOI 10.1037/a0016127
   Widjajanto W., 2008, Proceedings of the 6th International Conference on Advances in Mobile Computing and Multimedia, P464
   Yu C, 2002, LECT NOTES COMPUT SC, V2525, P611
NR 40
TC 13
Z9 13
U1 2
U2 46
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2017
VL 28
IS 5
AR e1727
DI 10.1002/cav.1727
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA FO9XG
UT WOS:000417251100002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kang, SH
   Krum, DM
   Khooshabeh, P
   Phan, T
   Chang, CY
   Amir, O
   Lin, R
AF Kang, Sin-Hwa
   Krum, David M.
   Khooshabeh, Peter
   Thai Phan
   Chang, Chien-Yen
   Amir, Ori
   Lin, Rebecca
TI Social influence of humor in virtual human counselor's self-disclosure
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE culture; ethnicity; humor; self-disclosure; smartphones; video chat
   services; virtual counseling; virtual counseling coaches; virtual humans
ID AGENTS
AB We explored the social influence of humor in a virtual human counselor's self-disclosure while also varying the ethnicity of the virtual counselor. In a 2x3 experiment (humor and ethnicity of the virtual human counselor), participants experienced counseling interview interactions via Skype on a smartphone. We measured user responses to and perceptions of the virtual human counselor. The results demonstrate that humor positively affects user responses to and perceptions of a virtual counselor. The results further suggest that matching styles of humor with a virtual counselor's ethnicity influences user responses and perceptions. The results offer insight into the effective design and development of realistic and believable virtual human counselors. Furthermore, they illuminate the potential use of humor to enhance self-disclosure in human-agent interactions.
C1 [Kang, Sin-Hwa; Krum, David M.; Thai Phan; Chang, Chien-Yen] USC Inst Creat Technol, Playa Vista, CA 90094 USA.
   [Khooshabeh, Peter] US Army Res Lab, Playa Vista, CA 90094 USA.
   [Amir, Ori; Lin, Rebecca] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
C3 United States Department of Defense; US Army Research, Development &
   Engineering Command (RDECOM); US Army Research Laboratory (ARL); United
   States Army; University of California System; University of California
   Santa Barbara
RP Kang, SH (corresponding author), USC Inst Creat Technol, Playa Vista, CA 90094 USA.
EM kang@ict.usc.edu
RI Amir, Ori/GZM-6612-2022; Krum, David/AAS-2694-2020
OI Krum, David/0000-0003-1051-5385
FU US Army Research Laboratory
FX US Army Research Laboratory
CR [Anonymous], 2007, INFLUENCE PSYCHOL PE
   [Anonymous], 1992, The International Journal of Instructional Media
   Babu S, 2006, P INT VIRT AG
   Berry K., 2004, USE HUMOR COUNSELING
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   DIMMER SA, 1990, PSYCHOL REP, V66, P795, DOI 10.2466/PR0.66.3.795-801
   FRY WF, 1987, AM BEHAV SCI, V30, P42, DOI 10.1177/000276487030003005
   Gladding ST, 1992, 340984 ERIC ED
   Goldin E, 1999, J COUNSELING DEV, V77
   Gratch J, 2007, P INT VIRT AG
   Kane T.R., 1977, It's a funny thing, humour, P13
   Kang S, 2016, P HUM COMP INT INT C
   Kang S, 2008, PROC OF COMPUTER HUM
   Kang SH, 2014, COMPUT HUM BEHAV, V34, P120, DOI 10.1016/j.chb.2014.01.006
   Khooshabeh P, 2011, P COMP HUM INT
   Kruger A., 1996, COUNSELING PSYCHOL Q, V9, P235
   Kulms P, 2014, P INT VIRT AG
   Maples MF, 2001, J COUNS DEV, V79, P53, DOI 10.1002/j.1556-6676.2001.tb01943.x
   MARTIN RA, 1993, HUMOR, V6, P89, DOI 10.1515/humr.1993.6.1.89
   Matsunaga M, 2010, INT J PSYCHOL RES, V3, P97, DOI 10.21500/20112084.854
   Morkes J, 1999, HUM-COMPUT INTERACT, V14, P395, DOI 10.1207/S15327051HCI1404_2
   MORREAULL J, 1983, TAKING LAUGHTER SERI
   Nijholt A, 2006, IEEE INTELL SYST, V21, P62
   Nijholt A, 2004, COMPUT GRAPH-UK, V28, P467, DOI 10.1016/j.cag.2004.04.002
   Norrick NealR., 1993, Conversational Joking : Humor in Everyday Talk
   NOWAK K, 2003, PRESENCE, V12
   Reeves B., 1996, The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places
   von der Pütten AM, 2010, COMPUT HUM BEHAV, V26, P1641, DOI 10.1016/j.chb.2010.06.012
   Wang N, 2010, P SIGCHI C HUM FACT
   Yin L, 2010, P INT VIRT AG
NR 30
TC 5
Z9 6
U1 3
U2 32
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1763
DI 10.1002/cav.1763
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200010
DA 2024-07-18
ER

PT J
AU Pino, AZ
   Bedia, MG
   Arbeloa, FJS
AF Zaldivar Pino, Angel
   Gonzalez Bedia, Manuel
   Seron Arbeloa, Francisco Jose
TI Modeling flocks with perceptual agents from a dynamicist perspective
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; flocking simulation; dynamical modeling; oscillators
   networks; artificial evolution
AB Computational simulations of flocks and crowds have typically been processed by a set of logic or syntactic rules. In recent decades, a new generation of systems has emerged from dynamicist approaches in which the agents and the environment are treated as a pair of dynamical systems coupled informationally and mechanically. Their spontaneous interactions allow them to achieve the desired behavior. The main proposition assumes that the agent does not need a full model or to make inferences before taking actions; rather, the information necessary for any action can be derived from the environment with simple computations and very little internal state. In this paper, we present a simulation framework in which the agents are endowed with a sensing device, an oscillator network as controller and actuators to interact with the environment. The perception device is designed as an optic array emulating the principles of the animal retina, which assimilates stimuli resembling optic flow to be captured from the environment. The controller modulates informational variables to action variables in a sensory-motor flow. Our approach is based on the Kuramoto model that describes mathematically a network of coupled phase oscillators and the use of evolutionary algorithms, which is proved to be capable of synthesizing minimal synchronization strategies based on the dynamical coupling between agents and environment. We carry out a comparative analysis with classical implementations taking into account several criteria. It is concluded that we should consider replacing the metaphor of symbolic information processing by that of sensory-motor coordination in problems of multi-agent organizations. Copyright (C) 2015 John Wiley & Sons, Ltd.
C1 [Zaldivar Pino, Angel; Gonzalez Bedia, Manuel; Seron Arbeloa, Francisco Jose] Univ Zaragoza, Adv Comp Graph Grp GIGA, Maria de Luna 1, Zaragoza 50015, Spain.
C3 University of Zaragoza
RP Pino, AZ (corresponding author), Univ Zaragoza, Adv Comp Graph Grp GIGA, Maria de Luna 1, Zaragoza 50015, Spain.
EM angelzp@gmail.com
RI Seron Arbeloa, Francisco Jose/L-3146-2014
OI Seron Arbeloa, Francisco Jose/0000-0003-1683-4694
FU Spanish "Direccion General de Investigacion" [TIN2011-24660]; European
   Commission [ALFA-Gaviota DCI-ALA/19.09.01/10/21526/245-654/ALFA
   111(2010)149]
FX This work was financed in part by project TIN2011-24660 funded by the
   Spanish "Direccion General de Investigacion" and the European Commission
   ALFA-Gaviota DCI-ALA/19.09.01/10/21526/245-654/ALFA 111(2010)149.
   Special thanks was given to Santander Bank Scholarships, University of
   Zaragoza.
CR Thalmann N. M., 2017, COMPUT ANIMAT VIRT W, V28, pe1784
NR 1
TC 1
Z9 1
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2017
VL 28
IS 1
AR e1676
DI 10.1002/cav.1748
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM0DZ
UT WOS:000394990300006
OA Bronze
DA 2024-07-18
ER

PT J
AU Pang, ZQ
   Zhao, Y
   Xiao, CX
AF Pang, Zhiqiang
   Zhao, Yong
   Xiao, Chunxia
TI Effective skeletons extraction for animated surfaces based on geometry
   propagation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE animated surfaces; skeleton extraction; skeleton alignment;
   bi-directional propagation
ID DECOMPOSITION
AB We introduce a registration-based propagation strategy to extract temporally coherent skeletons from the animated surfaces. We first extract complete skeletons for the key frames of the animated surfaces, and present a spatio-temporal L-1-medial skeleton extraction method to extract the initial skeletons for the immediate frames between the key frames. As these initial skeletons may not be complete, we then develop a global skeleton alignment method, which effectively warps the key skeleton to these initial skeletons subsequently. By using the geometry merging, we propagate the geometry of the warped key skeleton to the initial skeletons, and produce temporally coherent skeletons for the input animated surfaces. Our system can be applied to the raw scanned animated object and requires only minimal user interaction to extract complete and temporally coherent animated skeletons. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Pang, Zhiqiang; Xiao, Chunxia] Wuhan Univ, Comp Sch, Wuhan, Hubei, Peoples R China.
   [Zhao, Yong] Ocean Univ China, Sch Math Sci, Qingdao, Peoples R China.
C3 Wuhan University; Ocean University of China
RP Xiao, CX (corresponding author), Wuhan Univ, Comp Sch, Wuhan, Hubei, Peoples R China.
EM cxxiao@whu.edu.cn
RI wang, shuo/KCL-3379-2024
FU National Basic Research Program of China [2012CB725303]; NSFC [41271431,
   61472288, 61303145]; NCET [NCET-13-0441]; Key Grant Project of Hubei
   province [2013AAA020]
FX We thank Zhan Xu for proofreading the paper. This work was partly
   supported by the National Basic Research Program of China (No.
   2012CB725303), the NSFC (No. 41271431, No. 61472288, No. 61303145)),
   NCET (NCET-13-0441) and the Key Grant Project of Hubei province
   (2013AAA020).
CR Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Brown BJ, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276404, 10.1145/1239451.1239472]
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   de Aguiar E, 2008, COMPUT GRAPH FORUM, V27, P389, DOI 10.1111/j.1467-8659.2008.01136.x
   Grassia F. S., 1998, J. Graph. Tools, V6, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Katzs S, 2003, TALS HIERARCHICAL ME, V22
   Le BH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601161
   Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Liao B, 2013, COMPUT AIDED DESIGN, V45, P1394, DOI 10.1016/j.cad.2013.06.015
   Liao B, 2013, COMPUT AIDED DESIGN, V45, P861, DOI 10.1016/j.cad.2013.02.003
   Liao B, 2012, VISUAL COMPUT, V28, P387, DOI 10.1007/s00371-011-0625-4
   Pan JJ, 2009, COMPUT ANIMAT VIRT W, V20, P121, DOI 10.1002/cav.284
   Pantuwong N, 2012, COMPUT ANIMAT VIRT W, V23, P125, DOI 10.1002/cav.1429
   Sharf A, 2007, COMPUT GRAPH FORUM, V26, P323, DOI 10.1111/j.1467-8659.2007.01054.x
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Tagliasacchi A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531377
   Zheng Q, 2010, COMPUT GRAPH FORUM, V29, P635, DOI 10.1111/j.1467-8659.2009.01633.x
NR 21
TC 5
Z9 6
U1 1
U2 21
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 301
EP 309
DI 10.1002/cav.1658
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700012
DA 2024-07-18
ER

PT J
AU Ninomiya, K
   Kapadia, M
   Shoulson, A
   Garcia, F
   Badler, N
AF Ninomiya, Kai
   Kapadia, Mubbasir
   Shoulson, Alexander
   Garcia, Francisco
   Badler, Norman
TI Planning approaches to constraint-aware navigation in dynamic
   environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE path planning; spatial constraints; navigation; anytime dynamic
   planning; potential fields
AB Path planning is a fundamental problem in many areas, ranging from robotics and artificial intelligence to computer graphics and animation. Although there is extensive literature for computing optimal, collision-free paths, there is relatively little work that explores the satisfaction of spatial constraints between objects and agents at the global navigation layer. This paper presents a planning framework that satisfies multiple spatial constraints imposed on the path. The type of constraints specified can include staying behind a building, walking along walls, or avoiding the line of sight of patrolling agents. We introduce two hybrid environment representations that balance computational efficiency and search space density to provide a minimal, yet sufficient, discretization of the search graph for constraint-aware navigation. An extended anytime dynamic planner is used to compute constraint-aware paths, while efficiently repairing solutions to account for varying dynamic constraints or an updating world model. We demonstrate the benefits of our method on challenging navigation problems in complex environments for dynamic agents using combinations of hard and soft, attracting and repelling constraints, defined by both static obstacles and moving obstacles. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Ninomiya, Kai; Shoulson, Alexander; Badler, Norman] Univ Penn, Comp & Informat Sci, Philadelphia, PA 19104 USA.
   [Kapadia, Mubbasir; Garcia, Francisco] Rutgers State Univ, Comp Sci, New Brunswick, NJ 08903 USA.
C3 University of Pennsylvania; Rutgers University System; Rutgers
   University New Brunswick
RP Kapadia, M (corresponding author), Univ Penn, Comp & Informat Sci, Philadelphia, PA 19104 USA.
EM mubbasir.kapadia@gmail.com
FU U.S. Army Research Laboratory [W911NF-10-2-0016]
FX The research reported in this document/presentation was performed in
   connection with Contract Number W911NF-10-2-0016 with the U.S. Army
   Research Laboratory. The views and conclusions contained in this
   document are those of the authors and should not be interpreted as
   presenting the official policies or position, either expressed or
   implied, of the U.S. Army Research Laboratory, or the U.S. Government.
   Citation of manufacturers or trade names does not constitute an official
   endorsement or approval of the use thereof. The U.S. Government is
   authorized to reproduce and distribute reprints for Government purposes
   notwithstanding any copyright notation hereon.
CR Al Marzouqi M., 2011, Proceedings of the 2011 IEEE 5th International Conference on Robotics, Automation and Mechatronics (RAM), P77, DOI 10.1109/RAMECH.2011.6070460
   Andre E., 1986, ECAI '86. 7th European Conference on Artificial Intelligence. Proceedings, P1
   [Anonymous], 2005, P 1 INT WORKSH CROWD
   [Anonymous], 1999, P GAM DEV C
   Arkin R. C., 1987, Proceedings of the 1987 IEEE International Conference on Robotics and Automation (Cat. No.87CH2413-3), P264
   Bhattacharya S, 2012, AUTON ROBOT, V33, P273, DOI 10.1007/s10514-012-9304-1
   Bhattacharya S., 2012, P 26 AAAI C ART INT, P2097
   DECHTER R, 1985, J ACM, V32, P505, DOI 10.1145/3828.3830
   Geisberger R, 2008, LECT NOTES COMPUT SC, V5038, P319, DOI 10.1007/978-3-540-68552-4_24
   Geraerts R, 2010, IEEE INT CONF ROBOT, P1997, DOI 10.1109/ROBOT.2010.5509263
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Hart Peter E, 1972, SIGART Bull, V1, P28
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hernandez E., 2011, OCEANS 2011 IEEE SPA, P1
   Kallmann M., 2010, P 2010 ACM SIGGRAPH, P159
   Kapadia M., 2013, P 12 ACM SIG GRAPHEU, P115, DOI DOI 10.1145/2485895.2485909
   Kapadia M., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games, I3D '09, P215
   Kapadia M, 2013, WIRES COGN SCI, V4, P263, DOI 10.1002/wcs.1223
   Kapadia M, 2012, VISUAL COMPUT, V28, P1209, DOI 10.1007/s00371-011-0669-5
   Kapadias M, 2013, P 2013 ACM SIGGRAPH, P111
   Koenig S, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P476
   Likhachev M., 2005, P ICAPS, V5, P262
   Likhachev M., 2003, ADV NEURAL INFORM PR, V16, P767
   MITCHELL JSB, 1991, J ACM, V38, P18, DOI 10.1145/102782.102784
   Mononens M, 2009, RECAST NAVIGATION ME
   Narayanappas S, 2006, EXACT SOLUTIONS SIMP
   Oliva R, 2013, COMPUT GRAPH-UK, V37, P403, DOI 10.1016/j.cag.2013.03.004
   Oliva Ramon, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P328, DOI 10.1007/978-3-642-25090-3_28
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pelechanos N, 2008, VIRTUAL CROWDS METHO
   Phillipss M, 2013, ROBOTICS SCI SYSTEMS, VIX
   Reif J, 2001, ALGORITHMIC AND COMPUTATIONAL ROBOTICS: NEW DIRECTIONS, P191
   Schuerman M, 2010, COMPUT ANIMAT VIRT W, V21, P267, DOI 10.1002/cav.367
   Schultess D, 2008, ROUTE PLANNING ROAD
   Shimoda S, 2005, IEEE INT CONF ROBOT, P2828
   Shoulson A., 2013, I3D, P9
   Singh S, 2011, COMPUT ANIMAT VIRT W, V22, P151, DOI 10.1002/cav.403
   Singh Shawn., 2011, ACM SIGGRAPH I3D, P141
   Sturtevant N., 2013, Proceedings of the 9th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE'13), P177
   Sturtevant NR, 2012, IEEE T COMP INTEL AI, V4, P144, DOI 10.1109/TCIAIG.2012.2197681
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P535, DOI 10.1002/cav.1468
   Warren C. W., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P500, DOI 10.1109/ROBOT.1990.126028
   WARREN CW, 1989, PROCEEDINGS - 1989 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOL 1-3, P316, DOI 10.1109/ROBOT.1989.100007
   Xu YLD, 2000, COMP ANIM CONF PROC, P30, DOI 10.1109/CA.2000.889029
NR 47
TC 17
Z9 18
U1 0
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2015
VL 26
IS 2
BP 119
EP 139
DI 10.1002/cav.1622
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CG3GB
UT WOS:000353165400004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lu, XQ
   Wang, ZH
   Xu, ML
   Chen, WZ
   Deng, ZG
AF Lu, Xuequan
   Wang, Zonghui
   Xu, Mingliang
   Chen, Wenzhi
   Deng, Zhigang
TI A personality model for animating heterogeneous traffic behaviors
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE heterogeneous traffic; behavioral animation; personality traits
ID WAVES
AB How to automatically generate realistic and heterogeneous traffic behaviors has been a much needed yet challenging problem for numerous traffic simulation and urban planning applications. In this paper, we propose a novel approach to model heterogeneous traffic behaviors by adapting a well-established personality trait model (i.e., Eysenck's PEN (psychoticism, extraversion and neuroticism) model) into widely used traffic simulation approaches. First, we collected a large amount of user feedback while users watch a variety of computer-generated traffic simulation video clips. Then, we trained regression models to bridge low-level traffic simulation parameters and high-level perceived traffic behaviors (i.e., adjectives according to the PEN model and the three PEN traits). We also conducted an additional user study to validate the effectiveness and usefulness of our approach, in particular, high correlation coefficients and the Pearson values between users' feedback and our model predictions prove the effectiveness of our approach. Furthermore, our approach can also produce interesting emergent traffic patterns including faster-is-slower effect and sticking-in-a-pin-wherever-there-is-room effect. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Lu, Xuequan; Wang, Zonghui; Chen, Wenzhi] Zhejiang Univ, Hangzhou 310027, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450052, Henan, Peoples R China.
   [Deng, Zhigang] Univ Houston, Houston, TX USA.
C3 Zhejiang University; Zhengzhou University; University of Houston System;
   University of Houston
RP Wang, ZH (corresponding author), Zhejiang Univ, Hangzhou 310027, Peoples R China.
EM zjuzhwang@zju.edu.cn
RI 陳, 文誌/AAI-6255-2021; wen, Wen/KBB-1727-2024
OI Deng, Zhigang/0000-0003-2571-5865; Lu, Xuequan/0000-0003-0959-408X;
   Deng, Zhigang/0000-0002-0452-8676
FU National Science and Technology Support Program [2013BAH23F01]; Natural
   Science Foundation of China [61328204, 61202207]; China Postdoctoral
   Science Foundation [2012M520067, 2013T60706]; Research Fund for the
   Doctoral Program of Higher Education of China [20124101120005]
FX This research is supported by National Science and Technology Support
   Program (Grant 2013BAH23F01), Natural Science Foundation of China
   (Grants 61328204 and 61202207), China Postdoctoral Science Foundation
   (Grants 2012M520067 and 2013T60706), and Research Fund for the Doctoral
   Program of Higher Education of China (Grant 20124101120005).
CR [Anonymous], 1950, Osterreichisches Ingenieur Arch.
   BLOCK J, 1995, PSYCHOL BULL, V117, P187, DOI 10.1037/0033-2909.117.2.187
   Choudhury CF, 2004, THESIS MIT
   Costa P.T., 1992, REVISED NEO PERSONAL
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Eysenck H. J., 1985, PERSONALITY INDIVIDU
   Eysenck HJ, 2013, EYSENCK PERSONALITY
   EYSENCK SBG, 1977, BRIT J SOC CLIN PSYC, V16, P57, DOI 10.1111/j.2044-8260.1977.tb01003.x
   Gerlough D. L., 1955, THESIS U CALIFORNIA
   Guy S.J., 2011, P 2011 ACM SIGGRAPH, P43, DOI [10.1145/2019406.2019413, DOI 10.1145/2019406.2019413]
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Kesting A, 2008, TRANSPORT RES C-EMER, V16, P668, DOI 10.1016/j.trc.2007.12.004
   Kesting A, 2010, PHILOS T R SOC A, V368, P4585, DOI 10.1098/rsta.2010.0084
   Kesting A, 2008, TRANSPORT RES REC, P148, DOI 10.3141/2088-16
   Kesting Arne., 2013, Traffic Flow Dynamics: Data, Models and Simulation
   LIGHTHILL MJ, 1955, PROC R SOC LON SER-A, V229, P317, DOI 10.1098/rspa.1955.0089
   Lu XQ, 2014, COMPUT ANIMAT VIRT W, V25, P83, DOI 10.1002/cav.1540
   NAGEL K, 1992, J PHYS I, V2, P2221, DOI 10.1051/jp1:1992277
   Nelson P, 1997, TRANSPORTATION SYSTE, P799
   NEWELL GF, 1961, OPER RES, V9, P209, DOI 10.1287/opre.9.2.209
   Payne H.J., 1971, SIMULATION COUNCILS, V1, P51
   PRIGOGINE I, 1960, OPER RES, V8, P789, DOI 10.1287/opre.8.6.789
   RICHARDS PI, 1956, OPER RES, V4, P42, DOI 10.1287/opre.4.1.42
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   Sewall J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024169
   Treiber M, 2000, PHYS REV E, V62, P1805, DOI 10.1103/PhysRevE.62.1805
   Treiber M, 2006, PHYSICA A, V360, P71, DOI 10.1016/j.physa.2005.05.001
   Treiber M, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.046119
   Whitman GB, 1974, LINEAR NONLINEAR WAV
   Wilkie D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462021
   Zhang HM, 2002, TRANSPORT RES B-METH, V36, P275, DOI 10.1016/S0191-2615(00)00050-3
NR 31
TC 16
Z9 19
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 363
EP 373
DI 10.1002/cav.1575
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300017
DA 2024-07-18
ER

PT J
AU Pitiot, T
   Cazier, D
   Jund, T
   Habibi, A
   Kraemer, P
AF Pitiot, Thomas
   Cazier, David
   Jund, Thomas
   Habibi, Arash
   Kraemer, Pierre
TI Deformable polygonal agents in crowd simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; collision detection; virtual worlds; deformable
   entities; particle tracking
AB To produce impressive virtual worlds, real-time crowd simulations require large and detailed scenes populated by agents with complex shapes and geometry. For efficiency reasons, these agents are usually approximated by point-like representations to optimize the performances of collision avoidance and interactions between agents. This paper addresses the issue of handling deformable polygonal agents with arbitrary shapes in real time crowd simulations. The proposed multiresolution framework supports environments with arbitrary topologies and provides tools for efficient proximity queries. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Pitiot, Thomas; Cazier, David; Jund, Thomas; Habibi, Arash; Kraemer, Pierre] Univ Strasbourg, CNRS, ICube, UMR 7357,Geometry & Comp Graph Grp, Illkirch Graffenstaden, France.
C3 Universites de Strasbourg Etablissements Associes; Universite de
   Strasbourg; Centre National de la Recherche Scientifique (CNRS); CNRS -
   Institute for Engineering & Systems Sciences (INSIS)
RP Pitiot, T (corresponding author), Univ Strasbourg, CNRS, ICube, UMR 7357,Geometry & Comp Graph Grp, Illkirch Graffenstaden, France.
EM pitiot@unistra.fr
RI HABIBI, Arash/D-6564-2018
OI Cazier, David/0000-0001-5247-6404
CR [Anonymous], SIAM ACM GDSPM
   [Anonymous], 2013, P SCA 2013 12 ACM SI, DOI DOI 10.1145/2485895.2485910
   [Anonymous], SYNTHESIS LECT COMPU
   [Anonymous], 2006, PROC ACM INT C VIRTU
   Braun A, 2003, COMP ANIM CONF PROC, P143, DOI 10.1109/CASA.2003.1199317
   Fiorini P, 1998, INT J ROBOT RES, V17, P760, DOI 10.1177/027836499801700706
   Golas A, 2014, IEEE T VIS COMPUT GR, V20, P1022, DOI 10.1109/TVCG.2013.235
   Goldenstein S, 2001, COMPUT GRAPH-UK, V25, P983, DOI 10.1016/S0097-8493(01)00153-4
   Guy S., 2009, EUR ACM SIGGRAPH S C, P177
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   Jiang H, 2010, COMPUT GRAPH-UK, V34, P537, DOI 10.1016/j.cag.2010.05.013
   Jund T, 2012, COMPUT ANIMAT VIRT W, V23, P311, DOI 10.1002/cav.1449
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   Levine S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966402
   Lopez T, 2012, COMPUT ANIMAT VIRT W, V23, P87, DOI 10.1002/cav.1428
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Sewall J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024169
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Shen JJ, 2012, GRAPH MODELS, V74, P265, DOI 10.1016/j.gmod.2012.04.002
   Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
NR 22
TC 2
Z9 4
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 343
EP 352
DI 10.1002/cav.1581
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300015
DA 2024-07-18
ER

PT J
AU Ahn, J
   Gobron, S
   Thalmann, D
   Boulic, R
AF Ahn, Junghyun
   Gobron, Stephane
   Thalmann, Daniel
   Boulic, Ronan
TI Asymmetric facial expressions: revealing richer emotions for embodied
   conversational agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE asymmetric facial expression; VAD emotional model; real-time
   application; evaluation study; embodied agent; linear model
ID RECOGNITION; AREAS
AB In this paper, we propose a method to achieve effective facial emotional expressivity for embodied conversational agents by considering two types of asymmetry when exploiting the valence-arousal-dominance representation of emotions. Indeed, the asymmetry of facial expressions helps to convey complex emotional feelings such as conflicting and/or hidden emotions due to social conventions. To achieve such a higher degree of facial expression in a generic way, we propose a new model for mapping the valence-arousal-dominance emotion model onto a set of 12 scalar facial part actions built mostly by combining pairs of antagonist action units from the Facial Action Coding System. The proposed linear model can automatically drive a large number of autonomous virtual humans or support the interactive design of complex facial expressions over time. By design, our approach produces symmetric facial expressions, as expected for most of the emotional spectrum. However, more complex ambivalent feelings can be produced when differing emotions are applied on the left and right sides of the face. We conducted an experiment on static images produced by our approach to compare the expressive power of symmetric and asymmetric facial expressions for a set of eight basic and complex emotions. Results confirm both the pertinence of our general mapping for expressing basic emotions and the significant improvement brought by asymmetry for expressing ambivalent feelings. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Ahn, Junghyun; Gobron, Stephane; Boulic, Ronan] Ecole Polytech Fed Lausanne, IIG, CH-1015 Lausanne, Switzerland.
   [Gobron, Stephane] HE Arc, Informat & Commun Syst ISIC, St Imier, Switzerland.
   [Thalmann, Daniel] Nanyang Technol Univ, Inst Media Innovat, Singapore 639798, Singapore.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Nanyang Technological University
RP Ahn, J (corresponding author), Ecole Polytech Fed Lausanne, IIG, EPFL SCI IC RB, Stn 14, CH-1015 Lausanne, Switzerland.
EM junghyun.ahn@epfl.ch
RI Thalmann, Daniel/A-4347-2008; Thalmann, Daniel/AAL-1097-2020
OI Thalmann, Daniel/0000-0002-0451-7491
FU EU FP7 project CYBEREMOTIONS [231323]
FX The authors wish to thank Ms. Mireille Clavien, Mr. Olivier Renault, Mr.
   Quentin Silvestre, Dr. Janusz Holyst, Dr. Arvid Kappas, Ms. Kamila
   Kowalska, Dr. Jonathan Maim, Dr. Barbara Yersin, and Dr. Nan Wang for
   their collaboration on motion capture, character animation, avatar
   modeling, software development, and experiment design. This work was
   supported by the EU FP7 project CYBEREMOTIONS (contract 231323).
CR Ahn J, 2010, ENG SUMM SCH WORKSH
   Albrecht I., 2005, J VIRTUAL REALITY, V8, P201, DOI DOI 10.1007/S10055-005-0153-5
   [Anonymous], 2008, Computer Facial Animation
   Averill J. R., 1975, JSAS CATALOG SELECTE, V5, P1
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   BOROD JC, 1980, NEUROPSYCHOLOGIA, V18, P237, DOI 10.1016/0028-3932(80)90070-6
   Borod JC, 1997, NEUROPSYCHOL REV, V7, P41, DOI 10.1007/BF02876972
   Borod JC, 1998, NEUROPSYCHOLOGIA, V36, P1209, DOI 10.1016/S0028-3932(97)00166-8
   BOUCHER JD, 1975, J COMMUN, V25, P21, DOI 10.1111/j.1460-2466.1975.tb00577.x
   Bradley M.M., 1999, PSYCHOLOGY
   BUSH LE, 1973, J PERS SOC PSYCHOL, V25, P50, DOI 10.1037/h0034274
   CAMPBELL R, 1982, INT J PSYCHOL, V17, P211, DOI 10.1080/00207598208247442
   Chmiel A, 2011, PHYSICA A, V390, P2936, DOI 10.1016/j.physa.2011.03.040
   Cowie R, 2009, PHILOS T R SOC B, V364, P3515, DOI 10.1098/rstb.2009.0139
   Deng Zhigang., 2007, DATA DRIVEN 3D FACIA
   Dimberg U, 2000, PSYCHOPHYSIOLOGY, V37, P693, DOI 10.1017/S0048577200990759
   Egges A, 2004, COMPUT ANIMAT VIRT W, V15, P1, DOI 10.1002/cav.3
   EKMAN P, 1980, CHILD DEV, V51, P886, DOI 10.1111/j.1467-8624.1980.tb02627.x
   EKMAN P, 1980, J PERS SOC PSYCHOL, V39, P1125, DOI 10.1037/h0077722
   EKMAN P, 1982, J NONVERBAL BEHAV, V6, P238, DOI 10.1007/BF00987191
   Ekman P., 1979, Human Ethology, P169
   Ekman P., 1971, NEBRASKA S MOTIVATIO, P207
   Ekman P, 1978, FACIAL ACTION CODING
   Fasel B, 2000, INT C PATT RECOG, P1100, DOI 10.1109/ICPR.2000.905664
   GRAMMER K, 1994, J COMP PSYCHOL, V108, P233, DOI 10.1037/0735-7036.108.3.233
   Junghyun Ahn, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P122, DOI 10.1007/978-3-642-34710-8_12
   Krumhuber E, 2005, J NONVERBAL BEHAV, V29, P3, DOI 10.1007/s10919-004-0887-x
   Lance B, 2010, AUTON AGENT MULTI-AG, V20, P50, DOI 10.1007/s10458-009-9097-6
   Magnenat-Thalmann Nadia., 2004, HDB VIRTUAL HUMANS
   Martin JC, 2006, INT J HUM ROBOT, V3, P269, DOI 10.1142/S0219843606000825
   McManus IC., 2005, EUR REV, V13, P157, DOI [DOI 10.1017/S1062798705000736, 10.1017/S1062798705000736]
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, V12
   Norman GJ, 2011, EMOT REV, V3, P349, DOI 10.1177/1754073911402403
   Patterson H., 2001, Proceedings of the 23rd Annual Conference of the Cognitive Science Society, P756
   Pelachaud C, 2002, J VISUAL COMP ANIMAT, V13, P301, DOI 10.1002/vis.299
   Pelachaud C, 2009, PHILOS T R SOC B, V364, P3539, DOI 10.1098/rstb.2009.0186
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   SACKEIM HA, 1978, SCIENCE, V202, P434, DOI 10.1126/science.705335
   Schatz Howard., 2006, In Character: Actors Acting
   SCHIFF BB, 1990, NEUROPSYCHOLOGIA, V28, P777, DOI 10.1016/0028-3932(90)90002-6
   SCHWARTZ GE, 1979, PSYCHOPHYSIOLOGY, V16, P561, DOI 10.1111/j.1469-8986.1979.tb01521.x
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Vinayagamoorthy V, 2006, EUR C STAT ART REP E
   WYLER F, 1987, J CLIN EXP NEUROPSYC, V9, P105, DOI 10.1080/01688638708405351
NR 46
TC 7
Z9 7
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2013
VL 24
IS 6
BP 539
EP 551
DI 10.1002/cav.1539
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 273QL
UT WOS:000328551100003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Backman, R
   Kallmann, M
AF Backman, Robert
   Kallmann, Marcelo
TI Designing controllers for physics-based characters with motion networks
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE physics-based character animation; humanoid control
AB We present a system that allows non-programmers to create generic controllers for physically simulated characters. The core of our system is based on a directed acyclic graph of trajectory transformations, which can be modified by feedback terms and serve as reference motions tracked by the physically simulated character. We then introduce tools to enable the automatic creation of robust and parameterized controllers suitable for running in real-time applications, such as in computer games. The entire process is accomplished by means of a graphical user interface, and we demonstrate how our system can be intuitively used to design a SIMBICON-like walking controller and a parameterized jump controller to be used in real-time simulations. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Backman, Robert; Kallmann, Marcelo] Univ Calif, Merced, CA 95343 USA.
C3 University of California System; University of California Merced
RP Backman, R (corresponding author), Univ Calif, Merced 5200 Lake Rd, Merced, CA 95343 USA.
EM rbackman@ucmerced.edu
RI Kallmann, Marcelo/HSC-7222-2023
FU CITRIS [128]
FX This work was partially supported by CITRIS grant 128.
CR [Anonymous], 2012, ACM Transactions on Graphics (TOG)
   Coros S., 2008, ACM T GRAPHIC, V27, P1
   Coros S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964954
   Coros S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1781156
   Coros S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618516
   da Silva M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360681
   Faloutsos P, 2001, COMP GRAPH, P251, DOI 10.1145/383259.383287
   Hodgins J. K., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P153, DOI 10.1145/258734.258822
   Jain S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477936
   Kajita S, 2003, IEEE INT CONF ROBOT, P1620, DOI 10.1109/robot.2003.1241826
   Laszio J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P155, DOI 10.1145/237170.237231
   Lee Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1781155
   Liu L, 2012, ACM T GRAPHIC, V31, P154
   Liu LB, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778865
   Macchietto A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531386
   Mordatch I, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778808
   Muico U., 2009, ACM SIGGRAPH 2009 Papers, P1
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   Pratt J, 2001, INT J ROBOT RES, V20, P129, DOI 10.1177/02783640122067309
   Pratt JE, 2006, LECT NOTES CONTR INF, V340, P299
   Pratt J, 2006, IEEE-RAS INT C HUMAN, P200, DOI 10.1109/ichr.2006.321385
   Tsai YY, 2010, IEEE T VIS COMPUT GR, V16, P325, DOI 10.1109/TVCG.2009.76
   Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556
   Zordan V, 2007, SANDBOX SYMPOSIUM 2007: ACM SIGGRAPH VIDEO GAME SYMPOSIUM, PROCEEDINGS, P9
NR 24
TC 2
Z9 3
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2013
VL 24
IS 6
BP 553
EP 563
DI 10.1002/cav.1547
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 273QL
UT WOS:000328551100004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Djado, K
   Egli, R
   Granger, F
AF Djado, Khalid
   Egli, Richard
   Granger, Fabrice
TI Particle-based drop animation on meshes in real time
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE particles; water drop; drop deformation; drop trace; human sweating;
   water condensation; liquid-solid interaction
ID WATER DROPLETS; SIMULATION; MODEL
AB This paper presents a method for simulating the motion of water drops on a surface in real time. We describe the dynamics of a drop moving on the surface, and then we present our simulation model. We use a geometry-based representation of a drop. Each drop is modeled by a deformable 3D mesh. This geometrical representation allows drops to be on the surface or in the air. We also propose a simple method to handle drop merging and separation. For the rendering, we simulate reflection and refraction. The drop trace is also taken into account. Our method is fast and robust and yields realistic results when applied to treat condensation on a surface or human sweating in real time. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Djado, Khalid] CRIM, Res Ctr Informat Technol, Montreal, PQ, Canada.
   [Egli, Richard] Univ Sherbrooke, Dept Comp Sci, Sherbrooke, PQ J1K 2R1, Canada.
   [Granger, Fabrice] Cyanide France, Nanterre, France.
C3 Universite de Montreal; University of Sherbrooke
RP Djado, K (corresponding author), CRIM, Res Ctr Informat Technol, Montreal, PQ, Canada.
EM Khalid.Djado@siggraph.org
FU Natural Sciences and Engineering Research Council of Canada
FX This research was supported in part by grants from the Natural Sciences
   and Engineering Research Council of Canada to the second author. The
   authors would like to thank anonymous reviewers and Gilles-Philippe
   Paille, Fabrice Colin, Martin Guay, Patrick Guevin, Christian Preciado
   Castelo, and Olivier Vaillancourt for their comments.
CR Algan Eren, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P361, DOI 10.1109/3DTV.2008.4547883
   DJADO Khalid., 2009, AFRIGRAPH '09, P65
   Dorsey J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P411, DOI 10.1145/237170.237280
   El Hajjar J-F, 2008, THESIS U LIMOGES SAN
   El Hajjar JF, 2009, VISUAL COMPUT, V25, P87, DOI 10.1007/s00371-007-0207-7
   Elcott S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1189762.1189766
   Fan Z., 2005, ACM SIGGRAPHEUROGRAP, P245
   Fournier P, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P133
   Iglesias A, 2001, CAD/GRAPHICS '2001: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN AND COMPUTER GRAPHICS, VOLS 1 AND 2, P350
   Jung Y., 2009, Proceedings of the 14th international conference on 3D web technology, P51, DOI [10.1145/1559764.1559772, DOI 10.1145/1559764.1559772]
   Kaneda K., 1996, 1996 Pacific Graphics Conference Proceedings, P50
   Kaneda K, 1999, J VISUAL COMP ANIMAT, V10, P15, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<15::AID-VIS192>3.0.CO;2-P
   Kaneda K., 1993, Models and Techniques in Computer Animation, P177
   Lui LM, 2005, LECT NOTES COMPUT SC, V3752, P307
   Marieb Elaine Nicpon, 2007, Human Anatomy Physiology
   Murta A., 1999, 7th International Conference in Central Europe on Computer Graphics, Visualization and Interactive Digital Media'99. in co-operation with EUROGRAPHICS and IFIP WG 5.10. WSCG'99. Conference Proceedings, P194
   Sato T, 2002, IFIP 1 INT WORKSH EN, V240, P125
   Shi L, 2004, COMPUT ANIMAT VIRT W, V15, P173, DOI 10.1002/cav.19
   Stam J, 2003, ACM T GRAPHIC, V22, P724, DOI 10.1145/882262.882338
   TAKENAKA S., 2008, The 23rd International Techmcal Conference on Circuits/Systems, Computers and Communications (ITC-CSCC), P13
   Tong RF, 2002, VISUAL COMPUT, V18, P469, DOI 10.1007/s003710100164
   Wang HM, 2005, ACM T GRAPHIC, V24, P921, DOI 10.1145/1073204.1073284
   Yang YG, 2004, COMPUT SCI ENG, V6, P69, DOI 10.1109/MCSE.2004.20
   Yu YJ, 1999, COMPUT GRAPH-UK, V23, P213, DOI 10.1016/S0097-8493(99)00031-X
   Yu YJ, 1998, WSCG '98, VOL 3, P432
NR 25
TC 6
Z9 8
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 301
EP 309
DI 10.1002/cav.1446
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100017
DA 2024-07-18
ER

PT J
AU Chen, L
   Huang, J
   Zhang, HX
   Hua, W
AF Chen, Lu
   Huang, Jin
   Zhang, Hongxin
   Hua, Wei
TI GPU-friendly shape interpolation based on trajectory warping
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE shape interpolation; vertex path problem; trajectory warping
ID REAL-TIME SIMULATION; MESH
AB In this paper, we propose a GPU-friendly shape interpolation method. In contrast with state-of-the-art interpolation algorithms, our method computes the trajectory of each vertex independently instead of solving large linear systems in every interpolation step. Given two poses being interpolated, we find trajectory parameters for each vertex by optimization with the consideration of the key pose reconstruction and as-rigid-as-possible deformation in the pre-computing stage. During run-time, the vertices coordinates on the intermediate shape can be computed in parallel according to a close form formulation. In the results we demonstrate that our method achieves extremely high performance on modern GPU and can be extended easily to multi-pose interpolation. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Chen, Lu; Huang, Jin; Zhang, Hongxin; Hua, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Hua, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
EM huawei@cad.zju.edu.cn
CR Alexa M, 2003, VISUAL COMPUT, V19, P105, DOI 10.1007/s00371-002-0180-0
   Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575
   Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   Botsch M, 2006, Vision, modeling & visualization, P357
   Choi MG, 2005, IEEE T VIS COMPUT GR, V11, P91
   Choi MG, 2007, COMPUT GRAPH FORUM, V26, P349, DOI 10.1111/j.1467-8659.2007.01057.x
   Chu HK, 2009, IEEE T VIS COMPUT GR, V15, P853, DOI [10.1109/TVCG.2009.40, 10.1109/TVCG.2008-06-0082]
   Der KG, 2006, ACM T GRAPHIC, V25, P1174, DOI 10.1145/1141911.1142011
   FENG WW, 2008, SIGGRAPH, P1
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Kilian M, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239515, 10.1145/1276377.1276457]
   Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811
   LEE TY, 2006, COMPUT ANIMAT VIRTUA, P433, DOI DOI 10.1002/CAV.V17:3/4
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Schreiner J, 2004, ACM T GRAPHIC, V23, P870, DOI 10.1145/1015706.1015812
   SHEFFER A, 2003, P 3D DAT PROC VIS T, P68, DOI DOI 10.1109/3DPVT.2004.99
   Sumner RW, 2005, ACM T GRAPHIC, V24, P488, DOI 10.1145/1073204.1073218
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Xu DH, 2005, SOUTHEAST SYMP SYSTE, P267, DOI 10.1145/1060244.1060274
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
NR 20
TC 0
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 285
EP 294
DI 10.1002/cav.407
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700025
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xiao, XZ
   Huang, H
   Ma, LZ
AF Xiao, Xuezhong
   Huang, Hua
   Ma, Lizhuang
TI RBF network-based temporal color morphing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE video-based rendering; temporal color morphing; RBF networks
ID IMAGE; ALGORITHM
AB A method of RBF network-based temporal color morphing is proposed to simulate the natural phenomena characterized by temporal color alteration, e.g., turning green of foliage, resurgence of leaves. Such phenomena usually span a long time and it is very difficult to capture their whole process. Our system accepts a source image sequence and a reference image as input. The source sequence contains the desired scene except for color alteration, and the reference image has the color style which the source sequence is expected to advance into. First, an RBF network is employed to model the mapping between the colors of the source sequence and the reference image. Then, a simple interpolation algorithm is applied to render the resulting sequence. The effectiveness of the new method is verified by experiments. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Huang, Hua] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Ma, Lizhuang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Data Reconstruct Lab, Shanghai, Peoples R China.
C3 Xi'an Jiaotong University; Shanghai Jiao Tong University
RP Huang, H (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 Xianning W Rd, Xian 710049, Peoples R China.
EM huanghua@xjtu.edu.cn
RI Huang, Hua/M-9684-2013
OI Huang, Hua/0000-0003-2587-1702
CR Alexandridis A, 2003, NEURAL NETWORKS, V16, P1003, DOI 10.1016/S0893-6080(03)00052-2
   An XB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360639
   Chang Y., 2005, ACM Trans. Appl. Perception, V2, P322
   Chang YH, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P176, DOI 10.1109/CGI.2003.1214463
   Chang Y, 2007, IEEE T IMAGE PROCESS, V16, P329, DOI 10.1109/TIP.2006.888347
   CHEN S, 1995, ELECTRON LETT, V31, P117, DOI 10.1049/el:19950085
   Clark B., 2002, Guide to Postproduction for TV and Film: Managing the Process
   GREENFIELD GR, 2003, P WSCG
   Haykin S., 1998, NEURAL NETWORKS COMP
   Pitié F, 2005, IEEE I CONF COMP VIS, P1434
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Tai YW, 2007, IEEE T PATTERN ANAL, V29, P1520, DOI 10.1109/TPAMI.2007.1168
   Tai YW, 2005, PROC CVPR IEEE, P747
   Wang CM, 2004, J INF SCI ENG, V20, P1039
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Wen CL, 2008, COMPUT GRAPH FORUM, V27, P1765, DOI 10.1111/j.1467-8659.2008.01321.x
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   XIAO X, ENTERTAINMENT COMPUT, P104
   Xu K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618464
   Yan HB, 2007, J COMPUT SCI TECH-CH, V22, P147, DOI 10.1007/s11390-007-9020-z
   Yan HB, 2004, COMPUT ANIMAT VIRT W, V15, P443, DOI 10.1002/cav.48
NR 21
TC 1
Z9 3
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 289
EP 296
DI 10.1002/cav.343
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400016
DA 2024-07-18
ER

PT J
AU You, LH
   Yang, XS
   You, XY
   Jin, XG
   Zhang, JJ
AF You, L. H.
   Yang, Xiaosong
   You, X. Y.
   Jin, Xiaogang
   Zhang, Jian J.
TI Shape manipulation using physically based wire deformations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 23rd International Conference on Computer Animation and Social Agents
   (CASA 2010)
CY MAY 30-JUN 02, 2010
CL St Malo, FRANCE
DE shape manipulation; surface models; physically based wire deformations;
   ordinary differential equations; closed form solution
ID SPACE DEFORMATIONS; SURFACE; GENERATION; MODELS; VOLUME
AB This paper develops an efficient, physically based shape manipulation technique. It defines a 3D model with profile curves, and uses spine curves generated from the profile curves to control the motion and global shape of 3D models. Profile and spine curves are changed into profile and spine wires by specifying proper material and geometric properties together with external forces. The underlying physics is introduced to deform profile and spine wires through the closed form solution to ordinary differential Equations for axial and bending deformations. With the proposed approach, global shape changes are achieved through manipulating spine wires, and local surface details are created by deforming profile wires. A number of examples are presented to demonstrate the applications of our proposed approach in shape manipulation. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Zhang, Jian J.] Bournemouth Univ, Bournemouth Media Sch, Comp Animat Res Ctr, Poole BH12 5BB, Dorset, England.
   [Yang, Xiaosong; Zhang, Jian J.] Bournemouth Univ, Natl Ctr Comp Animat, Bournemouth Media Sch, Poole BH12 5BB, Dorset, England.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
   [Yang, Xiaosong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
   [Yang, Xiaosong] Chinese Univ Hong Kong, Virtual Real Visualizat & Imaging Res Ctr, Hong Kong, Hong Kong, Peoples R China.
C3 Bournemouth University; Bournemouth University; Zhejiang University;
   Tsinghua University; Chinese University of Hong Kong
RP Zhang, JJ (corresponding author), Bournemouth Univ, Media Sch, Poole BH12 5BB, Dorset, England.
EM jzhang@bournemouth.ac.uk
OI Zhang, Jian/0000-0002-7069-5771; Yang, Xiaosong/0000-0003-3815-0584
CR Au OKC, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239534, 10.1145/1276377.1276481]
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Botsch M, 2007, COMPUT GRAPH FORUM, V26, P339, DOI 10.1111/j.1467-8659.2007.01056.x
   Cohen-Or D, 2009, J COMPUT SCI TECH-CH, V24, P2, DOI 10.1007/s11390-009-9200-0
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Gal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531339
   HSU WM, 1992, COMP GRAPH, V26, P177, DOI 10.1145/142920.134036
   Hu SM, 2001, VISUAL COMPUT, V17, P370, DOI 10.1007/s003710100114
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Irving G, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239464
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Ju T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409075
   KOBBELT L, 1998, P SIGGRAPH 98, P105, DOI DOI 10.1145/280814.280831
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1189762.1189767, 10.1145/1186644.1186649]
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Marinov M, 2005, COMPUT GRAPH FORUM, V24, P479, DOI 10.1111/j.1467-8659.2005.00873.x
   McDonnell KT, 2007, VISUAL COMPUT, V23, P285, DOI 10.1007/s00371-007-0096-9
   Meriam J.L., 2002, ENG MECH DYNAMICS
   Nealen A, 2005, ACM T GRAPHIC, V24, P1142, DOI 10.1145/1073204.1073324
   Nealen A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276429
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Nesme M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531358
   Pyun H, 2004, COMPUT GRAPH-UK, V28, P757, DOI 10.1016/j.cag.2004.06.013
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Shi L, 2006, ACM T GRAPHIC, V25, P1108, DOI 10.1145/1141911.1142001
   SINGH K., 1998, SIGGRAPH 98, P405, DOI DOI 10.1145/280814.280946
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Yan HB, 2008, IEEE T VIS COMPUT GR, V14, P693, DOI 10.1109/TVCG.2008.28
   Yoon SH, 2006, COMPUT GRAPH FORUM, V25, P487, DOI 10.1111/j.1467-8659.2006.00968.x
   You LH, 2004, VISUAL COMPUT, V20, P199, DOI 10.1007/s00371-003-0241-7
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zhang JJ, 2004, COMPUT GRAPH FORUM, V23, P311, DOI 10.1111/j.1467-8659.2004.00762.x
   ZORIN D, 1997, P SIGGRAPH 97, P259
NR 36
TC 8
Z9 10
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2010
VL 21
IS 3-4
SI SI
BP 297
EP 309
DI 10.1002/cav.352
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 628QJ
UT WOS:000280135400017
OA Green Accepted
DA 2024-07-18
ER

PT J
AU García, M
   Espadero, JM
   Pastor, L
   Rodríguez, A
AF Garcia, M.
   Espadero, J. M.
   Pastor, L.
   Rodriguez, A.
TI SPEM:: A new haptic rendering method based on time coherence
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE haptic rendering; virtual reality systems; proxy computation; deformable
   models
AB Nowadays many interactive computer graphics applications use the haptic channel to achieve higher degrees of immersion. Most of these systems have to deal with soft bodies and they always demand higher and higher levels of realism, increasing the complexity of the animated scenarios. Therefore, the techniques used to animate the objects should be very efficient to grant interactivity. Furthermore, one of the most important issues in physically based simulations is to keep the model stable under all simulation conditions. This paper presents a technique called Separated Proxy-Effector Method (SPEM) to keep high levels of stability in the haptic response without degrading the performance of the simulation system. SPEM is fast, haptic plausible, robust, and it deals with soft bodies. Experimental results show the advantages of this new approach from the point of view of stability, in particular if it is compared with distance-based minimization techniques. Its simplicity grants efficient implementations for a wide range of applications. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Univ Politecn Madrid, Dept Technol Fotonica, E-28660 Madrid, Spain.
C3 Universidad Politecnica de Madrid
RP Rodríguez, A (corresponding author), Univ Politecn Madrid, Dept Technol Fotonica, Campus Montegancedo s-n, E-28660 Madrid, Spain.
EM arodri@dtf.fi.upm.es
RI Rodríguez, Angel/AAT-4582-2021; Pastor, Luis/E-4700-2019;
   Garcia-Lorenzo, Marcos/K-5870-2014
OI Rodríguez, Angel/0000-0002-5145-5676; Garcia-Lorenzo,
   Marcos/0000-0003-4413-4820
CR [Anonymous], P ROB SCI SYST
   AVILA RS, 1999, SIGGRAPH 1999 COURSE, V38
   BALANIUK R, 2000, 5 PHANTOM US GROUP W
   BALANIUM RA, 2006, VRST 06 P ACM S VIRT, P297
   Barbagli F, 2005, INT J ROBOT RES, V24, P703, DOI 10.1177/0278364905057055
   Burdea G. C., 2003, Virtual reality technology
   Chen P, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P499
   *COIN3D, 2007, SYST MOT
   *COMP GRAPH LAB, 2007, STANF 3D SCANN REP
   Conti F, 2003, IEEE INT CONF ROBOT, P3716
   CORSO J, 2002, EUROHAPTICS, P92
   Garcia M, 2005, LECT NOTES COMPUT SC, V3804, P167
   García M, 2006, COMPUT ANIMAT VIRT W, V17, P393, DOI 10.1002/cav.142
   GREGORY A, 2000, VISUALIZATION 00 P 1
   Ho CH, 1999, PRESENCE-VIRTUAL AUG, V8, P477, DOI 10.1162/105474699566413
   Laycock SD, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P148, DOI 10.1109/CGI.2004.1309205
   Laycock SD, 2003, COMPUT GRAPH FORUM, V22, P117, DOI 10.1111/1467-8659.00654
   Massie T. H., 1994, P S HAPT INT VIRT EN, P295
   Miller LA, 2005, J THEOR BIOL, V234, P511, DOI 10.1016/j.jtbi.2004.12.004
   Mitra P, 2004, 2004 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1 AND 2, P1054
   Moore M., 1988, Computer Graphics, V22, P289, DOI 10.1145/378456.378528
   Ruspini D. C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P345, DOI 10.1145/258734.258878
   Salisbury K, 2004, IEEE COMPUT GRAPH, V24, P24, DOI 10.1109/MCG.2004.1274058
   *SENS TECHN, 2007, OP TOOLK
   *SIL GRAPH, 2007, OP INVENT
   SPILLMAN J, 2006, P 3 INT WORKSH VIRT, P53
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   VAFAI NM, 2006, ICMI 06 P 8 INT C MU, P310
   ZILLES CB, 1995, IROS 95 P INT C INT, P3146
NR 29
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 319
EP 328
DI 10.1002/cav.198
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000011
DA 2024-07-18
ER

PT J
AU Guan, Y
   Chen, W
   Zou, LC
   Zhang, L
   Peng, QS
AF Guan, Yu
   Chen, Wei
   Zou, Lincan
   Zhang, Long
   Peng, Qunsheng
TI Modeling and rendering of realistic waterfall scenes with dynamic
   texture sprites
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dynamic texture sprites; texture synthesis; video-based rendering;
   natural scene simulation
ID VIDEO SYNTHESIS
AB We propose an efficient approach for authoring dynamic and realistic waterfall scenes based on an acquired video sequence. Traditional video based techniques generate new images by synthesizing 2D samples, i.e., texture sprites chosen from a video sequence. However, they are limited to one fixed viewpoint and cannot provide arbitrary walkthrough into 3D scenes. Our approach extends this scheme by synthesizing dynamic 2D texture sprites and projecting them into 3D space, We first generate a set of basis texture sprites, which capture the representative appearance and motions of waterfall scenes contained in the video sequence. To model the shape and motion Of a new waterfall scene, we interactively construct a set of flow lines taking account of physical principles. Along each flow line, the basis texture sprites are manipulated and animated dynamically, yielding a sequence of dynamic texture sprites in 3D space. These texture sprites are displayed using the point splatting technique, which can be accelerated efficiently by graphics hardware. By choosing varied basis texture sprites, waterfall scenes with different appearance and shapes can be conveniently simulated. The experimental results demonstrate that our approach achieves realistic effects and real-time frame rates on consumer PC platforms. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
EM chenwei@cad.zju.edu.cn
RI Chen, Wei/AAR-9817-2020
CR [Anonymous], P SIGGRAPHS, DOI DOI 10.1145/218380.218446
   Bar-Joseph Z, 2001, IEEE T VIS COMPUT GR, V7, P120, DOI 10.1109/2945.928165
   Bhat KS, 2004, ACM T GRAPHIC, V23, P360, DOI 10.1145/1015706.1015729
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Doretto G, 2003, PROC CVPR IEEE, P137
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   NELSON RC, 1992, CVGIP-IMAG UNDERSTAN, V56, P78, DOI 10.1016/1049-9660(92)90087-J
   Premoze S, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P23, DOI 10.1109/PCCGA.2000.883856
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   REEVES WT, 1985, P SIGGRAPH 85, P313
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   ROST RJ, OPENGLR SHADING LANG
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Sims K., 1990, Computer Graphics, V24, P405, DOI 10.1145/97880.97923
   Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871
   Wang YZ, 2002, LECT NOTES COMPUT SC, V2350, P583
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
NR 18
TC 4
Z9 4
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2006
VL 17
IS 5
BP 573
EP 583
DI 10.1002/cav.156
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 111UX
UT WOS:000242481700007
OA Bronze
DA 2024-07-18
ER

PT J
AU Huang, J
   Zhang, HX
   Shi, XH
   Liu, XG
   Bao, HJ
AF Huang, Jin
   Zhang, Hongxin
   Shi, Xiaohan
   Liu, Xinguo
   Bao, Hujun
TI Interactive mesh deformation with pseudo material effects
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE mesh deformation; gradient domain methods; material simulation
AB This paper presents a novel interactive mesh deformation method that can achieve various dynamic material effects, including elastic membrane and cloth effects. In our framework, a mesh is encoded by some differential quantities based on edge length and dihedral angle; and the deformation is formulated as a least square problem for preserving the edge length and dihedral angle via the differential quantities. In order to obtain anisotropic material effects, we further propose an edge-weighting scheme based on a user-specified vector field. To avoid specifying the local transformations, we set tip an iterative scheme for solving the deformation. At last, several examples are presented to show that our approach can interactively generate visually pleasing deformations. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab of CAD&CG, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Liu, XG (corresponding author), Zhejiang Univ, State Key Lab of CAD&CG, Hangzhou, Zhejiang, Peoples R China.
EM xgliu@cad.zju.edu.cn
RI Zhang, Hongxin/T-3714-2019
CR [Anonymous], 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'02
   Au OKC, 2006, IEEE T VIS COMPUT GR, V12, P386, DOI 10.1109/TVCG.2006.47
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Botsch M, 2004, ACM T GRAPHIC, V23, P630, DOI 10.1145/1015706.1015772
   Bridson R., 2003, Simulation of clothing with folds and wrinkles, P28
   Coquillart S., 1990, J. Computer Graphics, V24, P187, DOI DOI 10.1145/97880.97900
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   Grinspun E., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P62
   Guskov I, 1999, COMP GRAPH, P325, DOI 10.1145/311535.311577
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   Kobbelt L., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P105, DOI 10.1145/280814.280831
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Meyer M, 2001, J VISUAL COMP ANIMAT, V12, P1, DOI 10.1002/vis.244
   NEALEN A, 2005, EUROGRAPHIC 2005 STA
   POPA T, 2006, SMI 2006
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   SHEFFER A, 2004, 3DPVT04
   Sorkine O., 2004, P 2004 EUR ACM SIGGR, P179
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Turk G, 2001, COMP GRAPH, P347, DOI 10.1145/383259.383297
   XU D, 2006, LNCS, V4035
   Xu DH, 2005, SOUTHEAST SYMP SYSTE, P267, DOI 10.1145/1060244.1060274
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zayer R, 2005, COMPUT GRAPH FORUM, V24, P601, DOI 10.1111/j.1467-8659.2005.00885.x
   Zhou K, 2005, ACM T GRAPHIC, V24, P496, DOI 10.1145/1073204.1073219
NR 27
TC 7
Z9 8
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 383
EP 392
DI 10.1002/cav.141
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400024
DA 2024-07-18
ER

PT J
AU Sakuma, T
   Mukai, T
   Kuriyama, S
AF Sakuma, T
   Mukai, T
   Kuriyama, S
TI Psychological model for animating crowded pedestrians
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE crowd simulation; psychological model; personal space; virtual memory;
   locomotion graph
AB This paper proposes a psychological model for simulating pedestrian behaviors in a crowded space. Our decision-making scheme controls plausible avoidance behavior depending on the positional relations among surrounding persons, on the basis of a two-stage personal space and a virtual memory structure as proposed in social psychology. Our system determines pedestrian walking speed with the crowd density to imitate the measured data in urban engineering, and automatically generates plausible motions of the individual pedestrian by composing a locomotion graph with motion capture data. Our approach based on psychology and a variety of actual measurements can increase the accuracy of simulation at both the micro and macro levels. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Toyohashi Univ Technol, Visual Agent Lab, Toyohashi, Aichi 4418580, Japan.
C3 Toyohashi University of Technology
RP Toyohashi Univ Technol, Visual Agent Lab, 1-1 Hibarigaoka,Tenpaku Cho, Toyohashi, Aichi 4418580, Japan.
EM mukai@val.ics.tut.ac.jp
RI Mukai, Tomohiko/Q-7693-2019
CR Anderson M., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA'03, P286
   [Anonymous], 2000, (Ph.D. thesis
   Braun A., 2003, Modeling individual behaviors in crowd simulation, P143
   FRUIN J.J., 1971, Metropolitan Association of Urban Designers and Environmental Planners
   Go J., 2004, S COMPUTER ANIMATION, P9
   Goldenstein S, 1999, VISUAL COMPUT, V15, P349, DOI 10.1007/s003710050184
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lamarche F, 2004, COMPUT GRAPH FORUM, V23, P509, DOI 10.1111/j.1467-8659.2004.00782.x
   Li TY, 2001, COMP ANIM CONF PROC, P93, DOI 10.1109/CA.2001.982381
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   MURAKAMI Y, 2003, P INT JOINT C AUT AG, P369
   Musse SR, 2001, IEEE T VIS COMPUT GR, V7, P152, DOI 10.1109/2945.928167
   Osaragi T., 2004, P 3 INT JOINT C AUT, P836
   Reynolds C. W., 1999, P GAM DEV C, P763
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Sommer R., 1969, Personal Space: Behavioural Basis of Design
   Sung M, 2004, COMPUT GRAPH FORUM, V23, P519, DOI 10.1111/j.1467-8659.2004.00783.x
   TU X., 1994, P ACM SIGGRAPH 94, P43, DOI DOI 10.1145/192161.192170
NR 20
TC 40
Z9 49
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 343
EP 351
DI 10.1002/cav.105
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000019
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhuang, YT
   Xiao, J
   Wu, YZ
   Yang, T
   Wu, F
AF Zhuang, YT
   Xiao, J
   Wu, YZ
   Yang, T
   Wu, F
TI Automatic generation of human animation based on motion programming
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 18th International Conference on Computer Animation and Social Agents
   (CASA 2005)
CY OCT 17-19, 2005
CL Hong Kong, PEOPLES R CHINA
SP KC Wong Educ Fdn, Hong Kong Polytech Univ, Dept Comp
DE human animation; motion programming; motion scripts
AB In motion simulations, video games and animation films, lots of interactions between characters and virtual environments are needed. Even though realistic motion data can be derived from MoCap system, motion editing and synthesis, animators must adapt these motion data to specific virtual environment manually, which is a boring and time-consuming job. Here we propose a framework to program the movements of characters and generate navigation animations in virtual environment. Given a virtual environment, a visual user interface is provided for animators to interactively generate motion scripts, describing the characters' movements in this scene and finally used to retrieve motion clips from MoCap database and generate navigation animations automatically. This framework also provides flexible mechanism for animators to get varied resulting animations by configurable table of motion bias coefficients and interactive visual user interface. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, Inst Artif Intelligence, Coll Comp Sci, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhejiang Univ, Inst Artif Intelligence, Coll Comp Sci, 20 Zheda Rd, Hangzhou 310027, Peoples R China.
EM junx@cs.zju.edu.cn
CR [Anonymous], P 2003 S INT 3D GRAP
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Bruderlin Armin., 1995, Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH '95, P97, DOI DOI 10.1145/218380.218421
   Choi MG, 2003, ACM T GRAPHIC, V22, P182, DOI 10.1145/636886.636889
   Gleicher M., 2001, P 2001 S INTERACTIVE, P195
   Kavraki LE, 1996, IEEE INT CONF ROBOT, P3020, DOI 10.1109/ROBOT.1996.509171
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   KOVAR L, 2003, P ACM SIGGRAPH EUR S, P214
   Lee J, 2002, IEEE T VIS COMPUT GR, V8, P119, DOI 10.1109/2945.998665
   REITSMA PSA, 2004, P 2004 ACM SIGGRAPH, P89
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Rose C., 1996, Dans Proc. SIGGRAPH '96, P147
   Yamane K, 2004, ACM T GRAPHIC, V23, P532, DOI 10.1145/1015706.1015756
NR 14
TC 3
Z9 4
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2005
VL 16
IS 3-4
BP 305
EP 318
DI 10.1002/cav.109
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 974CD
UT WOS:000232568000016
DA 2024-07-18
ER

PT J
AU Zheng, JY
   Shi, M
AF Zheng, JY
   Shi, M
TI Mapping cityscapes into cyberspace for visualization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT International Conference on Cyberworlds (CW 2003)
CY DEC 03-05, 2003
CL SINGAPORE, SINGAPORE
SP Nanyang Technol Univ, Sch Comp Engn
DE route panorama; panoramic view; cyberspace; streaming media; virtual
   tour; visualization; georeference
ID REPRESENTATION
AB This work establishes a cyberspace of a real urban area for visiting on the Internet. By registering entire scenes along every street and at many locations, viewers can visually travel around and find their destinations in cyberspace. The issues we discuss here are mapping of a large-scale area to image domains in a small amount of data, and effective display of the captured scenes for various applications. Route Panoramas captured along streets and panoramic views captured at widely opening sites are associated to a city map to provide navigation functions. This paper focuses on the properties of our extended images-route panorama, addressing the archiving process applied to an urban area, an environment developed to transmit image data as streaming media, and display for scene traversing on the WWW in real time. The created cyberspaces of urban areas have broad applications such as city tour, real estate searching, e-commerce, heritage preservation, urban planning and construction, and vehicle navigation. Copyright (c) 2005 John Wiley & Sons, Ltd.
C1 Indiana Univ Purdue Univ, Dept Comp & Informat Sci, Indianapolis, IN 46202 USA.
C3 Indiana University System; Indiana University Indianapolis
RP Indiana Univ Purdue Univ, Dept Comp & Informat Sci, Indianapolis, IN 46202 USA.
EM jzheng@cs.iupui.edu
CR Aihara N, 1998, INT C PATT RECOG, P1799, DOI 10.1109/ICPR.1998.712078
   Chen SN, 1995, SWIMMING THROUGH TROUBLED WATER, P29
   Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446
   ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792
   Kawanishi T, 1998, INT C PATT RECOG, P485, DOI 10.1109/ICPR.1998.711187
   Li SG, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P570, DOI 10.1109/IROS.1998.724679
   LI SG, J IMAGE VISION COMPU, V17, P685
   Peleg S, 2000, IEEE T PATTERN ANAL, V22, P1144, DOI 10.1109/34.879794
   Zheng J. Y., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P161, DOI 10.1109/ICPR.1990.118082
   Zheng J.Y., 1990, P IEEE INT C ROB AUT, V2, P1154
   ZHENG JY, 1992, INT J COMPUT VISION, V9, P55
   Zheng JY, 2003, IEEE MULTIMEDIA, V10, P57, DOI 10.1109/MMUL.2003.1218257
   Zheng JY, 1998, COMPUT VIS IMAGE UND, V72, P237, DOI 10.1006/cviu.1998.0678
   ZHENG JY, 2004, 17 INT C PATT REC, V1
   Zhu ZG, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P345, DOI 10.1109/ICCV.2001.937539
NR 15
TC 7
Z9 20
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2005
VL 16
IS 2
BP 97
EP 107
DI 10.1002/cav.66
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 926BW
UT WOS:000229098800003
DA 2024-07-18
ER

PT J
AU Matsumoto, N
   Tokosumi, A
   Hirai, Y
AF Matsumoto, N
   Tokosumi, A
   Hirai, Y
TI Affection for cohabitant toy dolls
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE toy doll; cohabitant artifact; emotion; attachment; social agents;
   conversational agents
AB In an unprecedented phenomenon characterizing a new kind of relationship between humans and artifacts, a craze within middle-aged people for a toy doll is analyzed. In this paper, we deal with a talking toy doll. Specifically, 51 fan letters and 271 web site postings spontaneously sent to the toy company are analyzed in terms of their communicative functions and affective-cognitive contents. The results indicate that (a) the doll is simultaneously seen as both an artifact and a cohabitant (b) the doll owners attribute positive feelings in terms of both mental and physical states to the doll, W the doll owners believe that the utterances of the doll facilitate interaction with family members and with friends, and that (d) affections are evoked through owner actions toward the artifact. Based on these results, we propose a cognitive model of cognitive activity with artifacts. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Tokyo Inst Technol, Dept Value & Decis Sci, Meguro Ku, Tokyo 152, Japan.
C3 Tokyo Institute of Technology
RP Tokyo Inst Technol, Dept Value & Decis Sci, Meguro Ku, 2-12-1 Ookayama, Tokyo 152, Japan.
EM matsun@valdes.titech.ac.jp
CR [Anonymous], 1994, Discourse, consciousness, and time; the flow and displacement of conscious experience in speaking and writing
   Breazeal C, 2000, ADAPT BEHAV, V8, P49, DOI 10.1177/105971230000800104
   Chafe w, 1980, PEAR STORIES COGNITI
   Frijda N., 1986, EMOTIONS
   HAGA Y, 2000, J ROBOTICS SOC JAPAN, V20, P683
   LIBIN E, 2002, P 8 INT C VIRT SYST, P906
   Matsumoto N, 2003, LECT NOTES ARTIF INT, V2773, P778
   MATSUMOTO N, 2003, COGNITIVE STUDIES, V10, P383
   NAKANO S, 1992, ADV CHILD PSYCHOL, P60
   NORMAN D, 2002, ACM INTERACTIONS JUL, P36
   OGAWA Y, 2001, P SPEC INT GROUP LAN, V8, P35
   SHIBATA T, 2000, J ROBOTICS SOC JAPAN, V18, P200
   TOKOSUMI A, 2001, SHOULD BE COMPUTED U, P43
   Van Someren MW, 1994, AcademicPress
   VOITH VL, 1985, VET CLIN N AM-SMALL, V15, P289, DOI 10.1016/S0195-5616(85)50301-0
   YOKOYAMA M, 2001, JAPANESE J DEV PSYCH, V9, P95
NR 16
TC 2
Z9 2
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 339
EP 346
DI 10.1002/cav.37
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700024
DA 2024-07-18
ER

PT J
AU Liang, C
   Wang, QH
   Chen, YL
   Tang, MJ
AF Liang, Chao
   Wang, Qinghua
   Chen, Yunlin
   Tang, Minjie
TI Wav2Lip-HR: Synthesising clear high-resolution talking head in the wild
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE audio-driven; cross modal; talking-head generation; visual quality
ID IMAGE
AB Talking head generation aims to synthesize a photo-realistic speaking video with accurate lip motion. While this field has attracted more attention in recent audio-visual researches, most existing methods do not achieve the simultaneous improvement of lip synchronization and visual quality. In this paper, we propose Wav2Lip-HR, a neural-based audio-driven high-resolution talking head generation method. With our technique, all required to generate a clear high-resolution lip sync talking video is an image/video of the target face and an audio clip of any speech. The primary benefit of our method is that it generates clear high-resolution videos with sufficient facial details, rather than the ones just be large-sized with less clarity. We first analyze key factors that limit the clarity of generated videos and then put forth several important solutions to address the problem, including data augmentation, model structure improvement and a more effective loss function. Finally, we employ several efficient metrics to evaluate the clarity of images generated by our proposed approach as well as several widely used metrics to evaluate lip-sync performance. Numerous experiments demonstrate that our method has superior performance on visual quality and lip synchronization when compared to other existing schemes.
   Our proposed Wav2Lip-HR produces clear, high-resolution talking videos in real-time. All required is a portrait and a clip of speech, and the generated video is completely matched with the input audio.image
C1 [Liang, Chao; Wang, Qinghua] Nanjing Univ Sci & Technol, Sch Phys, Nanjing, Peoples R China.
   [Chen, Yunlin; Tang, Minjie] Mobvoi, AI Lab, Suzhou, Peoples R China.
   [Wang, Qinghua] Nanjing Univ Sci & Technol, Sch Phys, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Science & Technology
RP Wang, QH (corresponding author), Nanjing Univ Sci & Technol, Sch Phys, Nanjing 210094, Peoples R China.
EM qhwang@njust.edu.cn
RI Wang, Qinghua/GVT-3252-2022; Tang, Minjie/JEF-8422-2023
OI Tang, Minjie/0000-0002-2039-1729; Liang, Chao/0000-0002-6923-4505
CR Afouras T, 2022, IEEE T PATTERN ANAL, V44, P8717, DOI 10.1109/TPAMI.2018.2889052
   Borshukov G., 2005, ACM SIGGR 2005 COURS
   Bregler C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P353, DOI 10.1145/258734.258880
   Chen LL, 2019, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2019.00802
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   D'Eon E., 2007, P 18 EUR C REND TECH
   Drobyshev Nikita, 2022, MegaPortraits: One-shot Megapixel Neural Head Avatars, P3
   Eskimez SE., 2018, INT C LAT VAR AN SIG
   Goodfellow I. J., 2014, ARXIV
   Gururani Siddharth, 2022, Space: Speech-driven portrait animation with controllable expression
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hensel M, 2017, ADV NEUR IN, V30
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong FT, 2022, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR52688.2022.00339
   Jamaludin A, 2019, INT J COMPUT VISION, V127, P1767, DOI 10.1007/s11263-019-01150-y
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Khomenko A, 2019, PROCEEDINGS OF THE 2019 IEEE 9TH INTERNATIONAL CONFERENCE ON NANOMATERIALS: APPLICATIONS & PROPERTIES (NAP-2019), PTS 1-2, DOI 10.1109/NAP47236.2019.216990
   Kingma D. P., 2014, arXiv
   Krnoul Z., 2004, INT C TEXT SPEECH DI
   Lahiri A, 2021, PROC CVPR IEEE, P2754, DOI 10.1109/CVPR46437.2021.00278
   Li YJ, 2021, IEEE INFOCOM SER, DOI 10.1109/INFOCOM42981.2021.9488859
   Liao Miao, 2020, P AS C COMP VIS
   Liu MY, 2021, P IEEE, V109, P839, DOI 10.1109/JPROC.2021.3049196
   Ma Y., 2023, STYLETALK ONE SHOT T
   Markfryazino, 2021, WAV2LIP HQ HIGH QUAL
   Mazumder S., 2021, P 12 IND C COMP VIS
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Morishima S., 1998, AVSP98 INT C AUD VIS
   Prajwal K., 2020, LEARNING INDIVIDUAL
   Prajwal KR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P484, DOI 10.1145/3394171.3413532
   Prajwal KR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1428, DOI 10.1145/3343031.3351066
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Shen S., 2023, DIFFTALK CRAFTING DI
   Siarohin A, 2019, ADV NEUR IN, V32
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Wang G., 2022, ATTENTION BASED LIP
   Wang MY, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500525
   Wang T., 2018, ARXIV
   Wang TC., 2019, P 33 INT C NEUR INF
   Wang TC, 2021, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR46437.2021.00991
   Wang Xintao, 2021, Towards real-world blind face restoration with generative facial prior. Paper presented at: The IEEE conference on computer vision and pattern recognition (CVPR)
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen X, 2020, IEEE T VIS COMPUT GR, V26, P3457, DOI 10.1109/TVCG.2020.3023573
   Ye Z., 2023, GENEFACE GEN HIGH FI
   Yi R., 2020, AUDIO DRIVEN TALKING
   Yin F., 2022, 17 EUR C  TEL AV ISR
   Yu KW, 2019, 2019 IEEE 6TH INTERNATIONAL CONFERENCE ON ENERGY SMART SYSTEMS (2019 IEEE ESS), P18, DOI 10.1109/ess.2019.8764179
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zhang C., 2021, P IEEE CVF INT C COM
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang W., 2022, SADTALKER LEARNING R
   Zhao J., 2022, CVPR
   Zhou H, 2021, PROC CVPR IEEE, P4174, DOI 10.1109/CVPR46437.2021.00416
   Zhou HY, 2019, I C OPT COMMUN NETW, DOI [10.1109/icocn.2019.8934358, 10.1145/3339186.3339199]
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
NR 57
TC 0
Z9 0
U1 6
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2226
EA DEC 2023
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN5Q1
UT WOS:001125834200001
DA 2024-07-18
ER

PT J
AU Chen, YH
   Yang, XB
AF Chen, Yonghua
   Yang, Xubo
TI Can manipulating control-display ratio dynamically really work in
   changing pseudo-haptic weight?
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE CGI2023; hand redirection; pseudo-tactile; virtual ownership; virtual
   weight
ID PERCEPTION; VISION; AVATAR
AB Due to the limited hardware available in virtual reality, such as VR controllers or simple motion capture devices, users will need more tactile feedback, like the weight of virtual objects. Pseudo-tactile feedback, such as the control display (C/D) ratio manipulation method, is considered a standard method to simulate weight perception. In past studies, this method was basically used in a static environment, and the C/D ratio was usually determined initially. Can this method still work if the C/D ratio changes in dynamic usage scenarios? In a series of experiments, we tried to answer this question. We proved that the dynamic change of C/D ratio could simulate the weight change and improve the sense of embodiment through another hand redirection method.
C1 [Chen, Yonghua; Yang, Xubo] Shanghai Jiao Tong Univ, Digital ART Lab, Shanghai, Peoples R China.
   [Yang, Xubo] Shanghai Jiao Tong Univ, Digital ART Lab, 800 Dongchuan Rd, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Yang, XB (corresponding author), Shanghai Jiao Tong Univ, Digital ART Lab, 800 Dongchuan Rd, Shanghai, Peoples R China.
EM yangxubo@sjtu.edu.cn
RI Zhang, Yi/KHW-2039-2024; wang, jin/KHD-7243-2024; yang,
   xiao/KHT-9445-2024; li, qing/KHU-6871-2024; li, li/KHE-5750-2024
FU We thank all the reviewers for their insightful comments. We thank
   Xuanhui Yang and Yan Zhang for their valuable suggestions and feedback.
FX We thank all the reviewers for their insightful comments. We thank
   Xuanhui Yang and Yan Zhang for their valuable suggestions and feedback.
CR Achibet M, 2017, IEEE SYMP 3D USER, P103, DOI 10.1109/3DUI.2017.7893325
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Dominjon L, 2005, P IEEE VIRT REAL ANN, P19
   Jáuregui DAG, 2014, IEEE T VIS COMPUT GR, V20, P654, DOI 10.1109/TVCG.2014.45
   Gonzalez EJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364248
   Hachisu T., 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P327, DOI 10.1109/ISVRI.2011.5759662
   Hamilton Jillian., 2009, Proceedings of the Cumulus Conference: 38˚South: Hemispheric Shifts Across Learning, Teaching and Research, P1
   Han H., 2002, ACM SIGGRAPH 2002 C, P135
   Heller MA, 1999, PERCEPT PSYCHOPHYS, V61, P1384, DOI 10.3758/BF03206188
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Massie T. H., 1994, P S HAPT INT VIRT EN, P295
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Palmerius KL, 2014, LECT NOTES COMPUT SC, V8618, P117, DOI 10.1007/978-3-662-44193-0_16
   Pyasik M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62394-0
   Rietzler M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173702
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Samad M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300550
   Srinivasan M. A., 1996, Proceedings of the ASME Dynamic Systems and Control Division, P555
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Sugimoto M., 2000, SIGGRAPH 2000 SKETCH, P200
   Suhail M, 2017, IEEE SYMP 3D USER, P245, DOI 10.1109/3DUI.2017.7893363
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Tsai HR, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300450
   Yu R, 2020, IEEE T VIS COMPUT GR, V26, P2094, DOI 10.1109/TVCG.2020.2973056
   Zenner A, 2021, IEEE T VIS COMPUT GR, V27, P2627, DOI 10.1109/TVCG.2021.3067777
   Zenner A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300441
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
NR 29
TC 0
Z9 0
U1 2
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
AR e2205
DI 10.1002/cav.2205
EA SEP 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001067876200001
OA Bronze
DA 2024-07-18
ER

PT J
AU Cui, DX
   Mousas, C
AF Cui, Dixuan
   Mousas, Christos
TI Exploring the effects of virtual hand appearance on midair typing
   efficiency
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE head-mounted display; midair typing; task load; text-input; typing
   accuracy; typing speed; virtual hand appearance; virtual reality
ID ILLUSION; ERROR
AB Midair typing has gradually become the potential mainstream of virtual reality (VR) typing, as it eliminates the setup of additional hardware devices and provides convenience for portable head-mounted displays (HMDs). In midair typing, users type on a virtual keyboard while using their virtual hands. In addition to the lack of a dominant method for VR-based midair typing, we still do not know the impact that different appearances of virtual hands could have on text input in VR. Thus, we picked a widely used midair typing method (i.e., the VR-rendered QWERTY keyboard) and conducted a VR study to explore the effects of three hand appearances (i.e., abstract, mannequin, realistic hands) on typing efficiency in terms of typing accuracy, typing speed, and task load. Our within-group study revealed that (1) the mannequin hand caused significantly higher performance on typing speed than the abstract and realistic hands, (2) the abstract hand caused significantly lower performance (more typing errors) on typing accuracy compared to the mannequin and realistic hands, and (3) participants rated the task load of using the abstract hand significantly higher than the mannequin and realistic hands.
C1 [Cui, Dixuan; Mousas, Christos] Purdue Univ, Dept Comp Technol Graph, W Lafayette, IN USA.
   [Mousas, Christos] Purdue Univ, Dept Comp Technol Graph, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University; Purdue University System;
   Purdue University
RP Mousas, C (corresponding author), Purdue Univ, Dept Comp Technol Graph, W Lafayette, IN 47907 USA.
EM cmousas@purdue.edu
RI Mousas, Christos/AGV-3533-2022
OI Mousas, Christos/0000-0003-0955-7959; Cui, Dixuan/0000-0003-0114-042X
CR Adhikary J, 2021, LECT NOTES COMPUT SC, V12935, P132, DOI 10.1007/978-3-030-85610-6_9
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Bailenson JN, 2006, PRESENCE-TELEOP VIRT, V15, P699, DOI 10.1162/pres.15.6.699
   Boletsis C., 2019, INT J VIRTUAL REALIT, V19
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2154
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cui DX, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6090076
   Cui DX, 2021, BEHAV INFORM TECHNOL, V40, P1278, DOI 10.1080/0144929X.2021.1938679
   Doronichev A., 2016, GOOGLE DEV BLOG DAYD
   Du J, 2016, CONSTRUCTION RESEARCH CONGRESS 2016: OLD AND NEW CONSTRUCTION TECHNOLOGIES CONVERGE IN HISTORIC SAN JUAN, P2281
   Dudley JJ, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3232163
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P151, DOI 10.1109/VR.2018.8446250
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P159, DOI 10.1109/VR.2018.8446059
   Heah MNMQ, 2021, MULT VR COLL SYST
   Heinrich C, 2021, VIRTUAL REAL-LONDON, V25, P313, DOI 10.1007/s10055-020-00456-4
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim W, 2022, APPL ERGON, V104, DOI 10.1016/j.apergo.2022.103819
   Knierim P., 2018, ACM CHI C HUM FACT C, P1
   KNIERIM P, 2020, OPPORTUNITIES CHALLE, P1
   Kocur M., 2020, ACM ANN S COMP HUM I, P193
   Lee Y, 2017, LECT NOTES COMPUT SC, V10280, P111, DOI 10.1007/978-3-319-57987-0_9
   Li JB, 2021, AUTOPHAGY, V17, P3361, DOI 10.1080/15548627.2021.1872241
   Lin Jia-Wei., 2017, ACM SIGGRAPH 2017 Posters on - SIGGRAPH'17, P1, DOI [DOI 10.1145/3102163.3102175, DOI 10.1145/3102163]
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI [DOI 10.1145/2931002.2931006, 10.1145/2931002.2931006]
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.00-32, 10.1109/VR46266.2020.1581086151885]
   MacKenzie IS., 2010, TEXT ENTRY SYSTEMS M
   MACKENZIE IS, 2003, CHI 03 HUM FACT COMP, V3, P754, DOI [DOI 10.1145/765891.765971, 10.1145/765891.765971, 10.1145/765891.765971doi.org/10.1145/765891.765971, DOI 10.1145/765891.765971DOI.ORG/10.1145/765891.765971]
   MCGILL M, 2015, ACM C HUM FACT COMP, P2143
   McGill M, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3490495
   Moskvina V, 2006, HUM HERED, V61, P55, DOI 10.1159/000092553
   Novotny Alexander., 2020, EPiC Series in Computing, V69, P13, DOI DOI 10.29007/R1Q2
   Ogawa N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P519, DOI 10.1109/vr.2019.8798040
   Ogawa N, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P647, DOI 10.1109/VR.2018.8446318
   Oulasvirta A., 2013, ACM SIGCHI C HUM FAC, P2765
   Pyasik M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62394-0
   Rajanna V., 2018, ACM S EYE TRACK RES, P1
   Regenbrecht H, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P90, DOI 10.1109/ISMAR.2017.26
   SABBIR AA, 2009, IEEE TOR INT C SCI T, P100
   SCHWIND V, 2017, ACM CHI C HUM FACT C, P1577
   Schwind V, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P507, DOI 10.1145/3116595.3116596
   Shibuya S, 2017, EXP BRAIN RES, V235, P121, DOI 10.1007/s00221-016-4777-3
   Singh AK, 2018, IEEE ACCESS, V6, P24617, DOI 10.1109/ACCESS.2018.2832089
   Tran TV, 2016, IEEE SENS J, V16, P9021, DOI 10.1109/JSEN.2016.2616114
   Walker J., 2017, ACM CHI C HUM FACT C, P5457
   Wen J, 2020, CONSTR INNOV-ENGL, V20, P509, DOI 10.1108/CI-11-2019-0122
   Whitmire E., 2017, P ACM INTERACTIVE MO, V1, P113, DOI DOI 10.1145/3130978
   Yamada H., 1980, J INF PROCESS
   Yu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4479, DOI 10.1145/3025453.3025964
NR 49
TC 2
Z9 2
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2189
EA MAY 2023
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000994548300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Iffath, F
   Gavrilova, M
AF Iffath, Fariha
   Gavrilova, Marina
TI RAIF: A deep learning-based architecture for multi-modal aesthetic
   biometric system
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE aesthetics; deep learning; intermediate fusion; machine learning;
   multi-modal biometrics; residual network; virtual humans
ID IMAGE
AB Human aesthetics play a significant role in video game development, emotional-aware robot design, online recommender systems, digital human, and other domains of research focusing on human-computer interactions. Social network user recognition based on aesthetic preferences is an emerging research domain. In this paper, a novel deep learning architecture is proposed for multi-modal audio-visual person identification that combines audio and visual aesthetic features. A pre-trained ResNet architecture is utilized to extract high-level features from a set of user-preferred audio and image samples. A novel deep learning-based fusion technique called residual-aided intermediate fusion (RAIF) is introduced in order to effectively merge the audio and visual features. The proposed RAIF method achieved an accuracy of 98% and a loss of 0.01 on a proprietary multi-modal dataset, indicating its effectiveness in fusing audio and visual information.
C1 [Iffath, Fariha; Gavrilova, Marina] Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
C3 University of Calgary
RP Iffath, F (corresponding author), Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
EM fariha.iffath@ucalgary.ca
FU Natural Sciences and Engineering Research Council of Canada [10007544,
   10022972]
FX Natural Sciences and Engineering Research Council of Canada, Grant/Award
   Numbers: 10007544, 10022972
CR Almohammad MS., 2013, INT J COMPUT SCI TEL, P19
   Aristidou A, 2021, Arxiv, DOI arXiv:2111.12159
   Azam S., 2017, ADV ARTIFICIAL INTEL
   Bari ASMH, 2020, VISUAL COMPUT, V36, P2395, DOI 10.1007/s00371-020-01893-7
   Bhattacharyya S, 2011, J PATTERN RECOGNIT R, V6, P120, DOI 10.13176/11.191
   Chengfang Zhang, 2020, Advances in 3D Image and Graphics Representation, Analysis, Computing and Information Technology. Algorithms and Applications. Proceedings of IC3DIT 2019. Smart Innovation, Systems and Technologies (SIST 180), P159, DOI 10.1007/978-981-15-3867-4_19
   Ortega JDS, 2019, Arxiv, DOI arXiv:1907.03196
   Defferrard M, 2017, Arxiv, DOI [arXiv:1612.01840, DOI 10.48550/ARXIV.1612.01840]
   Gavrilova ML, 2017, STUD COMPUT INTELL, V691, P229, DOI 10.1007/978-3-319-44257-0_10
   Gaw N, 2022, IISE TRANS, V54, P1098, DOI 10.1080/24725854.2021.1987593
   Goethe O., 2019, Gamification Mindset, P85
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jurafsky D., 2013, Speech and language processing, VSecond
   Kumar K.P., 2019, 2019 16 IEEE INT C, P1, DOI 10.1109/AVSS.2019.8909839
   Liu F, 2021, APPL ACOUST, V178, DOI 10.1016/j.apacoust.2021.107989
   Lovato P, 2014, IEEE T INF FOREN SEC, V9, P364, DOI 10.1109/TIFS.2014.2298370
   Luo Y, 2008, INT J PATTERN RECOGN, V22, P555, DOI 10.1142/S0218001408006399
   Miah ASM, 2023, IEEE ACCESS, V11, P4703, DOI 10.1109/ACCESS.2023.3235368
   Segalin C., 2014, Proceedings of the 16th International Conference on Multimodal Interaction, ICMI'14, page, P180, DOI DOI 10.1145/2663204.2663259
   Sieu B, 2021, IEEE ACCESS, V9, P102225, DOI 10.1109/ACCESS.2021.3096776
   Sultana M, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415560133
   Tahir Y, 2020, INT J SOC ROBOT, V12, P1031, DOI 10.1007/s12369-018-0478-3
   Thalmann D., 2017, REAL HUMANS VIRTUAL
   Wu DX, 2020, Arxiv, DOI arXiv:2002.05990
NR 24
TC 1
Z9 1
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2163
EA MAY 2023
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000992272700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sun, LB
   Tang, T
   Qu, YK
   Qin, WH
AF Sun, Libo
   Tang, Ting
   Qu, Yuke
   Qin, Wenhu
TI Bidirectional temporal feature for 3D human pose and shape estimation
   from a video
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Bi-LSTM; human pose and shape estimation; transformer
AB 3D human pose and shape estimation is the foundation of analyzing human motion. However, estimating accurate and temporally consistent 3D human motion from a video remains a challenge. By now, most of the video-based methods for estimating 3D human pose and shape rely on unidirectional temporal features and lack more comprehensive information. To solve this problem, we propose a novel model "bidirectional temporal feature for human motion recovery" (BTMR), which consists of a human motion generator and a discriminator. The transformer-based generator effectively captures the forward and reverse temporal features to enhance the temporal correlation between frames and reduces the loss of spatial information. The motion discriminator based on Bi-LSTM can distinguish whether the generated pose sequences are consistent with the realistic sequences of the AMASS dataset. In the process of continuous generation and discrimination, the model can learn more realistic and accurate poses. We evaluate our BTMR on 3DPW and MPI-INF-3DHP datasets. Without the training set of 3DPW, BTMR outperforms VIBE by 2.4 mm and 14.9 mm/s(2) in PA-MPJPE and Accel metrics and outperforms TCMR by 1.7 mm in PA-MPJPE metric on 3DPW. The results demonstrate that our BTMR produces better accurate and temporal consistent 3D human motion.
C1 [Sun, Libo; Tang, Ting; Qu, Yuke; Qin, Wenhu] Southeast Univ, Sch Instrument Sci & Engn, Nanjing, Peoples R China.
   [Sun, Libo; Qin, Wenhu] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Sun, LB; Qin, WH (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
EM sunlibo@seu.edu.cn; qinwenhu@seu.edu.cn
FU National Key Research and Development Program of China
   [2020YFB160070301]; Jiangsu Provincial Key Research and Development
   Program [BE2019311]
FX ACKNOWLEDGMENTS This work was supported by National Key Research and
   Development Program of China under Grant 2020YFB160070301 and Jiangsu
   Provincial Key Research and Development Program under Grant BE2019311.
CR Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Carl D., SIM2REAL TRANSFER LE
   Chen YC, 2021, COMPUT VIS IMAGE UND, V213, DOI 10.1016/j.cviu.2021.103305
   Choi H., 2020, COMPUTER VISION ECCV, P769
   Choi H, 2021, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR46437.2021.00200
   Dosovitskiy A., An Image is Worth 16x16 Words: Transformers for Image Recognition at S cale
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Guan SY, 2023, IEEE T PATTERN ANAL, V45, P5070, DOI 10.1109/TPAMI.2022.3194167
   Huang Z, 2020, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR42600.2020.00316
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kanazawa Angjoo., 2019, Learning 3D Human Dynamics from Video
   Kingma D. P., 2014, arXiv
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Li J., HYBRIK HYBRID ANALYT
   Li W., MHFORMER MULTI HYPOT
   Li Z., DEEP 2 STREAM VIDEO
   Li ZH, 2022, LECT NOTES COMPUT SC, V13665, P590, DOI 10.1007/978-3-031-20065-6_34
   Lin K., END TO END HUMAN POS
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Luo Z., 2020, ACCV
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Marcard T., RECOVERING ACCURATE
   Mehta D., MONOCULAR 3D HUMAN P
   Osman Ahmed A. A., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P598, DOI 10.1007/978-3-030-58539-6_36
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Peng SD, 2021, PROC CVPR IEEE, P9050, DOI 10.1109/CVPR46437.2021.00894
   Reddi SJ., CONVERGENCE ADAM P I
   Sun Y, 2019, IEEE I CONF COMP VIS, P5348, DOI 10.1109/ICCV.2019.00545
   Vaswani A., ATTENTION IS ALL YOU
   Wan Z., ENCODER DECODER MULT
   Wei W., CAPTURING HUMANS MOT
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zheng ZR, 2022, IEEE T PATTERN ANAL, V44, P3170, DOI 10.1109/TPAMI.2021.3050505
NR 36
TC 3
Z9 3
U1 4
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2187
EA MAY 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000990225000001
DA 2024-07-18
ER

PT J
AU Li, SS
   Liu, YH
   Su, W
AF Li, Shasha
   Liu, Yuehu
   Su, Wei
TI Single-image human mesh reconstruction by parallel spatial feature
   aggregation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE graph convolutional network; human mesh reconstruction; spatial feature
   aggregation
AB Recovering human mesh from a single image with natural postures is a challenging task in human modeling and animation. Model-free methods regress the mesh vertices from the input image directly to avoid the 6-DoF human joint extraction from the 2D image. However, the missing of the global information in spatial feature aggregation of the existing GNNs may result in the undesired deformity and inaccuracy of the recovered human mesh. To address this issue, we propose a parallel-aggregating network with a novelly designed global layer for spatial feature extracting from random walk normalized matrix. Moreover, the coarse body mesh (head, hand, foot, etc.) provided by the coarsening network can add the human characteristic to the mesh. The local and global spatial features are aggregated to update vertice coordinates following an iterative, coarse-to-fine process to obtain an accurate and smooth human mesh. Experiments validated the effectiveness and robustness of the proposed approaches for single-image human mesh recovery.
C1 [Li, Shasha; Liu, Yuehu; Su, Wei] Xi An Jiao Tong Univ, Xian, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Liu, YH (corresponding author), Xi An Jiao Tong Univ, Xian, Shaanxi, Peoples R China.
EM liuyh@mail.xjtu.edu.cn
RI Li, Shasha/AAT-3255-2021
FU National Key Research and Development Project of New Generation
   Artificial Intelligence of China [2018AAA0102504]
FX National Key Research and Development Project of New Generation
   Artificial Intelligence of China, Grant/Award Number: 2018AAA0102504;
   the National Key Research and Development Project of New Generation
   Artificial Intelligence of China under Grant, Grant/Award Number:
   2018AAA0102504
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bruna J., 2014, P INT C LEARN REPR
   Chen X, 2021, INT J COMPUT VISION, V129, P2846, DOI 10.1007/s11263-021-01486-4
   Choi H., 2020, COMPUTER VISION ECCV, P769
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu YQ, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR '21), P101, DOI 10.1145/3460426.3463609
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Monti F., 2018, DUAL PRIMAL GRAPH CO
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Zhang L., 2019, P BRIT MACHINE VISIO
NR 23
TC 0
Z9 0
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2084
DI 10.1002/cav.2084
EA JUN 2022
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000818621800001
DA 2024-07-18
ER

PT J
AU Shang, J
   Wang, ML
AF Shang, Jing
   Wang, Meili
TI Variety decorative bas-relief generation based on normal prediction and
   transfer
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE decorative bas-relief; diversification; normal prediction; normal
   transfer; relief modeling
AB As the generation of realistic bas-relief models from 2D images suffers from insufficient 3D depth information and severe under-constraint, in this article, we propose a new framework for bas-relief modeling based on 2D decorative images, which adopts conditional generative adversarial network to infer the normal information of the decorative bas-reliefs from the greyscale information extracted from the images. For the variety of models, we extract the internal structure information through the saliency detection method based on scene perception, and use the transfer process based on the optimized texture synthesis algorithm to complete the normal editing from the source normal map to the new one, which can diversify and control the structure and detailed information of existed normal map. Finally, we adopt a bas-relief reconstruction approach based on domain transfer recursive filter and surface from gradient to recover 2.5D information from predicted and transferred normal maps. Experiments on various model examples demonstrate the efficiency and diversity of the proposed method in reconstructing bas-relief models from a single decorative image.
C1 [Shang, Jing; Wang, Meili] Northwest A&F Univ, Coll Informat Engn, Yangling, Shaanxi, Peoples R China.
   [Wang, Meili] Minist Agr, Key Lab Agr Internet Things, Yangling, Shaanxi, Peoples R China.
   [Wang, Meili] Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling, Shaanxi, Peoples R China.
C3 Northwest A&F University - China; Ministry of Agriculture & Rural
   Affairs
RP Wang, ML (corresponding author), Northwest A&F Univ, Yangling, Shaanxi, Peoples R China.
EM wml@nwsuaf.edu.cn
CR Alexa M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778797
   Ashutosh S., 2005, LEARNING DEPTH SINGL, V18
   Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712
   Cignoni P., 1997, Journal of Graphics Tools, V2, P15, DOI 10.1080/10867651.1997.10487476
   Eigen D, 2014, ADV NEUR IN, V27
   He Y, 2021, PROC SPIE, V11766, DOI 10.1117/12.2590760
   Hudon Matis, 2018, EUR C COMP VIS, P246
   Ji ZP, 2014, COMPUT GRAPH FORUM, V33, P75, DOI 10.1111/cgf.12433
   Ji ZP, 2014, IEEE T VIS COMPUT GR, V20, P675, DOI 10.1109/TVCG.2013.267
   Kerber J, 2007, P 23 SPRING C COMP G, P101
   Kerber J., 2010, COMPUT AIDED DES APP, V7, P465, DOI DOI 10.3722/CADAPS.2010.465-478
   King DB, 2015, ACS SYM SER, V1214, P1
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Men YF, 2018, PROC CVPR IEEE, P6353, DOI 10.1109/CVPR.2018.00665
   Qi XJ, 2018, PROC CVPR IEEE, P283, DOI 10.1109/CVPR.2018.00037
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schüller C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661267
   Shelhamer E, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P235, DOI 10.1109/ICCVW.2015.39
   Su WC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203186
   Wang M., 2010, PRACTICE THEORY, P33
   Wang ML, 2021, NEUROCOMPUTING, V453, P825, DOI 10.1016/j.neucom.2020.06.130
   Wang P, 2016, ADV NEUR IN, V29
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Wei MQ, 2019, IEEE T VIS COMPUT GR, V25, P1651, DOI 10.1109/TVCG.2018.2818146
   Weyrich T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239483
   Wu TP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409072
   Xie WY, 2014, PROC CVPR IEEE, P2203, DOI 10.1109/CVPR.2014.282
   Yongwei Miao, 2018, Computational Visual Media, V4, P209, DOI 10.1007/s41095-018-0111-2
   Zhang YW, 2019, COMPUT GRAPH FORUM, V38, P521, DOI 10.1111/cgf.13655
   Zhang YW, 2018, COMPUT GRAPH-UK, V70, P300, DOI 10.1016/j.cag.2017.07.022
   Zhang YW, 2013, GRAPH MODELS, V75, P297, DOI 10.1016/j.gmod.2013.07.002
   Zhongping J., 2018, ARXIV PREPRINT ARXIV
NR 33
TC 0
Z9 0
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2068
DI 10.1002/cav.2068
EA JUN 2022
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000813729800001
DA 2024-07-18
ER

PT J
AU Li, Q
   Luo, T
   Wang, JJ
AF Li, Qiang
   Luo, Tian
   Wang, Jingjing
TI The role of digital interactive technology in cultural heritage
   learning: Evaluating a mid-air gesture-based interactive media of
   Ruihetu
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cultural heritage; digital exhibit; gesture interaction; interactive
   media; museum; user experience
ID MUSEUMS; DESIGN
AB In this study, we investigate the role of mid-air gesture-based interaction technologies in cultural heritage learning. In an experiment, a mid-air gesture-based interactive media for Chinese Song Dynasty traditional painting-Ruihetu was developed and validated. Participants tested three experimental conditions: video learning only; interactive experience first, then video learning; and video learning first, then interactive experience. According to the research results, the outcomes of participants' learning of this cultural heritage differed significantly across all three experimental conditions. This study's findings offer insights into cultural learning of Chinese traditional painting in museums using mid-air gesture-based technology, specifically that video learning exhibits should be combined with and preceded by multimedia interactive exhibits for improved memory and understanding.
C1 [Li, Qiang; Luo, Tian; Wang, Jingjing] Shenyang Aerosp Univ, 37 Daoyi South Ave, Shenyang 110136, Peoples R China.
C3 Shenyang Aerospace University
RP Li, Q (corresponding author), Shenyang Aerosp Univ, 37 Daoyi South Ave, Shenyang 110136, Peoples R China.
EM qiangli@sau.edu.cn
RI Wang, Jingjing/ABD-5361-2021; li, qiang/GZA-3285-2022
OI Wang, Jingjing/0000-0003-2114-6626; Li, Qiang/0000-0002-6360-3357
FU Liaoning Province Education Department of China [JYT202009]
FX Liaoning Province Education Department of China, Grant/Award Number:
   JYT202009
CR Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Chao KJ, 2013, BRIT J EDUC TECHNOL, V44, pE151, DOI 10.1111/bjet.12018
   CHNG E, 2017, PRESENCE-VIRTUAL AUG, V26, pR3
   Edmonds E., 2006, VISUAL COMMUN-US, V5, P307
   Gong Z., 2022, Digital, V2, P33, DOI [10.3390/digital2010002, DOI 10.3390/DIGITAL2010002]
   Gonzales AL, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P415
   Hein GeorgeE., 2002, Learning in the Museum
   Hsu H.M. J., 2011, INT J INFORM ED TECH, V1, P365, DOI [10.7763/IJIET.2011.V1.59, DOI 10.7763/IJIET.2011.V1.59]
   Jin S, 2022, INT J HUM-COMPUT INT, V38, P213, DOI 10.1080/10447318.2021.1930389
   Koutsabasis P, 2018, VIRTUAL REAL-LONDON, V22, P103, DOI 10.1007/s10055-017-0325-0
   Koutsabasis Panayiotis., 2016, P INT WORKING C ADV, P21, DOI DOI 10.1145/2909132.2909248
   Li Q, 2022, DES J, V25, P1, DOI 10.1080/14606925.2021.2015162
   Manghisi VM, 2018, J CULT HERIT, V32, P186, DOI 10.1016/j.culher.2018.02.014
   Markussen T, 2013, DES ISSUES, V29, P38, DOI 10.1162/DESI_a_00195
   Mason M., 2020, DESIGN PRINCIPLES PR, V14, P1, DOI DOI 10.18848/1833-1874/CGP/V14I01/1-14
   Mayer R.E., 2002, New Directions for Teaching Learning, P55, DOI DOI 10.1002/TL.47
   Mayer R. E., 2001, Multimedia learning, DOI DOI 10.1017/CBO9781139164603
   Mayer RE, 2002, EDUC PSYCHOL REV, V14, P87, DOI 10.1023/A:1013184611077
   Messaci A, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2033
   Nancel M, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P177
   Othman MK, 2021, ACM J COMPUT CULT HE, V14, DOI 10.1145/3453073
   Parry R., 2013, Museum Worlds: Advances in Research, V1, P24, DOI 10.3167/armw.2013.010103
   Pescarin S., P 2013 DIGITAL HERIT, V1, P355
   Pollalis C, 2017, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'17), P565, DOI 10.1145/3024969.3025094
   Qiang Li, 2020, Culture and Computing. 8th International Conference, C&C 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12215), P215, DOI 10.1007/978-3-030-50267-6_17
   Rhee B, 2021, DIGIT CREAT, V32, P56, DOI 10.1080/14626268.2021.1876093
   Skublewska-Paszkowska M., 2022, SCIENCE, V10, P10
   Vosinakis S, 2018, VIRTUAL REAL-LONDON, V22, P47, DOI 10.1007/s10055-017-0313-4
   Wu S., 2021, INT J FRONT SOC, V3, P17
   Ye L, 2021, INT J ART DES EDUC, V40, P342, DOI 10.1111/jade.12347
   Ye L, 2021, J EDUC COMPUT RES, V59, P287, DOI 10.1177/0735633120963828
NR 31
TC 3
Z9 3
U1 19
U2 56
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2085
DI 10.1002/cav.2085
EA JUN 2022
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000805604000001
DA 2024-07-18
ER

PT J
AU Ferstl, Y
   Neff, M
   McDonnell, R
AF Ferstl, Ylva
   Neff, Michael
   McDonnell, Rachel
TI ExpressGesture: Expressive gesture generation from speech through
   database matching
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; conversational agents; expressive agents; gesture
   generation; motion matching; perception
AB Co-speech gestures are a vital ingredient in making virtual agents more human-like and engaging. Automatically generated gestures based on speech-input often lack realistic and defined gesture form. We present a database-driven approach guaranteeing defined gesture form. We built a large corpus of over 23,000 motion-captured co-speech gestures and select individual gestures based on expressive gesture characteristics that can be estimated from speech audio. The expressive parameters are gesture velocity and acceleration, gesture size, arm swivel, and finger extension. Individual, parameter-matched gestures are then combined into animated sequences. We evaluate our gesture generation system in two perceptual studies. The first study compares our method to the ground truth gestures as well as mismatched gestures. The second study compares our method to five current generative machine learning models. Our method outperformed mismatched gesture selection in the first study and showed competitive performance in the second.
C1 [Ferstl, Ylva; McDonnell, Rachel] Trinity Coll Dublin, Sch Comp Sci & Stat, Dublin, Ireland.
   [Neff, Michael] Univ Calif Davis, Dept Cinema & Digital Media, Dept Comp Sci, Davis, CA 95616 USA.
C3 Trinity College Dublin; University of California System; University of
   California Davis
RP Ferstl, Y (corresponding author), Trinity Coll Dublin, Sch Comp Sci & Stat, Dublin, Ireland.
EM yferstl@tcd.ie
RI Ferstl, Ylva/AAU-7379-2021; McDonnell, Rachel/HGC-4337-2022
OI Ferstl, Ylva/0000-0001-7259-0378; McDonnell, Rachel/0000-0002-1957-2506
FU Science Foundation Ireland under the ADAPT Centre for Digital Content
   Technology [13/RC/2106]
FX This work was funded by Science Foundation Ireland under the ADAPT
   Centre for Digital Content Technology (Grant 13/RC/2106).
CR Alexanderson S., 2020, COMPUT GRAPH FORUM
   [Anonymous], 2013, INT WORKSH INT VIRT
   [Anonymous], 2013, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'13
   Bergmann K, 2009, LECT NOTES ARTIF INT, V5773, P76, DOI 10.1007/978-3-642-04380-2_12
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Clavet S., 2015, P NUCL VIENN AUSTR
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Fernández-Baena A, 2014, SPEECH COMMUN, V57, P331, DOI 10.1016/j.specom.2013.06.005
   Ferstl Y, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423882
   Ferstl Y, 2020, COMPUT GRAPH-UK, V89, P117, DOI 10.1016/j.cag.2020.04.007
   Ferstl Y, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P93, DOI 10.1145/3267851.3267898
   Ferstl Ylva, 2021, P 20 INT C AUT AG MU, P151
   Ginosar S, 2019, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2019.00361
   Holden D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392440
   Kendon A., 1972, Studies in Dyadic Communication, V7, DOI [DOI 10.1016/B978-0-08-015867-9.50013-7, 10.1016/B978-0-08-015867-9.50013-7]
   Kendon A., 1980, The relationship of verbal and nonverbal communication, P207, DOI [10.1515/9783110813098.207, DOI 10.1515/9783110813098.207]
   Kim H, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P494, DOI 10.1109/ROMAN.2008.4600715
   Kucherenko Taras, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P242, DOI 10.1145/3382507.3418815
   Kucherenko Taras, 2020, GENEA CHALLENGE 2020
   Levine S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778861
   Marsella Stacy, 2013, P 12 ACM SIGGRAPH EU, P25, DOI DOI 10.1145/2485895.2485900
   Neff M, 2010, LECT NOTES ARTIF INT, V6356, P222, DOI 10.1007/978-3-642-15892-6_24
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   Ondras J., 2020, IEEE T CYBERNETICS, V50, P1
   Shapiro A., 2005, Proceedings of Graphics Interface, P61
   Sonlu S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3439795
   Stone M, 2004, ACM T GRAPHIC, V23, P506, DOI 10.1145/1015706.1015753
   Thiebaux Marcus., 2008, P AAMAS 08, P151
   Valcik J, 2016, COMPUT ANIMAT VIRT W, V27, P484, DOI 10.1002/cav.1674
   Yang Y., 2020, COMPUT GRAPH FORUM
NR 31
TC 23
Z9 23
U1 4
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2016
DI 10.1002/cav.2016
EA MAY 2021
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000656344100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Xiang, N
   Wang, RB
   Jiang, T
   Wang, L
   Li, YR
   Yang, XS
   Zhang, JJ
AF Xiang, Nan
   Wang, Ruibin
   Jiang, Tao
   Wang, Li
   Li, Yanran
   Yang, Xiaosong
   Zhang, Jianjun
TI Sketch-based modeling with a differentiable renderer
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deep learning; shape prediction; sketch-based modeling
AB Sketch-based modeling aims to recover three-dimensional (3D) shape from two-dimensional line drawings. However, due to the sparsity and ambiguity of the sketch, it is extremely challenging for computers to interpret line drawings of physical objects. Most conventional systems are restricted to specific scenarios such as recovering for specific shapes, which are not conducive to generalize. Recent progress of deep learning methods have sparked new ideas for solving computer vision and pattern recognition issues. In this work, we present an end-to-end learning framework to predict 3D shape from line drawings. Our approach is based on a two-steps strategy, it converts the sketch image to its normal image, then recover the 3D shape subsequently. A differentiable renderer is proposed and incorporated into this framework, it allows the integration of the rendering pipeline with neural networks. Experimental results show our method outperforms the state-of-art, which demonstrates that our framework is able to cope with the challenges in single sketch-based 3D shape modeling.
C1 [Xiang, Nan; Wang, Ruibin; Wang, Li; Li, Yanran; Yang, Xiaosong; Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
   [Jiang, Tao] Univ Surrey, Ctr Vis Speech & Signal Proc, Surrey, England.
   [Li, Yanran] Bournemouth Univ, TA123,Tolpuddle Annex 2, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University; University of Surrey; Bournemouth University
RP Yang, XS (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
EM xyang@bournemouth.ac.uk
RI Wang, Li/JDD-5101-2023
OI Wang, Li/0000-0002-5793-2437; XIANG, NAN/0000-0003-4028-2287; Li,
   Yanran/0000-0003-1385-7604
FU China Scholarship Council (CSC) [201707050015]; European Regional
   Development Funds - VISTA AR project (Interreg France [Channel] England)
FX The authors would like to appreciate the open dataset ShapeNet and open
   deep learning framework Pytorch. Author Nan Xiang would like to
   acknowledge financial support from China Scholarship Council (CSC,
   No.201707050015). The research leading to these results has been
   supported by European Regional Development Funds - VISTA AR project
   (funded by the Interreg France [Channel] England).
CR [Anonymous], 2015, Fundamentals of Computer Graphics
   Bessmeltsev M., 2016, RECOVERING 3D SHAPE
   Chang Angel X., 2015, arXiv
   Chen T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508378
   Chen W., 2019, P INT C NEUR INF PRO, P9605
   Cherlin J.J., 2005, Proceedings of the Spring Conference on Computer Graphics (SCCG), P137, DOI [DOI 10.1145/1090122.1090145, https://doi.org/10.1145/1090122.1090145]
   Cordier F, 2013, COMPUT AIDED DESIGN, V45, P301, DOI 10.1016/j.cad.2012.10.013
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Delanoy J, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203197
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Iarussi E, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2710026
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jain AK, 1998, SIGNAL PROCESS, V71, P109, DOI 10.1016/S0165-1684(98)00139-X
   Jung A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2749458
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11
   Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018
   MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527
   MALIK J, 1989, IEEE T PATTERN ANAL, V11, P555, DOI 10.1109/34.24791
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Moriya T., 2017, PIX2VOX SKETCH BASED
   Nealen A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276429
   Pan JY, 2018, INT CONF 3D VISION, P719, DOI 10.1109/3DV.2018.00087
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Shao C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185541
   Shtof A, 2013, COMPUT GRAPH FORUM, V32, P245, DOI 10.1111/cgf.12044
   Smirnov D., 2019, ARXIV190612337
   Su WC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203186
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Xiang N, 2019, PROCEEDINGS OF THE 32ND INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2019), P79, DOI 10.1145/3328756.3328766
   Yan XC, 2016, ADV NEUR IN, V29
NR 36
TC 8
Z9 9
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1939
DI 10.1002/cav.1939
EA AUG 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000562317400001
OA Green Published, hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Chen, ZM
   Pan, JJ
   Yang, XS
   Qin, H
AF Chen, Zhangmeng
   Pan, Junjun
   Yang, Xiaosong
   Qin, Hong
TI Hybrid features for skeleton-based action recognition based on network
   fusion
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE action recognition; CNN; human skeleton; hybrid features; LSTM;
   multistream neural network
AB In recent years, the topic of skeleton-based human action recognition has attracted significant attention from researchers and practitioners in graphics, vision, animation, and virtual environments. The most fundamental issue is how to learn an effective and accurate representation from spatiotemporal action sequences towards improved performance, and this article aims to address the aforementioned challenge. In particular, we design a novel method of hybrid features' extraction based on the construction of multistream networks and their organic fusion. First, we train a convolution neural networks (CNN) model to learn CNN-based features with the raw skeleton coordinates and their temporal differences serving as input signals. The attention mechanism is injected into the CNN model to weigh more effective and important information. Then, we employ long short-term memory (LSTM) to obtain long-term temporal features from action sequences. Finally, we generate the hybrid features by fusing the CNN and LSTM networks, and we classify action types with the hybrid features. The extensive experiments are performed on several large-scale publically available databases, and promising results demonstrate the efficacy and effectiveness of our proposed framework.
C1 [Chen, Zhangmeng; Pan, Junjun] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Chen, Zhangmeng; Pan, Junjun] Peng Cheng Lab, Shenzhen, Peoples R China.
   [Yang, Xiaosong] Bournemouth Univ, Fac Media & Commun, Poole, Dorset, England.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 Beihang University; Peng Cheng Laboratory; Bournemouth University; State
   University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Pan, JJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.; Qin, H (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM pan_junjun@buaa.edu.cn; qin@cs.stonybrook.edu
RI Pan, Junjun/A-1316-2013
FU National Key R&D Program of China [2018YFC0115102]; National Natural
   Science Foundation of China [61872020, 61532002, 61672149]; Beijing
   Natural Science Foundation Haidian Primitive Innovation Joint Fund
   [L182016]; Beijing Advanced Innovation Center for Biomedical Engineering
   [ZF138G1714]; Research Unit of Virtual Human and Virtual Surgery,
   Chinese Academy of Medical Sciences [2019RU004]; Shenzhen Research
   Institute of Big Data, Shenzhen; National Science Foundation of USA
   [IIS-1715985, IIS-1812606]
FX This research is supported in part by National Key R&D Program of China
   (No. 2018YFC0115102), National Natural Science Foundation of China (NO.
   61872020, 61532002, 61672149), Beijing Natural Science Foundation
   Haidian Primitive Innovation Joint Fund (L182016), Beijing Advanced
   Innovation Center for Biomedical Engineering (ZF138G1714), Research Unit
   of Virtual Human and Virtual Surgery, Chinese Academy of Medical
   Sciences (2019RU004), Shenzhen Research Institute of Big Data, Shenzhen
   518000, and National Science Foundation of USA (NO. IIS-1715985,
   IIS-1812606).
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2018, P 32 AAAI C ART INT
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Danish, 2018, J SUSTAIN TOUR, V26, P1928, DOI 10.1080/09669582.2018.1526293
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Hu G, 2019, IEEE INT CON MULTI, P1216, DOI 10.1109/ICME.2019.00212
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Hussein, 2013, INT JOINT C ART INT
   Kay W., 2017, CORR ABS170506950
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Lee K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275071
   Li C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P786
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Lu X, 2012, GREEN RADIO COMMUNICATION NETWORKS, P209
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Sun Y, 2019, IEEE INTERNET THINGS, V6, P5791, DOI 10.1109/JIOT.2019.2905743
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang Y, 2017, IEEE I CONF COMP VIS, P2116, DOI 10.1109/ICCV.2017.231
   Zhao G, 2020, P 34 AAAI C ART INT
NR 30
TC 3
Z9 3
U1 2
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1952
DI 10.1002/cav.1952
EA AUG 2020
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000559157500001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Cebeci, B
   Celikcan, U
   Capin, TK
AF Cebeci, Berk
   Celikcan, Ufuk
   Capin, Tolga K.
TI A comprehensive study of the affective and physiological responses
   induced by dynamic virtual reality environments
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE affect; cybersickness; emotion recognition; eye tracking; virtual
   reality
ID MOTION SICKNESS; PUPIL; SUSCEPTIBILITY; EXPOSURE
AB Previous studies showed that virtual reality (VR) environments can affect emotional state and cause significant changes in physiological responses. Aside from these effects, inadvertently induced cybersickness is a notorious problem faced in VR. In this study, to further investigate the effects of virtual environments (VEs) with different context, three dynamic VEs were created. Each VE had a particular purpose: evoking no emotion in Campfire (CF), unpleasant emotions in Hospital (HH), and cybersickness symptoms in Roller Coaster (RC). We made use of objective measurements of physiological responses such as pupil dilation, blinks, fixations, saccades, and heart rate, as well as subjective self-assessments via pre- and post-VE session questionnaires. While previous studies investigate different subsets of these measures, our study makes a comprehensive analysis of them jointly in dynamic VEs. The results of the study indicate that cybersickness produced higher saccade mean speed, whereas unpleasant context caused higher fixation count, saccade rate, and pupil dilation. Moreover, CF decreased anxiety, whereas HH and RC increased it and they also decreased comfort. Participants felt cybersickness in all VEs even in CF which is designed to minimize the effects.
C1 [Cebeci, Berk; Capin, Tolga K.] TED Univ, Dept Comp Engn, Ankara, Turkey.
   [Celikcan, Ufuk] Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ted University; Hacettepe University
RP Celikcan, U (corresponding author), Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM ufuk.celikcan@gmail.com
RI Celikcan, Ufuk/H-1191-2017
OI Celikcan, Ufuk/0000-0001-6421-185X; Cebeci, Berk/0000-0002-9984-3950
FU Scientific and Technical Research Council of Turkey (TUBITAK) [116E280]
FX Scientific and Technical Research Council of Turkey (TUBITAK),
   Grant/Award Number: 116E280
CR Abokyi S, 2017, EYE, V31, P615, DOI 10.1038/eye.2016.288
   Berntsen K., 2016, Proceedings ofthe Fourth International Conference on Technological Ecosystemsfor Enhancing Multiculturality, P435, DOI DOI 10.1145/3012430.3012553
   Bradley MM, 2008, PSYCHOPHYSIOLOGY, V45, P602, DOI 10.1111/j.1469-8986.2008.00654.x
   Chen H., 2017, P INT C ART REAL TEL, P1
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338
   Erdem U, 2015, J OPHTHALMOL, V2015, DOI 10.1155/2015/625470
   Giannakakis G, 2017, BIOMED SIGNAL PROCES, V31, P89, DOI 10.1016/j.bspc.2016.06.020
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   McCall C, 2016, COMPUT HUM BEHAV, V59, P93, DOI 10.1016/j.chb.2016.01.028
   Meehan M, 2005, APPL PSYCHOPHYS BIOF, V30, P239, DOI 10.1007/s10484-005-6381-3
   Morina N, 2015, BEHAV RES THER, V74, P18, DOI 10.1016/j.brat.2015.08.010
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Paillard AC, 2013, J VESTIBUL RES-EQUIL, V23, P203, DOI 10.3233/VES-130501
   Partala T, 2003, INT J HUM-COMPUT ST, V59, P185, DOI 10.1016/S1071-5819(03)00017-X
   PyGaze, OP SOURC TOOLB EY TR
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rizzo A, 2015, J CONTEMP PSYCHOTHER, V45, P255, DOI 10.1007/s10879-015-9306-3
   Schubert Matthew M, 2018, Sports Med Int Open, V2, pE67, DOI 10.1055/a-0631-0920
   Snowden RJ, 2016, PSYCHOPHYSIOLOGY, V53, P1217, DOI 10.1111/psyp.12668
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
NR 27
TC 27
Z9 28
U1 0
U2 24
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1893
DI 10.1002/cav.1893
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400012
DA 2024-07-18
ER

PT J
AU Ecormier-Nocca, P
   Pettré, J
   Memari, P
   Cani, MP
AF Ecormier-Nocca, Pierre
   Pettre, Julien
   Memari, Pooran
   Cani, Marie-Paule
TI Image-based authoring of herd animations
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE crowd simulation; distribution synthesis; image-based animation
ID SIMULATION
AB Animating herds of animals while achieving both convincing global shapes and plausible distributions within the herd is difficult, using simulation methods. In this work, we allow users to rely on photos of real herds, which are widely available, for keyframing their animation. More precisely, we learn global and local distribution features in each photo of the input set (which may depict different numbers of animals) and transfer them to the group of animals to be animated, thanks to a new statistical learning method enabling to analyze distributions of ellipses, as well as their density and orientation fields. The animated herd reconstructs the desired distribution at each keyframe while avoiding obstacles. As our results show, our method offers both high-level user control and help toward realism, enabling to easily author herd animations.
C1 [Ecormier-Nocca, Pierre; Memari, Pooran; Cani, Marie-Paule] CNRS, Ecole Polytech, Lab Informat LIX, F-91128 Palaiseau, France.
   [Pettre, Julien] INRIA, Inria Rennes, Ctr Rech, Villers Les Nancy, France.
C3 Centre National de la Recherche Scientifique (CNRS); Institut
   Polytechnique de Paris; Ecole Polytechnique; Inria; Universite de
   Lorraine
RP Ecormier-Nocca, P (corresponding author), CNRS, Ecole Polytech, Lab Informat LIX, F-91128 Palaiseau, France.
EM pierre.ecormier@polytechnique.edu
RI Pettré, Julien/AAB-2590-2022
OI Ecormier-Nocca, Pierre/0000-0002-3975-4913; Memari,
   Pooran/0000-0002-8811-6889
CR [Anonymous], P 2007 ACM SIGGRAPH
   Bonneel N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024192
   Ecormier-Nocca P, 2019, COMPUT GRAPH FORUM, V38, P157, DOI 10.1111/cgf.13627
   Emilien A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766975
   Favreau L, 2006, GRAPH MODELS, V68, P212, DOI 10.1016/j.gmod.2005.04.002
   Gain J, 2017, COMPUT GRAPH FORUM, V36, P63, DOI 10.1111/cgf.13107
   Gu Q, 2013, IEEE COMPUT GRAPH, V33, P20, DOI 10.1109/MCG.2011.87
   Ju E, 2010, P ACM SIGGRAPH AS 20
   Landes PE, 2013, COMPUT GRAPH FORUM, V32, P67, DOI 10.1111/cgf.12152
   Li WZ, 2015, COMPUT GRAPH FORUM, V34, P425, DOI 10.1111/cgf.12572
   Ma CY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964957
   Öztireli AC, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366189
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Reynolds CW, 1999, P GAM DEV C 1999 199
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Roveri R, 2017, COMPUT GRAPH FORUM, V36, P107, DOI 10.1111/cgf.13111
   Skrba L, 2009, COMPUT GRAPH FORUM, V28, P1541, DOI 10.1111/j.1467-8659.2008.01312.x
   Wang XJ, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12277
   Wang XJ, 2014, COMPUT ANIMAT VIRT W, V25, P353, DOI 10.1002/cav.1580
   Xu JY, 2008, COMPUT ANIMAT VIRT W, V19, P319, DOI 10.1002/cav.231
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Xu XM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409070
NR 23
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1903
DI 10.1002/cav.1903
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400026
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kyriakou, M
   Pan, XN
   Chrysanthou, Y
AF Kyriakou, Marios
   Pan, Xueni
   Chrysanthou, Yiorgos
TI Interaction with virtual crowd in Immersive and semi-Immersive Virtual
   Reality systems
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE Immersive Virtual Reality Systems; interaction; presence; user
   experience; virtual crowd
ID ENVIRONMENTS
AB This study examines attributes of virtual human behavior that may increase the plausibility of a simulated crowd and affect the user's experience in Virtual Reality. Purpose-developed experiments in both Immersive and semi-Immersive Virtual Reality systems queried the impact of collision and basic interaction between real-users and the virtual crowd and their effect on the apparent realism and ease of navigation within Virtual Reality (VR). Participants' behavior and subjective measurements indicated that facilitating collision avoidance between the user and the virtual crowd makes the virtual characters, the environment, and the whole Virtual Reality system appear more realistic and lifelike. Adding basic social interaction, such as verbal salutations, gaze, and other gestures by the virtual characters towards the user, further contributes to this effect, with the participants reporting a stronger sense of presence. On the other hand, enabling collision avoidance on its own produces a reduced feeling of comfort and ease of navigation in VR. Objective measurements showed another interesting finding that collision avoidance may reduce the user's performance regarding their primary goal (navigating in VR following someone) and that this performance is further reduced when both collision avoidance and social interaction are facilitated.
C1 [Kyriakou, Marios; Chrysanthou, Yiorgos] Univ Cyprus, Dept Comp Sci, Nicosia, Cyprus.
   [Pan, Xueni] Univ London, Goldsmiths Coll, Dept Comp, London, England.
C3 University of Cyprus; University of London; Goldsmiths University London
RP Kyriakou, M (corresponding author), Univ Cyprus, Dept Comp Sci Pure & Appl Sci FST 01, 1 Univ Ave, CY-2109 Aglantzia, Cyprus.
EM mkyriakou@gmail.com
FU Cyprus Research Promotion Foundation; European Structural Funds
   [IPE/NEKYP/0311/02]
FX This research was partially funded by the Cyprus Research Promotion
   Foundation and the European Structural Funds for the "VR CAVE" project
   under contract IPE/NEKYP/0311/02.
CR Ahn Junghyun., 2012, P 11 ACM SIGGRAPH IN, P231
   [Anonymous], P 7 INT JOINT C AUT
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Ennis C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778828
   Ennis C, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870078
   Freeman D, 2003, J NERV MENT DIS, V191, P509, DOI 10.1097/01.nmd.0000082212.83842.fe
   Garau M, 2008, PRESENCE-TELEOP VIRT, V17, P293, DOI 10.1162/pres.17.3.293
   Huerre S., 2010, P ACM SIGGRAPH US CO, p13:1
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Kalawsky R. S., 1998, BT TECHNOL J, P1
   Kyriakou M, 2015, P IEEE VIRT REAL ANN, P217, DOI 10.1109/VR.2015.7223373
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Martin D.W., 2008, DOING PSYCHOL EXPT, V7th
   Mcdonnell Rachel, 2009, ACM T APPL PERCEPT, V6, P1, DOI DOI 10.1145/1620993.1609969
   Pan XN, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032931
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Peters C, 2009, IEEE COMPUT GRAPH, V29, P54, DOI 10.1109/MCG.2009.69
   Sanz F. A., 2015, 2015 IEEE VIRTUAL RE
   SCHLOERB DW, 1995, PRESENCE-TELEOP VIRT, V4, P64, DOI 10.1162/pres.1995.4.1.64
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Slater M, 2006, PRESENCE-VIRTUAL AUG, V15, P553, DOI 10.1162/pres.15.5.553
   Slater M, 2009, ANU PSICOL, V40, P193
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Stanney K, 1998, INT J HUM-COMPUT INT, V10, P135, DOI 10.1207/s15327590ijhc1002_3
   Thalmann D, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P1, DOI 10.1109/CW.2009.23
   Thalmann Daniel., 2007, CROWD SIMULATION
   Wilcox Laurie M., 2006, ACM Trans. on Perception, V3, P412, DOI [DOI 10.1145/1190036.1190041, 10.1145/1190036.1190041]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 32
TC 32
Z9 35
U1 9
U2 67
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2017
VL 28
IS 5
AR e1729
DI 10.1002/cav.1729
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9XG
UT WOS:000417251100004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Liao, XY
   Si, WX
   Xu, B
   Yuan, ZY
   Wang, Q
   Heng, PA
AF Liao, Xiangyun
   Si, Weixin
   Xu, Biao
   Yuan, Zhiyong
   Wang, Qiong
   Heng, Pheng-Ann
TI Filament-based realistic turbulent wake synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2017
CL KAIST Sch Comp & Grad Sch Culture Technol, Seoul, SOUTH KOREA
SP ACM SIGGRAPH, Comp Graph Soc, KAIST BK21 Plus Postgraduate Org Content Sci
HO KAIST Sch Comp & Grad Sch Culture Technol
DE ring-shaped vortical structures; turbulent wake synthesis; vortex
   filament
ID SIMULATION
AB Turbulent wake is crucial for the visually appealing effects of liquid. Unfortunately, it is challenging to realistically simulate this phenomenon with ring-shaped vortical structures. To tackle this issue, we propose a filament-based turbulent wake synthesis method for realistically simulating the turbulent wake with ring-shaped vortical structures. The filaments are sampled at the separation points on the obstacle surface and emitted into the liquid flow to generate structured turbulent wake. Besides, the surface tension model is incorporated to generate natural turbulent wake diffusion visual effects in liquid by the anticurvature effects. The proposed approach can realistically and effectively synthesize the turbulent wake with ring-shaped vortical structures and make it diffuse naturally. The experimental results demonstrate that our method outperforms than the vortex particle-based method in synthesizing appealing turbulent wake.
C1 [Liao, Xiangyun; Xu, Biao; Yuan, Zhiyong] Wuhan Univ, Sch Comp, Wuhan, Peoples R China.
   [Si, Weixin; Heng, Pheng-Ann] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   [Si, Weixin; Wang, Qiong; Heng, Pheng-Ann] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Virtual Real & Human Interact Te, Shenzhen, Peoples R China.
C3 Wuhan University; Chinese University of Hong Kong; Chinese Academy of
   Sciences; Shenzhen Institute of Advanced Technology, CAS
RP Yuan, ZY (corresponding author), Wuhan Univ, Sch Comp, Wuhan, Peoples R China.; Wang, Q (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Virtual Real & Human Interact Te, Shenzhen, Peoples R China.
EM yuanzywhu@gmail.com; wangqiong@siat.ac.cn
OI Heng, Pheng Ann/0000-0003-3055-5034
FU National Natural Science Foundation of China [61373107, 61233012,
   U1613219, 81601576]; Science and Technology Program of Wuhan, China
   [2016010101010022]; Shenzhen Science and Technology Program
   [JCYJ20160429190300857]
FX National Natural Science Foundation of China, Grant/Award Number:
   61373107, 61233012, U1613219 and 81601576; Science and Technology
   Program of Wuhan, China, Grant/Award Number: 2016010101010022; the
   Shenzhen Science and Technology Program, Grant/Award Number:
   JCYJ20160429190300857
CR Adami S, 2010, J COMPUT PHYS, V229, P5011, DOI 10.1016/j.jcp.2010.03.022
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   [Anonymous], 2000, Vortex Methods: Theory and Practice
   [Anonymous], 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, DOI DOI 10.1145/1073368.1073380
   Barnat A., 2012, P ACM SIGGRAPHEUROGR, P77
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bernard PS, 2009, PHYS FLUIDS, V21, DOI 10.1063/1.3081559
   Breinlinger T, 2013, J COMPUT PHYS, V243, P14, DOI 10.1016/j.jcp.2013.02.038
   Bridson R., 2015, Fluid simulation for computer graphics
   CHORIN AJ, 1993, J COMPUT PHYS, V107, P1, DOI 10.1006/jcph.1993.1120
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P181, DOI 10.1145/258734.258838
   Gu Y., 2016, P SIGGRAPH ASIA 2016, P1
   Ihmsen M, 2011, COMPUT GRAPH FORUM, V30, P99, DOI [10.1111/j.1467-8659.2010.01832.x, 10.1111/j.1467-8659.2010.01834.x]
   Jihyun Kim, 2016, 2016 International Conference on Platform Technology and Service (PlatCon). Proceedings, P1, DOI 10.1109/PlatCon.2016.7456805
   Langlois TR, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925904
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Pan ZR, 2012, COMPUT GRAPH FORUM, V31, P2029, DOI 10.1111/j.1467-8659.2012.03195.x
   Park S. I., 2005, Computer Animation, Conference Proceedings, P261, DOI [DOI 10.1145/1073368.1073406, 10.1145/1073368.1073406]
   Pfaff T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185608
   Schlichting H., 2000, BOUNDARY LAYER THEOR
   Shao XQ, 2015, COMPUT ANIMAT VIRT W, V26, P79, DOI 10.1002/cav.1607
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Weimann S, 2014, ACM T GRAPHIC, V33
   Weissmann S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778852
   WeiSSmann Steffen., 2009, VRIPHYS, P1
   Zhu JXX, 2013, SCI CHINA CHEM, V56, P1, DOI 10.1007/s11426-012-4811-7
NR 27
TC 2
Z9 2
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2017
VL 28
IS 3-4
AR e1754
DI 10.1002/cav.1754
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EV6CA
UT WOS:000401856200001
DA 2024-07-18
ER

PT J
AU Qian, K
   Bai, JX
   Yang, XS
   Pan, JJ
   Zhang, JJ
AF Qian, Kun
   Bai, Junxuan
   Yang, Xiaosong
   Pan, Junjun
   Zhang, Jianjun
TI Essential techniques for laparoscopic surgery simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE laparoscopic surgery simulation; deformation; collision detection;
   dissection; rendering
ID SOFT-TISSUE MODELS; COLLISION DETECTION; TREE
AB Laparoscopic surgery is a complex minimum invasive operation that requires long learning curve for the new trainees to have adequate experience to become a qualified surgeon. With the development of virtual reality technology, virtual reality-based surgery simulation is playing an increasingly important role in the surgery training. The simulation of laparoscopic surgery is challenging because it involves large non-linear soft tissue deformation, frequent surgical tool interaction and complex anatomical environment. Current researches mostly focus on very specific topics (such as deformation and collision detection) rather than a consistent and efficient framework. The direct use of the existing methods cannot achieve high visual/haptic quality and a satisfactory refreshing rate at the same time, especially for complex surgery simulation. In this paper, we proposed a set of tailored key technologies for laparoscopic surgery simulation, ranging from the simulation of soft tissues with different properties, to the interactions between surgical tools and soft tissues to the rendering of complex anatomical environment. Compared with the current methods, our tailored algorithms aimed at improving the performance from accuracy, stability and efficiency perspectives. We also abstract and design a set of intuitive parameters that can provide developers with high flexibility to develop their own simulators. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Qian, Kun] Bournemouth Univ, Natl Ctr Comp Animat, Bournemouth, Dorset, England.
   [Yang, Xiaosong] Bournemouth Univ, Natl Ctr Comp Animat, Media Sch, Bournemouth, Dorset, England.
   [Zhang, Jianjun] Bournemouth Univ, Natl Ctr Comp Animat, Comp Graph, Bournemouth, Dorset, England.
   [Bai, Junxuan; Pan, Junjun] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Bournemouth University; Bournemouth University; Bournemouth University;
   Beihang University
RP Pan, JJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM pan_junjun@hotmail.com
RI Pan, Junjun/A-1316-2013; Bai, Junxuan/P-7282-2018
OI Bai, Junxuan/0000-0002-7941-0584; Yang, Xiaosong/0000-0003-3815-0584;
   Zhang, Jian/0000-0002-7069-5771
FU National Natural Science Foundation of China [61402025]; Centre for
   Digital Entertainment; EPSRC-funded centre
FX This work is partially supported by National Natural Science Foundation
   of China (61402025) and Centre for Digital Entertainment, which is an
   EPSRC-funded centre for doctoral training. We thank Prof. Ladislav Kavan
   and Tiantian Liu for the helpful discussions.
CR Allard J, 2007, STUD HEALTH TECHNOL, V125, P13
   Arbabi E, 2009, J BIOMECH, V42, P91, DOI 10.1016/j.jbiomech.2008.10.017
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bender J, 2014, COMPUT GRAPH-UK, V44, P1, DOI 10.1016/j.cag.2014.07.004
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P246, DOI 10.1111/cgf.12272
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Bradshaw G, 2004, ACM T GRAPHIC, V23, P1, DOI 10.1145/966131.966132
   Bradshaw G., 2002, Proceedings of the 2002 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P33, DOI DOI 10.1145/545261.545267
   Coles TR, 2011, IEEE T HAPTICS, V4, P51, DOI [10.1109/TOH.2010.19, 10.1109/ToH.2010.19]
   Courtecuisse H, 2014, MED IMAGE ANAL, V18, P394, DOI 10.1016/j.media.2013.11.001
   ElHelw MA, 2004, LECT NOTES COMPUT SC, V3150, P346
   Ericson C., 2004, The Morgan Kaufmann Series
   Heitz E., 2014, J. Comput. Graph. Tech, V3, P32
   Hoffman N., 2010, SIGGRAPH 10 ACM SIGG
   James DL, 2004, ACM T GRAPHIC, V23, P393, DOI 10.1145/1015706.1015735
   Kasyan N, 2013, SIGGRAPH 13 ACM SIGG
   KIM T.-Y., 2012, P ACM SIGGRAPHEUROGR, P305, DOI DOI 10.5555/2422356.2422399
   Lagarde S, 2014, SIGGRAPH 14 ACM SIGG, V23
   Lim YJ, 2007, PRESENCE-TELEOP VIRT, V16, P563, DOI 10.1162/pres.16.6.563
   Maciel A, 2007, IEEE T VIS COMPUT GR, V13, P518, DOI 10.1109/TVCG.2007.1016
   Maciel A, 2009, INT J MED ROBOT COMP, V5, P341, DOI 10.1002/rcs.266
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Mendoza C, 2006, COMPUT GRAPH-UK, V30, P432, DOI 10.1016/j.cag.2006.02.018
   Mor AB, 2000, LECT NOTES COMPUT SC, V1935, P598
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Muller Matthias, 2014, P EG S COMP AN, V2, P149, DOI DOI 10.1016/J.JVCIR.2007.01.005
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Pan J, 2015, VISUAL COMPUT, P1
   Pan JJ, 2011, INT J MED ROBOT COMP, V7, P304, DOI 10.1002/rcs.399
   Pan JJ, 2015, COMPUT ANIMAT VIRT W, V26, P321, DOI 10.1002/cav.1655
   Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317
   SCHLICK C, 1994, COMPUT GRAPH FORUM, V13, pC233, DOI 10.1111/1467-8659.1330233
   Smith J, 2002, ACM T GRAPHIC, V21, P295, DOI 10.1145/566570.566580
   Surazhsky T, 2003, IEEE INT CONF ROBOT, P1021, DOI 10.1109/ROBOT.2003.1241726
   Székely G, 2000, MED IMAGE ANAL, V4, P57, DOI 10.1016/S1361-8415(00)00002-5
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Tropp O, 2006, COMPUT ANIMAT VIRT W, V17, P527, DOI 10.1002/cav.115
   Tsai YT, 2006, ACM T GRAPHIC, V25, P967, DOI 10.1145/1141911.1141981
   Weller R., 2009, P 2009 ACM SIGGRAPH, P151, DOI DOI 10.1145/1581073.1581097
   Weller R, 2013, NEW GEOMETRIC DATA S, DOI [10.1007/978-3-319-01020-5, DOI 10.1007/978-3-319-01020-5]
   Wu CL, 2010, IEEE T VIS COMPUT GR, V16, P647, DOI 10.1109/TVCG.2009.103
   Wu J., 2014, EUROGRAPHICS 2014 ST, P1
   [No title captured]
NR 44
TC 8
Z9 8
U1 0
U2 26
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2017
VL 28
IS 2
AR e1724
DI 10.1002/cav.1724
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ER2AB
UT WOS:000398595200004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wang, X
   Yang, WW
   Kou, WB
   Yang, BL
   Wang, GZ
AF Wang, Xun
   Yang, Wenwu
   Kou, Wangbin
   Yang, Bailin
   Wang, Guozheng
TI Topology-aware moving least square deformation for 2D characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE shape deformation; two-dimensional character animation; moving least
   squares; harmonic weights
ID SHAPE; INTERPOLATION
AB Deformation method based on moving least squares (MLS) allows the user to manipulate 2D characters using either sets of points or line segments in real time. However, the traditional MLS deformation spreads the deformation of the controls with respect to the spatial distance, but oblivious to the shape topology, which would possibly lead to distortion. In this paper, we present a topology-aware MLS deformation approach for 2D characters. First, a Laplace equation is solved to obtain a set of weights, which are called harmonic weights. Then, the MLS deformation is performed by using the harmonic weights as the deformation influence of the user-specified controls. Finally, the possible distortion in the traditional MLS deformation can be effectively avoided, as the harmonic weights spread the deformation of the controls in a localized and topology-aware way. In addition, a simple but effective area-preserving variant of MLS deformation is proposed, which is suitable for the editing of incompressible objects. Copyright (c) 2015 John Wiley & Sons, Ltd.
C1 [Wang, Xun; Yang, Wenwu; Kou, Wangbin; Yang, Bailin; Wang, Guozheng] Zhejiang Gongshang Univ, Sch Comp Informat Engn, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University
RP Yang, WW (corresponding author), Zhejiang Gongshang Univ, Sch Comp Informat Engn, Hangzhou 310018, Zhejiang, Peoples R China.
EM wwyang@mail.zjgsu.edu.cn
OI Yang, Bailin/0000-0003-1754-5595
FU Ministry of Science and Technology of China [2014BAK14B01]; National
   Science Foundation of China [61100137, 61170214, 61379075]; Zhejiang
   Province Natural Science Foundation for Distinguished Young Scientists
   [LR12F02001]; Natural Science Foundation of Zhejiang Province
   [LY12F02025]
FX We would like to thank the anonymous reviewers for their helpful
   comments. This work was in part supported by the National Key Technology
   Research and Development Program of the Ministry of Science and
   Technology of China (grant no. 2014BAK14B01), the National Science
   Foundation of China (grant nos. 61100137, 61170214, and 61379075), the
   Zhejiang Province Natural Science Foundation for Distinguished Young
   Scientists (grant no. LR12F02001), and the Natural Science Foundation of
   Zhejiang Province (no. LY12F02025).
CR [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Davis TA, 2004, ACM T MATH SOFTWARE, V30, P196, DOI 10.1145/992200.992206
   Gain J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409625.1409629
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Jacobson A, 2011, TOG, V30
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Levin D, 1998, MATH COMPUT, V67, P1517, DOI 10.1090/S0025-5718-98-00974-0
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Shewchuk J. R., 1996, Applied Computational Geometry. Towards Geometric Engineering. FCRC'96 Workshop, WACG'96. Selected Papers, P203, DOI 10.1007/BFb0014497
   Sykora Daniel, 2009, P 7 INT S NONPHOTORE, P25, DOI DOI 10.1145/1572614.1572619.3,7
   Wang YZ, 2008, COMPUT ANIMAT VIRT W, V19, P411, DOI 10.1002/cav.251
   Weber O, 2007, COMPUT GRAPH FORUM, V26, P265, DOI 10.1111/j.1467-8659.2007.01048.x
   Weng YL, 2006, VISUAL COMPUT, V22, P653, DOI 10.1007/s00371-006-0054-y
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Xu K, 2009, COMPUT GRAPH-UK, V33, P391, DOI 10.1016/j.cag.2009.03.022
   Yang WW, 2012, COMPUT GRAPH FORUM, V31, P2249, DOI 10.1111/j.1467-8659.2012.03218.x
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zayer R, 2005, COMPUT GRAPH FORUM, V24, P601, DOI 10.1111/j.1467-8659.2005.00885.x
NR 24
TC 0
Z9 0
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2016
VL 27
IS 6
BP 546
EP 555
DI 10.1002/cav.1675
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EE1HQ
UT WOS:000389332200004
DA 2024-07-18
ER

PT J
AU Zollhöfer, M
   Thies, J
   Colaianni, M
   Stamminger, M
   Greiner, G
AF Zollhoefer, Michael
   Thies, Justus
   Colaianni, Matteo
   Stamminger, Marc
   Greiner, Guenther
TI Interactive model-based reconstruction of the human head using an RGB-D
   sensor
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE virtual avatars; model-based face reconstruction; 3D scanning; nonlinear
   optimisation; statistical head models; GPGPU
ID MORPHABLE MODEL; 3D; REGISTRATION; SHAPE
AB We present a novel method for the interactive markerless reconstruction of human heads using a single commodity RGB-D sensor. Our entire reconstruction pipeline is implemented on the graphics processing unit and allows to obtain high-quality reconstructions of the human head using an interactive and intuitive reconstruction paradigm. The core of our method is a fast graphics processing unit-based nonlinear quasi-Newton solver that allows us to leverage all information of the RGB-D stream and fit a statistical head model to the observations at interactive frame rates. By jointly solving for shape, albedo and illumination parameters, we are able to reconstruct high-quality models including illumination corrected textures. All obtained reconstructions have a common topology and can be directly used as assets for games, films and various virtual reality applications. We show motion retargeting, retexturing and relighting examples. The accuracy of the presented algorithm is evaluated by a comparison against ground truth data. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Zollhoefer, Michael; Thies, Justus; Colaianni, Matteo; Stamminger, Marc; Greiner, Guenther] Univ Erlangen Nurnberg, Comp Graph Grp, D-91058 Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Zollhöfer, M (corresponding author), Univ Erlangen Nurnberg, Comp Graph Grp, Cauerstr 11, D-91058 Erlangen, Germany.
EM michael.zollhoefer@cs.fau.de
FU GRK [1773]
FX We thank the reviewers for their insightful feedback. The head model is
   provided courtesy of Prof. Dr T. Vetter (Department of Computer Science)
   and the University of Basel. This work was partly funded by GRK 1773.
CR [Anonymous], COMPUTER GRAPHICS FO
   [Anonymous], 2009, VIS MOD VIS WORKSH 2
   [Anonymous], 1984, PYRAMID METHODS IMAG
   [Anonymous], CVPR
   [Anonymous], ACM SIGGRAPH 2011
   [Anonymous], 2013, ACM T GRAPHIC
   [Anonymous], ICOB 2005 WORKSH IMM
   [Anonymous], 2009, P 2009 ACM SIGGRAPHE, DOI [DOI 10.1145/1599470.1599472, 10.1145/1599470.1599472]
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2007, CVPR, P1
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Breuer P, 2008, IEEE INT CONF AUTOMA, P1, DOI 10.1109/AFGR.2008.4813339
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Goto T, 2001, IEEE SIGNAL PROC MAG, V18, P17, DOI 10.1109/79.924885
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Lee J., 2005, RENDERING TECHNIQUES, P73
   Lee WS, 1998, LECT NOTES ARTIF INT, V1537, P254
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Romdhani S, 2005, PROC CVPR IEEE, P986
   Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Scherbaum K, 2011, COMPUT GRAPH FORUM, V30, P485, DOI 10.1111/j.1467-8659.2011.01874.x
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tang LA, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P467, DOI 10.1109/ICIP.1996.560532
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Waziri M. Y., 2010, Journal of Mathematics and Statistics, V6, P246, DOI 10.3844/jmssp.2010.246.252
   WEISE T, 2009, IEEE INT WORKSH 3 D
   Zollhöfer M, 2011, COMPUT ANIMAT VIRT W, V22, P195, DOI 10.1002/cav.405
NR 36
TC 11
Z9 13
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 213
EP 222
DI 10.1002/cav.1584
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300003
DA 2024-07-18
ER

PT J
AU Lu, XQ
   Chen, WZ
   Xu, ML
   Wang, ZH
   Deng, ZG
   Ye, YD
AF Lu, Xuequan
   Chen, Wenzhi
   Xu, Mingliang
   Wang, Zonghui
   Deng, Zhigang
   Ye, Yangdong
TI AA-FVDM: An accident-avoidance full velocity difference model for
   animating realistic street-level traffic in rural scenes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE traffic animation; microscopic model; vehicle flow; rural traffic
ID FORCE MODEL; DYNAMICS; WAVES; FLOW
AB Most of existing traffic simulation efforts focus on urban regions with a coarse two-dimensional representation; relatively few studies have been conducted to simulate realistic three-dimensional traffic flows on a large, complex road web in rural scenes. In this paper, we present a novel agent-based approach called accident-avoidance full velocity difference model (abbreviated as AA-FVDM) to simulate realistic street-level rural traffics, on top of the existing FVDM. The main distinction between FVDM and AA-FVDM is that FVDM cannot handle a critical real-world traffic problem while AA-FVDM settles this problem and retains the essence of FVDM. We also design a novel scheme to animate the lane-changing maneuvering process (in particular, the execution course). Through numerous simulations, we demonstrate that besides addressing a previously unaddressed real-world traffic problem, our AA-FVDM method efficiently (in real time) simulates large-scale traffic flows (tens of thousands of vehicles) with realistic, smooth effects. Furthermore, we validate our method using real-world traffic data, and the validation results show that our method measurably outperforms state-of-the-art traffic simulation methods.Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Lu, Xuequan; Chen, Wenzhi; Wang, Zonghui] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310003, Zhejiang, Peoples R China.
   [Wang, Zonghui] Zhejiang Univ, Coll Comp Sci & Engn, Hangzhou 310027, Zhejiang, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450052, Peoples R China.
   [Deng, Zhigang] Univ Houston, Houston, TX USA.
C3 Zhejiang University; Zhejiang University; Zhengzhou University;
   University of Houston System; University of Houston
RP Wang, ZH (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310003, Zhejiang, Peoples R China.
EM zjuzhwang@zju.edu.cn
RI 陳, 文誌/AAI-6255-2021; wen, Wen/KBB-1727-2024
OI Deng, Zhigang/0000-0002-0452-8676; Deng, Zhigang/0000-0003-2571-5865;
   Lu, Xuequan/0000-0003-0959-408X
FU National Science and Technology Support Program [2013BAH23F01]; Natural
   Science Foundation of China [60970125, 61202207]; China Postdoctoral
   Science Foundation [2012M520067, 2013T60706]; Research Fund for the
   Doctoral Program of Higher Education of China [20124101120005]; Open
   Project Program of the State Key Lab of CAD&CG at Zhejiang University
   [A1209]
FX This research is supported by National Science and Technology Support
   Program (Grant 2013BAH23F01), Natural Science Foundation of China (Grant
   60970125 and 61202207), China Postdoctoral Science Foundation (Grant
   2012M520067 and 2013T60706), Research Fund for the Doctoral Program of
   Higher Education of China (Grant 20124101120005), and the Open Project
   Program of the State Key Lab of CAD&CG at Zhejiang University (grant
   A1209).
CR Ahmed KI, 1996, TRANSPORTATION AND TRAFFIC THEORY, P501
   ALGERS S., 1997, SMARTEST PROJECT REV
   Aw A, 2000, SIAM J APPL MATH, V60, P916, DOI 10.1137/S0036139997332099
   BANDO M, 1995, PHYS REV E, V51, P1035, DOI 10.1103/PhysRevE.51.1035
   Coleman TF, 1996, SIAM J OPTIMIZ, V6, P418, DOI 10.1137/0806023
   Gerlough D. L., 1955, THESIS U CALIFORNIA
   GIPPS PG, 1986, TRANSPORT RES B-METH, V20, P403, DOI 10.1016/0191-2615(86)90012-3
   Go J, 2006, GRAPH MODELS, V68, P90, DOI 10.1016/j.gmod.2005.04.003
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Helbing D, 2001, REV MOD PHYS, V73, P1067, DOI 10.1103/RevModPhys.73.1067
   Helbing D, 1998, PHYS REV E, V58, P133, DOI 10.1103/PhysRevE.58.133
   Hidas P, 2005, TRANSPORT RES C-EMER, V13, P37, DOI 10.1016/j.trc.2004.12.003
   Huang DW, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.026124
   Jiang R, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.017101
   Kesting A, 2007, TRANSPORT RES REC, P86, DOI 10.3141/1999-10
   Kesting A, 2010, PHILOS T R SOC A, V368, P4585, DOI 10.1098/rsta.2010.0084
   LIGHTHILL MJ, 1955, PROC R SOC LON SER-A, V229, P317, DOI 10.1098/rspa.1955.0089
   MITSIM, 2012, MIT INT TRANSP SYST
   Moridpour S, 2010, TRANSP LETT, V2, P157, DOI 10.3328/TL.2010.02.03.157-173
   NAGEL K, 1992, J PHYS I, V2, P2221, DOI 10.1051/jp1:1992277
   Nagel K, 1998, PHYS REV E, V58, P1425, DOI 10.1103/PhysRevE.58.1425
   Nelson P, 1997, NOVEL TRAFFIC STREAM
   NEWELL GF, 1961, OPER RES, V9, P209, DOI 10.1287/opre.9.2.209
   Ngoduy D, 2013, COMMUN NONLINEAR SCI, V18, P2838, DOI 10.1016/j.cnsns.2013.02.007
   Payne H.J., 1971, SIMULATION COUNCILS, V1, P51
   PRIGOGINE I, 1960, OPER RES, V8, P789, DOI 10.1287/opre.8.6.789
   RICHARDS PI, 1956, OPER RES, V4, P42, DOI 10.1287/opre.4.1.42
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   Sewall J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024169
   Sewall J, 2011, IEEE T VIS COMPUT GR, V17, P26, DOI 10.1109/TVCG.2010.27
   Shen JJ, 2012, GRAPH MODELS, V74, P265, DOI 10.1016/j.gmod.2012.04.002
   Shvetsov V, 1999, PHYS REV E, V59, P6328, DOI 10.1103/PhysRevE.59.6328
   Treiber M, 2000, PHYS REV E, V62, P1805, DOI 10.1103/PhysRevE.62.1805
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Yang Q, 1996, TRANSPORT RES C-EMER, V4, P113, DOI 10.1016/S0968-090X(96)00006-X
   Zhang HM, 2002, TRANSPORT RES B-METH, V36, P275, DOI 10.1016/S0191-2615(00)00050-3
NR 37
TC 11
Z9 15
U1 0
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2014
VL 25
IS 1
BP 83
EP 97
DI 10.1002/cav.1540
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AA4LQ
UT WOS:000331067500008
DA 2024-07-18
ER

PT J
AU Zhang, GJ
   Lu, DJ
   Zhu, DM
   Lv, L
   Liu, H
   Meng, XX
AF Zhang, Guijuan
   Lu, Dianjie
   Zhu, Dengming
   Lv, Lei
   Liu, Hong
   Meng, Xiangxu
TI Rigid-motion-inspired liquid character animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents Conference (CASA)
CY 2013
CL Istanbul, TURKEY
DE fluid animation; liquid control; rigid body animation
AB We present a rigid-motion-inspired method for animating liquid characters in this paper. Our method allows an animator to control the motion of liquid characters with motion capture data that is widely used in rigid body animation. It animates the most visual interesting part of liquid character, that is, to preserve character's shape as well as produce enough liquid details. To this end, we build a two-layer model to represent the character by two coaxial layers: the rigid kernel and the liquid shell. Different control paradigms are used for the two layers instead of applying homogeneous force that is common in previous approaches. By embedding the control algorithm to the NavierStokes equations, we compute the fluid velocity that drives the motion of the liquid character. Results show that the method is easy and intuitive to use while incurring little additional cost.Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Zhang, Guijuan; Lu, Dianjie; Liu, Hong] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Zhang, Guijuan; Lu, Dianjie; Liu, Hong] Shandong Prov Key Lab Novel Distributed Comp Soft, Jinan, Peoples R China.
   [Zhang, Guijuan; Meng, Xiangxu] Shandong Univ, Sch Comp Sci & Technol, Jinan 250100, Peoples R China.
   [Zhu, Dengming; Lv, Lei] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
C3 Shandong Normal University; Shandong University; Chinese Academy of
   Sciences; Institute of Computing Technology, CAS
RP Zhang, GJ (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, 88 East Wenhua Rd, Jinan, Peoples R China.
EM guijuanzhang@gmail.com
RI Liu, Hong/W-8431-2019; Li, Chun/KBC-9591-2024
FU National High-Tech R&D Program of China (863 program) [2012AA011501];
   National Natural Science Foundation of China [61202225, 61272094,
   61173067, 61104126]; Shenzhen Basic Research Foundation
   [JC201105190934A]
FX This work is supported by the National High-Tech R&D Program of China
   (863 program) under Grant Number 2012AA011501, National Natural Science
   Foundation of China under Grant Numbers 61202225, 61272094, 61173067,
   and 61104126, and Shenzhen Basic Research Foundation under Grant No.
   JC201105190934A.
CR Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Angelidis Alexis., 2006, S COMPUTER ANIMATION, P25
   [Anonymous], 2004, COMPUTER ANIMATION 2, DOI DOI 10.1145/1028523.1028549
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Foster N, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P178, DOI 10.1109/CGI.1997.601299
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Kim Y., 2006, P 2006 ACM SIGGRAPHE, P33
   Lamorlette A, 2002, ACM T GRAPHIC, V21, P729, DOI 10.1145/566570.566644
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Nielsen MichaelB., 2009, SCA '09: Proc. of the 2009 ACM SIGGRAPH/Eurographics Symp. on Comput. Anim, P217
   Pighin Frederic., 2004, SCA'04: Proceedings ofthe 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P223, DOI 10.1145/1028523.1028552
   Schpok J., 2005, P 2005 ACM SIGGRAPHE, P97, DOI [10.1145/1073368.1073381, DOI 10.1145/1073368.1073381]
   Shi Lin., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '05, P229, DOI DOI 10.1145/1073368.1073401
   Thurey N., 2006, Proceedings of the 2006 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'06, P7, DOI [10.5555/1218064.1218066, DOI 10.5555/1218064.1218066]
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Zhang GJ, 2011, VISUAL COMPUT, V27, P199, DOI 10.1007/s00371-010-0526-y
NR 18
TC 6
Z9 9
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 205
EP 213
DI 10.1002/cav.1502
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 145GP
UT WOS:000319003500008
DA 2024-07-18
ER

PT J
AU Ferraris, J
   Tian, F
   Gatzidis, C
AF Ferraris, John
   Tian, Feng
   Gatzidis, Christos
TI Feature-based probabilistic texture blending with feature variations for
   terrains
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE terrains; texturing; splatting; blending
AB The use of linear interpolation to blend different terrain types with distinct features produces translucency artefacts that can detract from the realism of the scene. The approach presented in this paper addresses the feature agnosticism of linear blending and makes the distinction between features (bricks, cobble stone, etc.) and non-features (cement, mortar, etc.). Using the blend weights from Bloom's texture splatting, intermittent texture transitions are generated on the fly without the need for artistic intervention. Furthermore, feature shapes are modified dynamically to give the illusion of wear and tear, thus further reducing repetition and adding authenticity to the scene. The memory footprint is constant regardless of texture complexity and uses nearly eight times less texture memory when compared to tile-based texture mapping. The scalability and diversity of our approach can be tailored to a wide range of hardware and can utilize textures of any size and shape compared to the grid layout and memory limitations of tile-based texture mapping. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Ferraris, John; Tian, Feng; Gatzidis, Christos] Bournemouth Univ, Poole BH12 5BB, Dorset, England.
C3 Bournemouth University
RP Ferraris, J (corresponding author), Bournemouth Univ, Poole BH12 5BB, Dorset, England.
EM jferraris@bournemouth.ac.uk
CR Bloom Charles., 2000, Terrain Texture Compositing by Blending in the Frame-Buffer from
   Cohen MF, 2003, ACM T GRAPHIC, V22, P287, DOI 10.1145/882262.882265
   Ferraris J, 2009, P INT C ADV COMP ENT, P407
   Ferraris J, 2010, INT J VIRTUAL WORLDS, V9, P21
   Ferraris J, 2010, ACM SIGGRAPH AS 2010, P51
   Gain J., 2009, P 2009 S INT 3D GRAP, V1, P31, DOI [10.1145/1507149.1507155, DOI 10.1145/1507149.1507155]
   Grundland M, 2006, COMPUT GRAPH FORUM, V25, P577, DOI 10.1111/j.1467-8659.2006.00977.x
   Hardy A., 2006, P 2006 ANN RES C S A, P61
   Huijie Zhang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P1158, DOI 10.1109/CSSE.2008.568
   LAI YY, 2005, P 3 INT C COMP GRAPH, P273
   Lefebvre S., 2003, P 2003 S INTERACTIVE, P203
   Mittring Martin., 2008, ACM SIGGRAPH Games, P23
   Moore C, 2002, SIAM PROC S, P402
   Neyret F, 1999, COMP GRAPH, P235, DOI 10.1145/311535.311561
   SMELIK R., 2010, P 2010 WORKSH PROC C, P2
   Teoh ST, 2009, LECT NOTES COMPUT SC, V5875, P468, DOI 10.1007/978-3-642-10331-5_44
   van Waveren J, 2009, ACM ANN SIGGRAPH C 2
   Wei Li-Yi., 2004, SIGGRAPHEUROGRAPHICS, P55
NR 18
TC 2
Z9 3
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 435
EP 445
DI 10.1002/cav.1460
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100030
DA 2024-07-18
ER

PT J
AU Fratarcangeli, M
AF Fratarcangeli, Marco
TI Position-based facial animation synthesis
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE facial animation; deformable bodies; muscle model; virtual humans
AB We propose an integrated facial dynamics model addressing the animation of 3D humanoid faces in real time. The computational model mimics facial motion by reproducing the layered anatomical structure of a human head including the bony structure, overlapping facial muscles and the skin. The model is flexible enough to animate face meshes of various shape, connectivity, and scale. Different from previously proposed approaches based on massspring networks, overshooting problems are avoided by simulating the dynamics through a position-based scheme, which allows for real-time performance, control, and robustness. Experiments demonstrate that convincing expressive facial animation can be interactively prototyped on consumer class platforms. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 Univ Roma La Sapienza, Dept Comp & Syst Sci A Ruberti, Rome, Italy.
C3 Sapienza University Rome
RP Fratarcangeli, M (corresponding author), Univ Roma La Sapienza, Dept Comp & Syst Sci A Ruberti, Rome, Italy.
EM frat@dis.uniroma1.it
RI Fratarcangeli, Marco/H-3967-2011
OI Fratarcangeli, Marco/0000-0002-1156-3760
CR [Anonymous], 2008, Computer Facial Animation
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], 2005, ACMEUROGRAPHICS S CO
   Ekman P, 1972, EMOTION HUMAN FACE
   Fang SF, 1996, P SOC PHOTO-OPT INS, V2710, P404, DOI 10.1117/12.237943
   Gladilin E, 2004, MED BIOL ENG COMPUT, V42, P167, DOI 10.1007/BF02344627
   Haber J, 2003, FACIAL MODELING ANIM
   Kahler K, 2007, 3D FACIAL ANIMATION
   Kahler K., 2002, Eurographics Symp. on Comp. Animation, P55, DOI DOI 10.1145/545261.545271
   MICCHELLI CA, 1986, CONSTR APPROX, V2, P11, DOI 10.1007/BF01893414
   Muller M, 2006, VIRTUAL REALITY INTE
   MULLER M., 2008, VIRTUAL REALITY INTE
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   Platt S. M., 1981, Computer Graphics, V15, P245, DOI 10.1145/965161.806812
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   Sifakis E., 2006, ACM SIGGRAPHEUROGRAP, P261
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Yuencheng Lee, 1995, Computer Graphics Proceedings. SIGGRAPH 95, P55
   Zhang Y, 2003, COMPUT GRAPH FORUM, V22, P159, DOI 10.1111/1467-8659.t01-1-00657
NR 20
TC 11
Z9 11
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 457
EP 466
DI 10.1002/cav.1450
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 963GB
UT WOS:000305607100032
DA 2024-07-18
ER

PT J
AU Jiang, K
   Chen, XW
   Zhang, Y
   Zhao, QP
AF Jiang, Kai
   Chen, Xiaowu
   Zhang, Yu
   Zhao, Qinping
TI Video event representation and inference on And-Or graph
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE video event representation; video event inference; And-Or graph
AB This paper presents an approach for video event inference from dozens of actions performed by multiple players. First, we constructed an And-Or graph to describe the different configurations of the event category such as shooting in soccer matches. We considered both temporal relations and role relations for the graph and encode them as vector parameters for each pair of graph nodes. Then, we developed an inference algorithm by using bottom-up and top-down processes. We found the proposals for each node during the bottom-up step by considering three terms of energies and refined the proposals during the top-down step by measuring the action-labeling similarity and the temporal misplacement penalty. The optimal proposal of the inferring event and its score are obtained as the result. In the experiments, we tested the inference performance of the approach for the shooting events on real soccer match videos. By our approach, we can infer different kinds of shooting events in one scenario and interpret them play-by-play in a flexible way. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Jiang, Kai; Chen, Xiaowu; Zhang, Yu; Zhao, Qinping] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Sch Comp Sci & Engn, Beijing, Peoples R China.
C3 Beihang University
RP Chen, XW (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Sch Comp Sci & Engn, Beijing, Peoples R China.
EM chen@vrlab.buaa.edu.cn; zhaoqp@vrlab.buaa.edu.cn
FU NSFC [60933006]; 863 Program [2012AA011504, 2012AA02A606]; RD Program
   [2012BAH07B01]; Doctoral Program [20091102110019]; BUAA
   [YWF-12-LKGY-001]
FX This work was partially supported by NSFC (60933006), 863 Program
   (2012AA011504 and 2012AA02A606), R&D Program (2012BAH07B01), Doctoral
   Program (20091102110019), and BUAA (YWF-12-LKGY-001).
CR Chen Y., 2007, NIPS, P289
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492
   Kai Jiang, 2011, 2011 12th International Conference on Computer-Aided Design and Computer Graphics, P183, DOI 10.1109/CAD/Graphics.2011.38
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Qian XM, 2010, LECT NOTES COMPUT SC, V6298, P439, DOI 10.1007/978-3-642-15696-0_41
   Ryoo MS, 2011, INT J COMPUT VISION, V93, P183, DOI 10.1007/s11263-010-0355-5
   Suha Kwak, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3345, DOI 10.1109/CVPR.2011.5995435
   Zhu GY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1629, DOI 10.1109/ICME.2006.262859
NR 11
TC 1
Z9 1
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 145
EP 154
DI 10.1002/cav.1452
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100003
DA 2024-07-18
ER

PT J
AU Wang, CB
   Zhang, Q
   Xiao, HJ
   Shen, QY
AF Wang, Changbo
   Zhang, Qiang
   Xiao, Huajun
   Shen, Qiuyan
TI Simulation of multiple fluids with solid-liquid phase transition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE multiple fluids; solid-liquid phase transition; free surface;
   hierarchical lattice
ID BINARY-MIXTURES; MODEL; DYNAMICS; VOLUME; FLOW
AB Physically based multiphase fluid simulation has been a hot topic in computer graphics. Since there are complex changing interface topology and interactions among air, solid, and different fluids, few papers have devoted to simulate the multiple fluids phenomena with solidliquid phase transition. In this paper, the thermal fluid model for phase transition combined with free surface tracking is used to describe the interaction between air and fluids. Then a new model based on hierarchical lattice is proposed to process the solidliquid interaction and the phase transition in the solidliquid interface. Further, with the use of hybrid interaction with multidistribution functions, different realistic multiple fluids phenomena are rendered with different lattice sizes. Copyright (C) 2012 John Wiley & Sons, Ltd.
C1 [Wang, Changbo; Zhang, Qiang; Xiao, Huajun; Shen, Qiuyan] E China Normal Univ, Inst Software Engn, Shanghai 200062, Peoples R China.
C3 East China Normal University
RP Wang, CB (corresponding author), E China Normal Univ, Inst Software Engn, Shanghai 200062, Peoples R China.
EM cbwangcg@gmail.com
FU Natural Science Foundation of China [61070128]; Shanghai Municipal
   Education Commission [12ZZ042]; State Key Lab of CAD&CG, Zhejiang
   University, China [A1008]; Fundamental Research Funds for the Central
   Universities
FX This paper was supported by the Natural Science Foundation of China
   under grant no. 61070128, Innovation Program of Shanghai Municipal
   Education Commission under grant 12ZZ042, Open Project of State Key Lab
   of CAD&CG, Zhejiang University, China, under grant A1008, and the
   Fundamental Research Funds for the Central Universities.
CR Bao K, 2010, COMPUT ANIMAT VIRT W, V21, P401, DOI 10.1002/cav.356
   Baraff D, 2003, ACM T GRAPHIC, V22, P862, DOI 10.1145/882262.882357
   Batty C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276502
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   El Ganaoui M, 2002, COMPUT FLUIDS, V31, P539, DOI 10.1016/S0045-7930(01)00067-6
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Fujisawa M, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P249
   Goktekin TG, 2004, ACM T GRAPHIC, V23, P463, DOI 10.1145/1015706.1015746
   HIRT CW, 1981, J COMPUT PHYS, V39, P201, DOI 10.1016/0021-9991(81)90145-5
   Iwasaki K, 2010, COMPUT GRAPH FORUM, V29, P2215, DOI 10.1111/j.1467-8659.2010.01810.x
   Kang N, 2010, COMPUTER GRAPHICS FO, V29
   Kass M., 1990, Computer Graphics, V24, P49, DOI 10.1145/97880.97884
   KEISER R, 2005, EUR S POINT BAS GRAP
   Lenaerts T, 2009, CW559 KATH U LEUV
   Liu HF, 2009, COMPUT FLUIDS, V38, P1108, DOI 10.1016/j.compfluid.2008.11.005
   Liu S, VISUAL COMPUTER, V27, P241
   Losasso F, 2006, IEEE T VIS COMPUT GR, V12, P343, DOI 10.1109/TVCG.2006.51
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   Luo LS, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.036302
   Mao H, 2006, PROC GRAPH INTERF, P49
   Marro J., 1999, Nonequilibrium Phase Transitions in Lattice Models, V1
   Miller W, 2001, PHYS REV LETT, V86, P3578, DOI 10.1103/PhysRevLett.86.3578
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Muller M, 2005, P 2005 ACM SIGGRAPH, P237, DOI DOI 10.1145/1073368.1073402
   Odor G, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.056114
   Park J, 2008, COMPUT ANIMAT VIRT W, V19, P455, DOI 10.1002/cav.256
   Peng Y, 2004, J COMPUT PHYS, V193, P260, DOI 10.1016/j.jcp.2003.08.008
   Pfleger D, 1999, CHEM ENG SCI, V54, P5091, DOI 10.1016/S0009-2509(99)00261-4
   PLESSET MS, 1977, ANNU REV FLUID MECH, V9, P145, DOI 10.1146/annurev.fl.09.010177.001045
   Premoze S, 2003, COMPUT GRAPH FORUM, V22, P401, DOI 10.1111/1467-8659.00687
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Thuerey N., 2004, VISION MODELING VISU, P199
   Thuerey N., 2006, PROC VIS MODEL VIS, V2006, P193
   Wojtan Christopher., 2007, Eurographics Workshop on Natural Phenomena, P15, DOI DOI 10.2312/NPH/NPH07/015-022
   Zhao Y, 2006, COMPUT GRAPH-UK, V30, P519, DOI 10.1016/j.cag.2006.03.009
   Zhu H, 2007, STABLE EFFICIENT MIS, P55
   Zhu HB, 2006, COMPUT ANIMAT VIRT W, V17, P403, DOI 10.1002/cav.143
   Zimmermann S, 2005, IND ENG CHEM RES, V44, P9818, DOI 10.1021/ie050490+
NR 39
TC 5
Z9 6
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 279
EP 289
DI 10.1002/cav.1457
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100015
DA 2024-07-18
ER

PT J
AU Chao, MW
   Lin, CH
   Chang, CC
   Lee, TY
AF Chao, Min-Wen
   Lin, Chao-Hung
   Chang, Chih-Chieh
   Lee, Tong-Yee
TI A graph-based shape matching scheme for 3D articulated objects
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE shape matching; skeleton; geometric features; graph matching
AB In this paper, a novel graph-based shape matching scheme for three-dimensional articulated objects is introduced. The underlying graph structure of a given 3D model is composed of its topological skeleton and local geometric features. Matching two graph structures is generally an NP-hard combinatorial optimization problem. To reduce computation cost, two graphs are embedded on a high-dimensional space, and then matched based on an extension of Earth Mover's Distance (EMD). Furthermore, the symmetric components of an articulated object are determined by a voting algorithm with a self-matching strategy to refine the matching correspondences. Experimental results show that the proposed approach is robust, even when the models are under the surface disturbances of noise addition, smoothing, simplification, similarity transformation, and pose deformation. In addition, the proposed approach is capable of handling both global and partial shape matching. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Chao, Min-Wen; Chang, Chih-Chieh; Lee, Tong-Yee] Natl Cheng Kung Univ, CGVSLab CSIE, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
   [Lin, Chao-Hung] Natl Cheng Kung Univ, DGLab Geomat, Dept Geometr, Tainan 70101, Taiwan.
C3 National Cheng Kung University; National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, CGVSLab CSIE, Dept Comp Sci & Informat Engn, 1 Ta Hsueh Rd, Tainan 70101, Taiwan.
EM tonylee@mail.ncku.edu.tw
CR [Anonymous], SIGGRAPH 01
   Au OKC, 2010, COMPUT GRAPH FORUM, V29, P645, DOI 10.1111/j.1467-8659.2009.01634.x
   AUO K, 2008, ACM T GRAPHIC, V27, P1
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Chang W, 2008, COMPUT GRAPH FORUM, V27, P1459, DOI 10.1111/j.1467-8659.2008.01286.x
   Cornea ND, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P366, DOI 10.1109/SMI.2005.1
   CYBENKO G, 1996, INT J INTELLIGENT EN, V95, P1
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Jain V, 2007, COMPUT AIDED DESIGN, V39, P398, DOI 10.1016/j.cad.2007.02.009
   KAZHDAN M, 2003, EUR ACM SIGGRAPH S G, P156
   LEE TY, 2006, COMPUT ANIMAT VIRTUA, P433, DOI DOI 10.1002/CAV.V17:3/4
   Matousek J, 1999, ISRAEL J MATH, V114, P221, DOI 10.1007/BF02785579
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Podolak J, 2006, ACM T GRAPHIC, V25, P549, DOI 10.1145/1141911.1141923
   Poirier M, 2009, Graphics interface, P103
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   SAUPE D, 2001, DAGM S PATT REC, P392
   Shen L, 2006, P 3 INT S 3D DAT PRO, P294, DOI DOI 10.1109/3DPVT.2006.86
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Zou GY, 2008, COMPUT ANIMAT VIRT W, V19, P399, DOI 10.1002/cav.244
NR 21
TC 9
Z9 10
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 295
EP 305
DI 10.1002/cav.396
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700026
DA 2024-07-18
ER

PT J
AU Deng, LQ
   Leung, H
   Gu, NJ
   Yang, Y
AF Deng, Liqun
   Leung, Howard
   Gu, Naijie
   Yang, Yang
TI Real-time mocap dance recognition for an interactive dancing game
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE interactive dancing game; motion capture; real-time motion recognition
AB In this paper, we present an interactive dancing game based on motion capture technology. We address the problem of real-time recognition of the user's live dance performance in order to determine the interactive motion to be rendered by a virtual dance partner. The real-time recognition algorithm is based on a human body partition indexing scheme with flexible matching to determine the end of a move as well as to detect unwanted motion. We show that the system can recognize the live dance motions of users with good accuracy and render the interactive dance move of the virtual partner. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Deng, Liqun; Gu, Naijie; Yang, Yang] Univ Sci & Technol China, Dept Comp Sci & Technol, Hefei 230026, Peoples R China.
   [Deng, Liqun; Leung, Howard; Gu, Naijie; Yang, Yang] USTC CityU Joint Adv Res Ctr, Suzhou, Peoples R China.
   [Deng, Liqun; Leung, Howard; Yang, Yang] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; City University of Hong Kong
RP Deng, LQ (corresponding author), Univ Sci & Technol China, Dept Comp Sci & Technol, Hefei 230026, Peoples R China.
EM dlqun@mail.ustc.edu.cn
OI , Yang/0000-0001-8782-4819; LEUNG, Wing Ho Howard/0000-0002-2633-2965
CR Alankus G, 2005, COMPUT ANIMAT VIRT W, V16, P259, DOI 10.1002/cav.99
   [Anonymous], I3D 09
   [Anonymous], SOM TOOLBOX
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   CHAN JCP, 2010, IEEE T LEARNING 0817
   Chiu CY, 2004, J VIS COMMUN IMAGE R, V15, P446, DOI 10.1016/j.jvcir.2004.04.004
   Deng LQ, 2010, LECT NOTES COMPUT SC, V6184, P250, DOI 10.1007/978-3-642-14246-8_26
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   KEOGH EJ, 2004, VLDB, P780
   KIM JW, 2009, COMPUTER ANIMATION V, V20, P184
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   LEE J, 2004, SCA 04, P79
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Li CJ, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1236471.1236475
   Liang XB, 2009, COMPUT ANIMAT VIRT W, V20, P89, DOI 10.1002/cav.311
   Magnenat-Thalmann N, 2008, LECT NOTES COMPUT SC, V4823, P1, DOI 10.1007/978-3-540-78139-4_1
   Mori A, 2006, INT C PATT RECOG, P560
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Shiratori T, 2006, COMPUT GRAPH FORUM, V25, P449, DOI 10.1111/j.1467-8659.2006.00964.x
   Tormene P, 2009, ARTIF INTELL MED, V45, P11, DOI 10.1016/j.artmed.2008.11.007
   Vesanto J., 2000, SOM TOOLBOX MATLAB 5
   Wu S., 2009, P 16 ACM S VIRTUAL R, P207
NR 22
TC 19
Z9 20
U1 0
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 229
EP 237
DI 10.1002/cav.397
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700019
DA 2024-07-18
ER

PT J
AU Huang, C
   Sun, HQ
   Liu, SG
   Li, P
AF Huang, Chen
   Sun, Hanqiu
   Liu, Shiguang
   Li, Ping
TI Interactive soft-fabrics watering simulation on GPU
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 24th International Conference on Computer Animation and Social Agents
   (CASA 2011)
CY MAY 26-28, 2011
CL Hangzhou, PEOPLES R CHINA
DE Soft-fabrics modeling; watering dynamics; real time simulation; GPUs
AB Physics-based simulation is usually complex and time consuming, and consequently not suitable for real-time applications. In this paper, we propose the efficient dynamics models for the real-time simulation of soft fabrics interacting with water, including multi-soaking effect and underwater dynamics. The multi-soaking effect of soft fabrics is modeled based on the physics processes. Further, we develop the optimized mass-spring model that supports the large flow forces interacting with the fabrics underwater. The fabric spring forces are linearly derived and integrated with GPU-CUDA acceleration, feasible for real-time VR applications with large set of fabric particles. Copyright (C) 2011 John Wiley & Sons, Ltd.
C1 [Huang, Chen; Sun, Hanqiu; Li, Ping] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
   [Liu, Shiguang] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
C3 Chinese University of Hong Kong; Tianjin University
RP Huang, C (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Rm 905,Ho Sin Hang Engn Bldg, Shatin, Hong Kong, Peoples R China.
EM hcmorning@hotmail.com
RI Li, Ping/AAO-2019-2020
OI Li, Ping/0000-0002-1503-0240
CR AILENI RM, 2010, P 7 TEXT SCI C
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Breen D. E., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P365, DOI 10.1145/192161.192259
   Breen D.E., 1992, PROC SIGGRAPH 94, P365
   CARIGNAN M, 1992, COMP GRAPH, V26, P99, DOI 10.1145/142920.134017
   Chentanez N., 2006, ACM SIG- GRAPH/Eurographics Symposium on Computer Animation, P83
   CHENTANEZ N, 2006, P SIGGRAPH SKETCH AP
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   Coimbra CFM, 1998, J FLUID MECH, V370, P53, DOI 10.1017/S0022112098001967
   Coimbra CFM, 2003, ANN PHYS-BERLIN, V12, P692, DOI 10.1002/andp.200310032
   Eberhardt B, 1996, IEEE COMPUT GRAPH, V16, P52, DOI 10.1109/38.536275
   GLODENTHAL R, 2007, P SIGGRAPH, V26
   Guendelman E, 2005, ACM T GRAPHIC, V24, P973, DOI 10.1145/1073204.1073299
   HARADA T, 2007, P EG UK THEOR PRACT
   JONATHAN MK, 2008, P SIGGRAPH, V27
   Kawabata Sueo., 1975, The Standardization and Analysis of Hand Evaluation, Vfirst
   Keckeisen M., 2004, Proceedings of Winter School of Computer Graphics (WSCG 2004), P205
   Lenaerts T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360648
   LING L, 1994, P 10 IEEE TENCON, P118
   Liu SG, 2009, VISUAL COMPUT, V25, P687, DOI 10.1007/s00371-009-0344-2
   Ozgen O, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805967
   PLATH J, 2001, COMPUTER GRAPHICS, V24, P879
   PROVOT X, 1995, GRAPH INTER, P147
   Robinson-Mosher A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360645
   Terzopoulos D., 1988, Visual Computer, V4, P306, DOI 10.1007/BF01908877
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   TU X., 1994, P ACM SIGGRAPH 94, P43, DOI DOI 10.1145/192161.192170
   VOLINO P, 1995, P SIGGRAPH 95, P137
   XU Y, 2000, MSRTR200034
   Xu YQ, 2001, COMP GRAPH, P391
NR 30
TC 1
Z9 1
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD APR-MAY
PY 2011
VL 22
IS 2-3
SI SI
BP 99
EP 106
DI 10.1002/cav.402
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 755OF
UT WOS:000289941700004
DA 2024-07-18
ER

PT J
AU Yoshida, E
   Laumond, JP
   Esteves, C
   Kanoun, O
   Mallet, A
   Sakaguchi, T
   Yokoi, K
AF Yoshida, Eiichi
   Laumond, Jean-Paul
   Esteves, Claudia
   Kanoun, Oussama
   Mallet, Anthony
   Sakaguchi, Takeshi
   Yokoi, Kazuhito
TI Motion autonomy for humanoids: experiments on HRP-2 No. 14
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion planning; humanoid; whole-body motoin; locomotion
AB This paper deals with whole-body motion planning and dynamic control for humanoid from two aspects: locomotion including manipulation and reaching. In the first part, we address a problem of simultaneous locomotion and manipulation planning that combines a geometric and kinematic motion planner with a dynamic humanoid motion generator. The second part deals with whole-body reaching tasks by using a generalized inverse kinematics (IK) method to fully exploit the high redundancy of the humanoid robot. Through experiments using humanoid platform HRP-2 No. 14 installed at LAAS-CNRS, we first verify the validity of each method. An integrated experiment is then presented that unifies the both results via visual perception to execute an object-fetching task. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Yoshida, Eiichi] Natl Inst Adv Ind Sci & Technol, Intelligent Syst Res Inst, Tsukuba, Ibaraki 3058568, Japan.
   [Laumond, Jean-Paul; Kanoun, Oussama; Mallet, Anthony] CNRS, LAAS, F-31077 Toulouse, France.
   [Esteves, Claudia] Univ Guanajuato, Fac Math, Mexico City, DF, Mexico.
   [Mallet, Anthony] Ecole Polytech Fed Lausanne, ASL Lab, CH-1015 Lausanne, Switzerland.
   [Yokoi, Kazuhito] Univ Tsukuba, Cooperat Grad Sch, Tsukuba, Ibaraki 305, Japan.
C3 National Institute of Advanced Industrial Science & Technology (AIST);
   Centre National de la Recherche Scientifique (CNRS); Universidad de
   Guanajuato; Swiss Federal Institutes of Technology Domain; Ecole
   Polytechnique Federale de Lausanne; University of Tsukuba
RP Yoshida, E (corresponding author), Natl Inst Adv Ind Sci & Technol, Intelligent Syst Res Inst, 1-1-1 Umezono, Tsukuba, Ibaraki 3058568, Japan.
EM e.yoshida@aist.go.jp
RI Sakaguchi, Takeshi/M-4024-2016; Yokoi, Kazuhito/K-2046-2012; Yoshida,
   Eiichi/M-3756-2016
OI Sakaguchi, Takeshi/0000-0002-2726-7448; Yokoi,
   Kazuhito/0000-0003-3942-2027; Yoshida, Eiichi/0000-0002-3077-6964
FU Japan Society for the Promotion of Science (JSPS) [18300070];
   Grants-in-Aid for Scientific Research [18300070] Funding Source: KAKEN
FX This research was partially Supported by Japan Society for the Promotion
   of Science (JSPS) Grant-in-Aid for Scientific Research (B), 18300070,
   2006.
CR [Anonymous], 1998, 4 IEEE WORKSH APPL C
   Baerlocher P, 2004, VISUAL COMPUT, V20, P402, DOI 10.1007/s00371-004-0244-4
   Chestnutt J, 2004, IEEE-RAS INT C HUMAN, P422
   Esteves C, 2006, ACM T GRAPHIC, V25, P319, DOI 10.1145/1138450.1138457
   Gleicher M, 2001, GRAPH MODELS, V63, P107, DOI 10.1006/gmod.2001.0549
   Harada K, 2005, IEEE INT CONF ROBOT, P1712
   Kajita S, 2003, IEEE INT CONF ROBOT, P1620, DOI 10.1109/robot.2003.1241826
   Kanehiro F, 2004, INT J ROBOT RES, V23, P155, DOI 10.1177/0278364904041324
   Kaneko K, 2004, IEEE INT CONF ROBOT, P1083, DOI 10.1109/ROBOT.2004.1307969
   Kuffner JJ, 2002, AUTON ROBOT, V12, P105, DOI 10.1023/A:1013219111657
   Laumond J.- P., 1998, LECT NOTES CONTROL I, V229
   Nakamura Y, 1991, Advanced Robotics-Redundancy and optimization
   Neo ES, 2006, IEEE-RAS INT C HUMAN, P327, DOI 10.1109/ICHR.2006.321292
   Okada K, 2004, IEEE INT CONF ROBOT, P3207, DOI 10.1109/ROBOT.2004.1308748
   Okada K, 2006, IEEE-RAS INT C HUMAN, P7, DOI 10.1109/ICHR.2006.321356
   Sentis L., 2005, Int. J. Humanoid Robot., V2, P505, DOI 10.1142/S0219843605000594
   Sian NE, 2004, IEEE-RAS INT C HUMAN, P608
   SICILIANO B, 1991, P IEEE INT C ADV ROB, P1211
   Stilman M, 2004, IEEE-RAS INT C HUMAN, P322
   Sugihara T, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1404, DOI 10.1109/ROBOT.2002.1014740
   Yamane K, 2004, ACM T GRAPHIC, V23, P532, DOI 10.1145/1015706.1015756
   Yoshida E, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P25, DOI 10.1109/IROS.2005.1544954
   Yoshida E, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P827, DOI 10.1109/IROS.2006.281732
   Yoshida E, 2006, IEEE-RAS INT C HUMAN, P208, DOI 10.1109/ICHR.2006.321386
   Yoshida Eiichi, 2008, P 2008 IEEE INT C RO, P1712
   Yoshida H, 2001, IEEE ASME INT C ADV, P266, DOI 10.1109/AIM.2001.936465
   YOSHIKAWA T, 1985, INT J ROBOT RES, V4, P3, DOI 10.1177/027836498500400201
NR 27
TC 5
Z9 6
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2009
VL 20
IS 5-6
SI SI
BP 511
EP 522
DI 10.1002/cav.280
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 516RI
UT WOS:000271559700004
DA 2024-07-18
ER

PT J
AU Bayona, S
   Fernández-Arroyo, JM
   Bayona, P
   Pastor, L
AF Bayona, Sofia
   Manuel Fernandez-Arroyo, Jose
   Bayona, Pilar
   Pastor, Luis
TI A new assessment methodology for virtual reality surgical simulators
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE surgical simulator; assessment methodology; virtual reality; arthroscopy
   training; randomized controlled trial
ID PERFORMANCE
AB This paper presents an assessment methodology to validate surgical simulators which will help researchers in avoiding most common errors by providing a complete structured guide, The methodology organizes the questions depending oil the validities they are related to, helping in objectives' definition and consistent hypothesis formulation. We will define the study depending on its purpose, time course and the study factor assignment, taking into account legal and ethical issues and choosing the population and sample size. If it is all experimental study, we will determine if there exist a control group and the operational definition of variables. We will avoid extraneous variables and make our study blind, establishing the final evaluation procedure, and stipulating actuation and observation protocols. A feasibility study will be performed before executing the pilot and final studies in which we will analyse the data as indicated by the statistical plait, obtaining our results and conclusions. We provide all example, applying the assessment methodology step by step to the evaluation of a virtual reality arthroscopy simulator with haptic feedback. Finally, possible experiments are. proposed as well as a conscientious study of different alternatives for the final evaluation procedure, and all extended proposal of surgical competence assessment measures. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Bayona, Sofia] Univ Rey Juan Carlos, DATCCCIA Ampliac Rectorado D0054, Madrid 28933, Spain.
   [Manuel Fernandez-Arroyo, Jose] Publ Hosp, Madrid, Spain.
   [Bayona, Pilar] Psicosalud Ctr Madrid, Madrid, Spain.
C3 Universidad Rey Juan Carlos
RP Bayona, S (corresponding author), Univ Rey Juan Carlos, DATCCCIA Ampliac Rectorado D0054, C Tulipan S-N, Madrid 28933, Spain.
EM sofia.bayona@urjc.es
RI Pastor, Luis/E-4700-2019; Bayona, Sofia/B-9449-2008
OI Bayona, Sofia/0000-0002-6167-5963
FU Spanish Ministry of Education and Science [TIN2007-67188]; Government of
   the Community of Madrid [S-0505/DPI/0235]; GMV
FX This work has been partially funded by the Spanish Ministry of Education
   and Science (grant TIN2007-67188), the Government of the Community of
   Madrid (grant S-0505/DPI/0235; GATAR-VISA) and by GMV S.A.
CR ABAJO FJ, 2001, REV ESP SALUD PUBLIC, V75, P407
   Aggarwal R, 2006, EUR J VASC ENDOVASC, V31, P588, DOI 10.1016/j.ejvs.2005.11.009
   Aggarwal R, 2007, J AM COLL SURGEONS, V204, P697, DOI 10.1016/j.jamcollsurg.2007.01.016
   Ali MR, 2002, SURG ENDOSC, V16, P1732, DOI 10.1007/s00464-002-8850-6
   BAYONA S, 2007, THESIS U R J CARLOS
   BAYONA S, 2006, MED INFORM VISUALISA, P71
   Bayona S, 2008, J ROBOT SURG, V2, P151, DOI 10.1007/s11701-008-0101-y
   *BIOM BEH RES, 1979, BELM REP ETH PRINC G
   Champion HR, 2003, BRIT J SURG, V90, P767, DOI 10.1002/bjs.4187
   Datta V, 2002, SURGERY, V131, P318, DOI 10.1067/msy.2002.120235
   Grantcharov TP, 2004, BRIT J SURG, V91, P146, DOI 10.1002/bjs.4407
   Kneebone R, 2003, MED EDUC, V37, P267, DOI 10.1046/j.1365-2923.2003.01440.x
   Moorthy K, 2003, MINIM INVASIV THER, V12, P137, DOI 10.1080/13645700310011233
   Moorthy K, 2003, RESPIRATION, V70, P195, DOI 10.1159/000070067
   *POLH, 2008, MOT TRACK 3D SCANN E
   Regehr G, 1998, ACAD MED, V73, P993, DOI 10.1097/00001888-199809000-00020
   RUIZSOLER M, 2007, OPERACIONALIZACION V
   *SAWB, 2006, ORTH
   Seymour NE, 2006, SURG ENDOSC, V20, P1774, DOI 10.1007/s00464-006-0107-3
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Sutherland LM, 2006, ANN SURG, V243, P291, DOI 10.1097/01.sla.0000200839.93965.26
   Taffinder NJ, 1999, SURG ENDOSC-ULTRAS, V13, P814, DOI 10.1007/s004649901107
   Verner L, 2003, ST HEAL T, V94, P373
   WINCKEL CP, 1994, AM J SURG, V167, P423, DOI 10.1016/0002-9610(94)90128-7
NR 24
TC 3
Z9 5
U1 0
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2009
VL 20
IS 1
BP 39
EP 52
DI 10.1002/cav.268
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 407WD
UT WOS:000263394100005
DA 2024-07-18
ER

PT J
AU Barakonyi, I
   Schmaistieg, D
AF Barakonyi, Istvan
   Schmaistieg, Dieter
TI Augmented reality agents for user interface adaptation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; ubiquitous computing; animated agents; autonomous
   agents; adaptive user interfaces
AB Most augmented reality (AR) applications are primarily concerned with letting a user browse a 3D virtual world registered with the real world. More advanced AR interfaces let the user interact with the mixed environment, but the virtual part is typically rather finite and deterministic. In contrast, autonomous behavior is often desirable in ubiquitous computing (Ubicomp), which requires the computers embedded into the environment to adapt to context and situation without explicit user intervention. We present an AR framework that is enhanced by typical Ubicomp features by dynamically and proactively exploiting previously unknown applications and hardware devices, and adapting the appearance of the user interface to persistently stored and accumulated user preferences. Our framework explores proactive computing, multi-user interface adaptation, and user interface migration. We employ mobile and autonomous agents embodied by real and virtual objects as an interface and interaction metaphor, where agent bodies are able to opportunistically migrate between multiple AR applications and computing platforms to best match the needs of the current application context. We present two pilot applications to illustrate design concepts. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Schmaistieg, Dieter] Graz Univ Technol, A-8010 Graz, Austria.
   [Barakonyi, Istvan] Imaginat & Vernandi GmbH, Graz, Austria.
C3 Graz University of Technology
RP Schmaistieg, D (corresponding author), Graz Univ Technol, Inffeldgasse 16, A-8010 Graz, Austria.
EM schmalstieg@tugraz.at
CR Anabuki Mahoro, 2000, C HUM FACT COMP SYST, P10
   [Anonymous], P SIGCHI HUM FACT CO
   BALCISOY S, 2001, P INT S MIX AUGM REA
   BANE R, 2004, P INT S MIX AUGM REA, P52
   Barakonyi I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P141, DOI 10.1109/ISMAR.2004.11
   BARAKONYI I, 2006, P INT S MIX AUGM REA
   Bratman M.E., 1987, Intention, Plans, and Practical Reason
   Butz A., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P35, DOI 10.1109/IWAR.1999.803804
   CAVAZZA M, 2003, P INT VIRT AG KOST I
   DUFFY BR, 2003, P INT C COMP AN SOC
   FEINER S, 1993, COMMUN ACM, V36, P53, DOI 10.1145/159544.159587
   FRANKLIN S, 1996, AGENT THEORIES ARCHI, P21
   Georgeff M, 1999, LECT NOTES ARTIF INT, V1555, P1
   HANDHELD AR, LIB WEBSITE
   Hesina Gerd, 1999, P ACM S VIRT REAL SO, P74, DOI [10.1145/323663.323675, DOI 10.1145/323663.323675]
   Julier S, 2002, IEEE COMPUT GRAPH, V22, P12, DOI 10.1109/MCG.2002.1028721
   Kalkusch M., 2002, P 1 IEEE INT WORKSH
   KOTZ D, 1999, SIGOPS OPER SYST REV, V33, P7
   KRUPPA M, 2003, P SIMVIS, P349
   Laurel Brenda., 1990, ART HUMAN COMPUTER I
   MACINTYRE B, 2002, P SIGGRAPH 2002 TECH
   MacWilliams A, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P123, DOI 10.1109/ISMAR.2003.1240695
   Maes P, 1997, MULTIMEDIA SYST, V5, P105, DOI 10.1007/s005300050046
   MASE K, 2000, P AS C COMP VIS ACCV
   MASSO PJM, 2006, P INT C INT US INT I, P140
   NEWMAN J, 2006, ADV PERVASIVE COMPUT, P207
   Poupyrev I, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P334
   REKIMOTO I, 1999, P C HUM FACT COMP SY, P378
   Schmalstieg D, 2003, PRESENCE-TELEOP VIRT, V12, P52, DOI 10.1162/1054746037638
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   TOMLINSON B, 2006, P INT JOINT C AUT AG
   Vacchetti L, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P449, DOI 10.1109/IM.2003.1240281
   WAGNER D, 2006, P C ADV COMP ENT TEC
   WAGNER D, 2007, P IEEE VIRT REAL 200
   WEISER M, 1992, MIT MEDIA LAB S INT
NR 35
TC 11
Z9 11
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2008
VL 19
IS 1
BP 23
EP 35
DI 10.1002/cav.220
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 283ZM
UT WOS:000254675000004
DA 2024-07-18
ER

PT J
AU Chao, SP
   Chiu, CY
   Yang, SN
   Lin, TG
AF Chao, SP
   Chiu, CY
   Yang, SN
   Lin, TG
TI Tai Chi synthesizer: a motion synthesis framework based on key-postures
   and motion instructions
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE animation from motion/video data; animation of articulated figures;
   animation system; animation techniques; motion capture and retargeting;
   language parsing and understanding
AB Human spontaneous motions such as walking and runing are seldom described in detail. However, some well designed motions such as conditioning and rehabilitation exercises are usually described in detail and edited into exercise manuals for training purpose. This paper presents a novel framework for synthesizing new motions based on given motion manuals and corresponding motion capture examples. First, using text analysis method, a set of basic motion texts is extracted from exercise manuals and converted into text normal form. Then we introduce an annotation method to build the mapping table between basic motion texts and their corresponding motion clips in the given examples. To facilitate the search for proper motion clips, a multi-dimensional index structure based on posture parameters is proposed. Then a new motion with given textual description can be synthesized by converting the description sentences into a sequence of text normal forms and then concatenating the corresponding motion clips to form the desired motion. Moreover, to realize the smooth concatenation, we show that it can be achieved by finding an appropriate path in the proposed multi-dimensional index space. Several experimental examples are given to demonstrate the proposed method is effective in synthesizing desired motions according to given descriptions. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Tsing Hua University
RP Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
EM spchao@cs.nthu.edu.tw
OI Chiu, Chih-Yi/0000-0002-2859-6120
CR Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Bindiganavale R., 2000, AUTONOMOUS AGENTS, P293
   Bruderlin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P97, DOI 10.1145/218380.218421
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   CHENG MC, 1986, CHENG MAN CHINGS ADV
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   Choi KJ, 2000, J VISUAL COMP ANIMAT, V11, P223, DOI 10.1002/1099-1778(200012)11:5<223::AID-VIS236>3.0.CO;2-5
   Gleicher M, 1998, J VISUAL COMP ANIMAT, V9, P65, DOI 10.1002/(SICI)1099-1778(199804/06)9:2<65::AID-VIS176>3.0.CO;2-Z
   GLEICHER M, 2003, ACM S INT 3D GRAPH, P181
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P214
   KOVAR L, 2002, ACM SIGGRAPH S COMP, P97
   Lan C, 1996, ARCH PHYS MED REHAB, V77, P612, DOI 10.1016/S0003-9993(96)90305-6
   Li JX, 2001, BRIT J SPORT MED, V35, P148, DOI 10.1136/bjsm.35.3.148
   MCFARLANE S, 2002, COMPLETE BOOK TAI CH
   Parsons T.W., 1986, Voice and Speech Processing
   Taylor CJ, 2000, PROC CVPR IEEE, P677, DOI 10.1109/CVPR.2000.855885
   UNUMA M, 1995, ANN C SERIES, P91
   Wang JS, 2001, ARCH PHYS MED REHAB, V82, P1176, DOI 10.1053/apmr.2001.24305
NR 20
TC 8
Z9 8
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 259
EP 268
DI 10.1002/cav.28
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700015
DA 2024-07-18
ER

PT J
AU Lee, JR
   Williams, AB
AF Lee, JR
   Williams, AB
TI Behavior development through task oriented discourse
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th Annual Conference on Computer Animation and Social Agents (CASA
   2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE behavior synthesis; behavior management; digital humans; task oriented
   discourse; trainee agents
AB As digital human animation and simulation systems are coming into widespread use, scenario designers and digital animators must introduce specific tasks, procedures and animation sequences into a digital human's repertoire of capabilities. The parameterized action representation (PAR) architecture allows the animator to introduce dynamic behaviors through natural language instructions. However, this architecture lacks any natural language feedback which would allow the animator to deal with inconsistencies, incompleteness and conflicts within the behavior. In this paper we introduce an extension to a typical PAR architecture that provides that natural language feedback mechanism and define a set of task oriented discourses (TOD) that allow this mechanism to be used in synthesizing and managing behaviors. We demonstrate our behavior development techniques in two applications. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Iowa, Dept Elect & Comp Engn, Ctr Comp Aided Design, Virtual Soldier Res Ctr,Distributed Intelligent A, Iowa City, IA 52242 USA.
C3 University of Iowa
RP Lee, JR (corresponding author), Univ Iowa, Dept Elect & Comp Engn, Ctr Comp Aided Design, Virtual Soldier Res Ctr,Distributed Intelligent A, Iowa City, IA 52242 USA.
EM jrlee@engineering.uiowa.edu
CR ALBECK JM, 2002, WORKSHOP EMBODIED CO
   ALLBECK JM, AUTHORING EMBODIED A
   AMORI RD, 1990, P 3 INT C IND ENG AP
   *AN CHOT, 2004, DIAL STRUCT TASK CON
   ANGROS R, 2002, AUTONOMOUS AGENTS MU
   Badler N., 1998, WORKSHOP EMBODIED CO
   BINDIGANAVALE R, 2000, MCCIS0017
   BINDIGANAVALE R, 2000, AUTONOMOUS AGENT JUN
   GROSZ BJ, 1974, P IEEE S SPEECH REC
   LOCHBAUM KE, 1993, COLLABORATIVE PLANIN
   LOPICCOLO P, 2002, COMPUTER GRAPHIC NOV
   RICKEL J, 2000, WORK NOT AAAI FALL S
   RICKEL J, 2001, AIED WORKSHOP TUTORI
   Rickel J., 2000, TASK ORIENTED COLLAB
NR 14
TC 4
Z9 7
U1 0
U2 0
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 327
EP 337
DI 10.1002/cav.36
PG 11
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 839OZ
UT WOS:000222795700023
DA 2024-07-18
ER

PT J
AU Yu, YZ
   Wu, Q
AF Yu, YZ
   Wu, Q
TI Video metamorphosis using dense flow fields
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE feature tracking; image matching; image pyramids; dynamic programming
ID OPTICAL-FLOW
AB When we perform video metamorphosis, it would be desirable to make smooth morphing transitions simultaneously along with the original motion in the image sequences. In this paper, we present a novel semi-automatic video morphing technique that exhibits this behavior. Our technique effectively exploits temporal coherence and automatic image matching. One-to-one dense mappings between pairs of corresponding frames are obtained by applying a compositing procedure and a hierarchical image matching technique. These dense mappings can be initialized with sparse frame-to-frame feature correspondences obtained semi-automatically by integrating a friendly user interface with a robust feature tracking algorithm. Experimental results show that our approach to video metamorphosis can produce superior results. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Illinois, Urbana, IL 61801 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign
RP Univ Illinois, 201 N Goodwin Ave, Urbana, IL 61801 USA.
EM yyz@uiuc.edu
RI YU, YIZHOU/D-1603-2013; /F-3345-2010
OI /0000-0002-0470-5548
CR [Anonymous], P SIGGRAPH 2002
   [Anonymous], P SIGGRAPHS, DOI DOI 10.1145/218380.218446
   [Anonymous], 1994, P IEEE C COMP VIS PA
   [Anonymous], 1986, COMPUTATIONAL APPROA, DOI DOI 10.1109/TPAMI.1986.4767851
   BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Gao PS, 1998, VISUAL COMPUT, V14, P390, DOI 10.1007/s003710050150
   GOMES J, 1997, SIGGRAPH 97 COURSE N
   Lee S.-Y., 1995, SIGGRAPH '95, P439
   Lucas B.D., DARPA IMAGE UNDERSTA
   Olson CF, 2002, IEEE T PATTERN ANAL, V24, P853, DOI 10.1109/TPAMI.2002.1008392
   Quenot GM, 1998, EXP FLUIDS, V25, P177, DOI 10.1007/s003480050222
   Shinagawa Y, 1998, IEEE T PATTERN ANAL, V20, P994, DOI 10.1109/34.713364
   Szewczyk R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P273, DOI 10.1145/266180.266378
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Wolberg G., 1990, Digital image warping
   YU Y, 2004, UIUCDCSR20042439 U I
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 19
TC 2
Z9 2
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 387
EP 397
DI 10.1002/cav.42
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700029
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kopp, S
   Wachsmuth, P
AF Kopp, S
   Wachsmuth, P
TI Synthesizing multimodal utterances for conversational agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE multimodal conversational agents; gesture animation; model-based
   computer animation; motion control
ID ANIMATION
AB Conversational agents are supposed to combine speech with non-verbal modalities for intelligible multimodal utterances. In this paper, we focus on the generation of gesture and speech from XML-based descriptions of their overt form. An incremental production model is presented that combines the synthesis of synchronized gestural, verbal, and facial behaviors with mechanisms for linking them in fluent utterances with natural co-articulation and transition effects. In particular, an efficient kinematic approach for animating hand gestures from shape specifications is presented, which provides fine adaptation to temporal constraints that are imposed by cross-modal synchrony. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Univ Bielefeld, Fac Technol, Artificial Intelligence Grp, D-33594 Bielefeld, Germany.
C3 University of Bielefeld
RP Univ Bielefeld, Fac Technol, Artificial Intelligence Grp, D-33594 Bielefeld, Germany.
EM skopp@techfak.uni-bielefeld.de
RI Kopp, Stefan/K-3456-2013
OI Kopp, Stefan/0000-0002-4047-9277; Wachsmuth, Ipke/0000-0002-4786-5189
CR [Anonymous], 1989, SPEAKING
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   CASSELL J, 2000, EMBODIED CONVERSATIO, P64
   CASSELL J, 1994, P SIGGRAPH 94
   Cassell J., 2000, Embodied Conversational Agents
   Churchill EF, 2000, EMBODIED CONVERSATIONAL AGENTS, P64
   de_Ruiter J. P, 1998, MPI SERIES PSYCHOLIN
   Gibet S, 2001, J VISUAL LANG COMPUT, V12, P657, DOI 10.1006/jvlc.2001.0202
   Kendon A., 1980, The relationship of verbal and nonverbal communication, P207, DOI [10.1515/9783110813098.207, DOI 10.1515/9783110813098.207]
   KOGA Y, 1994, P SIGGRAPH 94, P395
   Kopp S, 2002, COMP ANIM CONF PROC, P252, DOI 10.1109/CA.2002.1017547
   KOPP S, 2000, ECAI 2000 P 14 EUR C, P661
   Latash M.L., 1993, Control of human movement
   Mataric M. J., 1999, Autonomous Agents and Multi-Agent Systems, V2, P23, DOI 10.1023/A:1010023022632
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   MORASSO P, 1982, BIOL CYBERN, V45, P131, DOI 10.1007/BF00335240
   Nobe S., 2000, LANGUAGE GESTURE
   PERLIN K, 1995, IEEE T VIS COMPUT GR, V1, P5, DOI 10.1109/2945.468392
   Rickel J, 1999, APPL ARTIF INTELL, V13, P343, DOI 10.1080/088395199117315
   SOECHTING JF, 1989, J NEUROPHYSIOL, V62, P582, DOI 10.1152/jn.1989.62.2.582
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   WILHELMSJ, 2001, J GRAPHICS TOOLS, V2, P27
   ZELTZER D, 1982, IEEE COMPUT GRAPH, V2, P53
NR 24
TC 137
Z9 145
U1 0
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2004
VL 15
IS 1
BP 39
EP 52
DI 10.1002/cav.6
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 832EF
UT WOS:000222249300005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xinru, W
AF Xinru, Wu
TI A novel jigsaw game with eye-tracking: A multimodel interaction based on
   psycholinguistics for ADHD therapeutic
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE ADHD; digital therapy; eye-tracking; graphical human-computer
   interaction; user experience design
AB Attention-deficit hyperactivity disorder (ADHD) causes impulsive or hyperactive behaviors and emotional outbursts or trouble focusing. Simple psychotherapy has difficulty achieving desired therapeutic effects, and ADHD diagnoses in adults and children are increasing. However, e-health games may mitigate the limitations of traditional methods by providing an ecologically relevant experience. In this paper, inspired by psycholinguistics, multimodal interaction, and he Pupil-CR method, we have developed a narrative game therapy with eye-tracking to enhance dyslexia and attention deficit manifestations. Using the situated discourses in the game's interactive narration, ADHD patients can concentrate and reduce anxiety and impulsivity. To evaluate the efficacy in improving attention a controlled trial (N = 48) randomly assigned volunteers in 1:1:1 to an eye-tracking jigsaw game or two control groups. The principal measure was the average difference in attention comparison score (ACS) of the test of variables of attention (TOVA) preintervention and post-intervention periods. Based on significant differences observed between the groups, we concluded the eye-tracking jigsaw game could serve as a viable ADHD intervention for children.
C1 [Xinru, Wu] Zhejiang Sci Tech Univ, Sch Foreign Languages, Hangzhou 310018, Peoples R China.
C3 Zhejiang Sci-Tech University
RP Xinru, W (corresponding author), Zhejiang Sci Tech Univ, Sch Foreign Languages, Hangzhou 310018, Peoples R China.
EM 2020336711121@mails.zstu.edu.cn
OI Wu, Xinru/0009-0006-8964-5287
CR AlMarshedi A., 2015, PROCEDIA COMPUT SCI, V63, P63
   Amresh A., 2015, P 5 INT C DIG HLTH 2
   Chuang WC., 2019, PSYCHIATRY, p10:1
   Danielson ML, 2022, J ATTEN DISORD, V26, P1685, DOI 10.1177/10870547221099961
   Darzi A, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/25771
   Demsar J, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1914
   Fan L., 2019, HCI INT 2019 POSTERS, P313
   Gilbertson P., 2008, COMPUT ENTERTAIN, V6, p38:1
   Handelman K, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12080959
   Ikuse D, 2022, J NERV MENT DIS, V210, P525, DOI 10.1097/NMD.0000000000001465
   Kang SH, 2010, COMPUT ANIMAT VIRT W, V21, P473, DOI 10.1002/cav.345
   Kochanowicz J, 2015, COMPUT ANIMAT VIRT W, V26, P247, DOI 10.1002/cav.1639
   Kuijper SJM, 2017, J ABNORM PSYCHOL, V126, P63, DOI 10.1037/abn0000231
   Laraba S, 2016, COMPUT ANIMAT VIRT W, V27, P321, DOI 10.1002/cav.1715
   Moore DA, 2017, CHILD CARE HLTH DEV, V43, P489, DOI 10.1111/cch.12448
   Noah N, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2020
   Norman Don, 2013, The design of everyday things
   Partovi T, 2019, LEARN MOTIV, V68, DOI 10.1016/j.lmot.2019.101592
   PLAUT DC, 1993, COGNITIVE NEUROPSYCH, V10, P377, DOI 10.1080/02643299308253469
   Schunk DH, 2016, EDUC PSYCHOL HANDB, P34
   Tancos M., 2023, J INTELLIGENCE, V11, P11
   Zhang M, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/11640
   Zuckerman O., 2005, P C HUMAN FACTORS CO, P859, DOI [10.1145/1054972.1055093, DOI 10.1145/1054972.1055093]
   Zwaan RA, 1998, PSYCHOL BULL, V123, P162, DOI 10.1037/0033-2909.123.2.162
NR 24
TC 0
Z9 0
U1 8
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2214
EA SEP 2023
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NX4V7
UT WOS:001065805400001
DA 2024-07-18
ER

PT J
AU Zhou, D
   Liu, SG
   Xu, Q
AF Zhou, Dian
   Liu, Shiguang
   Xu, Qing
TI Music conditioned 2D hand gesture dance generation with HGS
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE dance motion synthesis; digital humans; hand gesture dance; multimodal;
   pose generation
AB In recent years, the short video industry is booming. However, there are still many difficulties in the action generation of virtual characters. We observed that on the short video social platform, "hand gesture dance" is a very popular short video form. However, its development is limited by the professionalism of choreography. In order to solve these problems, we propose an intelligent choreography framework, which can generate new gesture sequences for unseen audio based on pairing data in the database. Our framework adopts multimodal method and obtains excellent results. In additional, we collected and produced the first and largest pair labeled hand gesture dance data set. Various experiments showed that our results not only generate smooth and rich action sequences, but also collect some semantic information contained in the audio.
   We propose an intelligent choreography framework, which can generate new gesture sequences for unseen audio based on pairing data in the database. Our framework adopts multimodal method and obtains excellent results. In additional, we collected and produced the first and largest pair labeled hand gesture dance data set. Various experiments showed that our results not only generate smooth and rich action sequences, but also collect some semantic information contained in the audio. image
C1 [Zhou, Dian; Liu, Shiguang; Xu, Qing] Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Liu, Shiguang] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin, Peoples R China.
   [Liu, Shiguang] Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
C3 Tianjin University; Tianjin University; Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Alexanderson S, 2020, COMPUT GRAPH FORUM, V39, P487, DOI 10.1111/cgf.13946
   Ao T., 2023, P ACM SIGGRAPH NEW Y
   Aristidou A., 2022, P IEEE T VIS COMP GR
   Aristidou A, 2023, IEEE T VIS COMPUT GR, V29, P3519, DOI 10.1109/TVCG.2022.3163676
   Bhattacharya U, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P160, DOI 10.1109/VR50410.2021.00037
   Bogaers A, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P22, DOI 10.1145/3395035.3425244
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459932
   Chopin B., BIPARTITE GRAPH DIFF
   Ferstl Y, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P93, DOI 10.1145/3267851.3267898
   Fu Z., 2022, P 2022 IEEE INT C MU, P1
   Habibie Ikhsanul, 2022, SIGGRAPH22 Conference Proceeding: Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings, DOI 10.1145/3528233.3530750
   Habibie I, 2021, PROCEEDINGS OF THE 21ST ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA), P101, DOI 10.1145/3472306.3478335
   Jiang T., RTMPOSE REAL TIME MU
   Jin S., 2020, COMPUTER VISION ECCV, P196
   Kim J., 2023, AAAI, P8255
   Lee M, 2013, MULTIMED TOOLS APPL, V62, P895, DOI 10.1007/s11042-012-1288-5
   Li J., LEARNING GENERATE DI
   Li RL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13381, DOI 10.1109/ICCV48922.2021.01315
   Li SY, 2022, PROC CVPR IEEE, P11040, DOI 10.1109/CVPR52688.2022.01077
   Manfrè A, 2016, BIOL INSPIR COGN ARC, V15, P1, DOI 10.1016/j.bica.2015.09.009
   Park S, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3480145
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Qi Y, 2019, IEEE ACCESS, V7, P166540, DOI 10.1109/ACCESS.2019.2953698
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun L, 2019, IEEE INT CON MULTI, P1300, DOI 10.1109/ICME.2019.00226
   Tevet G., HUMAN MOTION DIFFUSI
   Tevet G, 2022, LECT NOTES COMPUT SC, V13682, P358, DOI 10.1007/978-3-031-20047-2_21
   Tseng J, 2023, PROC CVPR IEEE, P448, DOI 10.1109/CVPR52729.2023.00051
   Xu J., FREEFORM BODY MOTION
   Xu LM, 2023, IEEE T PATTERN ANAL, V45, P5296, DOI 10.1109/TPAMI.2022.3197352
   Yan XC, 2018, LECT NOTES COMPUT SC, V11209, P276, DOI 10.1007/978-3-030-01228-1_17
   Yoon Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417838
   Zauss D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11037, DOI 10.1109/ICCV48922.2021.01087
   Zeng W, 2022, PROC CVPR IEEE, P11091, DOI 10.1109/CVPR52688.2022.01082
   Zhang F, 2023, LECT NOTES COMPUT SC, V13833, P231, DOI 10.1007/978-3-031-27077-2_18
   Zhang H, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3448978, 10.1145/3450626.3459830]
   Zhang M., MOTIONDIFFUSE TEXT D
   Zhou YX, 2020, PROC CVPR IEEE, P5345, DOI 10.1109/CVPR42600.2020.00539
   Zhuang W., 2020, ACM T MULTIM COMPUT, V18, P1
   Zhuang W., 3D DANCE MOTION SYNT
NR 41
TC 0
Z9 0
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2211
EA AUG 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JK2X0
UT WOS:001151999700001
DA 2024-07-18
ER

PT J
AU Tu, ZL
   Peng, C
   Li, C
   Wang, CH
   Liu, L
   Wang, CB
   Qin, H
AF Tu, Zaili
   Peng, Chen
   Li, Chen
   Wang, Chenhui
   Liu, Long
   Wang, Changbo
   Qin, Hong
TI MPM-driven dynamic desiccation cracking and curling in unsaturated soils
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE material point method; mesh reconstruction; physics-based simulation;
   soil cracks simulation
ID FRACTURE
AB Desiccation cracking of soil-like materials is a common phenomenon in natural dry environment, however, it remains a challenge to model and simulate complicated multi-physical processes inside the porous structure. With the goal of tracking such physical evolution accurately, we propose an MPM based method to simulate volumetric shrinkage and crack during moisture diffusion. At the physical level, we introduce Richards equations to evolve the dynamic moisture field to model evaporation and diffusion in unsaturated soils, with which a elastoplastic model is established to simulate strength changes and volumetric shrinkage via a novel saturation-based hardening strategy during plastic treatment. At the algorithmic level, we develop an MPM-fashion numerical solver for the proposed physical model and achieve stable yet efficient simulation towards delicate deformation and fracture. At the geometric level, we propose a correlating stretching criteria and a saturation-aware extrapolation scheme to extend existing surface reconstruction for MPM, producing visual compelling soil appearance. Finally, we manifest realistic simulation results based on the proposed method with several challenging scenarios, which demonstrates usability and efficiency of our method.
C1 [Tu, Zaili; Peng, Chen; Li, Chen; Wang, Chenhui; Liu, Long; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY USA.
   [Li, Chen; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Technol, 3663 North Zhongshan Rd, Shanghai, Peoples R China.
C3 East China Normal University; State University of New York (SUNY)
   System; State University of New York (SUNY) Stony Brook; East China
   Normal University
RP Li, C; Wang, CB (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, 3663 North Zhongshan Rd, Shanghai, Peoples R China.
EM cli@cs.ecnu.edu.cn; cbwang@cs.ecnu.edu.cn
OI Tu, Zaili/0000-0001-6316-473X
FU Natural Science Foundation of China [62002121, 62072183]; National
   Science Foundation of USA [IIS-1715985, IIS-1812606]; Science and
   Technology Commission of Shanghai Municipality [22511104600]
FX This article is partially supported by Natural Science Foundation of
   China under Grants 62002121 and 62072183, National Science Foundation of
   USA (IIS-1715985 and IIS-1812606), Science and Technology Commission of
   Shanghai Municipality (No. 22511104600). The authors would like to
   express sincere gratitude to these institutions for their support, as
   well as to all the reviewers for their thoughtful and valuable
   suggestions.
CR Bao ZS, 2007, IEEE T VIS COMPUT GR, V13, P370, DOI 10.1109/TVCG.2007.39
   Brochu T, 2009, SIAM J SCI COMPUT, V31, P2472, DOI 10.1137/080737617
   Chen FB, 2013, COMPUT ANIMAT VIRT W, V24, P215, DOI 10.1002/cav.1514
   Chen JY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459874
   Chen XS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417809
   Da F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601146
   Ding MY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356537
   Enright D, 2005, COMPUT STRUCT, V83, P479, DOI 10.1016/j.compstruc.2004.04.024
   Fan LX, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3522573
   Fang Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392438
   Fei Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459678
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275044
   Glondu L, 2013, IEEE T VIS COMPUT GR, V19, P201, DOI 10.1109/TVCG.2012.121
   Hu YX, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392385
   Hu YM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201293
   Jiang C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766996
   Jiang CFF, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073623
   Klár G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925906
   Koschier D., ADAPTIVE TETRAHEDRAL
   Muller M., FAST ROBUST TRACKING
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Ram D., MAT POINT METHOD VIS
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Stomakhin A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601176
   Style RW, 2011, J GEOPHYS RES-EARTH, V116, DOI 10.1029/2010JF001842
   Sun YC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480541
   Tampubolon Andre Pradhana, 2017, ACM Transactions on Graphics, V36, DOI 10.1145/3072959.3073651
   Tang CS, 2021, EARTH-SCI REV, V216, DOI 10.1016/j.earscirev.2021.103586
   Wang S, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340259
   Wojtan C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778787
   Wolper J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392428
   Wolper J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322949
   Yue YH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2751541
   Zhao ZP, 2020, COMPUT GRAPH FORUM, V39, P105, DOI 10.1111/cgf.14130
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 35
TC 0
Z9 0
U1 4
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2172
EA MAY 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000989700900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Luo, Y
   Liu, F
   She, YY
   Yang, BR
AF Luo, Yan
   Liu, Fang
   She, Yingying
   Yang, Baorong
TI A context-aware mobile augmented reality pet interaction model to
   enhance user experience
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE context awareness; MAR; virtual pet
ID ATTACHMENT; AIBO
AB Virtual pet applications have been widely developed and applied in various fields. Mobile augmented reality (MAR) provides a new medium for virtual pets, allowing users to have a more immersive interactive experience through MAR pets. However, the issue of the user experience in MAR pets remains uninvestigated and relatively unexploited. Therefore, this article proposes a context-aware MAR pet interaction model (CAPet model) to enhance the user experience in MAR pet systems, which allows the MAR pet makes feedback adaptively corresponding to the dynamic context. In addition, this article presents a user experience pyramid to measure the user experience for MAR pet. According to the proposed CAPet model, a MAR pet-dog application is designed and implemented, based on which user test are conducted. The results of user test indicate the effectiveness of the proposed method on enhancing user experience, which provides a basis for the design of MAR pet applications in the future.
C1 [Luo, Yan] Xiamen Univ, Sch Informat, Xiamen, Peoples R China.
   [Liu, Fang; She, Yingying] Xiamen Univ, Sch Film, Xiamen, Peoples R China.
   [She, Yingying] Xiamen Univ, Natl Inst Data Sci Hlth & Med, Xiamen, Peoples R China.
   [Yang, Baorong] Jimei Univ, Coll Comp Engn, Xiamen, Peoples R China.
C3 Xiamen University; Xiamen University; Xiamen University; Jimei
   University
RP She, YY (corresponding author), Xiamen Univ, Sch Film, Xiamen, Peoples R China.; Yang, BR (corresponding author), Jimei Univ, Coll Comp Engn, Xiamen, Peoples R China.
EM yingyingshe@xmu.edu.cn; yangbaorong@jmu.edu.cn
RI fang, liu/HCI-5461-2022
OI She, Yingying/0000-0002-6770-4622; yang, baorong/0000-0002-2896-2506
FU Fujian Science and Technology Program Guiding Project [2020H0001];
   Fujian Provincial Department of Education [JAT200286]; Natural Science
   Foundation of Fujian Province [2021J05170]; Open Project Program of
   State Key Laboratory of Virtual Reality Technology and Systems, Beihang
   University [VRLAB2020B16]; Scientific Research Start-up Fund Project of
   Jimei University [ZQ2021002]
FX Fujian Science and Technology Program Guiding Project, Grant/Award
   Number: 2020H0001; General Program Funded by Fujian Provincial
   Department of Education, Grant/Award Number: JAT200286; Natural Science
   Foundation of Fujian Province, Grant/Award Number: 2021J05170; Open
   Project Program of State Key Laboratory of Virtual Reality Technology
   and Systems, Beihang University, Grant/Award Number: VRLAB2020B16;
   Scientific Research Start-up Fund Project of Jimei University,
   Grant/Award Number: ZQ2021002
CR Alfaro JLD, 2021, LECT NOTES COMPUT SC, V12980, P428, DOI 10.1007/978-3-030-87595-4_32
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Barreira J, 2018, IEEE T VIS COMPUT GR, V24, P1223, DOI 10.1109/TVCG.2017.2676777
   BOWLBY J, 1982, AM J ORTHOPSYCHIAT, V52, P664, DOI 10.1111/j.1939-0025.1982.tb01456.x
   Carmigniani J, 2011, HANDBOOK OF AUGMENTED REALITY, P3, DOI 10.1007/978-1-4614-0064-6_1
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Chesney T, 2007, INTERACT STUD, V8, P337, DOI 10.1075/is.8.2.09che
   Crawford EK, 2006, ANTHROZOOS, V19, P98, DOI 10.2752/089279306785593757
   Dey A.K., 2000, Providing Architectural Support for Building Context-Aware Applications
   Dieck MCT, 2018, CURR ISSUES TOUR, V21, P154, DOI 10.1080/13683500.2015.1070801
   Fujita M, 2001, INT J ROBOT RES, V20, P781, DOI 10.1177/02783640122068092
   Fujita M, 2004, P IEEE, V92, P1804, DOI 10.1109/JPROC.2004.835364
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Hung LL, 2019, BMC GERIATR, V19, DOI 10.1186/s12877-019-1244-6
   Kerepesi A, 2006, BEHAV PROCESS, V73, P92, DOI 10.1016/j.beproc.2006.04.001
   Kim MJ, 2013, AUTOMAT CONSTR, V33, P79, DOI 10.1016/j.autcon.2012.10.020
   Kim M, 2016, MULTIMED TOOLS APPL, V75, P16529, DOI 10.1007/s11042-016-3355-9
   Lian XJ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104550
   Lin CL, 2017, INT CONF AFFECT, P362, DOI 10.1109/ACII.2017.8273625
   Liu J, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420540051
   Norouzi N, 2019, INT SYM MIX AUGMENT, P157, DOI 10.1109/ISMAR.2019.000-8
   Paavilainen J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2493, DOI 10.1145/3025453.3025871
   Poretski Lev., 2019, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'19), P1
   Schilit B., 1994, 1994 1 WORKSHOP MOBI, P85, DOI [DOI 10.1109/WMCSA.1994.16, 10.1109/WMCSA.1994.16]
   Wang ZM, 2021, IEEE T HUM-MACH SYST, V51, P524, DOI 10.1109/THMS.2021.3097973
   Weiss A, 2009, INT J SOC ROBOT, V1, P243, DOI 10.1007/s12369-009-0024-4
   Wu QX, 2023, PATHOG GLOB HEALTH, V117, P235, DOI 10.1080/20477724.2022.2114620
   Zilcha-Mano S, 2011, J RES PERS, V45, P345, DOI 10.1016/j.jrp.2011.04.001
NR 28
TC 0
Z9 0
U1 12
U2 37
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2023
VL 34
IS 1
SI SI
AR e2123
DI 10.1002/cav.2123
EA AUG 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Z2BA
UT WOS:000843754700001
DA 2024-07-18
ER

PT J
AU Chen, ZY
   Chen, XW
   Ma, Y
   Guo, SH
   Qin, YP
   Liao, MH
AF Chen, Zhiyong
   Chen, Xiaowei
   Ma, Yong
   Guo, Shihui
   Qin, Yipeng
   Liao, Minghong
TI Human posture tracking with flexible sensors for motion recognition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE flexible sensor; smart clothes; user authentication
ID AUTHENTICATION; NETWORK
AB The integration of conventional clothes with flexible electronics is a promising solution as a future-generation computing platform. However, the problem of user authentication on this novel platform is still underexplored. This work uses flexible sensors to track human posture and achieves the goal of user authentication. We capture human movement pattern by four stretch sensors around the shoulder and one on the elbow. We introduce the long short-term memory fully convolutional network (LSTM-FCN), which directly takes noisy and sparse sensor data as input and verifies its consistency with the user's predefined movement patterns. The method can identify a user by matching movement patterns even if there are large intrapersonal variations. The authentication accuracy of LSTM-FCN reaches 98.0%, which is 10.7% and 6.5% higher than that of dynamic time warping and dynamic time warping dependent.
C1 [Chen, Zhiyong; Chen, Xiaowei; Guo, Shihui; Liao, Minghong] Xiamen Univ, Sch Informat, Xiamen, Peoples R China.
   [Ma, Yong] Jiangxi Normal Univ, Sch Comp Informat Engn, Nanchang, Jiangxi, Peoples R China.
   [Qin, Yipeng] Cardiff Univ, Sch Comp Sci & Informat, Cardiff, Wales.
C3 Xiamen University; Jiangxi Normal University; Cardiff University
RP Guo, SH (corresponding author), Xiamen Univ, Sch Informat, Xiamen, Peoples R China.
EM guoshihui@xmu.edu.cn
RI Qin, Yipeng/ACP-7391-2022
OI Qin, Yipeng/0000-0002-1551-9126; Chen, Xiaowei/0000-0003-0027-2420
FU National Natural Science Foundation of China [61702433, 61661146002];
   Fundamental Research Funds for the Central Universities [20720190006];
   Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University [VRLAB2020B17]
FX National Natural Science Foundation of China, Grant/Award Number:
   61702433, 61661146002; the Fundamental Research Funds for the Central
   Universities, Grant/Award Number: 20720190006; the Open Project Program
   of State Key Laboratory of Virtual Reality Technology and Systems,
   Beihang University, Grant/Award Number: VRLAB2020B17
CR El Khiyari H., 2016, Journal of Information Security, V7, P141
   Esfahani MIM, 2018, IEEE SENS J, V18, P7650, DOI 10.1109/JSEN.2018.2859626
   Gadaleta M, 2016, 2016 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP)
   Glauser O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311972
   Hajari K, 2016, PROCEDIA COMPUT SCI, V78, P675, DOI 10.1016/j.procs.2016.02.116
   He HS, 2015, IEEE T AUTOM SCI ENG, V12, P1181, DOI 10.1109/TASE.2015.2471175
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Javed A., 2019, MULTIVARIATE TIME SE
   Karim F, 2018, IEEE ACCESS, V6, P1662, DOI 10.1109/ACCESS.2017.2779939
   Kim D, 2019, IEEE-ASME T MECH, V24, P56, DOI 10.1109/TMECH.2018.2874647
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Liu Y, 2019, IEEE INFOCOM SER, P2386, DOI [10.1109/INFOCOM.2019.8737366, 10.1109/infocom.2019.8737366]
   Liu Y, 2018, SOFT COMPUT, V22, P2257, DOI 10.1007/s00500-017-2487-9
   Lu D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P531, DOI 10.1109/BTAS.2017.8272739
   Peter S, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040570
   Rajagopal Gayathri, 2015, ScientificWorldJournal, V2015, P861629, DOI 10.1155/2015/861629
   Reddy, 2019, INT J INTELL ENG SYS, V12, P62, DOI DOI 10.22266/IJIES2019.0228.07
   Ruibo Liu, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3314406
   Shioji R., 2017, P 5 IIAE INT C INT S
   Song HY, 2013, APPL MECH MATER, V321-324, P684, DOI 10.4028/www.scientific.net/AMM.321-324.684
   Tavenard R., 2017, tslearn: A machine learning toolkit dedicated to time-series data
   Tian YS, 2015, NEUROCOMPUTING, V159, P207, DOI 10.1016/j.neucom.2015.01.071
   Traore I, 2017, Information security practices: Emerging threats and perspectives, P73
   Vhaduri S, 2017, 2017 IEEE 28TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), DOI 10.1109/PIMRC.2017.8292272
   von Marcard T, 2018, LECT NOTES COMPUT SC, V11214, P614, DOI 10.1007/978-3-030-01249-6_37
   Wang XH, 2020, MULTIMED TOOLS APPL, V79, P2917, DOI 10.1007/s11042-019-08509-w
   Xu SY, 2019, ADV FUNCT MATER, V29, DOI 10.1002/adfm.201807058
   Yahya M, 2019, SENSOR REV, V39, P504, DOI 10.1108/SR-10-2018-0270
   Yeh KH, 2018, IEEE COMMUN MAG, V56, P150, DOI 10.1109/MCOM.2018.1700339
   Zhang X, 2017, NAT COMMUN, V8, DOI [10.1038/ncomms15280, 10.1038/ncomms14542]
   Zhang YH, 2016, IEEE-ASME T MECH, V21, P163, DOI 10.1109/TMECH.2015.2490118
NR 31
TC 4
Z9 4
U1 7
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2021
VL 32
IS 5
AR e1993
DI 10.1002/cav.1993
EA APR 2021
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WJ5HR
UT WOS:000637189900001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Yang, LJ
   Xu, TC
   Du, JX
   Zhang, HB
   Wu, EH
AF Yang, Lijie
   Xu, Tianchen
   Du, Jixiang
   Zhang, Hongbo
   Wu, Enhua
TI Brushwork master: Chinese ink painting synthesis for animating brushwork
   process
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 2D object synthesis; Chinese ink painting; computer animation; drawing
   process; image-based modeling
ID SIMULATION
AB Generally, it is regarded as challenge work to grasp the drawing style of an ancient masterpiece in Chinese painting learning. This paper presents a novel approach to the generation of a Chinese ink painting in a certain style and animating its brushwork process with expert skills. In order to demonstrate the techniques of brush and ink inside a stroke, a serials of geometric properties of a brush stroke, are first extracted, then through rational deformation calculation, the best stroke source is mapped onto the stroking path, which is sketched by the user, and finally a new Chinese painting can be synthesized by style migration and natural stroke composition. So with the generated strokes, the lifelike brushwork process of the new painting can be represented dramatically. Actually, by showing the authentic painting process, the tool we implemented helps the learners, who have no profound skills and knowledge in domain of Chinese painting, master the essence of a great painting style, and also provides an easy way to art creation and the comprehension of mysterious Chinese traditional art.
C1 [Yang, Lijie; Du, Jixiang; Zhang, Hongbo] Huaqiao Univ, Coll Comp Sci & Technol, 668 Jimei Ave, Xiamen, Fujian, Peoples R China.
   [Xu, Tianchen; Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Xu, Tianchen; Wu, Enhua] Univ CAS, Beijing, Peoples R China.
   [Wu, Enhua] Univ Macau, Fac Sci & Technol FST, Macau, Peoples R China.
C3 Huaqiao University; Chinese Academy of Sciences; Institute of Software,
   CAS; University of Macau
RP Xu, TC (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.; Xu, TC (corresponding author), Univ CAS, Beijing, Peoples R China.
EM tianchenx@outlook.com
OI Yang, Lijie/0000-0003-0902-401X
FU National Key Research and Development Program of China [2019YFC1604700];
   National Natural Science Foundation of China [61602190, 61632003,
   61673186, 61871196]; Natural Science Foundation of Fujian Province
   [2019J01082]; Promotion Program for Young and Middle-aged Teacher in
   Science and Technology Research of Huaqiao University [ZQN-710];
   University of Macau Grant [MYRG2019-00006-FST]
FX National Key Research and Development Program of China, Grant/Award
   Number: 2019YFC1604700; National Natural Science Foundation of China,
   Grant/Award Numbers: 61602190, 61632003, 61673186, 61871196; Natural
   Science Foundation of Fujian Province, Grant/Award Number: 2019J01082;
   Promotion Program for Young and Middle-aged Teacher in Science and
   Technology Research of Huaqiao University, Grant/Award Number: ZQN-710;
   University of Macau Grant, Grant/Award Number: MYRG2019-00006-FST
CR [Anonymous], 2004, COMP VIS PATT REC 20
   Chan C, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P403, DOI 10.1109/PCCGA.2002.1167884
   Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   Jun-Wei Yeh, 2002, Journal of System Simulation, V14, P1220
   Kalnins RD, 2002, ACM T GRAPHIC, V21, P755, DOI 10.1145/566570.566648
   Lee J, 1999, IEEE COMPUT GRAPH, V19, P74, DOI 10.1109/38.761553
   Liu J., 2014, Proceedings of the Workshop on Computational Aesthetics, P15, DOI DOI 10.22004/AG.ECON.169804
   Manli Yuan, 2007, Proceedings Graphics Interface 2007, P57, DOI 10.1145/1268517.1268529
   Porter T., 1984, Computers & Graphics, V18, P253
   Schmid J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964923
   Van Laerhoven T, 2005, COMPUT ANIMAT VIRT W, V16, P429, DOI 10.1002/cav.95
   Way DL, 2001, COMPUT GRAPH FORUM, V20, pC123
   Xie N., 2010, Proc. NPAR '10, P63
   Xu SH, 2006, ACM T GRAPHIC, V25, P239, DOI 10.1145/1138450.1138454
   Xu TC, 2012, P SIGGRAPH AS 2012 T, P19
   Yang L.-J., 2014, ACM SIGGRAPH ASIA 20, P1
   Yang LJ, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4740-2
   Yang Lijie XT, 2013, J COMPUT AID COMPUT, V28, P742
   You M, 2013, COMPUT ANIMAT VIRT W, V24, P297, DOI 10.1002/cav.1500
   Yu JH, 2003, J COMPUT SCI TECH-CH, V18, P22, DOI 10.1007/BF02946647
   Zhang SH, 2009, SCI CHINA SER F, V52, P162, DOI 10.1007/s11432-009-0035-7
NR 21
TC 2
Z9 2
U1 1
U2 25
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2020
VL 31
IS 4-5
AR e1949
DI 10.1002/cav.1949
EA SEP 2020
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OG1RS
UT WOS:000566758100001
DA 2024-07-18
ER

PT J
AU Frerichs, D
   Vidler, A
   Gatzidis, C
AF Frerichs, Dhana
   Vidler, Andrew
   Gatzidis, Christos
TI Computer graphics simulation of natural mummification by desiccation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE appearance modeling; decomposition; mummification; physical-based
   simulation
ID DEFORMATION; SHRINKAGE; WRINKLES; MODEL
AB Organic bodies are subject to internal processes after death, causing significant structural, and optical changes. Mummification by desiccation leads to volume shrinkage, skin wrinkling, and discoloration. We propose a method to simulate the process of mummification by desiccation and its effects on the corpse's morphology and appearance. The mummifying body is represented by a layered model consisting of a tetrahedral mesh, representing the volume, plus a high resolution triangle surface mesh representing the skin. The finite element method is used to solve the moisture diffusion and the resulting volume deformations. Skin wrinkling is achieved using position based dynamics. In order to model a visually believable reproduction of the skin coloration changes due to mummification, a skin shading approach is used that considers moisture content, hemoglobin content, and oxygen saturation. The main focus of the work in this article is to recreate the appearance changes of mummification by desiccation, which, to the best of our knowledge, has not been attempted before in computer graphics to this level of realism. The suggested approach is able to model changes in the internal structure and the surface appearance of the body which resemble the postmortem processes of natural mummification by desiccation.
C1 [Frerichs, Dhana; Vidler, Andrew] Ninja Theory Ltd, R&D Dept, Cambridge, England.
   [Gatzidis, Christos] Bournemouth Univ, Fac Sci & Technol, Dept Creat Technol, Poole, Dorset, England.
C3 Bournemouth University
RP Frerichs, D (corresponding author), Ninja Theory Ltd, Cambridge, England.
EM dhana.frerichs@ninjatheory.com
OI Vidler, Andrew/0000-0001-6342-0844
FU EPSRC, via the doctorate training Centre for Digital Entertainment;
   Ninja Theory Ltd.
FX We would like to thank the reviewers for constructive criticisms and
   suggestion that improved the article. The research presented in this
   article is funded by EPSRC, via the doctorate training Centre for
   Digital Entertainment in conjunction with Ninja Theory Ltd.
CR Aufderheide A.C., 2003, SCI STUDY MUMMIES
   Bohnert M, 2000, INT J LEGAL MED, V113, P343, DOI 10.1007/s004149900107
   Boissieux L, 2000, SPRING COMP SCI, P15
   BroNielsen M, 1996, COMPUT GRAPH FORUM, V15, pC57
   Chang YX, 2003, VISUAL COMPUT, V19, P50, DOI 10.1007/s00371-002-0172-0
   Chen YY, 2005, ACM T GRAPHIC, V24, P1127, DOI 10.1145/1073204.1073321
   Cotin S, 1999, IEEE T VIS COMPUT GR, V5, P62, DOI 10.1109/2945.764872
   Courtecuisse H, 2014, MED IMAGE ANAL, V18, P394, DOI 10.1016/j.media.2013.11.001
   Desbenoit B, 2005, VISUAL COMPUT, V21, P717, DOI 10.1007/s00371-005-0317-z
   Donner C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409093
   DORSEY J, 1996, P SIGGRAPH 96, P387
   Dorsey Julie., 1996, Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques, P411, DOI [10.1145/237170. 237280, DOI 10.1145/237170.237280]
   Eisenberg M. A., 1973, International Journal for Numerical Methods in Engineering, V7, P574, DOI 10.1002/nme.1620070421
   Farahani MHDA, 2016, DESALIN WATER TREAT, V57, P11931, DOI 10.1080/19443994.2015.1048739
   FRERICHS D, 2016, VISUAL COMPUT, P1
   Frerichs D, 2015, COMPUT GRAPH-UK, V52, P18, DOI 10.1016/j.cag.2015.06.004
   GUNTHER T, 2012, VMV 2012 VIS MOD VIS
   Iglesias-Guitian JA, 2015, COMPUT GRAPH FORUM, V34, P45, DOI 10.1111/cgf.12540
   Jeong S, 2013, COMPUT GRAPH FORUM, V32, P204, DOI 10.1111/cgf.12009
   Jimenez J, 2015, COMPUT GRAPH FORUM, V34, P188, DOI 10.1111/cgf.12529
   Jimenez J, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1609967.1609970
   Kider JT, 2011, COMPUT GRAPH FORUM, V30, P257, DOI 10.1111/j.1467-8659.2011.01857.x
   Liu YQ, 2012, COMPUT ANIMAT VIRT W, V23, P395, DOI 10.1002/cav.1459
   Lynnerup N, 2007, YEARB PHYS ANTHROPOL, V50, P162, DOI 10.1002/ajpa.20728
   Mayor L, 2004, J FOOD ENG, V61, P373, DOI 10.1016/S0260-8774(03)00144-4
   Merillou S., 2001, P GRAPHICS INTERFACE, P167
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muguercia L, 2014, COMPUT GRAPH-UK, V45, P86, DOI 10.1016/j.cag.2014.08.006
   Müller M, 2004, PROC GRAPH INTERF, P239
   Muller Matthias, 2010, Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P85, DOI [10.5555/1921427.19214412, DOI 10.5555/1921427.19214412]
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Neumann T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508417
   Papageorgopoulou C, 2015, ANAT REC, V298, P974, DOI 10.1002/ar.23134
   Querleux B., 2016, Computational Biophysics of the Skin
   Reddy J. N., 2010, FINITE ELEMENT METHO
   SARAH F, 1997, TR9719 MITS EL RES L
   Vidovic L, 2013, PROC SPIE, V9032, DOI 10.1117/12.2044682
   Wu Y, 1999, VISUAL COMPUT, V15, P183, DOI 10.1007/s003710050171
   Yang H, 2001, DRY TECHNOL, V19, P1441, DOI 10.1081/DRT-100105299
   Zhang N, 2010, IEEE T VIS COMPUT GR, V16, P1405, DOI 10.1109/TVCG.2010.221
   2016, TEN24 DIGITAL CAPTUR
NR 41
TC 0
Z9 0
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2020
VL 31
IS 6
AR e1927
DI 10.1002/cav.1927
EA JUN 2020
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE8AF
UT WOS:000538630700001
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Wang, B
   Liu, WB
   Xing, WW
AF Wang, Bin
   Liu, Weibin
   Xing, Weiwei
TI Motion capture data segmentation using Riemannian manifold learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE geodesic; manifold learning; motion capture; Riemannian manifold;
   segmentation
AB Due to the inherent nonlinear nature of data, traditional linear methods have some limitations in finding the intrinsic dimensions of motion capture (Mo-cap) data. Mo-cap data are more in line with the characteristics of the manifold. Assuming that the data are initially a low-dimensional manifold and uniformly sampled in high-dimensional Euclidean space, manifold learning recovers low-dimensional manifold structures from high-dimensional sampled data. This paper proposes an automatic segmentation method based on geodesics by introducing a Riemannian manifold. We convert Mo-cap data from Euler angles into quaternions, calculate the intrinsic mean of the motion sequence, hemispherize quaternions, and use logarithmic and exponential mapping to calculate geodesic distances instead of quaternions. The experimental results show that the algorithms can achieve automatic segmentation and have a better segmentation effect.
C1 [Wang, Bin; Liu, Weibin] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Wang, Bin] East China Jiaotong Univ, Sch Software, Nanchang, Jiangxi, Peoples R China.
   [Xing, Weiwei] Beijing Jiaotong Univ, Sch Software Engn, Beijing, Peoples R China.
C3 Beijing Jiaotong University; East China Jiaotong University; Beijing
   Jiaotong University
RP Liu, WB (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Inst Informat Sci, Beijing 100044, Peoples R China.
EM wbliu@bjtu.edu.cn
OI Wang, Bin/0000-0002-0409-9496
CR Barbic J, 2004, PROC GRAPH INTERF, P185
   Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e
   CHENG SY, 1975, COMMUN PUR APPL MATH, V28, P333, DOI 10.1002/cpa.3160280303
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   Diebel J., 2006, MATRIX, V58, P1, DOI [DOI 10.1093/JXB/ERM298, 10.1093/jxb/erm298]
   Dunteman G.H., 1989, PRINCIPAL COMPONENTS, P69, DOI DOI 10.4135/9781412985475
   Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793
   Fletcher PT, 2003, P IEEE COMP SOC C CO
   Fod A, 2002, AUTON ROBOT, V12, P39, DOI 10.1023/A:1013254724861
   Jenkins OC, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2551, DOI 10.1109/IRDS.2002.1041654
   Johnson MP, 2003, THESIS
   Kondo K., 2004, Journal for Geometry and Graphics, V8, P81
   Krüger B, 2017, IEEE T MULTIMEDIA, V19, P797, DOI 10.1109/TMM.2016.2635030
   Lv N, 2014, COMPUT ANIMAT VIRT W, V25, P283, DOI 10.1002/cav.1597
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Rocha L., 2003, A Practical Approach to Microarray Data Analysis, P91, DOI [10.1007/0-306-47815-3, DOI 10.1007/0-306-47815-35, 10.1007/0-306-47815-3_5, DOI 10.1007/0-306-47815-3_5]
   Santello M, 2002, J NEUROSCI, V22, P1426, DOI 10.1523/JNEUROSCI.22-04-01426.2002
   Sedmidubsky J, 2018, MULTIMED TOOLS APPL, V77, P12073, DOI 10.1007/s11042-017-4859-7
   Seward AE, 2005, P 43 ANN SE REG C NE, V2, P388
   Souvenir R, 2005, IEEE I CONF COMP VIS, P648
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Xia GY, 2018, IEEE T IMAGE PROCESS, V27, P135, DOI 10.1109/TIP.2017.2738562
   Xing WW, 2016, COMPUT ANIMAT VIRT W, V27, P501, DOI 10.1002/cav.1690
   Yu XM, 2017, J VISUAL LANG COMPUT, V43, P50, DOI 10.1016/j.jvlc.2017.09.001
   Zhao LW, 2005, GRAPH MODELS, V67, P1, DOI 10.1016/j.gmod.2004.08.002
   Zhou F, 2008, J ENVIRON INFORM, V11, P1, DOI 10.3808/jei.200800105
NR 28
TC 1
Z9 1
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2020
VL 31
IS 1
AR e1885
DI 10.1002/cav.1885
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KR0SC
UT WOS:000517329600004
DA 2024-07-18
ER

PT J
AU Ronchi, E
   Mayorga, D
   Lovreglio, R
   Wahlqvist, J
   Nilsson, D
AF Ronchi, Enrico
   Mayorga, David
   Lovreglio, Ruggiero
   Wahlqvist, Jonathan
   Nilsson, Daniel
TI Mobile-powered head-mounted displays versus cave automatic virtual
   environment experiments for evacuation research
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE CAVE; evacuation; flashing lights; HMD; tunnel; virtual reality
ID TUNNEL EVACUATION; REALITY; AFFORDANCES; NAVIGATION; SIMULATION; CHOICE;
   SIGNS
AB Different virtual reality (VR) experimental tools and equipment are available for evacuation research, ranging from highly immersive systems such as cave automatic virtual environments (CAVEs) to head-mounted displays (HMDs). In particular, mobile-powered HMDs are an extremely cost-efficient solution, for which the research potential for evacuation studies needs to be assessed. This study compares the results of tunnel evacuation experiments aimed at investigating the design of flashing lights on emergency exit portals using two different VR methods (CAVE vs. mobile-powered HMD). The experiments were performed by repeating the same case study in a CAVE laboratory and a low-cost mobile-powered HMD. The CAVE experiment involved 96 participants, whereas the HMD experiment involved 55 participants. An affordance-based questionnaire was used to interview participants immersed in a VR road tunnel emergency evacuation scenario and rank different emergency portal designs. Questionnaire results show consistency between the two experimental methods for the variables investigated, thus leading to be in favor of the use of low-cost mobile-powered HMD tools in evacuation scenarios with a relatively limited level of complexity.
C1 [Ronchi, Enrico; Mayorga, David; Wahlqvist, Jonathan; Nilsson, Daniel] Lund Univ, Div Fire Safety Engn, S-22100 Lund, Sweden.
   [Lovreglio, Ruggiero] Univ Auckland, Dept Civil & Environm Engn, Auckland, New Zealand.
C3 Lund University; University of Auckland
RP Ronchi, E (corresponding author), Lund Univ, Div Fire Safety Engn, S-22100 Lund, Sweden.
EM enrico.ronchi@brand.lth.se
RI Ronchi, Enrico/H-7130-2019; Lovreglio, Ruggiero/AAH-7275-2019
OI Ronchi, Enrico/0000-0002-2789-6359; Lovreglio,
   Ruggiero/0000-0003-4596-7656
FU SENESCYT
FX SENESCYT, Grant/Award Number: Equadorian government scholarship
CR [Anonymous], 1986, The Ecological Approach toVisual Perception
   [Anonymous], 2016, Modelling decision-making in fire evacuation based on random utility theory
   [Anonymous], 2010, MODELING ORDERED CHO
   Arias S, 2018, 3218 LUTVDGTVBB
   Arias S, 2017, 12 INT S FIR SAF SCI
   Ben-Akiva M, 2012, MARKET LETT, V23, P439, DOI 10.1007/s11002-012-9180-7
   Bode NWF, 2015, SCI REP-UK, V5, DOI 10.1038/srep15896
   British Standards, 2013, 583912013 BS
   Carattin E, 2016, 14 INT C EXH FIR SCI
   Juan MC, 2009, PRESENCE-VIRTUAL AUG, V18, P232, DOI 10.1162/pres.18.3.232
   Cepeda-Mayorga I. A., 2017, STUDENTS4CHANGE INIC
   Cosma G, 2016, J TRANSP SAF SECUR, V8, P101, DOI 10.1080/19439962.2015.1046621
   Duarte E, 2014, APPL ERGON, V45, P1367, DOI 10.1016/j.apergo.2013.10.004
   Galea E., 2010, P 12 INT FIRE SCI EN, V1, P879
   Hartson HR, 2003, BEHAV INFORM TECHNOL, V22, P315, DOI 10.1080/01449290310001592587
   Joo J, 2013, SIMUL MODEL PRACT TH, V32, P99, DOI 10.1016/j.simpat.2012.12.007
   Kinateder M., 2013, THESIS
   Kinateder M, 2019, APPL ERGON, V75, P155, DOI 10.1016/j.apergo.2018.08.010
   Kinateder M, 2014, ACSIS-ANN COMPUT SCI, V2, P313
   Kinateder M, 2014, TRANSPORT RES F-TRAF, V26, P116, DOI 10.1016/j.trf.2014.06.003
   Kobes M, 2010, BUILD ENVIRON, V45, P537, DOI 10.1016/j.buildenv.2009.07.004
   Krijn M, 2004, BEHAV RES THER, V42, P229, DOI 10.1016/S0005-7967(03)00139-6
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Li CY, 2017, IEEE T VIS COMPUT GR, V23, P1388, DOI 10.1109/TVCG.2017.2656958
   Lovreglio R, 2017, P LEAN COMP CONSTR C
   Lovreglio R, 2018, ADV ENG INFORM, V38, P670, DOI 10.1016/j.aei.2018.08.018
   Lovreglio R, 2015, PHYSICA A, V438, P308, DOI 10.1016/j.physa.2015.06.040
   McMahan A., 2003, The video game theory reader, DOI DOI 10.4324/9780203700457
   Mühlberger A, 2007, PSYCHOL ASSESSMENT, V19, P340, DOI 10.1037/1040-3590.19.3.340
   Nilsson D., 2005, FIRE SAFETY SCI, V8, P569, DOI [10.3801/iafss.fss.8-569, DOI 10.3801/IAFSS.FSS.8-569]
   Nilsson D., 2009, Exit choice in fire emergencies - Influencing choice of exit with flashing lights
   Nilsson D, 2018, FIRE SAFETY J, V97, P119, DOI 10.1016/j.firesaf.2017.07.001
   Olander J, 2017, APPL ERGON, V59, P84, DOI 10.1016/j.apergo.2016.08.029
   Ronchi E, 2015, 3180 LUND U DEP FIR
   Ronchi E, 2018, FIRE SAFETY J, V97, P126, DOI 10.1016/j.firesaf.2017.06.002
   Ronchi E, 2016, FIRE TECHNOL, V52, P623, DOI 10.1007/s10694-015-0462-5
   Ruggiero L, 2018, APPL MATH MODEL, V62, P499, DOI 10.1016/j.apm.2018.06.014
   Shaw R.E., 1977, PERCEIVING ACTING KN
   Troncoso J, 2015, HUM BEH FIR S 2015 S
   Wagoum AUK, 2012, COMPUT ANIMAT VIRT W, V23, P3, DOI 10.1002/cav.1420
   Wallergård M, 2007, PRESENCE-VIRTUAL AUG, V16, P16, DOI 10.1162/pres.16.1.16
   WARREN WH, 1984, J EXP PSYCHOL HUMAN, V10, P683, DOI 10.1037/0096-1523.10.5.683
   [No title captured]
NR 43
TC 31
Z9 32
U1 8
U2 45
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2019
VL 30
IS 6
AR e1873
DI 10.1002/cav.1873
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA KD5NX
UT WOS:000507913800001
DA 2024-07-18
ER

PT J
AU Zhao, X
   Su, ZQ
   Yang, XY
AF Zhao, Xi
   Su, Zhenqiang
   Yang, Xinyu
TI Building hierarchical structures for 3D scenes based on normalized cut
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE hierarchical structure; normalized cut; scene analysis; segmentation
AB The growing number of 3D scene data available online brings in new challenges for scene retrieval, understanding, and synthesis. Traditional shape processing methods have difficulty to manage 3D scenes because such methods ignore the contextual information, that is, the spatial relationship between the objects or groups of objects, which plays a significant role in describing scenes. Therefore, a context-aware representation is needed to deal with such a problem. In this paper, we propose a method to build scene hierarchies based on contextual information. Given a 3D scene, we first use the interaction bisector surface to measure the affinity between different objects/elements of the scene and then apply the normalized cut method to build a hierarchical structure for the whole scene. The resulting hierarchical structure contains not only the relationship between the individual objects but also the relationship between object groups, which provides much richer information of the scene compared with a flat structure that only describes the contacts or affinity between the individual objects. We test our method using several public databases and show that the resulting structure is more consistent with the ground truth. We also show that our method can be used for point cloud segmentation and outperforms previous methods.
C1 [Zhao, Xi; Su, Zhenqiang; Yang, Xinyu] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 West Xianning Rd, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Yang, XY (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 West Xianning Rd, Xian 710049, Shaanxi, Peoples R China.
EM xyyang@mail.xjtu.edu.cn
FU China Postdoctoral Science Foundation [2015M582664]; National Natural
   Science Foundation of China [61602366]
FX China Postdoctoral Science Foundation, Grant/Award Number: 2015M582664;
   National Natural Science Foundation of China, Grant/Award Number:
   61602366
CR [Anonymous], 2013, ACM T GRAPHIC, DOI DOI 10.1145/2461912.2461968
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Firman M, 2016, IEEE COMPUT SOC CONF, P661, DOI 10.1109/CVPRW.2016.88
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Fisher M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964929
   Fisher M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866204
   Gal R, 2009, SIGGRAPH 09 ACM SIGG
   Golovinskiy A, 2009, PAPER PRESENTED AT 2
   Hu R, 2015, ACM T GRAPHIC, P34
   Hua Binh -Son, 2016, 2016 4 INT C 3D VIS, P92
   Huang FC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766922
   Hueting M, 2014, PAPER PRESENTED AT S
   Jain A, 2012, COMPUT GRAPH FORUM, V31, P631, DOI 10.1111/j.1467-8659.2012.03042.x
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2077341.2077342, 10.1145/2185520.2185551]
   Kraevoy V, 2007, VIS COMPUT J
   Lai K, 2014, PAPER PRESENTED AT I
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Liu TQ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661243
   MacDonald D, 2006, 3 CAN C COMP ROB VIS
   Mitra N, 2013, SA 13 SIGGRAPH AS 20
   Paraboschi L, 2007, EUR IT CHAPT C TRENT
   RABBANI T., 2006, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V36, P248
   Shen CH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366199
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Trimble Navigation Ltd, 2006, 3D WAR
   van Kaick O, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461924
   Wang Y, 2011, COMPUT GRAPH FORUM, V30, P287, DOI 10.1111/j.1467-8659.2011.01885.x
   Xu K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185553
   Xu K, 2014, IEEE IPCCC, DOI 10.1109/PCCC.2014.7017103
   Yang Sheng, 2017, [Computational Visual Media, 计算可视媒体], V3, P131
   Yeh YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185552
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Yuan Liang, 2018, Computational Visual Media, V4, P123, DOI 10.1007/s41095-018-0110-3
   Zhao X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2574860
   Zheng YY, 2013, COMPUT GRAPH FORUM, V32, P195, DOI 10.1111/cgf.12039
NR 35
TC 0
Z9 0
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2019
VL 30
IS 5
AR e1869
DI 10.1002/cav.1869
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JD7JT
UT WOS:000490157800002
DA 2024-07-18
ER

PT J
AU Cao, W
   Yang, ZX
   Ren, XH
   Lyu, L
   Zhang, B
   Zhang, YC
   Wu, EH
AF Cao, Wei
   Yang, Zhixin
   Ren, Xiaohua
   Lyu, Luan
   Zhang, Bob
   Zhang, Yanci
   Wu, Enhua
TI An improved solution for deformation simulation of nonorthotropic
   geometric models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deformation simulation; finite element method; nonorthotropic
   constitutive model; physically based animation
ID TIME SUBSPACE INTEGRATION; ELEMENT
AB Physically based deformation simulation has been studied for many years in computer graphics. In order to simulate more complex geometric models and better meet the designer's requirements, many anisotropic approaches have been proposed in recent years. However, most of the approaches focus on simulating orthotropic models. In comparison with orthotropic models, nonorthotropic ones allow the objects to have anisotropic behaviors along nonorthogonal directions. In this paper, we introduce an improved approach to simulate nonorthotropic geometric models under large deformation. The improvements are mainly twofold. First, a frame field is specified on a given undeformed object, that is, each point of the object is equipped with a frame. In each local frame, we construct three independent vectors and form a nonorthogonal coordinate. Second, we design the deformation properties along each axis in the local nonorthogonal coordinate to get a local constitutive model. The final nonorthotropic model is generated by transforming the designed model from local nonorthogonal coordinates to the global standard Cartesian coordinate. To improve the stability, we introduce a time-varying method to simultaneously track the local coordinates reorientation by pushing forward the original frame field to the deformed frame field. Experiments show that the deformation simulation using the designed nonorthotropic models exhibits anisotropic behaviors along different directions and are more stable than previous methods.
C1 [Cao, Wei; Yang, Zhixin; Ren, Xiaohua; Lyu, Luan; Zhang, Bob; Wu, Enhua] Univ Macau, FST, Macau, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Wu, Enhua] Univ CAS, Beijing, Peoples R China.
   [Yang, Zhixin; Lyu, Luan] Univ Macau, Fac Sci & Technol, State Key Lab Internet Things Smart City, Macau, Peoples R China.
   [Zhang, Yanci] Sichuan Univ, Coll Comp Sci, Chengdu, Sichuan, Peoples R China.
   [Wu, Enhua] ZhuhaiUM Sci & Technol Res Inst, Zhuhai 519020, Peoples R China.
   [Wu, Enhua] Univ Macau, Fac Sci & Technol, E11 Ave Univ, Macau, Peoples R China.
C3 University of Macau; Chinese Academy of Sciences; Institute of Software,
   CAS; University of Macau; Sichuan University; University of Macau
RP Wu, EH (corresponding author), Univ Macau, FST, Macau, Peoples R China.
EM ehwu@umac.mo
RI Zhang, Bob/HIR-3656-2022; Zhang, Bob/ABD-5926-2021; Yang,
   Zhi-Xin/AAV-1335-2020
OI Zhang, Bob/0000-0001-6512-0474; Zhang, Bob/0000-0003-2497-9519; Yang,
   Zhi-Xin/0000-0001-9151-7758; Cao, Wei/0000-0002-9921-2227; Ren,
   Xiaohua/0000-0002-3196-9880
FU Macau Science and Technology Development Fund [068/2015/A2,
   015/2015/AMJ, 121/2016/A3, 194.2017]; NSFC [61672502, 61632003,
   61472261]; University of Macau [MYRG2018-00248-FST]
FX Macau Science and Technology Development Fund, Grant/Award Number:
   068/2015/A2, 015/2015/AMJ, 121/2016/A3, and 194.2017. A3; NSFC,
   Grant/Award Number: 61672502, 61632003, and 61472261; University of
   Macau, Grant/Award Number: MYRG2018-00248-FST
CR An SS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409118
   [Anonymous], 2005, ACMEUROGRAPHICS S CO
   [Anonymous], 2004, P 2004 ACM SIGGRAPH, DOI DOI 10.1145/1028523.1028541
   Barbic J, 2005, ACM T GRAPHIC, V24, P982, DOI 10.1145/1073204.1073300
   Bower A.F., 2009, APPL MECH SOLIDS
   Cai JP, 2017, VISUAL COMPUT, V33, P1307, DOI 10.1007/s00371-016-1221-4
   Chaves E.W., 2013, Notes on continuum mechanics
   Chen H, 2007, COMPUT ANIMAT VIRT W, V18, P339, DOI 10.1002/cav.194
   Clyde D, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099577
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275044
   Garg A, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P91
   Hecht F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231821
   Hernandez F, 2013, P C ESP INF GRAF BAR
   Jiang CFF, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073623
   Kharevych L, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1531326.1531357, 10.1145/15313261531357]
   Li L, 2018, COMPUT GRAPH FORUM, V37, P313, DOI 10.1111/cgf.13570
   Li YJ, 2015, IEEE T VIS COMPUT GR, V21, P1129, DOI 10.1109/TVCG.2015.2448105
   Liao SH, 2007, COMPUT METH PROG BIO, V88, P197, DOI 10.1016/j.cmpb.2007.09.009
   Liu N., 2012, P GRAPHICS INTERFACE, P193
   Liu TT, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2990496
   Martin S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964967
   McAdams A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964932
   Müller M, 2004, PROC GRAPH INTERF, P239
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   Peng XQ, 2005, COMPOS PART A-APPL S, V36, P859, DOI 10.1016/j.compositesa.2004.08.008
   Ram D., 2015, P 14 ACM SIGGRAPHEUR, P157, DOI DOI 10.1145/2786784.2786798
   Rohrle O, 2007, J BIOMECH, V40, P3363, DOI 10.1016/j.jbiomech.2007.05.011
   Si H, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2629697
   Sin FS, 2013, COMPUT GRAPH FORUM, V32, P36, DOI 10.1111/j.1467-8659.2012.03230.x
   Stomakhin Alexey., 2012, Proc. Symp. Comp. Anim, P25
   Talbot H, 2013, INTERFACE FOCUS, V3, DOI 10.1098/rsfs.2012.0091
   Taylor ZA, 2009, MED IMAGE ANAL, V13, P234, DOI 10.1016/j.media.2008.10.001
   ten Thije RHW, 2007, COMPUT METHOD APPL M, V196, P3141, DOI 10.1016/j.cma.2007.02.010
   Terzopoulos D., 1988, Computer Graphics, V22, P269, DOI 10.1145/378456.378522
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Thomaszewski B, 2009, COMPUT GRAPH FORUM, V28, P569, DOI 10.1111/j.1467-8659.2009.01397.x
   Wang HM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964966
   Wu W, 2004, COMPUT ANIMAT VIRT W, V15, P219, DOI 10.1002/cav.24
   Xu HY, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925916
   Xu HY, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766917
   Xu HY, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2699648
   Xu LY, 2018, COMPUT GRAPH FORUM, V37, P121, DOI 10.1111/cgf.13553
   Xu TC, 2014, COMPUT ANIMAT VIRT W, V25, P185, DOI 10.1002/cav.1545
   Yan GW, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275021
   Zhang WJ, 2015, COMPUT GRAPH FORUM, V34, P395, DOI 10.1111/cgf.12569
NR 45
TC 2
Z9 3
U1 0
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2020
VL 31
IS 1
AR e1915
DI 10.1002/cav.1915
EA AUG 2019
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KR0SC
UT WOS:000481537800001
OA Bronze
DA 2024-07-18
ER

PT J
AU Chen, Q
   Luo, GL
   Tong, Y
   Jin, XG
   Deng, ZG
AF Chen, Qiang
   Luo, Guoliang
   Tong, Yang
   Jin, Xiaogang
   Deng, Zhigang
TI Shape-constrained flying insects animation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2019
CL Paris, FRANCE
SP ACM Intelligent Virtual Agents, Ctr Natl Rech Sci, Sorbonne Univ, ACM SIGGRAPH
DE curl-noise; distance force; flying insects; multi-agent;
   shape-constrained
AB During the past decades, high-fidelity realistic simulations of various flying insects exhibiting collective behavior have been broadly used in entertainment industries and virtual reality applications. However, due to the intrinsic complexity and high computational cost, shape constrained simulation of collective behaviors remains a challenging topic. In this paper, we present a robust multi-agent model for large-scale controllable shape constrained simulation of flying insects. Specifically, we design an internal force model to biologically mimic an individual insect. We also propose an external force model based on a trade-off mechanic to guide the insects smoothly deforming into a target shape. Our experimental results and comparative studies show our method is able to simulate realistic and dynamic flying insects with various user-specified shape constraints.
C1 [Chen, Qiang; Luo, Guoliang; Tong, Yang] East China Jiaotong Univ, VR & Interact Tech Inst, Nanchang, Jiangxi, Peoples R China.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Nanchang, Jiangxi, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 East China Jiaotong University; Zhejiang University; University of
   Houston System; University of Houston
RP Deng, ZG (corresponding author), Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.; Luo, GL (corresponding author), East China Jiaotong Univ, Virtual Real & Interact Tech Inst, Nanchang, Jiangxi, Peoples R China.
EM luoguoliang@ecjtu.edu.cn; zdeng4@uh.edu
OI Jin, Xiaogang/0000-0001-7339-2920; Deng, Zhigang/0000-0002-0452-8676;
   Deng, Zhigang/0000-0003-2571-5865; Chen, Qiang/0000-0002-3642-8119
FU National Natural Science Foundation of China [61602222, 61732015];
   Natural Science Foundation of Jiangxi Province [20171BAB212011]; Key
   Research and Development Program of Zhejiang Province [2018C01090]; Key
   Research and Development Program of Jiangxi Province [2018BBE50024];
   Innovation Fund Designated for Graduate Students of Jiangxi Province
   [YC2018-B072]
FX National Natural Science Foundation of China, Grant/Award Number:
   61602222 and 61732015; Natural Science Foundation of Jiangxi Province,
   Grant/Award Number: 20171BAB212011; Key Research and Development Program
   of Zhejiang Province, Grant/Award Number: 2018C01090; Key Research and
   Development Program of Jiangxi Province, Grant/Award Number:
   2018BBE50024; Innovation Fund Designated for Graduate Students of
   Jiangxi Province, Grant/Award Number: YC2018-B072
CR [Anonymous], 2004, PROC EUROGRAPHICS S, DOI DOI 10.2312/SPBG/SPBG04/049-056
   [Anonymous], ACM T GRAPH
   Behley J, 2015, IEEE INT CONF ROBOT, P3625, DOI 10.1109/ICRA.2015.7139702
   Bridson R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276435, 10.1145/1239451.1239497]
   Couzin ID, 2002, J THEOR BIOL, V218, P1, DOI 10.1006/jtbi.2002.3065
   Demsar J, 2014, ARTIF LIFE, V20, P343, DOI 10.1162/ARTL_a_00135
   Dudley R, 2002, BIOTROPICA, V34, P452, DOI 10.1111/j.1744-7429.2002.tb00560.x
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Feng G, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1781
   Gu Q., 2011, Graphics Interface 2011, P266, DOI DOI 10.5555/1992917.1992919
   Henry J, 2014, IEEE T VIS COMPUT GR, V20, P211, DOI 10.1109/TVCG.2013.116
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   Kim J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601170
   Klotsman M, 2012, ARTIF LIFE, V18, P91, DOI 10.1162/artl_a_00050
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   Lai YK, 2006, VISUAL COMPUT, V22, P604, DOI 10.1007/s00371-006-0047-x
   Madill J., 2013, PROC GRAPHICS INTERF, P125
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Peterson ST, 2003, TRANSPORT RES REC, P28
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Takahashi S, 2009, COMPUT GRAPH FORUM, V28, P639, DOI 10.1111/j.1467-8659.2009.01404.x
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   VICSEK T, 1995, PHYS REV LETT, V75, P1226, DOI 10.1103/PhysRevLett.75.1226
   Wand M, 2002, COMPUT GRAPH FORUM, V21, P483, DOI 10.1111/1467-8659.t01-1-00608
   Wang XJ, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12277
   Wang XJ, 2014, COMPUT ANIMAT VIRT W, V25, P353, DOI 10.1002/cav.1580
   Wang Xinjie, 2015, P 14 ACM SIGGRAPHEUR, P111, DOI DOI 10.1145/2786784.2786790
   Xu JY, 2008, COMPUT ANIMAT VIRT W, V19, P319, DOI 10.1002/cav.231
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Zhang P, 2015, VISUAL COMPUT, V31, P5, DOI 10.1007/s00371-013-0900-7
   Zhou JH, 2005, HT2005: PROCEEDINGS OF THE ASME SUMMER HEAT TRANSFER CONFERENCE 2005, VOL 1, P221, DOI 10.1115/HT2005-72602
NR 32
TC 10
Z9 10
U1 0
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2019
VL 30
IS 3-4
AR e1902
DI 10.1002/cav.1902
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA IF4WM
UT WOS:000473082400027
DA 2024-07-18
ER

PT J
AU Chen, H
   Wong, SK
AF Chen, Hsuan
   Wong, Sai-Keung
TI Transporting objects by multiagent cooperation in crowd simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE cooperation; cooperative tasks; crowd simulation; multiagent; pushing
   manipulation; transport objects
AB This paper focuses on simulating agents transporting passive objects in a virtual environment with pedestrians. The agents adopt the pushing manipulation patterns to transport the passive objects. We propose techniques to achieve two kinds of cooperation. First, the agents transport the passive objects to the goal positions. During the transportation process, the agents may adjust their formation to transport the passive objects effectively. Second, the agents avoid collision with each other and passive objects in an unfreezing manner. Experiment results show that our technique avoids the freezing problem while the agents are transporting multiple objects.
C1 [Chen, Hsuan; Wong, Sai-Keung] Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, H (corresponding author), Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
EM wingo.wong@gmail.com; wingo.wong@gmail.com
FU Ministry of Science and Technology of the Republic of China (ROC)
   [104-2221-E-009-051-MY3, 106-2221-E-009-161-MY2]
FX The Ministry of Science and Technology of the Republic of China (ROC),
   Grant/Award Number: 104-2221-E-009-051-MY3 and 106-2221-E-009-161-MY2
CR Alonso-Mora J, 2015, IEEE INT CONF ROBOT, P5495, DOI 10.1109/ICRA.2015.7139967
   [Anonymous], IEEE T SYST MAN CYBE
   [Anonymous], ACM SIGGRAPH S INT 3
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2016, IEEE Trans. Automat. Sci. Eng.
   Barnett A, 2016, COMPUT GRAPH FORUM, V35, P120, DOI 10.1111/cgf.12735
   Barzel R., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P183
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kamogawa Hiromasa, 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P847, DOI 10.1109/ROBIO.2011.6181393
   Karamouzas I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073705
   Karamouzas I, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.238701
   Krivic Senka, 2016, 2016 IEEE International Conference on Automation Science and Engineering (CASE), P1184, DOI 10.1109/COASE.2016.7743539
   Li QG, 2007, INT J ROBOT RES, V26, P377, DOI 10.1177/0278364907076819
   López-Nicolás G, 2015, IEEE INT C INT ROBOT, P5472, DOI 10.1109/IROS.2015.7354152
   MATARIC MJ, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P556, DOI 10.1109/IROS.1995.525940
   Meriçli T, 2015, J INTELL ROBOT SYST, V80, pS189, DOI 10.1007/s10846-015-0232-0
   Nieuwenhuisen D, 2007, IEEE T ROBOT, V23, P431, DOI 10.1109/TRO.2007.898967
   Ohashi K, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P1019, DOI 10.1109/ROBIO.2014.7090466
   Rodriguez S, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4437, DOI 10.1109/IROS.2016.7759653
   Trautman P, 2010, IEEE INT C INT ROBOT, DOI 10.1109/IROS.2010.5654369
   Tsai TY, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1765
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Vemula Anirudh, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1685, DOI 10.1109/ICRA.2017.7989199
   Wolinski D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982442
   Wong SK, 2015, COMPUT ANIMAT VIRT W, V26, P387, DOI 10.1002/cav.1636
   Wong Saikeung, 2017, [Computational Visual Media, 计算可视媒体], V3, P243
NR 26
TC 11
Z9 11
U1 2
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1826
DI 10.1002/cav.1826
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100017
DA 2024-07-18
ER

PT J
AU Chen, L
   Ye, JT
   Jiang, LG
   Ma, CC
   Cheng, ZL
   Zhang, XP
AF Chen, Lan
   Ye, Juntao
   Jiang, Liguo
   Ma, Chengcheng
   Cheng, Zhanglin
   Zhang, Xiaopeng
TI Synthesizing cloth wrinkles by CNN-based geometry image superresolution
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE cloth animation; data-driven; deep learning; geometry image; wrinkle
   synthesis
AB We propose a novel deep learning-based method, called mesh superresolution, to enrich low-resolution (LR) cloth meshes with wrinkles. A pair of low and high-resolution (HR) meshes are simulated, with the simulation of the HR mesh tracks with that of the LR mesh. The frame data are converted into geometry images and used as a training data set. A residual network, called SR residual network, is employed to train an image synthesizer that superresolves an LR image into an HR one. Once the HR image is converted back to an HR mesh, it is abundant in wrinkles compared with its coarse counterpart. The synthesizing is very efficient and is 24x faster than a full HR simulation. We demonstrate the performances of mesh superresolution with various simulation scenes.
C1 [Chen, Lan; Ye, Juntao; Jiang, Liguo; Ma, Chengcheng; Zhang, Xiaopeng] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Chen, Lan; Jiang, Liguo; Ma, Chengcheng] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Cheng, Zhanglin] Chinese Acad Sci, Shenzhen Inst Adv Technol, VisuCA Key Lab, Shenzhen, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS
RP Ye, JT (corresponding author), Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
EM juntao.ye@ia.ac.cn
RI Cheng, Zhanglin/AAP-1760-2021
OI Cheng, Zhanglin/0000-0002-3360-2679
FU China's 863 Program [2015AA016401]; NSFC [61502471, 61502490]; Chinese
   Guangdong's ST project [2017B090912001]
FX China's 863 Program, Grant/Award Number: 2015AA016401; NSFC, Grant/Award
   Number: 61502471 and 61502490; Chinese Guangdong's S&T project,
   Grant/Award Number: 2017B090912001
CR [Anonymous], ACM T GRAPH
   [Anonymous], 2016, NEURIPS
   Bergou M, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239501
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Chu MY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073643
   Dahl R, 2017, IEEE I CONF COMP VIS, P5449, DOI 10.1109/ICCV.2017.581
   De Aguiar E, 2010, ACM T GRAPH, V29
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dunyach M, 2013, EUR 2013 34 ANN C EU, P1
   Feng WW, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731049
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Guan P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185531
   Hahn Fabian, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601160
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Kavan L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964988
   Kim DY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462020
   Kim J, 2016, ARXIV151104491
   Kim T-Y, 2008, SIGGRAPH 08 ACM SIGG
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Li Y, 2015, ACM T GRAPH, V34
   Loop CT, 1987, THESIS
   Narain R., 2012, ACM T GRAPH, V31
   Nash C, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13240
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sinha A, 2017, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2017.91
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Sorkine O, 2007, S GEOM PROC, V4, P109, DOI [10.1145/1073204.1073323, DOI 10.1145/1073204.1073323]
   Su H, 2015, IEEE INT CON MULTI
   Wang H, 2010, ACM T GRAPH, V29
   Wang H, 2015, ACM T GRAPH, V34
   Wang Z., 2015, 2015 IEEE INT C COMP
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Yan XC, 2016, ADV NEUR IN, V29
   Zurdo JS, 2013, IEEE T VIS COMPUT GR, V19, P149, DOI 10.1109/TVCG.2012.79
NR 37
TC 12
Z9 15
U1 1
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1810
DI 10.1002/cav.1810
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100001
DA 2024-07-18
ER

PT J
AU Zhu, J
   Luo, Y
   Ren, XH
   Cai, RC
   Hao, ZF
   Sun, HQ
   Wu, EH
AF Zhu, Jian
   Luo, Yu
   Ren, Xiaohua
   Cai, Ruichu
   Hao, Zhifeng
   Sun, Hanqiu
   Wu, Enhua
TI Synthetic fluid details for the vorticity loss in advection
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE advection; angular kinetic energy; numerical dissipation; turbulence
   synthesis; vorticity
ID VORTEX PARTICLE METHOD
AB In this paper, a novel method with good numerical stability is proposed from the perspective of energy preserving to alleviate the numerical dissipations in the advection step of Eulerian fluid simulation. The main idea is to measure the vorticity loss during advection, calculate the lost angular kinetic energy with a proposed scheme, and then synthesize a high-frequency incompressible details field to compensate the lost energy in a way that is consistent with Kolmogorov's theory, which prevents the synthetic details from interfering with the existing fluid flow. The method works independently of the advection scheme and can be easily combined with other advection schemes to enhance the effect. It adds only 5% to 10% of the computational overhead while producing convincing fluid details without changing the overall behavior of the original flow.
C1 [Zhu, Jian; Luo, Yu; Cai, Ruichu] Guangdong Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Comp, Guangzhou, Guangdong, Peoples R China.
   [Ren, Xiaohua; Wu, Enhua] Univ Macau, Macau, Peoples R China.
   [Hao, Zhifeng] Foshan Univ, Foshan, Peoples R China.
   [Sun, Hanqiu] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
C3 Guangdong University of Technology; University of Macau; Foshan
   University; Chinese University of Hong Kong; Chinese Academy of
   Sciences; Institute of Software, CAS
RP Luo, Y (corresponding author), Guangdong Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Comp, Guangzhou, Guangdong, Peoples R China.
EM yuluo@gdut.edu.cn
RI Luo, Yu/KVC-0220-2024; cai, ruichu/AAX-7200-2021
OI luo, yu/0000-0003-3968-9725; Ren, Xiaohua/0000-0002-3196-9880; Zhu,
   Jian/0000-0002-2551-2024
FU National Natural Science Foundation of China [61502109, 61672502,
   61702112, 61402038, 61672168]; Natural Science Foundation of Guangdong
   Province [2016A030310342]; China Postdoctoral Science Foundation
   [2017M612614]; Science and Technology Planning Project of Guangdong
   Province [2015B010131015, 2017B010110015, 2017B010110007]; Macao FDCT
   [068/2015/A2]; National Key R&D National Key Research and Development
   Program of China [2017YFB1002701]
FX National Natural Science Foundation of China, Grant/Award Number:
   61502109, 61672502, 61702112, 61402038 and 61672168; Natural Science
   Foundation of Guangdong Province, Grant/Award Number: 2016A030310342;
   China Postdoctoral Science Foundation, Grant/Award Number: 2017M612614;
   Science and Technology Planning Project of Guangdong Province,
   Grant/Award Number: 2015B010131015, 2017B010110015 and 2017B010110007;
   Macao FDCT Grant, Grant/Award Number: 068/2015/A2; National Key R&D
   National Key Research and Development Program of China, Grant/Award
   Number: 2017YFB1002701
CR [Anonymous], P SIGGRAPH LOS ANG
   [Anonymous], 2008, P 2008 ACM SIGGRAPHE
   [Anonymous], ACM T GRAPH
   Bender J, 2017, SCA 17 P ACM SIGGRAP
   BRACKBILL JU, 1986, J COMPUT PHYS, V65, P314, DOI 10.1016/0021-9991(86)90211-1
   Bridson R, 2007, ACM T GRAPHIC, V26
   Chen F, 2011, COMPUT GRAPH FORUM, V30, P435, DOI 10.1111/j.1467-8659.2011.01872.x
   Chuyuan Fu, 2017, ACM Transactions on Graphics, V36, DOI 10.1145/3130800.3130878
   Cook RL, 2005, ACM T GRAPHIC, V24, P803, DOI 10.1145/1073204.1073264
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Harlow F.H., 1964, Methods Comput. Phys., V3, P319, DOI DOI 10.1007/BF00230516
   He S, 2013, COMPUT GRAPH FORUM, V32, P27, DOI 10.1111/j.1467-8659.2012.03228.x
   Huang ZP, 2015, COMPUT ANIMAT VIRT W, V26, P141, DOI 10.1002/cav.1559
   Jiang C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766996
   Kim B., 2005, P 1 EUROGRAPHICS C N, DOI DOI 10.2312/NPH/NPH05/051-056
   Kim D, 2008, COMPUT GRAPH FORUM, V27, P467, DOI 10.1111/j.1467-8659.2008.01144.x
   Kim D, 2012, IEEE T VIS COMPUT GR, V18, P1488, DOI 10.1109/TVCG.2011.264
   Kim T, 2013, ACM T GRAPHIC, V32
   Lentine Michael., 2011, Proceedings of the 2011 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '11, P91, DOI [10.1145/2019406.2019419, DOI 10.1145/2019406.2019419]
   Mercier O, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818115
   Narain R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409119
   Pfaff T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866196
   Pope S.B., 2005, Turbulent Flows
   Schechter H., 2008, Symposium on Computer animation, P1
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Thuerey N, 2013, SIGGRAPH 13 ACM SIGG
   Yoon JC, 2009, COMPUT GRAPH FORUM, V28, P1853, DOI 10.1111/j.1467-8659.2009.01563.x
   Zhang X., 2015, ACM T GRAPHIC, V34
   Zhao Y., 2010, Proceedings of the 2010 ACM SIGGRAPH/Eurographics symposium on computer animation, P75
   Zhu B, 2010, COMPUT GRAPH FORUM, V29, P2207, DOI 10.1111/j.1467-8659.2010.01809.x
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 33
TC 1
Z9 1
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1834
DI 10.1002/cav.1834
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100025
DA 2024-07-18
ER

PT J
AU Zhang, XY
   Liu, SG
AF Zhang, Xiaoyong
   Liu, Shiguang
TI Parallel SPH fluid control with dynamic details
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE fluid control; parallel computing; SPH; spring force; vorticity
ID VORTEX PARTICLE METHOD; TURBULENCE; SMOKE; WATER
AB Real-time fluid control is indispensable in computer animation, games, virtual reality, etc. In the field of Smoothed Particle Hydrodynamics (SPH) fluid control, the strategy of control force is often employed to control fluid particles; however, the artificial viscosity introduced by the control force would frequently lead to the loss of fine-scale details. Although the introduction of the low-pass filter can add back details, it may easily destroy the control target, and the control force method itself cannot make SPH fluid follow the fast-moving control target. Meanwhile, this type of method is computation intensive and time consuming. To remedy the above problems, this paper proposed a novel, interactive SPH fluid control framework with turbulent details. We run SPH fluid simulation on Compute Unified Device Architecture (CUDA) and greatly improve the efficiency of fluid control. The control particle with curvature framework was adapted in this paper. We specially designed spring forces to make the fluid match a fast-moving control target. Moreover, fine fluid details were preserved separately by calculating the fluid turbulence under control and the free fluid turbulence. This improved SPH fluid control can run in real time, which can enhance the visual quality of fluid animation as well. Our novel method can be applied in fluid animation with special control effects to guide fluid to form a target shape while greatly preserving the dynamic details of fluid. Various experiment results demonstrated the ability of our novel method.
C1 [Zhang, Xiaoyong; Liu, Shiguang] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
   [Liu, Shiguang] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300350, Peoples R China.
C3 Tianjin University; Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn
FU Natural Science Foundation of China [61672375, 61170118]
FX Natural Science Foundation of China, Grant/Award Number: 61672375 and
   61170118
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Amada T., 2004, P ACM WORKSH GEN PUR
   [Anonymous], ACM T GRAPH
   Fedkiw R, 2001, P SIGGRAPH LOS ANG C
   Foster N, 1997, COMP GRAPH INT HASS
   Green S., 2008, CUDA PARTICLES NVIDI
   Harada T, 2007, COMP GRAPH INT PETR
   He S, 2013, COMPUT GRAPH FORUM, V32, P27, DOI 10.1111/j.1467-8659.2012.03228.x
   He SF, 2011, COMPUT ANIMAT VIRT W, V22, P107, DOI 10.1002/cav.408
   Hoetzlein RC, 2014, GPU TECHN C SAN JOS
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Muller M, 2003, P ACM SIGGRAPH SAN D
   Nielsen MB, 2009, 2009 ACM SIGGRAPH EU
   Pan ZR, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3016963
   Park SI, 2005, P SCA LOS ANG CAL
   Pfaff T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866196
   Rasmussen N, 2004, 2004 ACM SIGGRAPH EU
   Satish N, 2009, IPOPS 2009 IEEE INT
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Shao X, 2013, P CAD GRAPH GUANGZH
   Shi L, 2005, P SCA LOS ANG CAL
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Solenthaler B, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964976
   Thürey N, 2009, GRAPH MODELS, V71, P221, DOI 10.1016/j.gmod.2008.12.007
   Yoon JC, 2009, COMPUT GRAPH FORUM, V28, P1853, DOI 10.1111/j.1467-8659.2009.01563.x
   Yuan Z, 2012, VISUAL COMPUT, V28, P435, DOI 10.1007/s00371-011-0626-3
   Zhang S, 2015, P 19 S INT 3D GRAPH
   Zhang XY, 2015, COMPUT ANIMAT VIRT W, V26, P357, DOI 10.1002/cav.1637
   Zhang Y, 2008, P EUR DELFT NETH
   Zhao Y, 2010, 2010 ACM SIGGRAPH EU
NR 31
TC 6
Z9 7
U1 2
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR-APR
PY 2018
VL 29
IS 2
AR e1801
DI 10.1002/cav.1801
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GD0DX
UT WOS:000430170900003
DA 2024-07-18
ER

PT J
AU Boom, BJ
   Orts-Escolano, S
   Ning, XX
   McDonagh, S
   Sandilands, P
   Fisher, RB
AF Boom, Bastiaan J.
   Orts-Escolano, Sergio
   Ning, Xin X.
   McDonagh, Steven
   Sandilands, Peter
   Fisher, Robert B.
TI Interactive light source position estimation for augmented reality with
   an RGB-D camera
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE light source estimation; augmented reality; GPU implementation; RGB-D
   camera
ID ILLUMINATION; FRAMEWORK
AB The first hybrid CPU-GPU based method for estimating a point light source position in a scene recorded by an RGB-D camera is presented. The image and depth information from the Kinect is enough to estimate a light position in a scene, which allows for the rendering of synthetic objects into a scene that appears realistic enough for augmented reality purposes. This method does not require a light probe or other physical device. To make this method suitable for augmented reality, we developed a hybrid implementation that performs light estimation in under 1 second. This is sufficient for most augmented reality scenarios because both the position of the light source and the position of the Kinect are typically fixed. The method is able to estimate the angle of the light source with an average error of 20 degrees. By rendering synthetic objects into the recorded scene, we illustrate that this accuracy is good enough for the rendered objects to look realistic. Copyright (C) 2015 John Wiley & Sons, Ltd.
C1 [Boom, Bastiaan J.; Ning, Xin X.; McDonagh, Steven; Sandilands, Peter; Fisher, Robert B.] Univ Edinburgh, Sch Informat, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.
   [Orts-Escolano, Sergio] Univ Alicante, Dept Comp Technol Computat, Alicante, Spain.
C3 University of Edinburgh; Universitat d'Alacant
RP Boom, BJ (corresponding author), Univ Edinburgh, Sch Informat, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.
EM bas.boom12@gmail.com
OI Boom, Bas/0000-0002-8344-6491; McDonagh, Steven/0000-0001-7025-5197
FU Fish4Knowledge project - European Union 7th Framework Programme [FP7];
   HiPEAC Network of Excellence; Valencian Government grant
   [BEFPI/2012/056]; EPSRC [EP/P504902/1, EP/H012338/1]; EPSRC
   [EP/H012338/1] Funding Source: UKRI
FX This work is partially supported by the Fish4Knowledge project, which is
   funded by the European Union 7th Framework Programme [FP7/2007-2013], by
   the HiPEAC Network of Excellence, by the Valencian Government grant
   BEFPI/2012/056 and by EPSRC (EP/P504902/1, EP/H012338/1)
CR Agusanto K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P208, DOI 10.1109/ISMAR.2003.1240704
   [Anonymous], 2005, EUROPEAN C VISUAL ME
   [Anonymous], 2008, WORKSH MULT MULT SEN
   [Anonymous], P BMVC
   [Anonymous], 2008, NVIDIA CUDA Programming Guide
   Barron JT, 2013, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2013.10
   Breckon TP, 2004, LECT NOTES COMPUT SC, V3211, P680
   Chen QF, 2013, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2013.37
   Costa AC, 1999, SPRING EUROGRAP, P317
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Foley J.D., 1990, Computer graphics: Principles and practice
   Gibson S, 2001, COMPUT GRAPH FORUM, V20, pC203, DOI 10.1111/1467-8659.00513
   Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224
   Hara K, 2005, IEEE T PATTERN ANAL, V27, P493, DOI 10.1109/TPAMI.2005.82
   Heymann S, 2005, INT WORKSH IM AN MUL, P1
   Holz D, 2013, ADV INTELL SYST, V194, P61
   Hordley SD, 2006, COLOR RES APPL, V31, P303, DOI 10.1002/col.20226
   Izadi S, 2011, SIGGRAPH 11
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Konolige K., 2012, TECHNICAL DESCRIPTIO
   Lalonde JF, 2012, INT J COMPUT VISION, V98, P123, DOI 10.1007/s11263-011-0501-8
   Li YZ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1366, DOI 10.1109/ICCV.2003.1238649
   Liu YL, 2012, IEEE T VIS COMPUT GR, V18, P573, DOI 10.1109/TVCG.2012.53
   Liu YL, 2010, COMPUT ANIMAT VIRT W, V21, P321, DOI 10.1002/cav.357
   Liu YL, 2009, VISUAL COMPUT, V25, P637, DOI 10.1007/s00371-009-0342-4
   Lopez-Moreno J, 2010, P 7 S APPL PERC GRAP
   Lopez-Moreno J, 2010, COMPUT GRAPH-UK, V34, P698, DOI 10.1016/j.cag.2010.08.004
   Loscos C, 1999, SPRING EUROGRAP, P329
   Loscos C, 2000, IEEE T VIS COMPUT GR, V6, P289, DOI 10.1109/2945.895874
   Madsen, 2010, Augmented Reality, P15
   Madsen CB, 2008, GRAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P255
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Neumann D., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1161, DOI 10.1109/ICCVW.2011.6130381
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Panagopoulos A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130334
   Patow G, 2003, COMPUT GRAPH FORUM, V22, P663, DOI 10.1111/j.1467-8659.2003.00716.x
   Poulin P., 1997, Proceedings. Computer Graphics International (Cat. No.97TB100104), P56, DOI 10.1109/CGI.1997.601272
   Poulin Pierre., 1992, Proc. of I3D, P31, DOI DOI 10.1145/147156.147160
   RABBANI T., 2006, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V36, P248
   Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271
   Sato I, 2003, IEEE T PATTERN ANAL, V25, P290, DOI 10.1109/TPAMI.2003.1182093
   Sato I, 1999, IEEE COMP SOC C COMP, V1, P290
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang Y, 2003, GRAPH MODELS, V65, P185, DOI 10.1016/S1524-0703(03)00043-2
   Wang Y, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P38, DOI 10.1109/PCCGA.2002.1167837
   Wassenberg J, 2009, LECT NOTES COMPUT SC, V5702, P1003, DOI 10.1007/978-3-642-03767-2_122
   WIKI, 2014, MENT RAY REND IM VIS
   Yu LF, 2013, PROC CVPR IEEE, P1415, DOI 10.1109/CVPR.2013.186
   Zhan Q., 2009, Laser scanning, V38, P155
   Zhou W, 2004, INT C PATT RECOG, P214, DOI 10.1109/ICPR.2004.1334506
   Zhou W, 2008, IMAGE VISION COMPUT, V26, P415, DOI 10.1016/j.imavis.2006.12.003
NR 53
TC 8
Z9 8
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2017
VL 28
IS 1
AR e1686
DI 10.1002/cav.1686
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM0DZ
UT WOS:000394990300003
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Choi, MG
   Lee, KH
AF Choi, Myung Geol
   Lee, Kang Hoon
TI Points-based user interface for character posing
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE user interface; character animation; motion capture data; posing
AB We present a points-based user interface for character posing. In our method, users insert a number of three-dimensional (3D) points in a virtual environment. The system performs a linear search of a motion capture database for the best matched pose and then places the pose immediately in the virtual environment to be overlapped with the input points. For a fast and precise distance computation between the input points and the example poses from the database, we developed a closed-form solution of the 3D points registration problem. To demonstrate the easiness and usability of our approach, we built a motion database including various kinds of human motion and conducted a user study of character posing tasks with non-expert users. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Choi, Myung Geol] Catholic Univ Korea, Dept Media Technol & Contents Technol, Bucheon, South Korea.
   [Lee, Kang Hoon] Kwangwoon Univ, Dept Comp Sci, Seoul, South Korea.
C3 Catholic University of Korea; Kwangwoon University
RP Lee, KH (corresponding author), Kwangwoon Univ, Seoul, South Korea.
EM kang@kw.ac.kr
CR [Anonymous], KIN
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Choi MG, 2012, COMPUT GRAPH FORUM, V31, P2057, DOI 10.1111/j.1467-8659.2012.03198.x
   Davis J., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P320
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Guay M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508397
   Jain Eakta., 2009, Proceedings of SCA 2009, P93, DOI DOI 10.1145/1599470.1599483
   Kang CG, 2014, COMPUT GRAPH FORUM, V33, P1, DOI 10.1111/cgf.12468
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lee J, 1999, COMP GRAPH, P39
   Lin JC, 2012, IEEE T VIS COMPUT GR, V18, P1979, DOI 10.1109/TVCG.2012.61
   Mao C., 2005, EUR WORKSH SKETCH BA, P175
   Nara Yuto, 2013, P VIRT REAL INT C LA
   Numaguchi Naoki, 2011, P 2011 ACM SIGGRAPH, P157
   Pan J, 2011, T EDUTAINMENT, P164
   Park JP, 2011, COMPUT GRAPH FORUM, V30, P2183, DOI 10.1111/j.1467-8659.2011.01968.x
   Thorne Matthew., 2007, ACM SIGGRAPH 2007 courses, P24
   Wei XLK, 2011, IEEE COMPUT GRAPH, V31, P78, DOI 10.1109/MCG.2009.132
   Wu XM, 2011, IEEE COMPUT GRAPH, V31, P69, DOI 10.1109/MCG.2009.111
   Yoo I, 2014, VISUAL COMPUT, V30, P213, DOI 10.1007/s00371-013-0797-1
   Yoshizaki W, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P637
NR 21
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 213
EP 220
DI 10.1002/cav.1693
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300005
DA 2024-07-18
ER

PT J
AU Zhou, YF
   Zhang, CM
   Bo, PB
AF Zhou, Yuanfeng
   Zhang, Caiming
   Bo, Pengbo
TI Efficient tetrahedral mesh generation based on sampling optimization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE implicit surface; tetrahedral mesh; sampling; particle system;
   optimization
AB We present a heuristic approach to tetrahedral mesh generation for implicit closed surfaces. It consists of a surface sampling step and a volume sampling step that both work in a unified optimization framework. First, high-quality isotropic samplings as well as a triangular mesh on the surface are generated. Then uniform volume samplings are determined by optimizing the point distribution inside the closed surface domain. Finally, the tetrahedral mesh is easily obtained by constrained Delaunay triangulation. Experimental results show that the new method can generate ideal tetrahedral meshes for closed implicit surfaces efficiently that are Delaunay based. Our method has the advantage of high efficiency and nice performance at surface boundaries. Copyright (C) 2015 John Wiley & Sons, Ltd.
C1 [Zhou, Yuanfeng; Zhang, Caiming] Shandong Univ, Jinan 250100, Peoples R China.
   [Bo, Pengbo] Harbin Inst Technol, Weihai, Peoples R China.
C3 Shandong University; Harbin Institute of Technology
RP Zhou, YF (corresponding author), Shandong Univ, Jinan 250100, Peoples R China.
EM yfzhou@sdu.edu.cn
RI Zhang, Caiming/AHD-6558-2022; liu, xinyi/KFB-4466-2024
OI Zhang, Caiming/0000-0002-6365-6221; 
FU National Natural Science foundation of China [61202148, 61020106001,
   61373078]; Independent Innovation Foundation of Shandong University,
   IIFSDU [2012TB013]; scientific research foundation of Shandong province
   of Outstanding Young Scientist Award [BS2013DX041, BS2013ZZ001]
FX We thank Dong-ming Yan for the tetrahedral mesh generation programs.
   This work was supported by National Natural Science foundation of China
   (No. 61202148, No. 61020106001, and No. 61373078), Independent
   Innovation Foundation of Shandong University, IIFSDU (No. 2012TB013),
   and The scientific research foundation of Shandong province of
   Outstanding Young Scientist Award (No. BS2013DX041 and No. BS2013ZZ001).
CR Akkouche S, 2001, COMPUT GRAPH FORUM, V20, P67, DOI 10.1111/1467-8659.00479
   Alliez P, 2005, ACM T GRAPHIC, V24, P617, DOI 10.1145/1073204.1073238
   Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947
   Arya Sunil, 1998, P IEEE CGC WORKSH CO, P33
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290
   Curless B., The Stanford 3D scanning repository
   Dardenne J, 2009, VISUAL COMPUT, V25, P401, DOI 10.1007/s00371-009-0323-7
   Du Q, 2004, INT J NUMER METH ENG, V61, P1471, DOI 10.1002/nme.1120
   Du Q, 2003, INT J NUMER METH ENG, V56, P1355, DOI 10.1002/nme.616
   Labelle F, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239508
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Meyer MD, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P124, DOI 10.1109/SMI.2005.41
   Meyer M, 2007, IEEE T VIS COMPUT GR, V13, P1704, DOI 10.1109/TVCG.2007.70604
   Si H, 2005, PROCEEDINGS OF THE 14TH INTERNATIONAL MESHING ROUNDTABLE, P147, DOI 10.1007/3-540-29090-7_9
   Szeliski R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P82, DOI 10.1109/CVPR.1993.340975
   SZELISKI R, 1992, COMP GRAPH, V26, P185, DOI 10.1145/142920.134037
   Tournois J, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531381
   Turk G, 2002, ACM T GRAPHIC, V21, P855, DOI 10.1145/571647.571650
   Witkin A. P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P269, DOI 10.1145/192161.192227
   Yan DM, 2013, COMPUT AIDED DESIGN, V45, P843, DOI 10.1016/j.cad.2011.09.004
   Zhou YF, 2010, COMPUT GRAPH FORUM, V29, P2233, DOI 10.1111/j.1467-8659.2010.01812.x
NR 23
TC 2
Z9 2
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2015
VL 26
IS 6
BP 577
EP 588
DI 10.1002/cav.1628
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DB2QO
UT WOS:000368354300004
OA Bronze
DA 2024-07-18
ER

PT J
AU Kim, JH
   Kim, CH
   Lee, J
AF Kim, Jong-Hyun
   Kim, Chang-Hun
   Lee, Jung
TI A hybrid SDF for the detailed representation of liquid-solid mixed
   surfaces
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE hybrid SDF; melting fluids; particle-based fluid surface tracking
AB We propose a hybrid signed distance field (SDF) method for reconstructing the detailed surface of a model as it changes from a solid state to a liquid state. Previous particle-based fluid simulations suffer from a noisy surface problem when the particles are distributed irregularly. If a smoothing scheme is applied to reduce the problem, sharp and detailed features can be lost by over-smoothing artifacts. Our method constructs a hybrid SDF by combining level-set values from the solid and liquid parts of the object. This makes it possible to represent the detailed features and smooth surfaces of an object when both solid and liquid parts are mixed in that object. In addition, the concept of a guiding shape is proposed, which uses a coordinate-warping technique to query the level-set values quickly. The guiding shape is constructed from the object before the simulation begins and some parts of it become liquid. To track the details of the initial solid shape and preserve it, the transformation of the guiding shape is accumulated while the phase-shift is in progress. By warping the coordinates of this accumulated transformation of the guiding shape, the level-set values of the solid part can be acquired very quickly. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Kim, Jong-Hyun; Kim, Chang-Hun; Lee, Jung] Korea Univ, Graph Lab, 407B Woojung Bldg Korea Univ,Anam Dong 5 O Ga, Seoul 136713, South Korea.
C3 Korea University
RP Lee, J (corresponding author), Korea Univ, Graph Lab, 407B Woojung Bldg Korea Univ,Anam Dong 5 O Ga, Seoul 136713, South Korea.
EM airjung@gmail.com
FU Korea University; National Research Foundation of Korea (NRF) - Ministry
   of Education, Science and Technology [NRF-2013R1A1A2011602,
   2014R1A2A2A01007143]; Convergence Technology Development [S2172401]
FX This research was supported by a Korea University Grant, Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Education, Science and Technology
   (NRF-2013R1A1A2011602 and 2014R1A2A2A01007143), and Convergence
   Technology Development (S2172401).
CR Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]
   Ando R., 2011, Proceedings-SCA 2011: ACM SIGGRAPH / Eurographics Symposium on Computer Animation, P7, DOI DOI 10.1145/2019406.2019408
   Ando R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461982
   Ando R, 2012, IEEE T VIS COMPUT GR, V18, P1202, DOI 10.1109/TVCG.2012.87
   Bhatacharya Haimasree., 2011, P 2011 ACM SIGGRAPH, P17
   Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290
   Bojsen-Hansen M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461991
   Brochu T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778784
   Eden Ashley M., 2007, Proceedings Graphics Interface 2007, P51, DOI 10.1145/1268517.1268528
   Enright D, 2005, COMPUT STRUCT, V83, P479, DOI 10.1016/j.compstruc.2004.04.024
   Frisken SF, 2000, COMP GRAPH, P249, DOI 10.1145/344779.344899
   Heo N, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866198
   Iwasaki K, 2010, COMPUT GRAPH FORUM, V29, P2215, DOI 10.1111/j.1467-8659.2010.01810.x
   Lee SH, 2013, COMPUT GRAPH FORUM, V32, P419, DOI 10.1111/cgf.12062
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Muller M., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P237, DOI DOI 10.1145/1599470.1599501
   Rosenberg ID, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P35
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Wojtan C., 2010, ACM T GRAPHIC, V29
   Wojtan C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531382
   Yu JH, 2012, COMPUT GRAPH FORUM, V31, P815, DOI 10.1111/j.1467-8659.2012.03062.x
   Yu Jihun., 2010, Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '10, P217
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
   Zwicker M, 2001, COMP GRAPH, P371, DOI 10.1145/383259.383300
NR 25
TC 2
Z9 2
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2015
VL 26
IS 5
BP 527
EP 536
DI 10.1002/cav.1663
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS5NU
UT WOS:000362125800004
DA 2024-07-18
ER

PT J
AU He, ZY
   Liang, XH
   Wang, J
   Zhao, QP
   Guo, CY
AF He, Zhiying
   Liang, Xiaohui
   Wang, Jian
   Zhao, Qinping
   Guo, Chengyu
TI Flexible editing of human motion by three-way decomposition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE style editing; content editing; manifold learning; three-way
   decomposition
ID SEPARATING STYLE
AB This paper proposes a new generative model for flexible editing of human motion. Different from previous work, three intuitive factors of motion, namely, content, identity and style, can be manipulated directly with the new model. With the new generative model, motion editing can be achieved in various aspects, including transferring an unknown style from an actor to another, synthesizing other styles for an unknown actor and generating a new motion with other content. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [He, Zhiying; Liang, Xiaohui; Wang, Jian; Zhao, Qinping; Guo, Chengyu] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University
RP Liang, XH (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM lxh@vrlab.buaa.edu.cn
OI liang, xiaohui/0000-0001-6351-2538
FU National Natural Science Foundation of China [61170186]
FX This paper is supported by the National Natural Science Foundation of
   China (Grant No. 61170186).
CR Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Elgammal A, 2004, PROC CVPR IEEE, P478
   Elgammal A, 2008, COMPUT IMAGING VIS, V36, P25
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   He XF, 2004, ADV NEUR IN, V16, P153
   Heloir A, 2006, COMPUT ANIMAT VIRT W, V17, P347, DOI 10.1002/cav.138
   Hyvärinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312
   Hyvarinen A., 2001, Adaptative and Leaming Systems for Signal Processing, Communications and Control, P1
   Ikemoto L, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477927
   Jolliffe I.T., 1986, Principal component analysis, V487
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lee CS, 2006, LECT NOTES COMPUT SC, V4069, P464
   Liu GD, 2008, COMPUT ANIMAT VIRT W, V19, P199, DOI 10.1002/cav.254
   Ma W., 2010, P ACM SIGGRAPH EUR S, P21
   Min J., 2010, P 2010 ACM SIGGRAPH, DOI [10.1145/1730804.1730811, DOI 10.1145/1730804.1730811]
   Mullen M., 2007, A composite determination of mechanical rock properties for stimulation design (what to do when you don't have a sonic log), P1
   MYERS CS, 1981, AT&T TECH J, V60, P1389, DOI 10.1002/j.1538-7305.1981.tb00272.x
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Shapiro A, 2006, PROC GRAPH INTERF, P33
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Urtasun R, 2004, COMPUT GRAPH FORUM, V23, P799, DOI 10.1111/j.1467-8659.2004.00809.x
   van Basten Ben JH, 2009, P 4 INT C FDN DIGITA, P199
   van Welbergen H, 2010, COMPUT GRAPH FORUM, V29, P2530, DOI 10.1111/j.1467-8659.2010.01822.x
   Vasilescu M.A. O., 2002, Proc. ECCV, P447
   Xiang Jian, 2008, Journal of Zhejiang University, V42, P2049, DOI 10.3785/j.issn.1008-973X.2008.12.003
NR 30
TC 2
Z9 2
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2014
VL 25
IS 1
BP 57
EP 68
DI 10.1002/cav.1534
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AA4LQ
UT WOS:000331067500006
DA 2024-07-18
ER

PT J
AU Chen, YD
   Hao, CY
   Cai, ZM
   Wu, W
   Wu, EH
AF Chen, Yadang
   Hao, Chuanyan
   Cai, Zhongmou
   Wu, Wen
   Wu, Enhua
TI Live accurate and dense reconstruction from a handheld camera
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D reconstruction; real-time; handheld camera; depth maps; linear; error
   clouds optimization
ID DEPTH MAPS
AB We present a method to make an accurate and dense reconstruction from the input of video captured by a free moving handheld camera in real time. By the method firstly, the positions of the camera and sparse 3D points are estimated by simultaneous localization mapping. Then the depth maps of selected reference frames are computed from corresponding camera bundles. Lastly a novel linear algorithm is also proposed to integrate all the depth maps into dense meshes partially. The main contributions of this paper are in the following points: the reference frames and corresponding camera bundles are able to be selected automatically, then accurate and smooth depth maps are generated in real time, and the depth maps are merged into a dense mesh by using a linear algorithm based on the error clouds optimization. Our algorithm is implemented on dual CPU and graphics processing unit in a parallel framework for improving the performance. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Chen, Yadang; Hao, Chuanyan; Cai, Zhongmou; Wu, Wen; Wu, Enhua] Univ Macau, Macau, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, State Key Lab Comp Sci, Beijing, Peoples R China.
C3 University of Macau; Chinese Academy of Sciences
RP Chen, YD (corresponding author), Univ Macau, Macau, Peoples R China.
EM yb17407@umac.mo
RI Liu, xuefeng/IUP-1483-2023
FU National Fundamental Research Grant 973 Program [2009CB320802, 2011CB
   302801]; NSFC [61272326]; University of Macao
FX This research is supported by National Fundamental Research Grant 973
   Program (2009CB320802, 2011CB 302801), NSFC (61272326), the Grants and
   studentship of University of Macao. Thanks are also given to Gang Sun
   from State Key Laboratory of Computer Science, Chinese Academy of
   Sciences in Beijing for his helpful discussions.
CR [Anonymous], 2007, COMP VIS 2007 ICCV 2
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Dong ZL, 2009, IEEE I CONF COMP VIS, P1538
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802
   Graber G., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P708, DOI 10.1109/ICCVW.2011.6130318
   Kang SB, 2004, INT J COMPUT VISION, V58, P139, DOI 10.1023/B:VISI.0000015917.35451.df
   Klein George, 2007, P1
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Newcombe RA, 2010, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2010.5539794
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Stühmer J, 2010, LECT NOTES COMPUT SC, V6376, P11
   Vacchetti L, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P48, DOI 10.1109/ISMAR.2004.24
   Wendel A, 2012, PROC CVPR IEEE, P1450, DOI 10.1109/CVPR.2012.6247833
   Zach C., 2008, Proc. ASP/UI Symp. Close-Range Photogrammetry, P1
   Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52
NR 21
TC 6
Z9 7
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 387
EP 397
DI 10.1002/cav.1508
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500026
OA Bronze
DA 2024-07-18
ER

PT J
AU Jung, HR
   Kim, ST
   Noh, J
   Hong, JM
AF Jung, Hwi-Ryong
   Kim, Sun-Tae
   Noh, Junyong
   Hong, Jeong-Mo
TI A heterogeneous CPUGPU parallel approach to a multigrid Poisson solver
   for incompressible fluid simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents Conference (CASA)
CY 2013
CL Istanbul, TURKEY
DE fluid simulation; multigrid method; parallel processing; wavelet
   decomposition
ID ANIMATION
AB One of the major obstacles in incompressible fluid simulations is the projection step that enforces zero divergence of the velocity field. We propose a novel heterogeneous CPUGPU parallel multigrid Poisson solver that decomposes the high-frequency components of the residual field using a wavelet decomposition and conducts an additional smoothing process on them, using the CPU, while the GPU is performing projection at the coarsest level. In example animations of smoke and turbulent flow with thermal buoyancy, this additional smoothing improves the accuracy of the parallel multigrid Poisson solver in a single multigrid cycle and reduces the number of multigrid cycles required to reach a specified accuracy. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Jung, Hwi-Ryong] Korea Adv Inst Sci & Technol, Taejon 305701, South Korea.
   [Noh, Junyong] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Taejon 305701, South Korea.
   [Kim, Sun-Tae; Hong, Jeong-Mo] Dongguk Univ, Seoul 100715, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST); Dongguk University
RP Hong, JM (corresponding author), Dongguk Univ, 30 Pildong Ro 1 Gil,26 Pildong 3, Seoul 100715, South Korea.
EM jmhong@atelierj.pro
RI Noh, Junyong/C-1663-2011
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA) in the culture technology (CT) research & development
   program; National Research Foundation (NRF) [2011-0023134]
FX This research is supported by the Ministry of Culture, Sports and
   Tourism (MCST) and Korea Creative Content Agency (KOCCA) in the culture
   technology (CT) research & development program 2012 and National
   Research Foundation (NRF) (2011-0023134).
CR [Александрова Мария Викторовна Aleksandrova M.], 2010, [Проблемы Дальнего Востока, Problemy Dal'nego Vostoka], P65
   [Anonymous], P ACM SIGGRAPH EUROG
   [Anonymous], SIGGRAPH AS 2011 SKE
   [Anonymous], 2008, P 2008 ACM SIGGRAPHE
   Bolz J, 2003, ACM T GRAPHIC, V22, P917, DOI 10.1145/882262.882364
   Bruhn A, 2006, INT J COMPUT VISION, V70, P257, DOI 10.1007/s11263-006-6616-7
   Chentanez N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P219
   Chentanez Nuttapong., 2011, ACM SIGGRAPH 2011 PA
   Chorin A. J., 1997, Journal of Computational Physics, V135, P118, DOI 10.1006/jcph.1997.5716
   Chui C. K., 1992, An Introduction to Wavelets, DOI 10.2307/2153134
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Göddeke D, 2008, INT J COMPUT SCI ENG, V4, P36, DOI 10.1504/IJCSE.2008.021111
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Goswami P., 2010, P 2010 ACM SIGGRAPHE, P55
   Hori C, 2011, COMPUT FLUIDS, V51, P174, DOI 10.1016/j.compfluid.2011.08.004
   Horvath C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531347
   Hughes CJ, 2007, CONF PROC INT SYMP C, P220, DOI 10.1145/1273440.1250690
   Jeong W.-K., 2007, P SIAM C COMP SCI EN
   Kazhdan M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360620
   Lentine M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778851
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Ni XL, 2004, ACM T GRAPHIC, V23, P613, DOI 10.1145/1015706.1015769
   Oh S, 2008, COMPUT ANIMAT VIRT W, V19, P479, DOI 10.1002/cav.255
   Otaduy MA, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P181
   Richard F, 2002, LECT NOTES COMPUT SC, V2353, P531
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Shi L, 2006, ACM T GRAPHIC, V25, P1108, DOI 10.1145/1141911.1142001
   Stam J, 1995, SPRING COMP SCI, P41
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Trottenberg U, 2000, Multigrid
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 33
TC 9
Z9 11
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 185
EP 193
DI 10.1002/cav.1498
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 145GP
UT WOS:000319003500006
DA 2024-07-18
ER

PT J
AU Ma, WC
   Wang, YH
   Fyffe, G
   Chen, BY
   Debevec, P
AF Ma, Wan-Chun
   Wang, Yi-Hua
   Fyffe, Graham
   Chen, Bing-Yu
   Debevec, Paul
TI A blendshape model that incorporates physical interaction
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY MAY 09-11, 2012
CL Singapore, SINGAPORE
DE blendshape animation; mass-spring system; shape interpolation;
   physical-plausible animation; physical-based simulation
AB The linear blendshape technique has been intensively used for computer animation and games because of its simplicity and effectiveness. However, it cannot describe rotational deformations and deformations because of self collision or scene interaction. In this paper, we present a new technique to address these two major limitations by introducing physical-based simulation to blendshapes. The proposed technique begins by constructing a massspring system for each blendshape target. Each system is initialized in its steady state by setting the rest length of each spring as the edge length of the corresponding target. To begin shape interpolation, we linearly interpolate the rest lengths of the springs according to a given interpolation factor a???[0,1]. The interpolated shape is then generated by computing the equilibrium of the massspring system with the interpolated rest lengths. Results from our technique show physically plausible deformations even in the case of large rotations between blendshape targets. In addition, the new blendshape model is able to interact with other scene elements by introducing collision detection and handling to the massspring system. Copyright (C)2012 John Wiley & Sons, Ltd.
C1 [Ma, Wan-Chun] Weta Digital, Wellington, New Zealand.
   [Chen, Bing-Yu] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Dept Informat Management, Taipei 10764, Taiwan.
   [Fyffe, Graham; Debevec, Paul] Univ So Calif, Inst Creat Technol, Playa Vista, CA USA.
   [Chen, Bing-Yu] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10764, Taiwan.
C3 National Taiwan University; University of Southern California; National
   Taiwan University
RP Ma, WC (corresponding author), Weta Digital, Wellington, New Zealand.
EM alexma98@gmail.com
RI Chen, Bing-Yu/E-7498-2016
OI Chen, Bing-Yu/0000-0003-0169-7682
FU National Science Council, Taiwan [NSC98-2221-E-002-140-MY2]
FX The authors would like to thank the reviewers for their comments and
   suggestions. We are also grateful for the help of J. P. Lewis, Sebastian
   Sylwan, and Joe Letteri at Weta Digital and Jernej Barbic at the
   University of Southern California during the preparation of this paper.
   This research was partially supported by the National Science Council,
   Taiwan under NSC98-2221-E-002-140-MY2.
CR Alexa M, 2000, P SIGGRAPH 2000, P157
   Baraff D, 1998, P SIGGRAPH 1998, P43
   Barbic J, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531359
   Baxter W, P 2008 INT S NONPH A, P59
   Bell Nathan., 2010, Cusp: Generic parallel algorithms for sparse matrix and graph computations
   Bloomenthal J, P 2002 ACM SIGGRAPH, P147
   Borshukov G, ACM SIGGRAPH 2005 CO
   Bregler C, 2002, P SIGGRAPH 2002, P399
   Chadwick JE, 1989, P SIGGRAPH 1989, P243
   Choi K-J, 2002, P SIGGRAPH 2002, P604
   Chu HK, 2009, IEEE T VIS COMPUT GR, V15, P853, DOI [10.1109/TVCG.2009.40, 10.1109/TVCG.2008-06-0082]
   Der KG, 2006, ACM T GRAPHIC, V25, P1174, DOI 10.1145/1141911.1142011
   Desbrun M, 1999, P GRAPH INT 1999, P1
   Galoppo N, P 2009 S INT 3D GRAP, P39
   Huang J, 2006, ACM T GRAPHIC, V25, P1126, DOI 10.1145/1141911.1142003
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Kilian M, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239515, 10.1145/1276377.1276457]
   Kondo R, P 2005 ACM SIGGRAPH, P127
   Lee Y, 1995, P SIGGRAPH 1995, P55
   Lewis JP, 2010, IEEE COMPUT GRAPH, V30, P42, DOI 10.1109/MCG.2010.41
   Lewis JP, 2000, P SIGGRAPH 2000, P165
   Liu A, 2003, PRESENCE-VIRTUAL AUG, V12, P599, DOI 10.1162/105474603322955905
   Miller GSP, 1988, P SIGGRAPH 1988, P169
   Nedel LP, 1998, P COMP GRAPH INT 199, P156
   Popa T, P 2006 IEEE INT C SH, P22
   Raibert MH, 1991, P SIGGRAPH 1991, P349
   Rohmer D, P 2009 ACM SIGGRAPH, P83
   Schenk O, 2007, COMPUT OPTIM APPL, V36, P321, DOI 10.1007/s10589-006-9003-y
   Schenk O, 2006, SIAM J SCI COMPUT, V28, P963, DOI 10.1137/050637649
   Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242
   Si H, P 2005 INT MESH ROUN, P147
   Teran J., P 2005 ACM SIGGRAPH, P181
   Tu X, 1994, P SIGGRAPH 1994, P43
   van den Bergen G., SOLID SOFTWARE LIB I
   Weber O, 2007, COMPUT GRAPH FORUM, V26, P265, DOI 10.1111/j.1467-8659.2007.01048.x
   Winkler T, 2010, COMPUT GRAPH FORUM, V29, P309, DOI 10.1111/j.1467-8659.2009.01600.x
   Yan HB, 2008, IEEE T VIS COMPUT GR, V14, P693, DOI 10.1109/TVCG.2008.28
   Yoshizawa S, P 2003 ACM S SOL MOD, P247
NR 38
TC 9
Z9 11
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2012
VL 23
IS 3-4
BP 235
EP 243
DI 10.1002/cav.1441
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 963GB
UT WOS:000305607100011
DA 2024-07-18
ER

PT J
AU Hu, J
   Liu, X
   Xie, Q
AF Hu, Jianping
   Liu, Xiuping
   Xie, Qi
TI Subdivision connectivity remeshing and its applications
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE subdivision connectivity remeshing; spherical parameterization; level of
   detail; progressive transmission
AB This paper presents a subdivision connectivity remeshing approach for closed genus 0 meshes. It is based on spherical parameterization and umbrella-operator smoothing. Our main contribution lies in adopting a low-distortion spherical parameterization approach to generate high-quality subdivision connectivity meshes. Besides, a simple and efficient point location method on the sphere based on the uniform partition of the rectangle is presented, which is used to find the containing triangle in the spherical mesh for each point on the sphere rapidly. Our method can generate high-quality subdivision connectivity meshes fast, which can be applied to level of detail and progressive transmission. All the application examples demonstrate that our remeshing procedure is robust and efficient. Copyright (c) 2011 John Wiley & Sons, Ltd.
C1 [Hu, Jianping; Xie, Qi] NE Dianli Univ, Sch Sci, Jilin 132012, Jilin, Peoples R China.
   [Liu, Xiuping] Dalian Univ Technol, Sch Math Sci, Dalian 116024, Peoples R China.
C3 Northeast Electric Power University; Dalian University of Technology
RP Hu, J (corresponding author), NE Dianli Univ, Sch Sci, Jilin 132012, Jilin, Peoples R China.
EM hjp307@gmail.com
RI Hu, Jianping/IWM-3698-2023
FU National Natural Science Foundation of China [60873181]; Northeast
   Dianli university [BSJXM-200912]
FX We would like to thank the anonymous reviewers for their insightful
   comments and suggestions. This work is supported by the National Natural
   Science Foundation of China (no. 60873181) and the Doctor Research
   Start-up Fund of Northeast Dianli university (no. BSJXM-200912).
CR ALLIEZ P, 2007, SHAPE ANAL STRUCTURI
   [Anonymous], 2003, Level of detail for 3D graphics
   Certain A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P91, DOI 10.1145/237170.237213
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Eck M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P173, DOI 10.1145/218380.218440
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Hormann K, 2001, COMPUT AIDED DESIGN, V33, P779, DOI 10.1016/S0010-4485(01)00094-X
   Hu JP, 2009, J ZHEJIANG UNIV-SC A, V10, P1009, DOI 10.1631/jzus.A0820728
   Kazhdan M, 2004, ALGORITHMICA, V38, P201, DOI 10.1007/s00453-003-1050-5
   KIMMEL R, 1999, P AFA C CURV SURF, P193
   Kobbelt L., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P105, DOI 10.1145/280814.280831
   Kobbelt LP, 1999, COMPUT GRAPH FORUM, V18, pC119, DOI 10.1111/1467-8659.00333
   Labsik U, 2000, COMP GEOM-THEOR APPL, V15, P25, DOI 10.1016/S0925-7721(99)00045-0
   Saba S, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P256, DOI 10.1109/SMI.2005.32
   Sander PedroV., 2002, EGRW 02, P87
   SANDS P, 2003, PRINCIPLES INT ENV L, P246
   Schroder P., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P161, DOI 10.1145/218380.218439
   Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011
   Yang L, 2008, COMPUT GRAPH FORUM, V27, P1183, DOI 10.1111/j.1467-8659.2008.01256.x
   Zayer R, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P276, DOI 10.1109/SMI.2005.17
   Zhou K, 2004, COMPUT AIDED DESIGN, V36, P363, DOI 10.1016/S0010-4485(03)00098-8
   Zorin D., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P259, DOI 10.1145/258734.258863
NR 22
TC 0
Z9 0
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2011
VL 22
IS 6
BP 519
EP 528
DI 10.1002/cav.429
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 856IA
UT WOS:000297631200005
OA Bronze
DA 2024-07-18
ER

PT J
AU Spillmann, J
   Harders, M
AF Spillmann, Jonas
   Harders, Matthias
TI Inextensible elastic rods with torsional friction based on Lagrange
   multipliers
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE deformation modeling; elastic rods; constrained Lagrangian mechanics;
   friction
ID INTERACTIVE SIMULATION; CATHETER
AB Elastic rods are thin flexible objects typically undergoing large non-linear deformations that cannot be modeled with linear methods. They are used in a number of research fields, e. g., to represent hair or ropes in animations, or catheters or needles in medical simulations.
   In this paper, we propose a deformation model for inextensible elastic rods. The method of Lagrange multipliers is employed to enforce the inextensibility of the rod, and to couple the material frames with the centerline. The resulting system is banded, allowing for an efficient linear time solution.
   We also propose a manifold projection method to incorporate the non-penetration constraints resulting from contact handling into our constrained Lagrangian mechanics (CLM) problem. We further augment the contact model by treating torsional friction. This allows to reproduce friction effects such as dynamic rolling and twisting of rods. Various examples underline the benefits and applicability of our model. Copyright (C) 2010 John Wiley & Sons, Ltd.
C1 [Spillmann, Jonas] ETH, Comp Vis Lab, Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Spillmann, J (corresponding author), ETH, Comp Vis Lab, Swiss Fed Inst Technol, Sternwartstr 7, CH-8092 Zurich, Switzerland.
EM jonas.spillmann@vision.ee.ethz.ch
FU Swiss National Science Foundation
FX This work has been performed within the frame of the Swiss National
   Center of Competence in Research on Computer Aided and Image Guided
   Medical Interventions (NCCRCO-ME) supported by the Swiss National
   Science Foundation. The authors thank Evren Samur of the LSR, EPFL for
   providing the X-ray simulation.
CR [Anonymous], REPRESENTING ATTITUD
   [Anonymous], THESIS UTRECHT U
   [Anonymous], GEOMETRICALLY EXACT
   [Anonymous], IEEE T VISUALIZATION
   [Anonymous], APPL QUATERNIONS
   [Anonymous], 1996, Nonlinear problems in elasticity
   [Anonymous], THESIS LINKOPINGS UN
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Baumgarte J., 1972, Computer Methods in Applied Mechanics and Engineering, V1, P1, DOI 10.1016/0045-7825(72)90018-7
   Bergou M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360662
   Bertails F, 2006, ACM T GRAPHIC, V25, P1180, DOI 10.1145/1141911.1142012
   Bertails F, 2009, COMPUT GRAPH FORUM, V28, P417, DOI 10.1111/j.1467-8659.2009.01381.x
   Bosman P.A.N., 2005, GENETIC EVOLUTIONARY, P125
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Chentanez N, 2009, P OFACMSIGGRAPH, P1
   Choe B., 2005, SCA 05, P153, DOI DOI 10.1145/1073368.1073389
   Dequidt J, 2008, LECT NOTES COMPUT SC, V5241, P695, DOI 10.1007/978-3-540-85988-8_83
   Duratti L., 2008, Proceedings of the 2008 ACM symposium on Virtual reality software and technology, P105, DOI DOI 10.1145/1450579.1450602
   Duriez C, 2006, Comput Aided Surg, V11, P300
   Goldenthal R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239500
   Goldstein H., 1981, CLASSICAL MECH
   Hadap S., 2006, PROC ACM SIGGRAPHEUR, P91
   Hairer E., 2002, GEOMETRIC NUMERICAL
   Kaldor JM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360664
   Lawton W, 2000, INT J SOLIDS STRUCT, V37, P3031, DOI 10.1016/S0020-7683(99)00067-0
   Lenoir J, 2006, COMPUT GRAPH-UK, V30, P416, DOI 10.1016/j.cag.2006.02.013
   Lenoir Julien., 2002, ESAIM P, V12, P102, DOI DOI 10.1051/PROC:2002017
   Nowinski WL, 2001, INTERNATIONAL WORKSHOP ON MEDICAL IMAGING AND AUGMENTED REALITY, PROCEEDINGS, P87, DOI 10.1109/MIAR.2001.930269
   Pai DK, 2002, COMPUT GRAPH FORUM, V21, P347, DOI 10.1111/1467-8659.00594
   Persson B., 2000, SLIDING FRICTIONPHYS, V2nd
   Provot X., 1997, GRAPHICS INTERFACE, P177
   Qin H, 1996, IEEE T VIS COMPUT GR, V2, P85, DOI 10.1109/2945.489389
   Rémion Y, 2000, J VISUAL COMP ANIMAT, V11, P17, DOI 10.1002/(SICI)1099-1778(200002)11:1<17::AID-VIS213>3.0.CO;2-9
   Spillmann J, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P63
   Spillmann J, 2008, COMPUT GRAPH FORUM, V27, P497, DOI 10.1111/j.1467-8659.2008.01147.x
   Wang F, 2007, P ANN INT IEEE EMBS, P1742, DOI 10.1109/IEMBS.2007.4352647
   Wang Y, 1998, Comput Aided Surg, V3, P211, DOI 10.1002/(SICI)1097-0150(1998)3:5<211::AID-IGS1>3.0.CO;2-6
   Witkin A., 1990, Computer Graphics, V24, P11, DOI 10.1145/91394.91400
   Witkin A., 2001, ACM SIGGRAPH Course Notes
   Zirui Li, 2001, Simulation & Gaming, V32, P404, DOI 10.1177/104687810103200309
NR 40
TC 14
Z9 15
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2010
VL 21
IS 6
BP 561
EP 572
DI 10.1002/cav.362
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 696EB
UT WOS:000285423600003
DA 2024-07-18
ER

PT J
AU Hu, SJ
   Fujimoto, T
   Chiba, N
AF Hu, Shaojun
   Fujimoto, Tadahiro
   Chiba, Norishige
TI Pseudo-dynamics model of a cantilever beam for animating flexible leaves
   and branches in wind field
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE cantilever beam; computer animation; leaf deformation; natural
   phenomena; fBm noise; 1/f(beta) noise
ID NATURAL SWAY FREQUENCIES; REAL-TIME ANIMATION; DAMPING RATIOS; TREES
AB We present a pseudo-dynamics model of a cantilever beam to visually simulate motions Of leaves and branches ill a Wind field by considering the influence of natural frequency (f(0)) and damping ratio (e). Our pseudo-dynamics model consists of a static equilibrium Model, Which call handle the bending of a curved beam loaded by ail arbitrary force in three-dimensions, and a dynamic motion model that describes the dynamic response of the beam subjected to turbulence. Using the static equilibrium model, we call apply it to controlling the free bending of petioles and branches. Furthermore, We extend it to a surface deformation model that call deform some flexible laminae. Based on a mass spring system, we analyze the property of dynamic response of a cantilever beam in turbulence with various combinations of f(0) and e, and we give some guidelines to determine the combination types of branches and leaves according to their shapes and stiffness. The main advantage of our techniques is that we are. able to deform curved branches and some flexible leaves dynamically by taking account of their structures. Finally, we demonstrate that our proposed method is effective by showing various motions of leaves and branches with different model parameters. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Fujimoto, Tadahiro] Iwate Univ, Dept Comp & Informat Sci, Morioka, Iwate 020, Japan.
   [Chiba, Norishige] Tohoku Univ, Dept Commun Engn, Sendai, Miyagi 980, Japan.
   [Chiba, Norishige] Sendai Natl Coll Technol, Sendai, Miyagi, Japan.
C3 Iwate University; Tohoku University
RP Hu, SJ (corresponding author), Iwate Univ, Fac Engn, 4-3-5 Ueda, Morioka, Iwate 020, Japan.
EM hushaojun@cg.cis.iwate-u.ac.jp
OI HU, Shaojun/0000-0002-4686-7633
CR [Anonymous], 1994, LIFE MOVING FLUIDS
   BISSHOPP KE, 1945, Q APPL MATH, V3, P272, DOI 10.1090/qam/13360
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   Diener J, 2009, COMPUT GRAPH FORUM, V28, P533, DOI 10.1111/j.1467-8659.2009.01393.x
   González C, 2005, INT J SOLIDS STRUCT, V42, P1537, DOI 10.1016/j.ijsolstr.2004.08.018
   Habel R, 2009, COMPUT GRAPH FORUM, V28, P523, DOI 10.1111/j.1467-8659.2009.01391.x
   Hino M., 1977, SPECTRAL ANAL
   James KR, 2006, AM J BOT, V93, P1522, DOI 10.3732/ajb.93.10.1522
   MIYAMOTO H, 1987, MAT MECH
   Moore JR, 2005, TREES-STRUCT FUNCT, V19, P363, DOI 10.1007/s00468-004-0387-y
   Moore JR, 2004, TREES-STRUCT FUNCT, V18, P195, DOI 10.1007/s00468-003-0295-6
   Niklas K. J., 1992, PLANT BIOMECHANICS E
   Ota S, 2004, VISUAL COMPUT, V20, P613, DOI 10.1007/s00371-004-0266-y
   Rao B.N., 2007, J SOUND VIBRATION, V304, P969
   Shinya M., 1992, Computer Graphics Forum, V11, pC119, DOI 10.1111/1467-8659.1130119
   Stam J, 1997, COMPUT GRAPH FORUM, V16, pC159, DOI 10.1111/1467-8659.00152
   Weber J., 1995, Proceedings of the 22Nd Annual Conference on Computer Graphics and Interactive Techniques, P119, DOI DOI 10.1145/218380.218427
NR 17
TC 5
Z9 6
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 279
EP 287
DI 10.1002/cav.309
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700021
DA 2024-07-18
ER

PT J
AU Sheng, B
   Sun, HQ
   Yang, G
   Wu, EH
AF Sheng, Bin
   Sun, Hanqiu
   Yang, Gang
   Wu, Enhua
TI Furstyling on angle-split shell textures
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE furstyling; angle-split shell textures; vector fields; interactive
   modeling
AB This paper presents a new method for modeling and rendering fur with a wide variety of furstyles. We simulate virtual fur using shell textures-a multiple layers of textured slices for its generality and efficiency. As shell textures usually suffer from the inherent Visual gal; errors due to the uniform discretization nature, We present the angle-split shell textures (ASST) approach, which classifies the shell textures into different types with different numbers of texture layers, by splitting the angle space of the viewing angles between fur orientation and view directiom Our system can render the fur With biological patterns, and utilizes vector field and scalar field on ASST to control the geometric variations of the furry shape. Users can intuitively shape the fur by applying the combing, blowing, and interpolating effects in real time. Our approach is intuitive to implement without using complex data structures, with real-time performance for dynamic fur appearances. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Sheng, Bin] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
   [Yang, Gang] Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing, Peoples R China.
   [Wu, Enhua] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
   [Wu, Enhua] Univ Macau, Taipa, Peoples R China.
C3 Chinese University of Hong Kong; Beijing Forestry University; Chinese
   Academy of Sciences; Institute of Software, CAS; University of Macau
RP Sheng, B (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
EM bsheng@cse.cuhk.edu.hk; hanqiu@cse.cuhk.edu.hk; yanggang@bjfu.edu.cn;
   ehwu@umac.mo
CR ANJYO K, 1992, P SIGGRAPH 92, P111
   [Anonymous], 2008, ACM SIGGRAPH 2008 classes
   BAKAY B, 2002, P EUR 2002 GERM, P234
   GOLDMAN D, 1997, P ACM SIGGRAPH 97, P127
   ISIDORO J, 2002, ACM SIGGRAPH 2002 AB, P273
   Kajiya J. T., 1989, Computer Graphics, V23, P271, DOI 10.1145/74334.74361
   Kim TY, 2002, ACM T GRAPHIC, V21, P620
   KIM TY, 2002, P ACM SIGGRAPH, P620
   LeBlanc A. M., 1991, Journal of Visualization and Computer Animation, V2, P92, DOI 10.1002/vis.4340020305
   LENGYEL J, 2000, EUR REND WORKSH 2000, P243
   Lengyel J., 2001, P 2001 S INTERACTIVE, P227, DOI [10.1145/364338.364407, DOI 10.1145/364338.364407]
   MAGNENATTHALMAN.N, 2002, INT WORKSH HUM MOD A, P3
   MEYER A, 1998, EUR REND WORKSH 1998, P157
   Praun E, 2000, COMP GRAPH, P465, DOI 10.1145/344779.344987
   ROSENBLUM RE, 2006, COMPUTER ANIMATION V, V2, P141
   TURK G, 1992, COMP GRAPH, V26, P55, DOI 10.1145/142920.134008
   VOLINO P., 2004, P ACM S VIRTUAL REAL, P41
   Ward K, 2007, IEEE T VIS COMPUT GR, V13, P213, DOI 10.1109/TVCG.2007.30
   WITKIN A, 1991, COMP GRAPH, V25, P299, DOI 10.1145/127719.122750
   Xu Z, 2001, IEEE COMPUT GRAPH, V21, P36, DOI 10.1109/38.920625
   Yang Gang, 2004, Journal of Computer Aided Design & Computer Graphics, V16, P1244
NR 21
TC 2
Z9 3
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 205
EP 213
DI 10.1002/cav.289
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700014
DA 2024-07-18
ER

PT J
AU Shin, SH
   Kim, CH
AF Shin, Seung-Ho
   Kim, Chang-Hun
TI Target-driven liquid animation with interfacial discontinuities
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE multi-phase fluid; controlling fluid; target-driven fluid; fluid
   animation; pressure jump; bubbly water
AB We propose a novel method of controlling a multi-phase fluid so that it flows into a target shape in a natural way. To preserve the sharp detail of the target shape, we represent it as an implicit function and construct the level-set of that function. Previous approaches add the target-driven control force as an external term, which then becomes attenuated during the velocity projection step, making the convergence process unstable and causing sharp detail to be lost from the target shape. But we calculate the force on the fluid from the pressure discontinuity at the interface between phases, and integrate the control force into the projection step so as to preserve its effect. The control force is calculated using an enhanced version of the ghost fluid method (GFM), which guarantees that the fluid flows from the source shape and converges into the target shape, while achieving a more natural animation than other approaches. Our control force is merged during the projection step avoiding the need for a post-optimization process to eliminate divergence at the liquid interface. This makes our method easy to implement using existing fluid engines and it incurs little computational overhead. Experimental results show the accuracy and robustness of this technique. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Korea Univ, Comp Graph Lab, Seoul, South Korea.
C3 Korea University
RP Kim, CH (corresponding author), Korea Univ, Comp Graph Lab, Anam-Dong,Seongbuk-Gu, Seoul, South Korea.
EM chkim@korea.ac.kr
CR Enright D, 2005, COMPUT STRUCT, V83, P479, DOI 10.1016/j.compstruc.2004.04.024
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   Fedkiw RP, 1999, J COMPUT PHYS, V152, P457, DOI 10.1006/jcph.1999.6136
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Hong JM, 2005, ACM T GRAPHIC, V24, P915, DOI 10.1145/1073204.1073283
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   Hong JM, 2003, COMPUT GRAPH FORUM, V22, P253, DOI 10.1111/1467-8659.00672
   Kang M., 2000, J SCI COMPUT, V15, P323, DOI DOI 10.1023/A:1011178417620
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Osher S, 2001, J COMPUT PHYS, V169, P463, DOI 10.1006/jcph.2000.6636
   Shi L, 2005, ACM T GRAPHIC, V24, P140, DOI 10.1145/1037957.1037965
   Shi Lin., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '05, P229, DOI DOI 10.1145/1073368.1073401
   STAM J, 1999, ACM T GRAPHICS P ACM, V18, P121
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
NR 17
TC 11
Z9 11
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 447
EP 453
DI 10.1002/cav.202
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000023
DA 2024-07-18
ER

PT J
AU Tropp, O
   Tal, A
   Shimshoni, I
AF Tropp, Oren
   Tal, Ayellet
   Shimshoni, Ilan
TI A fast triangle to triangle intersection test for collision detection
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE triangle to triangle intersection; collision detection
AB The triangle-to-triangle intersection test is a basic component of all collision detection data structures and algorithms. This paper presents a fast method for testing whether two triangles embedded in three dimensions intersect. Our technique solves the basic sets of linear equations associated with the problem and exploits the strong relations between these sets to speed up their solution. Moreover, unlike previous techniques, with very little additional cost, the exact intersection coordinates can be determined. Finally, our technique uses general principles that can be applied to similar problems such as rectangle-to-rectangle intersection tests, and generally to problems where several equation sets are strongly related. We show that our algorithm saves about 20% of the mathematical operations used by the best previous triangle-to-triangle intersection algorithm. Our experiments also show that it runs 18.9% faster than the fastest previous algorithm on average for typical scenarios of collision detection (on Pentium 4). Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.
C3 Technion Israel Institute of Technology
RP Tal, A (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.
EM ayellet@ee.technion.ac.il
CR BAREQUET G, 1996, P EUR, P387
   COHEN J, P 1995 S INT 3D GRAP, P189
   DEFLORIANI L, 1999, APPL COMPUTATIONAL G, P333
   Devillers O., 2002, RR4488 INRIA
   DOBKIN DP, 1983, THEOR COMPUT SCI, V27, P241, DOI 10.1016/0304-3975(82)90120-7
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Gottschalk S., 1998, P IMA C MATH SURF, P3
   Guigue P., 2003, Journal of Graphics Tools, V8, P25
   Held M., 1997, Journal of Graphics Tools, V2, P25, DOI 10.1080/10867651.1997.10487482
   KLOSOWSKI JT, 1995, 7 CAN C COMP GEOM, V14, P36
   Moller T., 1997, J. Graph. Tools, V2, P25, DOI [DOI 10.1080/10867651.1997.10487472, 10.1080/10867651.1997.10487472]
   SHEN H, 2003, J GRAPHICS TOOLS, V8, P3
NR 12
TC 45
Z9 59
U1 0
U2 31
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2006
VL 17
IS 5
BP 527
EP 535
DI 10.1002/cav.115
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 111UX
UT WOS:000242481700003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU García, M
   Mendoza, C
   Pastor, L
   Rodríguez, A
AF Garcia, Marcos
   Mendoza, Cesar
   Pastor, Luis
   Rodriguez, Angel
TI Optimized linear FEM for modeling deformable objects
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE real-time simulation; deformable objects; robust linear FEM
AB The main contribution of our work is a technique to accelerate the real-time simulation Of deformable objects using a stable finite element method. Our purpose is to construct a preconditioner matrix for the coefficient matrix of the implicit integration scheme based on the global rotation matrix of the object. We describe some required steps to compute all optimal preconditioner in an off-line step. Our technique call be used to accelerate the element stiffness warping method and could be used to solve the system directly for objects with small deformations or for objects that appear outside of the users' interest zone. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Univ Rey Juan Carlos, Dept Arquitectura & Tecnol Comp Ciencias Comp & I, Madrid 28933, Spain.
C3 Universidad Rey Juan Carlos
RP García, M (corresponding author), Univ Rey Juan Carlos, Dept Arquitectura & Tecnol Comp Ciencias Comp & I, C-Tullpin S-N, Madrid 28933, Spain.
EM marcos.garcia@urjc.es
RI Pastor, Luis/E-4700-2019; Rodríguez, Angel/AAT-4582-2021;
   Garcia-Lorenzo, Marcos/K-5870-2014
OI Rodríguez, Angel/0000-0002-5145-5676; Garcia-Lorenzo,
   Marcos/0000-0003-4413-4820
CR [Anonymous], EUROGRAPHICS
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bathe K.J., 1996, Finite Element Procedures
   Bro-Nielsen M., 1996, COMPUT GRAPH FORUM, P57, DOI DOI 10.1111/1467-8659.1530057
   DEBUNNE G, 2001, COMP GRAPH P ANN C S
   Desbrun M, 1999, PROC GRAPH INTERF, P1
   Etzmuss O, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P244, DOI 10.1109/PCCGA.2003.1238266
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   Liu G.R., 2002, MESH FREE METHODS
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Müller M, 2004, PROC GRAPH INTERF, P239
   Muller M., 2002, P 2002 ACM SIGGRAPHE, P49, DOI DOI 10.1145/545261.545269
   NEALEN A, 2005, EUROGRAPHICS STATE A, P71
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   PICINBONO G, 2001, P IEEE INT C ROB AUT
   Press W.H., 1993, NUMERICAL RECIPES, V1st
   Teran J, 2005, IEEE T VIS COMPUT GR, V11, P317, DOI 10.1109/TVCG.2005.42
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Waters K., 1991, Journal of Visualization and Computer Animation, V2, P123, DOI 10.1002/vis.4340020405
   WU X, 2001, EUROGRAPHICS, V20, P349
NR 20
TC 11
Z9 11
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 393
EP 402
DI 10.1002/cav.142
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400025
DA 2024-07-18
ER

PT J
AU Hu, YH
   Velho, L
   Tong, X
   Guo, BN
   Shum, H
AF Hu, YH
   Velho, L
   Tong, X
   Guo, BN
   Shum, H
TI Realistic, real-time rendering of ocean waves
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE reflectance; shading models; real-time rendering
AB In computer games and other real-time graphics applications, the ocean surface is typically modelled as a texture or bump-mapped plane with simple lighting effects. This paper describes a system for realistically rendering the water surface in real time. Our system can render calm ocean waves with sophisticated lighting effects at 100 fps on a 680 MHz Pentium III with a GeForce 3 graphics card. The wave geometry is represented view-dependently as a dynamic displacement map with surface detail described by a dynamic bump map. The illumination model includes reflection, refraction and Fresnel effects, which are critical for producing the look and feel of water. Copyright (C) 2006 John Wiley & Sons, Ltd.
C1 CNPq, Inst Matemat Pura & Aplicada, BR-22460320 Rio De Janeiro, Brazil.
RP CNPq, Inst Matemat Pura & Aplicada, Estrada Dona Castorina 110,Sala 326, BR-22460320 Rio De Janeiro, Brazil.
EM lvelho@impa.br
RI Velho, Luiz/B-6979-2008
OI Tong, Xin/0000-0001-8788-2453
CR Cabral B, 1999, COMP GRAPH, P165, DOI 10.1145/311535.311553
   Duchaineau M, 1997, VISUALIZATION '97 - PROCEEDINGS, P81, DOI 10.1109/VISUAL.1997.663860
   Fournier A., 1986, Computer Graphics, V20, P75, DOI 10.1145/15886.15894
   Heidrich W, 1999, COMP GRAPH, P171, DOI 10.1145/311535.311554
   Hinsinger D., 2002, P 2002 ACM SIGGRAPH, P161
   JENSEN L.S., 2001, Deep-water animation and rendering
   *NVIDIA COOP, 2002, REFL REFR DEM DEM NV
   Premoze S, 2001, COMPUT GRAPH FORUM, V20, P189, DOI 10.1111/1467-8659.00548
   SCHLICK C, 1994, COMPUT GRAPH FORUM, V13, pC233, DOI 10.1111/1467-8659.1330233
   SCHNEIDER J, 2001, WORKSH VIS MOD VIS
   Tessendorf Jerry., 2001, SIGGRAPH COURSE NOTE
NR 11
TC 11
Z9 16
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2006
VL 17
IS 1
BP 59
EP 67
DI 10.1002/cav.74
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 019YN
UT WOS:000235874800005
DA 2024-07-18
ER

PT J
AU Lerner, A
   Chrysanthou, Y
   Cohen-Or, D
AF Lerner, A
   Chrysanthou, Y
   Cohen-Or, D
TI Efficient cells-and-portals partitioning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE visibility computation; cells-and-portals partitioning; architectural
   walkthroughs
AB In this paper we revisit the cells-and-portals visibility methods, originally developed for the special case of architectural interiors. We define an effectiveness measure for a cells-and-portals partition, and introduce a two-pass algorithm that computes a cells-and-portals partition. The algorithm uses a simple heuristic that strives to create small portals as a means for generating an effective partition. The input to the algorithm is a set of half edges in 2D that can be extracted from a complex polygonal model. The first pass of the algorithm creates an initial partition, which is then refined by the second pass. We show that our method creates a partition that is more effective than the common BSP partition, even when the latter is further refined with the application of our second pass. Our cells-and-portals algorithm is designed to deal with arbitrarily oriented walls. The algorithm also supports outdoor scenes, where the vertical walls of the buildings serve as occluders and portals are extended above the buildings. We show that the extended portals allow an output-sensitive rendering of large urban scenes. While most visibility algorithms use graphics hardware in order to cull hidden regions of the model, we examine the usefulness of a hardware-assisted portal test as opposed to the conventional software test. Finally, since our two-pass method is fully automatic and local, it supports incremental changes of the model by locally recomputing and updating the partition. We call our method 'Breaking the Walls' since it breaks out of indoor scenes to outdoor scenes, and allows walls to be broken interactively, with an instant updating of the partition. Copyright (C) 2006 John Wiley & Sons, Ltd.
C1 Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel.
   Univ Cyprus, Dept Comp Sci, Nicosia, Cyprus.
C3 Tel Aviv University; University of Cyprus
RP Tel Aviv Univ, Sch Comp Sci, Schreiber Bldg, IL-69978 Tel Aviv, Israel.
EM alan@post.tau.ac.il
CR *ACT, 2003, RET CASTL WOLF
   Cohen-Or D., 2003, IEEE T VISUALIZATION
   *EP GAM INC, 2003, UNR DEV NETW
   *EP GAM INC, 2003, UNR 2 AW
   *EP GAM INC, 2003, UNR TOURN 2003
   LUEBKE D, 1995, 1995 S INT 3D GRAPH, P105
   TELLER S, 1992, THESIS U CALIFORNIA
   Teller SJ, 1991, COMPUTER GRAPHICS, V25, P61
NR 8
TC 5
Z9 13
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2006
VL 17
IS 1
BP 21
EP 40
DI 10.1002/cav.70
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 019YN
UT WOS:000235874800003
DA 2024-07-18
ER

PT J
AU Xiao, CX
   Zheng, WT
   Peng, QS
   Forrest, AR
AF Xiao, CX
   Zheng, WT
   Peng, QS
   Forrest, AR
TI Robust morphing of point-sampled geometry
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on Computer Animation and Social Agents
   (CASA 2004)
CY JUL 07-09, 2004
CL Univ Geneva, Geneva, SWITZERLAND
HO Univ Geneva
DE point-sampled geometry; morphing; covariance analysis; dynamic sampling
   decomposition; parameterization
ID PARAMETERIZATION; 3D
AB We propose a novel morphing algorithm for objects represented by point-sampled geometry. The fundamental problem of point-sampled geometry morphing is how to set the correspondence between points of the two objects which are usually of different size. The two objects are first parameterized by projecting the sample points onto a common parametric domain. As both objects are densely sampled, we present a novel accelerated parameterization algorithm employing the technique of LOD. The common parameter domain is then split recursively into clusters. The correspondence between sample points of the two objects is established by performing a local mapping in each cluster. As for complex geometries, the establishment Of correspondence is facilitated by decomposing the geometry into patches using geodesic decomposition curves.
   To preserve the features during morphing, a process of features assignment is incorporated. By re-sampling the in-between object dynamically and adaptively, the cracks that would occasionally occur during morphing are successfully eliminated. Experiment results show that our algorithms are fast, stable and easy to implement. High-quality morphing is produced. Copyright (C) 2004 John Wiley Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM cxxiao@cad.zju.edu.cn
CR Adams B, 2003, ACM T GRAPHIC, V22, P651, DOI 10.1145/882262.882320
   Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575
   Alexa M, 2000, VISUAL COMPUT, V16, P26, DOI 10.1007/PL00007211
   ALEXA M, 2001, P IEEE VIS 2001 SAN, P537
   CMOLIK L, POINT CLOUD MORPHING
   DeCarlo D, 1996, PROC GRAPH INTERF, P194
   Floater MS, 2001, COMPUT AIDED GEOM D, V18, P77, DOI 10.1016/S0167-8396(01)00013-9
   Gotsman C, 2003, ACM T GRAPHIC, V22, P358, DOI 10.1145/882262.882276
   GREGORY A, 1998, P COMP AN 98 PHIL
   KENT JR, 1992, COMP GRAPH, V26, P47, DOI 10.1145/142920.134007
   Lévy B, 2001, COMP GRAPH, P417, DOI 10.1145/383259.383308
   Mémoli F, 2001, J COMPUT PHYS, V173, P730, DOI 10.1006/jcph.2001.6910
   Pauly M, 2003, ACM T GRAPHIC, V22, P641, DOI 10.1145/882262.882319
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   PAULY M, 2003, P SIGGRAPH 2003 SAN
   Pfister H, 2000, COMP GRAPH, P335, DOI 10.1145/344779.344936
   Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Shapiro A, 1998, VISUAL COMPUT, V14, P429, DOI 10.1007/s003710050153
   XIAO C, UNPUB POINT BASED SU
   Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
NR 22
TC 12
Z9 20
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2004
VL 15
IS 3-4
BP 201
EP 210
DI 10.1002/cav.22
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 839OZ
UT WOS:000222795700009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, XF
   Lu, J
   Zhou, J
   Liu, W
   Zhang, KB
AF Li, Xuanfeng
   Lu, Jian
   Zhou, Jian
   Liu, Wei
   Zhang, Kaibing
TI Multi-temporal scale aggregation refinement graph convolutional network
   for skeleton-based action recognition
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE action recognition; graph convolution; skeleton data; temporal
   information
AB Skeleton-based human action recognition is gaining significant attention and finding widespread application in various fields, such as virtual reality and human-computer interaction systems. Recent studies have highlighted the effectiveness of graph convolutional network (GCN) based methods in this task, leading to a remarkable improvement in prediction accuracy. However, most GCN-based methods overlook the varying contributions of self, centripetal and centrifugal subsets. Besides, only a single-scale temporal feature is adopted, and the multi-temporal scale information is ignored. To this end, firstly, in order to differentiate the importance of different skeleton subsets, we develop a refinement graph convolution, which can adaptively learn a weight for each subset feature. Secondly, a multi-temporal scale aggregation module is proposed to extract more discriminative temporal dynamic information. Furthermore, a multi-temporal scale aggregation refinement graph convolutional network (MTSA-RGCN) is proposed, and four-stream structure is also adopted in this paper, which can comprehensively model complementary features and eventually achieves a significant performance boost. In the empirical experiments, the performance of our approach has been greatly improved on both NTU-RGB+D 60 and NTU-RGB+D 120 datasets, compared to other state-of-the-art methods.
   The overall pipeline of our proposed method. The skeleton data is first input into RGCN to obtain basic feature expressions. RGCN can learn more spatial motion information of actions. Features with different temporal resolutions are then modulated in the temporal and spatial dimensions and aggregated into features with rich discriminative temporal information for final classification.image
C1 [Li, Xuanfeng; Lu, Jian; Zhou, Jian; Liu, Wei; Zhang, Kaibing] Xian Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
C3 Xi'an Polytechnic University
RP Lu, J (corresponding author), Xian Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
EM lujian_studio@163.com
RI WANG, SHIHAO/KHC-8263-2024; Wang, Fei/KEH-6292-2024; Zhang,
   Kaibing/AFS-4658-2022; Wang, Yuhan/KGL-5855-2024
OI Li, Xuanfeng/0000-0003-4347-9851
FU This article was funded in part by the National Natural Science
   Foundation of China, China (No. 61971339 and 62101419), in part by the
   Natural Science Project of Shaanxi Provincial Department of Science and
   Technology (No. 2022JM-146), and in part by Appli [61971339, 62101419];
   National Natural Science Foundation of China, China [2022JM-146];
   Natural Science Project of Shaanxi Provincial Department of Science and
   Technology [GX2007]; Applied Technology Research and Development Project
   in Beilin District, Xiamp;apos;an City
FX This article was funded in part by the National Natural Science
   Foundation of China, China (No. 61971339 and 62101419), in part by the
   Natural Science Project of Shaanxi Provincial Department of Science and
   Technology (No. 2022JM-146), and in part by Applied Technology Research
   and Development Project in Beilin District, Xi & apos;an City (No.
   GX2007).
CR [Anonymous], 2017, arXiv
   Chen Z, 2021, AAAI CONF ARTIF INTE, V35, P1113, DOI 10.1145/3474085.3475574
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Kipf TN, 2017, INT C LEARN REPR
   Kong J, 2022, IEEE SIGNAL PROC LET, V29, P528, DOI 10.1109/LSP.2022.3142675
   Li C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P786
   Li C, 2017, IEEE INT CONF MULTI
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li FJ, 2021, IEEE SENS J, V21, P16183, DOI 10.1109/JSEN.2021.3075722
   Li J, 2022, IEEE T ENG MANAGE, V69, P1902, DOI 10.1109/TEM.2019.2940702
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li SJ, 2021, IEEE ROBOT AUTOM LET, V6, P1028, DOI 10.1109/LRA.2021.3056361
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Liang DH, 2019, IEEE COMPUT SOC CONF, P934, DOI 10.1109/CVPRW.2019.00123
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Miao SY, 2022, IEEE T CIRC SYST VID, V32, P4893, DOI 10.1109/TCSVT.2021.3124562
   Papadopoulos K, 2021, INT C PATT RECOG, P452, DOI 10.1109/ICPR48806.2021.9413189
   Peng W, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1432, DOI 10.1145/3394171.3413910
   Plizzari Chiara, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12663), P694, DOI 10.1007/978-3-030-68796-0_50
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, ADV NEUR IN, V27
   Song YF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1625, DOI 10.1145/3394171.3413802
   Song YF, 2021, IEEE T CIRC SYST VID, V31, P1915, DOI 10.1109/TCSVT.2020.3015051
   Thakkar K. C., 2018, PRAC BRIZ MACH VIS C, P270
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Xie J, 2021, NEUROCOMPUTING, V440, P230, DOI 10.1016/j.neucom.2021.02.001
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yan YC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P199, DOI 10.1145/3123266.3123277
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
NR 35
TC 0
Z9 0
U1 2
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2221
EA SEP 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN8A9
UT WOS:001070034800001
DA 2024-07-18
ER

PT J
AU Li, Q
   Wang, P
   Liu, ZX
   Wang, CS
AF Li, Qiang
   Wang, Peng
   Liu, Zexue
   Wang, Changsheng
TI How generous interface affect user experience and behavior: Evaluating
   the information display interface for museum cultural heritage
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cultural heritage; engagement; generous interface; information behavior;
   museum; usability; user experience
ID AESTHETICS
AB Museum web interfaces continue to be important in how users search for information and navigate through digital cultural heritage resources. A generous interface was deemed appropriate for displaying large amounts of digital cultural heritage. However, more example verification is required in this field of study. This study compared the traditional interface and the generous interface of the Liaoning Provincial Museum to investigate the role of a generous interface for cultural heritage collections. Forty second-year design graduate students were randomly assigned to one of two interface groups: traditional interface or generous interface. Four variables were measured to compare the differences between the two interfaces for the participants. In addition, two parameters, holding time and average retrieval time, are recorded and used to evaluate and compare the impact of the two interfaces on user behavior. The generous interface, according to the findings, is more effective than the traditional interface in increasing participants' engagement with cultural heritage and is perceived to be more aesthetically pleasing. In addition, the generous interface has been proven to be more suitable for casual leisure users to explore cultural heritage information. This research provides the basis and reference for developing the web interface of cultural heritage collections.
   This study employs an experiment design to observe user behavior and quantitative data analysis methods to investigate the experience and factors influencing users' retrieval and browsing of digital cultural heritage resources. The study compares the difference between generous and traditional interfaces on user information behavior in several dimensions of user experience, namely aesthetics, usability, user engagement, and visual comfort, and seeks to investigate the correlation between them in order to investigate the role of the generous interface of cultural heritage on user experience. Meanwhile, four representative artifacts were chosen to test the user's retrieval time under different interfaces. Finally, the results of the quantitative data analysis and the qualitative analysis of the user interviews are discussed, and conclusions are presented. This study's findings offer design hints and a theoretical basis for improving user experiences of cultural heritage web interfaces. image
C1 [Li, Qiang; Wang, Peng; Liu, Zexue] Shenyang Aerosp Univ, Dept Digital Media Art, Shenyang, Peoples R China.
   [Wang, Changsheng] Sejong Univ, Seoul, South Korea.
   [Li, Qiang] Shenyang Aerosp Univ, Dept Digital Media Art, 37 Daoyi South Ave, Shenyang 110136, Peoples R China.
C3 Shenyang Aerospace University; Sejong University; Shenyang Aerospace
   University
RP Li, Q (corresponding author), Shenyang Aerosp Univ, Dept Digital Media Art, 37 Daoyi South Ave, Shenyang 110136, Peoples R China.
EM qiangli@sau.edu.cn
RI li, qiang/GZA-3285-2022; Liu, Zexue/AAR-8161-2020
OI Liu, Zexue/0000-0002-7333-3119; Li, Qiang/0000-0002-6360-3357
FU Shenyang Philosophy and Social Science Planning Project of China
FX No Statement Available
CR Arnold T., VISUALIZING LARGE SP
   Bilda Z, 2008, DESIGN STUD, V29, P525, DOI 10.1016/j.destud.2008.07.009
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Esmeria GJ., WEB USABILITY LIT RE
   Fanini B, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS & INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION & STANDARDS DIGITAL HERITAGE PROJECTS & APPLICATIONS, P623, DOI 10.1109/DigitalHeritage.2015.7419583
   Gibson J. J., 2014, The ecological approach to visual perception, Vclassic
   Gil-Fuentetaja I, 2019, ACM J COMPUT CULT HE, V12, DOI 10.1145/3283253
   Hassenzahl M, 2010, HUM-COMPUT INTERACT, V25, P235, DOI 10.1080/07370024.2010.500139
   Hou GH, 2020, AGEING SOC, V40, P389, DOI 10.1017/S0144686X18001022
   Hung SY., 2013, J ELECTRON COMMER RE, V14, P13
   KUHLTHAU CC, 1991, J AM SOC INFORM SCI, V42, P361, DOI 10.1002/(SICI)1097-4571(199106)42:5<361::AID-ASI6>3.0.CO;2-#
   Laurel Brenda., 1990, The Art of Human-Computer Interface Design
   Lavie T, 2004, INT J HUM-COMPUT ST, V60, P269, DOI 10.1016/j.ijhcs.2003.09.002
   Li Qiang, 2022, HCI International 2022 Posters: 24th International Conference on Human-Computer Interaction, HCII 2022, Virtual Event, Proceedings. Communications in Computer and Information Science (1582), P234, DOI 10.1007/978-3-031-06391-6_31
   Li Q, 2023, IEEE T COGN DEV SYST, V15, P925, DOI 10.1109/TCDS.2022.3193576
   Li Q, 2022, DES J, V25, P1, DOI 10.1080/14606925.2021.2015162
   Light B, 2018, CONVERGENCE-US, V24, P407, DOI 10.1177/1354856516678587
   Mason M., 2020, DESIGN PRINCIPLES PR, V14, P1, DOI DOI 10.18848/1833-1874/CGP/V14I01/1-14
   Morse C, 2021, ACM J COMPUT CULT HE, V14, DOI 10.1145/3437257
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Parry R., 2013, Museum Worlds: Advances in Research, V1, P24, DOI 10.3167/armw.2013.010103
   Ruecker S., 2016, Visual interface design for digital cultural heritage
   Ruecker S., 2009, ENCY MULTIMEDIA TECH, P1240, DOI [10.4018/978-1-60566-014-1.ch168, DOI 10.4018/978-1-60566-014-1.CH168]
   Schenkman BN, 2000, BEHAV INFORM TECHNOL, V19, P367, DOI 10.1080/014492900750000063
   Speakman R, 2018, LECT NOTES COMPUT SC, V11057, P186, DOI 10.1007/978-3-030-00066-0_16
   Sundar SS, 2016, COMMUN RES, V43, P595, DOI 10.1177/0093650214534962
   Tractinsky N, 2000, INTERACT COMPUT, V13, P127, DOI 10.1016/S0953-5438(00)00031-X
   Tsai CF, 2007, ONLINE INFORM REV, V31, P185, DOI 10.1108/14684520710747220
   Whitelaw M., 2012, Comma, V2012, P123
   Whitelaw M., GENEROUS INTERFACES
   Wilson TD, 2006, J DOC, V62, P658, DOI 10.1108/00220410610714895
   Wilson T. D., 2000, Informing Science, V3, P49
   Wilson TD, 1999, J DOC, V55, P249, DOI 10.1108/EUM0000000007145
   Wu Y, 2022, SAGE OPEN, V12, DOI 10.1177/21582440221082105
NR 34
TC 0
Z9 0
U1 20
U2 23
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2024
VL 35
IS 1
DI 10.1002/cav.2212
EA AUG 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JG4S9
UT WOS:001151749400001
OA Bronze
DA 2024-07-18
ER

PT J
AU She, YY
   Wang, Q
   Liu, F
   Lin, L
   Yang, BR
   Hu, B
AF She, Yingying
   Wang, Qing
   Liu, Fang
   Lin, Lin
   Yang, Baorong
   Hu, Bin
TI An interaction design model for virtual reality mindfulness meditation
   using imagery-based transformation and positive feedback
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE emotional relief; imagery; interaction design; mindfulness meditation;
   positive feedback; VR
ID STRESS REDUCTION; MOOD; ANXIETY
AB In recent years, mindfulness meditation has become increasingly popular as a way to relieve negative emotions. Although many studies have shown the advantages of the most immersive virtual reality (VR) technologies to support mindfulness meditation, few have summarized a standardized process for developing a VR tool to aid mindfulness meditation. We propose an interaction design model for VR mindfulness meditation using imagery-based transformation and positive feedback to help users quickly soothe their negative emotions. Based on the traditional mindfulness meditation model, we propose the three detailed transformational steps to build (1) an interaction guidance process, (2) an interaction experience context, and (3) an interaction feedback mechanism. We build two scenarios based on them. Our experimental results suggest that our design can effectively alleviate a user's anxiety and provide emotional relief. Our insights on the transformation model of VR mindfulness meditation can be applied in related research, providing an effective reference model for VR mindfulness meditation systems, while providing new ideas for non-pharmacological interventions in psychotherapy.
C1 [She, Yingying; Wang, Qing; Liu, Fang] Xiamen Univ, Sch Film, Xiamen, Peoples R China.
   [She, Yingying] Xiamen Univ, Natl Inst Data Sci Hlth & Med, Xiamen, Peoples R China.
   [Lin, Lin] Xiamen Univ, Inst Creat & Innovat, Xiamen, Peoples R China.
   [Yang, Baorong] Jimei Univ, Coll Comp Engn, Xiamen, Peoples R China.
   [Hu, Bin] Beijing Inst Technol, Sch Med Technol, Beijing, Peoples R China.
C3 Xiamen University; Xiamen University; Xiamen University; Jimei
   University; Beijing Institute of Technology
RP Lin, L (corresponding author), Xiamen Univ, Inst Creat & Innovat, Xiamen, Peoples R China.; Yang, BR (corresponding author), Jimei Univ, Coll Comp Engn, Xiamen, Peoples R China.
EM Linlinxiamen@xmu.edu.cn; yangbaorong@jmu.edu.cn
RI Chen, Fang/JZE-4446-2024; WU, SHAN/KGM-5484-2024; wang,
   yi/KBB-3614-2024; ren, jing/JXN-8411-2024; Zhang, Ge/KGL-7634-2024;
   Zhang, Wenli/JXL-4317-2024; zhang, jingxing/KCY-4726-2024
OI She, Yingying/0000-0002-6770-4622
FU Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University [VRLAB2020B16]; Fujian
   Science and Technology Program Guiding Project [2020H0001]; Fujian
   Provincial Department of Education [JAT200286]; Natural Science
   Foundation of Fujian Province [2021J05170]; Scientific Research Start-up
   Fund Project of Jimei University [ZQ2021002]
FX Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University, Grant/Award Number:
   VRLAB2020B16;Fujian Science and Technology Program Guiding Project,
   Grant/Award Number:2020H0001; General Program Funded by Fujian
   Provincial Department of Education, Grant/Award Number:JAT200286;
   Natural Science Foundation of Fujian Province, Grant/Award
   Number:2021J05170; Scientific Research Start-up Fund Project of Jimei
   University,Grant/Award Number: ZQ2021002
CR Asati M, 2019, Arxiv, DOI arXiv:1907.04487
   Astin JA, 1997, PSYCHOTHER PSYCHOSOM, V66, P97, DOI 10.1159/000289116
   Auerbach RP, 2018, J ABNORM PSYCHOL, V127, P623, DOI 10.1037/abn0000362
   Baker R, 2003, J ADV NURS, V43, P465, DOI 10.1046/j.1365-2648.2003.02744.x
   Black Lindsey I, 2018, NCHS Data Brief, P1
   Blanck P, 2018, BEHAV RES THER, V102, P25, DOI 10.1016/j.brat.2017.12.002
   Breedvelt JJF, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00193
   Chandrasiri A, 2020, VIRTUAL REAL-LONDON, V24, P143, DOI 10.1007/s10055-019-00380-2
   Choo A, 2014, 2014 IEEE GAMES, MEDIA, ENTERTAINMENT (GEM)
   Crescentini C, 2016, COMPUT HUM BEHAV, V59, P304, DOI 10.1016/j.chb.2016.02.031
   Dollinger N., 2021, FRONT VIRTUAL REAL, V2, P644
   Feinberg Rachel R., 2022, Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, P1
   Gaddy MA, 2014, CLIN PSYCHOL REV, V34, P402, DOI 10.1016/j.cpr.2014.06.001
   Gál É, 2021, J AFFECT DISORDERS, V279, P131, DOI 10.1016/j.jad.2020.09.134
   Gregory D, 2010, PHILOS QUART, V60, P735, DOI 10.1111/j.1467-9213.2009.644.x
   Gu J, 2015, CLIN PSYCHOL REV, V37, P1, DOI 10.1016/j.cpr.2015.01.006
   Holmes EA, 2007, J BEHAV THER EXP PSY, V38, P297, DOI 10.1016/j.jbtep.2007.10.007
   Holmes EA, 2010, CLIN PSYCHOL REV, V30, P349, DOI 10.1016/j.cpr.2010.01.001
   Khoury B, 2015, J PSYCHOSOM RES, V78, P519, DOI 10.1016/j.jpsychores.2015.03.009
   Lacey S, 2013, MULTISENSORY IMAGERY
   Lang AJ, 2013, DEPRESS ANXIETY, V30, P409, DOI 10.1002/da.22081
   Mantovani F, 2003, CYBERPSYCHOL BEHAV, V6, P389, DOI 10.1089/109493103322278772
   McCraty R, 1998, ALTERN THER HEALTH M, V4, P75
   Melo M, 2022, IEEE T VIS COMPUT GR, V28, P1428, DOI 10.1109/TVCG.2020.3010088
   Nanay B, 2017, PERCEPTION, V46, P1014, DOI 10.1177/0301006617699225
   Ozdemir L, 2009, J NEUROL SCI, V283, P211, DOI 10.1016/j.jns.2009.02.367
   Remmers C, 2016, MINDFULNESS, V7, P829, DOI 10.1007/s12671-016-0520-1
   Ren X, 2016, COMPUTER, V49, P104, DOI 10.1109/MC.2016.253
   Spielberger C.D., 1971, REV INTERAMERICANA P, V5, P145, DOI DOI 10.30849/RIP/IJP.V5I34.620
   Villani D., 2007, Int. J. Stress Manag. Copyr, V14, P260, DOI [DOI 10.1037/1072-5245.14.3.260, 10.1037/1072-5245.14.3.260https://dx.doi.org/10.1037/1072-5245.14.3.260, DOI 10.1037/1072-5245.14.3.260HTTPS://DX.DOI.ORG/10.1037/1072-5245.14.3.260]
   Weiss C, 2019, MUSIC SCI, V23, P486, DOI 10.1177/1029864918757595
   Wielgosz J, 2019, ANNU REV CLIN PSYCHO, V15, P285, DOI 10.1146/annurev-clinpsy-021815-093423
   Zeidan F, 2010, J ALTERN COMPLEM MED, V16, P867, DOI 10.1089/acm.2009.0321
   Zhu B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2685, DOI 10.1145/3025453.3025590
NR 34
TC 1
Z9 1
U1 11
U2 39
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2184
EA MAY 2023
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000991679500001
DA 2024-07-18
ER

PT J
AU Sarbia, F
   Cirelli, M
   Giannini, O
   Cera, M
   Valentini, PP
   Pennestrì, E
AF Sarbia, Franco
   Cirelli, Marco
   Giannini, Oliviero
   Cera, Mattia
   Valentini, Pier Paolo
   Pennestri, Ettore
TI Virtual testing of a new conjecture for the stone ascending device in
   Egyptian pyramids by means of a multibody dynamics simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
ID ALGORITHM; EVOLUTION; FRICTION
AB The ascending of rock blocks for building the Egyptian pyramids has been the topic of many discussions among Egyptologists. One of the authors (F.S.) conjectured a method that could be used for the task. In his own words: "This is the story of the random discovery of an oscillating machine, capable of using gravity to ascend, as the sail goes upwind." In this article, by means of a virtual prototype and multibody dynamics simulation, the physical feasibility of such method is tested for the first time. From historical and archeological bases, this investigation presents the fundamental functional features of the virtual model components for the ascending of the stones. Furthermore, the methodological details for the model setup, as well as the discussion on the stone ascending movements, are herein addressed. The main results obtained from the simulation include the evaluation of the advancement-per-cycle of the conjectured ascending device and the corresponding required driving forces.
C1 [Cirelli, Marco; Giannini, Oliviero] Univ Rome Niccolo Cusano, Dept Mech Engn, Via Don Carlo Gnocchi 3, I-00166 Rome, Italy.
   [Cera, Mattia; Valentini, Pier Paolo; Pennestri, Ettore] Univ Roma Tor Vergata, Dept Enterprise Engn, Rome, Italy.
C3 Niccolo Cusano Online University; University of Rome Tor Vergata
RP Cirelli, M (corresponding author), Univ Rome Niccolo Cusano, Dept Mech Engn, Via Don Carlo Gnocchi 3, I-00166 Rome, Italy.
EM marco.cirelli@unicusano.it
OI Sarbia, Franco/0000-0003-0287-9584; Cirelli, Marco/0000-0002-0700-3752
CR Cera M, 2021, NONLINEAR DYNAM, V104, P1023, DOI 10.1007/s11071-021-06345-y
   Cha HY, 2011, J MECH SCI TECHNOL, V25, P1687, DOI 10.1007/s12206-011-0504-y
   Choi J, 2013, INT J NONLIN MECH, V53, P13, DOI 10.1016/j.ijnonlinmec.2013.01.017
   Choi J, 2010, MULTIBODY SYST DYN, V23, P99, DOI 10.1007/s11044-009-9173-3
   Cirelli M., 2021, INT J VEH PERFORM, V7, P136
   Cirelli M, 2020, MECH MACH THEORY, V152, DOI 10.1016/j.mechmachtheory.2020.103948
   Davidovits J., 2006, NOUVELLE HIST PYRAMI
   Falesiedi O., 1996, ESPERIMENTO SOLLEVAM
   Fisette P, 2000, MECH MACH THEORY, V35, P329, DOI 10.1016/S0094-114X(99)00017-8
   FITCHEN J, 1978, J SOC ARCHIT HIST, V37, P3, DOI 10.2307/989311
   Goyon G., 1983, SECRET BATISSEURS GR
   Guidotti M., 1982, EGITTO VICINO ORIENT, V5, P16
   Hergenrother E., 2000, 8th International Conference in Central Europe on Computer Graphics, Visualization and Interactive Digital Media'2000. Under the Auspices of the Lord Mayor of the City of Pilsen in cooperation with EUROGRAPHOCS and IFIP WG 5.10. WSCG'2000. Conference Proceedings, P402
   Houdin J-P., 2006, KHUFU SECRETS BUILDI
   Hu W, 2021, COMPUT METHOD APPL M, V385, DOI 10.1016/j.cma.2021.114022
   Layard A.H., 1853, DISCOVERIES RUINS NI
   Lehner M., 2008, COMPLETE PYRAMIDS
   LIEH JH, 1994, MECH MACH THEORY, V29, P357, DOI 10.1016/0094-114X(94)90123-6
   Lv NJ, 2020, COMPUT AIDED DESIGN, V122, DOI 10.1016/j.cad.2020.102826
   Machado M, 2012, MECH MACH THEORY, V53, P99, DOI 10.1016/j.mechmachtheory.2012.02.010
   Palermo A, 2013, MECH MACH THEORY, V62, P13, DOI 10.1016/j.mechmachtheory.2012.11.006
   Pennestrì E, 2016, NONLINEAR DYNAM, V83, P1785, DOI 10.1007/s11071-015-2485-3
   Rahnejat H, 2000, P I MECH ENG C-J MEC, V214, P149, DOI 10.1243/0954406001522886
   Rosellini I., 1830, BREVE NOTIZIA OGGETT
   RUSSELL JM, 1987, ART BULL, V69, P520, DOI 10.2307/3050997
   Valentini PP, 2018, MECH MACH THEORY, V128, P225, DOI 10.1016/j.mechmachtheory.2018.06.003
   WU SC, 1986, MECH MACH THEORY, V21, P417, DOI 10.1016/0094-114X(86)90090-X
   Zanoni A, 2020, NONLINEAR DYNAM, V102, P1517, DOI 10.1007/s11071-020-06005-7
NR 28
TC 0
Z9 0
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2023
VL 34
IS 5
DI 10.1002/cav.2125
EA OCT 2022
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DM8E7
UT WOS:000865620700001
DA 2024-07-18
ER

PT J
AU Masood, Z
   Jiangbin, Z
   Irfan, M
   Ahmad, I
AF Masood, Zafar
   Jiangbin, Zheng
   Irfan, Muhammad
   Ahmad, Idrees
TI High-performance virtual globe GPU terrain rendering using game engine
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE game engines; hardware tessellation; real-time graphics; terrain
   rendering; virtual globes
ID GEOMETRY CLIPMAPS; VISUALIZATION
AB Virtual globes render planetary-scale terrain and have limited support for 3D applications development. Game engines provide development environment for interactive 3D applications development and have limited support for world-scale terrain rendering. The game engine based terrain rendering methods lacks hardware based tessellation for high-performance. This work presents a novel method for a high-performance large-scale terrain rendering for high-fidelity display systems using game engine. The proposed method performs patch-based hierarchical culling of a multi-resolution terrain model to reduce rendering load. A view-based algorithm simplifies the patches with error control on GPU. Simplified patches are efficiently submitted for drawing using indirect mesh instancing feature of game engine. The proposed method utilizes hardware tessellation feature for high-performance model tessellation and accurate earth's surface construction using displacement mapping. The proposed method is evaluated by rendering scenes for high-quality output on consumer-level hardware. Flights are performed with various settings and results are compared with clipmap-based and state-of-the-art hardware tessellation based adaptive methods. The proposed method achieved 750, 575, and 540 frames-per-second for HD, full-HD, and ultra-HD display resolutions.
C1 [Masood, Zafar; Jiangbin, Zheng; Irfan, Muhammad; Ahmad, Idrees] Northwestern Polytech Univ, Sch Software, Xian, Peoples R China.
C3 Northwestern Polytechnical University
RP Masood, Z (corresponding author), Northwestern Polytech Univ, Sch Software, Xian, Peoples R China.
EM masoodzafar@mail.nwpu.edu.cn
RI Masood, Zafar/GZK-5917-2022
OI Masood, Zafar/0000-0002-9296-0273
CR [Anonymous], 2003, Level of detail for 3D graphics
   [Anonymous], 2011, DIRECTX 11 TERRAIN T
   Asirvatham A., 2005, GPU GEMS 2, V2, P27
   Assarsson U., 2000, Journal of Graphics Tools, V5, P9, DOI 10.1080/10867651.2000.10487517
   Bladin K, 2018, IEEE T VIS COMPUT GR, V24, P802, DOI 10.1109/TVCG.2017.2743958
   Brainerd W, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925874
   Carbonell-Carrera C, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9030159
   Cartwright WE., 2006, HUMAN IT, V8, P28
   Cignoni P, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P147, DOI 10.1109/VISUAL.2003.1250366
   Cignoni P, 2004, ACM T GRAPHIC, V23, P796, DOI 10.1145/1015706.1015802
   Cozzi Patrick., 2011, 3D engine design for virtual globes
   Dimitrijevic AM, 2015, COMPUT GRAPH-UK, V52, P43, DOI 10.1016/j.cag.2015.06.006
   Dong QH, 2018, INT J GEOGR INF SCI, V32, P302, DOI 10.1080/13658816.2017.1372764
   Duchaineau M, 1997, VISUALIZATION '97 - PROCEEDINGS, P81, DOI 10.1109/VISUAL.1997.663860
   Friese KI, 2008, INT FED INFO PROC, V279, P11
   Fu HH, 2021, ALEX ENG J, V60, P2865, DOI 10.1016/j.aej.2021.01.029
   Germanchis Tim., 2007, Multimedia Cartography, V2nd, P359
   Graciano A, 2018, ADV ENG SOFTW, V115, P314, DOI 10.1016/j.advengsoft.2017.10.002
   Hwa LM, 2005, IEEE T VIS COMPUT GR, V11, P355, DOI 10.1109/TVCG.2005.65
   Kang H, 2018, GRAPH MODELS, V97, P64, DOI 10.1016/j.gmod.2018.04.001
   Kang H, 2015, VISUAL COMPUT, V31, P455, DOI 10.1007/s00371-014-0941-6
   Kooima R, 2009, IEEE T VIS COMPUT GR, V15, P719, DOI 10.1109/TVCG.2009.43
   Laksono D., 2019, INT ARCH PHOTOGRAMME
   Laksono D, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8080361
   Lee A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205967
   Levenberg J, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P259, DOI 10.1109/VISUAL.2002.1183783
   Li J, 2013, COMPUT GEOSCI-UK, V59, P78, DOI 10.1016/j.cageo.2013.04.029
   Li S, 2021, COMPUT GRAPH-UK, V95, P130, DOI 10.1016/j.cag.2021.02.003
   Losasso F, 2004, ACM T GRAPHIC, V23, P769, DOI 10.1145/1015706.1015799
   Masood Zafar, 2022, ICIGP 2022: 2022 the 5th International Conference on Image and Graphics Processing (ICIGP), P261, DOI 10.1145/3512388.3512426
   Mat RC, 2014, IOP C SER EARTH ENV, V20, DOI 10.1088/1755-1315/20/1/012037
   Niessner M, 2016, COMPUT GRAPH FORUM, V35, P113, DOI 10.1111/cgf.12714
   Paredes EG, 2012, INT J GEOGR INF SCI, V26, P771, DOI 10.1080/13658816.2011.615317
   Psaltoglou A, 2021, MULTIMED TOOLS APPL, V80, P15849, DOI 10.1007/s11042-021-10585-w
   Ruz├a┬noor CM., 2011, TRUE 3D CARTOGRAPHY, P265
   Ruzinoor CM, 2012, GEO-SPAT INF SCI, V15, P105, DOI 10.1080/10095020.2012.714101
   Sawyer B, 2007, COMPUT GRAPH FORUM, V26, pXVIII, DOI 10.1111/j.1467-8659.2007.01044.x
   Schafer H., 2014, Eurographics State of the Art Reports, P93
   Song G, 2017, IEICE T INF SYST, VE100D, P401, DOI 10.1587/transinf.2016EDL8160
   Van Waveren J., 2012, SOFTWARE VIRTUAL TEX
   Virtanen JP, 2020, ISPRS J PHOTOGRAMM, V163, P375, DOI 10.1016/j.isprsjprs.2020.03.007
   Wang RX, 2020, ADV ENG SOFTW, V148, DOI 10.1016/j.advengsoft.2020.102838
   Wirth F, 2019, IEEE INT VEH SYM, P1693, DOI 10.1109/IVS.2019.8814115
   Yu L, 2012, INT J REMOTE SENS, V33, P3966, DOI 10.1080/01431161.2011.636081
   Yusov E., 2011, Journal of WSCG, V19, P85
   Yusov E., 2012, GPU PRO 3, P2
   Zhai R, 2016, NEUROCOMPUTING, V171, P1, DOI 10.1016/j.neucom.2014.08.108
   Zhou MY, 2016, INT J GEOGR INF SCI, V30, P2208, DOI 10.1080/13658816.2016.1165819
NR 48
TC 4
Z9 4
U1 7
U2 20
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2023
VL 34
IS 2
AR e2108
DI 10.1002/cav.2108
EA AUG 2022
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D7UU4
UT WOS:000838438000001
DA 2024-07-18
ER

PT J
AU Palfinger, W
AF Palfinger, Werner
TI Continuous remeshing for inverse rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE differentiable rendering; geometry reconstruction; inverse rendering;
   mesh optimization; remeshing
AB We present a novel method for joint optimization and remeshing and apply it to inverse rendering. Rapid advances in differentiable rendering during the last years paved the way for fast inverse rendering of complex scenes. But serious problems with gradient-based optimization of triangle meshes remain. Applying gradient steps to the vertices can lead to mesh defects, such as flipped triangles, crumpled regions, and self-intersections. Choosing a good vertex count is crucial for the optimization quality and performance but is usually done by hand. Moreover, meshes with fixed triangulation struggle to adapt to complex geometry. Our novel method tackles all these problems by applying an adaptive remeshing step in each single iteration of the optimization loop. By immediately collapsing suspicious triangles, we avoid and heal mesh defects. We use a closed-loop-controlled location-dependent edge length. We compare our solution to state-of-the-art methods and find that it is faster and more accurate. It produces finer meshes with fewer defects, requires less parameter tuning and can reconstruct more complex objects.
C1 [Palfinger, Werner] Profactor GmbH, Machine Vis Grp, Steyr, Austria.
C3 Upper Austrian Research GmbH; PROFACTOR
RP Palfinger, W (corresponding author), Profactor GmbH, Machine Vis Grp, Steyr, Austria.
EM werner.palfinger@profactor.at
OI Palfinger, Werner/0000-0002-7991-6139
FU Upper Austria, European Regional Development Fund, Investment for Growth
   and Jobs (IGJ/ERDF), Priority 7, REACT-EU, ZDM_OmniScan; Upper Austria,
   Zer0P, Zero Defect Manufacturing fur die nachhaltige Produktion
FX Upper Austria, European Regional Development Fund, Investment for Growth
   and Jobs (IGJ/ERDF), Priority 7, REACT-EU, ZDM_OmniScan; Upper Austria,
   Zer0P, Zero Defect Manufacturing fur die nachhaltige Produktion
CR Botsch M., 2004, PROC EUROGRAPHICS AC, P185, DOI [10.1145/1057432.1057457, DOI 10.1145/1057432.1057457]
   Cheng Z., 2021, ARXIV ABS210405014
   Gkioxari G, 2019, IEEE I CONF COMP VIS, P9784, DOI 10.1109/ICCV.2019.00988
   Gupta K., 2020, ARXIV ABS200710973
   Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119
   Jacobson A., 2022, COMMON 3D MODELS
   Jakob W, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818078
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kingma D. P., 2014, arXiv
   Laine S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417861
   Li TM, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275109
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11
   Luan FJ, 2021, COMPUT GRAPH FORUM, V40, P101, DOI 10.1111/cgf.14344
   Nicolet B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480501
   Nimier-David M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392406
   Nimier-David M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356498
   O'Riordan A, 2018, I CONF SENS TECHNOL, P178, DOI 10.1109/ICSensT.2018.8603605
   Paszke A, 2019, ADV NEUR IN, V32
   Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317
   Ravi Nikhila, 2020, CoRR
   Sellan S., 2022, LIBIGL BOTSCH KOBBEL
   Surazhsky V., 2003, Symposium on Geometry Processing, P20
   Vicini D, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459804
   Vienna NHM., 2022, 3D SCAN SABER TOOTHE
   Zhang C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356522
   Zhou Qingnan, 2016, Thingi10k: A dataset of 10,000 3d-printing models
NR 27
TC 3
Z9 3
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP
PY 2022
VL 33
IS 5
AR e2101
DI 10.1002/cav.2101
EA JUL 2022
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5E9FV
UT WOS:000826787000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Liang, H
   Dong, XH
   Liu, XX
   Pan, JJ
   Zhang, JY
   Wang, RC
AF Liang, Hui
   Dong, Xiaohang
   Liu, Xiaoxiao
   Pan, Junjun
   Zhang, Jingyue
   Wang, Ruicong
TI A semantic-driven generation of 3D Chinese opera performance scenes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE 3D scene generation; semantic; traditional Chinese art
AB The emergence of digital opera has enriched the stage performance of Chinese opera and expanded its dissemination means. However, the modern spread of traditional Chinese opera still faces hindrances. Digital opera performances require the generation of virtual scenes of the stages and characters. However, traditional virtual scene generation requires workers to build 3D models using modeling software and incorporate them into the performance scene. This article proposes a semantic-based generation method for Chinese opera performance scenes. First, we analyze the scene description scripts to understand the elements in Chinese opera virtual scenes. The prior probability is subsequently used to learn the model placement rules in the opera scene model. A digital scene suitable for Chinese opera performance is then generated. The final results show that the method can generate natural and receptive opera digital performance scenes. This article's research ideas and achievements are conducive to the promotion of development of Chinese digital opera technology. They possess substantial significance to the inheritance and development of traditional Chinese opera art.
C1 [Liang, Hui; Dong, Xiaohang; Zhang, Jingyue; Wang, Ruicong] Zhengzhou Univ Light Ind, Dept Software Engn, Zhengzhou, Peoples R China.
   [Liu, Xiaoxiao] Bournemouth Univ, Fac Media, Poole, Dorset, England.
   [Pan, Junjun] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Zhengzhou University of Light Industry; Bournemouth University; Beihang
   University
RP Liang, H; Dong, XH (corresponding author), Zhengzhou Univ Light Ind, Dept Software Engn, Zhengzhou, Peoples R China.
EM hliang@zzuli.edu.cn; xiaohangdong@email.zzuli.edu.cn
RI SUN, YANLING/JTT-9082-2023; zhang, jt/JVE-1333-2024; Pan,
   Junjun/A-1316-2013; Liu, Xiaoxiao/HNI-6180-2023
OI Dong, Xiaohang/0000-0001-7969-3134
FU Scientific and Technological Project in Henan Province [222102210030];
   major Science and Technology program in Henan Province [211110110500]
FX The research leading to these results has received funding from the
   Scientific and Technological Project in Henan Province (222102210030)
   and the "Jie Bang Gua Shuai" project of the major Science and Technology
   program in Henan Province (211110110500).
CR Agresti A, 1998, AM STAT, V52, P119, DOI 10.2307/2685469
   Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543
   de Dinechin GD, 2019, PROCEEDINGS OF THE 32ND INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2019), P75, DOI 10.1145/3328756.3328775
   Evans Christopher., 2019, ACM SIGGRAPH 2019: Virtual, Augmented, and Mixed Reality
   Fisher M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818057
   He JX, 2017, AGRO FOOD IND HI TEC, V28, P858
   Hu KM, 2013, COMPUT AIDED DESIGN, V45, P739, DOI 10.1016/j.cad.2012.10.005
   Lan L., 2021, ARTS STUD CRITICISM, V2, P123
   Leng B, 2015, NEUROCOMPUTING, V151, P593, DOI 10.1016/j.neucom.2014.06.084
   Léon V, 2016, COMPUT GRAPH-UK, V54, P47, DOI 10.1016/j.cag.2015.07.018
   Liang H, 2018, VIRTUAL REAL-LONDON, V22, P149, DOI 10.1007/s10055-018-0333-8
   Ma R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275035
   Rosinol A, 2020, IEEE INT CONF ROBOT, P1689, DOI [10.1109/icra40945.2020.9196885, 10.1109/ICRA40945.2020.9196885]
   Ruiz-Sarmiento JR, 2015, KNOWL-BASED SYST, V86, P131, DOI 10.1016/j.knosys.2015.05.032
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   VLADIMIR G, 2014, ACM T GRAPH TOG PROC, V33, P1
   Yoo K., 2019, P 25 ACM S VIRTUAL R
   Zhang Y., 2019, ACM SIGGRAPH 2019 PO, P1
NR 18
TC 1
Z9 1
U1 10
U2 44
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2077
DI 10.1002/cav.2077
EA JUN 2022
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000806098900001
DA 2024-07-18
ER

PT J
AU Tekgün, E
   Uludagli, MÇ
   Akcan, H
   Erdeniz, B
AF Tekgun, Ege
   Uludagli, Muhtar C.
   Akcan, Huseyin
   Erdeniz, Burak
TI Virtual body anthropomorphism increases drift in self-location: Further
   support for the humanoid shape rule
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE avatar anthropomorphism; bodily self-consciousness; drift in
   self-location; first-person perspective; virtual reality
ID OWNERSHIP; STIMULATION; EMBODIMENT; MOVEMENTS; SKIN
AB Previous studies on bodily self-consciousness (BCS) have shown that self-location and body ownership are prone to changes based on the perceptual appearances of the fake virtual body. In the current study with 36 participants, we assessed the influence of virtual avatar anthropomorphism and the synchronicity of the visuo-tactile stimulation on self-location using a virtual reality full-body illusion experiment. During the experiment, half of the participants observed a gender-matched full-body humanoid avatar from a first-person perspective (1PP) and the other half observed a less anthropomorphic full-body cubical avatar from 1PP while they were receiving synchronous and asynchronous visuo-tactile stimulation. Results showed a significant main effect of the synchronicity of the visuo-tactile stimulation and avatar body type on self-location but no significant interaction was found between them. Moreover, the results of the self-report questionnaire provide additional evidence showing that participants who received synchronous visuo-tactile stimulation, experienced not only greater changes in the feeling of self-location, but also, increased ownership, and referral of touch. Our results provided further support for the previous findings that showed evidence for the effect of virtual avatar appearance on BCS.
C1 [Tekgun, Ege; Erdeniz, Burak] Izmir Univ Econ, Dept Psychol, Izmir, Turkey.
   [Uludagli, Muhtar C.] Izmir Univ Econ, IEU Game Lab, Dept Comp Engn, Izmir, Turkey.
   [Akcan, Huseyin] Izmir Univ Econ, IEU Game Lab, Dept Software Engn, Izmir, Turkey.
C3 Izmir Ekonomi Universitesi; Izmir Ekonomi Universitesi; Izmir Ekonomi
   Universitesi
RP Tekgün, E (corresponding author), Izmir Univ Econ, Dept Psychol, Izmir, Turkey.
EM etekgun@gmail.com
RI Tekgun, Ege/JCN-8703-2023; Uludagli, Cagkan/AAA-4930-2022
OI Tekgun, Ege/0000-0001-8764-2126; Uludagli, Cagkan/0000-0003-1018-650X
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [119K807]
FX Scientific and Technological Research Council of Turkey (TUBITAK),
   Grant/Award Number: 119K807
CR Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Armel KC, 2003, P ROY SOC B-BIOL SCI, V270, P1499, DOI 10.1098/rspb.2003.2364
   Aspell JE, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006488
   Aspell JE., 2012, NEURAL BASEMULTISE, P467
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bergström I, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148060
   Blanke O, 2012, NAT REV NEUROSCI, V13, P556, DOI 10.1038/nrn3292
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Blom KJ, 2014, PERCEPTION, V43, P275, DOI 10.1068/p7618
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Breidt M., 2018, P 25 IEEE WORKSH VIR
   Damasio AntonioR., 1999, FEELING WHAT HAPPENS
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   Debarba HG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190109
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Ehrsson HH, 2020, MULTISENSORY PERCEPTION: FROM LABORATORY TO CLINIC, P179, DOI 10.1016/B978-0-12-812492-5.00008-5
   Eubanks JC, 2020, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR50242.2020.00025
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fleming Reuben, 2016, VISIGRAPP 2016. 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications. Proceedings: GRAPP 2016, P335
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   Gonzalez-Franco M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00392
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Gorisse G, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00008
   Guterstam A, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.201911
   Guterstam A, 2015, CURR BIOL, V25, P1416, DOI 10.1016/j.cub.2015.03.059
   Guterstam A, 2012, CONSCIOUS COGN, V21, P1037, DOI 10.1016/j.concog.2012.01.018
   Hänsel A, 2011, EUR J PAIN, V15, P874, DOI 10.1016/j.ejpain.2011.03.013
   Heydrich L, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00946
   Huang HC, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00370
   Ionta S, 2009, EXP BRAIN RES, V195, P207, DOI 10.1007/s00221-009-1770-0
   Kalckert A, 2014, CONSCIOUS COGN, V26, P117, DOI 10.1016/j.concog.2014.02.003
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Krekhov A., 2019, IEEE CONF COMPU INTE, DOI [DOI 10.1109/cig.2019.8848005, DOI 10.1109/CIG.2019.8848005]
   Latoschik ME, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P73, DOI 10.1145/2993369.2993399
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lenggenhager B, 2009, CONSCIOUS COGN, V18, P110, DOI 10.1016/j.concog.2008.11.003
   Lesur MR, 2018, CONSTR FOUND, V14, P94
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P225, DOI 10.1109/VR.2015.7223377
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   Maselli A, 2015, COGN PROCESS, V16, pS309, DOI 10.1007/s10339-015-0667-z
   Maselli A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00693
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Metzinger T, 2008, PROG BRAIN RES, V168, P215, DOI 10.1016/S0079-6123(07)68018-2
   Montes GA, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00007
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Nagamine S, 2016, 2016 FIFTH ICT INTERNATIONAL STUDENT PROJECT CONFERENCE (ICT-ISPC), P97, DOI 10.1109/ICT-ISPC.2016.7519245
   Noel JP, 2015, COGNITION, V144, P49, DOI 10.1016/j.cognition.2015.07.012
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Parger M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281529
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Petkova VI, 2011, CURR BIOL, V21, P1118, DOI 10.1016/j.cub.2011.05.022
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Pfeiffer C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061751
   Lesur MR, 2020, PERCEPTION, V49, P693, DOI 10.1177/0301006620928669
   Rosén B, 2009, SCAND J PLAST RECONS, V43, P260, DOI 10.3109/02844310903113107
   Roth D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P357, DOI 10.1145/2993369.2996302
   Serino A, 2013, CONSCIOUS COGN, V22, P1239, DOI 10.1016/j.concog.2013.08.013
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   Tsakiris M, 2010, EXP BRAIN RES, V204, P343, DOI 10.1007/s00221-009-2039-3
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
NR 65
TC 0
Z9 0
U1 1
U2 38
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2022
VL 33
IS 2
AR e2038
DI 10.1002/cav.2038
EA JAN 2022
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 0T8YJ
UT WOS:000740634700001
DA 2024-07-18
ER

PT J
AU Hu, XY
   Bao, XZ
   Xie, SB
   Wei, GL
AF Hu, Xiaoyan
   Bao, Xizhao
   Xie, Shunbo
   Wei, Guoli
TI Unsupervised motion capture data segmentation based on topic model
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion analysis; motion capture; motion segmentation; sparse
   representation; topic model
AB In this paper, we propose an unsupervised motion segmentation method based on topical model borrowed from Natural Language Processing. We apply hierarchical clustering on motion dataset to obtain a list of representative poses to constitute motion 'vocabulary'. By doing so, motion capture data can be viewed as text which comprises a sequence of motion words. We use sliding window to generate a sequence of motion documents (with overlap between consecutive motion documents). Then we use Sparse Topical Coding (STC) model to extract sparse topical codes of motion documents and conduct spectral clustering to get motion segmentations. Silhouette coefficient is used to determine the value of K (number of motion types). The results of experiments show that our method can segment motions with a very high accuracy. Our method has a strong generalization ability that also performs well on motion data which is captured by different subjects, with various motion types, even though they are from different motion dataset (HDM05 in our experiment).
C1 [Hu, Xiaoyan; Bao, Xizhao; Wei, Guoli] Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Xie, Shunbo] ByteDance, Beijing, Peoples R China.
C3 Beijing Normal University
RP Bao, XZ (corresponding author), Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.
EM baoxzh@outlook.com
RI wang, xueting/JPY-2782-2023; zhou, you/KBC-3567-2024
OI Bao, Xizhao/0000-0001-6111-2127
FU National Key R&D Program of China [2018YFC0831201]
FX This research has been supported by National Key R&D Program of China
   (2018YFC0831201).
CR [Anonymous], 2009, P 2009 ACM SIGGRAPH
   [Anonymous], 2010, SCA'10: proceedings of the 2010 ACM SIGGRAPH/Eurographics symposium on computer animation, DOI [10.2312/SCA/SCA10/001-010, DOI 10.2312/SCA/SCA10/001-010]
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Beaudoin P., 2008, P 2008 ACM SIGGRAPHE, P117
   Graca Joao., 2009, Advances in Neural Information Processing Systems, V22, P664
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lan RY, 2015, VISUAL COMPUT, V31, P35, DOI 10.1007/s00371-013-0902-5
   Laraba S, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1782
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lin CC, 2008, I C WIREL COMM NETW, P12276
   Lv N, 2014, COMPUT ANIMAT VIRT W, V25, P283, DOI 10.1002/cav.1597
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Qi T, 2014, COMPUT ANIMAT VIRT W, V25, P293, DOI 10.1002/cav.1590
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Xia GY, 2018, IEEE T IMAGE PROCESS, V27, P135, DOI 10.1109/TIP.2017.2738562
   Yan X., 2013, P 22 INT C WORLD WID, P1445, DOI DOI 10.1145/2488388.2488514
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
   Zhu J., 2012, ABS12023778 CORR
NR 22
TC 1
Z9 1
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2021
VL 32
IS 3-4
AR e2005
DI 10.1002/cav.2005
EA JUN 2021
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH1NG
UT WOS:000662067300001
DA 2024-07-18
ER

PT J
AU Jáuregui, DAG
   Giraud, T
   Isableu, B
   Martin, JC
AF Antonio Gomez Jauregui, David
   Giraud, Tom
   Isableu, Brice
   Martin, Jean-Claude
TI Design and evaluation of postural interactions between users and a
   listening virtual agent during a simulated job interview
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE job interview; mirroring; postural interaction; virtual human
ID EMOTION; ANXIETY; RECOGNITION; PERCEPTION; RESPONSES; ACCURACY;
   BEHAVIOR; AROUSAL; GENDER; FREEZE
AB Postural interaction is of major importance during job interviews. While several prototypes enable users to rehearse for public speaking tasks and job interviews, few of these prototypes support subtle bodily interactions between the user and a virtual agent playing the role of an interviewer. The design of our system is informed by a multimodal corpus that was previously collected. In this paper, we explain how we were inspired by these video recordings of human interviewers to build a library of motion-captured movements that interviewers are most likely to display. We designed a fully automatic interactive virtual agent able to display these movements in response to the bodily movements of the user. Thirty-two participants presented themselves to this virtual agent during a simulated job interview. We focused on the self-presentation task of the job interview, the virtual agent being listening. Participants stood on a force platform that recorded the displacements of their center of pressure to assess the postural impact of our design. We also collected video recordings of their movements and computed the contraction index and the quantity of motion of their bodies. We explain the different hypotheses that we made concerning (1) the comparison between the performance of participants with human interviewers and the performance of participants with virtual interviewers, (2) the comparison between mirror and random postural behaviors displayed by a female versus a male virtual interviewer, and (3) the correlation between the participants' performance and their personality traits. Our results suggest that users perceive the simulated self-presentation task with the virtual interviewer as threatening and as difficult as the presentation task with the human interviewers. Furthermore, when users interact with a virtual interviewer that mirrors their postures, these users perceive the interviewer as being affiliative. Finally, a correlation analysis showed that personality traits had a significant relation to the postural behaviors and performance of the users during their presentation.
C1 [Antonio Gomez Jauregui, David] Univ Bordeaux, Estia Inst Technol, Bidart, France.
   [Giraud, Tom] Univ Augsburg, Human Ctr Multimedia, Augsburg, Germany.
   [Isableu, Brice] Aix Marseille Univ, PSYCLE, Aix En Provence, France.
   [Martin, Jean-Claude] Univ Paris Saclay, CNRS, LIMSI, Orsay, France.
C3 Universite de Bordeaux; University of Augsburg; Aix-Marseille
   Universite; Universite Paris Cite; Universite Paris Saclay; Centre
   National de la Recherche Scientifique (CNRS)
RP Jáuregui, DAG (corresponding author), Univ Bordeaux, Estia Inst Technol, Bidart, France.
EM d.gomez@estia.fr
RI Jauregui, David Antonio Gomez/W-1226-2019; ISABLEU, Brice/KEJ-6773-2024
CR Aigrain J, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P113, DOI 10.1145/2993148.2993200
   Aigrain J, 2018, IEEE T AFFECT COMPUT, V9, P491, DOI 10.1109/TAFFC.2016.2631594
   Anderson Keith, 2013, Advances in Computer Entertainment. 10th International Conference, ACE 2013. Proceedings: LNCS 8253, P476, DOI 10.1007/978-3-319-03161-3_35
   Andru, 2013, ACM MULTIMED
   [Anonymous], 2020, MICROSOFT KINECT SDK
   Baggett HL, 1996, PERS SOC PSYCHOL B, V22, P483, DOI 10.1177/0146167296225006
   Batrinca Ligia, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P116, DOI 10.1007/978-3-642-40415-3_10
   Behnke RR, 2000, COMMUN EDUC, V49, P187, DOI 10.1080/03634520009379205
   Bernieri FJ, 1996, J PERS SOC PSYCHOL, V71, P110, DOI 10.1037/0022-3514.71.1.110
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   BONARDI A, 2006, P IPMU 2006 11 INT C, P540
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Bull P.E., 1987, Posture and Gesture, V16
   Buschmeier H, 2014, LECT NOTES ARTIF INT, V8637, P71, DOI 10.1007/978-3-319-09767-1_10
   Buzzotta VR., 1972, EFFECTIVE SELLING PS
   Castellano G, 2007, LECT NOTES COMPUT SC, V4738, P71
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Chollet M, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P367, DOI 10.1145/2818346.2823294
   Condon W.S., 1971, Perception of Language, P150
   Coulson M, 2004, J NONVERBAL BEHAV, V28, P117, DOI 10.1023/B:JONB.0000023655.25550.be
   de Gelder B, 2015, WIRES COGN SCI, V6, P149, DOI 10.1002/wcs.1335
   de Kok I., 2010, INT C MULTIMODAL INT, P3
   Delaherche E, 2012, IEEE T AFFECT COMPUT, V3, P349, DOI 10.1109/T-AFFC.2012.12
   DEPAULO BM, 1992, PSYCHOL BULL, V111, P203, DOI 10.1037/0033-2909.111.2.203
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Duarte M, 2010, BRAZ J PHYS THER, V14, P183, DOI 10.1590/S1413-35552010000300003
   Frijda N. H., 1986, EMOTIONS
   Gaibani L., 2014, INT J ENGL LINGUIST, V2, P105
   Gebhard P, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P661
   Giraud T, 2015, ACM T APPL PERCEPT, V13, DOI 10.1145/2791294
   Giraud T, 2013, INT CONF AFFECT, P417, DOI 10.1109/ACII.2013.75
   Giraud T, 2013, INT CONF AFFECT, P109, DOI 10.1109/ACII.2013.25
   Gu YH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070112
   Hagenaars MA, 2014, NEUROSCI BIOBEHAV R, V47, P165, DOI 10.1016/j.neubiorev.2014.07.021
   Hagenaars MA, 2012, J EXP PSYCHOL GEN, V141, P98, DOI 10.1037/a0024211
   Harmon-Jones E., 2007, Social neuroscience: Integrating biological and psychological explanations of social behavior
   Haviland-Jones J., 2000, GENDER EMOTION EXPRE, P338
   Ho CC, 2010, COMPUT HUM BEHAV, V26, P1508, DOI 10.1016/j.chb.2010.05.015
   Hoque M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P697
   Horslen BC, 2011, EXP BRAIN RES, V215, P27, DOI 10.1007/s00221-011-2867-9
   John O. P., 1999, BIG 5 TRAIT TAXONOMY
   KANE EW, 1993, PUBLIC OPIN QUART, V57, P1, DOI 10.1086/269352
   Kang N, 2013, IEEE T AFFECT COMPUT, V4, P326, DOI 10.1109/TAFFC.2013.2297104
   Kang SH, 2008, LECT NOTES COMPUT SC, V5208, P253
   KIRSCHBAUM C, 1993, NEUROPSYCHOBIOLOGY, V28, P76, DOI 10.1159/000119004
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Kret ME, 2013, EXP BRAIN RES, V228, P399, DOI 10.1007/s00221-013-3557-6
   Kudielka B. M., 2007, SOCIAL NEUROSCIENCE, P56, DOI [DOI 10.1016/B978-012373947-6.00681-4, 10.4135/9781412956253.n539]
   LAFRANCE M, 1981, J NONVERBAL BEHAV, V5, P139, DOI 10.1007/BF00986131
   Lakin JL, 2003, PSYCHOL SCI, V14, P334, DOI 10.1111/1467-9280.14481
   Lang PJ, 2000, J AFFECT DISORDERS, V61, P137, DOI 10.1016/S0165-0327(00)00343-8
   Lazarus, 2007, STRESS EMOTION NEW S
   LAZARUS RS, 1991, AM PSYCHOL, V46, P819, DOI 10.1037/0003-066X.46.8.819
   Lixing Huang, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P68, DOI 10.1007/978-3-642-23974-8_8
   Marsella S., 2011, MORE COMPREHENSIVE L
   Martin, 2009, EUR J SOC SCI, V8, P129
   Matsuda S., 2004, SYSTEM, V32, P21, DOI [DOI 10.1016/J.SYSTEM.2003.08.002, 10.1016/j.system.2003.08.002]
   Mejias H., 1991, LANGUAGE ANXIETY THE, P87
   Morency LP, 2010, AUTON AGENT MULTI-AG, V20, P70, DOI 10.1007/s10458-009-9092-y
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Naim I, 2018, IEEE T AFFECT COMPUT, V9, P191, DOI 10.1109/TAFFC.2016.2614299
   Nguyen LS, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P51, DOI 10.1145/2818346.2820760
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Philip P, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-019-0213-y
   Plaisant O, 2010, ANN MED-PSYCHOL, V168, P97, DOI 10.1016/j.amp.2009.09.003
   Poppe R, 2013, AUTON AGENT MULTI-AG, V27, P235, DOI 10.1007/s10458-013-9219-z
   Porayska-Pomsta, 2014, P INT WORKSH INT DIG
   Proverbio AM, 2018, SOC COGN AFFECT NEUR, V13, P590, DOI 10.1093/scan/nsy033
   Ramanarayanan V, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P23, DOI 10.1145/2818346.2820765
   Roelofs K, 2010, PSYCHOL SCI, V21, P1575, DOI 10.1177/0956797610384746
   Scherer S., 2015, MULTIMODAL PUBLIC SP
   Schneider TR, 2012, STRESS HEALTH, V28, P102, DOI 10.1002/smi.1409
   Schröder M, 2012, IEEE T AFFECT COMPUT, V3, P165, DOI 10.1109/T-AFFC.2011.34
   Shockley K, 2003, J EXP PSYCHOL HUMAN, V29, P326, DOI 10.1037/0096-1523.29.2.326
   Shockley K, 2009, TOP COGN SCI, V1, P305, DOI 10.1111/j.1756-8765.2009.01021.x
   Stins John F, 2011, Exp Brain Res, V212, P603, DOI 10.1007/s00221-011-2767-z
   STREETER LA, 1983, J ACOUST SOC AM, V73, P1354, DOI 10.1121/1.389239
   Tan N., 2010, P 2 INT WORKSH SOC S, P53
   Tanveer MI, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P385, DOI 10.1145/2856767.2856785
   Technologies U, 2020, UNITY3D
   Tourangeau R, 2003, COMPUT HUM BEHAV, V19, P1, DOI 10.1016/S0747-5632(02)00032-8
   Vanni F, 2013, EUR REV MED PHARMACO, V17, P1561
   WALLBOTT HG, 1991, J PERS SOC PSYCHOL, V61, P147, DOI 10.1037/0022-3514.61.1.147
   Winter DA, 2009, BIOMECHANICS MOTOR C, DOI [10.1002/9780470549148, DOI 10.1002/9780470549148]
   Yabar Y, 2006, J NONVERBAL BEHAV, V30, P97, DOI 10.1007/s10919-006-0010-6
NR 85
TC 3
Z9 3
U1 4
U2 23
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2021
VL 32
IS 6
AR e2029
DI 10.1002/cav.2029
EA MAY 2021
PG 25
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW9UC
UT WOS:000655676200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Qian, K
   Wang, ML
   Cui, YQ
AF Qian, Kun
   Wang, Meili
   Cui, Yaqing
TI Simulation ready anatomy model generation pipeline for virtual surgery
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE cutting; remesh; simulation ready model; surface parameterization
   transfer; voxelization
AB For surgery simulation application, a high-quality anatomical model is very important not only for rendering but also for physics simulation. CT and MRI reconstructed model has no surface parameterization attribute so texture-based materials cannot be applied for rendering. Anatomical models on the digital market are efficient options but most can only be used for visualization because of the nonmanifold geometric degeneracies. We proposed a simulation ready model generation pipeline that can convert a nonmanifold polygonal surface mesh into a degeneracy free surface mesh (simulation ready state) while preserving the original model's surface parameterization attribute. Our pipeline includes two stages. The first stage is a voxelization and remesh based simulation ready model generation pipeline, which can keep the shape of the original three-dimensional surface model meanwhile eliminate the nonmanifold geometry. The second stage is the main contribution of this article. A cutting-based surface mesh parameterization transfer algorithm is proposed which can transfer the original surface parameterization (UV mapping especially the UV seam) to the simulation ready model. A detailed comparison with existing pipelines is made to show that our pipeline can achieve surface parameterization preservation feature and is more suitable for improving the efficiency of virtual surgery production.
C1 [Qian, Kun] Kings Coll London, Dept Perinatal Imaging & Hlth, London, England.
   [Wang, Meili] Northwest Agr & Forestry Univ, Coll Informat Engn, Xianyang, Peoples R China.
   [Cui, Yaqing] Bournemouth Univ, Dept Media & Commun, Poole, Dorset, England.
C3 University of London; King's College London; Northwest A&F University -
   China; Bournemouth University
RP Wang, ML (corresponding author), Northwest Agr & Forestry Univ, Coll Informat Engn, Xianyang, Peoples R China.
EM wml@nwsuaf.edu.cn
OI Cui, Yaqing/0009-0004-6282-0650
FU Key Research and Development Program of Shaanxi Province [2018NY-127];
   Key Laboratory of Agricultural Internet of Things, Ministry of
   Agriculture and Rural Affairs, China [2018AIOT-09]
FX Key Research and Development Program of Shaanxi Province, Grant/Award
   Number: 2018NY-127; Key Laboratory of Agricultural Internet of Things,
   Ministry of Agriculture and Rural Affairs, China, Grant/Award Number:
   2018AIOT-09
CR [Anonymous], 2001, P 3 INT C 3D DIG IM
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Audette MA., 2017, P SUMM SIM MULT BELL, P112
   Barbic J., 2012, ACM SIGGRAPH 2012 CO
   Bommes D, 2013, COMPUT GRAPH FORUM, V32, P51, DOI 10.1111/cgf.12014
   Chang B, 2008, COMPUT GRAPH FORUM, V27, P799, DOI 10.1111/j.1467-8659.2008.01210.x
   Cole F, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1360612.1360657, 10.1145/1360612.1360687]
   Crozier A, 2016, ANN BIOMED ENG, V44, P58, DOI 10.1007/s10439-015-1474-5
   Dicko A., 2013, Intelligent Computer Graphics 2012, P227
   Houston B, 2006, ACM T GRAPHIC, V25, P151, DOI 10.1145/1122501.1122508
   Humphreys G., 2016, Physically Based Rendering:From Theory to Implementation
   Johnson CR., 2007, BIOMESHOD MESHING PI
   Latorre CJ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P142, DOI [10.1109/VRW50115.2020.0-246, 10.1109/VRW50115.2020.00030]
   Lefebvre S, 2006, ACM T GRAPHIC, V25, P541, DOI 10.1145/1141911.1141921
   Peeters P, 2014, VISUAL COMPUT, V30, P127, DOI 10.1007/s00371-013-0788-2
   Persson PO, 2006, ENG COMPUT-GERMANY, V22, P95, DOI 10.1007/s00366-006-0014-1
   Polthier, 2006, ACM INT C PROCEEDING, V256
   Qian K, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1986
   Ray N, 2010, COMPUT GRAPH FORUM, V29, P1489, DOI 10.1111/j.1467-8659.2010.01746.x
   Seidel H.-P, 2004, 2 EUROGRAPHICS S GEO, P175, DOI DOI 10.1145/1057432.1057456
   Steinemann D, 2006, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2006.74
   Wang HM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778844
   Yoshiyasu Y, 2014, COMPUT GRAPH FORUM, V33, P257, DOI 10.1111/cgf.12451
NR 23
TC 2
Z9 2
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2021
VL 32
IS 6
AR e1986
DI 10.1002/cav.1986
EA JAN 2021
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XW9UC
UT WOS:000611665500001
DA 2024-07-18
ER

PT J
AU Liu, Z
   Liu, TT
   Ma, MH
   Hsu, HH
   Ni, ZR
   Chai, YJ
AF Liu, Zhen
   Liu, Tingting
   Ma, Minhua
   Hsu, Hui-Huang
   Ni, Zhongrui
   Chai, Yanjie
TI A perception-based emotion contagion model in crowd emergent evacuation
   simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Conference on Computer Animation and Social Agents (CASA)
CY 2018
CL Beijing, PEOPLES R CHINA
SP Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, ACM SIGGRAPH
DE crowd simulation; emotion; emotion contagion; perception
AB With the increasing number of emergencies, the crowd simulation technology has attracted wide attention in the recent years. Existing emergencies have shown that individuals are easy to be influenced by others' emotion during the evacuation. This will make it easier for people to aggregate together and increase security risks. Some of the existing evacuation models without considering emotion are therefore not suitable for describing crowd behaviors in emergencies. We propose a perception-based emotion contagion model and use multiagent technology to simulate crowd behaviors. Navigation points are introduced to guide the movement of the agents. Based on the proposed model, a prototype simulation system for crowd emotion contagion is developed. The comparative simulation experiments verify that the model can effectively deduct the evacuation time and crowd emotion contagion. The proposed model could be an assistant analysis method for crowd management in emergencies.
C1 [Liu, Zhen; Ni, Zhongrui; Chai, Yanjie] Ningbo Univ, Fac Informat Sci & Technol, Ningbo 315211, Zhejiang, Peoples R China.
   [Liu, Tingting] Ningbo Univ, Coll Sci & Technol, Ningbo 315211, Zhejiang, Peoples R China.
   [Ma, Minhua] Staffordshire Univ, Sch Comp & Digital Technol, Stoke On Trent ST4 2DE, Staffs, England.
   [Hsu, Hui-Huang] Tamkang Univ, Coll Engn, Tamsui 25137, Taiwan.
C3 Ningbo University; Ningbo University; Staffordshire University; Tamkang
   University
RP Liu, TT (corresponding author), Ningbo Univ, Coll Sci & Technol, Ningbo 315211, Zhejiang, Peoples R China.
EM liutingting@nbu.edu.cn
RI liu, zhen/AHE-0113-2022
OI Ma, Minhua/0000-0001-7451-546X; liu, tingting/0000-0002-3469-275X; chai,
   yan jie/0000-0002-3708-8101; Liu, Zhen/0000-0002-1806-5027
FU National Natural Science Foundation of China [61761166005, U1636111];
   Ministry of Science and Technology, Taiwan [MOST
   106-2218-E-032-003-MY3]; National Natural Science Foundation of Zhejiang
   [LQ17F020001]; Ningbo Science Technology Plan projects [2017C50018,
   2017A610113]
FX National Natural Science Foundation of China, Grant/Award Number:
   61761166005 and U1636111; Ministry of Science and Technology, Taiwan,
   Grant/Award Number: MOST 106-2218-E-032-003-MY3; National Natural
   Science Foundation of Zhejiang, Grant/Award Number: LQ17F020001; Ningbo
   Science Technology Plan projects, Grant/Award Number: 2017C50018 and
   2017A610113
CR [Anonymous], CASA 2010 P COMP AN
   [Anonymous], I3D 2009 P 2012 ACM
   Aydt H., 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P72, DOI 10.1109/WI-IAT.2011.154
   Basak AE, 2018, COMPUT GRAPH-UK, V72, P70, DOI 10.1016/j.cag.2018.02.004
   Bernardini G, 2016, SAFETY SCI, V82, P77, DOI 10.1016/j.ssci.2015.09.001
   Bosse T, 2015, COGN COMPUT, V7, P111, DOI 10.1007/s12559-014-9277-9
   Bosse T, 2013, AUTON AGENT MULTI-AG, V27, P52, DOI 10.1007/s10458-012-9201-1
   Cassol Vincius, 2016, 2016 IEEE Virtual Humans and Crowds for Immersive Environments (VHCIE), P1, DOI 10.1109/VHCIE.2016.7563565
   Cassol VJ, 2017, IEEE COMPUT GRAPH, V37, P60, DOI 10.1109/MCG.2017.3271454
   Chu ML, 2015, SIMUL-T SOC MOD SIM, V91, P825, DOI 10.1177/0037549715605363
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Durupinar F, 2011, IEEE COMPUT GRAPH, V31, P22, DOI 10.1109/MCG.2009.105
   Fridman N, 2010, COMPUT MATH ORGAN TH, V16, P348, DOI 10.1007/s10588-010-9082-2
   Galea ER, 1998, J FIRE SCI, V16, P414, DOI 10.1177/073490419801600603
   Gu ZY, 2016, INT J DISAST RISK RE, V18, P1, DOI 10.1016/j.ijdrr.2016.05.008
   Hatfield E., 1994, Emotion contagion
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kapadia M., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games, I3D '09, P215
   Kullu K, 2017, AUTON AGENT MULTI-AG, V31, P1403, DOI 10.1007/s10458-017-9366-8
   Lin P, 2016, PHYSICA A, V452, P157, DOI 10.1016/j.physa.2016.02.017
   Luo LB, 2008, COMPUT ANIMAT VIRT W, V19, P271, DOI 10.1002/cav.238
   Ondrej J, 2010, SIGGRAPH 2010 ACM SI, P1
   Ortony A., 1988, COGNITIVE STRUCTURE
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Ricks BC, 2012, VISUAL COMPUT, V28, P889, DOI 10.1007/s00371-012-0712-1
   Saboia P, 2012, VISUAL COMPUT, V28, P1039, DOI 10.1007/s00371-012-0731-y
   Sakuma T, 2005, COMPUT ANIMAT VIRT W, V16, P343, DOI 10.1002/cav.105
   Shiwakoti N, 2016, INT J DISAST RISK RE, V20, P129, DOI 10.1016/j.ijdrr.2016.11.002
   Thalmann Daniel., 2013, Crowd Simulation, VSecond
   Tsai J, 2013, AUTON AGENT MULTI-AG, V27, P200, DOI 10.1007/s10458-013-9220-6
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Xiong MZ, 2010, VISUAL COMPUT, V26, P367, DOI 10.1007/s00371-010-0421-6
NR 34
TC 23
Z9 26
U1 2
U2 70
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2018
VL 29
IS 3-4
AR e1817
DI 10.1002/cav.1817
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA GI0TT
UT WOS:000434083100008
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kwon, S
   Kim, Y
   Kim, K
   Lee, S
AF Kwon, Soonhyeon
   Kim, Younguk
   Kim, Kihyuk
   Lee, Sungkil
TI Heterogeneous volume deformation and animation authoring with
   density-aware moving least squares
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE animation; deformation; heterogeneous volume; moving least squares;
   volume
AB This paper presents a novel heterogeneous volume deformation technique and an intuitive volume animation authoring framework. Our volume deformation extends the previous technique based on moving least squares with a density-aware weighting metric for data-driven importance control and efficient upsampling-based volume synthesis. For user interaction, we present an intuitive visual metaphor and interaction schemes to support effective spatiotemporal editing of volume deformation animation. Our framework is implemented fully on graphics processors and thus suitable for quick-and-easy prototyping of volume deformation with improved controllability.
C1 [Kwon, Soonhyeon] Sungkyunkwan Univ, Comp Engn, Suwon, South Korea.
   [Kim, Younguk; Kim, Kihyuk] Sungkyunkwan Univ, Suwon, South Korea.
   [Lee, Sungkil] Sungkyunkwan Univ, Software Dept, Suwon, South Korea.
C3 Sungkyunkwan University (SKKU); Sungkyunkwan University (SKKU);
   Sungkyunkwan University (SKKU)
RP Lee, S (corresponding author), Sungkyunkwan Univ, Software Dept, Suwon, South Korea.
EM sungkil@skku.edu
RI LEE, Sungkil/AAJ-8474-2021
OI LEE, Sungkil/0000-0003-0123-9382
FU Mid-career (on Human-centered Interaction for Coexistence) RD program
   [2015R1A2A2A01003783, 2012M3A6A3055695]; ITRC support program
   [IITP-2017-2016-0-00312]; Korea Government (MSIP); Faculty Research
   Fund, Sungkyunkwan University; Global Frontier (on Human-centered
   Interaction for Coexistence) RD program [2015R1A2A2A01003783,
   2012M3A6A3055695]
FX Mid-career and Global Frontier (on Human-centered Interaction for
   Coexistence) R&D programs, Grant/Award Number: 2015R1A2A2A01003783,
   2012M3A6A3055695; ITRC support program, Grant/Award Number:
   IITP-2017-2016-0-00312; Korea Government (MSIP); Faculty Research Fund,
   Sungkyunkwan University
CR [Anonymous], 1994, ACM Transactions on Computer-Human Interaction, DOI [10.1145/180171.180173, DOI 10.1145/180171.180173]
   Björk S, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P85, DOI 10.1109/INFVIS.2000.885094
   Bowles H, 2012, COMPUT GRAPH FORUM, V31, P237, DOI 10.1111/j.1467-8659.2012.03002.x
   Bürger K, 2008, IEEE T VIS COMPUT GR, V14, P1388, DOI 10.1109/TVCG.2008.120
   Chandru V, 2000, COMP ANIM CONF PROC, P134, DOI 10.1109/CA.2000.889064
   Cohen M, 2004, THEORY AND PRACTICE OF COMPUTER GRAPHICS 2004, PROCEEDINGS, P32, DOI 10.1109/TPCG.2004.1314450
   Correa CarlosD., 2007, Sixth Eurographics / IEEE VGTC Workshop on Volume Graphics, P91
   Crassin C, 2011, COMPUT GRAPH FORUM, V30, P1921, DOI 10.1111/j.1467-8659.2011.02063.x
   Cuno A., 2007, Proceedings of the 27th Computer Graphics International Conference, P115
   Fang SF, 1996, IEEE VISUAL, P73, DOI 10.1109/VISUAL.1996.567609
   Hadwiger M, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P301, DOI 10.1109/VISUAL.2003.1250386
   He TS, 1996, IEEE VISUAL, P227, DOI 10.1109/VISUAL.1996.568113
   Kim K, 2012, P EUR CAGL IT EUR
   Kindlmann G., 2002, COURSE NOTES ACM SIG, V3
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Krüger J, 2006, IEEE T VIS COMPUT GR, V12, P941, DOI 10.1109/TVCG.2006.124
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Nakao M, 2010, IEEE PAC VIS SYMP, P161, DOI 10.1109/PACIFICVIS.2010.5429597
   Rasmussen N, 2003, ACM T GRAPHIC, V22, P703, DOI 10.1145/882262.882335
   Rezk-Salama C., 2001, 2001 ACM SIGGRAPHEUR, P17, DOI DOI 10.1145/383507.383517
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Singh V., 2003, Proceedings of the 2003 Eurographics/IEEE TVCG Workshop on Volume graphics, P45
   Tejada E, 2008, P LAT AM C INF SANT, P813
   Wang YS, 2008, IEEE T VIS COMPUT GR, V14, P1731, DOI 10.1109/TVCG.2008.132
   Westermann R, 2001, COMPUT GRAPH FORUM, V20, pC443, DOI 10.1111/1467-8659.00537
   Zhu QH, 1998, COMPUT GRAPH FORUM, V17, pC275, DOI 10.1111/1467-8659.00274
   Zollhofer M, 2012, P EUR SHORT PAP, P85, DOI 10.2312/conf/EG2012/short/085-088
NR 28
TC 1
Z9 1
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2018
VL 29
IS 1
AR e1784
DI 10.1002/cav.1784
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FV0GZ
UT WOS:000424235300003
DA 2024-07-18
ER

PT J
AU Pino, AZ
   Bedia, MG
   Arbeloa, FJS
AF Zaldivar Pino, Angel
   Gonzalez Bedia, Manuel
   Seron Arbeloa, Francisco Jose
TI A parsimonious model for locomotor in virtual agents based on dynamical
   coupling with the environment
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE artificial evolution; dynamical modeling; locomotor behavior;
   oscillators networks; virtual agents
ID SYNCHRONIZATION; EMERGENCE; KURAMOTO
AB In the domain of virtual agents modeling, computationalist approaches tend to predominate. The lack of plausibility of the rules in nature provides models with a low capacity to generalize and a very limited insight into behavioral phenomena. An alternative view is that behavior could emerge as a whole from the basic principles of non-linear dynamics that underlie such behavior in the environment. This paper presents a dynamic agent endowed with a sensing device, a controller and actuators to interact with the environment. The control architecture is based on ordinary differential equations with the function of modulating the stimulus signals to action signals under a sensory-motor flow. The parameter values are defined in an evolutionary process depending on the task to be performed. A series of experiments are presented to illustrate certain qualities of our model such as the adaptability to change, a highly intuitive and flexible design methodology, and a high degree of individual autonomy, among others. We think this kind of modeling is useful in the animation world for modeling flocks, crowds, and swarms as a valid alternative to other less parsimonious techniques.
C1 [Zaldivar Pino, Angel; Gonzalez Bedia, Manuel; Seron Arbeloa, Francisco Jose] Univ Zaragoza, Adv Comp Graph Grp GIGA, Maria de Luna 1, Zaragoza 50015, Spain.
C3 University of Zaragoza
RP Pino, AZ (corresponding author), Univ Zaragoza, Adv Comp Graph Grp GIGA, Maria de Luna 1, Zaragoza 50015, Spain.
EM angelzp@gmail.com
RI Seron Arbeloa, Francisco Jose/L-3146-2014
OI Seron Arbeloa, Francisco Jose/0000-0003-1683-4694
FU Spanish "Direccion General de Investigacion" European Commission
   ALFA-Gaviota DCI-ALA [TIN2011-24660, 19.09.01 / 10 / 21526 / 245-654 /
   ALFA 111(2010) 149]
FX Spanish "Direccion General de Investigacion" European Commission
   ALFA-Gaviota DCI-ALA, Grant/Award Number: TIN2011-24660 and, 19.09.01 /
   10 / 21526 / 245-654 / ALFA 111(2010) 149
CR Acebrón JA, 2005, REV MOD PHYS, V77, P137, DOI 10.1103/RevModPhys.77.137
   Adams F, 2010, PHENOMENOL COGN SCI, V9, P619, DOI 10.1007/s11097-010-9175-x
   [Anonymous], ENCY COGNITIVE SCI
   [Anonymous], SIMPLE NONLINEAR DYN
   [Anonymous], PHYSICS
   [Anonymous], ROB AUT 2008 ICRA 20
   [Anonymous], 1992, TECHNOMETRICS, DOI DOI 10.2307/1269570
   [Anonymous], SYST RES BEHAV SCI
   [Anonymous], COMPUTER GRAPHICS FO
   [Anonymous], ARTIFICIAL LIFE
   [Anonymous], EVOLVING ROBUST ROBO
   [Anonymous], NAIVE TIME TEMPORAL
   [Anonymous], ACM T GRAPHICS
   [Anonymous], 2014, RIGID BODY DYNAMICS
   [Anonymous], CAMBRIDGE HDB ARTIFI
   [Anonymous], PERCEPTION VISUAL WO
   [Anonymous], STEERFIT AUTOMATED P
   [Anonymous], OSCILLATIONS NEURAL
   [Anonymous], ELEMENTARY ADAPTIVE
   [Anonymous], S ART LIF ALIFE
   [Anonymous], COMPUTER ANIMATION V
   [Anonymous], 1995, Mind as Motion: Explorations in the Dynamics of Cognition
   [Anonymous], SYNTHESILECT COMPU
   [Anonymous], QUALITY QUANTITY
   [Anonymous], BEHAV CHAOS METAPHOR
   Baldwin J. M., 1896, Am. Nat, V30, P441, DOI DOI 10.1086/276428
   Bechtel W, 1998, COGNITIVE SCI, V22, P295, DOI 10.1207/s15516709cog2203_2
   Beer RD, 2003, ADAPT BEHAV, V11, P209, DOI 10.1177/1059712303114001
   Beer RD, 1997, ROBOT AUTON SYST, V20, P257, DOI 10.1016/S0921-8890(96)00063-2
   Braun A., 2005, Proceedings of the ACM symposium on Virtual reality software and technology, P244
   Buzsaki Gyorgy., 2006, Rhythms of the Brain, V54
   CRUTCHFIELD JP, 1994, PHYSICA D, V75, P11, DOI 10.1016/0167-2789(94)90273-9
   GIBSON JJ, 1958, BRIT J PSYCHOL, V49, P182, DOI 10.1111/j.2044-8295.1958.tb00656.x
   Hartman C, 2006, COMPUT ANIMAT VIRT W, V17, P199, DOI 10.1002/cav.123
   Harvey I, 2005, ARTIF LIFE, V11, P79, DOI 10.1162/1064546053278991
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hinton G. E., 1987, Complex Systems, V1, P495
   Ijspeert AJ, 2001, BIOL CYBERN, V84, P331, DOI 10.1007/s004220000211
   Ijspeert AJ, 2007, SCIENCE, V315, P1416, DOI 10.1126/science.1138353
   Inglis IR, 2000, BEHAVIOUR, V137, P1567, DOI 10.1163/156853900502727
   Ju E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866162
   Langley P, 2009, COGN SYST RES, V10, P141, DOI 10.1016/j.cogsys.2006.07.004
   Moioli RC, 2010, IEEE C EVOL COMPUTAT
   Paris S, 2007, COMPUT GRAPH FORUM, V26, P665, DOI 10.1111/j.1467-8659.2007.01090.x
   Peschl MF, 1999, UNDERSTANDING REPRESENTATION IN THE COGNITIVE SCIENCES, P9
   Reynolds C.W., 1982, Proc. SIGGRAPH '82. Computer Graphics, V18, P289, DOI DOI 10.1145/800064.801293
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Schuerman M, 2010, COMPUT ANIMAT VIRT W, V21, P267, DOI 10.1002/cav.367
   Seth AK, 2010, ARTIF LIFE, V16, P179, DOI 10.1162/artl.2010.16.2.16204
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Steels Luc, 1994, Artificial Life, V1, P75, DOI 10.1162/artl.1993.1.1_2.75
   Strogatz SH, 2000, PHYSICA D, V143, P1, DOI 10.1016/S0167-2789(00)00094-4
   Thelen E., 1994, A Dynamic Systems Approach to the Development of Cognition and Action
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   VANGELDER T, 1995, J PHILOS, V92, P345, DOI 10.2307/2941061
   Vernon D, 2007, IEEE T EVOLUT COMPUT, V11, P151, DOI 10.1109/TEVC.2006.890274
NR 56
TC 0
Z9 0
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV-DEC
PY 2017
VL 28
IS 6
AR e1733
DI 10.1002/cav.1733
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO9YH
UT WOS:000417254100001
DA 2024-07-18
ER

PT J
AU Ma, W
   Zhang, Y
   Yang, LW
   Duan, LJ
AF Ma, Wei
   Zhang, Yu
   Yang, Luwei
   Duan, Lijuan
TI Graph-cut based interactive image segmentation with randomized texton
   searching
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE interactive image segmentation; graph cut; texture constraint; LBP;
   randomized texton searching
ID FEATURES; TEXTURE; COLOR
AB In the paper, we present an interactive image-segmentation method in the framework of graph cut, which incorporates not only traditional color and gradient constraints, but also a new type of texture constraint. Given an image with user-input strokes, we first establish the color and texture prior models of the foreground/background. The texture prior model, which is key to establish the texture constraints, is represented by local binary patterns (LBP) histograms. Then, an energy function composed of color, gradient, and texture terms is formulated. At last, by using graph cut, we minimize the energy function to obtain the foreground. In the energy function, the color and gradient terms have similar forms with traditional methods. The texture term in the function is generated using a proposed randomized texton-searching algorithm. First, the algorithm locates an approximately best representative texton for every unknown pixel as foreground and an approximately best one as background, through randomized searching. Second, it computes the LBP histograms of the two textons as the pixel's foreground/background texture descriptors, respectively. Finally, the distances between the descriptors and the foreground/background prior models are used to formulate the texture term. Experimental results demonstrate that our method outperforms traditional ones. Copyright (C) 2015 John Wiley & Sons, Ltd.
C1 [Ma, Wei; Zhang, Yu; Yang, Luwei; Duan, Lijuan] Beijing Univ Technol, Coll Comp Sci, Beijing, Peoples R China.
C3 Beijing University of Technology
RP Ma, W (corresponding author), Beijing Univ Technol, Coll Comp Sci, Beijing, Peoples R China.
EM mawei@bjut.edu.cn
RI Yang, Luwei/ACS-0535-2022
FU Beijing Municipal Natural Science Foundation [4152006, 4152005];
   Scientific Research Project of Beijing Educational Committee
   [KM201510005015]; Ri-Xin Talents Project of Beijing University of
   Technology [2014-RX-L06]; National Basic Research Program of China
   [2014CB349303]; Jing-Hua Talents Project of Beijing University of
   Technology [2014-JH-L06]; Importation and Development of High-Caliber
   Talents Project of Beijing Municipal Institutions [CITTCD201304035]
FX This research is supported by the Beijing Municipal Natural Science
   Foundation (4152006 and 4152005), Scientific Research Project of Beijing
   Educational Committee (KM201510005015), and Ri-Xin Talents Project of
   Beijing University of Technology (2014-RX-L06). It is also supported in
   part by the National Basic Research Program of China (no. 2014CB349303),
   Jing-Hua Talents Project of Beijing University of Technology
   (2014-JH-L06), and the Importation and Development of High-Caliber
   Talents Project of Beijing Municipal Institutions (CIT&TCD201304035).
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2010, PROC ASIAN C COMPUT
   [Anonymous], 2011, P IEEE MTT S INT MIC
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Bresson X, 2005, TECHNICAL REPORT
   Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Dandu B.R., 2012, International Journal of Computational Engineering Research, V2250-3005, P819
   Grady L, 2011, IEEE I CONF COMP VIS, P367, DOI 10.1109/ICCV.2011.6126264
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   Guo YW, 2005, COMPUT ANIMAT VIRT W, V16, P451, DOI 10.1002/cav.82
   Hadid A, 2004, PROC CVPR IEEE, P797
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huijsmans DP, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P733
   Iran T., 2010, P 9 INT SEM WEB C 20, P1
   Kohli P, 2012, INT J COMPUT VISION, V100, P261, DOI 10.1007/s11263-012-0537-4
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Liu JY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531375
   Ma W, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P557, DOI 10.1109/ACPR.2013.50
   Mäenpää T, 2003, PATTERN ANAL APPL, V6, P169, DOI 10.1007/s10044-002-0179-1
   Mortensen E. N., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P191, DOI 10.1145/218380.218442
   Nieuwenhuis C, 2014, LECT NOTES COMPUT SC, V8694, P285, DOI 10.1007/978-3-319-10599-4_19
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Santos JL, 2009, DIMACS SER DISCRET M, V74, P1
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Turtinen M, 2006, IEICE T INF SYST, VE89D, P2076, DOI 10.1093/ietisy/e89-d.7.2076
   Unger M, 2008, P BRIT MACH VIS C LE
   Wong K. C.-H., 2000, Journal of Graphics Tools, V5, P1, DOI 10.1080/10867651.2000.10487520
   Xiang SM, 2006, LECT NOTES COMPUT SC, V3851, P216
   Xiao CX, 2008, COMPUT ANIMAT VIRT W, V19, P341, DOI 10.1002/cav.249
   Zhang Y, 2014, P ACM INT C VIRT REA, P57
   Zhu YX, 2010, IEEE IMAGE PROC, P4113, DOI 10.1109/ICIP.2010.5651171
NR 35
TC 8
Z9 8
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-OCT
PY 2016
VL 27
IS 5
BP 454
EP 465
DI 10.1002/cav.1671
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DZ1QS
UT WOS:000385614100001
DA 2024-07-18
ER

PT J
AU Wang, YZ
   Serracino-Inglott, F
   Yi, XD
   Yang, XJ
   Yuan, XF
AF Wang, Yanzhen
   Serracino-Inglott, Ferdinand
   Yi, Xiaodong
   Yang, Xue-Jun
   Yuan, Xue-Feng
TI An interactive computer-based simulation system for endovascular
   aneurysm repair surgeries
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE surgery simulation; physically based modeling; haptics; endovascular
   aneurysm repair
AB This paper presents an interactive simulation system for surgical procedures of endovascular aneurysm repair. It extracts anatomical structure of clinic interest from patient-specific X-ray computed tomography or magnetic resonance imaging data by image segmentation techniques, and then reconstructs surface triangular meshes of these anatomical structures from the volumetric data. The core of the system is an interactive computer-based simulation module. It consists of a physical modeling unit, a collision detection unit, a visualization unit, and a control unit. The integration of these units together makes it possible for users to interact with the system in real time, performing virtual catheterization, angiography, and stent graft deployment under a user-specified rendering mode. The prototype system can be used as a cost-efficient tool for surgical planning with patient-specific anatomical geometry and for practice of surgical procedures before actual operation. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Wang, Yanzhen; Yi, Xiaodong; Yang, Xue-Jun] Natl Univ Def Technol, Coll Comp, HPCL, Changsha, Hunan, Peoples R China.
   [Serracino-Inglott, Ferdinand] Manchester Royal Infirm, Manchester Acad Hlth Sci Ctr, Manchester, Lancs, England.
   [Yuan, Xue-Feng] Sun Yat Sen Univ, Natl Supercomp Ctr Guangzhou, Guangzhou, Guangdong, Peoples R China.
C3 National University of Defense Technology - China; University of
   Manchester; Sun Yat Sen University
RP Wang, YZ (corresponding author), Natl Univ Def Technol, Coll Comp, HPCL, Changsha, Hunan, Peoples R China.
EM yanzhenwang@hotmail.com
RI YANG, Xue/HPI-0953-2023
CR Ackerman MJ, 1998, P IEEE, V86, P504, DOI 10.1109/5.662875
   Benedetti F, 2002, PHYS RESPONSE COLLIS
   Bro-Nielsen M, 1998, P IEEE, V86, P490, DOI 10.1109/5.662874
   Cao J., 2010, SHAP MOD INT C SMI 2, P187, DOI [DOI 10.1109/SMI.2010.25, 10.1109/SMI.2010.25]
   Chen X, 2008, PROCEEDINGS OF 2008 INTERNATIONAL PRE-OLYMPIC CONGRESS ON COMPUTER SCIENCE, VOL II, P81
   Cotin S, 1999, IEEE T VIS COMPUT GR, V5, P62, DOI 10.1109/2945.764872
   Cotin S, 2000, Stud Health Technol Inform, V70, P59
   Höfer U, 2002, CARS 2002: COMPUTER ASSISTED RADIOLOGY AND SURGERY, PROCEEDINGS, P101
   Hong F, 2014, IEEE T VIS COMPUT GR, V20, P2545, DOI 10.1109/TVCG.2014.2346416
   Lenoir J, 2006, COMPUT GRAPH-UK, V30, P416, DOI 10.1016/j.cag.2006.02.013
   Liu I, 2012, ANN IEEE SYM FIELD P, P125, DOI 10.1109/FCCM.2012.31
   Luboz V, 2005, LECT NOTES COMPUT SC, V3749, P43
   Muniyandi M, 2003, ST HEAL T, V94, P233
   Nowinski WL, 2001, INTERNATIONAL WORKSHOP ON MEDICAL IMAGING AND AUGMENTED REALITY, PROCEEDINGS, P87, DOI 10.1109/MIAR.2001.930269
   Pai DK, 2002, COMPUT GRAPH FORUM, V21, P347, DOI 10.1111/1467-8659.00594
   Svensson S, 2002, PATTERN RECOGN LETT, V23, P1419, DOI 10.1016/S0167-8655(02)00102-2
   Székely G, 2000, MED IMAGE ANAL, V4, P57, DOI 10.1016/S1361-8415(00)00002-5
   Tang M, DEFORMCD COLLISION D
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   vanWalsum T, 1997, LECT NOTES COMPUT SC, V1205, P273, DOI 10.1007/BFb0029246
   Wang F, 2007, P ANN INT IEEE EMBS, P1742, DOI 10.1109/IEMBS.2007.4352647
   Wang YZ, 2013, COMPUT ANIMAT VIRT W, V24, P25, DOI 10.1002/cav.1434
   Wu XL, 2007, LECT NOTES COMPUT SC, V4791, P557
   Zhou Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818074
NR 24
TC 4
Z9 4
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 290
EP 300
DI 10.1002/cav.1713
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300013
DA 2024-07-18
ER

PT J
AU Wang, YY
   Ruhland, K
   Neff, M
   O'Sullivan, C
AF Wang, Yingying
   Ruhland, Kerstin
   Neff, Michael
   O'Sullivan, Carol
TI Walk the talk: coordinating gesture with locomotion for conversational
   characters
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents (CASA) Conference
CY 2016
CL Geneva, SWITZERLAND
SP MIRALab, Univ Geneva, Assoc Comp Machinery Special Interest Grp Comp Graph, Eurograph Assoc
DE animation; motion capture; gesture synthesis
AB Communicative behaviors are a very important aspect of human behavior and deserve special attention when simulating groups and crowds of virtual pedestrians. Previous approaches have tended to focus on generating believable gestures for individual characters and talker-listener behaviors for static groups. In this paper, we consider the problem of creating rich and varied conversational behaviors for data-driven animation of walking and jogging characters. We captured ground truth data of participants conversing in pairs while walking and jogging. Our stylized splicing method takes as input a motion captured standing gesture performance and a set of looped full body locomotion clips. Guided by the ground truth metrics, we perform stylized splicing and synchronization of gesture with locomotion to produce natural conversations of characters in motion. Copyright (C) 2016 John Wiley & Sons, Ltd.
C1 [Wang, Yingying; Neff, Michael] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
   [Ruhland, Kerstin] Trinity Coll Dublin, Dublin, Ireland.
   [O'Sullivan, Carol] Trinity Coll Dublin, Visual Comp, Dublin, Ireland.
C3 University of California System; University of California Davis; Trinity
   College Dublin; Trinity College Dublin
RP O'Sullivan, C (corresponding author), Trinity Coll Dublin, Coll Green, Dublin 2, Ireland.
EM Carol.OSullivan@scss.tcd.ie
RI Li, Yan/JUU-5189-2023; wang, yingying/GRS-3058-2022
OI Wang, Yingying/0000-0002-5680-1929; O'Sullivan,
   Carol/0000-0003-3772-4961
CR Al-Ghreimil N., 2003, WSCG 03
   Bohus D., 2010, PROC INT C MULTIMODA, P1, DOI DOI 10.1145/1891903.1891910
   BRITON NJ, 1995, SEX ROLES, V32, P79, DOI 10.1007/BF01544758
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Efron D., 1941, GESTURE ENV
   Ennis C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778828
   Fernandez-Baena A., 2013, P INT C COMPUTER GRA, P3
   Gleicher M, 2008, ACM SIGGRAPH 2008 CL
   Heck R, 2006, COMPUT GRAPH FORUM, V25, P459, DOI 10.1111/j.1467-8659.2006.00965.x
   Hoyet L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508367
   Kendon A., 1980, The relationship of verbal and nonverbal communication, P207, DOI [10.1515/9783110813098.207, DOI 10.1515/9783110813098.207]
   Kirchhof C., 2012, INT SOC GESTURE STUD
   Kita S., 1997, GESTURE SIGN LANGUAG, P23
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Levine S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778861
   Levine S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618518
   Majkowska A, 2006, P 2006 ACM SIGGRAPH, P309, DOI DOI 10.1145/1218064.1218106
   Marsella S, 2004, COG TECH, P317
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   McNeill D., 2005, GESTURE THOUGHT, DOI DOI 10.7208/CHICAGO/9780226514642.001.0001
   Mousas C, 2013, PROCEDIA COMPUT SCI, V25, P348, DOI 10.1016/j.procs.2013.11.042
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   Ng W, 2010, ACM SIGGRAPH ASIA 20
   Pengcheng Luo, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P254, DOI 10.1007/978-3-642-34710-8_24
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Stone M, 2004, ACM T GRAPHIC, V23, P506, DOI 10.1145/1015706.1015753
   Tamada K., 2010, SHORT PAPERS COMPUTE, V3
   Yingying Wang, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P180, DOI 10.1007/978-3-642-40415-3_16
NR 29
TC 1
Z9 1
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2016
VL 27
IS 3-4
BP 369
EP 377
DI 10.1002/cav.1703
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA DW0WI
UT WOS:000383363300021
DA 2024-07-18
ER

PT J
AU Wong, SK
   Fu, IT
AF Wong, Sai-Keung
   Fu, I-Ting
TI Hybrid-based snow simulation and snow rendering with shell textures
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents 2015 (CASA) Conference
CY MAY 11-13, 2015
CL Singapore, SINGAPORE
DE snow rendering; snow simulation; hybrid structure; mass-spring system;
   grid
AB In this study, we develop a system for interactive snow simulation and rendering. Snow is modeled as a hybrid structure that handles movable snow and static snow separately. We develop a simple approach to convert between these two types of snow. Movable snow is represented by a set of particles, whereas static snow is modeled as grid cells. For a piece of movable snow (e.g., snowflake), the particles are connected using springs. Thus, we can model snow as a type of brittle material, such as a snow pile split into chunks of smaller snow pieces after a collision. To render the snow, we adopt a shell structure that has a series of concentric, semitransparent, textured shells. We applied our system to several examples, with the rendered snow appearing similar to real snow. Copyright (c) 2015John Wiley & Sons, Ltd.
C1 [Wong, Sai-Keung; Fu, I-Ting] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Wong, SK (corresponding author), Natl Chiao Tung Univ, Hsinchu, Taiwan.
EM cswingo@cs.nctu.edu.tw
FU National Science Council of ROC (Taiwan) [NSC 102-2221-E-009-103-MY2];
   Ministry of Science and Technology of ROC (Taiwan) [MOST
   103-2221-E-009-122-MY3]
FX We would like to thank all the reviewers for the constructive comments.
   This work was supported by the National Science Council of ROC (Taiwan)
   under grant number NSC 102-2221-E-009-103-MY2 and the Ministry of
   Science and Technology of ROC (Taiwan) under grant number MOST
   103-2221-E-009-122-MY3.
CR Alduans I, 2009, P C ESP INF GRAF, P1
   [Anonymous], IPSJ SIG TECHNICAL R
   ARMSTRONG RL, 1980, J GLACIOL, V26, P283, DOI 10.3189/S0022143000010820
   Bell N., 2005, P 2005 ACM SIGGRAPH, P77, DOI DOI 10.1145/1073368.1073379
   Chen KC, 2013, COMPUT GRAPH-UK, V37, P963, DOI 10.1016/j.cag.2013.08.004
   Chen YY, 2003, J VISUAL COMP ANIMAT, V14, P21, DOI 10.1002/vis.301
   Fan NM, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P29, DOI 10.1109/ICICEE.2012.16
   Fearing P, 2000, COMP GRAPH, P37, DOI 10.1145/344779.344809
   Greens S., 2008, VOLUMETRIC PARTICLE
   Greens S, 2010, PRATICLE SIMULATION
   Haglund H., 2002, P SIGRAD, P11
   Jiangian Ning, 2011, Transactions on Edutainment VI, P193, DOI 10.1007/978-3-642-22639-7_19
   Lengyel J., 2001, P 2001 S INTERACTIVE, P227, DOI [10.1145/364338.364407, DOI 10.1145/364338.364407]
   Lius F, 2010, THESIS UPPSALA U UPP
   LUCIANI A, 1995, GRAPH INTER, P136
   Nishita T, 1997, COMPUT GRAPH FORUM, V16, pC357, DOI 10.1111/1467-8659.00173
   Ohlsson P., 2004, Proceedings of SIGRAD, P25
   Onoue K, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P252, DOI 10.1109/PCCGA.2003.1238267
   Painters TH, 2011, ENCY SNOW ICE GLACIE, P1050
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Sumner RW, 1999, COMPUT GRAPH FORUM, V18, P17, DOI 10.1111/1467-8659.00299
   Tan J, 2011, PROCEDIA ENVIRON SCI, V10, P1244, DOI 10.1016/j.proenv.2011.09.199
   Willemsens PJ, 2011, SNOW RENDERING INTER
   Yans L-Q, 2014, ACM T GRAPHIC, V33
   Zeng YL, 2007, COMPUT ANIMAT VIRT W, V18, P289, DOI 10.1002/cav.209
   Zhus B, 2010, EUROGRAPHICS SHORT P
NR 26
TC 8
Z9 9
U1 2
U2 38
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2015
VL 26
IS 3-4
BP 413
EP 421
DI 10.1002/cav.1644
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA CH8CW
UT WOS:000354264700023
OA Bronze
DA 2024-07-18
ER

PT J
AU Lee, SG
   Shin, BS
AF Lee, Sang-Gil
   Shin, Byeong-Seok
TI Contour-based polygonal ambient occlusion using a single-depth texture
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE visualization; real-time rendering; global illumination; ambient
   occlusion; screen-space ambient occlusion; the contour level
AB We present a novel approximation of a global illumination technique called contour-based polygonal ambient occlusion, an approach that darkens by only using a depth texture as screen-space ambient occlusion without additional information such as a normal buffer. We introduce a discrete level structure to calculate the amount of occlusion by using the contour level, an integer value derived from the depth difference of neighboring texels. We use the uniform sampling to define the positions of the neighboring texels in the depth texture. Our method does not depend on geometric complexity because our method works in screen space and works well for both static and dynamic scenes without any precomputation. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Lee, Sang-Gil; Shin, Byeong-Seok] Inha Univ, Dept Comp Sci & Informat Engn, Inchon, South Korea.
C3 Inha University
RP Shin, BS (corresponding author), Inha Univ, Dept Comp Sci & Informat Engn, Inchon, South Korea.
EM bsshin@inha.ac.kr
FU Next-Generation Information Computing Development Program through the
   National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology [2012M3C4A7032781]; INHA University Research
   Grant
FX This research was supported by the Next-Generation Information Computing
   Development Program through the National Research Foundation of Korea
   (NRF) funded by the Ministry of Education, Science and Technology (No.
   2012M3C4A7032781). This work was supported by the INHA University
   Research Grant.
CR [Anonymous], 2006, Advanced Global Illumination
   [Anonymous], 2009, P S INT 3D GRAPH GAM, DOI 10.1145/1507149.1507161.5,7
   Bavoil L, 2009, ACM SIGGRAPH 2009
   Bavoil Louis., 2009, SHADERX7 ADV RENDERI
   Christensen PH, 1997, P EUR WORKSH REND TE, P321
   Cohen M. F., 1985, Computer Graphics, V19, P31, DOI 10.1145/325165.325171
   DIMITROV R, 2008, I3D 08 P 2008 S INT, P1
   Everitt C, 2001, INTERACTIVE ORDER IN
   Filion D., 2008, SIGGRAPH 08, P133, DOI DOI 10.1145/1404435.1404441
   Fox M., 2008, GAME DEV MAGAZINE
   Gaitatzes A, 2008, JOURNAL WSCG, V16, P17
   Goral C., 1984, COMPUTER GRAPHICS P, V18, P212
   Huang J, 2011, EUROGRAPHICS 2011 SH, P29
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Kajiya J. T., 1986, SIGGRAPH, P143, DOI 10.1145/15886.15902
   Kontkanen Janne, 2005, P 2005 S INT 3D GRAP, P41, DOI 10.1145/1053427.1053434
   Landis H, 2002, P C ACM SIGGRAPH 200
   Leadwerks Team, LEADW ENG
   Luft T, 2006, ACM T GRAPHIC, V25, P1206, DOI 10.1145/1141911.1142016
   Mittring M., 2007, ACM SIGGRAPH 2007 CO, P97, DOI [DOI 10.1145/1281500.1281671, 10.1145/1281500.1281671]
   Nelson LM, 1998, VISUAL COMPUT, V4, P109
   Ogre Team, SCREEN SPAC AMB OCCL
   Perlin K.H., 1989, 16 ANN C COMP GRAPH, P253, DOI 10.1145/74333.74359
   PHARR M., 2004, GPU GEMS PROGRAMMING, P279
   Ritschel T, 2012, COMPUT GRAPH FORUM, V31, P160, DOI 10.1111/j.1467-8659.2012.02093.x
   Sloan PJ, 2000, P EUR WORKSH REND TE
   Wang R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531397
   WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882
   Zhukov S., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P45
NR 29
TC 0
Z9 0
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2015
VL 26
IS 1
BP 69
EP 77
DI 10.1002/cav.1567
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CC1LW
UT WOS:000350103200007
DA 2024-07-18
ER

PT J
AU Chen, X
   Feng, JQ
AF Chen, Xue
   Feng, Jieqing
TI Adaptive skeleton-driven cages for mesh sequences
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE adaptive cage generation; skeleton-driven; mesh sequence representation
ID DEFORMATION
AB The design of a compact and effective representation is a critical step in fully utilizing the abundant raw mesh-based animation resources. In this paper, we present a high-level control structure for animated mesh sequences referred to as an adaptive skeleton-driven cage representation. This approach combines a skeleton and cage to express time-varying shape details and offer flexible control for rigid limb motions. The initial skeleton is inferred by sketching on the rest pose mesh. The corresponding cage is constructed by using an adaptive cross-section-based method. Then, the initial skeleton and cage are propagated to the other meshes in the sequence. Additionally, the generated cage sequence can be automatically refined to improve the mesh reconstruction quality. Our results and comparisons demonstrate that the proposed approach is an intuitive, compact, and efficient representation. We demonstrate its potential through a variety of applications, such as animation compression, deformation transfer and pose editing. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Chen, Xue; Feng, Jieqing] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Feng, JQ (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM jqfeng@cad.zju.edu.cn
FU National Natural Science Foundation of China [61170138, 60933007];
   Program for New Century Excellent Talents in University [NCET-10-0728]
FX We would like to thank the anonymous reviewers for their valuable
   comments and Jean-Marc Thiery for sharing the horse cage sequence. This
   work is supported by the National Natural Science Foundation of China
   under Grant nos. 61170138, 60933007 and the Program for New Century
   Excellent Talents in University under Grant no. NCET-10-0728.
CR Ben-Chen M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531340
   Ben-Chen Mirela, 2009, P 2009 ACM SIGGRAPH, P67
   Buss SR, 2001, ACM T GRAPHIC, V20, P95, DOI 10.1145/502122.502124
   Chen CH, 2013, VISUAL COMPUT, V29, P241, DOI 10.1007/s00371-012-0759-z
   CHEN SE, 1989, IEEE COMPUT GRAPH, V9, P47, DOI 10.1109/38.20333
   Daniel V, 2008, ACM T GRAPHIC, V27, P97
   de Aguiar E., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P198, DOI 10.1109/SIBGRAPI.2012.35
   de Aguiar E, 2008, COMPUT GRAPH FORUM, V27, P389, DOI 10.1111/j.1467-8659.2008.01136.x
   de Aguiar E, 2014, COMPUT GRAPH-UK, V38, P10, DOI 10.1016/j.cag.2013.07.007
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Duveau E, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P206, DOI 10.1109/3DIMPVT.2012.29
   Gao L, 2013, COMPUT GRAPH FORUM, V32, P449, DOI 10.1111/cgf.12065
   García FG, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487232
   Joshi P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239522
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Ju T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409075
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Popa T, 2010, COMPUT GRAPH FORUM, V29, P1633, DOI 10.1111/j.1467-8659.2010.01772.x
   Savoye Y, 2011, LECT NOTES COMPUT SC, V6494, P599, DOI 10.1007/978-3-642-19318-7_47
   Sellamani S., 2010, COMPUT AIDED DESIGN, V7, P601
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Thiery JM, 2012, COMPUT GRAPH FORUM, V31, P2303, DOI 10.1111/j.1467-8659.2012.03159.x
   Xu W., 2007, ACM T GRAPHICS SIGGR, V26
   Yao CY, 2009, COMPUT ANIMAT VIRT W, V20, P101, DOI 10.1002/cav.313
NR 24
TC 7
Z9 8
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2014
VL 25
IS 3-4
SI SI
BP 447
EP 455
DI 10.1002/cav.1577
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AJ2WD
UT WOS:000337524300025
DA 2024-07-18
ER

PT J
AU Zhang, MM
   Pan, ZG
   Huang, XX
   Xiang, N
   Wang, SW
   Zhu, PY
AF Zhang, Mingmin
   Pan, Zhigeng
   Huang, Xixi
   Xiang, Nan
   Wang, Shuwen
   Zhu, Pengyu
TI EasyHome: an online virtual home decoration system
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE virtual reality; virtual house design and decoration; texture collage;
   web interaction
ID DESIGN
AB This paper provides an online virtual 7home decoration system, which integrates web interaction technique into virtual home decoration. The main functions of this system include house design, house decoration, and data management. For the house design, an automatic joint method of the walls is proposed, in order to design various house. For the house decoration, we introduce the wall decoration principle corresponding to the algorithm of discretization on the walls, which contains doors or windows, and triangularization on the irregular floors. To variety of different textures and collage regulations, we provide a new texture collage mapping method. Technology of rendering to texture is used to generate a small geometry texture, which will be mapped into a large target object on the basis of the texture's structural properties. As a result, the whole texture continuity is also maintained. In data management aspect, we embed a browser into this system so that users can conveniently obtain decoration models on the basis of web interaction. After these models have been downloaded, they can be shown in virtual scene according to guide information. In addition, some quotation lists can be generated automatically. Experimental results show that an authentic house can be easily presented in our system. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
   [Pan, Zhigeng] Hangzhou Normal Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Hangzhou Normal University
RP Pan, ZG (corresponding author), Hangzhou Normal Univ, Hangzhou, Zhejiang, Peoples R China.
EM zmm@cad.zju.edu.cn
RI Zhang, Miao/JXY-8985-2024; zhang, mm/IWV-4201-2023
OI Pan, Zhi-geng/0000-0003-0717-5850
FU NSFC [61173124, 61170318]; Greentown Electronic Commerce Co., Ltd.
FX The system is a result of teamwork; around 15 people are engaged in the
   system design and implementation. The project is financially supported
   by the Greentown Electronic Commerce Co., Ltd. The authors would like to
   thank other people who accomplish the other parts of the Virtual Home
   Decoration System together; they are Hao Ge, Rongzhao Li, Ze Zheng, Yong
   Lin, Feifei Song, Jun Li, Xuan Chen et al. This paper is also supported
   by NSFC (Grant nos. 61173124 and 61170318).
CR Chazalet A., 2011, P MIDDL 2011 IND TRA, P1
   Elber G, 2005, IEEE COMPUT GRAPH, V25, P66, DOI 10.1109/MCG.2005.79
   Guanhua Wang, 2011, Proceedings of the 2011 Third International Conference on Communications and Mobile Computing (CMC 2011), P182, DOI 10.1109/CMC.2011.25
   Jaglarz A, 2011, LECT NOTES COMPUT SC, V6767, P358, DOI 10.1007/978-3-642-21666-4_39
   Jiang L, 2006, ICAT 2006: 16TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE - WORSHOPS, PROCEEDINGS, P89
   Kotnik T, 2010, INT J ARCHIT COMPUT, V8, P1, DOI 10.1260/1478-0771.8.1.1
   Kwee V, 2006, P 4 INT C COMP GRAPH, P191
   Lee TY, 2007, INT J COMPUT SCI ENG, V3, P71
   Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787
   McFarlane DC, 2002, HUM-COMPUT INTERACT, V17, P1, DOI 10.1207/S15327051HCI1701_1
   Ouramdane N., 2006, P 2006 ACM INT C VIR, P137
   Oxman R, 2006, DESIGN STUD, V27, P229, DOI 10.1016/j.destud.2005.11.002
   Oxman R, 2008, DESIGN STUD, V29, P99, DOI 10.1016/j.destud.2007.12.003
   Pan ZG, 2004, SPRING INT SER ENG C, P309
   Porquet D., 2005, Proceedings of the 3rd International Conference on Computer Graphics and Interactive Techniques in Australasia and South East Asia, GRAPHITE'05, P213, DOI DOI 10.1145/1101389.1101432
   Run-tao Liu, 2002, Journal of Software, V13, P1309
   Shi L, 2005, LECT NOTES COMPUT SC, V3482, P190
   Singh Jeetinder, 2010, Proceedings of the Third IEEE International Conference on Digital Game and Intelligent Toy Enhanced Learning (DIGITEL 2010), P38, DOI 10.1109/DIGITEL.2010.25
   Stine DJ, 2009, RESIDENTIAL DESIGN U
   Wei Li-Yi., 2004, SIGGRAPHEUROGRAPHICS, P55
   Williams ME, 2005, ADV ENG SOFTW, V36, P709, DOI 10.1016/j.advengsoft.2005.03.017
   Yen-Chun Lin, 2009, WSEAS Transactions on Computers, V8, P312
NR 22
TC 1
Z9 1
U1 3
U2 27
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2014
VL 25
IS 2
BP 101
EP 113
DI 10.1002/cav.1549
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AE8SY
UT WOS:000334273500002
DA 2024-07-18
ER

PT J
AU Kim, J
   Seol, Y
   Lee, J
AF Kim, Jongmin
   Seol, Yeongho
   Lee, Jehee
TI Human motion reconstruction from sparse 3D motion sensors using kernel
   CCA-based regression
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE motion reconstruction; performance animation; motion capture; sensor;
   machine learning
AB This paper presents a real-time performance animation system that reproduces full-body character animation based on sparse three-dimensional (3D) motion sensors on a performer. Producing faithful character animation from this setting is a mathematically ill-posed problem, because input data from the sensors are not sufficient to determine the full degrees of freedom of a character. Given the input data from 3D motion sensors, we select similar poses from a motion database and build an online local model that transforms the low-dimensional input signal into a high-dimensional character pose. A regression method based on kernel canonical correlation analysis (CCA) is employed, because it effectively handles a wide variety of motions. Examples show that various human motions are naturally reproduced by the proposed method. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Kim, Jongmin; Seol, Yeongho; Lee, Jehee] Seoul Natl Univ, Dept Comp Sci & Engn, Movement Res Lab, Seoul 151742, South Korea.
C3 Seoul National University (SNU)
RP Lee, J (corresponding author), Seoul Natl Univ, Dept Comp Sci & Engn, Movement Res Lab, Seoul 151742, South Korea.
EM jehee@mrl.snu.ac.kr
RI Seol, Yeongho/KIE-6801-2024; Lee, Jehee/V-7545-2019
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) [2007-0056094, 2011-0018340]
FX We would like to thank all the members of the Movement Research
   Laboratory for their help. This research was supported by Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   (No. 2007-0056094 and No.2011-0018340).
CR [Anonymous], 2010, SCA'10: proceedings of the 2010 ACM SIGGRAPH/Eurographics symposium on computer animation, DOI [10.2312/SCA/SCA10/001-010, DOI 10.2312/SCA/SCA10/001-010]
   ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573
   Badler N.I., 1993, PRESENCE-VIRTUAL AUG, V2, P82, DOI 10.1162/pres.1993.2.1.82
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Chai J, ACM T GRAPHICS SIGGR, V26
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Davis T.A., 2012, UMFPACK VERSION 5 6
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Feng W-W, ACM T GRAPHICS SIGGR, V27, P1
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Huang HD, 2012, IEEE T VIS COMPUT GR, V18, P1215, DOI 10.1109/TVCG.2012.88
   InterSense, 2010, IS 900 SYST
   KangKang Yin, 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P329
   Lee J, ACM T GRAPHICS SIGGR, V21, P491
   Lee J, 2008, IEEE COMPUT GRAPH, V28, P75, DOI 10.1109/MCG.2008.37
   Lee Y, ACM T GRAPHICS SIGGR, V29, P129
   Liu G., 2006, P 2006 S INTERACTIVE, P35, DOI [DOI 10.1145/1111411.1111418, 10.1145/1111411.1111418.]
   Liu H, 2011, S INTERACTIVE 3D GRA, P133
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Mount DM, 2010, LIB APPROXIMATE NEAR
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Shin HJ, 2006, COMPUTER ANIMATION V, V17
   Slyper R, 2008, P 2008 ACM SIGGRAPHE, P193
   Tautges J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966397
   Wei X, 2009, IEEE COMPUT GRAPH, V31, P78
NR 26
TC 9
Z9 9
U1 0
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD NOV
PY 2013
VL 24
IS 6
BP 565
EP 576
DI 10.1002/cav.1557
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 273QL
UT WOS:000328551100005
DA 2024-07-18
ER

PT J
AU Akinci, N
   Cornelis, J
   Akinci, G
   Teschner, M
AF Akinci, Nadir
   Cornelis, Jens
   Akinci, Gizem
   Teschner, Matthias
TI Coupling elastic solids with smoothed particle hydrodynamics fluids
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT Computer Animation and Social Agents Conference (CASA)
CY 2013
CL Istanbul, TURKEY
DE physically based animation; fluid simulation; smoothed particle
   hydrodynamics; fluidsolid coupling
AB We propose a method for handling elastic solids in smoothed particle hydrodynamics fluids. Our approach samples triangulated surfaces of solids using boundary particles. To prevent fluid particle tunneling in case of large expansions, additional boundary particles are adaptively generated to prevent gaps and undesired leakage. Furthermore, as an object compresses, particles are adaptively removed to avoid unnecessary computations. We demonstrate that our approach produces plausible interactions of smoothed particle hydrodynamics fluids with both slowly and rapidly deforming solids. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Akinci, Nadir; Cornelis, Jens; Akinci, Gizem; Teschner, Matthias] Univ Freiburg, Comp Graph Grp, D-79106 Freiburg, Germany.
C3 University of Freiburg
RP Akinci, N (corresponding author), Univ Freiburg, Comp Graph Grp, Hugstetter Str 55, D-79106 Freiburg, Germany.
EM naadir@gmail.com; cornelij@informatik.uni-freiburg.de;
   gakinci@informatik.uni-freiburg.de; teschner@informatik.uni-freiburg.de
FU German Research Foundation (DFG) [SFB/TR-8, TE 632/1-2]; NVIDIA ARC GmbH
FX We thank the reviewers for their helpful comments. This project is
   supported by the German Research Foundation (DFG) under contract numbers
   SFB/TR-8 and TE 632/1-2. We also thank NVIDIA ARC GmbH for supporting
   this work.
CR Akinci G, 2012, COMPUT GRAPH FORUM, V31, P1797, DOI 10.1111/j.1467-8659.2012.02096.x
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Allard J, 2011, SIGGR TALKS VANC BRI
   [Anonymous], 2001, Game developers conference
   Becker M, 2009, IEEE T VIS COMPUT GR, V15, P493, DOI 10.1109/TVCG.2008.107
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bell N., 2005, P 2005 ACM SIGGRAPH, P77, DOI DOI 10.1145/1073368.1073379
   Botsch M., 2004, PROC EUROGRAPHICS AC, P185, DOI [10.1145/1057432.1057457, DOI 10.1145/1057432.1057457]
   Clavet S., 2005, SCA '05, P219, DOI DOI 10.1145/1073368.1073400
   Corbett R. D., 2005, THESIS U BRIT COLUMB
   COUMANS E., 2011, BULLET PHYS LIB VERS
   Dalrymple RA, 2001, COASTAL DYNAMICS '01: PROCEEDINGS, P779
   Du P, 2012, VRCAI 12, P309
   Harada T., 2007, P COMP GRAPH INT
   Hill JrFS., 1994, Graphics gems IV, P138, DOI [10.1016/B978-0-12-336156-1.50023-9, DOI 10.1016/B978-0-12-336156-1.50023-9]
   Ihmsen M., 2010, P VRIPHYS, P79
   Keiser R., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P125, DOI 10.1109/PBG.2005.194073
   Lenaerts T, 2008, ACM SIGGRAPH 2008 PO
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   NVIDIA ARC, 2011, MENT RAY 3 9
   Oh S, 2009, COMPUT ANIMAT VIRT W, V20, P215, DOI 10.1002/cav.290
   Robinson-Mosher A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360645
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Yang LP, 2012, COMPUT GRAPH FORUM, V31, P2037, DOI 10.1111/j.1467-8659.2012.03196.x
NR 27
TC 47
Z9 71
U1 3
U2 48
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 195
EP 203
DI 10.1002/cav.1499
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 145GP
UT WOS:000319003500007
DA 2024-07-18
ER

PT J
AU Bozgeyikli, G
   Bozgeyikli, E
   Isler, V
AF Bozgeyikli, Gamze
   Bozgeyikli, Evren
   Isler, Veysi
TI Introducing tangible objects into motion controlled gameplay using
   Microsoft® Kinect TM
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE tangible; Kinect; motion controlled video games; motion tracking
AB Improvements in ways of game controlling in recent years yielded higher level of interaction. Release of motion controller devices changed conventional ways of controlling games that have been used so far. Microsoft (R); Kinect(Microsoft Corporation, WA, USA) recognizes motions of the players as game controlling inputs. Although touchless interaction is perceived to be attractive, games mimicking real life activities may benefit from hand-held tangible objects for the player to get more involved into game. In this study, a tangible gameplay interaction method is developed using Microsoft (R); Kinectthat senses hand-held objects with their dimensions and incorporates them into gameplay. Proposed algorithm is implemented on an experimental game, and a user study is performed to measure effects of tangible interaction on Kinect gameplay experience. Results revealed that an improved gameplay with more natural and accurate motion controlling is achieved. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Bozgeyikli, Gamze; Bozgeyikli, Evren; Isler, Veysi] Middle E Tech Univ, Inst Informat, TR-06531 Ankara, Turkey.
   [Bozgeyikli, Gamze; Bozgeyikli, Evren; Isler, Veysi] Middle E Tech Univ, Modeling & Simulat Res & Dev Ctr, Game & Animat Technol Res Lab, TR-06531 Ankara, Turkey.
   [Isler, Veysi] Middle E Tech Univ, Dept Comp Engn, TR-06531 Ankara, Turkey.
C3 Middle East Technical University; Middle East Technical University;
   Middle East Technical University
RP Bozgeyikli, G (corresponding author), Middle E Tech Univ, Inst Informat, TR-06531 Ankara, Turkey.
EM bozgeyik@metu.edu.tr
RI Isler, Veysi/A-6801-2016
OI Isler, Veysi/0000-0003-0174-7600
CR Bowman DA, 1998, IEEE COMPUT GRAPH, V18, P9, DOI 10.1109/38.708555
   Bozgeyikli G, 2012, THESIS MIDDLE E TU
   Brown M, 2010, HUM-COMPUT INT-SPRIN, P209, DOI 10.1007/978-1-84882-963-3_12
   Calvillo-Gámez EH, 2010, HUM-COMPUT INT-SPRIN, P47, DOI 10.1007/978-1-84882-963-3_4
   Cheok AD, 2011, COMPUTERS ENTERTAINM, V9, P4
   HARFIELD A, 2009, P 8 INT C INT DES CH, P178, DOI DOI 10.1145/1551788.1551822
   Hornecker Eva, 2011, Interactions, V18, P19, DOI 10.1145/1925820.1925826
   Ishii H., 1999, CHI'99 Proceedings, P394, DOI [10.1145/ 302979.303115, DOI 10.1145/302979.303115]
   LaViola JJ, 2011, ACM SIGGRAPH 2011 CO, P1
   Lok B, 2003, PRESENCE-VIRTUAL AUG, V12, P615, DOI 10.1162/105474603322955914
   Moore ME, 2006, INTRO GAME IND DES D
   Raymond M, 1996, P ROY SOC B-BIOL SCI, V263, P1627, DOI 10.1098/rspb.1996.0238
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Spina-Caza L, 2010, TEI 2010, P299
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Wiebe EN, 2009, COMPUT EDUC, V53, P667, DOI 10.1016/j.compedu.2009.04.004
   Yao L., 2011, C HUM FACT COMP SYST, P1729, DOI [10.1145/1979742.1979836, DOI 10.1145/1979742.1979836]
NR 17
TC 3
Z9 3
U1 1
U2 24
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 429
EP 441
DI 10.1002/cav.1513
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500030
DA 2024-07-18
ER

PT J
AU Huang, CG
   Huang, TS
   Lin, WC
   Chuang, JH
AF Huang, Cheng-Guo
   Huang, Tsung-Shian
   Lin, Wen-Chieh
   Chuang, Jung-Hong
TI Physically based cosmetic rendering
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE skin rendering; translucent rendering; cosmetic rendering
ID MODEL
AB Simulating realistic makeup effects is one of the important research issues in the 3D facial animation and cosmetic industry. Existing approaches based on image processing techniques, such as warping and blending, have been mostly applied to transfer one's makeup to another's. Although these approaches are intuitive and need only makeup images, they have some drawbacks, for example, distorted shapes and fixed viewing and lighting conditions. In this paper, we propose an integrated approach, which combines the KubelkaMunk model and a screen-space skin rendering approach, to simulate 3D makeup effects. The KubelkaMunk model is used to compute total transmittance when light passes through cosmetic layers, whereas the screen-space translucent rendering approach simulates the subsurface scattering effects inside human skin. The parameters of KubelkaMunk model are obtained by measuring the optical properties of different cosmetic materials, such as foundations, blushes, and lipsticks. Our results demonstrate that the proposed approach is able to render realistic cosmetic effects on human facial models, and different cosmetic materials and styles can be flexibly applied and simulated in real time. Copyright (c) 2013 John Wiley & Sons, Ltd.
C1 [Huang, Cheng-Guo; Huang, Tsung-Shian; Lin, Wen-Chieh; Chuang, Jung-Hong] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lin, WC (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM wclin@cs.nctu.edu.tw
FU Taiwan National Science Council [101-2221-E-009-156-MY2,
   101-2628-E-009-021-MY3]; UST-UCSD International Center of Excellence in
   Advanced Bioengineering; Taiwan National Science Council I-RiCE Program
   [NSC-101-2911-I-009-101]
FX This work was supported in part by the Taiwan National Science Council
   (101-2221-E-009-156-MY2, 101-2628-E-009-021-MY3) and the UST-UCSD
   International Center of Excellence in Advanced Bioengineering sponsored
   by the Taiwan National Science Council I-RiCE Program under Grant
   Number: NSC-101-2911-I-009-101. We would like to thank Next Media CO.,
   LTD. for the support of Light Stage and the captured human models and
   Taiwan Industrial Technology Research Institute for the support of
   spectroradiometer and cosmetic samples.
CR [Anonymous], 2007, P 18 EUROGRAPHICS C, DOI [10.2312/EGWR/EGSR07/183-194., DOI 10.2312/EGWR/EGSR07/183-194.6]
   dEon E., 2007, P EUR S REND TECHN, P147
   Doi M, 2005, LECT NOTES COMPUT SC, V3540, P95
   Donner C, 2005, ACM T GRAPHIC, V24, P1032, DOI 10.1145/1073204.1073308
   Donner C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409093
   Dorsey J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P387, DOI 10.1145/237170.237278
   Ghosh A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409092
   Guo D, 2009, PROC CVPR IEEE, P73, DOI 10.1109/CVPRW.2009.5206833
   Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319
   Jimenez J, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1609967.1609970
   Kelemen Cs., 2001, Eurographics 2001, Short papers, P25, DOI [10.2312/egs.20011003, DOI 10.2312/EGS.20011003]
   Kortm G., 1969, REFLECTANCE SPECTROS, DOI DOI 10.1007/978-3-642-88071-1
   Krishnaswamy A, 2004, COMPUT GRAPH FORUM, V23, P331, DOI 10.1111/j.1467-8659.2004.00764.x
   Moriuchi Y, 2009, LECT NOTES COMPUT SC, V5575, P138, DOI 10.1007/978-3-642-02230-2_15
   Scherbaum K, 2011, COMPUT GRAPH FORUM, V30, P485, DOI 10.1111/j.1467-8659.2011.01874.x
   Tong WS, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P211, DOI 10.1109/PG.2007.31
NR 16
TC 6
Z9 7
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY-AUG
PY 2013
VL 24
IS 3-4
BP 275
EP 283
DI 10.1002/cav.1523
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 145GP
UT WOS:000319003500015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cramer, H
   Kemper, N
   Amin, A
   Wielinga, B
   Evers, V
AF Cramer, Henriette
   Kemper, Nicander
   Amin, Alia
   Wielinga, Bob
   Evers, Vanessa
TI 'Give me a hug': the effects of touch and autonomy on people's responses
   to embodied social agents
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE social agents; human-robot interaction; social behaviour; touch;
   autonomy; proactive behaviour
ID TRUST
AB Embodied social agents are programmed to display human-like social behaviour to increase intuitiveness of interacting With these agents. It is yet unclear what the differences in peoples' responses are to different types of agents' social behaviours. One example is touch. Despite robots' physical embodiment and increasing autonomy, the effect of communicative touch has been a Mostly overlooked aspect of human-robot interaction. This Video-based, 2x2 between-subject survey experiment (N = 119) found that the combination of touch and proactivity influenced whether people saw the robot as machine-like and dependable. Furthermore, participants' attitude toward robots in general was found to influence perceived closeness between a human and a robot. Results show that communicative touch could be considered a more appropriate behaviour for proactive agents rather than reactive agents. Also, people that art! generally more positive towards robots find robots that interact by touch less machine-like. These effects illustrate that careful consideration is necessary When incorporating social behaviours in agents' physical interaction design. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Cramer, Henriette] Univ Amsterdam, Human Comp Studies Lab, NL-1098 XG Amsterdam, Netherlands.
C3 University of Amsterdam
RP Cramer, H (corresponding author), Univ Amsterdam, Human Comp Studies Lab, Sci Pk 107, NL-1098 XG Amsterdam, Netherlands.
EM hcramer@uva.nl
CR [Anonymous], 2003, THESIS MIT
   ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596
   Breazeal C, 2006, ROBOT AUTON SYST, V54, P385, DOI 10.1016/j.robot.2006.02.004
   Castelfranchi C, 2000, APPL ARTIF INTELL, V14, P799, DOI 10.1080/08839510050127560
   CHEVERST K, 2001, MOBILE HCI 01
   Desmond PA, 1998, TRANSPORT RES REC, P8, DOI 10.3141/1628-02
   EVERS M, 2008, P HRI 08 ACM NEW YOR, P255
   FISHER JD, 1976, SOCIOMETRY, V39, P416, DOI 10.2307/3033506
   Guéguen N, 2002, PERCEPT MOTOR SKILL, V95, P355, DOI 10.2466/PMS.95.5.355-360
   Hinds PJ, 2004, HUM-COMPUT INTERACT, V19, P151, DOI 10.1207/s15327051hci1901&2_7
   Hook K., 1997, IUI97. 1997 International Conference on Intelligent User Interfaces, P179, DOI 10.1145/238218.238320
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Jameson A., 2002, Adaptive Hypermedia and Adaptive Web-Based Systems. Second International Conference, AH 2002. Proceedings (Lecture Notes in Computer Science Vol.2347), P193
   Kim T., 2006, 15 IEEE INT S ROB HU, P80, DOI DOI 10.1109/ROMAN.2006.314398
   Lee KM, 2006, INT J HUM-COMPUT ST, V64, P962, DOI 10.1016/j.ijhcs.2006.05.002
   Lohse Manja, 2007, P AISB 07
   MACDORMAN KF, 2006, P C COGN SCI WORKSH
   MAJOR B, 1982, J NONVERBAL BEHAV, V6, P148, DOI 10.1007/BF00987064
   Nomura T, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P35, DOI 10.1109/ROMAN.2004.1374726
   Parasuraman R, 2004, COMMUN ACM, V47, P51, DOI 10.1145/975817.975844
   PATTERSON ML, 1986, J NONVERBAL BEHAV, V10, P41, DOI 10.1007/BF00987204
   Reeves B., 1996, MEDIA EQUATION PEOPL
   SALOVAARA A, 2004, P NORDICHI 04
   SCHREMPF O, 2005, P RO MAN 05
   Shiloh S, 2003, ANXIETY STRESS COPIN, V16, P387, DOI 10.1080/1061580031000091582
   STIEHL WD, 2006, P CCNC 06
   TAPUS A, 2008, AAAI SPRING 08
   Walters ML, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P347
   WILLIS FN, 1980, J NONVERBAL BEHAV, V5, P49, DOI 10.1007/BF00987054
   Woods SN, 2006, P 15 IEEE INT S ROB, P51, DOI [DOI 10.1109/ROMAN.2006.314394, DOI 10.1109/ROMAN2006.314394]
   YOHANAN S, 2008, P REIGN KATZ DOGZ 2, P7
NR 31
TC 50
Z9 52
U1 4
U2 34
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 437
EP 445
DI 10.1002/cav.317
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700036
OA Green Published
DA 2024-07-18
ER

PT J
AU Huang, J
   Sun, HQ
   Zhou, K
   Bao, HJ
AF Huang, Jin
   Sun, Hanqiu
   Zhou, Kun
   Bao, Hujun
TI Real-time dynamics for geometric textures in shell
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE geometric texture; real-time simulation; Poisson's ratio
AB Embedding geometric textures in a shell space around apt arbitrary surface has been a popular Way to add highly detailed geometric details and enhance visual richness in graphics community, but the dynamic effects of geometric textures have not been modeled and simulated. In this paper, we introduce an efficient algorithm for deforming geometric textures with dynamic effects. The algorithm consists of two steps. First, it computes a deformed shell space by optimizing a material related energy function, Which is then used to evaluate the equilibrium position of the geometric texture. Second, an explicit time integration scheme is applied for vibrating the geometric texture around its equilibrium position. Users can deform the geometric textures by dragging its vertices directly, and the dynamic behavior of the geometric textures can be changed by adjusting several material parameters. The dynamic simulation of geometric textures can be easily implemented on GPU and runs at real-time rates. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Huang, Jin] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
   [Sun, Hanqiu] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
C3 Zhejiang University; Chinese University of Hong Kong
RP Huang, J (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
EM hj@cad.zju.edu.cn; hanqiu@cse.cuhk.edu.hk
RI Zhou, Kun/AAH-9290-2019; Zhou, Kun/ABF-4071-2020
OI Zhou, Kun/0000-0003-2320-3655
CR Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Botsch M., 2006, SGP 06, P11
   BRIDSON R, 2003, P 2003 ACM SIGGRAPH, P28
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   Galoppo N., 2006, Proc. Symp. on Computer Animation, P73
   Grinspun E., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P62
   Huang J, 2006, ACM T GRAPHIC, V25, P1126, DOI 10.1145/1141911.1142003
   Irving G, 2006, GRAPH MODELS, V68, P66, DOI 10.1016/j.gmod.2005.03.007
   Lemaitre J, 1994, Mechanics of solid materials
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Müller M, 2004, PROC GRAPH INTERF, P239
   Porumbescu SD, 2005, ACM T GRAPHIC, V24, P626, DOI 10.1145/1073204.1073239
   Rivers AR, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239533
   Sorkine O., 2004, P 2004 EUR ACM SIGGR, P179
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zayer R, 2005, COMPUT GRAPH FORUM, V24, P601, DOI 10.1111/j.1467-8659.2005.00885.x
   Zhou K, 2005, ACM T GRAPHIC, V24, P496, DOI 10.1145/1073204.1073219
   Zhou K, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239542
   Zhou K, 2006, ACM T GRAPHIC, V25, P690, DOI 10.1145/1141911.1141942
NR 22
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 133
EP 141
DI 10.1002/cav.303
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700007
DA 2024-07-18
ER

PT J
AU Shum, HPH
   Komura, T
   Yadav, P
AF Shum, Hubert P. H.
   Komura, Taku
   Yadav, Pranjul
TI Angular momentum guided motion concatenation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 22nd International Conference on Computer Animation and Social Agents
   (CASA 2009)
CY JUN 17-19, 2009
CL Amsterdam, NETHERLANDS
SP Comp Graph Soc
DE motion editing; motion control
AB In this paper, we propose a new Method to concatenate two dynamic full-body motions such as punches, kicks, and flips by using the angular momentum as a cue. Through the observation of real humans, We have identified two patterns of angular momentum that make the transition of such motions efficient. Based on these observations, we propose a new method to concatenate two full-body motions in a natural manner. Our method is useful for applications Where dynamic, full-body motions are required, such as 3D computer games and animations. Copyright (C) 2009 John Wiley & Sons, Ltd.
C1 [Shum, Hubert P. H.; Komura, Taku] Univ Edinburgh, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland.
C3 University of Edinburgh
RP Shum, HPH (corresponding author), Univ Edinburgh, Sch Informat, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.
EM hubert.shum@ed.ac.uk
RI Shum, Hubert P. H./E-8060-2015
OI Shum, Hubert P. H./0000-0001-5651-6039
CR ABE Y, 2004, P ACM SIGGRAPH EUR S, P173
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Arikan Okan., 2005, SCA 2005: Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P59
   Fang AC, 2003, ACM T GRAPHIC, V22, P417, DOI 10.1145/882262.882286
   HECK R, 2007, 13D 07, P129
   JAKOBSEN T, 2001, GAM DEV C, P383
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Liu CK, 2002, ACM T GRAPHIC, V21, P408, DOI 10.1145/566570.566596
   MAJKOWSKA A, 2001, P 2007 ACM SIGGRAPH, P79
   Sulejmanpasic A, 2005, ACM T GRAPHIC, V24, P165, DOI 10.1145/1037957.1037966
   THORNE ME, 2001, THESIS U WATERLOO
   Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507
   ZHAO L, 2008, P 2008 ACM EUR S COM
   Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249
NR 15
TC 4
Z9 5
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2009
VL 20
IS 2-3
SI SI
BP 385
EP 394
DI 10.1002/cav.315
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 472DY
UT WOS:000268110700031
DA 2024-07-18
ER

PT J
AU Lee, TH
   Shin, YG
AF Lee, Taek Hee
   Shin, Yeoung Gil
TI Coherence aware GPU-based ray casting for virtual colonoscopy
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE CPU; virtual colonoscopy; reprojecting; temporal coherence; Shader Model
   4.0
AB In this paper, we propose a GPU-based volume ray casting for virtual colonoscopy to generate high-quality rendering images with a large screen size. Using the temporal coherence for ray casting, the empty space leaping can be efficiently done by reprojecting first-hit points of the previous frame; however, these approaches could produce artifacts such as holes or illegal starting positions due to the insufficient resolution Of first-hit points. To eliminate these artifacts, we use a triangle mesh of first-hit points and check the intersection of each triangle with the corresponding real surface. Illegal starting positions can be avoided by replacing a false triangle cutting the real surface with five newly generated triangles. The proposed algorithm is best fit to the recent GPU architecture with Shader Model 4.0 which supports not only fast rasterization of a triangle mesh but also many flexible vertex operations. Experimental results on ATI 2900 with DirectX10 show perspective volume renderings of over 24fps on 1024 x 1024 screen size without any loss of image quality. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Lee, Taek Hee; Shin, Yeoung Gil] Seoul Natl Univ, Seoul 151742, South Korea.
C3 Seoul National University (SNU)
RP Lee, TH (corresponding author), Seoul Natl Univ, 599 Gwanangno, Seoul 151742, South Korea.
EM thlee@cglab.snu.ac.kr
FU Ministry of Commerce, Industry and Energy (MOCIE, Korea) [10028331];
   Seoul Research and Business Development Program [10888]
FX This work was supported in part by Grant No. 10028331 from the
   Medium-term Strategic Technology Development Program of the Ministry of
   Commerce, Industry and Energy (MOCIE, Korea) and in part by Grant No.
   10888 from the Seoul Research and Business Development Program. The ICT
   at Seoul National University provided research facilities for this
   study. We would like to thank Bohyoung Kim for her helpful discussions
   on this work.
CR [Anonymous], 2002, DIRECTX9 SDK
   Brady ML, 1998, IEEE T VIS COMPUT GR, V4, P243, DOI 10.1109/2945.722298
   Cabral B., 1994, P 1994 S VOLUME VISU, P91, DOI DOI 10.1145/197938.197972
   COORG S, 1996, TM546
   CULLIP TJ, 1993, TR93027
   Engel Klaus, 2001, P ACM SIGGRAPH EUROG, P9, DOI [DOI 10.1145/383507.383515, 10.1145/383507.383515]
   HONG L, 1997, P SIGGRAPH 97, P27
   Klein T, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P223
   Krüger J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P287, DOI 10.1109/VISUAL.2003.1250384
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   LEE J, 2000, LECT NOTES COMPUTER, V4035, P452
   Li W, 2001, SPRING EUROGRAP, P363
   Meissner M., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P207, DOI 10.1109/VISUAL.1999.809889
   *MICROSOFT, 2007, DIRECTX10 SDK
   Ming W, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P195, DOI 10.1109/VISUAL.2002.1183775
   NOVINS K, 1990, ACM SIGGRAPH COMPUTE, V24, P285
   REZK-SALAMA C., 2000, EGSIGGRAPH WORKSHOP, P109, DOI DOI 10.1145/346876.348238
   ROETTGER S, 2003, P EG IEEE TCVG S VIS, P231
   SARANG L, 2004, P C VIS 04, P19
   SCHARSACH H, 2005, P CESCG 2005, P69
   SCHARSACH H, 2006, EUR IEEE VGTC S VIS, P315
   SHARGHI M, 2002, P 6 ANN M MED IM UND, P133
   VanGelder A, 1996, 1996 SYMPOSIUM ON VOLUME VISUALIZATION, PROCEEDINGS, P23, DOI 10.1109/SVV.1996.558039
   Wan M, 2000, PROC SPIE, V3978, P165, DOI 10.1117/12.383395
   Wan M., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P397, DOI 10.1109/VISUAL.1999.809914
   WESTERMANN R, 1998, P SIGGRAPH 98, P169
   Yagel R., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), P62, DOI 10.1109/VISUAL.1993.398852
   You SY, 1997, VISUALIZATION '97 - PROCEEDINGS, P433, DOI 10.1109/VISUAL.1997.663915
NR 28
TC 7
Z9 8
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN-FEB
PY 2009
VL 20
IS 1
BP 1
EP 9
DI 10.1002/cav.273
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 407WD
UT WOS:000263394100002
DA 2024-07-18
ER

PT J
AU Hong, JM
   Yoon, JC
   Kim, CH
AF Hong, Jeong-Mo
   Yoon, Jong-Chul
   Kim, Chang-Hun
TI Divergence-constrained moving least squares for fluid simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 21st Annual Conference on Computer Animation and Social Agents (CASA
   2008)
CY SEP 01-03, 2008
CL Seoul, SOUTH KOREA
DE fluid simulation; moving least squares; vector interpolation; divergence
   constraints; computer animation
ID LEVEL SET
AB Developing suitable interpolation methods to simulate dynamic motions of continuous materials such as fluids is an important problem. In this paper, we propose a novel method to enforce the divergence condition to the interpolated velocity field by moving least squares (MLS), by means of the diffusive derivatives and moving divergence constraints that allow the practical use and easy implementation. As results, we present the velocity interpolation examples and a fluid-like particle simulation method to show the meaningful potential of our method as a tool of physical interpolation for fluid simulations. Copyright (C) 2008 John Wiley & Sons, Ltd.
C1 [Kim, Chang-Hun] Korea Univ, Comp Graph Lab, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Korea University
RP Kim, CH (corresponding author), Korea Univ, Comp Graph Lab, Dept Comp Sci & Engn, Seoul, South Korea.
EM chkim@korea.ac.kr
CR [Anonymous], 2003, P 4 ASME JSME JOINT
   Belytschko T, 1996, COMPUT METHOD APPL M, V139, P3, DOI 10.1016/S0045-7825(96)01078-X
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Feldman BE, 2005, ACM T GRAPHIC, V24, P904, DOI 10.1145/1073204.1073281
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Hong JM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360647
   Hong JM, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239498
   Hong JM, 2005, ACM T GRAPHIC, V24, P915, DOI 10.1145/1073204.1073283
   Huerta A, 2004, COMPUT METHOD APPL M, V193, P1119, DOI 10.1016/j.cma.2003.12.010
   KIM B, 2007, ACM T GRAPHICS SIGGR, V26, P481
   Kim B, 2007, IEEE T VIS COMPUT GR, V13, P135, DOI 10.1109/TVCG.2007.3
   Kim J., 2006, Proc ACM SIGGRAPH/Eurograph Symp Comp Anim, SCA '06, P335
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Nayroles B., 1992, COMPUT MECH, V10, P307, DOI [DOI 10.1007/BF00364252, 10.1007/BF00364252]
   Nealen A., 2004, An As-Short-As-Possible Introduction to the Least Squares, Weighted Least Squares and Moving Least Squares Methods for Scattered Data Approximation and Interpolation
   Rasmussen N., 2004, ACM SIGGRAPH/ Eurographics Symp. Comp. Anim, P193, DOI DOI 10.1145/1028523.1028549
   Shen C., 2004, ACM T GRAPHICS SIGGR, V31, P321
   Song OY, 2005, ACM T GRAPHIC, V24, P81, DOI 10.1145/1037957.1037962
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Sussman M, 2003, J COMPUT PHYS, V187, P110, DOI 10.1016/S0021-9991(03)00087-1
   Yabe T, 2001, J COMPUT PHYS, V169, P556, DOI 10.1006/jcph.2000.6625
NR 22
TC 4
Z9 4
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD AUG
PY 2008
VL 19
IS 3-4
SI SI
BP 469
EP 477
DI 10.1002/cav.236
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 354GZ
UT WOS:000259628200028
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lee, J
   Kim, MS
AF Lee, Jieun
   Kim, Myung-Soo
TI Human hand adaptation using sweeps: generating animatable hand models
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE hand modeling; shape fitting; shape adaptation; model reconstruction
   from 2D image
ID DEFORMATION
AB We introduce a sweep-based hand shape adaptation algorithm to fit a generic sweep-based hand model to the shape of an individual's hand, presented as a single photograph. The sweep trajectory curves of the generic hand model are modified to interpolate a sequence of keyframes determined by target featnres. Details of the real hand can be transferred to the model by adjusting its sweep displacement map. Palm lines are also acquired from sketches drawn on the photograph. The bespoke model inherits the fully animatable structure of the generic model. We demonstrate the effectiveness of our sweep-based approach using several examples of reconstructing animatable bespoke hand models. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Seoul Natl Univ, Seoul 151744, South Korea.
C3 Seoul National University (SNU)
RP Kim, MS (corresponding author), Seoul Natl Univ, Seoul 151744, South Korea.
EM mskirn@cse.snu.ac.kr
RI Lee, Eun-ju/JAN-8749-2023; LEE, YU/JXY-2338-2024; LEE,
   JIEUN/HTN-1777-2023; Lee, Jieun/J-3909-2016
OI Lee, Jieun/0000-0001-5692-9263
CR *AD SYST INC, PHOT
   Albrecht Irene., 2003, P 2003 ACM SIGGRAPHE, P98
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Chang TI, 1998, VISUAL COMPUT, V14, P228, DOI 10.1007/s003710050137
   COQUILLART S, 1987, IEEE COMPUT GRAPH, V7, P36, DOI 10.1109/MCG.1987.277068
   Hyun DE, 2005, VISUAL COMPUT, V21, P542, DOI 10.1007/s00371-005-0343-x
   Kahler K., 2002, Eurographics Symp. on Comp. Animation, P55, DOI DOI 10.1145/545261.545271
   Lee J, 2006, COMPUT ANIMAT VIRT W, V17, P479, DOI 10.1002/cav.150
   Lee Y., 1995, SIGGRAPH, P55, DOI [10.1145/218380.218407, DOI 10.1145/218380.218407]
   NOH JY, 1998, 99705 U SO CAL INT M
   Rhee Taehyun., 2006, Human Hand Modeling from Surface Anatomy, DOI DOI 10.1145/1111411.1111417
   SEO H, 2003, P ACM SIGGRAPH EUR S, P120
NR 12
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 505
EP 516
DI 10.1002/cav.193
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000029
DA 2024-07-18
ER

PT J
AU Sanyal, S
   Banerjee, S
   Kalra, PK
AF Sanyal, Subhajit
   Banerjee, Subhashis
   Kalra, Prem K.
TI Designing quality walkthroughs
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article; Proceedings Paper
CT 64th Annual Meeting of the Society-of-American-Archivists
CY 2000
CL Denver, CO
SP Soc Amer Archivists
DE guided tours; navigation; walkthrough
AB In this paper we present a framework for designing quality walkthroughs. Our framework aids the content creator in designing tours where one sees interesting objects for the most part of the tour. Further, the speed of the tour is controlled by what is shown. In particular we consider the designing of walkthroughs of scenes constructed by image-based techniques where such a design framework helps to optimize on the effort needed to create the content. Copyright (c) 2007 John Wiley & Sons, Ltd.
C1 Indian Inst Technol, Dept Comp Sci & Engn, New Delhi 110016, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Sanyal, S (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, New Delhi 110016, India.
EM subhajit@cse.iitd.ernet.in
CR [Anonymous], P IEEE VR 2000 C
   [Anonymous], 2012, Robot Motion Planning
   BECKHAUS S, 2001, COMPUTER GRAPHICS FO, V201
   BECKHAUS S, COMPUTER GRAPHICS FO, V20
   Edelsbrunner H., 1987, Algorithms in Combinatorial Geometry
   Fleishman S, 2000, COMPUT GRAPH FORUM, V19, P101, DOI 10.1111/1467-8659.00447
   Granot E, 2004, CLIN NUTR, V23, P3, DOI 10.1016/S0261-5614(03)00097-9
   Hanson AJ, 1997, VISUALIZATION '97 - PROCEEDINGS, P175, DOI 10.1109/VISUAL.1997.663876
   KHAN A, 2005, 13D 05, P73
   KUSHAL AM, 2003, MULTILEVEL MODELLING
   Li TY, 1999, COMP ANIM CONF PROC, P99, DOI 10.1109/CA.1999.781203
   MACKINLAY JD, 1990, P ACM SIGGRAPH 90, V24, P171
   MACKKER SM, 1994, IJGRAPH INT 94, P190
   MARCHAND E, 2000, 1310 IRISA
   Rivest R., 1990, INTRO ALGORITHMS
   SANYAL S, 2006, INTERACTICE IMAGE BA
   [No title captured]
NR 17
TC 1
Z9 1
U1 0
U2 3
PU WILEY-BLACKWELL
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD SEP-DEC
PY 2007
VL 18
IS 4-5
BP 527
EP 538
DI 10.1002/cav.214
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 221EU
UT WOS:000250211000031
OA Bronze
DA 2024-07-18
ER

PT J
AU Schaeffer, B
   Brinkmann, P
   Francis, G
   Goudeseune, C
   Crowell, J
   Kaczmarski, H
AF Schaeffer, Benjamin
   Brinkmann, Peter
   Francis, George
   Goudeseune, Camille
   Crowell, Jim
   Kaczmarski, Hank
TI Myriad: Scalable VR via peer-to-peer connectivity, PC clustering, and
   transient inconsistency
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE virtual reality; virtual environment; PC cluster; peer-to-peer
ID VIRTUAL ENVIRONMENTS
AB Distributed scene graphs are important in virtual reality, both in collaborative virtual environments and in cluster rendering. Modern scalable visualization systems have high local throughput, but collaborative virtual environments (VEs) over a wide-area network (WAN) share data at much lower rates. This complicates the use of one scene graph across the whole application. Myriad is an extension of the Syzygy VR toolkit in which individual scene graphs form a peer-to-peer network. Myriad connections filter scenegraph updates and create flexible relationships between nodes of the scene graph. Myriad's sharing is fine-grained: the properties of individual scenegraph nodes to share are dynamically specified (in C+ + or Python). Myriad permits transient inconsistency, relaxing resource requirements in collaborative VEs. A test application, WorldWideCrowd, demonstrates collaborative prototyping of a 300-avatar crowd animation viewed on two PC-cluster displays and edited on low-powered laptops, desktops, and over a WAN. We have further used our framework to facilitate collaborative educational experiences and as a vehicle for undergraduates to experiment with shared virtual worlds. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Univ Illinois, Beckman Inst, Integrated Syst Lab, Urbana, IL 61801 USA.
   CUNY City Coll, New York, NY 10031 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign;
   City University of New York (CUNY) System; City College of New York
   (CUNY)
RP Schaeffer, B (corresponding author), Univ Illinois, Beckman Inst, Integrated Syst Lab, 405 N Mathews St, Urbana, IL 61801 USA.
EM ben.schaeffer@gmail.com
OI Goudeseune, Camille/0000-0003-3530-8577
CR Capps M, 2000, IEEE COMPUT GRAPH, V20, P12, DOI 10.1109/38.865873
   CARLSSON C, 1993, COMPUT GRAPH, V17, P663, DOI 10.1016/0097-8493(93)90115-P
   CRUZNEIRA C, 1993, PROC COMPUT GRAPH SI, V27, P135
   FRECON E, 1999, P ACM S VIRT REAL SO, P58
   Greenhalgh C., 1998, Distributed Systems Engineering, V5, P129, DOI 10.1088/0967-1846/5/3/006
   Greenhalgh C., 2000, Proceedings of the third international conference on Collaborative virtual environments, P119, DOI DOI 10.1145/351006.351027
   HANGSAND O, 1996, IEEE MULTIMEDIA, V3, P30
   Hesina Gerd, 1999, P ACM S VIRT REAL SO, P74, DOI [10.1145/323663.323675, DOI 10.1145/323663.323675]
   HUPHREYS G, 2001, P ACM SIGGRAPH, V35, P129
   LEIGH J, 1997, J VIRTUAL REALITY RE, V2, P217
   Macedonia M.R., 1994, PRESENCE, V3, P265, DOI 10.1162/pres.1994.3.4.265
   MACINTYRE B, 1998, P ACM SIGGRAPH, V32, P361
   OLSON EC, 2002, THESIS IOWA STATE U
   Park KyoungS., 2000, P ACM S VIRTUAL REAL, P8, DOI DOI 10.1145/502390.502394
   Purbrick J, 2002, P IEEE VIRT REAL ANN, P15, DOI 10.1109/VR.2002.996500
   Schaeffer B, 2003, P IEEE VIRT REAL ANN, P15, DOI 10.1109/VR.2003.1191116
   SMITH G, 1990, COMPUTER SUPPORTED C, P390
   Tramberend H, 1999, P IEEE VIRT REAL ANN, P14, DOI 10.1109/VR.1999.756918
   Tran FD, 2002, P IEEE VIRT REAL ANN, P22, DOI 10.1109/VR.2002.996501
NR 19
TC 2
Z9 2
U1 2
U2 3
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 1546-4261
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD FEB
PY 2007
VL 18
IS 1
BP 1
EP 17
DI 10.1002/cav.158
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 149ML
UT WOS:000245150900003
DA 2024-07-18
ER

PT J
AU Pennestrì, E
   Pezzuti, E
   Valentini, PP
   Vita, L
AF Pennestri, E.
   Pezzuti, E.
   Valentini, P. P.
   Vita, L.
TI Computer-aided virtual reconstruction of Italian ancient clocks
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE ancient clock; cultural heritage; computer-aided simulation; virtual
   museum
ID MODEL
AB Italy has plenty of cultural heritages. The masterpieces are often placed in locations which are difficult to reach, moreover many artifacts, coming from man's creativity, have very complex functioning. The authors of this paper describe their experience in using the computer graphics capabilities in order to reproduce four ancient clocks functioning coming from different Italian regions. The study is based not only on the 3D-shapes reconstruction but also on the simulation of their complex mechanisms in order to mimic their functioning. The realism of the reconstruction allows to use the graphical products in exhibits, museums and also for maintenance: programs. The rendering techniques together with an accurate camera path, allow to get into the clock mechanisms and to appreciate all the features (and even secrets) that a simple glance cannot reveal. Copyright (c) 2006 John Wiley & Sons, Ltd.
C1 Univ Roma Tor Vergata, Dept Mech Engn, I-00133 Rome, Italy.
C3 University of Rome Tor Vergata
RP Valentini, PP (corresponding author), Univ Roma Tor Vergata, Dept Mech Engn, Via Politecnico 1, I-00133 Rome, Italy.
EM valentini@ing.uniroma2.it
RI Pennestri, Ettore/AAW-9018-2020; Vita, Leonardo/AAU-9478-2021;
   Pennestri, E./AAI-4216-2020
OI Vita, Leonardo/0000-0001-8484-2827; Pezzuti,
   Eugenio/0000-0002-5177-188X; Pennestri', Ettore/0000-0002-4091-8444;
   Valentini, Pier Paolo/0000-0001-8243-8142
CR Beacham R, 2003, COMPUT HUMANITIES, V37, P129, DOI 10.1023/A:1021859830043
   Blackaby J., 1997, ARCH MUSEUM INFORM, V11, P117
   CAPUCCI PL, 1997, DOMUS, V792, P103
   Cheverst K, 1999, COMPUT GRAPH-UK, V23, P883, DOI 10.1016/S0097-8493(99)00119-3
   DECARLE D, 1951, PRACTICAL CLOCK REPA
   Diderot D., 1772, Encyclopedie, ou Dictionnaire Raisonne des Sciences, des Arts et des Metiers, par une Societe de Gens de lettres
   EBERHARDT B, 1999, EUROGRAPHICS
   ETHIER SJ, 2001, 3D STUDIO VIZ
   FIELD JV, 1985, EARLY GEARINGS
   Hanisch F, 2000, J CULT HERIT, V1, P335, DOI 10.1016/S1296-2074(00)01090-6
   HARRISON JD, 1994, MUSEUM MANAGEMENT CU, V13, P160
   MASE K, 1996, P INT C VIRTUAL  SEP, P107
   MORPURGO E, 1984, GLI OROLOGI
   Pennestrì E, 2003, J MECH DESIGN, V125, P602, DOI 10.1115/1.1587157
   Pennestrì E, 2002, MULTIBODY SYST DYN, V7, P249, DOI 10.1023/A:1015270811968
   PERATONER A, 2000, OROLOGIO TORRE SAN M
   POLEVOI R, 1999, 3D STUDIO MAX 3
   Rio-Cidoncha G., 2008, CLOCKS WATCHES, V23, P33
   TRANT J, 1997, ARCH MUSEUMS INFORM, V11, P73
   WENHAM E, 1951, OLD CLOCKS
   Yan HS, 2002, MECH MACH THEORY, V37, P15, DOI 10.1016/S0094-114X(01)00059-3
NR 21
TC 3
Z9 3
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD DEC
PY 2006
VL 17
IS 5
BP 565
EP 572
DI 10.1002/cav.155
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science
GA 111UX
UT WOS:000242481700006
OA Bronze
DA 2024-07-18
ER

PT J
AU Lee, TY
   Yao, CY
   Chu, HK
   Tai, MJ
   Chen, CC
AF Lee, Tong-Yee
   Yao, Chih-Yuan
   Chu, Hung-Kuo
   Tai, Ming-Jen
   Chen, Cheng-Chieh
TI Generating genus-n-to-m mesh morphing using spherical parameterization
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE spherical parameterization; genus reduction; Poisson stitching; positive
   and negative objects; metamorphosis
AB Surface parameterization is a fundamental tool ill computer graphics and benefits many applications such as texture mapping, morphing, and re-meshing. Many spherical parameterization schemes with very nice properties have been proposed and widely used in the past. However, it is well known that the spherical parameterization is limited to genus-0 models. In this paper, we first propose a novel framework to extend spherical parameterization for handling a genus-n surface. In this frame work, we represent a surface S of arbitrary genus by a positive mesh O and several negative meshes N-i. Each negative surface is used to represent a hole. A positive surface 0 is obtained by removing all holes in the original surface S. Then, both positive and negative meshes are genus-0 and call be spherically parameterized, respectively. To compute S, we call use a Boolean difference operation to subtract negative Ni from a Positive O. Next, we apply this novel framework to generate genus-n-to-m mesh morphing application Without restriction of n = m. Finally, there are many interesting non-genus-0 mesh morphing sequences generated. Copyright (c) 2006 John Wiley & Soils, Ltd.
C1 Natl Cheng Kung Univ, Dept Comp Sci & Engn, Comp Graphics Grp, Visual Syst Lab, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Engn, Comp Graphics Grp, Visual Syst Lab, 1 Ta Hsueh Rd, Tainan 701, Taiwan.
EM tonylee@mail.ncku.edu.tw
CR AARON W, COMPUTER GRAPHICS P, P343
   Alexa M, 1999, SHAPE MODELING INTERNATIONAL '99 - INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P202, DOI 10.1109/SMA.1999.749341
   Alexa M, 2000, VISUAL COMPUT, V16, P26, DOI 10.1007/PL00007211
   Asirvatham A, 2005, LECT NOTES COMPUT SC, V3515, P265
   EDMONDS J, 1972, J ACM, V19, P248, DOI 10.1145/321694.321699
   Gotsman C, 2003, ACM T GRAPHIC, V22, P358, DOI 10.1145/882262.882276
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Haker S, 2000, IEEE T VIS COMPUT GR, V6, P181, DOI 10.1109/2945.856998
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Ju T, 2004, ACM T GRAPHIC, V23, P888, DOI 10.1145/1015706.1015815
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811
   Lee TY, 2005, IEICE T INF SYST, VE88D, P646, DOI 10.1093/ietisy/e88-d.3.646
   Lee TY, 2003, IEEE T VIS COMPUT GR, V9, P85, DOI 10.1109/TVCG.2003.1175099
   Lin CH, 2005, COMPUT ANIMAT VIRT W, V16, P487, DOI 10.1002/cav.85
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Praun E, 2001, COMP GRAPH, P179, DOI 10.1145/383259.383277
   Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274
   REEB G, 1946, CR HEBD ACAD SCI, V222, P847
   Schreiner J, 2004, ACM T GRAPHIC, V23, P870, DOI 10.1145/1015706.1015812
   SHEFFER A, 2003, 4 ISR KOR BIN C GEOM, P94
   Sorkine O, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P355, DOI 10.1109/VISUAL.2002.1183795
   Wood Z, 2004, ACM T GRAPHIC, V23, P190, DOI 10.1145/990002.990007
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
NR 24
TC 16
Z9 17
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUL
PY 2006
VL 17
IS 3-4
BP 433
EP 443
DI 10.1002/cav.146
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 062FG
UT WOS:000238929400029
OA Bronze
DA 2024-07-18
ER

PT J
AU Li, LY
   Huang, TY
   Li, YH
   Li, P
AF Li, Lingyu
   Huang, Tianyu
   Li, Yihao
   Li, Peng
TI Trajectory-BERT: Pre-training and fine-tuning bidirectional transformers
   for crowd trajectory enhancement
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd trajectory tracking; machine learning; multi-person tracking
ID SURVEILLANCE
AB To address the issue of trajectory fragments and ID switches caused by occlusion in dense crowds, we propose a space-time trajectory encoding method and a point-line-group division method to construct Trajectory-BERT in this paper. Leveraging the spatiotemporal context-dependent features of trajectories, we introduce pre-training and fine-tuning Trajectory-BERT tasks to repair occluded trajectories. Experimental results show that data augmented with Trajectory-BERT outperforms raw annotated data on the MOTA metric and reduces ID switches in raw labeled data, demonstrating the feasibility of our method.
C1 [Li, Lingyu; Huang, Tianyu; Li, Yihao; Li, Peng] Beijing Inst Technol, Key Lab Digital Performance & Simulat Technol, Beijing, Peoples R China.
   [Huang, Tianyu] Beijing Inst Technol, Key Lab Digital Performance & Simulat Technol, 5 Yard Zhong Guan Cun South St, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Technology
RP Huang, TY (corresponding author), Beijing Inst Technol, Key Lab Digital Performance & Simulat Technol, 5 Yard Zhong Guan Cun South St, Beijing 100081, Peoples R China.
EM huangtianyu@bit.edu.cn
RI ZHANG, JING/KHY-1073-2024; zhang, lu/KGL-6144-2024; Wang,
   Jiawei/KHC-8971-2024; chen, xiao/KFQ-6812-2024; Cheng,
   Lin/KFQ-3111-2024; Wang, Yitong/KBA-1959-2024; li,
   chunlin/KFS-0761-2024; Wang, Junzhe/KCK-4991-2024; zhang,
   zheng/KHY-8870-2024
OI Li, Yihao/0000-0001-9159-0373
FU National Key Research and Development Program of China [2020YFC2007200]
FX National Key Research and Development Program of China, Grant/Award
   Number: 2020YFC2007200
CR Bashar M., 2022, arXiv
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Chenjiao T., 2022, COMPUT ELECT AGR, V193
   Daniel S., 2021, IMPROVING MULTIPLE P
   Dendorfer P., 2020, arXiv
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   En Y., 2022, DISCRIMINATIVE REPRE
   Fu HY, 2021, CHINA COMMUN, V18, P89, DOI 10.23919/JCC.2021.06.008
   Gaoang W., 2022, IEEE T MULTIMED
   Hideaki U., 2012, OBJECT DETECTION POS
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Jiangmiao P., 2021, QUASIDENSE SIMILARIT
   Jing S., 2014, SCENE INDEPENDENT GR
   Koller D., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P189
   Leal-Taix‚ L, 2015, Arxiv, DOI arXiv:1504.01942
   Luo W., 2014, 2014 IEEE C COMP VIS
   Milan A, 2016, Arxiv, DOI arXiv:1603.00831
   Tomas P., 2015, FLOWING CONVNETS HUM
   Wan J., 2022, arXiv
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wongun C., 2012, EUR C COMP VIS, P215
   Yang B., 2011, CVPR 2011 IEEE
   Yihong X., 2023, IEEE T PATTERN ANAL, V45, P7820
   Yuting N., 2022, BERT LID LEVERAGING
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
NR 25
TC 3
Z9 3
U1 2
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2190
EA MAY 2023
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000995887800001
DA 2024-07-18
ER

PT J
AU Li, Q
   Liu, TT
   Liu, Z
   Chai, YJ
AF Li, Qing
   Liu, Tingting
   Liu, Zhen
   Chai, Yanjie
TI Emotionally intelligent virtual tour guide in handling group conflicts:
   Effect on user outcomes
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE conflict resolution; emotional intelligence; group emotional
   intelligence; rapport; virtual agents
AB An effective virtual agent can serve humans complete task-based work efficaciously and manage interpersonal relationships with humans judiciously. This article investigates the effectiveness of emotional intelligence (EI) of a virtual agent taking over the role of a virtual tour guide (VTGuide) in a desktop application when witnessing a personal conflict between a human user and two virtual agents participating in the tour (the human user was ignored by the agents). A within-subject experiment is conducted to verify the validity of EI. Participants rate VTGuides (with or without EI) on conflict handling and report their feelings during the interaction. In addition, objective behavioral data of users are recorded, including facial expressions and textual sentiment, to assess the perception of rapport. The results show that an emotionally intelligent VTGuide performs an agreeable behavior system (e.g., nodding, eye contact, friendly facial expressions), comforting verbal strategy (e.g., distracting attention, mediating between conflicting parties), and positive paralinguistic cues (e.g., smiling textual emojis). It can effectively mitigate intra-group conflicts and maintain interpersonal relationships. Thus, demonstrating a stronger sense of EI can better transmit engagement, interest, understanding, and emotional feedback in complex relationships.
C1 [Li, Qing; Liu, Zhen; Chai, Yanjie] Ningbo Univ, Fac Informat Sci & Technol, Ningbo, Peoples R China.
   [Liu, Tingting] Ningbo Univ, Coll Sci & Technol, Cixi, Peoples R China.
C3 Ningbo University; Ningbo University
RP Liu, TT (corresponding author), Ningbo Univ, Coll Sci & Technol, Cixi, Peoples R China.
EM liutingting@nbu.edu.cn
OI liu, tingting/0000-0002-3469-275X
FU Ningbo Science Technology Plan projects [2021S091, 2022Z077]
FX ACKNOWLEDGMENTS This work was partially sponsored by Ningbo Science
   Technology Plan projects (Grants 2021S091 and 2022Z077).
CR Abdollahi H, 2023, IEEE T AFFECT COMPUT, V14, P2020, DOI [10.1109/TAFFC.2022.3143803, 10.1109/taffc.2022.3143803]
   baidu, BAID SENT AN INT
   Cafaro A, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2914796
   Cerekovic A, 2017, IEEE T AFFECT COMPUT, V8, P382, DOI 10.1109/TAFFC.2016.2545650
   Druskat VU, 2001, HARVARD BUS REV, V79, P80
   Edelman P, 2018, LEADERSHIP ORG DEV J, V39, P592, DOI 10.1108/LODJ-04-2018-0154
   Gautam I., P VIS UTT 2040 AG SO
   Goleman D, 1998, WORKING EMOTIONAL IN
   Jhan XD, 2022, IEEE T VIS COMPUT GR, V28, P3767, DOI 10.1109/TVCG.2022.3203107
   Johanson Deborah L., 2020, Paladyn, Journal of Behavioral Robotics, V11, P40, DOI 10.1515/pjbr-2020-0008
   Jung MF, 2017, ACMIEEE INT CONF HUM, P263, DOI 10.1145/2909824.3020224
   Lee S, 2020, INT J HUM-COMPUT INT, V36, P930, DOI 10.1080/10447318.2019.1699748
   Loveys K, 2022, INT J HUM-COMPUT ST, V160, DOI 10.1016/j.ijhcs.2021.102771
   Loveys K, 2021, J MED INTERNET RES, V23, DOI 10.2196/30624
   Lu YL, 2021, J NURS MANAGE, V29, P2453, DOI 10.1111/jonm.13406
   Lubold N, 2021, USER MODEL USER-ADAP, V31, P35, DOI 10.1007/s11257-020-09267-3
   Ma XJ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1222, DOI 10.1145/3308558.3313400
   Mayer JD, 2003, EMOTION, V3, P97, DOI 10.1037/1528-3542.3.1.97
   Moskowitz DS, 2005, J PERS, V73, P1607, DOI 10.1111/j.1467-6494.2005.00360.x
   Moussaïd M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Murali P., P 21 ACM INT C INT V
   Mysirlaki S, 2020, LEADERSHIP ORG DEV J, V41, P551, DOI 10.1108/LODJ-01-2019-0035
   Oh SY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161794
   Pan ZH, 2021, TRAVEL BEHAV SOC, V22, P262, DOI 10.1016/j.tbs.2020.10.007
   Pellitteri J., 2021, Psychology and Its Contexts, V12, P39, DOI DOI 10.15452/PSYX.2021.12.0010
   Potdevin D, 2021, INT J HUM-COMPUT ST, V150, DOI 10.1016/j.ijhcs.2021.102612
   Ratnasari SL., 2021, J SOC TRANSFORM REG, V3, P47
   Reeves B., 1996, The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places
   Salovey P., 1990, IMAGINATION COGNITIO, V9, P185, DOI [10.2190/DUGG-P24E-52WK-6CDG, DOI 10.2190/DUGG-P24E-52WK-6CDG]
   Samsonovich A.V., 2021, PROCEDIA COMPUT SCI, V190, P414, DOI 10.1016/j.procs.2021.06.050
   SARKAR M.P., 2020, INT J MANAGEMENT, V11, P581, DOI [10.34218/IJM.11.12.2020.054, DOI 10.34218/IJM.11.12.2020.054]
   Taigman Y., P 2014 IEEE C COMP V
   Ullah R, 2022, INT J CONFL MANAGE, V33, P223, DOI 10.1108/IJCMA-03-2021-0050
   Volonte M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P293, DOI [10.1109/VR46266.2020.1581610451331, 10.1109/VR46266.2020.00-55]
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Yang Y., P 2017 CHI C HUM FAC
   Zhang AD, 2023, COMPUT HUM BEHAV, V138, DOI 10.1016/j.chb.2022.107415
NR 37
TC 0
Z9 0
U1 4
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAY
PY 2023
VL 34
IS 3-4
DI 10.1002/cav.2153
EA MAY 2023
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H9ZY0
UT WOS:000991777900001
DA 2024-07-18
ER

PT J
AU Lin, X
   Liu, Z
   Liu, TT
   Chai, YJ
AF Lin, Xiao
   Liu, Zhen
   Liu, Tingting
   Chai, Yanjie
TI A personalized and emotion based virtual simulation model for
   pedestrian-vehicle collision avoidance
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE computer animation; microscopic model; pedestrian-vehicle avoidance
   simulation; traffic simulation
ID RISK PERCEPTION; BEHAVIOR
AB Since the differences of individual pedestrians and the diversity of pedestrian-vehicle avoidance behaviors in real life, it is important to consider the behavioral heterogeneity of pedestrians and vehicles in simulation. Most existing simulation models cannot generate personalized pedestrian-vehicle avoidance scenarios. Taking personality and emotional factors into account, we proposed a simulation method to realize various pedestrian-vehicle collision avoidance scenarios by adjusting the parameter of personality trait. In this study, drivers' yielding strategies were classified as careful and aggressive based on their different personality traits. For pedestrians, in addition to personality traits, emotional factors were also introduced to achieve more realistic speed control. The experimental results showed that the proposed method could generate personalized pedestrian-vehicle collision avoidance scenarios in multiple traffic scenarios.
C1 [Lin, Xiao; Liu, Zhen; Chai, Yanjie] Ningbo Univ, Fac Informat Sci & Technol, Ningbo 315211, Peoples R China.
   [Liu, Tingting] Ningbo Univ, Coll Sci & Technol, Cixi, Peoples R China.
C3 Ningbo University; Ningbo University
RP Liu, Z (corresponding author), Ningbo Univ, Fac Informat Sci & Technol, Ningbo 315211, Peoples R China.
EM liuzhen@nbu.edu.cn
RI Lin, Xiao/HTQ-6001-2023
OI Lin, Xiao/0000-0002-6148-418X; liu, tingting/0000-0002-3469-275X
FU Natural Science Foundation of Zhejiang Province [LY20F020007]; Ningbo
   Science Technology Plan project [2021R003, 2020Z082, 2021S091]; K.C.
   Wong Magna Fund in Ningbo University
FX This work was partially sponsored by the Natural Science Foundation of
   Zhejiang Province (Grant No. LY20F020007), and the Ningbo Science
   Technology Plan project (Grant No. 2021R003, 2020Z082, 2021S091), and
   the K.C. Wong Magna Fund in Ningbo University.
CR BANDO M, 1995, PHYS REV E, V51, P1035, DOI 10.1103/PhysRevE.51.1035
   Chao QW, 2015, COMPUT ANIMAT VIRT W, V26, P405, DOI 10.1002/cav.1654
   Costa P.T., 1992, REVISED NEO PERSONAL
   Durupinar F, 2016, IEEE T VIS COMPUT GR, V22, P2145, DOI 10.1109/TVCG.2015.2501801
   Fyhri A, 2012, ACCIDENT ANAL PREV, V49, P470, DOI 10.1016/j.aap.2012.03.017
   Guy S. J., 2011, P 2011 ACM SIGGRAPHE
   Han Y, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1974
   Herrero-Fernández D, 2016, TRANSPORT RES F-TRAF, V36, P14, DOI 10.1016/j.trf.2015.11.007
   Jiang R, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.017101
   Kesting A, 2010, PHILOS T R SOC A, V368, P4585, DOI 10.1098/rsta.2010.0084
   Lin WC, 2016, IEEE T INTELL TRANSP, V17, P3171, DOI 10.1109/TITS.2016.2542283
   Lobjois R, 2009, ACCIDENT ANAL PREV, V41, P259, DOI 10.1016/j.aap.2008.12.001
   Lu LL, 2016, ACCIDENT ANAL PREV, V95, P425, DOI 10.1016/j.aap.2016.04.014
   Olivier AH., 2012, P INT SOC POSTURE GA
   Reynolds CW., 1999, P GAME DEVELOPERS C
   Sjöberg L, 2002, RISK ANAL, V22, P751, DOI 10.1111/0272-4332.00066
   Subramanian R, 2018, IEEE T AFFECT COMPUT, V9, P147, DOI 10.1109/TAFFC.2016.2625250
   Sun H., 2020, CICTP, V2020, P3820
   Taubman-Ben-Ari O, 2012, ACCIDENT ANAL PREV, V45, P416, DOI 10.1016/j.aap.2011.08.007
   Treiber M, 2000, PHYS REV E, V62, P1805, DOI 10.1103/PhysRevE.62.1805
   Zeng WL, 2014, TRANSPORT RES C-EMER, V40, P143, DOI 10.1016/j.trc.2014.01.007
   Zheng TT, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188153
NR 22
TC 0
Z9 0
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2089
DI 10.1002/cav.2089
EA JUN 2022
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000816955600001
DA 2024-07-18
ER

PT J
AU Dai, J
   Zhang, XY
AF Dai, Jin
   Zhang, Xinyu
TI Automatic image caption generation using deep learning and multimodal
   attention
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE attention mechanism; CBAM; deep learning; image captioning
AB We present an improved image caption generation model that incorporating multimodal attention mechanism. We use ResNet-101 to extract image features while incorporating channel attention mechanism and spatial attention mechanism. We use Faster R-CNN for object detection and use a multi-head attention structure consisting of spatial attention and self-attention. This allows our algorithm to improve the model's capability to learn and use the internal grammatical features of natural sentences. Moreover, we use GPU parallel computing to accelerate the entire model training. We apply our model and algorithm to early education scenarios: show and tell for kids. We compare our algorithm with the state-of-the-art deep learning algorithms. Our experimental results show that our model improves the captioning accuracy in terms of standard automatic evaluation metrics.
C1 [Dai, Jin; Zhang, Xinyu] Shanghai Key Lab Trustworthy Comp, Shanghai, Peoples R China.
   [Dai, Jin; Zhang, Xinyu] Engn Res Ctr Software Hardware Codesign Technol &, Shanghai, Peoples R China.
   [Dai, Jin; Zhang, Xinyu] East China Normal Univ, Sch Software Engn, Shanghai, Peoples R China.
C3 East China Normal University
RP Zhang, XY (corresponding author), East China Normal Univ, Sch Software Engn, Shanghai, Peoples R China.
EM xyzhang@sei.ecnu.edu.cn
OI Zhang, Xinyu/0000-0001-5000-2483
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   Bengio Y., 2014, TECHNICAL REPORT
   Chen JZ, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P551, DOI [10.1109/CIS.2016.133, 10.1109/CIS.2016.0134]
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin Zhouhan, 2017, A structured self-attentive sentence embedding
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo RT, 2018, PROC CVPR IEEE, P6964, DOI 10.1109/CVPR.2018.00728
   Mnih V, 2014, ADV NEUR IN, V27
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Parikh AP., 2016, EMNLP
   Paulus Romain, A deep reinforced model for abstractive summarization
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Shizhe Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9959, DOI 10.1109/CVPR42600.2020.00998
   Sutskever I, 2014, ADV NEUR IN, V27
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
NR 30
TC 2
Z9 2
U1 4
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2072
DI 10.1002/cav.2072
EA JUN 2022
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000813363600001
DA 2024-07-18
ER

PT J
AU Sun, LB
   Qu, YK
   Qin, WH
AF Sun, Libo
   Qu, Yuke
   Qin, Wenhu
TI Crowd navigation in an unknown and complex environment based on deep
   reinforcement learning
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd simulation; curiosity driven; deep reinforcement learning;
   hierarchical reinforcement learning
AB We propose a virtual crowd navigation approach based on deep reinforcement learning to improve the adaptability of virtual crowds in an unknown and complex environment. To address the problem of local optimum or slow iteration or even failure to converge due to sparse rewards in complex environments, we integrate the curiosity-driven mechanism, the key navigation points acquisition and the failure path penalty method in addition to combining long short-term memory networks, dynamic obstacle collision prediction with proximal policy optimization algorithms, which realizes the crowd navigation in a complex environment. The experimental results show that the proposed approach can simulate the motions of virtual crowds in various dynamic and complex scenarios without the environment modeling. The use of continuous action space also ensures that the movement trajectories of the virtual crowds are more realistic and natural. Furthermore, our approach can provide analysis and demonstration tools for a variety of independent collaborations such as competition and cooperation of group intelligence in an open and dynamic environment.
C1 [Sun, Libo; Qu, Yuke; Qin, Wenhu] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Sun, LB; Qin, WH (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.
EM sunlibo@seu.edu.cn; qinwenhu@seu.edu.cn
FU Key R&D Program of Jiangsu Province [BE2019311]; Jiangsu Modern
   Agricultural Industry Key Technology Innovation Project [CX(20)2013];
   National Key Research And Development Program [2020YFB160070301]
FX This work was supported by the Key R&D Program of Jiangsu Province under
   Grant BE2019311, Jiangsu Modern Agricultural Industry Key Technology
   Innovation Project under Grant CX(20)2013, and National Key Research And
   Development Program under Grant 2020YFB160070301.
CR Arul SH., 2021, ARXIV PREPRINT ARXIV
   Bischoff B., 2013, P EUR S ART NEUR NET, P1
   Fan TX, 2020, INT J ROBOT RES, V39, P856, DOI 10.1177/0278364920916531
   Faust A, 2016, IEEE INT CONF ROBOT, P484, DOI 10.1109/ICRA.2016.7487169
   Gao M., 2019, APPL RES COMPUTERS, V36, P1
   Haworth B., 2020, Deep integration of physical humanoid control and crowd navigation. Proceedings of the 13th ACM SIGGRAPH conference on motion
   Huang BQ, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P85
   Khriji L, 2011, INT J ADV ROBOT SYST, V8, P45, DOI 10.5772/10528
   Kremer M., 2020, WATCH OUT MODELLING
   Long PX, 2018, IEEE INT CONF ROBOT, P6252
   Oliva R, 2013, COMPUT GRAPH-UK, V37, P403, DOI 10.1016/j.cag.2013.03.004
   Pathak D, 2017, IEEE COMPUT SOC CONF, P488, DOI 10.1109/CVPRW.2017.70
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Pflueger M, 2019, IEEE ROBOT AUTOM LET, V4, P1387, DOI 10.1109/LRA.2019.2895892
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   Sohre N., 2020, SPNETS HUMAN LIKE NA
   Sud A, 2008, IEEE T VIS COMPUT GR, V14, P526, DOI 10.1109/TVCG.2008.27
   Sun LB, 2019, IEEE ACCESS, V7, P109544, DOI 10.1109/ACCESS.2019.2933492
   Tan Q., 2020, IEEERSJ INT C INTELL
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Wang Wei, 2018, Journal of Computer Aided Design & Computer Graphics, V30, P695, DOI 10.3724/SP.J.1089.2018.16441
   Yap P., 2013, DATABASE DRIVEN SEAR
NR 22
TC 0
Z9 0
U1 2
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JUN
PY 2022
VL 33
IS 3-4
AR e2062
DI 10.1002/cav.2062
EA JUN 2022
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2S4AL
UT WOS:000812031600001
DA 2024-07-18
ER

PT J
AU Li, JY
   Zhou, X
   Yang, BB
   Zhang, GF
   Wang, X
   Bao, HJ
AF Li, Jinyu
   Zhou, Xin
   Yang, Bangbang
   Zhang, Guofeng
   Wang, Xun
   Bao, Hujun
TI RLP-VIO: Robust and lightweight plane-based visual-inertial odometry for
   augmented reality
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE augmented reality; bundle adjustment; plane prior; SLAM; visual-inertial
   odometry
ID MONOCULAR SLAM; KALMAN FILTER; PARAMETRIZATION; VERSATILE
AB We propose RLP-VIO-a robust and lightweight monocular visual-inertial odometry system using multiplane priors. With planes extracted from the point cloud, visual-inertial-plane PnP uses the plane information for fast localization. Depth estimation is susceptible to degenerated motion, so the planes are expanded in a reprojection consensus-based way robust to depth errors. For sensor fusion, our sliding-window optimization uses a novel structureless plane-distance error cost, which prevents the fill-in effect that poisons the BA problem's sparsity and permits the use of a smaller sliding window while maintaining good accuracy. The total computational cost is further reduced with our modified marginalization strategy. To further improve the tracking robustness, the landmark depths are constrained using the planes during degenerated motion. The whole system is parallelized with a three-stage pipeline. Under controlled environments, this parallelization runs deterministically and produces consistent results. The resulting VIO system is tested on widely used datasets and compared with several state-of-the-art systems. Our system achieves competitive accuracy and works robustly even on long and challenging sequences. To demonstrate the effectiveness of the proposed system, we also show the AR application running on mobile devices in real-time.
C1 [Li, Jinyu; Zhou, Xin; Yang, Bangbang; Zhang, Guofeng; Bao, Hujun] Zhejiang Univ, State Key Lab CAD & CG, East Bldg 1A-509, Hangzhou 310058, Peoples R China.
   [Wang, Xun] Zhejiang Gongshang Univ, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang Gongshang University
RP Zhang, GF (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, East Bldg 1A-509, Hangzhou 310058, Peoples R China.
EM zhangguofeng@cad.zju.edu.cn
RI Yang, Bangbang/GYQ-7787-2022
OI Yang, Bangbang/0000-0001-7604-5553; Bao, Hujun/0000-0002-2662-0334;
   Zhang, Guofeng/0000-0001-5661-8430; zhou, xin/0000-0002-3936-7657; Li,
   Jinyu/0000-0002-5206-8600
FU National Natural Science Foundation of China [61822310, 61672457];
   ZJU-SenseTime Joint Lab of 3D Vision
FX National Natural Science Foundation of China, Grant/Award Numbers:
   61822310, 61672457; ZJU-SenseTime Joint Lab of 3D Vision
CR Bavle H, 2020, IEEE ACCESS, V8, P60704, DOI 10.1109/ACCESS.2020.2983121
   Blanco JL., 2021, ARXIV PREPRINT ARXIV
   Bloesch M, 2017, INT J ROBOT RES, V36, P1053, DOI 10.1177/0278364917728574
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Campos Carlos, 2021, IEEE Transactions on Robotics, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276
   Cortés S, 2018, LECT NOTES COMPUT SC, V11214, P425, DOI 10.1007/978-3-030-01249-6_26
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   Dellaert F., 2017, TRENDS ROBOT, V6, P1, DOI 0.1561/2300000043
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321
   Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Geneva P, 2018, IEEE INT C INT ROBOT, P123, DOI 10.1109/IROS.2018.8594463
   Gim Hee Lee, 2011, IEEE International Conference on Robotics and Automation, P3139
   Gomez-Ojeda R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4211, DOI 10.1109/IROS.2016.7759620
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925
   He YJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041159
   Hsiao M, 2018, IEEE INT CONF ROBOT, P6521
   Jinyu Li, 2019, Pattern Recognition and Computer Vision. Second Chinese Conference, PRCV 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11859), P283, DOI 10.1007/978-3-030-31726-3_24
   Jones ES, 2011, INT J ROBOT RES, V30, P407, DOI 10.1177/0278364910388963
   Kaess M, 2015, IEEE INT CONF ROBOT, P4605, DOI 10.1109/ICRA.2015.7139837
   Kim P, 2018, IEEE INT CONF ROBOT, P7247
   Klein George, 2007, P1
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Li MY, 2012, IEEE INT CONF ROBOT, P828, DOI 10.1109/ICRA.2012.6225229
   Li PL, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P11, DOI 10.1109/ISMAR.2017.18
   Li X, 2020, IEEE INT C INT ROBOT, P5120, DOI 10.1109/IROS45743.2020.9341278
   Li X, 2020, IEEE ROBOT AUTOM LET, V5, P6972, DOI 10.1109/LRA.2020.3027230
   Li Y., 2021, P 2021 IEEE INT C RO
   Li YY, 2020, IEEE ROBOT AUTOM LET, V5, P6583, DOI 10.1109/LRA.2020.3015456
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nardi F, 2019, IEEE ROBOT AUTOM LET, V4, P625, DOI 10.1109/LRA.2019.2891989
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Pirchheim C, 2013, INT SYM MIX AUGMENT, P229, DOI 10.1109/ISMAR.2013.6671783
   Pumarola A., 2017, P 2017 IEEE INT C RO, P4503, DOI DOI 10.1109/ICRA.2017.7989522
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Qin T, 2017, IEEE INT C INT ROBOT, P4225, DOI 10.1109/IROS.2017.8206284
   Ram K, 2021, IEEE INT C INT ROBOT, P9198, DOI 10.1109/IROS51168.2021.9636522
   Rosinol A, 2019, IEEE INT CONF ROBOT, P8220, DOI [10.1109/ICRA.2019.8794456, 10.1109/icra.2019.8794456]
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schubert D, 2018, IEEE INT C INT ROBOT, P1680, DOI 10.1109/IROS.2018.8593419
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517
   Strasdat H, 2010, IEEE INT CONF ROBOT, P2657, DOI 10.1109/ROBOT.2010.5509636
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387
   Trevor AJB, 2012, IEEE INT CONF ROBOT, P3041, DOI 10.1109/ICRA.2012.6225287
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Wietrzykowski J., 2016, J AUTOMAT MOB ROBOT, V10, P3
   Yang YL, 2019, IEEE INT CONF ROBOT, P6094, DOI [10.1109/icra.2019.8794078, 10.1109/ICRA.2019.8794078]
   Yun DS, 2014, I C INF COMM TECH CO, P609, DOI 10.1109/ICTC.2014.6983225
   Zhou HZ, 2015, IEEE T VEH TECHNOL, V64, P1364, DOI 10.1109/TVT.2015.2388780
   Zou DP, 2019, IEEE T ROBOT, V35, P999, DOI 10.1109/TRO.2019.2915140
   Zuo X., 2021, P 2020 IEEERSJ INT C
NR 62
TC 1
Z9 1
U1 10
U2 30
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2023
VL 34
IS 2
AR e2046
DI 10.1002/cav.2046
EA MAY 2022
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D7UU4
UT WOS:000796865300001
DA 2024-07-18
ER

PT J
AU Bruno, A
   Moore, M
   Zhang, JL
   Lancette, S
   Ward, VP
   Chang, J
AF Bruno, Alessandro
   Moore, Morgan
   Zhang, Jinglu
   Lancette, Stephane
   Ward, Ville P.
   Chang, Jian
TI Toward a head movement-based system for multilayer digital content
   exploration
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE digital content exploration; head movements; interaction
ID RECOGNITION
AB In this article, we propose a novel technique based on Head Movement tracking to explore multilayer digital content. We extend an existing method by Kazemi et al. dealing with the extraction of facial landmarks to define the "head-gaze" of the user. We use the "head-gaze" to calculate the users' on-screen coordinates. Hovering the cursor over an interactive area for a given time threshold allows users to explore the next layer contents. Our experimental sessions allowed us to measure the technique's level of control and usability. Our results were promising, and users were able to interact with considerably small regions. Furthermore, our lightweight method can be used with a low-cost camera or webcam and a wide range of screen sizes and distances.
C1 [Bruno, Alessandro; Moore, Morgan; Zhang, Jinglu; Lancette, Stephane; Chang, Jian] Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
   [Ward, Ville P.] Shoppar Ltd, London, England.
C3 Bournemouth University
RP Bruno, A (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole, Dorset, England.
EM abruno@brounemouth.ac.uk
RI BRUNO, Alessandro/AAX-4679-2020
OI BRUNO, Alessandro/0000-0003-0707-6131; Chang, Jian/0000-0003-4118-147X
FU Innovate UK [39012]
FX Innovate UK, Grant/Award Number: Smart Grants (39012) - Shoppar:
   Dynamically Optimised Digital Content.
CR Al-Rahayfeh A, 2013, IEEE J TRANSL ENG HE, V1, DOI 10.1109/JTEHM.2013.2289879
   [Anonymous], 2013, OpenCV Computer Vision With Python
   Boyko N, 2018, 2018 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P478, DOI 10.1109/DSMP.2018.8478556
   Brauner P., 2015, Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, P145, DOI DOI 10.1007/978-3-319-19656-5_21
   Coetzer RC, 2011, IEEE INT VEH SYM, P66, DOI 10.1109/IVS.2011.5940406
   de la Barré R, 2009, LECT NOTES COMPUT SC, V5611, P161, DOI 10.1007/978-3-642-02577-8_18
   Einicke GA, 2012, SMOOTHING, FILTERING AND PREDICTION: ESTIMATING THE PAST, PRESENT AND FUTURE, P1
   Horning RD, 2013, US Patent, Patent No. [8,398,239, 8398239]
   Hotrakool W., 2010, Proc. International Conference on Electrical Engineering/Electronics Computer Telecommunications and Information Technology (ECTI-CON), P492
   Ju Q, 2019, P ACM HUM COMP INT E, V3, P1
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Klaib A F., 2019, Journal of Communications, V14, P614, DOI [10.12720/jcm.14.7.614-621, DOI 10.12720/JCM.14.7.614-621]
   Laird John E., 2009, ARTIF INTELL, V33, P1
   Langton SRH, 2000, J EXP PSYCHOL HUMAN, V26, P747, DOI 10.1037//0096-1523.26.2.747
   Müller JA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164627
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Patacchiola M, 2017, PATTERN RECOGN, V71, P132, DOI 10.1016/j.patcog.2017.06.009
   Pisharady PK, 2013, INT J COMPUT VISION, V101, P403, DOI 10.1007/s11263-012-0560-5
   Ruiz N., 2018, P CVPR WORKSH SALT L, P2074
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Scanziani M., 2020, BIORXIV, DOI [10.1101/2020.01.20.913160, DOI 10.1101/2020.01.20.913160]
   Tang A, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2735952
   Vivek Veeriah J., 2013, International Journal of Computer and Communication Engineering, V2, P219
   Wang K, 2019, PROC CVPR IEEE, P9823, DOI 10.1109/CVPR.2019.01006
   Yan L, 2014, 2014 Fifth International Conference on Intelligent Systems Design and Engineering Applications (ISDEA), P461, DOI 10.1109/ISDEA.2014.111
NR 28
TC 1
Z9 1
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD MAR
PY 2021
VL 32
IS 2
AR e1980
DI 10.1002/cav.1980
EA NOV 2020
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RK2HP
UT WOS:000594379100001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Han, Y
   Chao, QW
   Jin, XG
AF Han, Yi
   Chao, Qianwen
   Jin, Xiaogang
TI A simplified force model for mixed traffic simulation
SO COMPUTER ANIMATION AND VIRTUAL WORLDS
LA English
DT Article
DE crowd animation; force-based model; multiagent system; traffic
   simulation
ID ANIMATION
AB We present a simplified force-based heterogeneous traffic simulation model to facilitate consistent adjustment of the parameters involved. Different from previous work which requires the adjustment of multiple ad hoc parameters to produce satisfactory results, our approach can achieve similar results by using clear and meaningful parameters to simulate interactions between various kinds of road users. To simulate diverse and realistic motions of road users, we parameterize the coefficients of the force model for better detailed motion control. Our approach is also scalable to new types of road users, and facilitates an object-oriented implementation with high performance. We validate our framework with extensive experiments.
C1 [Han, Yi; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Chao, Qianwen] Xidian Univ, Dept Comp Sci, Xian, Peoples R China.
   [Jin, Xiaogang] Zhejiang Univ, ZJU Tencent Game & Intelligent Graph Innovat Tech, Hangzhou, Peoples R China.
C3 Zhejiang University; Xidian University; Zhejiang University
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
EM jin@cad.zju.edu.cn
OI Han, Yi/0000-0002-9548-7979; Jin, Xiaogang/0000-0001-7339-2920
FU Key Research and Development Program of Zhejiang Province [2018C01090,
   2020C03096]; National Key R&D Program of China [2017YFB1002600];
   National Natural Science Foundation of China [61702393, 61972344,
   62036010]
FX The Key Research and Development Program of Zhejiang Province,
   Grant/Award Numbers: 2018C01090, 2020C03096; The National Key R&D
   Program of China, Grant/Award Number: 2017YFB1002600; The National
   Natural Science Foundation of China, Grant/Award Numbers: 61702393,
   61972344, 62036010
CR Best A., 2018, C COMPUTER VISION PA, P1048
   Bi H., 2016, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P149
   Chao QW, 2020, COMPUT GRAPH FORUM, V39, P287, DOI 10.1111/cgf.13803
   Chao QW, 2019, IEEE INT CONF ROBOT, P8298, DOI [10.1109/icra.2019.8794430, 10.1109/ICRA.2019.8794430]
   Chao QW, 2018, IEEE T VIS COMPUT GR, V24, P1167, DOI 10.1109/TVCG.2017.2648790
   Chao QW, 2015, COMPUT ANIMAT VIRT W, V26, P405, DOI 10.1002/cav.1654
   Chao QW, 2013, GRAPH MODELS, V75, P305, DOI 10.1016/j.gmod.2013.07.003
   Dosovitskiy A., 2017, P 1 ANN C ROBOT LEAR, V78, P1
   Ferrer G, 2013, IEEE INT C INT ROBOT, P1688, DOI 10.1109/IROS.2013.6696576
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   HERMAN R, 1963, SCI AM, V209, P35, DOI 10.1038/scientificamerican1263-35
   Janai J., 2017, Computer vision for autonomous vehicles: Problems, datasets and state-of-the-art
   Karamouzas I, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.238701
   Kesting A, 2007, TRANSPORT RES REC, P86, DOI 10.3141/1999-10
   Krajzewicz D., 2012, Int. J. Adv. Syst. Meas., V5, P128
   Li WZ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130847
   Lovric M, 2016, TRANSPORT RES REC, P10, DOI 10.3141/2544-02
   NAGEL K, 1992, J PHYS I, V2, P2221, DOI 10.1051/jp1:1992277
   PIPES LA, 1953, J APPL PHYS, V24, P274, DOI 10.1063/1.1721265
   Schwarting W, 2018, ANNU REV CONTR ROBOT, V1, P187, DOI 10.1146/annurev-control-060117-105157
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   Sewall J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024169
   Sewall J, 2011, IEEE T VIS COMPUT GR, V17, P26, DOI 10.1109/TVCG.2010.27
   Shen JJ, 2012, GRAPH MODELS, V74, P265, DOI 10.1016/j.gmod.2012.04.002
   Wilkie D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462021
NR 26
TC 11
Z9 12
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1546-4261
EI 1546-427X
J9 COMPUT ANIMAT VIRT W
JI Comput. Animat. Virtual Worlds
PD JAN
PY 2021
VL 32
IS 1
AR e1974
DI 10.1002/cav.1974
EA OCT 2020
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QP5QT
UT WOS:000575332600001
DA 2024-07-18
ER

EF