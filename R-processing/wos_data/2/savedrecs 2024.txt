FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Huang, ZZ
   Tozoni, DC
   Gjoka, A
   Ferguson, Z
   Schneider, T
   Panozzo, D
   Zorin, D
AF Huang, Zizhou
   Tozoni, Davi Colli
   Gjoka, Arvi
   Ferguson, Zachary
   Schneider, Teseo
   Panozzo, Daniele
   Zorin, Denis
TI Differentiable solver for time-dependent deformation problems with
   contact
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Differentiable simulation; finite element method; elastodynamics;
   frictional contact
ID SENSITIVITY-ANALYSIS; SHAPE OPTIMIZATION; FRICTION; DESIGN
AB We introduce a general differentiable solver for time-dependent deformation problems with contact and friction. Our approach uses a finite element discretization with a high-order time integrator coupled with the recently proposed incremental potential contact method for handling contact and friction forces to solve ODE- and PDE-constrained optimization problems on scenes with complex geometry. It supports static and dynamic problems and differentiation with respect to all physical parameters involved in the physical problem description, which include shape, material parameters, friction parameters, and initial conditions. Our analytically derived adjoint formulation is efficient, with a small overhead (typically less than 10% for nonlinear problems) over the forward simulation, and shares many similarities with the forward problem, allowing the reuse of large parts of existing forward simulator code.
   We implement our approach on top of the open-source PolyFEM library and demonstrate the applicability of our solver to shape design, initial condition optimization, and material estimation on both simulated results and physical validations.
C1 [Huang, Zizhou; Tozoni, Davi Colli; Gjoka, Arvi; Ferguson, Zachary; Zorin, Denis] NYU, 60 5th Ave, New York, NY 10011 USA.
   [Schneider, Teseo] Univ Victoria, Comp Sci, Victoria, BC, Canada.
   [Panozzo, Daniele] NYU, Comp Sci, 60 5th Ave, New York, NY 10011 USA.
   [Schneider, Teseo] Univ Victoria, Dept Comp Sci, 3800 Finnerty Rd,Engn & Comp Sci Bldg, Victoria, BC V8P 5C2, Canada.
C3 New York University; University of Victoria; New York University;
   University of Victoria
RP Huang, ZZ (corresponding author), NYU, 60 5th Ave, New York, NY 10011 USA.
EM zizhou@nyu.edu; davi.tozoni@nyu.edu; ag4571@nyu.edu; zfergus@nyu.edu;
   teseo@uvic.ca; panozzo@nyu.edu; dzorin@cs.nyu.edu
FU NSF CAREER award [1652515]; NSF [OAC-1835712, CHS-1908767, CHS-1901091,
   IIS-2313156]; Sloan Fellowship
FX This work was supported in part through the NYU IT High Performance
   Computing resources, services, and staff expertise. This work was also
   partially supported by the NSF CAREER award under Grant No. 1652515, the
   NSF grants OAC-1835712, CHS-1908767, CHS-1901091, IIS-2313156, a Sloan
   Fellowship, and a gift from Adobe Research.
CR Alappat C, 2020, ACM TRANS PARALLEL C, V7, DOI 10.1145/3399732
   Allaire G., 2021, GEOMETRIC PARTIAL DI, V22, P1, DOI DOI 10.1016/BS.HNA.2020.10.004
   Alnaer MS, 2015, Archive of numerical software 3.100, P9, DOI [DOI 10.11588/ANS.2015.100.20553, 10.11588/ans.2015.100.20553]
   Chang MB, 2017, Arxiv, DOI arXiv:1612.00341
   Bacher Moritz, 2021, Curr. Robot. Rep, V2021, P1, DOI [10.1007/s43154-021-00052-7, DOI 10.1007/S43154-021-00052-7]
   Baque P, 2018, PR MACH LEARN RES, V80
   Belytschko T., 2000, NONLINEAR FINITE ELE
   Beremlijski P, 2014, SIAM J CONTROL OPTIM, V52, P3371, DOI 10.1137/130948070
   Bern James, 2019, Robotics: Science and Systems XV, V1, DOI [10.15607/rss.2019.xv, DOI 10.15607/RSS.2019.XV]
   Bern JM, 2020, 2020 3RD IEEE INTERNATIONAL CONFERENCE ON SOFT ROBOTICS (ROBOSOFT), P417, DOI [10.1109/RoboSoft48309.2020.9116011, 10.1109/robosoft48309.2020.9116011]
   Bischof C.H., 2000, Modem Methods and Algorithms of Quantum Chemistry, V3, P315
   Bollhöfer M, 2019, SIAM J SCI COMPUT, V41, pA380, DOI 10.1137/17M1147615
   Bollig M, 2020, AFR STUD-SER, V149, P3
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Brogliato Bernard, 1999, Nonsmooth mechanics
   Brown GE, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275011
   Chen BC, 2020, SMART MATER STRUCT, V29, DOI 10.1088/1361-665X/ab8b2d
   Daviet G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024173
   de Vaucorbeil Alban, 2019, Advances in Applied Mechanics, P1
   Desmorat B, 2007, INT J SOLIDS STRUCT, V44, P1132, DOI 10.1016/j.ijsolstr.2006.06.010
   Dokken Jorgen S., 2020, arXiv
   Du T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3490168
   Eck Christof, 2005, Unilateral Contact Problems: Variational Methods and Existence Theorems, DOI DOI 10.1201/9781420027365
   Ferguson Z, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459802
   Ferguson Zachary, 2020, IPC Toolkit
   Gavriil K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417843
   Geilinger M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417766
   Geuzaine C, 2009, INT J NUMER METH ENG, V79, P1309, DOI 10.1002/nme.2579
   Griewank A, 2008, OTHER TITL APPL MATH, V105, P1, DOI 10.1137/1.9780898717761
   Hafner C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356576
   Hahn D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356548
   Harmon D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360622
   Harmon D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531393
   Haslinger J., 1986, Aplikace Matematiky, V31, P54
   Heiden E, 2021, Arxiv, DOI arXiv:2011.04217
   Heiden E, 2021, ROBOT SCI SYS
   Herskovits J, 2000, STRUCT MULTIDISCIP O, V20, P214, DOI 10.1007/s001580050149
   Hoshyari S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323034
   Hsu J, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530165
   Hu YX, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392385
   Hu YM, 2019, IEEE INT CONF ROBOT, P6265, DOI [10.1109/icra.2019.8794333, 10.1109/ICRA.2019.8794333]
   Hu Yuanming, 2019, INT C LEARN REPR
   Jakob Wenzel, 2010, Mitsuba renderer
   Jatavallabhula Krishna Murthy, 2021, INT C LEARN REPR ICL
   Jiang ZS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417769
   Kikuchi Noboru, 1988, SIAM Studies in App. and Numer. Math., V8
   Knupp PM, 2001, SIAM J SCI COMPUT, V23, P193, DOI 10.1137/S1064827500371499
   Li MC, 2023, Arxiv, DOI arXiv:2307.15908
   Li MC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392425
   Li YF, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3527660
   Li ZH, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3618318
   Liang JB, 2019, ADV NEUR IN, V32
   Liang Junbang, 2020, ICML, P7847
   Ly M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275036
   Maloisel G, 2021, IEEE T ROBOT, V37, P996, DOI 10.1109/TRO.2020.3043654
   Margossian CC, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1305
   Maury A., 2017, SHAPE OPTIMISATION L
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Mitusch Sebastian K., 2019, Journal of Open Source Software, V4, P1292, DOI DOI 10.21105/JOSS.01292
   Moses WS, 2022, INT CONF HIGH PERFOR, DOI 10.1109/SC41404.2022.00065
   Naumann U, 2012, SOFTW ENVIRON TOOLS, V24, P1
   Otaduy MA, 2009, COMPUT GRAPH FORUM, V28, P559, DOI 10.1111/j.1467-8659.2009.01396.x
   Panetta J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073649
   Panetta J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766937
   Rabinovich M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983621
   Rojas J, 2021, Arxiv, DOI arXiv:2102.05791
   Schenck Connor, 2018, PMLR, V87, P317
   Schneider Teseo, 2019, PolyFEM
   Schumacher C, 2020, IEEE ROBOT AUTOM LET, V5, P3780, DOI 10.1109/LRA.2020.2982058
   Schumacher C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275085
   Shan SC, 2015, ADV MATER, V27, P4296, DOI 10.1002/adma.201501708
   Sharma A, 2018, STRUCT MULTIDISCIP O, V57, P17, DOI 10.1007/s00158-017-1833-y
   Skouras M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461979
   Stewart DE, 2001, PHILOS T ROY SOC A, V359, P2467, DOI 10.1098/rsta.2001.0904
   Stupkiewicz S, 2010, COMPUT METHOD APPL M, V199, P2165, DOI 10.1016/j.cma.2010.03.021
   Tapia J, 2020, SOFT ROBOT, V7, P332, DOI 10.1089/soro.2018.0162
   Tozoni DC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480552
   Tozoni DC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392451
   van Keulen F, 2005, COMPUT METHOD APPL M, V194, P3213, DOI 10.1016/j.cma.2005.02.002
   Verschoor M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3209887
   Wieschollek Patrick, 2016, CppOptimizationLibrary
   Wriggers P, 1995, ARCH COMPUT METHOD E, V2, P1, DOI 10.1007/BF02736195
   Xu Jie, 2022, arXiv, DOI [10.48550/ARXIV.2204.07137, DOI 10.48550/ARXIV.2204.07137]
   Zhang XT, 2016, COMPUT GRAPH FORUM, V35, P157, DOI 10.1111/cgf.12972
NR 84
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
AR 31
DI 10.1145/3657648
PG 30
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400007
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Kim, D
   Lee, M
   Museth, K
AF Kim, Doyub
   Lee, Minjae
   Museth, Ken
TI NeuralVDB: High-resolution Sparse Volume Representation using
   Hierarchical Neural Networks
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Sparse volumes; neural networks; implicit surface; volumetric models;
   compression
ID LAGRANGIAN CONTOURING METHOD; LEVEL SET; COMPRESSION; ALGORITHMS; WATER
AB We introduce NeuralVDB, which improves on an existing industry standard for efficient storage of sparse volumetric data, denoted VDB [Museth 2013], by leveraging recent advancements in machine learning. Our novel hybrid data structure can reduce the memory footprints of VDB volumes by orders of magnitude, while maintaining its flexibility and only incurring small (user-controlled) compression errors. Specifically, NeuralVDB replaces the lower nodes of a shallow and wide VDB tree structure with multiple hierarchical neural networks that separately encode topology and value information by means of neural classifiers and regressors respectively. This approach is proven to maximize the compression ratio while maintaining the spatial adaptivity offered by the higher-level VDB data structure. For sparse signed distance fields and density volumes, we have observed compression ratios on the order of 10x to more than 100x from already compressed VDB inputs, with little to no visual artifacts. Furthermore, NeuralVDB is shown to offer more effective compression performance compared to other neural representations such as Neural Geometric Level of Detail [Takikawa et al. 2021], Variable Bitrate Neural Fields [Takikawa et al. 2022a], and Instant Neural Graphics Primitives [Muller et al. 2022]. Finally, we demonstrate how warm-starting from previous frames can accelerate training, i.e., compression, of animated volumes as well as improve temporal coherency of model inference, i.e., decompression.
C1 [Kim, Doyub; Lee, Minjae; Museth, Ken] NVIDIA, 2788 San Tomas Expressway, Santa Clara, CA 95051 USA.
C3 Nvidia Corporation
RP Kim, D (corresponding author), NVIDIA, 2788 San Tomas Expressway, Santa Clara, CA 95051 USA.
EM doyubkim@nvidia.com; minjael@nvidia.com; kmuseth@nvidia.com
OI Kim, Doyub/0000-0002-8932-5519
CR Achilles Felix, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P491, DOI 10.1007/978-3-319-46720-7_57
   Bargteil AW, 2006, ACM T GRAPHIC, V25, P19, DOI 10.1145/1122501.1122503
   Boddeti N, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73333-4
   Bouaziz Sofien, 2016, P SIGGRAPH ASIA 2016, P1
   Brock A, 2016, Arxiv, DOI arXiv:1608.04236
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Chentanez N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964977
   Davies T, 2021, Arxiv, DOI arXiv:2009.09808
   Gailly J.-l., 2004, ZLIB COMPRESSION LIB
   Hedman P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5855, DOI 10.1109/ICCV48922.2021.00582
   Hoetzlein R. K, 2016, P HIGH PERF GRAPH, P109, DOI DOI 10.2312/HPG.20161197
   Houston B, 2006, ACM T GRAPHIC, V25, P151, DOI 10.1145/1122501.1122508
   Irving G, 2006, ACM T GRAPHIC, V25, P805, DOI 10.1145/1141911.1141959
   Jacot A, 2018, ADV NEUR IN, V31
   JangaFX, 2020, EmberGen VDB Dataset
   Ken Museth, 2011, P ACM SIGGRAPH 2011
   Kingma D. P., 2014, arXiv
   Kirchhoffer H, 2022, IEEE T CIRC SYST VID, V32, P3203, DOI 10.1109/TCSVT.2021.3095970
   Kraska T, 2018, INT CONF MANAGE DATA, P489, DOI 10.1145/3183713.3196909
   Lee M, 2019, IEEE T VIS COMPUT GR, V25, P1449, DOI 10.1109/TVCG.2018.2808972
   Lee Minjae, 2019, P 18 ANN ACM SIGGRAP, P1
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   Leveque RJ, 1996, SIAM J NUMER ANAL, V33, P627, DOI 10.1137/0733033
   Li Yuanzhan, 2022, arXiv
   Liu L., 2020, Advances in Neural Information Processing Systems, V33, P15651
   Liu Z, 2018, DES AUT CON, DOI 10.1145/3195970.3196022
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Maisano Jessie, 2003, CT Scan of a Chameleon
   Martel J, 2021, Arxiv, DOI arXiv:2105.02788
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Michalkiewicz M, 2019, IEEE I CONF COMP VIS, P4742, DOI 10.1109/ICCV.2019.00484
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Moseley B, 2021, Arxiv, DOI arXiv:2107.07871
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Müller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156
   Müller T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459812
   Müller T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417804
   Museth K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487235
   Museth Ken, 2021, P ACM SIGGRAPH 2021, P1
   Nielsen MB, 2006, J SCI COMPUT, V26, P261, DOI 10.1007/s10915-005-9062-8
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Paszke A, 2019, ADV NEUR IN, V32
   Peng DP, 1999, J COMPUT PHYS, V155, P410, DOI 10.1006/jcph.1999.6345
   Peng S., 2020, COMPUTER VISION ECCV
   Pennebaker William B, 1992, JPEG STILL IMAGE DAT
   Rahaman N, 2019, PR MACH LEARN RES, V97
   Saito S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275019
   Sattler M., 2005, SCA 05, P209, DOI [10.1145/1073368.1073398, DOI 10.1145/1073368.1073398]
   Setaluri R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661269
   Shazeer Noam, 2017, P ICLR POSTER
   Sitzmann V., 2020, Advances in Neural Information Processing Systems, V33, P10136
   Sitzmann V., 2020, Advances in neural information processing systems, V33, P7462, DOI DOI 10.48550/ARXIV.2006.09661
   Strain J, 2001, J COMPUT PHYS, V170, P373, DOI 10.1006/jcph.2001.6740
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Takikawa Towaki, 2022, ACM SIGGRAPH 2022 C, P1
   Takikawa Towaki, 2022, Kaolin Wisp: A PyTorch Library and Engine for Neural Fields Research
   Tancik M., 2020, ADV NEURAL INFORM PR, V33, P7537, DOI DOI 10.48550/ARXIV.2006.10739
   Tang DH, 2020, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR42600.2020.00137
   Tang DH, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275096
   The Blosc Development Team, 2020, Blosc
   Valette S, 2004, IEEE T VIS COMPUT GR, V10, P123, DOI 10.1109/TVCG.2004.1260764
   Vivo Patricio Gonzalez, 2015, The book of shaders: Fractal brownian motion
   Vizzo I, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031296
   Walt Disney Animation Studios, 2017, Disney Clouds Dataset
   Wrenninge Magnus, 2020, Field3D
   Wu T., 2021, arXiv
   Xie YH, 2022, COMPUT GRAPH FORUM, V41, P641, DOI 10.1111/cgf.14505
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Zhou ZW, 2017, PROC CVPR IEEE, P4761, DOI 10.1109/CVPR.2017.506
NR 71
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
DI 10.1145/3641817
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900007
OA Bronze, Green Submitted
DA 2024-08-05
ER

PT J
AU Careaga, C
   Aksoy, Y
AF Careaga, Chris
   Aksoy, Yagiz
TI Intrinsic Image Decomposition via Ordinal Shading
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Intrinsic decomposition; inverse rendering; mid-level vision; shading
   and reflectance estimation; image manipulation
AB Intrinsic decomposition is a fundamental mid-level vision problem that plays a crucial role in various inverse rendering and computational photography pipelines. Generating highly accurate intrinsic decompositions is an inherently under-constrained task that requires precisely estimating continuous-valued shading and albedo. In this work, we achieve high-resolution intrinsic decomposition by breaking the problem into two parts. First, we present a dense ordinal shading formulation using a shift- and scale-invariant loss in order to estimate ordinal shading cues without restricting the predictions to obey the intrinsic model. We then combine low- and high-resolution ordinal estimations using a second network to generate a shading estimate with both global coherency and local details. We encourage the model to learn an accurate decomposition by computing losses on the estimated shading as well as the albedo implied by the intrinsic model. We develop a straightforward method for generating dense pseudo ground truth using our model's predictions and multi-illumination data, enabling generalization to in-the-wild imagery. We present exhaustive qualitative and quantitative analysis of our predicted intrinsic components against state-of-the-art methods. Finally, we demonstrate the real-world applicability of our estimations by performing otherwise difficult editing tasks such as recoloring and relighting.
C1 [Careaga, Chris; Aksoy, Yagiz] Simon Fraser Univ, 8888 Univ Dr W, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Careaga, C (corresponding author), Simon Fraser Univ, 8888 Univ Dr W, Burnaby, BC V5A 1S6, Canada.
EM chris_careaga@sfu.ca; yagiz@sfu.ca
OI Aksoy, Yagiz/0000-0002-1495-0491; Careaga, Christian/0000-0002-0800-1118
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2020-05375]
FX We acknowledge the support of the Natural Sciences and Engineering
   Research Council of Canada (NSERC) [grant no. RGPIN-2020-05375].
CR Baslamisli AS, 2018, PROC CVPR IEEE, P6674, DOI 10.1109/CVPR.2018.00698
   Baslamisli AS, 2018, LECT NOTES COMPUT SC, V11210, P289, DOI 10.1007/978-3-030-01231-1_18
   Bell Sean, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601206
   Bi Sai, 2018, P EGSR
   Bonneel N, 2017, COMPUT GRAPH FORUM, V36, P593, DOI 10.1111/cgf.13149
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cheng LC, 2018, PROC CVPR IEEE, P656, DOI [10.1109/ICMLC.2018.8527016, 10.1109/CVPR.2018.00075]
   Das P, 2022, PROC CVPR IEEE, P19758, DOI 10.1109/CVPR52688.2022.01917
   Eftekhar A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10766, DOI 10.1109/ICCV48922.2021.01061
   Fan QN, 2018, PROC CVPR IEEE, P8944, DOI 10.1109/CVPR.2018.00932
   Garces E, 2022, INT J COMPUT VISION, V130, P836, DOI 10.1007/s11263-021-01563-8
   Garces E, 2012, COMPUT GRAPH FORUM, V31, P1415, DOI 10.1111/j.1467-8659.2012.03137.x
   Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428
   Janner M, 2017, ADV NEUR IN, V30
   Kovacs B, 2017, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2017.97
   Krähenbühl P, 2018, PROC CVPR IEEE, P2955, DOI 10.1109/CVPR.2018.00312
   Le HA, 2021, IEEE WINT CONF APPL, P1578, DOI 10.1109/WACV48630.2021.00162
   Lettry L, 2018, COMPUT GRAPH FORUM, V37, P409, DOI 10.1111/cgf.13578
   Lettry L, 2018, IEEE WINT CONF APPL, P1359, DOI 10.1109/WACV.2018.00153
   Li ZQ, 2018, PROC CVPR IEEE, P9039, DOI 10.1109/CVPR.2018.00942
   Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218
   Li ZQ, 2021, PROC CVPR IEEE, P7186, DOI 10.1109/CVPR46437.2021.00711
   Li ZQ, 2020, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR42600.2020.00255
   Li ZQ, 2018, LECT NOTES COMPUT SC, V11207, P74, DOI 10.1007/978-3-030-01219-9_5
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu YF, 2020, PROC CVPR IEEE, P3245, DOI 10.1109/CVPR42600.2020.00331
   Luo JD, 2020, IEEE T VIS COMPUT GR, V26, P3434, DOI 10.1109/TVCG.2020.3023565
   Ma WC, 2018, LECT NOTES COMPUT SC, V11218, P211, DOI 10.1007/978-3-030-01264-9_13
   Meka A, 2018, PROC CVPR IEEE, P6315, DOI 10.1109/CVPR.2018.00661
   Miangoleh SMH, 2021, PROC CVPR IEEE, P9680, DOI 10.1109/CVPR46437.2021.00956
   Murmann Lukas, 2019, P ICCV
   Narihira T, 2015, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2015.342
   Narihira T, 2015, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2015.7298915
   Nestmeyer T, 2017, PROC CVPR IEEE, P1771, DOI 10.1109/CVPR.2017.192
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Roberts M., 2021, P ICCV
   Sengupta S, 2019, IEEE I CONF COMP VIS, P8597, DOI 10.1109/ICCV.2019.00869
   Shen JB, 2011, PROC CVPR IEEE
   Shi J, 2017, PROC CVPR IEEE, P5844, DOI 10.1109/CVPR.2017.619
   Tan MX, 2019, PR MACH LEARN RES, V97
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xian K, 2020, PROC CVPR IEEE, P608, DOI 10.1109/CVPR42600.2020.00069
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Ye GZ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601135
   Zhao Q, 2012, IEEE T PATTERN ANAL, V34, P1437, DOI 10.1109/TPAMI.2012.77
   Zhou H, 2019, IEEE I CONF COMP VIS, P7819, DOI 10.1109/ICCV.2019.00791
   Zhou TH, 2015, IEEE I CONF COMP VIS, P3469, DOI 10.1109/ICCV.2015.396
   Zhu R, 2022, PROC CVPR IEEE, P2812, DOI 10.1109/CVPR52688.2022.00284
   Zoran D, 2015, IEEE I CONF COMP VIS, P388, DOI 10.1109/ICCV.2015.52
NR 50
TC 1
Z9 1
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 12
DI 10.1145/3630750
PG 24
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800012
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Ponton, JL
   Yun, HR
   Aristidou, A
   Andujar, C
   Pelechano, N
AF Ponton, Jose Luis
   Yun, Haoran
   Aristidou, Andreas
   Andujar, Carlos
   Pelechano, Nuria
TI SparsePoser: Real-time Full-body Motion Reconstruction from Sparse Data
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Motion tracking; character animation; wearable devices; sparse data
ID TRACKING
AB Accurate and reliable human motion reconstruction is crucial for creating natural interactions of full-body avatars in Virtual Reality (VR) and entertainment applications. As the Metaverse and social applications gain popularity, users are seeking cost-effective solutions to create full-body animations that are comparable in quality to those produced by commercial motion capture systems. In order to provide affordable solutions though, it is important to minimize the number of sensors attached to the subject's body. Unfortunately, reconstructing the full-body pose from sparse data is a heavily under-determined problem. Some studies that use IMU sensors face challenges in reconstructing the pose due to positional drift and ambiguity of the poses. In recent years, some mainstream VR systems have released 6-degree-of-freedom (6-DoF) tracking devices providing positional and rotational information. Nevertheless, most solutions for reconstructing full-body poses rely on traditional inverse kinematics (IK) solutions, which often produce non-continuous and unnatural poses. In this article, we introduce SparsePoser, a novel deep learning-based solution for reconstructing a full-body pose from a reduced set of six tracking devices. Our system incorporates a convolutional-based autoencoder that synthesizes high-quality continuous human poses by learning the human motion manifold from motion capture data. Then, we employ a learned IK component, made of multiple lightweight feed-forward neural networks, to adjust the hands and feet toward the corresponding trackers. We extensively evaluate our method on publicly available motion capture datasets and with real-time live demos. We show that our method outperforms state-of-the-art techniques using IMU sensors or 6-DoF tracking devices, and can be used for users with different body dimensions and proportions.
C1 [Ponton, Jose Luis; Yun, Haoran; Andujar, Carlos; Pelechano, Nuria] Univ Politecn Cataluna, Barcelona 08034, Spain.
   [Aristidou, Andreas] Univ Cyprus, 75 Kallipoleos, CY-1678 Nicosia, Cyprus.
   [Aristidou, Andreas] CYENS Ctr Excellence, 23 Plateia Dimarchias, CY-1016 Nicosia, Cyprus.
C3 Universitat Politecnica de Catalunya; University of Cyprus
RP Ponton, JL (corresponding author), Univ Politecn Cataluna, Barcelona 08034, Spain.
EM jose.luis.ponton@upc.edu; haoran.yun@upc.edu; a.aristidou@ieee.org;
   andujar@cs.upc.edu; npelechano@cs.upc.edu
RI Ponton, Jose Luis/HTN-5598-2023
OI Ponton, Jose Luis/0000-0001-6576-4528; Aristidou,
   Andreas/0000-0001-7754-0791
FU European Union [739578, 860768]; HORIZON-CL4-2022-HUMAN-01 [101093159];
   MCIN/AEI/FEDER, UE [PID2021-122136OB-C21]; European Union's Horizon 2020
   Research and Innovation Programme [739578]; Government of the Republic
   of Cyprus through the Deputy Ministry of Research, Innovation and
   Digital Policy; Spanish Ministry of Universities [FPU21/01927]
FX This work has received funding from the European Union's Horizon 2020
   research and innovation programme under the Marie SkLodowska-Curie grant
   agreement No 860768 (CLIPE project), HORIZON-CL4-2022-HUMAN-01 grant
   agreement No 101093159 (XR4ED), and from
   MCIN/AEI/10.13039/501100011033/FEDER, UE (PID2021-122136OB-C21). This
   project has also received funding from the European Union's Horizon 2020
   Research and Innovation Programme under Grant Agreement No 739578 and
   the Government of the Republic of Cyprus through the Deputy Ministry of
   Research, Innovation and Digital Policy. Jose Luis Ponton was also
   funded by the Spanish Ministry of Universities (FPU21/01927).
CR Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392462
   Ahuja K, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3463499
   Aliakbarian S, 2022, PROC CVPR IEEE, P13243, DOI 10.1109/CVPR52688.2022.01290
   Ames B, 2022, IEEE ROBOT AUTOM LET, V7, P7177, DOI 10.1109/LRA.2022.3181374
   Andreou N, 2022, COMPUT GRAPH FORUM, V41, P155, DOI 10.1111/cgf.14632
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Aristidou A, 2019, ACM J COMPUT CULT HE, V12, DOI 10.1145/3344383
   Bensadoun R., 2022, PMLR, P1787
   Bócsi B, 2011, IEEE INT C INT ROBOT, P698, DOI 10.1109/IROS.2011.6048552
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Chatzitofis A, 2020, IEEE ACCESS, V8, P176241, DOI 10.1109/ACCESS.2020.3026276
   Clavet Simon, 2016, P GAM DEV C
   Csiszar A, 2017, I C MECH MACH VIS PR, P372
   Debarba HG, 2022, IEEE T VIS COMPUT GR, V28, P1880, DOI 10.1109/TVCG.2020.3025175
   Dittadi A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11667, DOI 10.1109/ICCV48922.2021.01148
   Duka AV, 2014, PROC TECH, V12, P20, DOI 10.1016/j.protcy.2013.12.451
   FLASH T, 1985, J NEUROSCI, V5, P1688, DOI 10.1523/jneurosci.05-07-01688.1985
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Ghorbani N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11097, DOI 10.1109/ICCV48922.2021.01093
   Gonçalves G, 2022, VIRTUAL REAL-LONDON, V26, P1, DOI 10.1007/s10055-021-00530-5
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Huang J, 2017, COMPUT GRAPH FORUM, V36, P418, DOI 10.1111/cgf.13089
   Huang YH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275108
   Jia Yan-Bin, 2013, Dual quaternions
   Jiang JX, 2022, LECT NOTES COMPUT SC, V13665, P443, DOI 10.1007/978-3-031-20065-6_26
   Jiang YF, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555428
   Kavan L, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P39
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Loshchilov I., 2018, INT C LEARN REPR
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Oliva R, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.937191
   Paszke A, 2019, ADV NEUR IN, V32
   Pavllo D., 2018, P BRIT MACH VIS C, P1
   Pavllo D, 2020, INT J COMPUT VISION, V128, P855, DOI 10.1007/s11263-019-01245-6
   Ponton JL, 2022, COMPUT GRAPH FORUM, V41, P107, DOI 10.1111/cgf.14628
   Ponton Jose Luis, 2022, P EUR 2022 SHORT PAP, P77, DOI [10.2312/egs20221037, DOI 10.2312/EGS20221037]
   Ren H, 2020, ROBOT AUTON SYST, V124, DOI 10.1016/j.robot.2019.103386
   RootMotion, 2017, Final IK
   Toothman N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P756, DOI [10.1109/vr.2019.8798108, 10.1109/VR.2019.8798108]
   Vaswani A, 2017, ADV NEUR IN, V30
   Victor L, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2013
   von Marcard T, 2017, COMPUT GRAPH FORUM, V36, P349, DOI 10.1111/cgf.13131
   Winkler A, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555411
   Wu XM, 2011, IEEE COMPUT GRAPH, V31, P69, DOI 10.1109/MCG.2009.111
   Xsens, 2000, 3D motion tracking
   Yang D, 2021, COMPUT GRAPH FORUM, V40, P265, DOI 10.1111/cgf.142631
   Yi XY, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592099
   Yi XY, 2022, PROC CVPR IEEE, P13157, DOI 10.1109/CVPR52688.2022.01282
   Yi XY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459786
   Yun HR, 2023, Symposium Virtual Re, P286, DOI 10.1109/VR55154.2023.00044
   Zeng Q, 2022, VIRTUAL REAL-LONDON, V26, P1391, DOI 10.1007/s10055-022-00635-5
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
   Zhou YX, 2020, PROC CVPR IEEE, P5345, DOI 10.1109/CVPR42600.2020.00539
NR 53
TC 3
Z9 3
U1 8
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 5
DI 10.1145/3625264
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800005
OA hybrid, Green Submitted, Green Published
DA 2024-08-05
ER

PT J
AU Kucherenko, T
   Wolfert, P
   Yoon, Y
   Viegas, C
   Nikolov, T
   Tsakov, M
   Henter, GE
AF Kucherenko, Taras
   Wolfert, Pieter
   Yoon, Youngwoo
   Viegas, Carla
   Nikolov, Teodor
   Tsakov, Mihail
   Henter, Gustav Eje
TI Evaluating Gesture Generation in a Large-scale Open Challenge: The GENEA
   Challenge 2022
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Animation; gesture generation; embodied; conversational agents;
   evaluation paradigms
ID SPEECH; ASSOCIATION; ANIMATION; BEAT
AB This article reports on the second GENEA Challenge to benchmark datadriven automatic co-speech gesture generation. Participating teams used the same speech and motion dataset to build gesture-generation systems. Motion generated by all these systems was rendered to video using a standardised visualisation pipeline and evaluated in several large, crowdsourced user studies. Unlike when comparing different research articles, differences in results are here only due to differences betweenmethods, enabling direct comparison between systems. The dataset was based on 18 hours of fullbody motion capture, including fingers, of different persons engaging in a dyadic conversation. Ten teams participated in the challenge across two tiers: full-body and upper-body gesticulation. For each tier, we evaluated both the human-likeness of the gesture motion and its appropriateness for the specific speech signal. Our evaluations decouple human-likeness from gesture appropriateness, which has been a difficult problem in the field.
   The evaluation results show some synthetic gesture conditions being rated as significantly more human-like than 3D human motion capture. To the best of our knowledge, this has not been demonstrated before. On the other hand, all synthetic motion is found to be vastly less appropriate for the speech than the original motion-capture recordings. We also find that conventional objective metrics do not correlate well with subjective human-likeness ratings in this large evaluation. The one exception is the Frechet gesture distance (FGD), which achieves a Kendall's tau rank correlation of around -0.5. Based on the challenge results we formulate numerous recommendations for system building and evaluation.
C1 [Kucherenko, Taras] Elect Arts Inc, SEED, Stockholm, Sweden.
   [Wolfert, Pieter] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Gelderland, Netherlands.
   [Wolfert, Pieter] Univ Ghent, IDLab, Ghent, Belgium.
   [Yoon, Youngwoo] ETRI, Daejeon, South Korea.
   [Viegas, Carla] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Viegas, Carla] Nova Univ Lisbon, Lisbon, Portugal.
   [Nikolov, Teodor; Tsakov, Mihail] Umea Univ, Dept Comp Sci, Umea, Sweden.
   [Nikolov, Teodor; Henter, Gustav Eje] Motorica AB, Stockholm, Sweden.
   [Henter, Gustav Eje] KTH Royal Inst Technol, Div Speech Mus & Hearing, Stockholm, Sweden.
C3 Radboud University Nijmegen; Ghent University; Electronics &
   Telecommunications Research Institute - Korea (ETRI); Carnegie Mellon
   University; Universidade Nova de Lisboa; Umea University; Royal
   Institute of Technology
RP Kucherenko, T (corresponding author), Elect Arts Inc, SEED, Stockholm, Sweden.
EM tkucherenko@ea.com; pieter.wolfert@donders.ru.nl; youngwoo@etri.re.kr;
   cviegas@andrew.cmu.edu; tnikolov@hotmail.com; tsakovm@gmail.com;
   ghe@kth.se
FU Industrial Fundamental Technology Development Program - MOTIE, Korea
   [20023495]; Portuguese Foundation for Science and Technology through
   Wallenberg Research Arena (WARA) Media and Language
   [SFRH/BD/127842/2016]; Knut and Alice Wallenberg Foundation, through
   Wallenberg Research Arena (WARA) Media and Language; Flemish Research
   Foundation (FWO) [1S95020N]
FX This research was partially supported by the Industrial Fundamental
   Technology Development Program (no. 20023495) funded by MOTIE, Korea, by
   the Flemish Research Foundation (FWO) grant no. 1S95020N, by the
   Portuguese Foundation for Science and Technology grant no.
   SFRH/BD/127842/2016, and by the Knut and Alice Wallenberg Foundation,
   both through Wallenberg Research Arena (WARA) Media and Language-with
   in-kind contribution from the Electronic Arts R&D department, SEED-and
   through theWallenberg AI, Autonomous Systems and Software Program
   (WASP).
CR Ahuja C, 2022, PROC CVPR IEEE, P20534, DOI 10.1109/CVPR52688.2022.01991
   Ahuja C, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1884
   Alexanderson Simon, 2023, ACM Transactions on Graphics, DOI 10.1145/3592458
   Alexanderson S, 2020, COMPUT GRAPH FORUM, V39, P487, DOI 10.1111/cgf.13946
   Alexanderson Simon, 2020, P GENEA WORKSH GENEA, DOI [DOI 10.5281/ZENODO.4088600, 10.5281/zenodo.4088599, DOI 10.5281/ZENODO.4088599]
   Ao TL, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555435
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Baevski A., 2020, P NEURIPS, V33, P12449
   BARNARD GA, 1945, NATURE, V156, P177, DOI 10.1038/156177a0
   Bergmann K, 2010, LECT NOTES ARTIF INT, V6356, P104, DOI 10.1007/978-3-642-15892-6_11
   Bergmann K, 2009, LECT NOTES ARTIF INT, V5773, P76, DOI 10.1007/978-3-642-04380-2_12
   Bergmann Kirsten, 2011, P WORKSH GEST SPEECH
   Bhattacharya U, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2027, DOI 10.1145/3474085.3475223
   Black Alan W., 2005, P ANN C INT SPEECH C, P77, DOI [10.21437/Interspeech.2005-72, DOI 10.21437/INTERSPEECH.2005-72]
   Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652
   Bojanowski Piotr, 2017, T ASSOC COMPUT LING, V5, P135, DOI [10.48550/arXiv.1607.04606, DOI 10.1162/TACLA00051]
   Bosker HR, 2021, P ROY SOC B-BIOL SCI, V288, DOI 10.1098/rspb.2020.2419
   Bozkurt E, 2015, IEEE INT CON MULTI
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165
   Buttner Michael, 2015, P NUCL AI
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Chang CJ, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P784, DOI 10.1145/3536221.3558060
   Charfuelan M, 2013, INTERSPEECH, P1563
   Chen K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459932
   Chen SY, 2022, IEEE J-STSP, V16, P1505, DOI 10.1109/JSTSP.2022.3188113
   Chiu CC, 2015, LECT NOTES ARTIF INT, V9238, P152, DOI 10.1007/978-3-319-21996-7_17
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   European Broadcasting Union, 2020, EBU Recommendation EBU R 128v4
   Ferstl Y, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2016
   Ferstl Y, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P93, DOI 10.1145/3267851.3267898
   Ghorbani S, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P778, DOI 10.1145/3536221.3558068
   Govender A, 2019, INTERSPEECH, P1551, DOI 10.21437/Interspeech.2019-1783
   Hahn Gerald J., 1991, Statistical Intervals: A Guide for Practitioners, DOI [10.1002/9780470316771, DOI 10.1002/9780470316771]
   He Y, 2022, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS, IVA 2022, DOI 10.1145/3514197.3549697
   He ZY, 2022, INT J COMPUT GAMES T, V2022, DOI 10.1155/2022/1828293
   Hensel M, 2017, ADV NEUR IN, V30
   Holler J, 2018, PSYCHON B REV, V25, P1900, DOI 10.3758/s13423-017-1363-z
   HOLM S, 1979, SCAND J STAT, V6, P65
   Huang WC, 2022, INTERSPEECH, P4536, DOI 10.21437/Interspeech.2022-970
   International Telecommunication Union Telecommunication Standardisation Sector, 1996, Recommendation ITU-T P.800
   Ishi CT, 2018, IEEE ROBOT AUTOM LET, V3, P3757, DOI 10.1109/LRA.2018.2856281
   Ishii R, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P87, DOI 10.1145/3267851.3267866
   Jonell Patrik, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P707, DOI 10.1145/3462244.3479957
   Jonell P, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423911
   Jonell P, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423860
   Kaneko N, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P753, DOI 10.1145/3536221.3558061
   Kendall M. G., 1948, Rank correlation methods.
   King S, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.006
   Korzun V, 2022, COMPANION PUBLICATION OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P94, DOI 10.1145/3536220.3558801
   Korzun Vladislav, 2021, P COMP LING INT TECH, DOI [10.28995/2075-7182-2021-20-425-432, DOI 10.28995/2075-7182-2021-20-425-432]
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kucherenko Taras, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P242, DOI 10.1145/3382507.3418815
   Kucherenko T, 2023, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2023, P792, DOI 10.1145/3577190.3616120
   Kucherenko T, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P11, DOI 10.1145/3397481.3450692
   Kucherenko T, 2021, PROCEEDINGS OF THE 21ST ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA), P145, DOI 10.1145/3472306.3478333
   Kucherenko T, 2021, INT J HUM-COMPUT INT, V37, P1300, DOI 10.1080/10447318.2021.1883883
   Kucherenko T, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P97, DOI 10.1145/3308532.3329472
   Kucherenko Taras, 2022, P INT C AUT AG MULT, P770, DOI DOI 10.5555/3535850
   Le Quoc Anh., 2012, Evaluating an Expressive Gesture Model for a Humanoid Robot: Experimental Results
   Lee G, 2019, IEEE I CONF COMP VIS, P763, DOI 10.1109/ICCV.2019.00085
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Levine S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778861
   Li NH, 2019, AAAI CONF ARTIF INTE, P6706
   Li RL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13381, DOI 10.1109/ICCV48922.2021.01315
   Liang YZ, 2022, PROC CVPR IEEE, P10463, DOI 10.1109/CVPR52688.2022.01022
   Liu HY, 2022, LECT NOTES COMPUT SC, V13667, P612, DOI 10.1007/978-3-031-20071-7_36
   Liu X, 2022, PROC CVPR IEEE, P10452, DOI 10.1109/CVPR52688.2022.01021
   Liu Y, 2021, PROCEEDINGS OF THE 9TH INTERNATIONAL USER MODELING, ADAPTATION AND PERSONALIZATION HUMAN-AGENT INTERACTION, HAI 2021, P31, DOI 10.1145/3472307.3484167
   Lu JH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P900, DOI 10.1109/ICASSP39728.2021.9414660
   Lu SH, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P790, DOI 10.1145/3536221.3558059
   Lydersen S, 2009, STAT MED, V28, P1159, DOI 10.1002/sim.3531
   Maiorca A, 2023, 15TH ANNUAL ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION AND GAMES, MIG 2023, DOI 10.1145/3623264.3624443
   Malisz Zofia, 2019, P INT C PHON SCI ICP, P487, DOI [10.31234/osf.io/dxvhc, DOI 10.31234/OSF.IO/DXVHC]
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   Mehta Shivam, 2023, P ISCA SPEECH SYNTH
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mittag G, 2020, INTERSPEECH, P1748, DOI 10.21437/Interspeech.2020-2382
   Möller S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1325
   Montgomery G, 2018, J LANG SOC PSYCHOL, V37, P330, DOI 10.1177/0261927X17728361
   MORASSO P, 1981, EXP BRAIN RES, V42, P223
   Nikulin Mikhail S., 2001, Encyclopedia of mathematics
   Nyatsanga S, 2023, COMPUT GRAPH FORUM, V42, P569, DOI 10.1111/cgf.14776
   Oord A.v.d., 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.03499
   Pang Kunkun, 2020, P GENEA WORKSH GENEA, DOI [10.5281/zenodo.4090878, DOI 10.5281/ZENODO.4090878]
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Radford A, 2021, PR MACH LEARN RES, V139
   Ravanelli M, 2020, INT CONF ACOUST SPEE, P6989, DOI [10.1109/ICASSP40776.2020.9053569, 10.1109/icassp40776.2020.9053569]
   Rebol M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P573, DOI 10.1109/VR50410.2021.00082
   Ribeiro MS, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1586
   Sadoughi N, 2019, SPEECH COMMUN, V110, P90, DOI 10.1016/j.specom.2019.04.005
   Saleh K, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P748, DOI 10.1145/3536221.3558064
   Salem M., 2011, 2011 RO-MAN: The 20th IEEE International Symposium on Robot and Human Interactive Communication, P247, DOI 10.1109/ROMAN.2011.6005285
   Salem M, 2013, INT J SOC ROBOT, V5, P313, DOI 10.1007/s12369-013-0196-9
   Salem M, 2012, INT J SOC ROBOT, V4, P201, DOI 10.1007/s12369-011-0124-9
   Salvi G, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/191940
   Saratxaga I, 2016, SPEECH COMMUN, V81, P30, DOI 10.1016/j.specom.2016.04.001
   Saund C, 2021, IEEE INT CONF AUTOMA, DOI 10.1109/FG52635.2021.9667023
   Sebastian Grassia F., 1998, Journal of graphics tools, V3, P29, DOI [DOI 10.1080/10867651.1998.10487493, 10.1080/10867651.1998.10487493]
   SEN PK, 1968, J AM STAT ASSOC, V63, P1379
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Shimazu A, 2018, IEEE ROMAN, P961, DOI 10.1109/ROMAN.2018.8525621
   Siyang Wang, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P177, DOI 10.1145/3462244.3479914
   Székely É, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3335
   Teshima H, 2022, IEEE INT C INT ROBOT, P8286, DOI 10.1109/IROS47612.2022.9981734
   Thangthai Ausdang, 2021, 2021 18th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), P718, DOI 10.1109/ECTI-CON51831.2021.9454931
   Theil H., 1950, HENRI THEILS CONTRIB, V12, P173, DOI DOI 10.1007/978-94-011-2546-8_20
   Thompson Bruce, 1984, Canonical correlation analysis: uses and interpretation
   Toderici George, 2020, CLIC 2020: Overview, and Analysis of the Competition Results
   UNO Y, 1989, BIOL CYBERN, V61, P89, DOI 10.1007/BF00204593
   Wagner P, 2014, SPEECH COMMUN, V57, P209, DOI 10.1016/j.specom.2013.09.008
   Wang A, 2019, ADV NEUR IN, V32
   Windle J, 2023, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2023, P802, DOI 10.1145/3577190.3616116
   Winters Stephen J., 2004, P RES SPOK LANG PROC, P95
   Wolfert Pieter, 2023, ICMI '23 Companion: International Conference on Multimodal Interaction, P6, DOI 10.1145/3610661.3617160
   Wolfert Pieter, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P494, DOI 10.1145/3462244.3479889
   Wolfert P, 2022, IEEE T HUM-MACH SYST, V52, P379, DOI 10.1109/THMS.2022.3149173
   Wolfert Pieter, 2019, P ICDL EPIROB WORKSH
   Woo Jieyeon, 2021, P ACM INT C MULT INT, P822, DOI [10.1145/3462244.3481275, DOI 10.1145/3462244.3481275]
   Yang SC, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P758, DOI 10.1145/3536221.3558066
   Yazdian PJ, 2022, IEEE INT C INT ROBOT, P3100, DOI 10.1109/IROS47612.2022.9981117
   Ye S, 2022, LECT NOTES COMPUT SC, V13665, P712, DOI 10.1007/978-3-031-20065-6_41
   Yoon Y, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P736, DOI 10.1145/3536221.3558058
   Yoon Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417838
   Yoon Y, 2019, IEEE INT CONF ROBOT, P4303, DOI [10.1109/icra.2019.8793720, 10.1109/ICRA.2019.8793720]
   Yoshimura T, 2016, INTERSPEECH, P342, DOI 10.21437/Interspeech.2016-847
   Youngwoo Yoon, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P826, DOI 10.1145/3472749.3474789
   Zhang F, 2023, LECT NOTES COMPUT SC, V13833, P231, DOI 10.1007/978-3-031-27077-2_18
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
   Zhang K, 2020, IEEE COMPUT SOC CONF, P2045, DOI 10.1109/CVPRW50498.2020.00254
   Zhou C, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P764, DOI 10.1145/3536221.3558063
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
NR 134
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
AR 32
DI 10.1145/3656374
PG 28
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400008
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Huang, KM
   Chitalu, FM
   Lin, HC
   Komura, T
AF Huang, Kemeng
   Chitalu, Floyd M.
   Lin, Huancheng
   Komura, Taku
TI GIPC: Fast and Stable Gauss-Newton Optimization of IPC Barrier Energy
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE IPC; Barrier Hessian; eigen analysis; GPU
ID COLLISION DETECTION; CONTACT
AB Barrier functions are crucial for maintaining an intersection- and inversionfree simulation trajectory but existing methods, which directly use distance can restrict implementation design and performance. We present an approach to rewriting the barrier function for arriving at an efficient and robust approximation of its Hessian. The key idea is to formulate a simplicial geometric measure of contact using mesh boundary elements, from which analytic eigensystems are derived and enhanced with filtering and stiffening terms that ensure robustness with respect to the convergence of a Project-Newton solver. A further advantage of our rewriting of the barrier function is that it naturally caters to the notorious case of nearly parallel edge-edge contacts for which we also present a novel analytic eigensystem. Our approach is thus well suited for standard second-order unconstrained optimization strategies for resolving contacts, minimizing nonlinear nonconvex functions where the Hessian may be indefinite. The efficiency of our eigensystems alone yields a 3x speedup over the standard Incremental Potential Contact (IPC) barrier formulation. We further apply our analytic proxy eigensystems to produce an entirely GPU-based implementation of IPCwith significant further acceleration.
C1 [Huang, Kemeng; Chitalu, Floyd M.; Lin, Huancheng; Komura, Taku] Univ Hong Kong, TransGP, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Huang, KM (corresponding author), Univ Hong Kong, TransGP, Hong Kong, Peoples R China.
EM kmhuang@connect.hku.hk; floyd.m.chitalu@gmail.com; lamws@connect.hku.hk;
   taku@cs.hku.hk
OI Huang, Kemeng/0000-0001-9147-2289; Chitalu, Floyd/0000-0001-9489-8592;
   Lin, Huancheng/0000-0003-4446-1442
FU Research Grant Council of Hong Kong [GRF 17210222]; Innovation and
   Technology Commission of the HKSAR Government under the InnoHK
   initiative (TransGP Project); JC STEM Lab of Robotics for Soft Materials
   - Hong Kong Jockey Club Charities Trust
FX This work was partially funded by the Research Grant Council of Hong
   Kong (Grant No. GRF 17210222). This work was also supported by the
   Innovation and Technology Commission of the HKSAR Government under the
   InnoHK initiative (TransGP Project), and the JC STEM Lab of Robotics for
   Soft Materials funded by The Hong Kong Jockey Club Charities Trust.
CR Allard J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778819
   Andreu S., 2022, P ACM SPECIAL INTERE, P2
   Apetrei Ciprian., 2014, Computer Graphics and Visual Computing (CGVC)
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Chitalu FM, 2020, COMPUT GRAPH FORUM, V39, P509, DOI 10.1111/cgf.13948
   Christer Ericson, 2005, Real-Time Collision Detection, P235
   Erleben K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3096239
   Fang Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459757
   Ferguson Z, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459802
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275044
   Geoffrey Irving, 2004, P S COMP AN, P131, DOI DOI 10.1145/1028523.1028541
   Guennebaud Gael, 2022, Eigen v3.4
   Harmon D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360622
   Huang ZZ, 2024, Arxiv, DOI arXiv:2205.13643
   Jiang ZS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130895
   Kane C, 2000, INT J NUMER METH ENG, V49, P1295, DOI 10.1002/1097-0207(20001210)49:10<1295::AID-NME993>3.0.CO;2-W
   Kane C, 1999, COMPUT METHOD APPL M, V180, P1, DOI 10.1016/S0045-7825(99)00034-1
   Karras Tero, 2012, P 4 ACM SIGGRAPH EUR, P33, DOI [10.2312/EGGH/HPG12/033-037, DOI 10.2312/EGGH/HPG12/033-037]
   Kaufman DM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409117
   Kim T, 2020, COMPUT GRAPH FORUM, V39, P171, DOI 10.1111/cgf.14111
   Kim T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323014
   Kim Theodore, 2020, P ACM SPECIAL INTERE
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lan L, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530069
   Lan L, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459753
   Lan Lei, 2022, Affine body dynamics: Fast, stable & intersection-free simulation of stiff materials
   Lauterbach C, 2010, COMPUT GRAPH FORUM, V29, P419, DOI 10.1111/j.1467-8659.2009.01611.x
   Lauterbach C, 2009, COMPUT GRAPH FORUM, V28, P375, DOI 10.1111/j.1467-8659.2009.01377.x
   Li C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417763
   Li MC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459767
   Li MC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392425
   Li SW, 2015, COMPUT GRAPH FORUM, V34, P269, DOI 10.1111/cgf.12765
   Lin HC, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555507
   Macklin M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3338695
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Meister D, 2021, COMPUT GRAPH FORUM, V40, P683, DOI 10.1111/cgf.142662
   Müller M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766907
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Otaduy MA, 2009, COMPUT GRAPH FORUM, V28, P559, DOI 10.1111/j.1467-8659.2009.01396.x
   Pabst S, 2010, COMPUT GRAPH FORUM, V29, P1605, DOI 10.1111/j.1467-8659.2010.01769.x
   Panetta J, 2020, Arxiv, DOI [arXiv:2008.10698, 10.48550/ARXIV.2008.10698, DOI 10.48550/ARXIV.2008.10698]
   Provot Xavier, 1997, P EUR WORKSH COMP AN, P177
   Shi A, 2023, P ACM COMPUT GRAPH, V6, DOI 10.1145/3606934
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   Sifakis Eftychios, 2012, P ACM SPECIAL INTERE, DOI DOI 10.1145/2343483.2343501
   Sifakis Eftychios, 2008, P S COMPUTER ANIMATI
   Smith B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3241041
   Smith B, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3180491
   Tang M, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203188
   Tang M, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275005
   Tang M, 2016, COMPUT GRAPH FORUM, V35, P511, DOI 10.1111/cgf.12851
   Teran J., 2005, Proc_2005_ACM_SIGGRAPH/Eurograph_Symp_Comp Anim, P181
   Tissot Olivier, 2019, Iterative Methods for Solving Linear Systems on Massively Parallel Architectures
   Verschoor M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3209887
   Wang BL, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3460775
   Wang HM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459787
   Wang XL, 2018, COMPUT GRAPH FORUM, V37, P227, DOI 10.1111/cgf.13356
   Wu BT, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530085
NR 60
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
AR 23
DI 10.1145/3643028
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900010
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Chu, KF
   Huang, JW
   Takana, H
   Kitamura, Y
AF Chu, Kinfung
   Huang, Jiawei
   Takana, Hidemasa
   Kitamura, Yoshifumi
TI Real-Time Reconstruction of Fluid Flow under Unknown Disturbance
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Fluid simulation; fluid tracking; parameter optimization; SPH;
   reinforcement learning
ID DIVERGENCE-FREE; SPH; PARAMETERS; MOTION
AB We present a framework that captures sparse Lagrangian flow information from a volume of real liquid and reconstructs its detailed kinematic information in real time. Our framework can perform flow reconstruction even when the liquid is disturbed by an object of unknown movement and shape. Through a large dataset of liquid moving under external disturbance, an agent is trained using reinforcement learning to reproduce the target flow kinematics with only the captured sparse information as inputs while remaining oblivious to the movement and the shape of the disturbance sources. To ensure that the underlying simulation model faithfully obeys physical reality, we also optimize the viscosity parameters in Smoothed Particle Hydrodynamics (SPH) using classical fluid dynamics knowledge and gradient-based optimization. By quantitatively comparing the reconstruction results against real-world and simulated ground truth, we verified that our reconstruction method is resilient to different agitation patterns.
C1 [Chu, Kinfung; Takana, Hidemasa; Kitamura, Yoshifumi] Tohoku Univ, 2-1-1 Katahira,Aoba Ku, Sendai, Miyagi 9808577, Japan.
   [Huang, Jiawei] Chuzhou Univ, 1 Huifeng West Rd, Chuzhou 239000, Anhui, Peoples R China.
   [Huang, Jiawei] Void Dimens, Chuzhou 239000, Anhui, Peoples R China.
C3 Tohoku University; Chuzhou University
RP Chu, KF (corresponding author), Tohoku Univ, 2-1-1 Katahira,Aoba Ku, Sendai, Miyagi 9808577, Japan.
EM kennychu@riec.tohoku.ac.jp; swfly@riec.tohoku.ac.jp;
   takana@tohoku.ac.jp; Kitamura@riec.tohoku.ac.jp
OI Chu, Kinfung/0000-0003-0816-3130; Huang, Jiawei/0000-0001-7670-2971
FU JSPS KAKENHI [18H04103]
FX This work was supported in part by the JSPS KAKENHI 18H04103.
CR Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Band S, 2018, COMPUT GRAPH-UK, V76, P37, DOI 10.1016/j.cag.2018.08.001
   Bender J, 2017, IEEE T VIS COMPUT GR, V23, P1193, DOI 10.1109/TVCG.2016.2578335
   Bender Jan, 2019, Motion, Interaction and Games, DOI [DOI 10.1145/3359566.3360077, 10.1145/3359566.3360077]
   Bockmann A, 2012, COMPUT FLUIDS, V67, P138, DOI 10.1016/j.compfluid.2012.07.007
   de Anda-Suárez J, 2018, STUD COMPUT INTELL, V749, P153, DOI 10.1007/978-3-319-71008-2_13
   Du T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417795
   Eckert ML, 2018, COMPUT GRAPH FORUM, V37, P47, DOI 10.1111/cgf.13511
   Eckert ML, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356545
   Elsinga GE, 2006, EXP FLUIDS, V41, P933, DOI 10.1007/s00348-006-0212-z
   Fujimoto S, 2018, PR MACH LEARN RES, V80
   GHIL M, 1991, ADV GEOPHYS, V33, P141, DOI 10.1016/S0065-2687(08)60442-2
   Gissler C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3284980
   Gregson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601147
   Gupta Jayesh K., 2017, Autonomous Agents and Multiagent Systems, AAMAS 2017: Workshops, Best Papers. Revised Selected Papers: LNAI 10642, P66, DOI 10.1007/978-3-319-71682-4_5
   Hayase Toshiyuki, 2015, Journal of Flow Control, Measurement & Visualization, V3, P51, DOI [10.4236/jfcmv.2015.32006, DOI 10.4236/JFCMV.2015.32006]
   Hu Y, 2020, P INT C LEARN REPR
   Huang JW, 2022, IEEE T VIS COMPUT GR, V28, P2400, DOI 10.1109/TVCG.2020.3031632
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Ihmsen Markus., 2014, EUROGRAPHICS 2014 ST, DOI [10.2312/egst.20141034, DOI 10.2312/EGST.20141034]
   Kalnay E., 2002, Atmospheric Modeling, Data Assimilation and Predictability, DOI [10.1017/CBO9780511802270, DOI 10.1017/CBO9780511802270]
   Koschier Dan, 2019, Eurographics Tutorial, DOI [10.2312/egt, DOI 10.2312/EGT]
   Kugelstadt T, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3480142
   Lenaerts T, 2009, COMPUT GRAPH FORUM, V28, P213, DOI 10.1111/j.1467-8659.2009.01360.x
   Lourenco L.M., 1989, PARTICLE IMAGE VELOC, P127, DOI [10.1007/978-3-642-83787-6_4, DOI 10.1007/978-3-642-83787-6_4]
   Lowe R, 2017, ADV NEUR IN, V30
   MAAS HG, 1993, EXP FLUIDS, V15, P133, DOI 10.1007/BF00190953
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   Mao Hongzi, 2019, P INT C LEARN REPR, DOI [10.48550/ARXIV.1807.02264, DOI 10.48550/ARXIV.1807.02264]
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Museth K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487235
   Nagasawa K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322947
   Pan ZR, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3016963
   Price DJ, 2012, J COMPUT PHYS, V231, P759, DOI 10.1016/j.jcp.2010.12.011
   Roselli RAR, 2018, ENVIRON MODELL SOFTW, V103, P62, DOI 10.1016/j.envsoft.2018.02.003
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Schenck Connor, 2018, PMLR, V87, P317
   Shahriari S, 2013, APPL MATH MODEL, V37, P1431, DOI 10.1016/j.apm.2012.04.017
   Shi Lin., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '05, P229, DOI DOI 10.1145/1073368.1073401
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Stam J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P129, DOI 10.1145/218380.218430
   Takahashi T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356551
   TAKEDA H, 1994, PROG THEOR PHYS, V92, P939, DOI 10.1143/PTP.92.939
   Thapa S, 2020, PROC CVPR IEEE, P21, DOI 10.1109/CVPR42600.2020.00010
   Thielicke W., 2014, J OPEN RES STW, V2, P30, DOI [10.5334/jors.bl, DOI 10.5334/JORS.BL]
   Thurey N., 2006, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA'06), P7, DOI [10.5555/1218064.1218066, DOI 10.5555/1218064.1218066]
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Wang HM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531396
   Weiler M, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13349
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xiong JH, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073662
   Ye JW, 2012, PROC CVPR IEEE, P310, DOI 10.1109/CVPR.2012.6247690
NR 53
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 4
DI 10.1145/3624011
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800004
OA hybrid
DA 2024-08-05
ER

PT J
AU Brokman, J
   Burger, M
   Gilboa, G
AF Brokman, Jonathan
   Burger, Martin
   Gilboa, Guy
TI Spectral Total-variation Processing of Shapes-Theory and Applications
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Geometry processing; total-variation; 3-Laplacian; nonlinear;
   non-Euclidean; nonlinear spectral processing
ID BOUNDED VARIATION; IMAGE; DIFFUSION; FRAMEWORK; GEOMETRY; TEXTURE;
   SCALE; DECOMPOSITIONS; MINIMIZATION; COLOR
AB We present a comprehensive analysis of total variation (TV) on non-Euclidean domains and its eigenfunctions. We specifically address parameterized surfaces, a natural representation of the shapes used in 3D graphics. Our work sheds new light on the celebrated Beltrami and Anisotropic TV flows and explains experimental findings from recent years on shape spectral TV [Fumero et al. 2020] and adaptive anisotropic spectral TV [Biton and Gilboa 2022]. A new notion of convexity on surfaces is derived by characterizing structures that are stable throughout the TV flow, performed on surfaces. We establish and numerically demonstrate quantitative relationships between TV, area, eigenvalue, and eigenfunctions of the TV operator on surfaces. Moreover, we expand the shape spectral TV toolkit to include zero-homogeneous flows, leading to efficient and versatile shape processing methods. These methods are exemplified through applications in smoothing, enhancement, and exaggeration filters. We introduce a novel method that, for the first time, addresses the shape deformation task using TV. This deformation technique is characterized by the concentration of deformation along geometrical bottlenecks, shown to coincide with the discontinuities of eigenfunctions. Overall, our findings elucidate recent experimental observations in spectral TV, provide a diverse framework for shape filtering, and present the first TV-based approach to shape deformation.
C1 [Brokman, Jonathan; Gilboa, Guy] Technion Israel Inst Technol, IL-32000 Haifa, Israel.
   [Burger, Martin] Helmholtz Imaging, Deutsch Elektronen Synchrotron DESY, Notkestr 85, Hamburg, Germany.
   [Burger, Martin] Univ Hamburg, Fachbereich Math, Bundesstr 55, D-20146 Hamburg, Germany.
C3 Technion Israel Institute of Technology; Helmholtz Association;
   Deutsches Elektronen-Synchrotron (DESY); University of Hamburg
RP Brokman, J (corresponding author), Technion Israel Inst Technol, IL-32000 Haifa, Israel.
EM jonathanbrok@gmail.com; martin.burger@desy.de;
   guy.gilboa@ee.technion.ac.il
OI Burger, Martin/0000-0003-2619-2912
FU DESY (Hamburg, Germany); Israel Science Foundation [534/19, 1472/23];
   Ministry of Science and Technology [5074/22]; OllendorffMinerva Center;
   European Union [777826]
FX MB acknowledges support from DESY (Hamburg, Germany), a member of the
   Helmholtz Association. GG acknowledges support by the Israel Science
   Foundation (Grant Nos. 534/19 and 1472/23), by the Ministry of Science
   and Technology (Grant No. 5074/22), and by the OllendorffMinerva Center.
   MB and GG further acknowledge support of the European Union's Horizon
   2020 research and innovation programme under the Marie Sklodowska-Curie
   grant agreement No. 777826 (NoMADS).
CR Aflalo Y, 2013, SIAM J IMAGING SCI, V6, P1579, DOI 10.1137/120888107
   Andreu F., 2001, Differential and Integral Equations, V14, P321
   [Anonymous], 2012, P IEEE CVF C COMP VI
   [Anonymous], 2013, P INT C SCALE SPACE
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Bellettini G, 2002, J DIFFER EQUATIONS, V184, P475, DOI 10.1006/jdeq.2001.4150
   Ben-Artzi M, 2007, ANN I H POINCARE-AN, V24, P989, DOI 10.1016/j.anihpc.2006.10.004
   Benning M, 2017, LECT NOTES COMPUT SC, V10302, P41, DOI 10.1007/978-3-319-58771-4_4
   Biton S, 2022, J MATH IMAGING VIS, V64, P916, DOI 10.1007/s10851-022-01097-9
   Blatt S., 2009, ANAL MUNICH, V29, P407
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Bracha Amit, 2020, P EUROGRAPHICS WORKS, P1, DOI [10.2312/3dor.20201159, DOI 10.2312/3DOR.20201159]
   Bronstein A, 2016, INT CONF 3D VISION, P435, DOI 10.1109/3DV.2016.53
   Bronstein Alexander M., 2008, Numerical Shapes
   Bungert L, 2021, ANAL PDE, V14, P823, DOI 10.2140/apde.2021.14.823
   Bungert L, 2020, J EVOL EQU, V20, P1061, DOI 10.1007/s00028-019-00545-1
   Burger M, 2006, COMMUN MATH SCI, V4, P179
   Burger M, 2016, SIAM J IMAGING SCI, V9, P1374, DOI 10.1137/15M1054687
   Burger M, 2013, LECT NOTES MATH, V2090, P1, DOI 10.1007/978-3-319-01712-9_1
   Cammarasana S, 2021, COMPUT GRAPH-UK, V97, P1, DOI 10.1016/j.cag.2021.03.006
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A., 2010, Theoretical foundations and numerical methods for sparse recovery, V9, P227
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Cignoni P, 2005, COMPUT GRAPH-UK, V29, P125, DOI 10.1016/j.cag.2004.11.012
   Cohen I, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107281
   Crane K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461986
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Dinesh C, 2020, INT CONF ACOUST SPEE, P1983, DOI [10.1109/icassp40776.2020.9053971, 10.1109/ICASSP40776.2020.9053971]
   Dinesh C, 2019, IEEE IMAGE PROC, P4390, DOI [10.1109/icip.2019.8803560, 10.1109/ICIP.2019.8803560]
   Do Carmo M. P., 2016, DIFFERENTIAL GEOMETR
   Duan PH, 2019, IEEE J-STARS, V12, P1948, DOI 10.1109/JSTARS.2019.2915272
   Elmoataz A, 2008, IEEE T IMAGE PROCESS, V17, P1047, DOI 10.1109/TIP.2008.924284
   Fumero M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417849
   Gallot S., 1990, Riemannian Geometry, V2
   Gallot Sylvestre, 2004, Riemannian Geometry, P1
   Gilboa G, 2018, Nonlinear Eigenproblems in Image Processing and Computer Vision
   Gilboa G, 2014, SIAM J IMAGING SCI, V7, P1937, DOI 10.1137/130930704
   Grasmair M, 2010, APPL MATH OPT, V62, P323, DOI 10.1007/s00245-010-9105-x
   Güneysu B, 2015, MATH ANN, V363, P1307, DOI 10.1007/s00208-015-1208-x
   Hait E, 2019, IEEE T IMAGE PROCESS, V28, P880, DOI 10.1109/TIP.2018.2872630
   HUISKEN G, 1990, J DIFFER GEOM, V31, P285
   Jacobson A, 2017, SA'17: SIGGRAPH ASIA 2017 COURSES, DOI 10.1145/3134472.3134497
   Jacobson Alec, 2021, gptoolbox: Geometry Processing Toolbox
   Kazhdan M, 2012, COMPUT GRAPH FORUM, V31, P1745, DOI 10.1111/j.1467-8659.2012.03179.x
   Kerautret Bertrand, 2020, Pattern Recognition. 5th Asian Conference, ACPR 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12046), P391, DOI 10.1007/978-3-030-41404-7_28
   Kimmel R, 2000, INT J COMPUT VISION, V39, P111, DOI 10.1023/A:1008171026419
   Kimmel R., 1998, Proc. of 3-rd Asian Conf. on Computer Vision, P574
   Lee John M, 2013, INTRO SMOOTH MANIFOL, P1
   Leng CC, 2021, IEEE-CAA J AUTOMATIC, V8, P1025, DOI 10.1109/JAS.2021.1003979
   Lipman Y., 2004, P 2004 EUROGRAPHICSA, P175, DOI DOI 10.1145/1057432.1057456
   Litany O, 2017, IEEE I CONF COMP VIS, P5660, DOI 10.1109/ICCV.2017.603
   Liu HTD, 2017, COMPUT GRAPH FORUM, V36, P139, DOI 10.1111/cgf.13252
   Miranda M, 2003, J MATH PURE APPL, V82, P975, DOI 10.1016/S0021-7824(03)00036-9
   Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003
   Pascal B, 2021, J MATH IMAGING VIS, V63, P923, DOI 10.1007/s10851-021-01035-1
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sawant SS, 2020, EGYPT J REMOTE SENS, V23, P243, DOI 10.1016/j.ejrs.2018.11.001
   Sela M, 2015, COMPUT VIS IMAGE UND, V141, P1, DOI 10.1016/j.cviu.2015.05.013
   Sharp N, 2020, COMPUT GRAPH FORUM, V39, P69, DOI 10.1111/cgf.14069
   Sorkine O, 2007, Proc. Symposium on Geometry Processing, V4, P109, DOI [DOI 10.1145/1281991.1282006, 10.1145/1073204.1073323]
   Sorkine O., 2009, EUROGRAPHICS TUTORIA, P11
   Spivak M., 2018, Calculus on manifolds: A modern approach to classical theorems of advanced calculus
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Vallet B, 2008, COMPUT GRAPH FORUM, V27, P251, DOI 10.1111/j.1467-8659.2008.01122.x
   Wardetzky M., 2007, Proceedings of the Fifth Eurographics Symposium on Geometry Processing, P33, DOI [DOI 10.2312/SGP/SGP07/033-037, 10.2312/SGP/SGP07/033-037]
   Wei W, 2019, PATTERN RECOGN, V92, P64, DOI 10.1016/j.patcog.2019.03.009
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Wetzler Aaron, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P302, DOI 10.1007/978-3-642-38294-9_26
   Yifan W., 2021, arXiv
   Zhang HY, 2020, COMPUT GRAPH-UK, V90, P95, DOI 10.1016/j.cag.2020.05.022
   Zhang HY, 2015, IEEE T VIS COMPUT GR, V21, P873, DOI 10.1109/TVCG.2015.2398432
   Zhang JW, 2022, PATTERN RECOGN LETT, V153, P159, DOI 10.1016/j.patrec.2021.12.001
   Zhong SS, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1827
NR 73
TC 0
Z9 0
U1 4
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
AR 22
DI 10.1145/3641845
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900009
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Peytavie, A
   Gain, J
   Guérin, E
   Argudo, O
   Galin, E
AF Peytavie, Adrien
   Gain, James
   Guerin, Eric
   Argudo, Oscar
   Galin, Eric
TI DeadWood: Including Disturbance and Decay in the Depiction of Digital
   Nature
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Ecosystem simulation; natural phenomena
ID COARSE WOODY DEBRIS; MODEL; VEGETATION; SIMULATION; DYNAMICS; FORESTS;
   BIOMASS; SYSTEMS; VOLUME; TREES
AB The creation of truly believable simulated natural environments remains an unsolved problem in Computer Graphics. This is, in part, due to a lack of visual variety. In nature, apart from variation due to abiotic and biotic growth factors, a significant role is played by disturbance events, such as fires, windstorms, disease, and death and decay processes, which give rise to both standing dead trees (snags) and downed woody debris (logs). For instance, snags constitute on average 10% of unmanaged forests by basal area, and logs account for 2 1 2 times this quantity.
   While previous systems have incorporated individual elements of disturbance (e.g., forest fires) and decay (e.g., the formation of humus), there has been no unifying treatment, perhaps because of the challenge of matching simulation results with generated geometric models.
   In this paper, we present a framework that combines an ecosystem simulation, which explicitly incorporates disturbance events and decay processes, with a model realization process, which balances the uniqueness arising from life history with the need for instancing due to memory constraints. We tested our hypothesis concerning the visual impact of disturbance and decay with a two-alternative forced-choice experiment (n = 116). Our findings are that the presence of dead wood in various forms, as snags or logs, significantly improves the believability of natural scenes, while, surprisingly, general variation in the number of model instances, with up to 8 models per species, and a focus on disturbance events, does not.
C1 [Peytavie, Adrien; Galin, Eric] Univ Lyon 1, CNRS, LIRIS, 43 bd 11 Novembre 1918, F-69622 Villeurbanne, France.
   [Gain, James] Univ Cape Town, Woolsack Dr, ZA-7701 Cape Town, South Africa.
   [Guerin, Eric] CNRS, INSA Lyon, LIRIS, 20 Ave Albert Einstein, F-69621 Villeurbanne, France.
   [Argudo, Oscar] Univ Politecn Cataluna, Jordi Girona I-3, Barcelona 08034, Spain.
C3 Universite Claude Bernard Lyon 1; Institut National des Sciences
   Appliquees de Lyon - INSA Lyon; Centre National de la Recherche
   Scientifique (CNRS); University of Cape Town; Institut National des
   Sciences Appliquees de Lyon - INSA Lyon; Centre National de la Recherche
   Scientifique (CNRS); Universitat Politecnica de Catalunya
RP Peytavie, A (corresponding author), Univ Lyon 1, CNRS, LIRIS, 43 bd 11 Novembre 1918, F-69622 Villeurbanne, France.
EM adrien.peytavie@liris.cnrs.fr; jgain@cs.uct.ac.za;
   eric.guerin@liris.cnrs.fr; oscar.argudo@upc.edu;
   eric.galin@liris.cnrs.fr
OI Peytavie, Adrien/0000-0002-6994-9164; Argudo, Oscar/0000-0003-3943-1839;
   Guerin, Eric/0000-0002-2189-2728; Galin, Eric/0000-0002-5946-4112; Gain,
   James/0000-0002-1699-9619
FU Agence Nationale de la Recherche (France) [AMPLI ANR-20-CE23-0001];
   National Research Foundation of South Africa [129257]; Ministerio de
   Universidades (Spain)
FX This work was funded by the project AMPLI ANR-20-CE23-0001, supported by
   Agence Nationale de la Recherche (France), by the National Research
   Foundation of South Africa (Grant Number: 129257) and is also part of a
   Maria Zambrano fellowship by Ministerio de Universidades (Spain).
CR Aakala T, 2008, FOREST ECOL MANAG, V255, P410, DOI 10.1016/j.foreco.2007.09.008
   Alexandridis A, 2008, APPL MATH COMPUT, V204, P191, DOI 10.1016/j.amc.2008.06.046
   Alsweis M, 2006, LECT NOTES COMPUT SC, V4035, P1
   Alsweis Monssef, 2005, EurographicsWorkshop on Natural Phenomena, P83
   Andújar C, 2014, COMPUT GRAPH FORUM, V33, P101, DOI 10.1111/cgf.12281
   [Anonymous], 2009, P S INT 3D GRAPH GAM
   Benes Bedrich., 2009, Eurographics Workshop on Natural Phenomena, P9
   Bjornstad ON, 2020, NAT METHODS, V17, P557, DOI 10.1038/s41592-020-0856-2
   Bolton NW, 2011, FOREST ECOL MANAG, V262, P1215, DOI 10.1016/j.foreco.2011.06.019
   Bradbury GwynethA., 2015, Journal of Computer Graphics Techniques, V4, P28
   Bradley D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461952
   Ch'ng E, 2013, SIMUL-T SOC MOD SIM, V89, P635, DOI 10.1177/0037549712470582
   Cordonnier G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073667
   Desbenoit B, 2004, COMPUT GRAPH FORUM, V23, P341, DOI 10.1111/j.1467-8659.2004.00765.x
   Deussen O., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P275, DOI 10.1145/280814.280898
   Dorsey J, 1999, COMP GRAPH, P225, DOI 10.1145/311535.311560
   Ecormier-Nocca P, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459952
   Ecormier-Nocca P, 2019, COMPUT GRAPH FORUM, V38, P157, DOI 10.1111/cgf.13627
   Fraver S, 2013, ECOSYSTEMS, V16, P1262, DOI 10.1007/s10021-013-9682-z
   Freschet GT, 2012, J ECOL, V100, P161, DOI 10.1111/j.1365-2745.2011.01896.x
   Gain J, 2017, COMPUT GRAPH FORUM, V36, P63, DOI 10.1111/cgf.13107
   Gardiner BA, 2000, FOREST ECOL MANAG, V135, P261, DOI 10.1016/S0378-1127(00)00285-1
   Hädrich T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459954
   Hädrich T, 2017, COMPUT GRAPH FORUM, V36, P49, DOI 10.1111/cgf.13106
   Hale SE, 2015, ENVIRON MODELL SOFTW, V68, P27, DOI 10.1016/j.envsoft.2015.01.016
   HARMON ME, 1986, ADV ECOL RES, V15, P133, DOI 10.1016/S0065-2504(08)60121-X
   Henry M, 2013, IFOREST, V6, pE1, DOI 10.3832/ifor0901-006
   Houston Durrant T., 2016, European Atlas of Forest Tree Species, P132
   Josep M. Marmi, 2000, L'Erol: Revista Cultural del Bergueda, V65, P22
   Kapp K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417848
   Kider JT, 2011, COMPUT GRAPH FORUM, V30, P257, DOI 10.1111/j.1467-8659.2011.01857.x
   Lane B, 2002, PROC GRAPH INTERF, P69
   Li BS, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480525
   Li C, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024161
   Li JQ, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7030127
   Liu YC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480486
   Makowski M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323039
   Marechal Nicolas, 2010, P GRAPHICS INTERFACE, P217
   Mech R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P397, DOI 10.1145/237170.237279
   Mérillou S, 2008, COMPUT GRAPH-UK, V32, P159, DOI 10.1016/j.cag.2008.01.003
   Niese T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3502220
   Nilsson SG, 2002, FOREST ECOL MANAG, V161, P189, DOI 10.1016/S0378-1127(01)00480-7
   Palubicki W, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531364
   Palubicki W, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530146
   Pirk S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661252
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366188
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185546
   Pirk S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130814
   Polasek T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480519
   Pretzsch H, 2015, URBAN FOR URBAN GREE, V14, P466, DOI 10.1016/j.ufug.2015.04.006
   Prusinkiewicz P, 2001, COMP GRAPH, P289, DOI 10.1145/383259.383291
   Purves DW, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000870
   Rajasekaran SD, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3514244
   Randolph KaDonna, 2010, Technical Report
   Russell MB, 2015, FOREST ECOL MANAG, V350, P107, DOI 10.1016/j.foreco.2015.04.033
   Sato H, 2007, ECOL MODEL, V200, P279, DOI 10.1016/j.ecolmodel.2006.09.006
   Scott JJ, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3531526
   Seidl R, 2014, ENVIRON MODELL SOFTW, V51, P1, DOI 10.1016/j.envsoft.2013.09.018
   Seidl R, 2012, ECOL MODEL, V231, P87, DOI 10.1016/j.ecolmodel.2012.02.015
   Sitch S, 2008, GLOBAL CHANGE BIOL, V14, P2015, DOI 10.1111/j.1365-2486.2008.01626.x
   Tolles J, 2020, JAMA-J AM MED ASSOC, V323, P2515, DOI 10.1001/jama.2020.8420
   Tsoularis A, 2002, MATH BIOSCI, V179, P21, DOI 10.1016/S0025-5564(02)00096-2
   Volarík D, 2013, FOREST ECOL MANAG, V292, P39, DOI 10.1016/j.foreco.2012.12.016
   Wither J, 2009, COMPUT GRAPH FORUM, V28, P541, DOI 10.1111/j.1467-8659.2009.01394.x
   Woodall Christopher W., 2008, Technical Report NRS-22
   Xie K, 2016, IEEE T VIS COMPUT GR, V22, P2608, DOI 10.1109/TVCG.2015.2513409
   Zell J, 2009, ECOL MODEL, V220, P904, DOI 10.1016/j.ecolmodel.2009.01.020
   Zhang J, 2019, VISUAL COMPUT, V35, P1181, DOI 10.1007/s00371-019-01667-w
NR 68
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
AR 21
DI 10.1145/3641816
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900008
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Tumanyan, N
   Bar-Tal, O
   Amir, S
   Bagon, S
   Dekel, T
AF Tumanyan, Narek
   Bar-Tal, Omer
   Amir, Shir
   Bagon, Shai
   Dekel, Tali
TI Disentangling Structure and Appearance in ViT Feature Space
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Style transfer; real-time style transfer; feature inversion; vision
   transformers
AB We present a method for semantically transferring the visual appearance of one natural image to another. Specifically, our goal is to generate an image in which objects in a source structure image are "painted" with the visual appearance of their semantically related objects in a target appearance image. To integrate semantic information into our framework, our key idea is to leverage a pre-trained and fixed Vision Transformer (ViT) model. Specifically, we derive novel disentangled representations of structure and appearance extracted fromdeep ViT features. We then establish an objective function that splices the desired structure and appearance representations, interweaving them together in the space of ViT features. Based on our objective function, we propose two frameworks of semantic appearance transfer - "Splice", which works by training a generator on a single and arbitrary pair of structure-appearance images, and "SpliceNet", a feed-forward real-time appearance transfer model trained on a dataset of images from a specific domain. Our frameworks do not involve adversarial training, nor do they require any additional input information such as semantic segmentation or correspondences. We demonstrate high-resolution results on a variety of in-the-wild image pairs, under significant variations in the number of objects, pose, and appearance. Code and supplementary material are available in our project page: splice-vit.github.io.
C1 [Tumanyan, Narek; Bar-Tal, Omer; Amir, Shir; Bagon, Shai; Dekel, Tali] Weizmann Inst Sci, 234 Herzl St,POB 26, IL-7610001 Rehovot, Israel.
C3 Weizmann Institute of Science
RP Tumanyan, N (corresponding author), Weizmann Inst Sci, 234 Herzl St,POB 26, IL-7610001 Rehovot, Israel.
EM narek.tumanyan@weizmann.ac.il; omer-bar.tal@weizmann.ac.il;
   shiramiremail@gmail.com; shai.bagon@weizmann.ac.il;
   tali.dekel@weizmann.ac.il
OI Dekel, Tali/0000-0003-3703-0783; Bagon, Shai/0000-0002-6057-4263
FU Israeli Science Foundation [2303/20]; Carolito Stiftung
FX This project received funding from the Israeli Science Foundation (grant
   2303/20), and the Carolito Stiftung. Dr Bagon is a Robin Chemers
   Neustein Artificial Intelligence Fellow.
CR Amir Shir, 2022, ECCVW What is Motion For?
   [Anonymous], 2016, Semantic style transfer and turning two-bit doodles into fine artworks
   Beech Frank, 2005, Splicing ropes illustrated
   Benaim S, 2021, COMPUT GRAPH FORUM, V40, P249, DOI 10.1111/cgf.14186
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Cohen T, 2019, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2019.00187
   Dekel T, 2015, PROC CVPR IEEE, P2021, DOI 10.1109/CVPR.2015.7298813
   Dosovitskiy A., 2021, ICLR
   Dumoulin V, 2017, INT C LEARN REPR
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T., 2020, P IEEE CVF C COMP VI, P8110, DOI [10.1109/cvpr42600.2020.00813, DOI 10.1109/CVPR42600.2020.00813]
   Kim K, 2022, PROC CVPR IEEE, P18218, DOI 10.1109/CVPR52688.2022.01770
   Kim Sunnie S. Y., 2020, Deformable style transfer
   Kim T, 2017, PR MACH LEARN RES, V70
   Kolkin N, 2019, PROC CVPR IEEE, P10043, DOI 10.1109/CVPR.2019.01029
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li YJ, 2017, PROC CVPR IEEE, P266, DOI 10.1109/CVPR.2017.36
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Lin J., 2020, EUR C COMP VIS, P18, DOI DOI 10.1007/978-3-030-58548-8_2
   Liu Ming-Yu, 2017, P 31 INT C NEUR INF
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Mechrez R., 2018, The contextual loss for image transformation with non-aligned data
   Melas-Kyriazi L, 2022, PROC CVPR IEEE, P8354, DOI 10.1109/CVPR52688.2022.00818
   Mokady Ron, 2022, ACM SIGGRAPH 2022 C, P1
   Naseer Muzammal, 2021, Advances in Neural Information Processing Systems
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Olah C., 2017, Distill, V2, P7, DOI DOI 10.23915/DISTILL.00007
   Park S, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387527
   Park T., 2020, ADV NEURAL INFORM PR
   Chen TQ, 2016, Arxiv, DOI arXiv:1612.04337
   Risser Eric, 2017, Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Shih YC, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601137
   Shih YC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508419
   Simeoni Oriane, 2021, P BRIT MACH VIS C BM
   Simonyan K., 2014, 13126034 ARXIV
   Taigman Yaniv, 2017, INT C LEARN REPR
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Wang Li, 2018, P COMP GRAPH INT 201
   Wang YT, 2022, PROC CVPR IEEE, P14523, DOI 10.1109/CVPR52688.2022.01414
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yoo J, 2019, IEEE I CONF COMP VIS, P9035, DOI 10.1109/ICCV.2019.00913
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhongyou Xu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9360, DOI 10.1109/CVPR42600.2020.00938
   Zhou Bolei, 2018, International Journal on Computer Vision, V2018
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 56
TC 0
Z9 0
U1 5
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 11
DI 10.1145/3630096
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800011
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Huang, JW
   Iizuka, A
   Tanaka, H
   Komura, T
   Kitamura, Y
AF Huang, Jiawei
   Iizuka, Akito
   Tanaka, Hajime
   Komura, Taku
   Kitamura, Yoshifumi
TI Online Neural Path Guiding with Normalized Anisotropic Spherical
   Gaussians
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
AB Importance sampling techniques significantly reduce variance in physically based rendering. In this article, we propose a novel online framework to learn the spatial-varying distribution of the full product of the rendering equation, with a single small neural network using stochastic ray samples. The learned distributions can be used to efficiently sample the full product of incident light. To accomplish this, we introduce a novel closed-form density model, called the Normalized Anisotropic Spherical Gaussian mixture, that can model a complex light field with a small number of parameters and that can be directly sampled. Our framework progressively renders and learns the distribution, without requiring any warm-up phases. With the compact and expressive representation of our density model, our framework can be implemented entirely on the GPU, allowing it to produce high-quality images with limited computational resources. The results showthat our framework outperforms existing neural path guiding approaches and achieves comparable or even better performance than state-of-the-art online statistical path guiding techniques.
C1 [Huang, Jiawei] Chuzhou Univ, Chuzhou, Peoples R China.
   [Huang, Jiawei] Void Dimensions, Chuzhou, Peoples R China.
   [Iizuka, Akito; Tanaka, Hajime; Komura, Taku; Kitamura, Yoshifumi] Tohoku Univ, Sendai, Miyagi, Japan.
   [Komura, Taku] Univ Hong Kong, Hong Kong, Peoples R China.
C3 Chuzhou University; Tohoku University; University of Hong Kong
RP Huang, JW (corresponding author), Chuzhou Univ, Chuzhou, Peoples R China.; Huang, JW (corresponding author), Void Dimensions, Chuzhou, Peoples R China.
FU JSPS KAKENHI [JP20K03551]
FX This work was supported in part by JSPS KAKENHI Grant Number JP20K03551.
CR Bitterli B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392481
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Currius RR, 2020, COMPUT GRAPH FORUM, V39, P133, DOI 10.1111/cgf.13918
   Diolatzis S, 2020, COMPUT GRAPH FORUM, V39, P23, DOI 10.1111/cgf.14051
   Dittebrandt Addis, 2020, EUROGRAPHICS S RENDE
   Dodik A, 2022, COMPUT GRAPH FORUM, V41, P172, DOI 10.1111/cgf.14428
   Dong HH, 2023, PROCEEDINGS OF SIGGRAPH 2023 CONFERENCE PAPERS, SIGGRAPH 2023, DOI 10.1145/3588432.3591533
   Estevez AC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3233305
   Gilboa Dar, 2021, arXiv
   Hanika J, 2015, COMPUT GRAPH FORUM, V34, P87, DOI 10.1111/cgf.12681
   Hart D, 2020, COMPUT GRAPH FORUM, V39, P149, DOI 10.1111/cgf.14060
   Heitz E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925895
   Herholz S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3230635
   Herholz S, 2016, COMPUT GRAPH FORUM, V35, P67, DOI 10.1111/cgf.12950
   Jarosz W, 2009, COMPUT GRAPH FORUM, V28, P577, DOI 10.1111/j.1467-8659.2009.01398.x
   Jensen HW, 1995, SPRING COMP SCI, P326, DOI 10.1007/978-3-7091-9430-0_31
   Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902
   KENT JT, 1982, J ROY STAT SOC B MET, V44, P71
   Kingma D. P., 2014, arXiv
   Kobyzev I, 2021, IEEE T PATTERN ANAL, V43, P3964, DOI 10.1109/TPAMI.2020.2992934
   Lafortune EP, 1995, SPRING COMP SCI, P11
   Laine Samuli, 2013, Proceedings of the 5th High-Performance Graphics Conference, P137, DOI [10.1145/2492045.2492060, DOI 10.1145/2492045.2492060]
   Lin DQ, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530158
   Lü YS, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P560, DOI 10.1145/3123939.3124532
   Maxon, 2023, Redshift Renderer
   Meister D, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384534
   Moon B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925936
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Müller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156
   Müller T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459812
   Müller T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417804
   Müller T, 2017, COMPUT GRAPH FORUM, V36, P91, DOI 10.1111/cgf.13227
   Muller Thomas, 2019, P ACM SIGGRAPH COURS, DOI DOI 10.1145/3305366.3328091
   OTOY, 2023, Octane Renderer
   Ouyang Y, 2021, COMPUT GRAPH FORUM, V40, P17, DOI 10.1111/cgf.14378
   Pantaleoni Jacopo, 2020, arXiv
   Paszke A., 2019, Advances in Neural Information Processing Systems, ppp 8024, DOI DOI 10.48550/ARXIV.1912.01703
   Rath A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392441
   Ruppert L, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392421
   Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612
   Ureña C, 2013, COMPUT GRAPH FORUM, V32, P59, DOI 10.1111/cgf.12151
   Veach E., 1998, ROBUST MONTE CARLO M, pAAI9837162
   Void Dimensions, 2024, Clight Renderer
   Vorba J, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2601097.2601203, 10.1145/2801097.2801203]
   Wang JP, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618479
   Xu K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508386
   Zheng SK, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555463
   Zhu JQ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459798
   Zhu SL, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459810
NR 49
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
DI 10.1145/3649310
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400002
OA Green Submitted, hybrid
DA 2024-08-05
ER

PT J
AU Garanzha, V
   Kaporin, I
   Kudryavtseva, L
   Protais, F
   Sokolov, D
AF Garanzha, Vladimir
   Kaporin, Igor
   Kudryavtseva, Liudmila
   Protais, Francois
   Sokolov, Dmitry
TI In the Quest for Scale-optimal Mappings
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Parameterization; injective mapping; mesh untangling; bounded
   distortion; quality mapping
ID GENERATION; ALGORITHM
AB Optimal mapping is one of the longest-standing problems in computational mathematics. It is natural to measure the relative curve length error under map to assess its quality. The maximum of such error is called the quasi-isometry constant, and its minimization is a nontrivial max-norm optimization problem. We present a physics-based quasi-isometric stiffening (QIS) algorithm for the max-norm minimization of hyperelastic distortion.
   QIS perfectly equidistributes distortion over the entire domain for the ground-truth test (unit hemisphere flattening) and, when it is not possible, tends to create zones where all cells have the same distortion. Such zones correspond to fragments of elastic material that became rigid under stiffening, reaching the deformation limit. As such, maps built by QIS are related to the de Boor equidistribution principle, which asks for an integral of a certain error indicator function to be the same over each mesh cell.
   Under certain assumptions on the minimization toolbox, we prove that our method can build, in a finite number of steps, a deformation whose maximum distortion is arbitrarily close to the (unknown) minimum. We performed extensive testing: onmore than 10,000 domains QISwas reliably better than the competing methods. In summary, we reliably build 2D and 3D mesh deformations with the smallest known distortion estimates for very stiff problems.
C1 [Garanzha, Vladimir; Kaporin, Igor; Kudryavtseva, Liudmila] FRC CSC RAS, Dorodnicyn Comp Ctr, Moscow, Russia.
   [Garanzha, Vladimir; Kaporin, Igor; Kudryavtseva, Liudmila] Moscow Inst Phys & Technol, Moscow, Russia.
   [Protais, Francois; Sokolov, Dmitry] Univ Lorraine, INRIA, CNRS, F-54000 Nancy, France.
   [Protais, Francois; Sokolov, Dmitry] Univ Lorraine, LORIA, F-54000 Nancy, France.
   [Garanzha, Vladimir; Kaporin, Igor; Kudryavtseva, Liudmila] Russian Acad Sci FRC CSC RAS, Fed Res Ctr Comp Sci & Control, Vavilov Str 44-2, Moscow 119333, Russia.
   [Protais, Francois; Sokolov, Dmitry] Univ Lorraine, LORIA, Campus Sci,BP 239, F-54506 Vandoeuvre Les Nancy, France.
C3 Federal Research Center "Computer Science & Control" of RAS; Russian
   Academy of Sciences; Dorodnitsyn Computing Centre, RAS; Moscow Institute
   of Physics & Technology; Centre National de la Recherche Scientifique
   (CNRS); Inria; Universite de Lorraine; Universite de Lorraine; Federal
   Research Center "Computer Science & Control" of RAS; Universite de
   Lorraine
RP Garanzha, V (corresponding author), FRC CSC RAS, Dorodnicyn Comp Ctr, Moscow, Russia.; Garanzha, V (corresponding author), Moscow Inst Phys & Technol, Moscow, Russia.; Garanzha, V (corresponding author), Russian Acad Sci FRC CSC RAS, Fed Res Ctr Comp Sci & Control, Vavilov Str 44-2, Moscow 119333, Russia.
EM garan@ccas.ru; igorkaporin@mail.ru; lkudryavtseva@frccsc.ru;
   francois.protais@inria.fr; dmitry.sokolov@univ-lorraine.fr
OI Garanzha, Vladimir/0000-0002-8376-756X
FU Ministry of Science and Higher Education of the Russian Federation
   [075-15-2020-799]
FX This work is supported by the Ministry of Science and Higher Education
   of the Russian Federation, Project No. 075-15-2020-799.
CR Aigerman N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461931
   Airy Esq G. B., 1861, LONDON EDINBURGH DUB, V22, P409, DOI [10.1080/14786446108643179, DOI 10.1080/14786446108643179]
   Andersen E.D., 2000, High Performance Optimization, P197, DOI [DOI 10.1007/978-1-4757-3216-0, DOI 10.1007/978-1-4757-3216-08, DOI 10.1007/978-1-4757-3216-0_8]
   Bakhvalov N. S., 1969, USSR Comput. Math. Math. Phys, V9, P139, DOI [10.1016/0041-5553(69)90038-X, DOI 10.1016/0041-5553(69)90038-X]
   BALL JM, 1977, ARCH RATION MECH AN, V63, P337, DOI 10.1007/BF00279992
   Bommes D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531383
   Bonk M, 2003, MATH ANN, V327, P135, DOI 10.1007/s00208-003-0443-8
   Chebyshev Pafnuty Lvovich, 1856, Bulletin de la classe physico-mathematique de l'Academie Imperiale des sciences de Saint-Petersbourg VIV (1856), P257
   Chien E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982426
   CIARLET PG, 1985, ARCH RATION MECH AN, V87, P319, DOI 10.1007/BF00250917
   Ciarlet PG, 1982, CR Acad. Sci. Paris Ser. II., V295, P423
   Ciarlet PhilippeG., 1988, Studies in Mathematics and its Applications, VI
   de Boor Carl, 1973, Good Approximation by Splines with Variable Knots, P57, DOI [10.1007/978-3-0348-5979-0_3, DOI 10.1007/978-3-0348-5979-0_3]
   Dinchenko A., 1938, Geodesist, V10, P4
   Du XY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392484
   Fang Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459757
   Fu XM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980231
   Fu XM, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766938
   Garanzha V., 1999, Computational mathematics and mathematical physics, V39, P1426
   Garanzha VA, 2014, J COMPUT APPL MATH, V269, P24, DOI 10.1016/j.cam.2014.03.006
   Garanzha V, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459847
   Garanzha Vladimir, 2019, Optimization and Applications, P497
   Garanzha Vladimir, 2000, Comput. Math. Math. Phys., V40, P1617
   Godunov Sergei Konstantinovich, 1994, Matematicheskie Trudy, V26, P3
   Grave D, 1911, J REINE ANGEW MATH, V140, P247
   HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044
   Hormann Kai, 2000, Curve and Surface Design: Saint-Malo, V1999, P153
   Huang WZ, 2001, J COMPUT PHYS, V174, P903, DOI 10.1006/jcph.2001.6945
   Ivanenko S. A., 2000, Zh. Vychisl. Mat. Mat. Fiz., V40, P1662
   JACQUOTTE OP, 1988, COMPUT METHOD APPL M, V66, P323, DOI 10.1016/0045-7825(88)90005-9
   Kovalsky SZ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818098
   Kovalsky SZ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601142
   Levi Z, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661258
   Lipman Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185604
   MILNOR J, 1969, AM MATH MON, V76, P1101, DOI 10.2307/2317182
   PRAGER W, 1957, T SOC RHEOL, V1, P169, DOI 10.1122/1.548818
   Rabinovich M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983621
   Reshetnyak Yu G., 1966, Siberian Math. J., V7, P879
   Rumpf M, 1996, NUMER MATH, V72, P523, DOI 10.1007/s002110050180
   Schüller C, 2013, COMPUT GRAPH FORUM, V32, P125, DOI 10.1111/cgf.12179
   Sorkine O, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P355, DOI 10.1109/VISUAL.2002.1183795
   Sorkine O, 2007, Proc. Symposium on Geometry Processing, V4, P109, DOI [DOI 10.1145/1281991.1282006, 10.1145/1073204.1073323]
   Su JP, 2019, COMPUT GRAPH FORUM, V38, P287, DOI 10.1111/cgf.13837
   Tchebychev P., 1853, Theorie des mecanismes connus sous le nom de parallelogrammes
   Xu X, 2011, IMA J NUMER ANAL, V31, P580, DOI 10.1093/imanum/drp052
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
NR 46
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 8
DI 10.1145/3627102
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800008
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Lee, JJ
   Li, BS
   Benes, B
AF Lee, Jae Joong
   Li, Bosheng
   Benes, Bedrich
TI Latent L-systems: Transformer-based Tree Generator
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE L-systems; geometric modeling; neural networks
AB We show how a Transformer can encode hierarchical tree-like string structures by introducing a new deep learning-based framework for generating 3D biological tree models represented as Lindenmayer system (L-system) strings. L-systems are string-rewriting procedural systems that encode tree topology and geometry. L-systems are efficient, but creating the production rules is one of the most critical problems precluding their usage in practice. We substitute the procedural rules creation with a deep neural model. Instead of writing the rules, we train a deep neural model that produces the output strings. We train our model on 155k tree geometries that are encoded as L-strings, de-parameterized, and converted to a hierarchy of linear sequences corresponding to branches. An end-to-end deep learning model with an attention mechanism then learns the distributions of geometric operations and branches from the input, effectively replacing the L-system rewriting rule generation. The trained deep model generates new L-strings representing 3D tree models in the same way L-systems do by providing the starting string. Our model allows for the generation of a wide variety of new trees, and the deep model agrees with the input by 93.7% in branching angles, 97.2% in branch lengths, and 92.3% in an extracted list of geometric features. We also validate the generated trees using perceptual metrics showing 97% agreement with input geometric models.
C1 [Lee, Jae Joong; Li, Bosheng; Benes, Bedrich] Purdue Univ, Dept Comp Sci, 305 N Univ St, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Lee, JJ (corresponding author), Purdue Univ, Dept Comp Sci, 305 N Univ St, W Lafayette, IN 47907 USA.
EM lee2161@purdue.edu; li2343@purdue.edu; bbenes@purdue.edu
RI Benes, Bedrich/A-8150-2016
OI Benes, Bedrich/0000-0002-5293-2112; LI, BOSHENG/0009-0006-6490-1184;
   Lee, Jae Joong/0000-0002-0445-3141
FU Foundation for Food and Agriculture Research, United States Grant
   [602757]; PERSEUS award under USDA NIFA [2023-68012-38992]
FX This research was supported by the Foundation for Food and Agriculture
   Research, United States Grant ID: 602757 to Benes. The content of this
   publication is solely the responsibility of the authors and does not
   necessarily represent the official views of the Foundation for Food and
   Agriculture Research. This work is based upon efforts supported by the
   PERSEUS award, #2023-68012-38992 under USDA NIFA to Benes. The views and
   conclusions contained herein are those of the authors and should not be
   interpreted as representing the official policies, either expressed or
   implied, of NIFA or the U.S. Government. The U.S. Government is
   authorized to reproduce and distribute reprints for governmental
   purposes notwithstanding any copyright annotation therein.
CR AONO M, 1984, IEEE COMPUT GRAPH, V4, P10, DOI 10.1109/MCG.1984.276141
   Arvo J., 1988, Ausgraph 88 Proceedings, P27
   Bernard J, 2021, SWARM EVOL COMPUT, V64, DOI 10.1016/j.swevo.2021.100893
   Bishop CM., 2006, PATTERN RECOGN
   Bokeloh M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778841
   Brandes N, 2022, BIOINFORMATICS, V38, P2102, DOI 10.1093/bioinformatics/btac020
   Chen JC, 2019, IEEE I CONF COMP VIS, P2661, DOI 10.1109/ICCV.2019.00275
   de Reffye P., 1988, Computer Graphics, V22, P151, DOI 10.1145/378456.378505
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dong HW, 2018, AAAI CONF ARTIF INTE, P34
   Du SL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11182074
   Du T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275006
   Fedus W, 2018, Arxiv, DOI arXiv:1801.07736
   Fitch BG, 2018, COMM COM INF SC, V732, P16, DOI 10.1007/978-3-319-90418-4_2
   Gao L, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356488
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gravelius H, 1914, kompendium of Hydrology, V1, P265
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Greene N., 1989, Computer Graphics, V23, P175, DOI 10.1145/74334.74351
   Guo JW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3394105
   Guo JX, 2018, AAAI CONF ARTIF INTE, P5141
   Habel R, 2009, COMPUT GRAPH FORUM, V28, P523, DOI 10.1111/j.1467-8659.2009.01391.x
   Hädrich T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459954
   Hädrich T, 2017, COMPUT GRAPH FORUM, V36, P49, DOI 10.1111/cgf.13106
   HOLTON M, 1994, COMPUT GRAPH FORUM, V13, P57, DOI 10.1111/1467-8659.1310057
   Jones RK, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417812
   Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2
   Karwowski R., 2004, P 4 INT WORKSHOP FUN, P403
   Kingma D. P., 2014, arXiv
   Li BS, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592145
   Li BS, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480525
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Li Y, 2018, INFORM SCIENCES, V450, P301, DOI 10.1016/j.ins.2018.03.050
   LINDENMAYER A, 1968, J THEOR BIOL, V18, P280, DOI 10.1016/0022-5193(68)90079-9
   Longay A., 2012, P INT S SBIM, P107, DOI DOI 10.2312/SBM/SBM12/107-120
   Marvie JE, 2005, VISUAL COMPUT, V21, P329, DOI 10.1007/s00371-005-0289-z
   Mech R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P397, DOI 10.1145/237170.237279
   Minamino R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093535
   Mo KC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356527
   Nash Charlie, 2020, ICML
   Ochoa G, 1998, LECT NOTES COMPUT SC, V1498, P335, DOI 10.1007/BFb0056876
   Okabe Makoto, 2007, P ACM SIGGRAPH 2007, DOI [10.1145/1281500.1281537, DOI 10.1145/1281500.1281537]
   Oppenheimer P. E., 1986, Computer Graphics, V20, P55, DOI 10.1145/15886.15892
   Palubicki W, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531364
   Pirk S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661252
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185546
   Pirk Soren, 2016, P ACM SIGGRAPH 2016, DOI [10.1145/2897826.2927332, DOI 10.1145/2897826.2927332]
   Polasek T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480519
   Prusinkiewicz P., 1993, Computer Graphics Proceedings, P351, DOI 10.1145/166117.166161
   Prusinkiewicz P., 1986, Proceedings of Graphics Interface '86 and Vision Interface '86, P247
   Prusinkiewicz P., 1990, ALGORITHMIC BEAUTY P
   Prusinkiewicz Przemyslaw, 1990, Scientific Visualization and Graphics Simulation, P183
   Smelik RM, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12276
   Smith A. R., 1984, Computers & Graphics, V18, P1
   Stava O, 2014, COMPUT GRAPH FORUM, V33, P118, DOI 10.1111/cgf.12282
   Sutskever I, 2014, ADV NEUR IN, V27
   Vanegas CA, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366187
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang G, 2018, COMPUT GRAPH FORUM, V37, P185, DOI 10.1111/cgf.13501
   Weber J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P119, DOI 10.1145/218380.218427
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wu FZ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601162
   Ying C., 2021, ADV NEURAL INF PROCE, V34, P28877, DOI DOI 10.48550/ARXIV.2106.05234
   Yun S, 2019, ADV NEUR IN, V32
   Zhou XC, 2024, IEEE T VIS COMPUT GR, V30, P5795, DOI 10.1109/TVCG.2023.3307887
NR 65
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 7
DI 10.1145/3627101
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800007
DA 2024-08-05
ER

PT J
AU Hu, JY
   Hui, KH
   Liu, ZZ
   Li, RH
   Fu, CW
AF Hu, Jingyu
   Hui, Ka-Hei
   Liu, Zhengzhe
   Li, Ruihui
   Fu, Chi-Wing
TI Neural Wavelet-domain Diffusion for 3D Shape Generation, Inversion, and
   Manipulation
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Shape generation; shape manipulation; diffusion model; wavelet
   representation
AB This paper presents a new approach for 3D shape generation, inversion, and manipulation, through a direct generative modeling on a continuous implicit representation in wavelet domain. Specifically, we propose a compact wavelet representation with a pair of coarse and detail coefficient volumes to implicitly represent 3D shapes via truncated signed distance functions and multi-scale biorthogonal wavelets. Then, we design a pair of neural networks: a diffusion-based generator to produce diverse shapes in the form of the coarse coefficient volumes and a detail predictor to produce compatible detail coefficient volumes for introducing fine structures and details. Further, we may jointly train an encoder network to learn a latent space for inverting shapes, allowing us to enable a rich variety of whole-shape and region-aware shape manipulations. Both quantitative and qualitative experimental results manifest the compelling shape generation, inversion, and manipulation capabilities of our approach over the state-of-the-art methods.
C1 [Hu, Jingyu; Hui, Ka-Hei; Liu, Zhengzhe; Fu, Chi-Wing] Chinese Univ Hong Kong, Ho Sin Hang Engn Bldg, Hong Kong, Peoples R China.
   [Li, Ruihui] Hunan Univ, 2 Lushan St, Changsha, Peoples R China.
C3 Chinese University of Hong Kong; Hunan University
RP Hu, JY (corresponding author), Chinese Univ Hong Kong, Ho Sin Hang Engn Bldg, Hong Kong, Peoples R China.
EM jyhu@cse.cuhk.edu.hk; khhui@cse.cuhk.edu.hk; zzliu@cse.cuhk.edu.hk;
   liruihui@hnu.edu.cn; cwfu@cse.cuhk.edu.hk
OI LIU, Zhengzhe/0000-0002-8434-3224; Fu, Chi Wing/0000-0002-5238-593X; Li,
   Ruihui/0000-0002-4266-6420; Hui, Ka-Hei/0000-0002-9786-2648; Hu,
   Jingyu/0000-0003-4235-8679
FU Research Grants Council of the Hong Kong Special Administrative Region;
   CUHK [14206320, 14201921]
FX This work is supported by Research Grants Council of the Hong Kong
   Special Administrative Region (Project no. CUHK 14206320 & 14201921).
CR Abdal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447648
   Achlioptas P, 2018, PR MACH LEARN RES, V80
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Atzmon M, 2020, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR42600.2020.00264
   Bau D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323023
   Blinn B, 2022, Arxiv, DOI arXiv:2112.07022
   Cai Ruojin, 2020, EUR C COMP VIS, P364, DOI [DOI 10.1007/978-3-030-58580-822, DOI 10.1007/978-3-030-58580-8_22]
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13067, DOI 10.1109/ICCV48922.2021.01284
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Cheng ZZ, 2022, LECT NOTES COMPUT SC, V13663, P303, DOI 10.1007/978-3-031-20062-5_18
   Chibane J, 2020, PROC CVPR IEEE, P6968, DOI 10.1109/CVPR42600.2020.00700
   Cohen Albert, 1992, Wavelet Anal. Appl., V2, P123
   Cotter Fergal, 2020, Ph.D. Dissertation.
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Dhariwal P, 2021, ADV NEUR IN, V34
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Fathony Rizal, 2020, INT C LEARNING REPRE
   Gal R, 2021, IEEE INT CONF COMP V, P2039, DOI 10.1109/ICCVW54120.2021.00231
   Gao Jun, 2022, C NEURAL INFORM PROC
   Genova K, 2020, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR42600.2020.00491
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Goodfellow I. J., 2014, ADV NEURAL INFORM PR
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Hao Zekun, 2020, P IEEECVF C COMPUTER, P7631
   Hertz Amir, 2022, ACM Transactions on Graphics (SIGGRAPH), V41, P20
   Ho J., 2020, Adv. Neural. Inf. Process. Syst, V33, P6840, DOI DOI 10.48550/ARXIV.2006.11239
   Hui KH, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555394
   Hui KH, 2022, PROC CVPR IEEE, P18551, DOI 10.1109/CVPR52688.2022.01802
   Hui Le, 2020, ECCV, P397, DOI DOI 10.1007/978-3-030-58555
   Ibing M, 2021, PROC CVPR IEEE, P13554, DOI 10.1109/CVPR46437.2021.01335
   Jiang L, 2018, LECT NOTES COMPUT SC, V11212, P820, DOI 10.1007/978-3-030-01237-3_49
   Kim H., 2020, Advances in Neural Information Processing Systems, P16388
   Kingma D. P., 2014, arXiv
   Kleineberg Marian, 2020, Eurographics ( Short Paper).
   Li CJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073632
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Li MY, 2021, PROC CVPR IEEE, P10241, DOI 10.1109/CVPR46437.2021.01011
   Li RH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459766
   Lin Connor Z., 2022, C NEURAL INFORM PROC
   Lipman Yaron, 2020, P MACHINE LEARNING S, P3569
   Liu L., 2020, Advances in Neural Information Processing Systems, V33, P15651
   Liu SC, 2019, 33 C NEURAL INFORM P, V32
   Liu SL, 2021, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR46437.2021.00183
   Liu ZZ, 2022, PROC CVPR IEEE, P17875, DOI 10.1109/CVPR52688.2022.01737
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Lugmayr A, 2022, PROC CVPR IEEE, P11451, DOI 10.1109/CVPR52688.2022.01117
   Luo A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16218, DOI 10.1109/ICCV48922.2021.01593
   Luo ST, 2021, PROC CVPR IEEE, P2836, DOI 10.1109/CVPR46437.2021.00286
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Martel JNP, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459785
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mo KC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356527
   Nichol A, 2021, PR MACH LEARN RES, V139
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Preechakul K, 2022, PROC CVPR IEEE, P10609, DOI 10.1109/CVPR52688.2022.01036
   Saragadam Vishwanath, 2022, EUROPEAN C COMPUTER
   Smith E. J., 2017, C ROB LEARN, P87
   Smith EJ, 2019, PR MACH LEARN RES, V97
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Song JM, 2022, Arxiv, DOI [arXiv:2010.02502, DOI 10.48550/ARXIV.2010.02502]
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tang JP, 2022, IEEE T PATTERN ANAL, V44, P6454, DOI 10.1109/TPAMI.2021.3087358
   Tang JP, 2019, PROC CVPR IEEE, P4536, DOI 10.1109/CVPR.2019.00467
   Tewari A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417803
   Tov O, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459838
   Velho Luiz, 1994, P SIBGRAPI, V94, P93
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang WY, 2019, ADV NEUR IN, V32
   Wei FY, 2020, INT CONF 3D VISION, P434, DOI 10.1109/3DV50981.2020.00053
   Wu JJ, 2016, ADV NEUR IN, V29
   Chang AX, 2015, Arxiv, DOI [arXiv:1512.03012, DOI 10.48550/ARXIV.1512.03012]
   Xia WH, 2023, IEEE T PATTERN ANAL, V45, P3121, DOI 10.1109/TPAMI.2022.3181070
   Xu Y., 2020, ECCV, P248
   Yan XG, 2022, PROC CVPR IEEE, P6229, DOI 10.1109/CVPR52688.2022.00614
   Yang GD, 2018, LECT NOTES COMPUT SC, V11219, P90, DOI 10.1007/978-3-030-01267-0_6
   Yang GD, 2019, IEEE I CONF COMP VIS, P4540, DOI 10.1109/ICCV.2019.00464
   Yin KX, 2020, INT CONF 3D VISION, P61, DOI 10.1109/3DV50981.2020.00016
   Zadeh A, 2021, Arxiv, DOI arXiv:1903.00840
   Zhang JZ, 2021, PROC CVPR IEEE, P1768, DOI 10.1109/CVPR46437.2021.00181
   Zhao WB, 2021, PROC CVPR IEEE, P10251, DOI 10.1109/CVPR46437.2021.01012
   Zheng Xin-Yang, 2022, EUROGRAPHICS S GEOME
   Zhou LQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5806, DOI 10.1109/ICCV48922.2021.00577
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
   Zhu R, 2017, IEEE I CONF COMP VIS, P57, DOI 10.1109/ICCV.2017.16
NR 86
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
AR 16
DI 10.1145/3635304
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900003
OA Green Submitted, Bronze
DA 2024-08-05
ER

PT J
AU Mo, HR
   Gao, CY
   Wang, RM
AF Mo, Haoran
   Gao, Chengying
   Wang, Ruomei
TI Joint Stroke Tracing and Correspondence for 2D Animation
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Stroke tracing; stroke correspondence; automatic inbetweening; 2D
   animation
AB To alleviate human labor in redrawing keyframes with ordered vector strokes for automatic inbetweening, we for the first time propose a joint stroke tracing and correspondence approach. Given consecutive raster keyframes along with a single vector image of the starting frame as a guidance, the approach generates vector drawings for the remaining keyframes while ensuring one-to-one stroke correspondence. Our framework trained on clean line drawings generalizes to rough sketches, and the generated results can be imported into inbetweening systems to produce inbetween sequences. Hence, the method is compatible with standard 2D animation workflow. An adaptive spatial transformation module (ASTM) is introduced to handle non-rigid motions and stroke distortion. We collect a dataset for training with 10k+ pairs of raster frames and their vector drawings with stroke correspondence. Comprehensive validations on real clean and rough animated frames manifest the effectiveness of our method and superiority to existing methods.
C1 [Mo, Haoran; Gao, Chengying; Wang, Ruomei] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
C3 Sun Yat Sen University
RP Gao, CY (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
EM mohaor@mail2.sysu.edu.cn; mcsgcy@mail.sysu.edu.cn;
   isswrm@mail.sysu.edu.cn
FU Natural Science Foundation of Guangdong Province, China
   [2022A1515011425]
FX This work was supported by the Natural Science Foundation of Guangdong
   Province, China (Grant No. 2022A1515011425).
CR Adobe, 2022, Adobe Animate
   Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   Bao WB, 2019, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2019.00382
   Bessmeltsev M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3202661
   Blender, 2023, ABOUT US
   Burtnyk Nestor, 1975, P 2 ANN C COMP GRAPH, P78
   CACANi, 2020, About us
   Catmull E., 1978, COMPUT GRAPHICS-US, V12, P348, DOI DOI 10.1145/800248.807414
   Chen SH, 2022, LECT NOTES COMPUT SC, V13677, P271, DOI 10.1007/978-3-031-19790-1_17
   Dalstein B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766913
   Dalstein B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601169
   DURAND CX, 1991, COMPUT GRAPH, V15, P285, DOI 10.1016/0097-8493(91)90081-R
   Dvoroznák M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201326
   Dvorozñák M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073611
   DWANGO, 2023, OpenToonz
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Even M, 2023, COMPUT GRAPH FORUM, V42, P411, DOI 10.1111/cgf.14771
   Favreau JD, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925946
   Fekete J.-D., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P79, DOI 10.1145/218380.218417
   Guo Y, 2019, COMPUT GRAPH FORUM, V38, P81, DOI 10.1111/cgf.13818
   Gutan O, 2023, COMPUT GRAPH FORUM, V42, DOI 10.1111/cgf.14901
   Ha David, 2018, P INT C LEARN REPR
   Huang ZW, 2022, LECT NOTES COMPUT SC, V13674, P624, DOI 10.1007/978-3-031-19781-9_36
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang J, 2022, COMPUT GRAPH FORUM, V41, P257, DOI 10.1111/cgf.14433
   Jiang Jie, 2020, The Digital Handbook, P245
   Jiang SA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9752, DOI 10.1109/ICCV48922.2021.00963
   Jiang W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6187, DOI 10.1109/ICCV48922.2021.00615
   KDE, 2023, Krita
   Kim K, 2022, LECT NOTES COMPUT SC, V13668, P414, DOI 10.1007/978-3-031-20074-8_24
   Kort A., 2002, NPAR 02, P125
   Li SY, 2021, PROC CVPR IEEE, P6583, DOI 10.1109/CVPR46437.2021.00652
   Li TM, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417871
   Li XY, 2022, IEEE T VIS COMPUT GR, V28, P2938, DOI 10.1109/TVCG.2021.3049419
   Liu CX, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592130
   Liu CX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201314
   Liu HY, 2022, AAAI CONF ARTIF INTE, P4559
   Liu XT, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818067
   Live2D, 2023, About us
   Miura Takeo, 1967, P SPRING JOINT COMP, P141
   Mo HR, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459833
   Myronova M, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592420
   Narita R, 2019, IEEE IMAGE PROC, P4200, DOI [10.1109/ICIP.2019.8803506, 10.1109/icip.2019.8803506]
   Navarro P, 2021, COMPUT GRAPH FORUM, V40, P410, DOI 10.1111/cgf.14197
   Noris G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421640
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Puhachov I, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480529
   Reallusion, 2023, Cartoon Animator
   Reeves W. T., 1981, Computer Graphics, V15, P263, DOI 10.1145/965161.806814
   Ren J, 2021, COMPUT GRAPH FORUM, V40, P81, DOI 10.1111/cgf.14359
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Shugrina M, 2019, PROC CVPR IEEE, P5379, DOI 10.1109/CVPR.2019.00553
   Siarohin A, 2019, PROC CVPR IEEE, P2372, DOI 10.1109/CVPR.2019.00248
   Simo-Serra E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201370
   Simo-Serra E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3132703
   Simo-Serra E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925972
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siyao Li, 2022, Proceedings of the 36th Conference on Neural Information Processing Systems, V35, P18996
   Siyao Li, 2023, P IEEE CVF INT C COM, P7291
   Smith HJ, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592788
   Stanko T, 2020, COMPUT GRAPH FORUM, V39, P149, DOI 10.1111/cgf.14075
   Su QK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174236
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sykora Daniel, 2009, Proceedings of the International Symposium on Non-Photorealistic Animation and Rendering, P25
   Teed Zachary, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P402, DOI 10.1007/978-3-030-58536-5_24
   Toon Boom, 2022, Harmony
   TVPaint, 2023, About us
   Wang ZY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459819
   Whited B, 2010, COMPUT GRAPH FORUM, V29, P605, DOI 10.1111/j.1467-8659.2009.01630.x
   Xiao CF, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555493
   Xu HF, 2022, PROC CVPR IEEE, P8111, DOI 10.1109/CVPR52688.2022.00795
   Xu XM, 2021, IEEE T VIS COMPUT GR, V27, P178, DOI 10.1109/TVCG.2019.2930512
   Xu Z, 2022, PROC CVPR IEEE, P11625, DOI 10.1109/CVPR52688.2022.01134
   Yan C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417784
   Yang WW, 2018, COMPUT GRAPH FORUM, V37, P125, DOI 10.1111/cgf.13518
   Yang WW, 2018, IEEE T VIS COMPUT GR, V24, P1049, DOI 10.1109/TVCG.2017.2657511
   Yu D, 2021, IEEE T CIRC SYST VID, V31, P1738, DOI 10.1109/TCSVT.2020.3015279
   Zhao J, 2022, PROC CVPR IEEE, P3647, DOI 10.1109/CVPR52688.2022.00364
NR 79
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
AR 29
DI 10.1145/3649890
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400005
DA 2024-08-05
ER

PT J
AU Knodt, JL
   Pan, ZR
   Wu, K
   Gao, XF
AF Knodt, Julian
   Pan, Zherong
   Wu, Kui
   Gao, Xifeng
TI Joint UV Optimization and Texture Baking
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Texture baking; differentiable rendering; UV optimization
AB Level of detail has been widely used in interactive computer graphics. In current industrial 3D modeling pipelines, artists rely on commercial software to generate highly detailed models with UV maps and then bake textures for low-poly counterparts. In these pipelines, each step is performed separately, leading to unsatisfactory visual appearances for low polygon count models. Moreover, existing texture baking techniques assume the low-poly mesh has a small geometric difference from the high-poly, which is often not true in practice, especially with extremely low poly count models.
   To alleviate the visual discrepancy of the low-poly mesh, we propose to jointly optimize UV mappings during texture baking, allowing for low-poly models to faithfully replicate the appearance of the high-poly even with large geometric differences. We formulate the optimization within a differentiable rendering framework, allowing the automatic adjustment of texture regions to encode appearance information. To compensate for view parallaxwhen two meshes have large geometric differences, we introduce a spherical harmonic parallaxmapping, which uses spherical harmonic functions to modulate per-texel UV coordinates based on the view direction. We evaluate the effectiveness and robustness of our approach on a dataset composed of online downloaded models, with varying complexities and geometric discrepancies. Our method achieves superior quality over state-of-the-art techniques and commercial solutions.
C1 [Knodt, Julian; Pan, Zherong; Gao, Xifeng] LightSpeed Studios, Bellevue, WA 98004 USA.
   [Wu, Kui] LightSpeed Studios, Los Angeles, CA 94306 USA.
RP Knodt, JL (corresponding author), LightSpeed Studios, Bellevue, WA 98004 USA.
EM julianknodt@global.tencent.com; zrpan@global.tencent.com;
   kwwu@global.tencent.com; xifgao@global.tencent.com
OI Pan, Zherong/0000-0001-9348-526X; Knodt, Julian/0000-0003-4461-2036;
   Gao, Xifeng/0000-0003-0829-7075
CR Adobe, 2014, Substance Painter
   Cohen J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P115, DOI 10.1145/280814.280832
   Community B.O., 2018, BLEND 3D MOD REND PA
   DGG, 2018, RapidCompact
   Donya Labs AB, 2022, Simplygon 10
   Engel W., 2019, GPU Zen 2: Advanced Rendering Techniques
   Epic Games, 2022, Unreal Engine 5
   Hasselgren Jon, 2021, EUROGRAPHICS S RENDE
   Jiang ZS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417769
   Jiang ZS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130895
   Johnson Justin, 2020, SIGGRAPH ASIA 2020 C, P1, DOI DOI 10.1145/3415263.3419160
   Kaneko T., 2001, Proceedings of ICAT, V2001, P205
   Kingma D. P., 2014, arXiv
   Laine S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417861
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Levy Bruno, 2019, Geogram
   Li MC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459767
   Li MC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392425
   Li MC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275042
   Li TM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275109
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11
   Luan FJ, 2021, Arxiv, DOI arXiv:2103.15208
   Marmoset, 2022, Marmoset Toolbag
   McGuire Morgan., 2005, STEEP PARALLAX MAPPI
   Nerurkar Manfred M., 2021, InstaLOD
   Nicolet B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480501
   Nimier-David M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356498
   Patow G, 2003, COMPUT GRAPH FORUM, V22, P663, DOI 10.1111/j.1467-8659.2003.00716.x
   Pixologic, 2022, ZBrush
   Policarpo F, 2005, ACM T GRAPHIC, V24, P935, DOI 10.1145/1073204.1073292
   Rabinovich M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983621
   Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317
   Sander P. V., 2003, Symposium on Geometry Processing, P146
   Sander P. V., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P87
   Sketchfab, 2022, About us
   Smith J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766947
   Su JP, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392435
   Sun Haoran, 2022, Computer Graphics Forum, V41, P1
   Tatarchuk Natalya, 2006, ACM SIGGRAPH 2006 Courses (SIGGRAPH'06), P81
   Tewari G., 2004, Symposium on Geometry Processing, P55
   Thonat T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480535
   Tutte W.T., 1963, Proc. London Math. Soc., V13, P743
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Welsh T., 2004, PARALLAX MAPPING OFF
   Young Jonathon, 2017, Xatlas
NR 47
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 2
DI 10.1145/3617683
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800002
DA 2024-08-05
ER

PT J
AU Gupta, M
   Wang, J
   Bayer, K
   Nayar, SK
AF Gupta, Mohit
   Wang, Jian
   Bayer, Karl
   Nayar, Shree K.
TI Light Codes for Fast Two-Way Human-Centric Visual Communication
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Visual codes; human-centric visual communication; communication
   protocols
AB Visual codes, such as QR codes, are widely used in several applications for conveying information to users. However, user interactions based on spatial codes (e.g., displaying codes on phone screens for exchanging contact information) are often tedious, time consuming, and prone to errors due to image corruptions such as noise, blur, saturation, and perspective distortions. We propose Light Codes (LICO), a novel method for fast and fluid exchange of information among users. Light codes are based on transmitting and receiving temporal codes (instead of spatial) using compact and low-cost transceiver devices. The resulting approach enables seamless and near instantaneous exchange of short messages among users with minimal physical and cognitive effort. We design novel coding techniques, hardware prototypes, and applications that are optimized for human-centric communication, and facilitate fast and fluid user-to-user interactions in various challenging conditions, including a range of distances, motion, and ambient illumination. We evaluate the performance of the proposed methods both via quantitative analysis and user study based comparisons with several existing approaches including display-camera links, Bluetooth, and near-field communication, which show strong preference toward Light Codes in various real-world application scenarios.
C1 [Gupta, Mohit] Univ Wisconsin Madison, 1210 West Dayton St, Madison, WI 53706 USA.
   [Wang, Jian; Bayer, Karl; Nayar, Shree K.] Snap Res, 229 W 43rd St, New York, NY 10036 USA.
C3 University of Wisconsin System; University of Wisconsin Madison
RP Gupta, M (corresponding author), Univ Wisconsin Madison, 1210 West Dayton St, Madison, WI 53706 USA.
EM mohitg@cs.wisc.edu; jwang4@snap.com; kbayer@snapchat.com;
   snayar@snap.com
OI Wang, Jian/0000-0001-5266-3808; Gupta, Mohit/0000-0002-2323-7700
CR ABRAMSON N, 1985, IEEE T INFORM THEORY, V31, P119, DOI 10.1109/TIT.1985.1057021
   ABRAMSON N, 1990, P IEEE, V78, P1267, DOI 10.1109/5.56937
   Abramson N, 2009, IEEE COMMUN MAG, V47, P21, DOI 10.1109/MCOM.2009.5350363
   Amazon, 2022, Popl Dot Digital Business Card-Smart NFC Sticker Tag
   Apple, 2022, Share Audio with AirPods or Beats Headphones
   Baluja S., 2017, Adv. Neural Inf. Process. Syst, P1
   BARRY JR, 1995, APPL OPTICS, V34, P3764, DOI 10.1364/AO.34.003764
   Bimber Oliver, 2007, P INT C ADV VIS COMP
   Coskun V, 2013, WIRELESS PERS COMMUN, V71, P2259, DOI 10.1007/s11277-012-0935-5
   DigiKey, 2022, Understanding the Basics of Infrared Communications
   Dot, 2022, Shop Basics
   GitHub, 2021, WeChat QR Code Detector for Detecting and Parsing QR Code
   Hao T., 2012, Proceedings of the 10th international conference on Mobile systems, applications, and services, P85
   HAUGEN PR, 1986, OPT ENG, V25, P1076, DOI 10.1117/12.7973962
   Hu WJ, 2014, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '14), P79, DOI 10.1145/2639108.2639132
   IEC, 2006, IEC 62471:2006-Photobiological safety of lamps and lamp systems
   Jo K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2896818
   Lee CG, 2007, OPT ENG, V46, DOI 10.1117/1.2823157
   Martin J, 2005, CONSUM COMM NETWORK, P302
   METCALFE RM, 1976, COMMUN ACM, V19, P395, DOI 10.1145/360248.360253
   Miao Guowang, 2016, Fundamentals of Mobile Data Networks
   Nayar Shree K., 2022, US Patent, Patent No. [11,461,924, 11461924]
   Nguyen V, 2016, 35 IEEE ANN INT C CO
   Otte Rob, 2013, Low-Power Wireless Infrared Communications
   PAHLAVAN K, 1994, P IEEE, V82, P1398, DOI 10.1109/5.317085
   Park H, 2004, IEEE T COMMUN, V52, P643, DOI 10.1109/TCOMM.2004.826382
   Paus A., 2007, Near Field Communication in Cell Phones
   Perli SD, 2010, MOBICOM 10 & MOBIHOC 10: PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING AND THE 11TH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P137
   PETERSON WW, 1961, P IRE, V49, P228, DOI 10.1109/JRPROC.1961.287814
   Sony, 2022, Sony SIRC Protocol
   Statista, 2019, Protective Case Usage among U.S. Smartphone Owners 2017
   Stavenow B., 1984, Performance Evaluation Review, V12, P105, DOI 10.1145/1031382.809318
   Tancik M, 2020, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR42600.2020.00219
   Tran Vu, 2021, P INT C INF PROC SEN
   Tsonev D, 2014, PROC SPIE, V9007, DOI 10.1117/12.2044649
   Vishay Semiconductors, 2022, TFDU4301 Infrared Transceiver Module (SIR, 115.2 kbit/s) for IrDA<(R)> Applications.
   Vucic J, 2010, J LIGHTWAVE TECHNOL, V28, P3512, DOI 10.1109/JLT.2010.2089602
   Wengrowski E, 2019, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR.2019.00161
   Wenjia Yuan, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P345, DOI 10.1109/WACV.2012.6162992
NR 39
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 1
DI 10.1145/3617682
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800001
DA 2024-08-05
ER

PT J
AU Zeltner, T
   Rousselle, F
   Weidlich, A
   Clarberg, P
   Novák, J
   Bitterli, B
   Evans, A
   Davidovic, T
   Kallweit, S
   Lefohn, A
AF Zeltner, Tizian
   Rousselle, Fabrice
   Weidlich, Andrea
   Clarberg, Petrik
   Novak, Jan
   Bitterli, Benedikt
   Evans, Alex
   Davidovic, Tomas
   Kallweit, Simon
   Lefohn, Aaron
TI Real-time Neural Appearance Models
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Appearance models; neural networks; real-time rendering
ID REPRESENTATION
AB We present a complete system for real-time rendering of scenes with complex appearance previously reserved for offline use. This is achieved with a combination of algorithmic and system level innovations.
   Our appearance model utilizes learned hierarchical textures that are interpreted using neural decoders, which produce reflectance values and importance-sampled directions. To best utilize the modeling capacity of the decoders, we equip the decoders with two graphics priors. The first prior-transformation of directions into learned shading frames-facilitates accurate reconstruction of mesoscale effects. The second prior-a microfacet sampling distribution-allows the neural decoder to perform importance sampling efficiently. The resulting appearance model supports anisotropic sampling and level-of-detail rendering, and allows baking deeply layered material graphs into a compact unified neural representation.
   By exposing hardware accelerated tensor operations to ray tracing shaders, we show that it is possible to inline and execute the neural decoders efficiently inside a real-time path tracer. We analyze scalability with increasing number of neural materials and propose to improve performance using code optimized for coherent and divergent execution. Our neural material shaders can be over an order of magnitude faster than non-neural layered materials. This opens up the door for using film-quality visuals in real-time applications such as games and live previews.
C1 [Zeltner, Tizian; Rousselle, Fabrice; Kallweit, Simon] NVIDIA, Zurich, Switzerland.
   [Weidlich, Andrea] NVIDIA, Montreal, PQ, Canada.
   [Clarberg, Petrik] NVIDIA, Lund, Sweden.
   [Novak, Jan; Davidovic, Tomas] NVIDIA, Prague, Czech Republic.
   [Bitterli, Benedikt; Lefohn, Aaron] NVIDIA, Redmond, WA USA.
   [Evans, Alex] NVIDIA, London, England.
RP Zeltner, T (corresponding author), NVIDIA, Zurich, Switzerland.
EM tzeltner@nvidia.com; frousselle@nvidia.com; aweidlich@nvidia.com;
   pclarberg@nvidia.com; jnovak@nvidia.com; bbitterli@nvidia.com;
   alexe@nvidia.com; tdavidovic@nvidia.com; skallweit@nvidia.com;
   alefohn@nvidia.com
CR Akenine-Moller Tomas, 2021, Journal of Computer Graphics Techniques (JCGT), V10, P1
   Andersson P, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3406183
   Baatz H, 2022, COMPUT GRAPH FORUM, V41, P287, DOI 10.1111/cgf.14449
   Bai YY, 2023, Arxiv, DOI [arXiv:2210.13681, 10.48550/ARXIV.2210.13681, DOI 10.48550/ARXIV.2210.13681]
   Bako S, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3570327
   Clarberg Petrik, 2022, HPG 2022 KEYN
   Clarberg Petrik, 2022, GAM DEV C GDC
   Dinh L., 2017, INT C LEARN REPR
   Dupuy J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275059
   Dupuy Jonathan, 2015, Photorealistic Surface Rendering with Microfacet Theory
   Fan Jiahui, 2022, ACM SIGGRAPH 2022 C, DOI DOI 10.1145/3528233.3530732
   Gauthier A, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555487
   He Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201380
   Jakob Wenzel, 2019, P ACM SIGGRAPH 2019, DOI DOI 10.1145/3305366.3328085
   Kallweit Simon, 2022, The Falcor Rendering Framework
   Kuznetsov Alexandr, 2022, SIGGRAPH22 Conference Proceeding: Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings, DOI 10.1145/3528233.3530721
   Kuznetsov A, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459795
   Kuznetsov A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356525
   Laine Samuli, 2013, Proceedings of the 5th High-Performance Graphics Conference, P137, DOI [10.1145/2492045.2492060, DOI 10.1145/2492045.2492060]
   Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Müller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156
   Müller T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417804
   Nalbach O, 2017, COMPUT GRAPH FORUM, V36, P65, DOI 10.1111/cgf.13225
   Olano Marc, 2010, Proceedings of the Symposium on Interactive 3D Graphics and Games, P181, DOI 10.1145/1730804.1730834
   Pharr Matt, 2016, From Theory to Implementation, VThird
   Rainer G, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13921
   Rainer G, 2019, COMPUT GRAPH FORUM, V38, P235, DOI 10.1111/cgf.13633
   Rebain Daniel, 2023, Transactions on Machine Learning Research
   Rusinkiewicz S. M., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P11
   Smythe Doug, 2021, MaterialX: An Open Standard for NetworkBased CG Object Looks
   Sztrajman A, 2021, COMPUT GRAPH FORUM, V40, P332, DOI 10.1111/cgf.14335
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   TROWBRIDGE TS, 1975, J OPT SOC AM, V65, P531, DOI 10.1364/JOSA.65.000531
   Vaidyanathan K, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592407
   van Antwerpen Dietger, 2011, P ACM SIGGRAPH S HIG, P41, DOI DOI 10.1145/2018323.2018330
   Vaswani A, 2017, ADV NEUR IN, V30
   Veach E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P419, DOI 10.1145/218380.218498
   Vogels T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201388
   Walter B., 2007, P 18 EUR C REND TECH, P195, DOI [10.2312/EGWR/EGSR07/195-206, DOI 10.2312/EGWR/EGSR07/195-206]
   Xu B, 2023, PROCEEDINGS OF SIGGRAPH 2023 CONFERENCE PAPERS, SIGGRAPH 2023, DOI 10.1145/3588432.3591524
   Zheng CK, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3490335
NR 43
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
AR 33
DI 10.1145/3659577
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400009
OA Bronze, Green Submitted
DA 2024-08-05
ER

PT J
AU Nagata, Y
   Imahori, S
AF Nagata, Yuichi
   Imahori, Shinji
TI Creation of Dihedral Escher-like Tilings Based on As-Rigid-As-Possible
   Deformation
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Tilings; dihedral escherization; Escher tiling; as-rigid-as-possible
   deformation
AB An Escher-like tiling is a tiling consisting of one or a few artistic shapes of tile. This article proposes a method for generating Escher-like tilings consisting of two distinct shapes (dihedral Escher-like tilings) that are as similar as possible to the two goal shapes specified by the user. This study is an extension of a previous study that successfully generated Escher-like tilings consisting of a single tile shape for a single goal shape. Building upon the previous study, our method attempts to exhaustively search for which parts of the discretized tile contours are adjacent to each other to form a tiling. For each configuration, two tile shapes are optimized to be similar to the given two goal shapes. By evaluating the similarity based on as-rigid-as possible deformation energy, the optimized tile shapes preserve the local structures of the goal shapes, even if substantial deformations are necessary to form a tiling. However, in the dihedral case, this approach is seemingly unrealistic because it suffers from the complexity of the energy function and the combinatorial explosion of the possible configurations. We developed a method to address these issues and show that the proposed algorithms can generate satisfactory dihedral Escher-like tilings in a realistic computation time, even for somewhat complex goal shapes.
C1 [Nagata, Yuichi] Tokushima Univ, 2-1 Minami jousanjima, Tokushima, Tokushima 7708506, Japan.
   [Imahori, Shinji] Chuo Univ, I-13-27 Kasuga,Bunkyo Ku, Tokyo 1128551, Japan.
C3 Tokushima University; Chuo University
RP Nagata, Y (corresponding author), Tokushima Univ, 2-1 Minami jousanjima, Tokushima, Tokushima 7708506, Japan.
EM nagata@is.tokushima-u.ac.jp; imahori@ise.chuo-u.ac.jp
FU JSPS KAKENHI [20K11695]
FX This work was supported by JSPS KAKENHI Grant Number 20K11695.
CR ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509
   Dress Andreas W. M., 1986, Art and science, P35
   Grunbaum B., 1987, Tilings and Patterns
   Hisatomi A, 2021, APPL SOFT COMPUT, V112, DOI 10.1016/j.asoc.2021.107771
   Imahori S, 2016, LECT NOTES COMPUT SC, V9943, P132, DOI 10.1007/978-3-319-48532-4_12
   Kaplan C.S., 2009, Introductory tiling theory for computer graphics
   Kaplan CS, 2004, PROC GRAPH INTERF, P255
   Kaplan CS, 2000, COMP GRAPH, P499, DOI 10.1145/344779.345022
   Kawade Shizuka, 2015, RIMS Kokyuroku, V2015, P107
   Koizumi H, 2011, GRAPH COMBINATOR, V27, P431, DOI 10.1007/s00373-011-1022-5
   Lin SS, 2018, IEEE T VIS COMPUT GR, V24, P1089, DOI 10.1109/TVCG.2017.2660488
   Liu XK, 2020, COMPUT AIDED DESIGN, V127, DOI 10.1016/j.cad.2020.102853
   Nagata Y, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3487017
   Nagata Y, 2020, ALGORITHMICA, V82, P2502, DOI 10.1007/s00453-020-00695-6
   Ono S, 2015, PROCEEDINGS OF THE 18TH ASIA PACIFIC SYMPOSIUM ON INTELLIGENT AND EVOLUTIONARY SYSTEMS, VOL 1, P421, DOI 10.1007/978-3-319-13359-1_33
   Ono Satoshi, 2014, SIGGRAPH ASIA 2014 P, P1
   Ouyang PC, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3560711
   Ouyang PC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3456298
   Peichang OY, 2022, VISUAL COMPUT, V38, P3923, DOI 10.1007/s00371-021-02232-0
   Schattschneider Doris, 2004, M. C. Escher: Visions of Symmetry
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Sugihara K, 2009, J MATH ARTS, V3, P195, DOI 10.1080/17513470903185626
   Nguyen VB, 2016, J GLOBAL OPTIM, V64, P399, DOI 10.1007/s10898-015-0315-2
   WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P810, DOI 10.1109/34.400572
   Zhang LH, 2013, COMPUT OPTIM APPL, V54, P111, DOI 10.1007/s10589-012-9479-6
NR 25
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
AR 18
DI 10.1145/3638048
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900005
OA hybrid
DA 2024-08-05
ER

PT J
AU Ren, J
   Segall, A
   Sorkine-Hornung, O
AF Ren, Jing
   Segall, Aviv
   Sorkine-Hornung, Olga
TI Digital Three-dimensional Smocking Design
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Smocking; embroidery; shape deformation; graph embedding
AB We develop an optimization-based method to model smocking, a surface embroidery technique that provides decorative geometric texturing while maintaining stretch properties of the fabric. During smocking, multiple pairs of points on the fabric are stitched together, creating non-manifold geometric features and visually pleasing textures. Designing smocking patterns is challenging, because the outcome of stitching is unpredictable: The final texture is often revealed only when the whole smocking process is completed, necessitating painstaking physical fabrication and time consuming trial-and-error experimentation. This motivates us to seek a digital smocking design method. Straightforward attempts to compute smocked fabric geometry using surface deformation or cloth simulationmethods fail to produce realistic results, likely due to the intricate structure of the designs, the large number of contacts and high-curvature folds. We instead formulate smocking as a graph embedding and shape deformation problem. We extract a coarse graph representing the fabric and the stitching constraints and then derive the graph structure of the smocked result. We solve for the three-dimensional embedding of this graph, which in turn reliably guides the deformation of the high-resolution fabric mesh. Our optimization based method is simple, efficient, and flexible, which allows us to build an interactive system for smocking pattern exploration. To demonstrate the accuracy of our method, we compare our results to real fabrications on a large set of smocking patterns.
C1 [Ren, Jing; Segall, Aviv; Sorkine-Hornung, Olga] Swiss Fed Inst Technol, Dept Comp Sci, Inst Visual Comp, Univ Str 6, CH-8092 Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Ren, J (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Inst Visual Comp, Univ Str 6, CH-8092 Zurich, Switzerland.
EM jing.ren@inf.ethz.ch; aviv.segall@inf.ethz.ch; sorkine@inf.ethz.ch
OI Sorkine-Hornung, Olga/0000-0002-8089-3974
FU ERC Consolidator Grant [101003104]
FX This work was supported in part by the ERC Consolidator Grant No.
   101003104 (MYCLOTH).
CR An N, 2020, ADV FUNCT MATER, V30, DOI 10.1002/adfm.201906711
   Banner Bernadette, 2022, Make, Sew and Mend: Traditional Techniques to Sustainably Maintain and Refashion Your Clothes
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bauer Margie, 1992, Austr. J. Adult Commun. Educ., V32, P84
   Blender Foundation and Community, 2023, BLENDER
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Bridson R., 2005, ACM SIGGRAPH 2005 Courses, P3
   Carlson Christopher, 2015, P BRIDGES MATH MUSIC, P231
   Castle T, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1601258
   Castle T, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.245502
   Chen Z, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3462758
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   Cirio G, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661279
   CLO, 2023, clo3d.com
   CLO, 2020, Garment Details: Expressing Smocking Detail (w/track Tool)
   Delaunay B., 1934, IZV AKAD NAUK SSSR, V7, P1, DOI [10.4236/sar.2016.43003, DOI 10.4236/SAR.2016.43003]
   Dudte LH, 2016, NAT MATER, V15, P583, DOI [10.1038/nmat4540, 10.1038/NMAT4540]
   Durand Dianne, 1979, Smocking: Techniques, Projects and Designs
   Efrat TA, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5984, DOI 10.1145/2858036.2858441
   Elbyaly MYH, 2022, CURR PSYCHOL, V41, P8010, DOI 10.1007/s12144-020-01165-6
   Goldenthal R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276438
   Igarashi Yuki, 2015, ACM SIGGRAPH 2015 PO, P1
   Jiang CG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417844
   Joseph R., 2011, Asian Journal of Home Science, V6, P5
   Kaldor JM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778842
   Kim Minkyoung, 2020, [Journal of Fashion Business, 패션 비즈니스], V24, P106
   Leake M, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459853
   LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785
   Li MC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459767
   Li MC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201310
   Lind Malin, 2019, Bachelor thesis
   Liu TT, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508406
   MarvelousDesigner, 2023, About us
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Narain R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366171
   Ren YY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459788
   Sorkine O, 2007, Proc. Symposium on Geometry Processing, V4, P109, DOI [DOI 10.1145/1281991.1282006, 10.1145/1073204.1073323]
   Sorkine Olga, 2009, P ANN C EUROPEAN ASS
   Sperl G, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392412
   Spufford Margaret, 2017, The Clothing of the Common Sort: 1570-1700
   Tang M, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275005
   Terzopoulos D., 1987, Computer Graphics, V21, P205, DOI 10.1145/37402.37427
   Toplis Alison, 2021, The Hidden History of the Smock Frock
   Wang F, 2017, J APPL MECH-T ASME, V84, DOI 10.1115/1.4036476
   Wang HM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459787
   Wu K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3292481
NR 46
TC 0
Z9 0
U1 6
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
AR 14
DI 10.1145/3631945
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900001
OA hybrid
DA 2024-08-05
ER

PT J
AU Teotia, K
   Mallikarjun, BR
   Pan, XG
   Kim, H
   Garrido, P
   Elgharib, M
   Theobalt, C
AF Teotia, Kartik
   Mallikarjun, B. R.
   Pan, Xingang
   Kim, Hyeongwoo
   Garrido, Pablo
   Elgharib, Mohamed
   Theobalt, Christian
TI HQ3DAvatar: High-quality Implicit 3D Head Avatar
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Volumetric rendering; implicit representations; Neural Radiance Fields;
   neural avatars; free-viewpoint; rendering
AB Multi-view volumetric rendering techniques have recently shown great potential in modeling and synthesizing high-quality head avatars. A common approach to capture full head dynamic performances is to track the underlying geometry using a mesh-based template or 3D cube-based graphics primitives. While these model-based approaches achieve promising results, they often fail to learn complex geometric details such as the mouth interior, hair, and topological changes over time. This article presents a novel approach to building highly photorealistic digital head avatars. Our method learns a canonical space via an implicit function parameterized by a neural network. It leverages multiresolution hash encoding in the learned feature space, allowing for high quality, faster training, and high-resolution rendering. At test time, our method is driven by a monocular RGB video. Here, an image encoder extracts face-specific features that also condition the learnable canonical space. This encourages deformation-dependent texture variations during training. We also propose a novel optical flow-based loss that ensures correspondences in the learned canonical space, thus encouraging artifact-free and temporally consistent renderings. We show results on challenging facial expressions and showfree-viewpoint renderings at interactive real-time rates for a resolution of 480x270. Our method outperforms related approaches both visually and numerically. We will release our multiple-identity dataset to encourage further research.
C1 [Teotia, Kartik; Mallikarjun, B. R.; Pan, Xingang; Elgharib, Mohamed; Theobalt, Christian] Max Planck Inst Informat, Saarbrucken, Germany.
   [Teotia, Kartik; Mallikarjun, B. R.; Theobalt, Christian] Univ Saarland, Saarbrucken, Germany.
   [Pan, Xingang] Nanyang Technol Univ, Singapore, Singapore.
   [Kim, Hyeongwoo] Imperial Coll London, London, England.
   [Garrido, Pablo] Flawless AI, Los Angeles, CA USA.
C3 Max Planck Society; Saarland University; Nanyang Technological
   University; Imperial College London
RP Teotia, K (corresponding author), Max Planck Inst Informat, Saarbrucken, Germany.; Teotia, K (corresponding author), Univ Saarland, Saarbrucken, Germany.
EM ktoetia@mpi-inf.mpg.de; mallik.jeevan@gmail.com; xingang.pan@ntu.edu.sg;
   hyeongwoo.kim@imperial.ac.uk; pablo.garrido@flawlessai.com;
   elgharib@mpi-inf.mpg.de; theobalt@mpi-inf.mpg.de
CR Abdal Rameen, 2023, CoRR abs/2301.02700
   Amodio Matthew, 2019, arXiv
   Athar S, 2022, PROC CVPR IEEE, P20332, DOI 10.1109/CVPR52688.2022.01972
   Bai YP, 2023, Arxiv, DOI arXiv:2211.15064
   Bergman Alexander W., 2022, C ADV NEUR INF PROC
   Bharadwaj S, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3618401
   Cao C, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530143
   Cao C, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459806
   Cao C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925873
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chan ER, 2022, PROC CVPR IEEE, P16102, DOI 10.1109/CVPR52688.2022.01565
   Chan ER, 2021, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR46437.2021.00574
   Chandran P, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480509
   Chen LL, 2021, PROC CVPR IEEE, P13054, DOI 10.1109/CVPR46437.2021.01286
   Deng Y, 2022, PROC CVPR IEEE, P10663, DOI 10.1109/CVPR52688.2022.01041
   Duan HB, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3618399
   Egger B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3395208
   Elgharib M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417808
   Fridovich-Keil S, 2022, PROC CVPR IEEE, P5491, DOI 10.1109/CVPR52688.2022.00542
   Gafni G, 2021, PROC CVPR IEEE, P8645, DOI 10.1109/CVPR46437.2021.00854
   Gao X, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555501
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Gerig T, 2018, IEEE INT CONF AUTOMA, P75, DOI 10.1109/FG.2018.00021
   Gu Jiatao, 2022, INT C LEARN REPR
   Hong Y, 2022, PROC CVPR IEEE, P20342, DOI 10.1109/CVPR52688.2022.01973
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Kasten Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480546
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Lattas A, 2022, IEEE T PATTERN ANAL, V44, P9269, DOI 10.1109/TPAMI.2021.3125598
   Li R, 2022, LECT NOTES COMPUT SC, V13692, P419, DOI 10.1007/978-3-031-19824-3_25
   Li TY, 2022, PROC CVPR IEEE, P5511, DOI 10.1109/CVPR52688.2022.00544
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Li ZQ, 2021, PROC CVPR IEEE, P6494, DOI 10.1109/CVPR46437.2021.00643
   Lin JK, 2020, PROC CVPR IEEE, P5890, DOI 10.1109/CVPR42600.2020.00593
   Lin SC, 2021, PROC CVPR IEEE, P8758, DOI 10.1109/CVPR46437.2021.00865
   Lombardi S, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3476576.3476608, 10.1145/3450626.3459863]
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Lombardi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201401
   Ma SG, 2021, PROC CVPR IEEE, P64, DOI 10.1109/CVPR46437.2021.00013
   Mallikarjun BR, 2021, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR46437.2021.00337
   Meshry M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13809, DOI 10.1109/ICCV48922.2021.01357
   Metashape, 2020, Agisoft Metashape (Version 1.8.4) (Software)
   Mihajlovic M, 2022, LECT NOTES COMPUT SC, V13675, P179, DOI 10.1007/978-3-031-19784-0_11
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Nagano K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275075
   OrEl R, 2022, PROC CVPR IEEE, P13493, DOI 10.1109/CVPR52688.2022.01314
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Park K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480487
   Parkhi O. M., 2015, P BRIT MACH VIS C, p41.1
   Raj A, 2021, PROC CVPR IEEE, P11728, DOI 10.1109/CVPR46437.2021.01156
   Ramon E, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5600, DOI 10.1109/ICCV48922.2021.00557
   Ren Xingyu, 2022, arXiv
   Shamai G, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3337067
   Sun KQ, 2022, Arxiv, DOI arXiv:2206.08361
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tang Jiaxiang, 2022, Torch-ngp: a pytorch implementation of instant-ngp
   Tewari A, 2022, COMPUT GRAPH FORUM, V41, P703, DOI 10.1111/cgf.14507
   Tewari A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417803
   Tewari A, 2018, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2018.00270
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2019, COMMUN ACM, V62, P96, DOI 10.1145/3292039
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122
   Wang D, 2022, ANN OPER RES, DOI 10.1007/s10479-022-04621-7
   Wang LZ, 2023, PROCEEDINGS OF SIGGRAPH 2023 CONFERENCE PAPERS, SIGGRAPH 2023, DOI 10.1145/3588432.3591517
   Wang TC, 2021, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR46437.2021.00991
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2022, PROC CVPR IEEE, P6133, DOI 10.1109/CVPR52688.2022.00605
   Wang ZY, 2021, PROC CVPR IEEE, P5700, DOI 10.1109/CVPR46437.2021.00565
   Xiang JF, 2023, Arxiv, DOI arXiv:2206.07255
   Xu Yuelang, 2023, ACM SIGGRAPH C SIGGR
   Yamaguchi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201364
   Yu A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5732, DOI 10.1109/ICCV48922.2021.00570
   Zhang H, 2022, Arxiv, DOI arXiv:2211.11202
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao XC, 2024, ACM T GRAPHIC, V43, DOI 10.1145/3626316
   Zheng YF, 2023, PROC CVPR IEEE, P21057, DOI 10.1109/CVPR52729.2023.02017
   Zheng YF, 2022, PROC CVPR IEEE, P13535, DOI 10.1109/CVPR52688.2022.01318
   Zielonka W, 2023, PROC CVPR IEEE, P4574, DOI 10.1109/CVPR52729.2023.00444
   Zielonka W, 2022, LECT NOTES COMPUT SC, V13673, P250, DOI 10.1007/978-3-031-19778-9_15
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
NR 83
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
AR 27
DI 10.1145/3649889
PG 24
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400003
OA hybrid
DA 2024-08-05
ER

PT J
AU Li, P
   Quan, WZ
   Guo, JW
   Yan, DM
AF Li, Pu
   Quan, Weize
   Guo, Jianwei
   Yan, Dong-Ming
TI Layout-aware Single-image Document Flattening
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Document image rectification; document layout analysis; deep neural
   networks; geometric models
ID RECTIFICATION; SHAPE; RESTORATION
AB Single image rectification of document deformation is a challenging task. Although some recent deep learning-based methods have attempted to solve this problem, they cannot achieve satisfactory results when dealing with document images with complex deformations. In this article, we propose a new efficient framework for document flattening. Our main insight is that most layout primitives in a document have rectangular outline shapes, making unwarping local layout primitives essentially homogeneous with unwarping the entire document. The former task is clearly more straightforward to solve than the latter due to the more consistent texture and relatively smooth deformation. On this basis, we propose a layout-aware deep model working in a divide-and-conquer manner. First, we employ a transformer-based segmentation module to obtain the layout information of the input document. Then a new regression module is applied to predict the global and local UV maps. Finally, we design an effective merging algorithm to correct the global prediction with local details. Both quantitative and qualitative experimental results demonstrate that our framework achieves favorable performance against state-of-the-art-methods. In addition, the current publicly available document flattening datasets have limited 3D paper shapes without layout annotation and also lack a general geometric correction metric. Therefore, we build a new-large-scale synthetic dataset by utilizing a fully automatic rendering method to generate deformed documents with diverse shapes and exact layout segmentation labels. We also propose a newgeometric correction metric based on our paired document UV maps. Code and dataset will be released at https://github.com/BunnySoCrazy/LA-DocFlatten
C1 [Li, Pu; Quan, Weize; Guo, Jianwei; Yan, Dong-Ming] Chinese Acad Sci, Inst Automat, MAIS, Beijing, Peoples R China.
   [Li, Pu; Quan, Weize; Guo, Jianwei; Yan, Dong-Ming] UCAS, Sch Artificial Intelligence, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Guo, JW (corresponding author), Chinese Acad Sci, Inst Automat, MAIS, Beijing, Peoples R China.; Guo, JW (corresponding author), UCAS, Sch Artificial Intelligence, Beijing, Peoples R China.
EM lipu2021@ia.ac.cn; qweizework@gmail.com; jianwei.guo@nlpr.ia.ac.cn;
   yan-dongming@gmail.com
OI Guo, Jianwei/0000-0002-3376-1725; Yan, Dong-Ming/0000-0003-2209-2404
FU NSFC [U22B2034, U21A20515, 62172416, 62172415, 62102418]; Youth
   Innovation Promotion Association of the Chinese Academy of Sciences
   [2022131]
FX This work was supported in part by NSFC (U22B2034, U21A20515, 62172416,
   62172415, 62102418) and Youth Innovation Promotion Association of the
   Chinese Academy of Sciences (2022131).
CR Binmakhashen GM, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355610
   Oliveria DAB, 2017, IEEE INT CONF COMP V, P1173, DOI 10.1109/ICCVW.2017.142
   Brown MS, 2007, IEEE T PATTERN ANAL, V29, P1904, DOI 10.1109/TPAMI.2007.1118
   Brown MS, 2006, IEEE T IMAGE PROCESS, V15, P1544, DOI 10.1109/TIP.2006.871082
   Brown MS, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P367, DOI 10.1109/ICCV.2001.937649
   Burden A, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P33, DOI 10.1109/CRV.2019.00013
   Cao HG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P228, DOI 10.1109/ICCV.2003.1238346
   Chen L, 2020, VIS COMPUT IND BIOME, V3, DOI 10.1186/s42492-020-00045-x
   Courteille F, 2007, MACH VISION APPL, V18, P301, DOI 10.1007/s00138-006-0062-y
   Das S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4248, DOI 10.1109/ICCV48922.2021.00423
   Das S, 2019, IEEE I CONF COMP VIS, P131, DOI 10.1109/ICCV.2019.00022
   Das S, 2017, PROCEEDINGS OF THE 2017 ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG 17), P125, DOI 10.1145/3103010.3121030
   Dasgupta Tanmoy, 2020, arXiv
   Davoudi H, 2021, INT C PATT RECOG, P5936, DOI 10.1109/ICPR48806.2021.9413280
   Ding HH, 2020, IEEE T IMAGE PROCESS, V29, P3520, DOI 10.1109/TIP.2019.2962685
   Dosovitskiy A., 2020, ARXIV, DOI 10.48550/arXiv.2010.11929
   Fawzi M, 2015, PROC INT CONF DOC, P1226, DOI 10.1109/ICDAR.2015.7333959
   Feng H, 2023, Arxiv, DOI [arXiv:2304.08796, 10.48550/arXiv.2304.08796, DOI 10.48550/ARXIV.2304.08796]
   Feng H, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P273, DOI 10.1145/3474085.3475388
   Feng Hao, 2021, arXiv
   Gardner MA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130891
   He DF, 2017, PROC INT CONF DOC, P254, DOI 10.1109/ICDAR.2017.50
   He Y, 2013, PROC INT CONF DOC, P403, DOI 10.1109/ICDAR.2013.88
   Islam MA, 2017, PROC CVPR IEEE, P4877, DOI 10.1109/CVPR.2017.518
   Jiang XW, 2022, PROC CVPR IEEE, P4533, DOI 10.1109/CVPR52688.2022.00450
   Kim BS, 2015, PATTERN RECOGN, V48, P3600, DOI 10.1016/j.patcog.2015.04.026
   Kim T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360649
   Kingma D. P., 2014, arXiv
   Koo HI, 2010, LECT NOTES COMPUT SC, V6312, P421
   Lavialle O, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P748, DOI 10.1109/ICIP.2001.958227
   Li XY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356563
   Liang J, 2008, IEEE T PATTERN ANAL, V30, P591, DOI 10.1109/TPAMI.2007.70724
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu XY, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107576
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma Ke, 2022, ACM SIGGRAPH C P, P1
   Ma Ke, 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00494
   Markovitz Amir, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P208, DOI 10.1007/978-3-030-58610-2_13
   Meng GF, 2018, LECT NOTES COMPUT SC, V11220, P180, DOI 10.1007/978-3-030-01270-0_11
   Meng GF, 2014, PROC CVPR IEEE, P3890, DOI 10.1109/CVPR.2014.497
   Mischke L, 2005, LECT NOTES COMPUT SC, V3617, P1068, DOI 10.1007/11553595_131
   Pfaff T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866196
   Ranftl R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12159, DOI 10.1109/ICCV48922.2021.01196
   Salvi D, 2015, IEEE WINT CONF APPL, P757, DOI 10.1109/WACV.2015.106
   Stamatopoulos N, 2011, IEEE T IMAGE PROCESS, V20, P910, DOI 10.1109/TIP.2010.2080280
   Sun MX, 2005, IEEE I CONF COMP VIS, P1117
   Takezawa Y, 2017, PROC INT CONF DOC, P27, DOI 10.1109/ICDAR.2017.345
   Tan CL, 2006, IEEE T PATTERN ANAL, V28, P195, DOI 10.1109/TPAMI.2006.40
   Tian YD, 2011, PROC CVPR IEEE, P377, DOI 10.1109/CVPR.2011.5995540
   Tsoi Yau-Chat, 2007, IEEE COMPUTER VISION, P1
   Ulges A, 2005, PROC INT CONF DOC, P1001, DOI 10.1109/ICDAR.2005.90
   Vaswani A, 2017, ADV NEUR IN, V30
   Wada T, 1997, INT J COMPUT VISION, V24, P125, DOI 10.1023/A:1007906904009
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wu Xingjiao, 2021, INT C MULT EXP, P1
   Xian K, 2018, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2018.00040
   Xiao P, 2022, IEEE I C VI COM I PR, DOI 10.1109/VCIP56404.2022.10008829
   Xie Guangzeng, 2021, ARXIV
   Xie GW, 2021, LECT NOTES COMPUT SC, V12821, P466, DOI 10.1007/978-3-030-86549-8_30
   Xu Zhong, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1015, DOI 10.1109/ICDAR.2019.00166
   You S, 2018, IEEE T PATTERN ANAL, V40, P505, DOI 10.1109/TPAMI.2017.2675980
   Zandifar A, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P129, DOI 10.1109/ICIAP.2007.4362769
   Zhang JX, 2022, Arxiv, DOI arXiv:2207.11515
   Zhang L, 2008, IEEE T PATTERN ANAL, V30, P728, DOI 10.1109/TPAMI.2007.70831
   Zhang L, 2009, PATTERN RECOGN, V42, P2961, DOI 10.1016/j.patcog.2009.03.025
NR 67
TC 2
Z9 2
U1 4
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 9
DI 10.1145/3627818
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800009
DA 2024-08-05
ER

PT J
AU Sun, JM
   Yang, J
   Mo, KC
   Lai, YK
   Guibas, L
   Gao, L
AF Sun, Jia-Mu
   Yang, Jie
   Mo, Kaichun
   Lai, Yu-Kun
   Guibas, Leonidas
   Gao, Lin
TI Haisor: Human-aware Indoor Scene Optimization via Deep Reinforcement
   Learning
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Scene optimization; scene synthesis; human aware; reinforcement
   learning; Monte Carlo search; robot simulation; imitation learning
ID REARRANGEMENT
AB 3D scene synthesis facilitates and benefits many real-world applications. Most scene generators focus on making indoor scenes plausible via learning from training data and leveraging extra constraints such as adjacency and symmetry. Although the generated 3D scenes are mostly plausible with visually realistic layouts, they can be functionally unsuitable for human users to navigate and interact with furniture. Our key observation is that human activity plays a critical role and sufficient free space is essential for human-scene interactions. This is exactly where many existing synthesized scenes fail-the seemingly correct layouts are often not fit for living. To tackle this, we present a human-aware optimization framework Haisor for 3D indoor scene arrangement via reinforcement learning, which aims to find an action sequence to optimize the indoor scene layout automatically. Based on the hierarchical scene graph representation, an optimal action sequence is predicted and performed via Deep Q-Learning with Monte Carlo Tree Search (MCTS), where MCTS is our key feature to search for the optimal solution in long-term sequences and large action space. Multiple human-aware rewards are designed as our core criteria of human-scene interaction, aiming to identify the next smart action by leveraging powerful reinforcement learning. Our framework is optimized end-to-end by giving the indoor scenes with part-level furniture layout including part mobility information. Furthermore, our methodology is extensible and allows utilizing different reward designs to achieve personalized indoor scene synthesis. Extensive experiments demonstrate that our approach optimizes the layout of 3D indoor scenes in a human-aware manner, which is more realistic and plausible than original state-of-the-art generator results, and our approach produces superior smart actions, outperforming alternative baselines.
C1 [Sun, Jia-Mu; Yang, Jie; Gao, Lin] Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Mo, Kaichun; Guibas, Leonidas] Stanford Univ, Dept Comp Sci, 450 Serra Mall, Stanford, CA 94305 USA.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Stanford University; Cardiff University
RP Gao, L (corresponding author), Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing 100190, Peoples R China.
EM sunjiamu21s@ict.ac.cn; yangjie01@ict.ac.cn; kaichun@cs.stanford.edu;
   LaiY4@cardiff.ac.uk; guibas@cs.stanford.edu; gaolin@ict.ac.cn
OI Lai, Yukun/0000-0002-2094-5680; Guibas, Leonidas/0000-0002-8315-4886;
   Yang, Jie/0000-0002-6503-8312
FU National Natural Science Foundation of China [62322210]; Beijing
   Municipal Natural Science Foundation for Distinguished Young Scholars
   [JQ21013]; Beijing Municipal Science and Technology Commission
   [Z231100005923031]; ARL [W911NF-21-2-0104]; Vannevar Bush Faculty
   Fellowship
FX This work was supported by National Natural Science Foundation of China
   (No. 62322210), Beijing Municipal Natural Science Foundation for
   Distinguished Young Scholars (No. JQ21013) and Beijing Municipal Science
   and Technology Commission (No. Z231100005923031). Kaichun Mo and
   Leonidas J. Guibas were supported by the ARL grant W911NF-21-2-0104, a
   Vannevar Bush Faculty Fellowship, and a gift from the Adobe Corporation.
CR Achiam J, 2017, PR MACH LEARN RES, V70
   Agarwal Alekh, 2020, PMLR, P64
   Andrychowicz M, 2016, ADV NEUR IN, V29
   Bai Fan, 2021, arXiv
   Barrow Harry G, 1977, Proceedings of the 5th international joint conference on Artificial intelligence
   Blinn B, 2022, Arxiv, DOI arXiv:2112.07022
   Chaslot Guillaume, 2008, AIIDE, V4, P216, DOI DOI 10.1609/AIIDE.V4I1.18700
   Chen C, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0354-4
   Christopher B., arXiv
   Defferrard M, 2016, ADV NEUR IN, V29
   Fanbo Xiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11094, DOI 10.1109/CVPR42600.2020.01111
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Fu H, 2021, INT J COMPUT VISION, V129, P3313, DOI 10.1007/s11263-021-01534-z
   Fu Q, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130805
   Haustein JA, 2015, IEEE INT CONF ROBOT, P3075, DOI 10.1109/ICRA.2015.7139621
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henderson P, 2019, Arxiv, DOI arXiv:1711.10939
   Hester T, 2018, AAAI CONF ARTIF INTE, P3223
   Hu RZ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392391
   Kermani ZS, 2016, COMPUT GRAPH FORUM, V35, P197, DOI 10.1111/cgf.12976
   King Jennifer E., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4681, DOI 10.1109/ICRA.2017.7989544
   King JE, 2016, IEEE INT CONF ROBOT, P3940, DOI 10.1109/ICRA.2016.7487583
   Kipf T.N., 2017, INT C LEARN REPR, P1
   Kocsis L, 2006, LECT NOTES COMPUT SC, V4212, P282, DOI 10.1007/11871842_29
   Koval MC, 2015, IEEE INT C INT ROBOT, P2678, DOI 10.1109/IROS.2015.7353743
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leimer K, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555425
   Levine S, 2018, INT J ROBOT RES, V37, P421, DOI 10.1177/0278364917710318
   Li MY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3303766
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Liu JJ, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P270, DOI 10.1109/VR50410.2021.00049
   Liu LJ, 2021, AAAI CONF ARTIF INTE, V35, P336
   Ma R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275035
   Ma R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980223
   Merrell P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964982
   Mirhoseini A, 2021, NATURE, V594, P207, DOI 10.1038/s41586-021-03544-w
   Mirowski P., 2017, 5 INT C LEARNING REP
   Mnih V., 2013, ARXIV
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100
   Nauata N, 2021, PROC CVPR IEEE, P13627, DOI 10.1109/CVPR46437.2021.01342
   Nauata Nelson, 2020, COMPUTER VISION ECCV, P162
   O'Donoghue B., 2017, 5 INT C LEARNING REP
   Panero Julius, 1999, Human Dimension & Interior Space: A Source Book of Design Reference Standards
   Paschalidou D., 2021, ADV NEUR IN, V34
   Pintore G, 2020, COMPUT GRAPH FORUM, V39, P667, DOI 10.1111/cgf.14021
   Qi SY, 2018, PROC CVPR IEEE, P5899, DOI 10.1109/CVPR.2018.00618
   Ritchie D, 2019, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2019.00634
   Schaul T, 2016, 4 INT C LEARNING REP
   Shalev-Shwartz S., 2014, Understanding machine learning: from theory to algorithms, DOI [DOI 10.1017/CBO9781107298019, 10.1017/cbo9781107298019]
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Song HR, 2020, IEEE INT C INT ROBOT, P9433, DOI 10.1109/IROS45743.2020.9341532
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Vaswani A, 2017, ADV NEUR IN, V30
   Vuong Quan Ho, 2019, 7 INT C LEARNING REP
   Wang HQ, 2021, Arxiv, DOI arXiv:2105.04088
   Wang HQ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417788
   Wang K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322941
   Wang K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201362
   Wang XP, 2021, INT CONF 3D VISION, P106, DOI 10.1109/3DV53792.2021.00021
   Wang ZY, 2016, PR MACH LEARN RES, V48
   Wilfong G., 1991, Annals of Mathematics and Artificial Intelligence, V3, P131, DOI [10.1145/73393.73422, 10.1007/BF01530890]
   Xu WZ, 2015, COMPUT GRAPH-UK, V46, P231, DOI 10.1016/j.cag.2014.09.032
   Yang HT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5610, DOI 10.1109/ICCV48922.2021.00558
   Ye SF, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555426
   Yeh YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185552
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Yuan WH, 2019, ROBOT AUTON SYST, V119, P119, DOI 10.1016/j.robot.2019.06.007
   Yuan WH, 2018, IEEE INT CONF ROBOT, P270
   Zhang SH, 2022, IEEE T VIS COMPUT GR, V28, P3082, DOI 10.1109/TVCG.2021.3050143
   Zhang SH, 2019, J COMPUT SCI TECH-CH, V34, P594, DOI 10.1007/s11390-019-1929-5
   Zhang ZW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3381866
   Zhou Y, 2019, IEEE I CONF COMP VIS, P7383, DOI 10.1109/ICCV.2019.00748
NR 74
TC 0
Z9 0
U1 5
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
AR 15
DI 10.1145/3632947
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900002
OA hybrid, Green Accepted
DA 2024-08-05
ER

PT J
AU Li, HP
   Jiang, H
   Luo, A
   Tan, P
   Fan, HQ
   Zeng, B
   Liu, SC
AF Li, Haipeng
   Jiang, Hai
   Luo, Ao
   Tan, Ping
   Fan, Haoqiang
   Zeng, Bing
   Liu, Shuaicheng
TI DMHomo: Learning Homography with Diffusion Models
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Homography; diffusion models; image alignment; datasets
ID UNSUPERVISED DEEP HOMOGRAPHY
AB Supervised homography estimation methods face a challenge due to the lack of adequate labeled training data. To address this issue, we propose DMHomo, a diffusion model-based framework for supervised homography learning. This framework generates image pairs with accurate labels, realistic image content, and realistic intervalmotion, ensuring that they satisfy adequate pairs. We utilize unlabeled image pairs with pseudo labels such as homography and dominant plane masks, computed from existing methods, to train a diffusion model that generates a supervised training dataset. To further enhance performance, we introduce a new probabilistic mask loss, which identifies outlier regions through supervised training, and an iterative mechanism to optimize the generative and homography models successively. Our experimental results demonstrate that DMHomo effectively overcomes the scarcity of qualified datasets in supervised homography learning and improves generalization to real-world scenes. The code and dataset are available at GitHub (https://github.com/lhaippp/DMHomo).
C1 [Li, Haipeng; Zeng, Bing; Liu, Shuaicheng] Univ Elect Sci & Technol China, Xiyuan Ave,West Hi Tech Zone, Chengdu 611731, Sichuan, Peoples R China.
   [Jiang, Hai] Sichuan Univ, 24 South Sect 1,Yihuan Rd, Chengdu, Sichuan, Peoples R China.
   [Luo, Ao; Fan, Haoqiang] Megvii Technol, 27 Jiancailu Middle Rd, Beijing 100096, Peoples R China.
   [Tan, Ping] Hong Kong Univ Sci & Technol, Clear Water Bay, Hongkong 999077, Peoples R China.
C3 University of Electronic Science & Technology of China; Sichuan
   University; Hong Kong University of Science & Technology
RP Liu, SC (corresponding author), Univ Elect Sci & Technol China, Xiyuan Ave,West Hi Tech Zone, Chengdu 611731, Sichuan, Peoples R China.
EM lihaipeng@std.uestc.edu.cn; jiang-hai1@stu.scu.edu.cn;
   luoao02@megvii.com; pingtan@sfu.ca; fhq@megvii.com;
   liushuaicheng@uestc.edu.cn
FU National Natural Science Foundation of China (NSFC) [62372091, 61872405,
   61720106004]; Sichuan Science and Technology Program of China
   [2023NSFSC0462]; "111" Project [B17008]
FX Thiswork was supported by the National Natural Science Foundation of
   China (NSFC) under grants 62372091, 61872405, and 61720106004; the
   Sichuan Science and Technology Program of China under grant
   2023NSFSC0462; and the "111" Project under grant B17008.
CR Balntas V, 2017, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2017.410
   Bao F, 2022, Arxiv, DOI arXiv:2201.06503
   Barath D, 2020, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR42600.2020.00138
   Barath D, 2019, PROC CVPR IEEE, P10189, DOI 10.1109/CVPR.2019.01044
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cao SY, 2022, PROC CVPR IEEE, P1869, DOI 10.1109/CVPR52688.2022.00192
   Chang CH, 2017, PROC CVPR IEEE, P3777, DOI 10.1109/CVPR.2017.402
   Cunningham P, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3459665
   DeTone D, 2016, Arxiv, DOI arXiv:1606.03798
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   Dhariwal P, 2021, ADV NEUR IN, V34
   Ding TJ, 2020, PROC CVPR IEEE, P6079, DOI 10.1109/CVPR42600.2020.00612
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gast J, 2018, PROC CVPR IEEE, P3369, DOI 10.1109/CVPR.2018.00355
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Greff K, 2022, PROC CVPR IEEE, P3739, DOI 10.1109/CVPR52688.2022.00373
   Han YH, 2022, LECT NOTES COMPUT SC, V13679, P288, DOI 10.1007/978-3-031-19800-7_17
   Hartley R, 2003, Multiple view geometry in computer vision, DOI [10.1016/S0143-8166(01)00145-2, DOI 10.1017/CBO9780511811685]
   Ho J., 2020, Adv. Neural. Inf. Process. Syst, V33, P6840, DOI DOI 10.48550/ARXIV.2006.11239
   Ho JAT, 2022, Arxiv, DOI [arXiv:2207.12598, DOI 10.48550/ARXIV.2207.12598]
   Hoang Le, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7649, DOI 10.1109/CVPR42600.2020.00767
   Hong MB, 2022, PROC CVPR IEEE, P17642, DOI 10.1109/CVPR52688.2022.01714
   Hoogeboom E, 2023, Arxiv, DOI arXiv:2301.11093
   Ilg E, 2018, LECT NOTES COMPUT SC, V11211, P677, DOI 10.1007/978-3-030-01234-2_40
   Jiang Hai, 2022, arXiv
   Jirong Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P653, DOI 10.1007/978-3-030-58452-8_38
   Karras T, 2022, Arxiv, DOI [arXiv:2206.00364, DOI 10.48550/ARXIV.2206.00364]
   Kharismawati Dewi Endah, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12540), P400, DOI 10.1007/978-3-030-65414-6_28
   Kingma D. P., 2014, arXiv
   Kingma Durk P., 2015, Advances in Neural Information Processing Systems, V28, P1
   Li HP, 2023, Arxiv, DOI arXiv:2301.10018
   Li Haipeng, 2021, P IEEE CVF INT C COM, P12869
   Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu SC, 2023, IEEE T PATTERN ANAL, V45, P2849, DOI 10.1109/TPAMI.2022.3174130
   Liu SC, 2022, IEEE T CIRC SYST VID, V32, P2856, DOI 10.1109/TCSVT.2021.3103281
   Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995
   Liu Shuaicheng, 2022, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Liu XH, 2023, IEEE WINT CONF APPL, P289, DOI [10.1109/WACV56688.2023.00037, 10.1007/978-3-031-33545-7_20]
   Liu Z, 2021, IEEE COMPUT SOC CONF, P463, DOI 10.1109/CVPRW53098.2021.00057
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu C, 2022, Arxiv, DOI arXiv:2206.00927
   Luo ZW, 2023, Arxiv, DOI arXiv:2301.11699
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Pumarola Albert, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P10313, DOI 10.1109/CVPR46437.2021.01018
   Raistrick A, 2023, PROC CVPR IEEE, P12630, DOI 10.1109/CVPR52729.2023.01215
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saharia C, 2023, IEEE T PATTERN ANAL, V45, P4713, DOI 10.1109/TPAMI.2022.3204461
   Salimans Tim, 2022, arXiv, DOI 10.48550/arXiv.2202.00512
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Saurer Olivier, 2012, P VIC WORKSH IROS, V2012
   Shao Ruizhi, 2021, P IEEECVF INT C COMP, P14890
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Song JM, 2022, Arxiv, DOI [arXiv:2010.02502, DOI 10.48550/ARXIV.2010.02502]
   Song Y, 2019, ADV NEUR IN, V32
   Song Y, 2022, Arxiv, DOI arXiv:2111.08005
   Song Y, 2021, Arxiv, DOI [arXiv:2011.13456, DOI 10.48550/ARXIV.2011.13456]
   Sun JM, 2021, PROC CVPR IEEE, P8918, DOI 10.1109/CVPR46437.2021.00881
   Tevet Guy, 2022, arXiv
   Tian YR, 2019, PROC CVPR IEEE, P11008, DOI 10.1109/CVPR.2019.01127
   Truong P, 2021, PROC CVPR IEEE, P5710, DOI 10.1109/CVPR46437.2021.00566
   Truong P, 2020, PROC CVPR IEEE, P6257, DOI 10.1109/CVPR42600.2020.00629
   Nguyen T, 2018, IEEE ROBOT AUTOM LET, V3, P2346, DOI 10.1109/LRA.2018.2809549
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang YH, 2022, Arxiv, DOI arXiv:2212.00490
   Wu SZ, 2018, LECT NOTES COMPUT SC, V11206, P120, DOI 10.1007/978-3-030-01216-8_8
   Ye NJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13097, DOI 10.1109/ICCV48922.2021.01287
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Yu JJ, 2016, LECT NOTES COMPUT SC, V9915, P3, DOI 10.1007/978-3-319-49409-8_1
NR 74
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
AR 30
DI 10.1145/3652207
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400006
DA 2024-08-05
ER

PT J
AU Tu, ZL
   Li, C
   Zhao, ZP
   Liu, L
   Wang, CH
   Wang, CB
   Qin, H
AF Tu, Zaili
   Li, Chen
   Zhao, Zipeng
   Liu, Long
   Wang, Chenhui
   Wang, Changbo
   Qin, Hong
TI A Unified MPM Framework Supporting Phase-field Models and
   Elastic-viscoplastic Phase Transition
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Physics-based animation; material point method; phase-field method
ID DIVERGENCE-FREE; SPH; FLUIDS
AB Recent years have witnessed the rapid deployment of numerous physics-based modeling and simulation algorithms and techniques for fluids, solids, and their delicate coupling in computer animation. However, it still remains a challenging problem to model the complex elastic-viscoplastic behaviors during fluid-solid phase transitions and facilitate their seamless interactions inside the same framework. In this article, we propose a practical method capable of simulating granular flows, viscoplastic liquids, elastic-plastic solids, rigid bodies, and interacting with each other, to support novel phenomena all heavily involving realistic phase transitions, including dissolution, melting, cooling, expansion, shrinking, and so on. At the physics level, we propose to combine and morph von Mises with Drucker-Prager and Cam-Clay yield models to establish a unified phasefield-driven EVP model, capable of describing the behaviors of granular, elastic, plastic, viscous materials, liquid, non-Newtonian fluids, and their smooth evolution. At the numerical level, we derive the discretization form of Cahn-Hilliard and Allen-Cahn equations with the material point method to effectively track the phase-field evolution, so as to avoid explicit handling of the boundary conditions at the interface. At the application level, we design a novel heuristic strategy to control specialized behaviors via user-defined schemes, including chemical potential, density curve, and so on. We exhibit a set of numerous experimental results consisting of challenging scenarios to validate the effectiveness and versatility of the new unified approach. This flexible and highly stable framework, founded upon the unified treatment and seamless coupling among various phases, and effective numerical discretization, has its unique advantage in animation creation toward novel phenomena heavily involving phase transitions with artistic creativity and guidance.
C1 [Tu, Zaili; Li, Chen; Zhao, Zipeng; Liu, Long; Wang, Chenhui; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200062, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Stony Brook, NY 11794 USA.
C3 East China Normal University; State University of New York (SUNY)
   System; State University of New York (SUNY) Stony Brook
RP Wang, CH (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200062, Peoples R China.; Qin, H (corresponding author), SUNY Stony Brook, Stony Brook, NY 11794 USA.
EM undersilence@foxmail.com; cli@cs.ecnu.edu.cn; cbwang@cs.ecnu.edu.cn;
   leo.longliu@outlook.com; wangch_daily@qq.com; qin@cs.stonybrook.edu
OI QIN, HONG/0000-0001-7699-1355; liu, long/0009-0000-7193-4626; Wang,
   Changbo/0000-0001-8940-6418
FU National Natural Science Foundation of Chinander [62002121, 62072183];
   Shanghai Science and Technology Commission [22511104600]; USA
   [NSFIS-1812606, NSFIS-1715985]
FX This article was supported in part by the National Natural Science
   Foundation of Chinander Grant No. 62002121 (awarded to Chen Li), Grant
   No. 62072183, and the Shanghai Science and Technology Commission under
   Grant No. 22511104600 (awarded to Changbo Wang), USA NSFIS-1715985 and
   USA NSFIS-1812606
CR Band S, 2018, COMPUT GRAPH-UK, V76, P37, DOI 10.1016/j.cag.2018.08.001
   Bargteil AW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239467
   Bender J, 2017, IEEE T VIS COMPUT GR, V23, P1193, DOI 10.1109/TVCG.2016.2578335
   Bialek James M., 1998, Nucl. Fusion, V38, P776
   CAHN JW, 1958, J CHEM PHYS, V28, P258, DOI 10.1063/1.1744102
   CARREAU PJ, 1972, T SOC RHEOL, V16, P99, DOI 10.1122/1.549276
   Chen XS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417809
   Ding MY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356537
   Fang Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392438
   Fang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322968
   Fei Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459678
   Fei Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201392
   Fu CY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130878
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275044
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201309
   Goktekin TG, 2004, ACM T GRAPHIC, V23, P463, DOI 10.1145/1015706.1015746
   Han XC, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340258
   Herschel WH, 1926, KOLLOID Z, V39, P291, DOI 10.1007/BF01432034
   Hu YM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201293
   Jiang C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766996
   Jiang CFF, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073623
   Klár G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925906
   Larionov E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073628
   Li D, 2022, MATH COMPUT, V91, P785, DOI 10.1090/mcom/3704
   Li W, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530132
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Museth Ken, 2013, ACM SIGGRAPH 2013 CO, DOI DOI 10.1145/2504435.2504454
   Nagasawa K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322947
   OLDROYD JG, 1950, PROC R SOC LON SER-A, V200, P523, DOI 10.1098/rspa.1950.0035
   Ram D, 2015, P 14 ACM SIGGRAPH EU, P157
   Ren B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459764
   Ren B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2645703
   Roscoe KH, 1968, On the generalized stress-strain behavior of wet clay
   Setaluri R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661269
   Simo J.C., 2006, Computational Inelasticity, V7
   Smith B, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3180491
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Stomakhin A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601176
   Su HZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459820
   SULSKY D, 1994, COMPUT METHOD APPL M, V118, P179, DOI 10.1016/0045-7825(94)00033-6
   Sun YC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480541
   Tampubolon AP, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073651
   Terzopoulos D., 1988, Computer Graphics, V22, P269, DOI 10.1145/378456.378522
   Wang S, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340259
   Wang XL, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392442
   Weiler M, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13349
   Wolper J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392428
   Wolper J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322949
   Xue T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417863
   Yan X, 2018, COMPUT GRAPH FORUM, V37, P183, DOI 10.1111/cgf.13523
   Yan X, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925897
   Yang T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130882
   Yang T, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818117
   Yue YH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275095
   Yue YH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2751541
   Zhu B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766981
NR 57
TC 1
Z9 1
U1 4
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
AR 19
DI 10.1145/3638047
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900006
DA 2024-08-05
ER

PT J
AU Zhao, XC
   Wang, LZ
   Sun, JX
   Zhang, HW
   Suo, JL
   Liu, YB
AF Zhao, Xiaochen
   Wang, Lizhen
   Sun, Jingxiang
   Zhang, Hongwen
   Suo, Jinli
   Liu, Yebin
TI HAvatar: High-fidelity Head Avatar via Facial Model Conditioned Neural
   Radiance Field
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Head avatar; image synthesis; parametric facial model; neural radiance
   field; image-to-image translation
AB The problem of modeling an animatable 3D human head avatar under light-weight setups is of significant importance but has not been well solved. Existing 3D representations either perform well in the realism of portrait images synthesis or the accuracy of expression control, but not both. To address the problem, we introduce a novel hybrid explicit-implicit 3D representation, Facial Model Conditioned Neural Radiance Field, which integrates the expressiveness of NeRF and the prior information from the parametric template. At the core of our representation, a synthetic-renderingsbased condition method is proposed to fuse the prior information from the parametric model into the implicit field without constraining its topological flexibility. Besides, based on the hybrid representation, we properly overcome the inconsistent shape issue presented in existing methods and improve the animation stability. Moreover, by adopting an overall GAN-based architecture using an image-to-image translation network, we achieve high-resolution, realistic and view-consistent synthesis of dynamic head appearance. Experiments demonstrate that our method can achieve state-of-the-art performance for 3D head avatar animation compared with previous methods.
C1 [Zhao, Xiaochen; Wang, Lizhen; Sun, Jingxiang; Zhang, Hongwen; Suo, Jinli; Liu, Yebin] Tsinghua Univ, Beijing, Peoples R China.
   [Wang, Lizhen] NNKosmos Technol, Hangzhou, Peoples R China.
C3 Tsinghua University
RP Zhao, XC (corresponding author), Tsinghua Univ, Beijing, Peoples R China.
EM Zhaoxc19@mails.tsinghua.edu.cn; wang-lz@mail.tsinghua.edu.cn;
   starkjxsun@gmail.com; zhanghongwen@mail.tsinghua.cdu.cn;
   jlsuo@tsinghua.edu.cn; liuyebin@mail.tsinghua.edu.cn
RI Wang, Lizhen/JXL-5347-2024; Zhao, Xiaochen/D-2594-2018
OI Wang, Lizhen/0000-0002-6674-9327; Sun, Jingxiang/0000-0003-2966-9501;
   Zhao, XiaoChen/0000-0001-8976-7723
FU National Key R&D Program of China [2022YFF0902200]; NSFC [62125107,
   61827805]
FX This article is supported by National Key R&D Program of China
   (2022YFF0902200), the NSFC project No. 62125107, and No. 61827805.
CR Athar S, 2022, PROC CVPR IEEE, P20332, DOI 10.1109/CVPR52688.2022.01972
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Brunton A, 2014, LECT NOTES COMPUT SC, V8689, P297, DOI 10.1007/978-3-319-10590-1_20
   Cao C, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530143
   Cao C, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459806
   Cao C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925873
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chan ER, 2022, PROC CVPR IEEE, P16102, DOI 10.1109/CVPR52688.2022.01565
   Chen C. Wang, 2020, P IEEE CVF C COMP VI, P13518
   Chen X., 2021, P IEEE CVF INT C COM, P11594
   Cheng SY, 2019, Arxiv, DOI arXiv:1903.10384
   Danecek R, 2022, PROC CVPR IEEE, P20279, DOI 10.1109/CVPR52688.2022.01967
   DaoyeWang Prashanth Chandran, 2022, P ACM SIGGRAPH C, P1
   Doukas Michail Christos, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P31, DOI 10.1109/TBIOM.2021.3049576
   Ersanilli E., 2020, arXiv, DOI 10.31234/osf.io/g7rzq
   Feng Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459936
   Gafni G, 2021, PROC CVPR IEEE, P8645, DOI 10.1109/CVPR46437.2021.00854
   Gal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459836
   Gecer B, 2022, IEEE T PATTERN ANAL, V44, P4879, DOI 10.1109/TPAMI.2021.3084524
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Grassal PW, 2022, PROC CVPR IEEE, P18632, DOI 10.1109/CVPR52688.2022.01810
   Gu JT, 2021, Arxiv, DOI arXiv:2110.08985
   Guo YD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5764, DOI 10.1109/ICCV48922.2021.00573
   Hong Y, 2022, PROC CVPR IEEE, P20342, DOI 10.1109/CVPR52688.2022.01973
   Hu LW, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3130800.3130887, 10.1145/3130800.31310887]
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kasten Y., 2020, PROC NEURIPS, V33, P2492, DOI 10.48550/arXiv.2003.09852
   Kellnhofer P, 2021, PROC CVPR IEEE, P4285, DOI 10.1109/CVPR46437.2021.00427
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Koujan MR, 2020, IEEE INT CONF AUTOMA, P16, DOI 10.1109/FG47880.2020.00048
   Lattas A, 2022, IEEE T PATTERN ANAL, V44, P9269, DOI 10.1109/TPAMI.2021.3125598
   Li H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778769
   Li RL, 2020, PROC CVPR IEEE, P3407, DOI 10.1109/CVPR42600.2020.00347
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Lombardi S, 2019, Arxiv, DOI [arXiv:1906.07751, 10.1145/3306346.3323020, DOI 10.1145/3306346.3323020]
   Lombardi S, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3476576.3476608, 10.1145/3450626.3459863]
   Lombardi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201401
   Lorensen H. E., 1987, Proc. SIGGRAPH, V21, P163, DOI 10.1145/37401.37422
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Luo HW, 2021, PROC CVPR IEEE, P11657, DOI 10.1109/CVPR46437.2021.01149
   Ma SG, 2021, PROC CVPR IEEE, P64, DOI 10.1109/CVPR46437.2021.00013
   Mescheder L, 2018, PR MACH LEARN RES, V80
   Mihajlovic M, 2022, LECT NOTES COMPUT SC, V13675, P179, DOI 10.1007/978-3-031-19784-0_11
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Nagano K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356568
   Nagano K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275075
   Neumann T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508417
   Niemeyer M, 2021, PROC CVPR IEEE, P11448, DOI 10.1109/CVPR46437.2021.01129
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Park K, 2021, Arxiv, DOI arXiv:2106.13228
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Ravi N., 2020, arXiv
   Roich D, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3544777
   Tewari A, 2018, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2018.00270
   Thies Justus, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P716, DOI 10.1007/978-3-030-58517-4_42
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Wang LZ, 2022, PROC CVPR IEEE, P20301, DOI 10.1109/CVPR52688.2022.01969
   Wang ZY, 2021, PROC CVPR IEEE, P5700, DOI 10.1109/CVPR46437.2021.00565
   Weng CY, 2022, PROC CVPR IEEE, P16189, DOI 10.1109/CVPR52688.2022.01573
   Xu S., 2020, P IEEE C COMP VIS PA, P7710
   Yang HT, 2020, PROC CVPR IEEE, P598, DOI 10.1109/CVPR42600.2020.00068
   Yenamandra T, 2021, PROC CVPR IEEE, P12798, DOI 10.1109/CVPR46437.2021.01261
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zheng YF, 2022, PROC CVPR IEEE, P13535, DOI 10.1109/CVPR52688.2022.01318
NR 68
TC 1
Z9 1
U1 5
U2 5
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 6
DI 10.1145/3626316
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800006
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Menapace, W
   Siarohin, A
   Lathuiliere, S
   Achlioptas, P
   Golyanik, V
   Tulyakov, S
   Ricci, E
AF Menapace, Willi
   Siarohin, Aliaksandr
   Lathuiliere, Stephane
   Achlioptas, Panos
   Golyanik, Vladislav
   Tulyakov, Sergey
   Ricci, Elisa
TI Promptable Game Models: Text-guided Game Simulation via Masked Diffusion
   Models
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Neural radiance fields; diffusion models; human motion generation;
   language modeling
AB Neural video game simulators emerged as powerful tools to generate and edit videos. Their idea is to represent games as the evolution of an environment's state driven by the actions of its agents. While such a paradigm enables users to play a game action-by-action, its rigidity precludes more semantic forms of control. To overcome this limitation, we augment game models with prompts specified as a set of natural language actions and desired states. The result-a Promptable Game Model (PGM)-makes it possible for a user to play the game by prompting it with high- and low-level action sequences. Most captivatingly, our PGM unlocks the director's mode, where the game is played by specifying goals for the agents in the form of a prompt. This requires learning "game AI," encapsulated by our animation model, to navigate the scene using high-level constraints, play against an adversary, and devise a strategy to win a point. To render the resulting state, we use a compositional NeRF representation encapsulated in our synthesis model. To foster future research, we present newly collected, annotated and calibrated Tennis and Minecraft datasets. Our method significantly outperforms existing neural video game simulators in terms of rendering quality and unlocks applications beyond the capabilities of the current state-of-the-art. Our framework, data, and models are available at snap-research.github.io/promptable-game-models.
C1 [Menapace, Willi] Univ Trento, Trento, Italy.
   [Siarohin, Aliaksandr; Achlioptas, Panos; Tulyakov, Sergey] Snap Inc, Santa Monica, CA USA.
   [Lathuiliere, Stephane] Inst Polytech Paris, LTCI, Telecom Paris, Paris, France.
   [Golyanik, Vladislav] SIC, MPI Informat, Saarbrucken, Germany.
C3 University of Trento; IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom Paris; Max Planck Society
RP Menapace, W (corresponding author), Univ Trento, Trento, Italy.
EM menapace@gmail.com; asiarohin@snapchat.com;
   stephane.lathuiliere@telecom-paris.fr; pachlioptas@gmail.com;
   golyanik@mpi-inf.mpg.de; stulyakov@snapchat.com; e.ricci@unitn.it
RI Ricci, Elisa/IYS-6532-2023; Menapace, Willi/JVY-9690-2024
OI Menapace, Willi/0000-0002-0715-9300
FU EU HEU AI4TRUST [101070190]
FX This work was partially supported by the EU HEU AI4TRUST (101070190)
   project.
CR Achlioptas Panos, 2023, P IEEE C COMPUTER VI
   Athanasiou Nikos, 2022, P INT C 3D VISION 3D
   Babaeizadeh M., 2018, ICLR
   Bain M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1708, DOI 10.1109/ICCV48922.2021.00175
   Blattmann A, 2023, PROC CVPR IEEE, P22563, DOI 10.1109/CVPR52729.2023.02161
   Buttner Michael, 2015, P NUCLAI
   Chan ER, 2022, PROC CVPR IEEE, P16102, DOI 10.1109/CVPR52688.2022.01565
   Chen Anpei, 2022, P EUROPEAN C COMPUTE
   Chen N., 2021, P INT C LEARNING REP
   Curtis C, 2022, 15TH ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION AND GAMES, MIG 2022, DOI 10.1145/3561975.3562941
   Dabral R, 2023, PROC CVPR IEEE, P9760, DOI 10.1109/CVPR52729.2023.00941
   Davtyan A, 2022, LECT NOTES COMPUT SC, V13677, P68, DOI 10.1007/978-3-031-19790-1_5
   Dieleman S, 2022, Arxiv, DOI [arXiv:2211.15089, DOI 10.48550/ARXIV.2211.15089]
   Fortuin Vincent, 2020, P INT C ARTIFICIAL I
   FRECHET M, 1957, CR HEBD ACAD SCI, V244, P689
   Fridovich-Keil S, 2022, PROC CVPR IEEE, P5491, DOI 10.1109/CVPR52688.2022.00542
   Fu TJ, 2023, PROC CVPR IEEE, P10681, DOI 10.1109/CVPR52729.2023.01029
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gregory J., 2018, Game engine architecture
   Han LG, 2022, PROC CVPR IEEE, P3605, DOI 10.1109/CVPR52688.2022.00360
   Hensel M, 2017, ADV NEUR IN, V30
   Ho J., 2020, Adv. Neural. Inf. Process. Syst, V33, P6840, DOI DOI 10.48550/ARXIV.2006.11239
   Ho JAT, 2022, Arxiv, DOI [arXiv:2210.02303, DOI 10.48550/ARXIV.2210.02303]
   Holden D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392440
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Hong W., 2022, arXiv
   Huang JH, 2022, LECT NOTES COMPUT SC, V13676, P546, DOI 10.1007/978-3-031-19787-1_31
   Jain A, 2022, PROC CVPR IEEE, P857, DOI 10.1109/CVPR52688.2022.00094
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   JonathanHo Tim Salimans, 2022, P ICLRWORKSHOP DEEP
   Karras Tero, 2020, P IEEE C COMPUTER VI
   Kim SW, 2021, PROC CVPR IEEE, P5816, DOI 10.1109/CVPR46437.2021.00576
   Kim SW, 2020, PROC CVPR IEEE, P1228, DOI 10.1109/CVPR42600.2020.00131
   Kingma D. P., 2014, arXiv
   Kong Zhifeng, 2020, P INT C LEARNING REP
   Kundu A, 2022, PROC CVPR IEEE, P12861, DOI 10.1109/CVPR52688.2022.01253
   Kwon YH, 2019, PROC CVPR IEEE, P1811, DOI 10.1109/CVPR.2019.00191
   Lam Max W. Y., 2022, P INT C LEARNING REP
   Lee K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275071
   Leng Yichong, 2022, P C ADV NEURAL INFOR
   Levy Omer, 2020, P INT C LEARNING REP
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Li R, 2022, LECT NOTES COMPUT SC, V13692, P419, DOI 10.1007/978-3-031-19824-3_25
   Lin CH, 2023, PROC CVPR IEEE, P300, DOI 10.1109/CVPR52729.2023.00037
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Martel JNP, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459785
   Menapace W, 2022, PROC CVPR IEEE, P3574, DOI 10.1109/CVPR52688.2022.00357
   Menapace W, 2021, PROC CVPR IEEE, P10056, DOI 10.1109/CVPR46437.2021.00993
   Meng Chenlin, 2022, P NEURIPS 2022 WORKS
   Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272
   Mildenhall Ben, 2020, P EUROPEAN C COMPUTE
   Müller N, 2022, PROC CVPR IEEE, P3961, DOI 10.1109/CVPR52688.2022.00394
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Müller T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417804
   Niemeyer M, 2021, PROC CVPR IEEE, P11448, DOI 10.1109/CVPR46437.2021.01129
   Oh J, 2015, ADV NEUR IN, V28
   Ost J, 2021, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR46437.2021.00288
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Park K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480487
   Raffel C, 2020, J MACH LEARN RES, V21
   Ramesh A., 2022, Hierarchical text-conditional image generation with clip latents, DOI 10.48550/arXiv.2204.06125
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Ren Shaoqing, 2015, P C ADV NEURAL INFOR
   ReplayMod, 2022, ReplayMod
   Rombach R., 2021, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saharia Chitwan, 2022, ADV NEURAL INFORM PR
   Salimans Tim, 2022, P INT C LEARNING REP
   Schuhmann Christoph, 2022, P C NEURAL INFORM PR
   Singer U., 2023, 11 INT C LEARNING RE
   Song J., 2021, P INT C LEARNING REP
   Stanton Matt, 2016, P EUROGRAPHICSACM SI
   Starke S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392450
   Starke S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356505
   Tashiro Y, 2021, ADV NEUR IN, V34
   Tevet G, 2022, LECT NOTES COMPUT SC, V13682, P358, DOI 10.1007/978-3-031-20047-2_21
   Tretschk E, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12939, DOI 10.1109/ICCV48922.2021.01272
   Unterthiner T, 2019, Arxiv, DOI [arXiv:1812.01717, 10.48550/arXiv.1812.01717]
   Vaswani Ashish, 2017, P C ADV NEURAL INFOR
   Weng CY, 2022, PROC CVPR IEEE, P16189, DOI 10.1109/CVPR52688.2022.01573
   Xu YH, 2023, PROC CVPR IEEE, P4402, DOI 10.1109/CVPR52729.2023.00428
   Yu A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5732, DOI 10.1109/ICCV48922.2021.00570
   Zhang MY, 2022, Arxiv, DOI arXiv:2208.15001
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 84
TC 1
Z9 1
U1 4
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
AR 17
DI 10.1145/3635705
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900004
OA Green Submitted
DA 2024-08-05
ER

PT J
AU Sawhney, R
   Lin, DQ
   Kettunen, M
   Bitterli, B
   Ramamoorthi, R
   Wyman, C
   Pharr, M
AF Sawhney, Rohan
   Lin, Daqi
   Kettunen, Markus
   Bitterli, Benedikt
   Ramamoorthi, Ravi
   Wyman, Chris
   Pharr, Matt
TI Decorrelating ReSTIR Samplers via MCMC Mutations
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Real-time rendering; resampled importance sampling; weighted reservoir
   sampling; Markov Chain Monte Carlo
ID METROPOLIS LIGHT TRANSPORT; ROBUST
AB Monte Carlo rendering algorithms often utilize correlations between pixels to improve efficiency and enhance image quality. For real-time applications in particular, repeated reservoir resampling offers a powerful framework to reuse samples both spatially in an image and temporally across multiple frames. While such techniques achieve equal-error up to 100x faster for real-time direct lighting [Bitterli et al. 2020] and global illumination [Ouyang et al. 2021; Lin et al. 2021], they are still far from optimal. For instance, spatiotemporal resampling often introduces noticeable correlation artifacts, while reservoirs holding more than one sample suffer from impoverishment in the form of duplicate samples. We demonstrate how interleaving Markov Chain Monte Carlo (MCMC) mutations with reservoir resampling helps alleviate these issues, especially in scenes with glossy materials and difficult-to-sample lighting. Moreover, our approach does not introduce any bias, and in practice, we find considerable improvement in image quality with just a single mutation per reservoir sample in each frame.
C1 [Sawhney, Rohan] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Sawhney, Rohan; Lin, Daqi; Bitterli, Benedikt; Ramamoorthi, Ravi; Wyman, Chris; Pharr, Matt] NVIDIA, Santa Clara, CA 95051 USA.
   [Kettunen, Markus] NVIDIA, Helsinki, Finland.
   [Ramamoorthi, Ravi] Univ Calif San Diego, La Jolla, CA USA.
C3 Carnegie Mellon University; Nvidia Corporation; University of California
   System; University of California San Diego
RP Sawhney, R (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.; Sawhney, R (corresponding author), NVIDIA, Santa Clara, CA 95051 USA.
EM rsawhney@nvidia.com; daqil@nvidia.com; mkettunen@nvidia.com;
   bbitterli@nvidia.com; ravir@cs.ucsd.edu; cwyman@nvidia.com;
   mpharr@nvidia.com
RI Lin, Daqi/ABT-7010-2022
OI Pharr, Matt/0000-0002-0566-8291; LIN, DAQI/0000-0002-5139-6418; Sawhney,
   Rohan/0000-0002-3661-1554; Bitterli, Benedikt/0000-0002-8799-7119
FU NVIDIA Graduate Fellowship
FX The authors thank Aaron Lefhon, Bill Dally and Keenan Crane for
   supporting this work. This work was generously supported by an NVIDIA
   Graduate Fellowship for the first author during his graduate studies at
   Carnegie Mellon University.
CR Andersson P, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3406183
   [Anonymous], 1987, P 14 ANN C COMP GRAP, DOI [10.1145/37401.37410, DOI 10.1145/37401.37410, DOI 10.1145/37402.37410]
   [Anonymous], 2018, Nvidia turing architecture in-depth
   [Anonymous], 1998, Robust Monte Carlo Methods for Light Transport Simulation
   Bashford-Rogers T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3472294
   Bitterli B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392481
   Bitterli B, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3132704
   Bitterli Benedikt, 2022, Ph. D Dissertations
   Cappé O, 2004, J COMPUT GRAPH STAT, V13, P907, DOI 10.1198/106186004X12803
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   CHAO MT, 1982, BIOMETRIKA, V69, P653
   Chenney S., 2007, PROC EUROGRAPHICS S, P287
   Cline D, 2005, ACM T GRAPHIC, V24, P1186, DOI 10.1145/1073204.1073330
   Dachsbacher C, 2014, COMPUT GRAPH FORUM, V33, P88, DOI 10.1111/cgf.12256
   Del Moral P, 2006, J R STAT SOC B, V68, P411, DOI 10.1111/j.1467-9868.2006.00553.x
   Doucet A, 2001, STAT ENG IN, P3
   Fan ShaoHua, 2007, Technical Report
   Georgiev Iliyan., 2016, P ACM SIGGRAPH 2016, P1
   GHOSH A., 2006, Eurographics Symposium on Rendering, P115
   Gruson A, 2020, COMPUT GRAPH FORUM, V39, P351, DOI 10.1111/cgf.13935
   Hachisuka T, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601138
   Hachisuka T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618487
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.1093/biomet/57.1.97
   Hedman P, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P121, DOI 10.1145/2856400.2856406
   Heitz E, 2019, COMPUT GRAPH FORUM, V38, P149, DOI 10.1111/cgf.13778
   Hua BS, 2019, COMPUT GRAPH FORUM, V38, P455, DOI 10.1111/cgf.13652
   Jakob W, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185554
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902
   Kallweit Simon, 2022, The Falcor Rendering Framework
   Kaplanyan AS, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601108
   Kelemen C, 2002, COMPUT GRAPH FORUM, V21, P531, DOI 10.1111/1467-8659.t01-1-00703
   Keller A., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P49, DOI 10.1145/258734.258769
   Kozlowski Pawel., 2021, GPU TECHN C 2021
   Lafortune E. P., 1993, EDUGRAPHICS '93. First International Conference on Graphics Education. COMPUGRAPHICS '93. Third International Conference on Computational Graphics and Visualization Techniques. Combined Proceedings, P145
   Lai YC, 2015, VISUAL COMPUT, V31, P83, DOI 10.1007/s00371-013-0908-z
   Lai Yu-Chi., 2007, Technical Report
   Lai Yu-Chi., 2009, Technical Report
   Lehtinen J, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461943
   Lin DQ, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530158
   Lin DQ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480499
   Luan FJ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392382
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Müller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156
   Müller T, 2017, COMPUT GRAPH FORUM, V36, P91, DOI 10.1111/cgf.13227
   Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028
   NVIDIA, 2022, NVIDIA Real-time Denoisers (NRD)
   NVIDIA, 2017, NVIDIA OptiX AI-Accelerated Denoiser
   Otsu H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275106
   Ouyang Y, 2021, COMPUT GRAPH FORUM, V40, P17, DOI 10.1111/cgf.14378
   Pauly M, 2000, SPRING COMP SCI, P11
   Schied C, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3233301
   Schied C, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105770
   Talbot J.F., 2005, Importance resampling for global illumination
   Talbot JustinF., 2005, RENDERING TECHNIQUES, P139, DOI DOI 10.2312/EGWR/EGSR05/139-146
   Van de Woestijne Joran, 2017, P EUR S REND EXP ID, P55
   Veach E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P419, DOI 10.1145/218380.218498
   Veach E., 1995, Photorealistic Rendering Techniques, P145
   Veach E., 1997, Proceedings of the 24th annual conference on Computer graphics and interactive techniques, P65, DOI DOI 10.1145/258734.258775
   Ward G. J., 1988, Computer Graphics, V22, P85, DOI 10.1145/378456.378490
   Wyman C., 2021, HIGH PERF GRAPH S PA, DOI DOI 10.2312/HPG.20211281
   Wyman Chris., 2021, P RAY TRAC GEMS 2, P345
NR 62
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 10
DI 10.1145/3629166
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800010
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Lipp, L
   Hahn, D
   Ecormier-Nocca, P
   Rist, F
   Wimmer, M
AF Lipp, Lukas
   Hahn, David
   Ecormier-Nocca, Pierre
   Rist, Florian
   Wimmer, Michael
TI View-Independent Adjoint Light Tracing for Lighting Design Optimization
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Lighting design; differentiable rendering; global illumination;
   optimization; ray tracing
AB Differentiable rendering methods promise the ability to optimize various parameters of three-dimensional (3D) scenes to achieve a desired result. However, lighting design has so far received little attention in this field. In this article, we introduce amethod that enables continuous optimization of the arrangement of luminaires in a 3D scene via differentiable light tracing. Our experiments show twomajor issues when attempting to apply existing methods from differentiable path tracing to this problem: First, many rendering methods produce images, which restricts the ability of a designer to define lighting objectives to image space. Second, most previous methods are designed for scene geometry or material optimization and have not been extensively tested for the case of optimizing light sources. Currently available differentiable ray-tracing methods do not provide satisfactory performance, even on fairly basic test cases in our experience. In this article, we propose, to the best of our knowledge, a novel adjoint light tracing method that overcomes these challenges and enables gradient-based lighting design optimization in a view-independent (camera-free) way. Thus, we allow the user to paint illumination targets directly onto the 3D scene or use existing baked illumination data (e.g., light maps). Using modern ray-tracing hardware, we achieve interactive performance. We find light tracing advantageous over path tracing in this setting, as it naturally handles irregular geometry, resulting in less noise and improved optimization convergence. We compare our adjoint gradients to state-of-the-art imagebased differentiable rendering methods. We also demonstrate that our gradient data works with various common optimization algorithms, providing good convergence behaviour. Qualitative comparisons with real-world scenes underline the practical applicability of our method.
C1 [Lipp, Lukas; Hahn, David; Ecormier-Nocca, Pierre; Rist, Florian; Wimmer, Michael] Vienna Univ Technol, Vienna, Austria.
   [Rist, Florian] King Abdullah Univ Sci & Technol, Thuwal, Makkah, Saudi Arabia.
C3 Technische Universitat Wien; King Abdullah University of Science &
   Technology
RP Lipp, L (corresponding author), Vienna Univ Technol, Vienna, Austria.
EM lukas.lipp@cg.tuwien.ac.at; david.hahn@tuwien.ac.at;
   pierre.ecormiernocca@tuwien.ac.at; florian.rist@kaust.edu.sa;
   wimmer@cg.tuwien.ac.at
CR ANSI/IES, 2020, ANSI/IES LM-63-19
   Bangaru SP, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417833
   Bradley Andrew M., 2019, PDE-constrained Optimization and the Adjoint Method
   DIAL GmbH, 2022, DIALux evo 10.1
   EasternGraphics GmbH, 2023, pCon.Planner
   Fridovich-Keil S, 2022, PROC CVPR IEEE, P5491, DOI 10.1109/CVPR52688.2022.00542
   Gautron Pascal., 2004, EUROGRAPHICS SYMPOSI, P321, DOI [10.2312/EGWR/EGSR04/321-330, DOI 10.2312/EGWR/EGSR04/321-330]
   Geilinger M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417766
   Gkaravelis A, 2016, VISUAL COMPUT, V32, P771, DOI 10.1007/s00371-016-1237-9
   Gkioulekas I, 2016, LECT NOTES COMPUT SC, V9907, P685, DOI 10.1007/978-3-319-46487-9_42
   Gkioulekas I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508377
   Goral C. M., 1984, Computers & Graphics, V18, P213
   Green Robin, 2003, ARCH GAM DEV C, V56
   Greenberg D. P., 1986, Visual Computer, V2, P291, DOI 10.1007/BF02020429
   Hansen N, 2003, EVOL COMPUT, V11, P1, DOI 10.1162/106365603321828970
   Hansen Nikolaus, 2021, c-cmaes
   Hasan M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618489
   Jakob W., 2022, MITSUBA 3 RENDERER
   Jensen HW, 1995, SPRING COMP SCI, P326, DOI 10.1007/978-3-7091-9430-0_31
   Jin S, 2019, COMPUT GRAPH FORUM, V38, P733, DOI 10.1111/cgf.13875
   Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902
   Khungurn P, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2818648
   Kingma D. P., 2014, arXiv
   Krivánek J, 2005, IEEE T VIS COMPUT GR, V11, P550, DOI 10.1109/TVCG.2005.83
   Larson Mats, 2013, The Finite ElementMethod: Theory, Implementation, and Applications
   Lehtinen J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360636
   Li TM, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275109
   Lin WC, 2013, COMPUT GRAPH FORUM, V32, P133, DOI 10.1111/cgf.12159
   Liu HTD, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275047
   Loubet G, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356510
   Luksch C, 2019, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2019), DOI 10.1145/3306131.3317015
   Nimier-David M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392406
   Nimier-David M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356498
   Nimier-David Merlin, 2021, EUROGRAPHICS S RENDE, DOI [DOI 10.2312/SR.20211292, 10.2312/SR.20211292]
   NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.1090/S0025-5718-1980-0572855-7
   Omidvar M, 2016, VISUAL COMPUT, V32, P1239, DOI 10.1007/s00371-015-1159-y
   OpenArena Team a FANDOM Games Community, 2008, OpenArena 0.8.1
   Pellacini F, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239505, 10.1145/1276377.1276444]
   Poulin P, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P58
   Qiu Yixuan, 2021, LBFGS++
   Relux Informatik AG, 2022, ReluxDesktop
   Schwarz M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629573
   Shesh A, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P95
   SILLION FX, 1991, COMP GRAPH, V25, P187, DOI 10.1145/127719.122739
   Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612
   Sorger J, 2016, IEEE T VIS COMPUT GR, V22, P290, DOI 10.1109/TVCG.2015.2468011
   Stam J, 2020, Arxiv, DOI arXiv:2006.15059
   Veach Eric, 1998, Ph.D. Dissertation, DOI [10.5555/927297AAI9837162, DOI 10.5555/927297AAI9837162]
   Vicini Delio, 2021, ACM Transactions on Graphics, V40, DOI 10.1145/3476576.3476672
   Walch A, 2020, IEEE T VIS COMPUT GR, V26, P569, DOI 10.1109/TVCG.2019.2934658
   Wieczorek MA, 2018, GEOCHEM GEOPHY GEOSY, V19, P2574, DOI 10.1029/2018GC007529
   Yan K, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530080
   Zeltner T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459807
   Zhang C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392383
   Zhang C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356522
NR 55
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
AR 35
DI 10.1145/3662180
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400011
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Jeske, SR
   Westhofen, L
   Löschner, F
   Fernández-fernández, JA
   Bender, J
AF Jeske, Stefan Rhys
   Westhofen, Lukas
   Loeschner, Fabian
   Fernandez-fernandez, Jose Antonio
   Bender, Jan
TI Implicit Surface Tension for SPH Fluid Simulation
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Surface tension; cohesion; adhesion; smoothed particle hydrodynamics;
   fluid simulation
ID SMOOTHED PARTICLE HYDRODYNAMICS; FORMULATION; BUBBLES; MODEL
AB The numerical simulation of surface tension is an active area of research in many different fields of application and has been attempted using a wide range of methods. Our contribution is the derivation and implementation of an implicit cohesion force based approach for the simulation of surface tension effects using the Smoothed Particle Hydrodynamics (SPH) method. We define a continuous formulation inspired by the properties of surface tension at the molecular scale which is spatially discretized using SPH. An adapted variant of the linearized backward Euler method is used for time discretization, which we also strongly couple with an implicit viscosity model. Finally, we extend our formulation with adhesion forces for interfaces with rigid objects.
   Existing SPH approaches for surface tension in computer graphics are mostly based on explicit time integration, thereby lacking in stability for challenging settings. We compare our implicit surface tension method to these approaches and further evaluate our model on a wider variety of complex scenarios, showcasing its efficacy and versatility. Among others, these include but are not limited to simulations of awater crown, a dripping faucet, and a droplet toy.
C1 [Jeske, Stefan Rhys; Westhofen, Lukas; Loeschner, Fabian; Fernandez-fernandez, Jose Antonio; Bender, Jan] Rhein Westfal TH Aachen, Aachen, Germany.
C3 RWTH Aachen University
RP Jeske, SR (corresponding author), Rhein Westfal TH Aachen, Aachen, Germany.
EM jeske@cs.rwth-aachen.de; l.westhofen@cs.rwth-aachen.de;
   loeschner@cs.rwth-aachen.de; fernandez@cs.rwth-aachen.de;
   bender@cs.rwth-aachen.de
OI Loschner, Fabian/0000-0001-6818-2953; Westhofen,
   Lukas/0000-0003-4427-2377
FU Deutsche Forschungsgemeinschaft e.V. (DFG, German Research Foundation)
FX This work was funded by the Deutsche Forschungsgemeinschaft e.V. (DFG,
   German Research Foundation).
CR Aanjaneya M, 2013, J COMPUT PHYS, V247, P17, DOI 10.1016/j.jcp.2013.03.048
   Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Albadawi A, 2013, INT J MULTIPHAS FLOW, V53, P11, DOI 10.1016/j.ijmultiphaseflow.2013.01.005
   Azencot Omri, 2015, P 14 ACM SIGGRAPH EU, P137, DOI DOI 10.1145/2786784.2786793
   Batty C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185609
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J, 2017, IEEE T VIS COMPUT GR, V23, P1193, DOI 10.1109/TVCG.2016.2578335
   Bender Jan, 2022, SPlisHSPlasH Library
   Bender Jan, 2019, Motion, Interaction and Games, P26
   Bergou M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778853
   Boyd L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159522
   BRACKBILL JU, 1992, J COMPUT PHYS, V100, P335, DOI 10.1016/0021-9991(92)90240-Y
   CAHN JW, 1958, J CHEM PHYS, V28, P258, DOI 10.1063/1.1744102
   Chen JY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459874
   Chen YL, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417859
   Clavet S., 2005, SCA 05 P 2005 ACM SI, P219, DOI DOI 10.1145/1073368.1073400
   Da F, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2767003
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Farrokhpanah A, 2021, NUMER HEAT TR B-FUND, V79, P255, DOI 10.1080/10407790.2021.1929295
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Gissler C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392431
   Gissler C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3284980
   He XW, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682630
   Hong JM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360647
   Hong JM, 2005, ACM T GRAPHIC, V24, P915, DOI 10.1145/1073204.1073283
   Hong JM, 2003, COMPUT GRAPH FORUM, V22, P253, DOI 10.1111/1467-8659.00672
   Hopp-Hirschler M, 2019, EUR PHYS J-SPEC TOP, V227, P1501, DOI 10.1140/epjst/e2019-800152-6
   Hu XY, 2006, J COMPUT PHYS, V213, P844, DOI 10.1016/j.jcp.2005.09.001
   Huber M., 2015, VRIPHYS, P41, DOI DOI 10.2312/VRIPHYS.20151333
   Hyde DAB, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417845
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Ihmsen Markus., 2014, EUROGRAPHICS 2014 ST, DOI [10.2312/egst.20141034, DOI 10.2312/EGST.20141034]
   Ishida S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392405
   Ishida S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130835
   Jeske SR, 2023, COMPUT PART MECH, V10, P1, DOI 10.1007/s40571-022-00465-x
   Kang M, 2008, COMPUT FLUIDS, V37, P524, DOI 10.1016/j.compfluid.2007.07.002
   Komen Hisaya, 2020, Quarterly Journal of the Japan Welding Society, V38, p25s, DOI [10.2207/qjjws.38.25s, DOI 10.2207/QJJWS.38.25S]
   Koschier D, 2022, COMPUT GRAPH FORUM, V41, P737, DOI 10.1111/cgf.14508
   Koschier D, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099565
   Kugelstadt T, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3480142
   Landau L. D., 1959, Fluid Mechanics, DOI DOI 10.1016/C2013-0-03799-1
   Lennard-Jones JE, 1931, P PHYS SOC, V43, P461, DOI 10.1088/0959-5309/43/5/301
   Liu SS, 2022, IEEE T VIS COMPUT GR, V28, P3168, DOI 10.1109/TVCG.2021.3055789
   Löschner F, 2020, COMPUT GRAPH FORUM, V39, P157, DOI 10.1111/cgf.14110
   LUCY LB, 1977, ASTRON J, V82, P1013, DOI 10.1086/112164
   Misztal MK, 2014, IEEE T VIS COMPUT GR, V20, P4, DOI 10.1109/TVCG.2013.97
   Misztal Marek Krzysztof, 2012, Multiphase flow of immiscible fluids on unstructured moving meshes, P1, DOI [10.2312/SCA/SCA12/097-106, DOI 10.2312/SCA/SCA12/097-106]
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   MONAGHAN JJ, 1989, J COMPUT PHYS, V82, P1, DOI 10.1016/0021-9991(89)90032-6
   Morris JP, 2000, INT J NUMER METH FL, V33, P333, DOI 10.1002/1097-0363(20000615)33:3<333::AID-FLD11>3.0.CO;2-7
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Nelkon Michael, 1969, Mechanics and Properties of Matter
   Ni XY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392445
   Patkar S., 2013, P 12 ACM SIGGRAPHEUR, P105
   Peer A, 2018, COMPUT GRAPH FORUM, V37, P135, DOI 10.1111/cgf.13317
   Popinet S, 2018, ANNU REV FLUID MECH, V50, P49, DOI [10.1146/annurev-fluid-122316045034, 10.1146/annurev-fluid-122316-045034]
   Ruan LW, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459862
   Schroeder C, 2012, J COMPUT PHYS, V231, P2092, DOI 10.1016/j.jcp.2011.11.021
   Solenthaler B., 2008, P 2008 ACM SIGGRAPH, P211, DOI 10.2312/SCA/SCA08/211-218
   Tartakovsky A, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.026301
   Wang H, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392487
   Wang MD, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459864
   Wang XK, 2017, J COMPUT SCI TECH-CH, V32, P1186, DOI 10.1007/s11390-017-1793-0
   Weiler M, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13349
   Xing JR, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555476
   Yang LJ, 2020, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2019, VOL 6
   Yang S., 2016, S COMP ANIM, P29
   Yang T., 2016, P ACM SIGGRAPH EUR S, P57, DOI DOI 10.2312/SCA.20161223
   Yang T, 2017, IEEE T VIS COMPUT GR, V23, P2235, DOI 10.1109/TVCG.2017.2706289
   Zhang MY, 2010, J COMPUT PHYS, V229, P7238, DOI 10.1016/j.jcp.2010.06.010
   Zhang YZ, 2012, IEEE T VIS COMPUT GR, V18, P1281, DOI 10.1109/TVCG.2011.141
   Zheng W, 2009, GRAPH MODELS, V71, P229, DOI 10.1016/j.gmod.2009.08.001
   Zheng W, 2015, J COMPUT PHYS, V280, P96, DOI 10.1016/j.jcp.2014.08.051
   Zhu B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766981
   Zhu B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601201
   Zorilla F, 2020, COMPUTERS, V9, DOI 10.3390/computers9020023
NR 77
TC 1
Z9 1
U1 6
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 13
DI 10.1145/3631936
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800013
DA 2024-08-05
ER

PT J
AU Uchytil, C
   Storti, D
AF Uchytil, Christopher
   Storti, Duane
TI A Function-Based Approach to Interactive High-Precision Volumetric
   Design and Fabrication
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Computer aided design; additive manufacturing; 3D printing; implicit
   surface; FReps; GPU; CUDA
AB We present a novel function representation (F-Rep) based geometric modeling kernel tailor-made to support computer aided design (CAD) and fabrication of high resolution volumetric models containing hundreds of billions of voxel grid elements. Our modeling kernel addresses existing limitations associated with evaluating, storing, and accessing volumetric data produced by F-Reps in contexts outside of rendering. The result is an F-Rep modeling kernel well suited for CAD-based applications.
   Our kernel utilizes a sparse volume data structure to manage F-Rep data while efficient F-Rep evaluation is achieved through a combination of interval arithmetic (IA), just-in-time (JIT) compilation of user-defined functions, and massively parallel evaluation on the GPU. We employ IA as the basis for local pruning of the function evaluation tree to minimize total function evaluations, we use a novel JIT compilation scheme to optimize function execution, and we take advantage of GPU-parallelism to enhance computational throughput. We illustrate the kernel's effectiveness in visualizing and slicing models with complex defining functions and detailed geometry, and utilize the geometry kernel to manufacture a physical part. Additionally, we present performance metrics across multiple hardware configurations demonstrating significant performance improvements over existing F-Rep geometry kernels, and we examine how our geometry kernel scales with computing power.
C1 [Uchytil, Christopher; Storti, Duane] Univ Washington, 1410 NE Campus Pkwy, Seattle, WA 98195 USA.
C3 University of Washington; University of Washington Seattle
RP Uchytil, C (corresponding author), Univ Washington, 1410 NE Campus Pkwy, Seattle, WA 98195 USA.
EM uchytilc@uw.edu; storti@uw.edu
CR Aleksandrov M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248241
   Bader C, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aas8652
   Beyer J, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12605
   Bloomenthal J., 1997, INTRO IMPLICIT SURFA
   Cook S, 2013, CUDA PROGRAMMING: A DEVELOPER'S GUIDE TO PARALLEL COMPUTING WITH GPUS, P1
   Crassin Cyril, 2009, GigaVoxels: Ray-guided streaming for efficient and detailed voxel rendering
   de Araújo BR, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2732197
   De Cusatis A.  Jr., 1999, XII Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00481), P65, DOI 10.1109/SIBGRA.1999.805711
   de Figueiredo LH, 2004, NUMER ALGORITHMS, V37, P147, DOI 10.1023/B:NUMA.0000049462.70970.b6
   DUFF T, 1992, COMP GRAPH, V26, P131, DOI 10.1145/142920.134027
   Fogal Thomas, 2013, Proc IEEE Symp Large Scale Data Anal Vis, V2013, P43, DOI 10.1109/LDAV.2013.6675157
   Fryazinov Oleg, 2007, GRAPHICON 2007 INT C
   Galin E, 2020, COMPUT GRAPH FORUM, V39, P545, DOI 10.1111/cgf.13951
   Ganter D, 2019, COMPUT GRAPH FORUM, V38, P13, DOI 10.1111/cgf.13756
   Génevaux JD, 2015, COMPUT GRAPH FORUM, V34, P198, DOI 10.1111/cgf.12530
   Gobbetti E, 2008, VISUAL COMPUT, V24, P797, DOI 10.1007/s00371-008-0261-9
   Hart J. C., 1989, Computer Graphics, V23, P289, DOI 10.1145/74334.74363
   Hart JC, 1996, VISUAL COMPUT, V12, P527, DOI 10.1007/s003710050084
   Hoetzlein R. K, 2016, P HIGH PERF GRAPH, P109, DOI DOI 10.2312/HPG.20161197
   Jazar K, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592448
   Ju T, 2002, ACM T GRAPHIC, V21, P339
   Kanamori Y, 2008, COMPUT GRAPH FORUM, V27, P351, DOI 10.1111/j.1467-8659.2008.01132.x
   Keeter Matthew, 2019, About us
   Keeter MJ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392429
   Keinert Benjamin., 2014, Smart Tools and Apps for Graphics - Eurographics Italian Chapter Conference, DOI DOI 10.2312/STAG.20141233
   Kim D, 2024, Arxiv, DOI arXiv:2208.04448
   Knoll A, 2009, COMPUT GRAPH FORUM, V28, P26, DOI 10.1111/j.1467-8659.2008.01189.x
   Knoll A, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P11, DOI 10.1109/RT.2007.4342585
   Knoll A, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P115
   Knoll AM, 2009, VISUAL COMPUT, V25, P209, DOI 10.1007/s00371-008-0215-2
   Krüger J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P287, DOI 10.1109/VISUAL.2003.1250384
   Liu BQ, 2013, IEEE T VIS COMPUT GR, V19, P1732, DOI 10.1109/TVCG.2012.151
   Loop C, 2006, ACM T GRAPHIC, V25, P664, DOI 10.1145/1141911.1141939
   Manson J, 2010, COMPUT GRAPH FORUM, V29, P377, DOI 10.1111/j.1467-8659.2009.01607.x
   Maple C, 2003, 2003 INTERNATIONAL CONFERENCE ON GEOMETRIC MODELING AND GRAPHICS, PROCEEDINGS, P90, DOI 10.1109/GMAG.2003.1219671
   MITCHELL DP, 1990, GRAPH INTER, P68
   Moore R.E, 2009, Introduction to interval analysis, DOI DOI 10.1137/1.9780898717716
   Moore RE., 1966, Interval Analysis
   Museth K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487235
   Museth Ken., 2014, ACM SIGGRAPH 2014 Talks. SIGGRAPH'14, DOI [DOI 10.1145/2614106.2614136, 10.1145/2614106.2614136]
   Museth Ken, 2021, ACM SIGGRAPH 2021 TA, DOI DOI 10.1145/3450623.3464653
   PASKO A, 1995, VISUAL COMPUT, V11, P429, DOI 10.1007/BF02464333
   Pasko A, 2011, GRAPH MODELS, V73, P165, DOI 10.1016/j.gmod.2011.03.001
   Ruijters D, 2006, JOURNAL WSCG, V14, P9
   Seyb D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356502
   Singh JM, 2010, IEEE T VIS COMPUT GR, V16, P261, DOI 10.1109/TVCG.2009.41
   Yurtoglu M, 2018, J COMPUT INF SCI ENG, V18, DOI 10.1115/1.4039639
   Zellmann Stefan, 2019, arXiv
NR 48
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD FEB
PY 2024
VL 43
IS 1
AR 3
DI 10.1145/3622934
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK8B8
UT WOS:001159478800003
OA hybrid
DA 2024-08-05
ER

PT J
AU Belhe, Y
   Xu, B
   Bangaru, SP
   Ramamoorthi, R
   Li, TM
AF Belhe, Yash
   Xu, Bing
   Bangaru, Sai Praveen
   Ramamoorthi, Ravi
   Li, Tzu-Mao
TI Importance Sampling BRDF Derivatives
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
AB We propose a set of techniques to efficiently importance sample the derivatives of a wide range of Bidirectional Reflectance Distribution Function (BRDF) models. In differentiable rendering, BRDFs are replaced by their differential BRDF counterparts, which are real-valued and can have negative values. This leads to a newsource of variance arising from their change in sign. Real-valued functions cannot be perfectly importance sampled by a positive-valued PDF, and the direct application of BRDF sampling leads to high variance. Previous attempts at antithetic sampling only addressed the derivativewith the roughness parameter of isotropicmicrofacet BRDFs. Our work generalizes BRDF derivative sampling to anisotropic microfacet models, mixture BRDFs, Oren-Nayar, Hanrahan-Krueger, among other analytic BRDFs.
   Our method first decomposes the real-valued differential BRDF into a sum of single-signed functions, eliminating variance from a change in sign. Next, we importance sample each of the resulting single-signed functions separately. The first decomposition, positivization, partitions the realvalued function based on its sign, and is effective at variance reduction when applicable. However, it requires analytic knowledge of the roots of the differential BRDF, and for it to be analytically integrable too. Our key insight is that the single-signed functions can have overlapping support, which significantly broadens the ways we can decompose a real-valued function. Our product and mixture decompositions exploit this property, and they allow us to support several BRDF derivatives that positivization could not handle. For a wide variety of BRDF derivatives, our method significantly reduces the variance (up to 58x in some cases) at equal computation cost and enables better recovery of spatially varying textures through gradient-descent-based inverse rendering.
C1 [Belhe, Yash; Xu, Bing; Bangaru, Sai Praveen; Ramamoorthi, Ravi; Li, Tzu-Mao] Univ Calif San Diego, San Diego, CA 92093 USA.
C3 University of California System; University of California San Diego
RP Belhe, Y (corresponding author), Univ Calif San Diego, San Diego, CA 92093 USA.
EM ybelhe@ucsd.edu; b4xu@ucsd.edu; sbangaru@mit.edu; ravir@ucsd.edu;
   tzli@ucsd.edu
FU NSF [2105806, 2212085]
FX This work was funded in part by NSF Grants No. 2105806 and No. 2212085,
   gifts from Adobe, Google, and Qualcomm, the Ronald L. Graham Chair, and
   the UC San Diego Center for Visual Computing.
CR Arvo J., 1990, Computer Graphics, V24, P63, DOI 10.1145/97880.97886
   Arvo J., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P343, DOI 10.1145/192161.192250
   ASHIKHMIN M., 2001, J GRAPHICS TOOLS, V5, P25
   Azinovic D, 2019, PROC CVPR IEEE, P2442, DOI 10.1109/CVPR.2019.00255
   Bangaru SP, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3618353
   Bangaru SP, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417833
   Beckmann Petr, 1987, The Scattering of Electromagnetic Waves From Rough Surfaces
   Blinn James F., 1977, ACM SIGGRAPH computer graphics, V11, P192, DOI DOI 10.1145/563858.563893
   Burley B., 2012, ACM SIGGRAPH, P1
   Burlingame B., 2015, South Europe: Food and Agriculture Organization of the United Nations, P1
   Chang W, 2023, PROCEEDINGS OF SIGGRAPH 2023 CONFERENCE PAPERS, SIGGRAPH 2023, DOI 10.1145/3588432.3591512
   Chen CL, 2020, AIP CONF PROC, V2231, DOI [10.1063/5.0002464, 10.1109/iccp48838.2020.9105209]
   Cohen Michael, 1993, Radiosity and Realistic Image Synthesis
   de La Gorce M, 2011, IEEE T PATTERN ANAL, V33, P1793, DOI 10.1109/TPAMI.2011.33
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Dupuy J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275059
   Fan Jiahui, 2022, P SIGGRAPH C
   Georgiev Iliyan, 2019, Autodesk standard surface
   Gkioulekas I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508377
   Grittmann P, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530126
   Hanrahan P., 1993, Computer Graphics Proceedings, P165, DOI 10.1145/166117.166139
   Heitz E, 2014, COMPUT GRAPH FORUM, V33, P103, DOI 10.1111/cgf.12417
   Heitz Eric, 2018, Journal of Computer Graphics Techniques (JCGT), V7, P1
   Heitz Eric, 2017, Research Report
   Henyey LG, 1941, ASTROPHYS J, V93, P70, DOI 10.1086/144246
   Jakob W, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530099
   Jakob Wenzel, 2014, Technical Report
   Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Khungurn P, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2818648
   Kingma D. P., 2014, arXiv
   Kuznetsov A, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459795
   Kuznetsov Alexandr, 2022, P SIGGRAPH C P
   Lafortune E. P. F., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P117, DOI 10.1145/258734.258801
   Laine S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417861
   Lawrence J, 2004, ACM T GRAPHIC, V23, P496, DOI 10.1145/1015706.1015751
   Li T.-M., 2018, ACM Trans. Graph. (Proc. SIGGRAPH Asia), V37, p222:1
   Liu SC, 2022, IEEE T PATTERN ANAL, V44, P50, DOI 10.1109/TPAMI.2020.3007759
   Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11
   Loubet G, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356510
   Löw J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077350
   Luan FJ, 2021, COMPUT GRAPH FORUM, V40, P101, DOI 10.1111/cgf.14344
   Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343
   Minnaert M, 1941, ASTROPHYS J, V93, P403, DOI 10.1086/144279
   Mitchell D. P., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P277, DOI 10.1145/237170.237265
   Nicolet B, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592139
   Nimier-David M, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530073
   Nimier-David M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392406
   Nimier-David M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356498
   Nimier-David Merlin, 2021, P EUR S REND DL ONL
   Nishino K, 2009, IEEE I CONF COMP VIS, P476, DOI 10.1109/ICCV.2009.5459255
   Oren Michael, 1994, PROC INT C COMPUT GR, P239, DOI DOI 10.1145/192161.192213
   Owen A, 2000, J AM STAT ASSOC, V95, P135, DOI 10.2307/2669533
   Owen Art B., 2013, Monte Carlo theory, methods and examples
   Pharr M., 2016, Physically based rendering: From theory to implementation
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Ramamoorthi R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1189762.1189764, 10.1145/1186644.1186646]
   Sadeghi I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451240
   Sbert M, 2018, EURASIP J ADV SIG PR, DOI 10.1186/s13634-018-0531-2
   Sun C, 2023, IEEE I CONF COMP VIS, P18000, DOI 10.1109/ICCV51070.2023.01654
   Sztrajman A, 2021, COMPUT GRAPH FORUM, V40, P332, DOI 10.1111/cgf.14335
   Talbot JustinF., 2005, RENDERING TECHNIQUES, P139, DOI DOI 10.2312/EGWR/EGSR05/139-146
   TROWBRIDGE TS, 1975, J OPT SOC AM, V65, P531, DOI 10.1364/JOSA.65.000531
   Veach E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P419, DOI 10.1145/218380.218498
   Vicini D, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459804
   Wald I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601199
   Walter B., 2007, P 18 EUR C REND TECH, P195, DOI [10.2312/EGWR/EGSR07/195-206, DOI 10.2312/EGWR/EGSR07/195-206]
   Wang YC, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3618331
   Ward G. J., 1992, Proceedings of the Third Eurographics Workshop on Rendering, P85
   WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078
   Wu LF, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480489
   Wu Liwen, 2023, Proceedings of the IEEE/CVF International Conference on Computer Vision, P3848
   Xing JK, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555479
   Xu B, 2023, PROCEEDINGS OF SIGGRAPH 2023 CONFERENCE PAPERS, SIGGRAPH 2023, DOI 10.1145/3588432.3591524
   Xu PY, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3618330
   He HY, 2014, Arxiv, DOI arXiv:1411.3954
   Yan K, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530080
   Yi SY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480498
   Yu ZH, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555500
   Yuksel C, 2022, P ACM COMPUT GRAPH, V5, DOI 10.1145/3543865
   Zeltner T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459807
   Zhang C, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459782
   Zhang C, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459783
   Zhang C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392383
   Zhang C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356522
   Zhang ZY, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3618385
NR 86
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
DI 10.1145/3648611
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400001
OA hybrid, Green Submitted
DA 2024-08-05
ER

PT J
AU Liu, SS
   He, XW
   Guo, YZ
   Chang, Y
   Wang, WC
AF Liu, Shusen
   He, Xiaowei
   Guo, Yuzhong
   Chang, Yue
   Wang, Wencheng
TI A Dual-Particle Approach for Incompressible SPH Fluids
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Adual-particle framework; incompressible fluids; tensile instability;
   smoothed particle hydrodynamics
ID TRANSPORT-VELOCITY FORMULATION; DELTA-PLUS-SPH; TENSILE INSTABILITY;
   HYDRODYNAMICS; STABILIZATION; IMPROVEMENT; SOLVER; MODEL; FLIP
AB Tensile instability is one of the major obstacles to particle methods in fluid simulation, which would cause particles to clump in pairs under tension and prevent fluid simulation to generate small-scale thin features. To address this issue, previousparticlemethods either use a backgroundpressure or a finite difference scheme to alleviate the particle clustering artifacts, yet still fail to produce small-scale thin features in free-surface flows. In this article, we propose a dual-particle approach for simulating incompressible fluids. Our approach involves incorporating supplementary virtual particles designed to capture and store particle pressures. These pressure samples undergo systematic redistribution at each time step, grounded in the initial positions of the fluid particles. By doing so, we effectively reduce tensile instability in standard SPH by narrowing down the unstable regions for particles experiencing tensile stress. As a result, we can accurately simulate free-surface flowswith rich small-scale thin features, such as droplets, streamlines, and sheets, as demonstrated by experimental results.
C1 [Liu, Shusen; Wang, Wencheng] Chinese Acad Sci, Inst Software, SKLCS, 4 South Fourth St, Beijing 100190, Peoples R China.
   [Liu, Shusen; Wang, Wencheng] UCAS, 4 South Fourth St, Beijing 100190, Beijing, Peoples R China.
   [He, Xiaowei; Guo, Yuzhong] Chinese Acad Sci, Inst Software, 4 South Fourth St, Beijing 100190, Peoples R China.
   [Chang, Yue] Peking Univ, 5 Yiheyuan Rd, Beijing 100871, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; Institute of Software, CAS; Peking University
RP Wang, WC (corresponding author), Chinese Acad Sci, Inst Software, SKLCS, 4 South Fourth St, Beijing 100190, Peoples R China.; Wang, WC (corresponding author), UCAS, 4 South Fourth St, Beijing 100190, Beijing, Peoples R China.; He, XW (corresponding author), Chinese Acad Sci, Inst Software, 4 South Fourth St, Beijing 100190, Peoples R China.
EM liushusen@iscas.ac.cn; xiaowei@iscas.ac.cn; guoyuzhong@iscas.ac.cn;
   yuechang@pku.edu.cn; whn@ios.ac.cn
FU National Key R&D Program of China [2021YFB1715800]; National Natural
   Science Foundation of China [62072446, 62302490, 61872345]
FX Y. Chang now at University of Toronto. Work was done while at Peking
   University. The project was partially supported by the National Key R&D
   Program of China (No.2021YFB1715800), and the National Natural Science
   Foundation of China (No. 62072446, 62302490, 61872345).
CR Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Ando R, 2012, IEEE T VIS COMPUT GR, V18, P1202, DOI 10.1109/TVCG.2012.87
   Batty C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276502
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Belytschko T, 2002, COMPUT MATH APPL, V43, P329, DOI 10.1016/S0898-1221(01)00290-5
   Bender Jan, 2015, P 14 ACM SIGGRAPH EU, P147, DOI DOI 10.1145/2786784.2786796
   BRACKBILL JU, 1986, J COMPUT PHYS, V65, P314, DOI 10.1016/0021-9991(86)90211-1
   Bridson Robert, 2015, Fluid Simulation for Computer Graphics, P1
   Chalk CM, 2020, COMPUT METHOD APPL M, V366, DOI 10.1016/j.cma.2020.113034
   Chen JK, 1999, COMPUT MECH, V23, P279, DOI 10.1007/s004660050409
   Chen JK, 2000, COMPUT METHOD APPL M, V190, P225, DOI 10.1016/S0045-7825(99)00422-3
   Chen XS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417809
   Chen YL, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417859
   Colagrossi A, 2009, PHYS REV E, V79, DOI 10.1103/PhysRevE.79.056701
   Colagrossi Andrea, 2005, A meshless Lagrangian method for free-surface and interface flows with fragmentation
   Cornelis J, 2014, COMPUT GRAPH FORUM, V33, P255, DOI 10.1111/cgf.12324
   Cummins SJ, 1999, J COMPUT PHYS, V152, P584, DOI 10.1006/jcph.1999.6246
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Dyka CT, 1997, INT J NUMER METH ENG, V40, P2325, DOI 10.1002/(SICI)1097-0207(19970715)40:13<2325::AID-NME161>3.0.CO;2-8
   DYKA CT, 1995, COMPUT STRUCT, V57, P573, DOI 10.1016/0045-7949(95)00059-P
   Fei Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459678
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Fries TP, 2008, INT J NUMER METH ENG, V74, P1067, DOI 10.1002/nme.2198
   Fu CY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130878
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275044
   Gerszewski D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508430
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Gissler C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3284980
   Gotoh H., 2016, J OCEAN ENG MAR ENER, V2, P251, DOI DOI 10.1007/S40722-016-0049-3
   Hardt SRIN, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356503
   HARLOW FH, 1965, PHYS FLUIDS, V8, P2182, DOI 10.1063/1.1761178
   Harlow Francis H., 1962, PARTICLE IN CELL MET, DOI [DOI 10.2172/4769185, 10. 2172/4769185]
   He XW, 2020, Arxiv, DOI arXiv:2001.09421
   He XW, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682630
   He XW, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366168
   He XW, 2012, COMPUT GRAPH FORUM, V31, P1948, DOI 10.1111/j.1467-8659.2012.03074.x
   Hu YM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201293
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Ihmsen Markus., 2014, EUROGRAPHICS 2014 ST, DOI [10.2312/egst.20141034, DOI 10.2312/EGST.20141034]
   Jiang C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766996
   Khayyer A, 2011, J COMPUT PHYS, V230, P3093, DOI 10.1016/j.jcp.2011.01.009
   Koschier D, 2022, COMPUT GRAPH FORUM, V41, P737, DOI 10.1111/cgf.14508
   Larionov E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073628
   Liu MB, 2010, ARCH COMPUT METHOD E, V17, P25, DOI 10.1007/s11831-010-9040-7
   Liu SS, 2022, IEEE T VIS COMPUT GR, V28, P3168, DOI 10.1109/TVCG.2021.3055789
   LIU WK, 1995, INT J NUMER METH ENG, V38, P1655, DOI 10.1002/nme.1620381005
   Liu XX, 2018, COMPUT METHOD APPL M, V339, P467, DOI 10.1016/j.cma.2018.05.005
   LUCY LB, 1977, ASTRON J, V82, P1013, DOI 10.1086/112164
   Lyu HG, 2021, APPL OCEAN RES, V117, DOI 10.1016/j.apor.2021.102938
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Monaghan JJ, 2000, J COMPUT PHYS, V159, P290, DOI 10.1006/jcph.2000.6439
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Museth Ken, 2013, ACM SIGGRAPH 2013 CO, DOI DOI 10.1145/2504435.2504454
   Museth Ken, 2021, ACM SIGGRAPH 2021 TA, DOI DOI 10.1145/3450623.3464653
   Nair P, 2014, COMPUT FLUIDS, V102, P304, DOI 10.1016/j.compfluid.2014.07.006
   Nakanishi R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417794
   Oger G, 2007, J COMPUT PHYS, V225, P1472, DOI 10.1016/j.jcp.2007.01.039
   Randles PW, 2000, INT J NUMER METH ENG, V48, P1445, DOI 10.1002/1097-0207(20000810)48:10<1445::AID-NME831>3.0.CO;2-9
   Raveendran K., 2011, P 2011 ACM SIGGRAPHE, P33
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Shewchuk Jonathan R., 1994, INTRO CONJUGATE GRAD
   Si WX, 2018, IEEE T MULTIMEDIA, V20, P3033, DOI 10.1109/TMM.2018.2825888
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Sun PN, 2018, COMPUT PHYS COMMUN, V224, P63, DOI 10.1016/j.cpc.2017.11.016
   Sun PN, 2017, COMPUT METHOD APPL M, V315, P25, DOI 10.1016/j.cma.2016.10.028
   Sun PN, 2021, OCEAN ENG, V221, DOI 10.1016/j.oceaneng.2020.108552
   Sun PN, 2019, PHYS FLUIDS, V31, DOI 10.1063/1.5124613
   SWEGLE JW, 1995, J COMPUT PHYS, V116, P123, DOI 10.1006/jcph.1995.1010
   Takahashi T, 2018, COMPUT GRAPH FORUM, V37, P313, DOI 10.1111/cgf.13292
   Tsuruta N, 2013, COMPUT FLUIDS, V82, P158, DOI 10.1016/j.compfluid.2013.05.001
   Um K, 2014, COMPUT GRAPH FORUM, V33, P209, DOI 10.1111/cgf.12489
   Vacondio R, 2021, COMPUT PART MECH, V8, P575, DOI 10.1007/s40571-020-00354-1
   Wang XL, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392442
   Weiler M, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13349
   Winchenbach R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3363555
   Wriggers Peter, 2017, 12 INT SPHERIC WORKS
   Xu R, 2009, J COMPUT PHYS, V228, P6703, DOI 10.1016/j.jcp.2009.05.032
   Yang M, 2017, VISUAL COMPUT, V33, P597, DOI 10.1007/s00371-016-1274-4
   Yang S., 2016, S COMP ANIM, P29
   Yang T, 2017, IEEE T VIS COMPUT GR, V23, P2235, DOI 10.1109/TVCG.2017.2706289
   Zhan L, 2019, J FLUID STRUCT, V86, P329, DOI 10.1016/j.jfluidstructs.2019.02.002
   Zhang C, 2017, J COMPUT PHYS, V337, P216, DOI 10.1016/j.jcp.2017.02.016
NR 85
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
AR 28
DI 10.1145/3649888
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400004
OA hybrid
DA 2024-08-05
ER

PT J
AU Richardson, E
   Goldberg, K
   Alaluf, Y
   Cohen-Or, D
AF Richardson, Elad
   Goldberg, Kfir
   Alaluf, Yuval
   Cohen-Or, Daniel
TI ConceptLab: Creative Concept Generation using VLM-Guided Diffusion Prior
   Constraints
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE Diffusion Models; Image Generation; Personalization
AB Recent text-to-image generative models have enabled us to transform our words into vibrant, captivating imagery. The surge of personalization techniques that has followed has also allowed us to imagine unique concepts in new scenes. However, an intriguing question remains: How can we generate a new, imaginary concept that has never been seen before? In this article, we present the task of creative text-to-image generation, where we seek to generate new members of a broad category (e.g., generating a pet that differs from all existing pets). We leverage the under-studied Diffusion Prior models and show that the creative generation problem can be formulated as an optimization process over the output space of the diffusion prior, resulting in a set of "prior constraints." To keep our generated concept from converging into existing members, we incorporate a question-answering Vision-Language Model that adaptively adds new constraints to the optimization problem, encouraging the model to discover increasingly more unique creations. Finally, we show that our prior constraints can also serve as a strong mixing mechanism allowing us to create hybrids between generated concepts, introducing even more flexibility into the creative process.
C1 [Richardson, Elad; Goldberg, Kfir; Alaluf, Yuval; Cohen-Or, Daniel] Tel Aviv Univ, Tel Aviv, Israel.
C3 Tel Aviv University
RP Richardson, E (corresponding author), Tel Aviv Univ, Tel Aviv, Israel.
EM elad.richardson@gmail.com; kfirgold99@gmail.com; yuvalalaluf@gmail.com;
   cohenor@gmail.com
CR Aggarwal P, 2023, Arxiv, DOI arXiv:2302.11710
   Alaluf Y, 2023, Arxiv, DOI arXiv:2305.15391
   Avrahami O, 2023, Arxiv, DOI arXiv:2206.02779
   Balaji Y., 2022, arXiv
   Brooks T, 2023, PROC CVPR IEEE, P18392, DOI 10.1109/CVPR52729.2023.01764
   Chefer H, 2023, Arxiv, DOI arXiv:2301.13826
   Cohen N, 2022, LECT NOTES COMPUT SC, V13680, P558, DOI 10.1007/978-3-031-20044-1_32
   Cohen-Or D, 2016, VISUAL COMPUT, V32, P7, DOI 10.1007/s00371-015-1193-9
   Couairon Guillaume, 2023, TPROCEEDINGS 11 INT
   Dhariwal P, 2021, ADV NEUR IN, V34
   Ding Ming, 2022, Advances in Neural Information Processing Systems, V35, P16890
   Elgammal A, 2017, Arxiv, DOI arXiv:1706.07068
   Esser Patrick, 2023, arXiv
   Gal R, 2023, Arxiv, DOI arXiv:2302.12228
   Gal Rinon, 2023, P 11 INT C LEARN REP
   Ge Songwei, 2021, INT C LEARN REPR
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Hertz Amir, 2023, P 11 INT C LEARN REP
   Hertzmann A, 2018, ARTS, V7, DOI 10.3390/arts7020018
   Ho J., 2020, Adv. Neural. Inf. Process. Syst, V33, P6840, DOI DOI 10.48550/ARXIV.2006.11239
   Kawar B, 2023, PROC CVPR IEEE, P6007, DOI 10.1109/CVPR52729.2023.00582
   Khalid NM, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555392
   Kumari N, 2023, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR52729.2023.00192
   Li JN, 2023, Arxiv, DOI arXiv:2301.12597
   Liu N, 2022, LECT NOTES COMPUT SC, V13677, P423, DOI 10.1007/978-3-031-19790-1_26
   Meng Chenlin, 2022, P INT C LEARN REPR
   Nichol A, 2021, PR MACH LEARN RES, V139
   Nichol A, 2022, Arxiv, DOI arXiv:2112.10741
   Parmar G, 2023, PROCEEDINGS OF SIGGRAPH 2023 CONFERENCE PAPERS, SIGGRAPH 2023, DOI 10.1145/3588432.3591513
   pharmapsychotic, 2022, clip-interrogator
   Poole Ben, 2023, P 11 INT C LEARN REP
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramesh A., 2022, Hierarchical text-conditional image generation with clip latents, DOI 10.48550/arXiv.2204.06125
   Ranaweera W, 2017, J COMPUT SCI TECH-CH, V32, P1138, DOI 10.1007/s11390-017-1789-9
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Ruiz N, 2023, PROC CVPR IEEE, P22500, DOI 10.1109/CVPR52729.2023.02155
   Saharia C., 2022, ADV NEURAL INF PROCE, V35, P36479
   Sbai O, 2019, LECT NOTES COMPUT SC, V11131, P37, DOI 10.1007/978-3-030-11015-4_5
   Shakhmatov Arseniy, 2022, Kandinsky 2
   Shi J, 2023, Arxiv, DOI arXiv:2304.03411
   Sims K., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P15, DOI 10.1145/192161.192167
   SIMS K, 1991, COMP GRAPH, V25, P319, DOI 10.1145/127719.122752
   Singer Uriel, 2023, P 11 INT C LEARN REP
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Song Jiaming, 2021, P INT C LEARN REPR
   Tewel Y, 2023, PROCEEDINGS OF SIGGRAPH 2023 CONFERENCE PAPERS, SIGGRAPH 2023, DOI 10.1145/3588432.3591506
   Tumanyan N, 2023, PROC CVPR IEEE, P1921, DOI 10.1109/CVPR52729.2023.00191
   Vinker Y, 2023, Arxiv, DOI arXiv:2305.18203
   Voynov A, 2023, Arxiv, DOI arXiv:2303.09522
   Wei YX, 2023, Arxiv, DOI arXiv:2302.13848
   Xu JL, 2023, PROC CVPR IEEE, P20908, DOI 10.1109/CVPR52729.2023.02003
   Xu K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185553
   Zhou YF, 2023, PROC CVPR IEEE, P10157, DOI 10.1109/CVPR52729.2023.00979
NR 53
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD JUN
PY 2024
VL 43
IS 3
AR 34
DI 10.1145/3659578
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XZ7E2
UT WOS:001265558400010
OA Green Submitted, Bronze
DA 2024-08-05
ER

PT J
AU Banterle, F
   Marnerides, D
   Bashford-Rogers, T
   Debattista, K
AF Banterle, Francesco
   Marnerides, Demetris
   Bashford-Rogers, Thomas
   Debattista, Kurt
TI Self-supervised High Dynamic Range Imaging: What Can Be Learned from a
   Single 8-bit Video?
SO ACM TRANSACTIONS ON GRAPHICS
LA English
DT Article
DE High dynamic range imaging; inverse tone mapping; deep learning;
   computational photography
ID EXPANSION
AB Recently, Deep Learning-based methods for inverse tone mapping standard dynamic range (SDR) images to obtain high dynamic range (HDR) images have become very popular. These methods manage to fill over-exposed areas convincingly both in terms of details and dynamic range. To be effective, deep learning-based methods need to learn from large datasets and transfer this knowledge to the network weights. In this work, we tackle this problem from a completely different perspective. What can we learn from a single SDR 8-bit video? With the presented self-supervised approach, we show that, in many cases, a single SDR video is sufficient to generate an HDR video of the same quality or better than other state-of-the-art methods.
C1 [Banterle, Francesco] CNR, ISTI, Via G Moruzzi 1, I-56124 Pisa, Italy.
   [Marnerides, Demetris; Bashford-Rogers, Thomas; Debattista, Kurt] Univ Warwick, WMG, Warwick CV4 7AL, England.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR); University
   of Warwick
RP Banterle, F (corresponding author), CNR, ISTI, Via G Moruzzi 1, I-56124 Pisa, Italy.
EM francesco.banterle@isti.cnr.it; dmarnerides@gmail.com;
   Thomas.Bashford-Rogers@warwick.ac.uk; K.Debattista@warwick.ac.uk
CR Akyüz AG, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239489
   Akyüz AO, 2007, J VIS COMMUN IMAGE R, V18, P366, DOI 10.1016/j.jvcir.2007.04.001
   Aydin TO, 2008, PROC SPIE, V6806, DOI 10.1117/12.765095
   Azimi Maryam, 2014, INT C MULTIMEDIA SIG
   Banitalebi-Dehkordi A, 2014, 2014 10TH INTERNATIONAL CONFERENCE ON HETEROGENEOUS NETWORKING FOR QUALITY, RELIABILITY, SECURITY AND ROBUSTNESS (QSHINE), P8, DOI [10.1109/QSHINE.2014.6928652, 10.4108/icst.qshine.2014.256318]
   Banterle F, 2006, Proceedings of the 4th international conference on Computer graphics and interactive techniques in Australasia and Southeast Asia, P349
   Bist C, 2017, COMPUT GRAPH-UK, V62, P77, DOI 10.1016/j.cag.2016.12.006
   Chen GY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2482, DOI 10.1109/ICCV48922.2021.00250
   Chen XY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4480, DOI 10.1109/ICCV48922.2021.00446
   Debevec P, 2002, IEEE COMPUT GRAPH, V22, P26, DOI 10.1109/38.988744
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Didyk P, 2008, COMPUT GRAPH FORUM, V27, P1265, DOI 10.1111/j.1467-8659.2008.01265.x
   Eilertsen G, 2021, IEEE INT CONF COMP V, P3981, DOI 10.1109/ICCVW54120.2021.00445
   Eilertsen G, 2019, PROC CVPR IEEE, P11168, DOI 10.1109/CVPR.2019.01143
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Froehlich J, 2014, PROC SPIE, V9023, DOI 10.1117/12.2040003
   Hanji Param, 2022, SIGGRAPH22 Conference Proceeding: Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings, DOI 10.1145/3528233.3530729
   Hasinoff SW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980254
   Huo YQ, 2014, VISUAL COMPUT, V30, P507, DOI 10.1007/s00371-013-0875-4
   ITU-R, 2018, Recommendation ITU-R BT.2100-2: Image Parameter Values for High Dynamic Range Television for Use in Production and International Programme Exchange
   Jo SY, 2022, IEEE T MULTIMEDIA, V24, P2713, DOI 10.1109/TMM.2021.3087034
   Kalantari NK, 2019, COMPUT GRAPH FORUM, V38, P193, DOI 10.1111/cgf.13630
   Kalantari NK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508402
   Kim SY, 2020, AAAI CONF ARTIF INTE, V34, P11287
   Kim SY, 2019, IEEE I CONF COMP VIS, P3116, DOI 10.1109/ICCV.2019.00321
   Kingma D. P., 2014, arXiv
   Kovaleski RP, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P49, DOI 10.1109/SIBGRAPI.2014.29
   Landis Hayden, 2002, RenderMan in Production, P87
   Lecouat B, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530180
   Lee CY, 2018, IEEE T PATTERN ANAL, V40, P863, DOI 10.1109/TPAMI.2017.2703082
   Lee S, 2021, IEEE T MULTIMEDIA, V23, P2561, DOI 10.1109/TMM.2020.3013378
   Lee S, 2018, LECT NOTES COMPUT SC, V11206, P613, DOI 10.1007/978-3-030-01216-8_37
   Li H, 2017, 14TH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION (CVMP), DOI 10.1145/3150165.3150170
   Lin S, 2004, PROC CVPR IEEE, P938
   Liu YL, 2020, PROC CVPR IEEE, P1648, DOI 10.1109/CVPR42600.2020.00172
   Mantiuk RK, 2023, Arxiv, DOI arXiv:2304.13625
   Mantiuk RK, 2021, PICT COD SYMP, P56, DOI 10.1109/PCS50896.2021.9477471
   Marnerides D, 2018, COMPUT GRAPH FORUM, V37, P37, DOI 10.1111/cgf.13340
   Masia B, 2017, MULTIMED TOOLS APPL, V76, P631, DOI 10.1007/s11042-015-3036-0
   Masia B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618506
   Metzler CA, 2020, PROC CVPR IEEE, P1372, DOI 10.1109/CVPR42600.2020.00145
   Meylan L, 2006, IEEE T IMAGE PROCESS, V15, P2820, DOI 10.1109/TIP.2006.877312
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   Perez-Pellitero E, 2021, IEEE COMPUT SOC CONF, P691, DOI 10.1109/CVPRW53098.2021.00078
   Rempel AG, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239490, 10.1145/1276377.1276426]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Santos MS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392403
   Seetzen Helge, 2004, ACM SIGGRAPH EMERGIN, P8, DOI [10.1145/1186155.1186164, DOI 10.1145/1186155.1186164]
   Sharma A., 2020, P INT C LEARN REPR, DOI DOI 10.1007/978-3-030-69544-6_2
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Sun QL, 2020, PROC CVPR IEEE, P1383, DOI 10.1109/CVPR42600.2020.00146
   Vo TV, 2020, IEEE ACCESS, V8, P24576, DOI 10.1109/ACCESS.2020.2970857
   Ulyanov D, 2020, INT J COMPUT VISION, V128, P1867, DOI 10.1007/s11263-020-01303-4
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang C, 2022, Arxiv, DOI arXiv:2211.12352
   Wang Lvdi, 2007, ACM SIGGRAPH 2007 SK, P72, DOI DOI 10.1145/1278780.1278867
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Yang X, 2018, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2018.00193
   Yu HN, 2021, COMPUT GRAPH FORUM, V40, P181, DOI 10.1111/cgf.14412
   Zhang Y, 2021, COMPUT GRAPH FORUM, V40, P179, DOI 10.1111/cgf.142624
   Zontak M, 2011, PROC CVPR IEEE, P977, DOI 10.1109/CVPR.2011.5995401
NR 62
TC 2
Z9 2
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0730-0301
EI 1557-7368
J9 ACM T GRAPHIC
JI ACM Trans. Graph.
PD APR
PY 2024
VL 43
IS 2
AR 24
DI 10.1145/3648570
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OQ7R2
UT WOS:001208809900011
OA Bronze
DA 2024-08-05
ER

EF