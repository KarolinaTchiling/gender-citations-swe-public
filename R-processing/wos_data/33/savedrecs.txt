FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Hernoux, F
   Christmann, O
AF Hernoux, Franck
   Christmann, Olivier
TI A seamless solution for 3D real-time interaction: design and evaluation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Seamless solution; Hand tracking; Real time; 3D
   interaction; 3D camera
ID TRACKING; VISION; INTERFACE; MOTION
AB This paper aims to propose and evaluate a markerless solution for capturing hand movements in real time to allow 3D interactions in virtual environments (VEs). Tools such as keyboard and mice are not enough for interacting in 3D VE; current motion capture systems are expensive and require wearing equipment. We developed a solution to allow more natural interactions with objects and VE for navigation and manipulation tasks. We conducted an experimental study involving 20 participants. The goal was to realize object manipulation (moving, orientation, scaling) and navigation tasks in VE. We compared our solution (Microsoft Kinect-based) with data gloves and magnetic sensors (3DGloves) regarding two criteria: performance and acceptability. Results demonstrate similar performance (precision, execution time) but a better overall acceptability for our solution. Preferences of participants are mostly in favor of the 3DCam, mainly for the criteria of comfort, freedom of movement, and handiness. Our solution can be considered as a real alternative to conventional systems for object manipulation in virtual reality.
C1 [Hernoux, Franck; Christmann, Olivier] Arts & Metiers ParisTech, LAMPA, F-49000 Angers, France.
C3 Arts et Metiers Institute of Technology
RP Hernoux, F (corresponding author), Arts & Metiers ParisTech, LAMPA, 2 Bd Ronceray, F-49000 Angers, France.
EM hernouxfranck@yahoo.fr; olivier.christmann@ensam.eu
OI Christmann, Olivier/0000-0001-8652-5630
CR [Anonymous], P ACM S VIRT REAL SO
   [Anonymous], SBC S VIRT REAL 2006
   [Anonymous], AS PAC C COMP HUM IN
   [Anonymous], MOT TECHN
   [Anonymous], C EIAH 2003 STRAB FR
   [Anonymous], VISUAL ARTICULATED H
   [Anonymous], P 2008 S INT 3D GRAP
   [Anonymous], P SIGCHI C HUM FACT
   [Anonymous], P 2009 S INT 3D GRAP
   [Anonymous], ENG REALITY VIRTUAL
   [Anonymous], TRAITE REALITE VIRTU
   [Anonymous], PRACTICAL COLOR BASE
   [Anonymous], 3D TIME FLIGHT DIST
   [Anonymous], 6EMES JOURNEES TRAVA
   [Anonymous], SIMULATION MOUVEMENT
   [Anonymous], VIRT REAL INT C LAV
   [Anonymous], INT C SIGN INF PROC
   [Anonymous], 3D HAND TRACKING VID
   [Anonymous], 1995, P SIGCHI C HUM FACT
   [Anonymous], 3D STEREO MEDIA
   [Anonymous], 22 WSCG INT C COMP G
   [Anonymous], P 6 INT C ART MOT DE
   [Anonymous], 7 INT C 3D WEB TECHN
   [Anonymous], TRAITE REALITE VIRTU
   [Anonymous], TRAVAIL HUMAIN
   [Anonymous], INT C COMP GRAPH VIS
   [Anonymous], INT C TANG EMB EMB I
   [Anonymous], 9 IFIP TC13 INT C HU
   [Anonymous], 1992, PROC S INTERACTIVE 3
   [Anonymous], 9 ANN ACM S US INT S
   [Anonymous], SIGCHI C HUM FACT CO
   [Anonymous], BRIT MACH VIS C BMVA
   [Anonymous], P 12 ACM SIGGRAPH IN
   [Anonymous], 2011, ACM S US INT SOFTW T
   [Anonymous], AFFECTIONS NEUROLOGI
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Beaudouin-Lafon M., 2004, Proceedings of the working conference on Advanced visual interfaces, P15, DOI DOI 10.1145/989863.989865
   Bérard F, 2009, LECT NOTES COMPUT SC, V5727, P400, DOI 10.1007/978-3-642-03658-3_45
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Callahan J., 1988, P ACM CHI C HUMAN FA, P95, DOI DOI 10.1145/57167.57182
   Chen M., 1988, Computer Graphics, V22, P121, DOI 10.1145/378456.378497
   Dewaele G, 2004, LECT NOTES COMPUT SC, V3021, P495
   Di Stefano L, 2004, IMAGE VISION COMPUT, V22, P983, DOI 10.1016/j.imavis.2004.03.009
   Diaz Rodriguez Natalia, 2013, Ubiquitous Computing and Ambient Intelligence. Context-Awareness and Context-Driven Interaction. 7th International Conference, UCAmI 2013. Proceedings: LNCS 8276, P254, DOI 10.1007/978-3-319-03176-7_33
   Dorner Brigitte., 1994, Chasing the colour glove: Visual hand tracking
   Elmezain M, 2008, INT C PATT RECOG, P424
   Fiorentino M, 2013, INT J INTERACT DES M, V7, P249, DOI 10.1007/s12008-012-0179-3
   Gratzel C, 2004, Technol Health Care, V12, P245
   GUIARD Y, 1987, J MOTOR BEHAV, V19, P486
   Hand C, 1997, COMPUT GRAPH FORUM, V16, P269, DOI 10.1111/1467-8659.00194
   Hassanpour R., 2008, P WORLD ACAD SCI ENG, V31, P1
   Hayward V., 1996, Robotics Research, P195, DOI [DOI 10.1007/978-1-4471-1021-722, DOI 10.1007/978-1-4471-0765-122]
   HOMMA K, 1985, J NUCL MED, V26, P1472
   Hong DP, 2006, INT J HUM-COMPUT INT, V20, P271, DOI 10.1207/s15327590ijhc2003_6
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Kim Y, 2014, SURG ENDOSC, V28, P1993, DOI 10.1007/s00464-013-3383-8
   Klein T, 2012, COMPUT GRAPH FORUM, V31, P1225, DOI 10.1111/j.1467-8659.2012.03115.x
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   Lange R., 2000, Sensor Review, V20, P212, DOI 10.1108/02602280010372359
   Laurel B.K., 1986, Interface as mimesis User centered system design - New Perspectives on Human-Computer Interaction
   Lee J, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2013), P1220, DOI 10.1109/ICCAS.2013.6704175
   Lévesque JC, 2011, P IEEE VIRT REAL ANN, P223, DOI 10.1109/VR.2011.5759479
   Lin JC, 2014, MULTIMED TOOLS APPL, V73, P2009, DOI 10.1007/s11042-013-1690-7
   Livingston MA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P119, DOI 10.1109/VR.2012.6180911
   Maes PJ, 2013, INT J HUM-COMPUT INT, V29, P471, DOI 10.1080/10447318.2012.720197
   Mason AH, 2009, INT J HUM-COMPUT INT, V25, P785, DOI 10.1080/10447310903025529
   May Stefan, 2007, Vision Systems- Applications, P181
   Mine M.R., 1995, Virtual Environment Interaction Techniques
   Mistry P., 2009, P CHI 09 EXTENDED AB, P4111, DOI [DOI 10.1145/1520340.1520626, 10.1145/1520340.1520626]
   Moerman C., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P15, DOI 10.1109/3DUI.2012.6184178
   Mohr D, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P519
   Norman D. A., 1988, PSYCHOL EVERYDAY THI
   Pamplona V.F., 2008, P X S VIRTUAL REALIT, P204
   Pedersoli F, 2014, VISUAL COMPUT, V30, P1107, DOI 10.1007/s00371-014-0921-x
   Poupyrev I, 1998, COMPUT GRAPH FORUM, V17, pC41
   Prisacariu Victor Adrian, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P368, DOI 10.1109/FG.2011.5771427
   Raheja J. L., 2011, 2011 Third International Conference on Computational Intelligence, Modelling and Simulation, P248, DOI 10.1109/CIMSim.2011.51
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Shen Y, 2011, INT J HUM-COMPUT INT, V27, P523, DOI 10.1080/10447318.2011.555297
   Song J, 2014, COMPUT AIDED DESIGN, V46, P239, DOI 10.1016/j.cad.2013.08.039
   Stenger B, 2006, LECT NOTES COMPUT SC, V3852, P551
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   Theobalt C, 2004, ACM T GRAPHIC, V23, P540, DOI 10.1145/1015706.1015758
   Tosas M, 2007, PROCEEDINGS OF THE NINTH IASTED INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND IMAGING, P81
   Ueda E, 2003, IEEE T IND ELECTRON, V50, P676, DOI 10.1109/TIE.2003.814758
   Ware C., 1990, Computer Graphics, V24, P175, DOI 10.1145/91394.91442
   Winer B. J., 1971, STAT PRINCIPLES EXPT
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
   Zhou HY, 2008, BIOMED SIGNAL PROCES, V3, P1, DOI 10.1016/j.bspc.2007.09.001
NR 91
TC 11
Z9 12
U1 1
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2015
VL 19
IS 1
BP 1
EP 20
DI 10.1007/s10055-014-0255-z
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CB5CS
UT WOS:000349645700001
DA 2024-07-18
ER

PT J
AU Carvalho, FG
   Trevisan, DG
   Raposo, A
AF Carvalho, Felipe G.
   Trevisan, Daniela G.
   Raposo, Alberto
TI Toward the design of transitional interfaces: an exploratory study on a
   semi-immersive hybrid user interface
SO VIRTUAL REALITY
LA English
DT Article
DE Transitional interfaces; Hybrid user interfaces; Continuity properties
AB A task that can be decomposed into subtasks with different technological demands may be a challenge, since it requires multiple interactive environments as well as transitions between them. Some of these transitions may involve changes in hardware devices and interface paradigms at the same time. Some previous works have proposed various setups for hybrid user interfaces, but none of them focused on the design of transition interactions. Our work emphasizes the importance of interaction continuity as a guideline in the design and evaluation of transitional interfaces within a hybrid user interface (HUI). Finally, an exploratory study demonstrates how this design aspect is perceived by users during transitions in an HUI composed by three interactive environments.
C1 [Trevisan, Daniela G.] Univ Fed Fluminense, Comp Inst, Niteroi, RJ, Brazil.
   [Carvalho, Felipe G.] Pontificia Univ Catolica Rio de Janeiro, Tecgraf, Comp Graph Technol Grp, Rio De Janeiro, RJ, Brazil.
   [Raposo, Alberto] Pontificia Univ Catolica Rio de Janeiro, Dept Informat, Rio De Janeiro, Brazil.
C3 Universidade Federal Fluminense; Pontificia Universidade Catolica do Rio
   de Janeiro
RP Trevisan, DG (corresponding author), Univ Fed Fluminense, Comp Inst, Niteroi, RJ, Brazil.
EM kamel@tecgraf.puc-rio.br; daniela@ic.uff.br; abraposo@inf.puc-rio.br
RI Raposo, Alberto B/G-3204-2012; Trevisan, Daniela G/I-4402-2013
OI Trevisan, Daniela/0000-0003-0061-4689; Raposo,
   Alberto/0000-0001-7279-1823
FU Petrobras; National Council for Scientific and Technological Development
   (CNPq); FAPERJ
FX The authors would like to thank all volunteer users who took part in the
   experiments. Thanks also to Petrobras, the National Council for
   Scientific and Technological Development (CNPq), and FAPERJ for the
   financial support of this work.
CR Alencar Marcus F. C., 2011, P ACM S APPL COMP AC, P1237, DOI [10.1145/1982185.1982457, DOI 10.1145/1982185.1982457]
   [Anonymous], 1999, P C HUM FACT COMP SY
   Baumgartner S, 2007, EUROVIS, P99
   Benko H, 2005, P IEEE VIRT REAL ANN, P209
   Billinghurst M, 1999, IWAR 99, P35
   Bornik A, 2006, IEEE S 3D US INT
   Bowman D.A., 2005, 3D User Interfaces: Theory and Practice
   Butz A., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P35, DOI 10.1109/IWAR.1999.803804
   Carvalho F, 2009, VRCAI 2009 8 INT ACM
   Czerwinski M., 2002, ACM C HUMAN FACTORS, P195, DOI DOI 10.1145/503376.503412
   De Souza CS., 2005, The semiotic engineering of human-computer interaction, DOI [10.7551/mitpress/6175.001.0001, DOI 10.7551/MITPRESS/6175.001.0001]
   Demiralp Ç, 2006, IEEE T VIS COMPUT GR, V12, P323, DOI 10.1109/TVCG.2006.42
   Dubois E., 2002, Universal Access in the Information Society, V1, P263, DOI 10.1007/sIO209-002-0024-8
   Feiner S., 1991, UIST Fourth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P9, DOI 10.1145/120782.120783
   Grasset Raphael, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P231, DOI 10.1109/ISMAR.2006.297819
   Grasset R, 2008, ICAT 2008 18 INT C A
   Hall E.T., 1992, The Hidden Dimension
   ISHII H, 1994, COMMUN ACM, V37, P83, DOI 10.1145/179606.179687
   Kiyokawa K, 2000, IEEE MULTIMEDIA, V7, P22, DOI 10.1109/93.839308
   Masso JPM, 2008, THESIS ALBACETE
   Milgram P, 1999, MIXED REALITY, P5
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nakashima Kousuke., 2005, VRST 05, P16, DOI [10.1145/1101616.1101621, DOI 10.1145/1101616.1101621]
   Polys N.F., 2005, Proceedings of ACM Symposium on Virtual Reality Software and Technology (VRST), P46, DOI 10.1145/1101616.1101626
   Prabhat, 2008, IEEE T VIS COMPUT GR, V14, P551, DOI 10.1109/TVCG.2007.70433
   Raja Dheva, 2004, 8 INT IMM PROJ TECHN
   Raposo A, 2009, IEEE COMPUT GRAPH, V29, P91, DOI 10.1109/MCG.2009.118
   Raskar R., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P179, DOI 10.1145/280814.280861
   Raymaekers C, 2005, P INT C EN INT 05
   Rekimoto J., 1995, Eighth Annual Symposium on User Interface Software and Technology. UIST '95. Proceedings of the ACM Symposium on User Interface Software and Technology, P29, DOI 10.1145/215585.215639
   Steed A, 2005, PRESENCE-TELEOP VIRT, V14, P511, DOI 10.1162/105474605774918750
   Tan D. S., 2006, ACM Transactions on Computer-Human Interaction, V13, P71, DOI 10.1145/1143518.1143521
   Trevisan DG, 2004, VIRTUAL REAL J, V8, P83
   Trevisan DG, 2004, 2004 C HUM FACT COMP, P1043
NR 34
TC 7
Z9 8
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2012
VL 16
IS 4
BP 271
EP 288
DI 10.1007/s10055-011-0205-y
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 025YG
UT WOS:000310233000002
DA 2024-07-18
ER

PT J
AU Watanabe, J
   Ando, H
AF Watanabe, Junji
   Ando, Hideyuki
TI Pace-sync shoes: intuitive walking-pace guidance based on cyclic
   vibro-tactile stimulation for the foot
SO VIRTUAL REALITY
LA English
DT Article
DE Walking guidance; Walking pace; Foot stimulation; Vibro-tactile
   stimulation; Sensory-motor synchronization
ID POSTURAL CONTROL; LOCOMOTION
AB We propose a walking guidance method with a sandal-shaped vibration interface and describe two experiments we performed to formulate the design principles of the interface. In the interface, a vibrating motor presents timing information to the foot, and pressure sensors measure walking pace. Our method is a combination of the walking-state monitoring and vibro-tactile feedback to maintain or promote a walking pace. Vibration stimuli with a constant presentation interval are alternately and repeatedly given to the right or left foot of the user according to the measured walking pace, and then the walking pace gradually conforms to the presented interval of the vibration. In the experiments, we specified the effective timing and intervals of the vibration stimuli for efficient inductance of walking pace. The method is applicable for training and coaching in sports and rehabilitation in health care.
C1 [Watanabe, Junji] NTT Corp, Commun Sci Labs, Kanagawa 2430198, Japan.
   [Watanabe, Junji] Japan Soc Promot Sci, Kanagawa 2430198, Japan.
   [Ando, Hideyuki] Osaka Univ, Grad Sch Informat Sci & Technol, Suita, Osaka 5650871, Japan.
C3 Nippon Telegraph & Telephone Corporation; Japan Society for the
   Promotion of Science; Osaka University
RP Watanabe, J (corresponding author), NTT Corp, Commun Sci Labs, 3-1 Morinosato Wakamiya, Kanagawa 2430198, Japan.
EM junji@junji.org
OI ANDO, HIDEYUKI/0000-0002-8405-3120
CR [Anonymous], P IEEE INT C SYST MA
   Bamberg SJM, 2008, IEEE T INF TECHNOL B, V12, P413, DOI 10.1109/TITB.2007.899493
   Bosman S, 2003, LECT NOTES COMPUT SC, V2795, P358
   BUDAKOVA N N, 1972, Neuroscience and Behavioral Physiology, V5, P355, DOI 10.1007/BF01183110
   Dault MC, 2001, GAIT POSTURE, V14, P248, DOI 10.1016/S0966-6362(01)00130-8
   DELCOMYN F, 1980, SCIENCE, V210, P492, DOI 10.1126/science.7423199
   Ertan S, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P164, DOI 10.1109/ISWC.1998.729547
   Frey M., 2007, Proceedings of the 1st International Conference on Tangible and Embedded Interaction, TEI'07, P245, DOI DOI 10.1145/1226969.1227019
   GEURTS ACH, 1991, ARCH PHYS MED REHAB, V72, P1059
   Giphart JE, 2007, PRESENCE-TELEOP VIRT, V16, P399, DOI 10.1162/pres.16.4.399
   GRILLNER S, 1979, EXP BRAIN RES, V34, P241
   *IDEO, 2001, GPS TOES RINGS
   Lindeman R.W., 2005, CHI'05, P271, DOI DOI 10.1145/1054972.1055010
   Lindeman RW., 2006, Virtual Reality, V9, P203, DOI [DOI 10.1007/S10055-005-0010-6, 10.1007/s10055-005-0010-6]
   MIYAKE Y, 1999, P 1999 IEEE INT C SY, P229
   NEMIROVSKY P, 1999, CHI 99 EXTENDED ABST, P266
   Pearson KG, 1995, CURR OPIN NEUROBIOL, V5, P786, DOI 10.1016/0959-4388(95)80107-3
   Philippson M., 1905, Trav. Lab. Physiol. Inst. Solvay, V7, P1
   Razzaque S., 2002, P 8 EUROGRAPHICS WOR, P123
   Rovers A.F., 2006, Virtual Reality, V9, P177, DOI [10.1007/s10055-005-0016-0, DOI 10.1007/S10055-005-0016-0]
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Terrier P, 2003, EUR J APPL PHYSIOL, V90, P554, DOI 10.1007/s00421-003-0906-3
   Trulsson M, 2001, EXP BRAIN RES, V137, P111, DOI 10.1007/s002210000649
   van Erp J., 2003, Proceedings of Eurohaptics 2003, P405
   WERTSCH JJ, 1992, J REHABIL RES DEV, V29, P13, DOI 10.1682/JRRD.1992.01.0013
   YANG U, 2002, P INT C ART REAL TEL, P4
NR 26
TC 13
Z9 14
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2010
VL 14
IS 3
BP 213
EP 219
DI 10.1007/s10055-009-0137-y
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HW
UT WOS:000296279700004
DA 2024-07-18
ER

PT J
AU Zhang, XL
AF Zhang, Xiaolong (Luke)
TI Multiscale traveling: crossing the boundary between space and scale
SO VIRTUAL REALITY
LA English
DT Article
DE Navigation; Multiscale; Virtual environments
ID VIRTUAL ENVIRONMENTS; SPATIAL INFORMATION; REPRESENTATIONS; NAVIGATION;
   KNOWLEDGE; COGNITION; DISTANCE
AB Adding multiscale interaction capabilities to 3D virtual environments may permit work with huge virtual worlds that might otherwise be too large to manage. Multiscale technology has shown potential to support user interactions. This paper reports an experimental study of two multiscale traveling techniques. Our results show that while allowing a flexible control on travel speed and accuracy is beneficial, directly traversing the space-scale could be a challenge for users, probably due to difficulties in perceiving scalable virtual space and executing scaling operations. The results suggest that more research is needed to improve the understanding of the coupling of space and scale in multiscale user interface and to harness the full potentials of multiscale traveling techniques.
C1 Penn State Univ, University Pk, PA 16802 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; Pennsylvania State University -
   University Park
RP Zhang, XL (corresponding author), Penn State Univ, 307D IST Bldg, University Pk, PA 16802 USA.
EM lzhang@ist.psu.edu
RI ZHANG, XIAOLONG/IZQ-4553-2023
OI Zhang, Xiaolong/0000-0002-6828-4930
FU Microsoft Research
FX The author likes to thank George Furnas for his help on this research
   and the anonymous reviewers for their constructive suggestions and
   comments. This research was supported, in part, by Microsoft Research.
CR [Anonymous], P C VIRT REAL SOFTW
   [Anonymous], 1996, ACM Transactions on Computer-Human Interaction, DOI DOI 10.1145/230562.230577
   [Anonymous], 2001, P 2001 S INT 3D GRAP
   [Anonymous], 2006, Proceedings of the 3rd Symposium on Applied Perception in Graphics and Visualization, APGV'06, DOI 10.1145/1140491.1140495
   Bagrow L., 1985, HIST CARTOGRAPHY, V2nd
   Barkowsky T, 1997, LECT NOTES COMPUT SC, V1329, P347, DOI 10.1007/3-540-63623-4_60
   Bederson B. B., 1994, UIST '94. Seventh Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P17, DOI 10.1145/192426.192435
   Bell S, 2002, J ENVIRON PSYCHOL, V22, P9, DOI 10.1006/jevp.2002.0250
   Bier EA, 1986, 1986 P WORKSH INT 3D, P183
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Combs T. T. A., 1999, Digital 99 Libraries. Fourth ACM Conference on Digital Libraries, P130, DOI 10.1145/313238.313286
   Darken RP, 1996, INT J HUM-COMPUT INT, V8, P49, DOI 10.1080/10447319609526140
   Downs R.M., 1973, Image and Environment: Cognitive Mapping and Spatial Behavior
   Durlach N, 2000, PRESENCE-VIRTUAL AUG, V9, P593, DOI 10.1162/105474600300040402
   Elvins T. T., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P21, DOI 10.1145/263407.263504
   EVANS GW, 1980, J EXP PSYCHOL-HUM L, V6, P13, DOI 10.1037/0278-7393.6.1.13
   Furnas GeorgeW., 1995, SIGCHI C HUMAN FACTO, P234
   Ghosh P, 1999, CSTR4028 U MARYLAND
   Gibson J., 1979, The ecological approach to visual perception
   Golledge RG, 1999, WAYFINDING BEHAVIOR, P5
   Guiard Y., 1999, P SIGCHI C HUMAN FAC, P450, DOI [https://doi.org/10.1145/302979.303128, DOI 10.1145/302979.303128]
   Hart R.A., 1973, IMAGE ENV, P226
   HIRTLE SC, 1991, J ENVIRON PSYCHOL, V11, P335, DOI 10.1016/S0272-4944(05)80106-9
   Hornbaek K., 2002, ACM Transactions on Computer-Human Interaction, V9, P362, DOI 10.1145/586081.586086
   Huff M, 2007, LECT NOTES ARTIF INT, V4387, P140
   Interrante V, 2007, P 13 EUR S VIRT ENV, P75
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Jul S., 1998, P 11 ANN ACM S USER, P97, DOI [10.1145/288392.288578., DOI 10.1145/288392.288578]
   Kaufman L., 1974, SIGHT MIND
   Kopper R, 2006, P IEEE VIRT REAL ANN, P175, DOI 10.1109/VR.2006.47
   KOSSLYN SM, 1978, J EXP PSYCHOL HUMAN, V4, P47, DOI 10.1037/0096-1523.4.1.47
   Leigh J, 1996, IEEE COMPUT GRAPH, V16, P47, DOI 10.1109/38.511853
   Leshed G, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1675
   Liben L. S., 2001, SPATIAL SCHEMAS ABST, P44
   Lynch K., 1960, IMAGE CITY
   Mackinlay J. D., 1990, Computer Graphics, V24, P171, DOI 10.1145/97880.97898
   MAPES DP, 1995, PRESENCE-TELEOP VIRT, V4, P403, DOI 10.1162/pres.1995.4.4.403
   MCNAMARA TP, 1989, J EXP PSYCHOL LEARN, V15, P211, DOI 10.1037/0278-7393.15.2.211
   MINE M, 1995, TR95018 UNC CHAP HIL
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Montello D.R., 2001, INT ENCY SOCIAL BEHA, DOI DOI 10.1016/B0-08-043076-7/02492-X
   NIELSON G., 1986, Proc. Symposium on Interactive 3D Graphics, P175
   Paez LB, 1996, P ASIS 96, P58
   Parush A, 2007, LECT NOTES COMPUT SC, V4736, P238
   Passini R., 1984, JournalofEnvironmentalPsychology, V4, P153, DOI DOI 10.1016/S0272-4944(84)80031-6
   Perlin K., 1993, Computer Graphics Proceedings, P57, DOI 10.1145/166117.166125
   Piaget J., 1967, Child's conception of space
   Pierce JS, 2004, P IEEE VIRT REAL ANN, P173, DOI 10.1109/VR.2004.1310071
   Plumlee M. D., 2006, ACM Transactions on Computer-Human Interaction, V13, P179, DOI 10.1145/1165734.1165736
   PRESSON CC, 1989, J EXP PSYCHOL LEARN, V15, P887, DOI 10.1037/0278-7393.15.5.887
   PRESSON CC, 1988, BRIT J DEV PSYCHOL, V6, P378, DOI 10.1111/j.2044-835X.1988.tb01113.x
   RIESER JJ, 1995, J EXP PSYCHOL HUMAN, V21, P480, DOI 10.1037/0096-1523.21.3.480
   Robinett R., 1992, P 1992 S INT 3D GRAP, P189, DOI 10.1145/147156.1472012
   Roskos-Ewoldsen B, 1998, J EXP PSYCHOL LEARN, V24, P215, DOI 10.1037/0278-7393.24.1.215
   Ruddle RA, 1997, J EXP PSYCHOL-APPL, V3, P143, DOI 10.1037/1076-898X.3.2.143
   Rump B, 2007, LECT NOTES ARTIF INT, V4387, P249
   STEVENS A, 1978, COGNITIVE PSYCHOL, V10, P422, DOI 10.1016/0010-0285(78)90006-3
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Tan D. S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P418, DOI 10.1145/365024.365307
   Thorndyke, 1983, SPATIAL ORIENTATION, P195
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Tversky B., 1993, Spatial Information Theory. A Theoretical Basis for GIS. European Conference, COSIT '93 Proceedings, P14
   Vinson N.G., 1999, CHI 99, P278, DOI DOI 10.1145/302979.303062
   Ware C., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P127, DOI 10.1145/253284.253319
   Wernert E.A., 1997, SCI VISUALIZATION C, P95
   Wilson PN, 1997, HUM FACTORS, V39, P526, DOI 10.1518/001872097778667988
   Witmer BG, 1996, INT J HUM-COMPUT ST, V45, P413, DOI 10.1006/ijhc.1996.0060
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P144, DOI 10.1162/105474698565640
   ZHANG X., 2002, Proceedings of the 4th International Conference on Collaborative Virtual Environments, p, P31, DOI [10.1145/571878.5718841,3, DOI 10.1145/571878.5718841,3]
   Zhang X, 2008, INT J HUM-COMPUT ST, V66, P243, DOI 10.1016/j.ijhcs.2007.09.004
   Zhang XL, 2005, PRESENCE-TELEOP VIRT, V14, P31, DOI 10.1162/1054746053890288
NR 71
TC 13
Z9 15
U1 0
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2009
VL 13
IS 2
BP 101
EP 115
DI 10.1007/s10055-009-0114-5
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XD
UT WOS:000208104200003
DA 2024-07-18
ER

PT J
AU Sánchez-Brizuela, G
   Cisnal, A
   de la Fuente-López, E
   Fraile, JC
   Pérez-Turiel, J
AF Sanchez-Brizuela, Guillermo
   Cisnal, Ana
   de la Fuente-Lopez, Eusebio
   Fraile, Juan-Carlos
   Perez-Turiel, Javier
TI Lightweight real-time hand segmentation leveraging MediaPipe landmark
   detection
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Hand segmentation; MediaPipe; Online processing;
   Semantic segmentation
ID GESTURE RECOGNITION
AB Real-time hand segmentation is a key process in applications that require human-computer interaction, such as gesture recognition or augmented reality systems. However, the infinite shapes and orientations that hands can adopt, their variability in skin pigmentation and the self-occlusions that continuously appear in images make hand segmentation a truly complex problem, especially with uncontrolled lighting conditions and backgrounds. The development of robust, real-time hand segmentation algorithms is essential to achieve immersive augmented reality and mixed reality experiences by correctly interpreting collisions and occlusions. In this paper, we present a simple but powerful algorithm based on the MediaPipe Hands solution, a highly optimized neural network. The algorithm processes the landmarks provided by MediaPipe using morphological and logical operators to obtain the masks that allow dynamic updating of the skin color model. Different experiments were carried out comparing the influence of the color space on skin segmentation, with the CIELab color space chosen as the best option. An average intersection over union of 0.869 was achieved on the demanding Ego2Hands dataset running at 90 frames per second on a conventional computer without any hardware acceleration. Finally, the proposed segmentation procedure was implemented in an augmented reality application to add hand occlusion for improved user immersion. An open-source implementation of the algorithm is publicly available at https://github.com/itap-robotica-medica/lightweight-hand-segmentation.
C1 [Sanchez-Brizuela, Guillermo; Cisnal, Ana; de la Fuente-Lopez, Eusebio; Fraile, Juan-Carlos; Perez-Turiel, Javier] Univ Valladolid, ITAP Inst Tecnol Avanzadas Prod, Paseo Cauce 59, Valladolid 47011, Spain.
C3 Universidad de Valladolid
RP Cisnal, A (corresponding author), Univ Valladolid, ITAP Inst Tecnol Avanzadas Prod, Paseo Cauce 59, Valladolid 47011, Spain.
EM guillermo.sanchez.brizuela@uva.es; ana.cisnal@uva.es; efuente@uva.es;
   jcfraile@eii.uva.es; jpturiel@uva.es
RI ; de la Fuente Lopez, Eusebio/F-7679-2016
OI Cisnal, Ana/0000-0002-1556-7179; de la Fuente Lopez,
   Eusebio/0000-0001-5837-3510
FU CRUE-CSIC; Springer Nature; Ministry of Science and Innovation of Spain
   [RTC2019-007350-1]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. The research leading to these results received funding
   from the Ministry of Science and Innovation of Spain under Grant
   Agreement No. RTC2019-007350-1.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arsalan M, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112922
   Bambach S, 2015, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2015.226
   Baraldi L, 2015, IEEE SENS J, V15, P2705, DOI 10.1109/JSEN.2015.2411994
   Chakraborty BK, 2018, IET COMPUT VIS, V12, P3, DOI 10.1049/iet-cvi.2017.0052
   Cheng J, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/9346863
   Glauser O., 2019, ACM T GRAPHIC, V10, P3322957
   Kang B, 2017, IEEE GLOB CONF SIG, P259, DOI 10.1109/GlobalSIP.2017.8308644
   Kaur A., 2012, IJAIS, V3, P30
   Khan AU, 2018, PROC CVPR IEEE, P4710, DOI 10.1109/CVPR.2018.00495
   Li C, 2013, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2013.458
   Lim Guan Ming, 2020, International Conference on Neural Information Processing, P450
   Lin F, 2020, ARXIV
   Liu XW, 2020, IEEE T PATTERN ANAL, V42, P1191, DOI 10.1109/TPAMI.2019.2892416
   Ly BCK, 2020, J INVEST DERMATOL, V140, P3, DOI 10.1016/j.jid.2019.11.003
   Minjie Cai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14380, DOI 10.1109/CVPR42600.2020.01440
   Montenegro J, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE), P313, DOI 10.1109/ICEEE.2013.6676048
   Qingrui Zhang, 2018, IAENG International Journal of Computer Science, V45, P435
   Seeber M, 2021, INT CONF 3D VISION, P22, DOI 10.1109/3DV53792.2021.00013
   Shilkrot R, 2019, P BRIT MACH VIS C BM, P1, DOI [10.5244/C.33.171, DOI 10.5244/C.33.171]
   Shin J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175856
   Thwe PM., 2019, INT J IMAGE GRAPH, V11, P25, DOI [10.5815/ijigsp.2019.09.03, DOI 10.5815/IJIGSP.2019.09.03]
   Tsai TH, 2022, NEUROCOMPUTING, V495, P1, DOI 10.1016/j.neucom.2022.04.079
   Wang W, 2019, IEEE I CONF COMP VIS, P2142, DOI 10.1109/ICCV.2019.00223
   Xiao FY, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104089
   Yu X, 2022, DIGIT SIGNAL PROCESS, V123, DOI 10.1016/j.dsp.2022.103442
   Yu X, 2021, INT J PRES VES PIP, V189, DOI 10.1016/j.ijpvp.2020.104249
   Zhang F., 2020, ARXIV
   Zhao Y, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0262-1
   Zhu XL, 2015, COMPUT VIS IMAGE UND, V141, P95, DOI 10.1016/j.cviu.2015.07.008
NR 30
TC 2
Z9 2
U1 11
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3125
EP 3132
DI 10.1007/s10055-023-00858-0
EA SEP 2023
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001058961300001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Marichal, S
   Ezcurdia, I
   Morales, R
   Ortiz, A
   Marzo, A
   Ardaiz, O
AF Marichal, Sebastian
   Ezcurdia, Inigo
   Morales, Rafael
   Ortiz, Amalia
   Marzo, Asier
   Ardaiz, Oscar
TI Hand-as-a-prop: using the hand as a haptic proxy for manipulation in
   virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Manipulation; Human actuation; Self-haptics;
   Controller-free interaction
AB Haptic feedback can be almost as important as visual information in virtual reality environments. On the one hand, in Active Haptic Feedback, specialized devices such as vibrotactile gloves are employed; however, these solutions can be expensive, vendor-specific or cumbersome to setup. On the other hand, Passive Haptic Feedback approaches use inexpensive objects as proxies for the virtual entities; but mapping virtual objects to real props is not scalable nor flexible. We propose the Hand-as-a-Prop technique, which consists in using human hands as object props. We implemented two modalities: Self, where the user's non-dominant hand act as the virtual object while the dominant hand grabs, translates and releases it; and External, where the hand of another person is used. Hand-as-a-Prop can represent multiple shapes with a single prop and does not require extra hardware. We performed an evaluation comparing both Self and External Hand-as-a-Prop with traditional Object Props in terms of user experience (goodness, ease, realism, fatigue, and preference) and performance (task completion time and translation time). Results showed that Hand-as-a-Prop was rated as neutral tending to positive, and in some cases, the performance was similar to Object Props. Users preferred Self Hand-as-a-Prop over External Hand-as-a-Prop and also obtained better results.
C1 [Marichal, Sebastian; Ezcurdia, Inigo; Ortiz, Amalia; Marzo, Asier; Ardaiz, Oscar] Univ Publ Navarra, Inst Smart Cities, Pamplona, Spain.
   [Morales, Rafael] Ultraleap Ltd, Bristol, England.
C3 Universidad Publica de Navarra
RP Ardaiz, O (corresponding author), Univ Publ Navarra, Inst Smart Cities, Pamplona, Spain.
EM sebastian.marichal@unavarra.es; inigofermin.ezcurdia@unavarra.es;
   rafael.morales@ultraleap.com; amalia.ortiz@unavarra.es;
   asier.marzo@unavarra.es; oscar.ardaiz@unavarra.es
OI Ortiz, Amalia/0000-0002-6446-6024
FU Universidad Publica de Navarra; Public University of Navarra
   [OTRI-2020901-135]; EU [101017746]
FX Open Access funding provided by Universidad Publica de Navarra.
   Sebastian Marichalar was funded by Public University of Navarra postdoc
   contract OTRI-2020-901-135. This research was partially funded by the EU
   Horizon 2020 research and innovation programme under grant agreement No
   101017746.
CR Abtahi P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173724
   Aguerreche L, 2010, P 17 ACM S VIRT REAL, P227, DOI [10.1145/1889863.1889913, DOI 10.1145/1889863.1889913]
   Araujo B, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P218, DOI 10.1145/2839462.2839484
   Arif Ahmed Sabbir., 2021, Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice, V1st, P59, DOI DOI 10.1145/3447404.3447410
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Ban Y, 2015, ACM SIGGRAPH 2015 EM, V1, DOI [10.1145/2782782.2792498, DOI 10.1145/2782782.2792498]
   Bergström J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445193
   Bovet S, 2018, IEEE T VIS COMPUT GR, V24, P1428, DOI 10.1109/TVCG.2018.2794658
   Burns E, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P295
   Cao P, 1993, RENT BODY
   Cheng LP, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173663
   Cheng LP, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P797, DOI 10.1145/3126594.3126667
   Cheng LP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3718, DOI 10.1145/3025453.3025753
   Cheng LP, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P417
   Cheng LP, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3463, DOI 10.1145/2556288.2557101
   Choi I, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P986, DOI 10.1109/IROS.2016.7759169
   Cohen J., 1988, STAT POWER ANAL BEHA
   Colman A. M., 2015, A Dictionary of Psychology, V4th, DOI DOI 10.1093/ACREF/9780199657681.001.0001/ACREF-9780199657681-E-3750?RSKEY=BO9UMJRESULT=3954
   Fang Cathy Mengying, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1109, DOI 10.1145/3472749.3474810
   Gibson JJ, 1933, J EXP PSYCHOL, V16, P1, DOI 10.1037/h0074626
   Grotowski Jerzy., 1967, TULANE DRAMA REV, V11, P60, DOI DOI 10.2307/1125118
   Hecht D, 2009, EXP BRAIN RES, V193, P307, DOI 10.1007/s00221-008-1626-z
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Hoffman HG, 1998, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VRAIS.1998.658423
   Hoppe M, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P7, DOI 10.1145/3282894.3282898
   Insko B., 2001, THESIS U N CAROLINA
   Knierim P, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P329, DOI 10.1145/3173225.3173273
   Knierim Pascal, 2017, P 2017 CHI C HUM FAC, P433, DOI DOI 10.1145/3027063.3050426
   Kohli L., 2005, Proceedings of Graphics Interface, P1, DOI DOI 10.5555/1089508.1089510
   Kohli L, 2012, 3D US INT 3DUI 2012, P105, DOI DOI 10.1109/3DUI.2012.6184193
   Kohli L, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P79, DOI 10.1109/3DUI.2013.6550201
   Kyriakou Panayiotis, 2019, Digital Applications in Archaeology and Cultural Heritage, V12, DOI 10.1016/j.daach.2018.e00088
   MacKenzie I.S., 2013, Human-Computer Interaction, P157, DOI [10.1016/B978-0-12-405865-1.00005-4, DOI 10.1016/B978-0-12-405865-1.00005-4]
   Massie T. H., 1994, P S HAPT INT VIRT EN, P295
   McClelland JC, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P82, DOI 10.1145/3131277.3132179
   MCNEELY WA, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P336, DOI 10.1109/VRAIS.1993.380761
   Mercado VR, 2021, IEEE T HAPTICS, V14, P449, DOI 10.1109/TOH.2021.3061150
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Taylor J.L., 2009, ENCY NEUROSCIENCE, P1143, DOI DOI 10.1016/B978-008045046-9.01907-0
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
   Zhao YW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174118
NR 43
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 2911
EP 2925
DI 10.1007/s10055-023-00846-4
EA AUG 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001052048800001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Zhao, HF
   Karlsson, P
   Chiu, D
   Sun, CR
   Kavehei, O
   McEwan, A
AF Zhao, Haifeng
   Karlsson, Petra
   Chiu, Darryl
   Sun, Carter
   Kavehei, Omid
   McEwan, Alistair
TI Wearable augmentative and alternative communication (wAAC): a novel
   solution for people with complex communication needs
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed reality (MR); Eye-Gaze technology (EGT); Brain-computer interfaces
   (BCI); Electroencephalograph (EEG); Cerebral palsy (CP); Complex
   communication needs (CCN)
ID BRAIN-COMPUTER-INTERFACE; CEREBRAL-PALSY; REACTION-TIME; AUTISM; AAC;
   CHILDREN; ADULTS; CLASSIFICATION; TECHNOLOGIES; ADOLESCENTS
AB Communication is a vital skill of a human's life. People with different types of disabilities may have Complex Communication Needs and may need a wearable device to help them to communicate. Augmentative and Alternative Communication (AAC) is a term which refers to the methods of facilitating or replacing people's communication abilities. Brain-computer interfaces (BCI) and Eye-Gaze Technology (EGT) are two widely used access technologies in AAC devices. However, there are only a few studies that have investigated the utilisation of these technologies in a Virtual Reality (VR) or Augmented Reality (AR) environment. VR and AR are both modern technologies which provide immersive environments. In addition, the Mixed Reality (MR) environment combines virtual reality with real life and may offer extra benefits such as better immersion, better interaction, and more information. This paper proposed an MR-based wearable AAC device and compared the usability and acceptability between its Eye-Gaze (EG) and BCI interaction options. Eight neurotypical participants and two participants with cerebral palsy participated. The result showed high usability (accuracy = 93.30%, the information transfer rate was 8.55 selections per minutes) and acceptability (QUEST 2.0 = 4.30, NASA-TLX = 2.14) in the EG session. In contrast, the usability of the BCI system in the current design was questionable. This novel interaction method using Electroencephalogram signals is not sufficiently exploited at the moment, and more research is suggested in the future.
C1 [Zhao, Haifeng; Karlsson, Petra; Chiu, Darryl; Sun, Carter; Kavehei, Omid; McEwan, Alistair] Univ Sydney, Sydney, NSW 2006, Australia.
   [Karlsson, Petra; Chiu, Darryl; McEwan, Alistair] Cerebral Palsy Alliance, Sydney, NSW 2100, Australia.
C3 University of Sydney; Cerebral Palsy Alliance - Australia
RP Zhao, HF; McEwan, A (corresponding author), Univ Sydney, Sydney, NSW 2006, Australia.; McEwan, A (corresponding author), Cerebral Palsy Alliance, Sydney, NSW 2100, Australia.
EM haifeng.zhao@sydney.edu.au; pkarlsson@cerebralpalsy.org.au;
   darryl.chiu@cerebralpalsy.org.au; jian.sun@sydney.edu.au;
   omid.kavehei@sydney.edu.au; alistair.mcewan@sydney.edu.au
RI Kavehei, Omid/C-1294-2012; zhao, haifeng/JNX-7170-2023; McEwan, Alistair
   L/C-4792-2014
OI Kavehei, Omid/0000-0002-2753-5553; Sun, Carter/0000-0002-0800-3906;
   Zhao, Haifeng/0000-0003-4234-5894
CR Allison BZ, 2007, EXPERT REV MED DEVIC, V4, P463, DOI 10.1586/17434440.4.4.463
   Amaral C, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00477
   Amaral CP, 2017, J NEUROSCI METH, V290, P105, DOI 10.1016/j.jneumeth.2017.07.029
   BASAR E, 1984, INT J NEUROSCI, V24, P1, DOI 10.3109/00207458409079530
   Boster JB., 2017, Perspectives of the ASHA Special Interest Groups, V2, P40, DOI [DOI 10.1044/PERSP2.SIG12.40, 10.1044/persp2. SIG12.40]
   Bulárka S, 2016, 2016 12TH IEEE INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND TELECOMMUNICATIONS (ISETC'16), P219, DOI 10.1109/ISETC.2016.7781096
   Carmigniani J, 2011, HANDBOOK OF AUGMENTED REALITY, P3, DOI 10.1007/978-1-4614-0064-6_1
   Clarke M., 2012, Paediatr Child Health, V22, P367, DOI [10.1016/j.paed.2012.03.002, DOI 10.1016/J.PAED.2012.03.002]
   Cognixion Inc., 2022, COGN
   Cooper L, 2009, AUGMENT ALTERN COMM, V25, P154, DOI 10.1080/07434610903036785
   Demers L., 2000, Quebec User Evaluation of Satisfaction with Assistive Technology QUEST 2.0
   DiStefano C, 2016, AUTISM RES, V9, P1093, DOI 10.1002/aur.1594
   Antao JYFD, 2020, CYBERPSYCH BEH SOC N, V23, P16, DOI 10.1089/cyber.2019.0103
   Galea C, 2019, DEV MED CHILD NEUROL, V61, P186, DOI 10.1111/dmcn.14011
   GBD 2015 Disease and Injury Incidence and Prevalence Collaborators, 2016, Lancet, V388, P1545, DOI 10.1016/S0140-6736(16)31678-6
   Hart SG, 1986, NASA TASK LOAD INDEX
   Hashimoto Y, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-117
   Higginbotham DJ, 2007, AUGMENT ALTERN COMM, V23, P243, DOI 10.1080/07434610701571058
   Holyfield C, 2017, AUGMENT ALTERN COMM, V33, P201, DOI 10.1080/07434618.2017.1370495
   Käthner I, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00207
   Karlsson Petra, 2018, Dev Neurorehabil, V21, P497, DOI 10.1080/17518423.2017.1362057
   Lai ML, 2013, EDUC RES REV-NETH, V10, P90, DOI 10.1016/j.edurev.2013.10.001
   Lariviere, 2015, INT HDB OCCUPATIONAL, P339, DOI DOI 10.1007/978-3-319-08141-0_23
   Lawhern V. J., 2018, Journal of neural engineering, V15, DOI DOI 10.1088/1741-2552/AACE8C
   Liberatore MJ, 2021, VIRTUAL REAL-LONDON, V25, P773, DOI 10.1007/s10055-020-00492-0
   Light J., 1989, Augmentative and Alternative Communication, V5, P137, DOI [DOI 10.1080/07434618912331275126, https://doi.org/10.1080/07434618912331275126]
   Light J, 2007, AUGMENT ALTERN COMM, V23, P204, DOI 10.1080/07434610701553635
   Light J, 2012, ASSIST TECHNOL, V24, P34, DOI 10.1080/10400435.2011.648717
   Lotte F, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aab2f2
   Lungu AJ, 2021, EXPERT REV MED DEVIC, V18, P47, DOI 10.1080/17434440.2021.1860750
   Mcnaughton D, 2007, AUGMENT ALTERN COMM, V23, P217, DOI 10.1080/07434610701573856
   Mele ML, 2012, DISABIL REHABIL-ASSI, V7, P261, DOI 10.3109/17483107.2011.635326
   Mitchell S, 2006, J DEV BEHAV PEDIATR, V27, pS69, DOI 10.1097/00004703-200604002-00004
   Murray J., 2009, Paediatr. Child Health, V19, P464, DOI DOI 10.1016/J.PAED.2009.05.003
   Nielsen J., 1994, Usability engineering
   Nordberg A, 2013, ACTA PAEDIATR, V102, P161, DOI 10.1111/apa.12076
   Ortner R, 2012, P IEEE RAS-EMBS INT, P219, DOI 10.1109/BioRob.2012.6290800
   Pennington L., 2008, Paediatrics and Child Health, V18, P405, DOI DOI 10.1016/J.PAED.2008.05.013
   Ramadan RA, 2017, NEUROCOMPUTING, V223, P26, DOI 10.1016/j.neucom.2016.10.024
   Rezeika A, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8040057
   Römer K, 2005, WILEY SER PARA DIST, P199, DOI 10.1002/047174414X.ch7
   Rokhsaritalemi S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020636
   Roy Y, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab260c
   Scherer R, 2015, ANN PHYS REHABIL MED, V58, P14, DOI 10.1016/j.rehab.2014.11.005
   Sherman WilliamR., 2003, UNDERSTANDING VIRTUA
   Spencer KM, 1999, PSYCHOPHYSIOLOGY, V36, P220, DOI 10.1017/S0048577299971615
   Tang YM, 2020, VIRTUAL REAL-LONDON, V24, P797, DOI 10.1007/s10055-020-00427-9
   Weaver CM, 2005, NORTHEAST BIOENGIN C, P26
   Wolk K, 2019, CYBERPSYCH BEH SOC N, V22, P151, DOI 10.1089/cyber.2018.0035
   Wu Q, 2019, INT J NEURAL SYST, V29, DOI 10.1142/S0129065719500023
   Xiong JH, 2020, OSA CONTINUUM, V3, P2730, DOI 10.1364/OSAC.400900
   Yagi Y, 1999, EUR J APPL PHYSIOL O, V80, P402, DOI 10.1007/s004210050611
   Yu S, 2019, MEDITERRANEAN C MEDI, P1861
   Zhao H, 2021, IEEE SENSORS, P1
   Zhao HF, 2020, HEALTH TECHNOL-GER, V10, P979, DOI 10.1007/s12553-020-00458-x
NR 55
TC 0
Z9 0
U1 10
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2441
EP 2459
DI 10.1007/s10055-023-00818-8
EA JUN 2023
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001008553500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Cha, HS
   Im, CH
AF Cha, Ho-Seung
   Im, Chang-Hwan
TI Improvement of robustness against electrode shift for facial
   electromyogram-based facial expression recognition using domain
   adaptation in VR-based metaverse applications
SO VIRTUAL REALITY
LA English
DT Article
DE Covariate shift adaptation; Electromyogram; Electrode shift; Facial
   expression recognition; Human-machine interface; Virtual reality
ID VIRTUAL-REALITY; CLASSIFICATION; INTERFACES; SYSTEMS
AB Recognition of users' facial expressions and reflecting them on the face of the user's virtual avatar is a key technology for realizing immersive virtual reality (VR)-based metaverse applications. As a method to realize this technology, a facial electromyogram (fEMG)-based facial expression recognition (FER) system, with the fEMG electrodes being attached on the pad of a VR headset, has recently been proposed. However, the performance of such FER systems has severely deteriorated when the locations of fEMG electrodes change by the re-wearing of the VR headset, requiring long and tedious calibration sessions every time the user wears the VR headset. In this study, we developed an fEMG-based FER system that is robust against electrode shifts by employing new signal processing techniques: covariate shift adaptation techniques in feature and classifier domains. To verify the feasibility of the proposed method, fEMG data were recorded while participants were making 11 facial expressions repeatedly in four sessions, between which they detached and reattached the fEMG electrodes on their faces. Our experiments showed that classification accuracy dropped from 88 to 79% by the change of the electrode locations when the proposed method was not applied, whereas the accuracy was significantly improved up to 86% when the proposed covariate shift adaptation method was employed. It is expected that the proposed method would contribute to enhancing the practicality of the fEMG-based FER, promoting the practical application of the fEMG-based FER to VR-based metaverse applications.
C1 [Cha, Ho-Seung; Im, Chang-Hwan] Hanyang Univ, Dept Biomed Engn, 222 Wangsimni Ro, Seoul 04763, South Korea.
C3 Hanyang University
RP Im, CH (corresponding author), Hanyang Univ, Dept Biomed Engn, 222 Wangsimni Ro, Seoul 04763, South Korea.
EM hoseungcha@gmail.com; ich@hanyang.ac.kr
RI Im, Chang-Hwan/ABB-4391-2021
OI Cha, Ho-Seung/0000-0002-9492-2318
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government (MIST) [2017-0-00432, 2020-0-01373]
FX This work was supported by the Institute of Information & communications
   Technology Planning & Evaluation (IITP) grants funded by the Korea
   government (MIST) (Nos. 2017-0-00432 & 2020-0-01373).
CR Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Barachant A, 2013, NEUROCOMPUTING, V112, P172, DOI 10.1016/j.neucom.2012.12.039
   Barachant A, 2010, LECT NOTES COMPUT SC, V6365, P629, DOI 10.1007/978-3-642-15995-4_78
   Bouveyron C, 2012, NEUROCOMPUTING, V90, P12, DOI 10.1016/j.neucom.2011.11.027
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Cha HS, 2022, VIRTUAL REAL-LONDON, V26, P385, DOI 10.1007/s10055-021-00575-6
   Cha HS, 2020, IEEE ACCESS, V8, P62065, DOI 10.1109/ACCESS.2020.2983608
   Chen YM, 2015, NEUROCOMPUTING, V168, P871, DOI 10.1016/j.neucom.2015.05.037
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Driscoll WC, 1996, COMPUT IND ENG, V31, P265, DOI 10.1016/0360-8352(96)00127-1
   Ekman P., 2012, What the Face Reveals: Basic and Applied Studies of Spontaneous Epression Using the Facial Action Coding System (FACS), DOI [DOI 10.1093/ACPROF:OSO/9780195179644.001.0001, 10.1093/acprof:oso/9780195179644.001.0001]
   Forstner W, 2003, Geodesy-the Challenge of the 3rd Millennium, P299, DOI [10.1007/978-3-662-05296-9_31, DOI 10.1007/978-3-662-05296-9_31]
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Guevara JE., 2017, IEEE T NEUR SYS REH, V24, P27, DOI [10.1002/9781119090670.ch2, DOI 10.1002/9781119090670.CH2]
   Hakonen M, 2015, BIOMED SIGNAL PROCES, V18, P334, DOI 10.1016/j.bspc.2015.02.009
   Hamedi Mahyar, 2011, Journal of Computer Sciences, V7, P1407, DOI 10.3844/jcssp.2011.1407.1415
   Hamedi M, 2018, IEEE T AFFECT COMPUT, V9, P102, DOI 10.1109/TAFFC.2016.2569098
   Hargrove L, 2008, BIOMED SIGNAL PROCES, V3, P175, DOI 10.1016/j.bspc.2007.11.005
   Hickson S, 2019, IEEE WINT CONF APPL, P1626, DOI 10.1109/WACV.2019.00178
   Hiraoka K, 2001, IEICE T FUND ELECTR, VE84A, P1431
   Htut K-M, 2002, P IEEK C 2008 2011
   Kumar S, 2019, INT WINT WORKSH BR, P19, DOI 10.1109/iww-bci.2019.8737349
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Lee J, 2020, MULTIMED TOOLS APPL, V79, P979, DOI 10.1007/s11042-019-08220-w
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Li L, 2017, AM J TRANSL RES, V9, P3867
   Lou JW, 2020, IEEE T MULTIMEDIA, V22, P730, DOI 10.1109/TMM.2019.2933338
   Ma MH, 2011, STUD COMPUT INTELL, V337, P169
   Mavridou I, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P152, DOI 10.1145/3131277.3134366
   Mavridou I, 2017, P IEEE VIRT REAL ANN, P441, DOI 10.1109/VR.2017.7892369
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Morerio P., 2017, ARXIV
   MORRISON DG, 1969, J MARKETING RES, V6, P156, DOI 10.2307/3149666
   Olszewski K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980252
   Oskoei MA, 2007, BIOMED SIGNAL PROCES, V2, P275, DOI 10.1016/j.bspc.2007.07.009
   Ostertagova Eva, 2014, Applied Mechanics and Materials, V611, P115, DOI 10.4028/www.scientific.net/AMM.611.115
   Psotka J, 1995, INSTR SCI, V23, P405, DOI 10.1007/BF00896880
   Sato W, 2007, COGNITION, V104, P1, DOI 10.1016/j.cognition.2006.05.001
   Saxena V. V., 2014, P IND HCI 2014 C HUM, P86, DOI [10.1145/2676702.2676708, DOI 10.1145/2676702.2676708]
   Sugiyama M, 2007, J MACH LEARN RES, V8, P985
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182644
   Vidaurre C, 2011, IEEE T BIO-MED ENG, V58, P587, DOI 10.1109/TBME.2010.2093133
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Yger F, 2017, IEEE T NEUR SYS REH, V25, P1753, DOI 10.1109/TNSRE.2016.2627016
NR 45
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1685
EP 1696
DI 10.1007/s10055-023-00761-8
EA FEB 2023
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000932543100001
DA 2024-07-18
ER

PT J
AU Feng, S
   He, XJ
   He, WP
   Billinghurst, M
AF Feng, Shuo
   He, Xinjing
   He, Weiping
   Billinghurst, Mark
TI Can you hear it? Stereo sound-assisted guidance in augmented reality
   assembly
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Stereo sound; Assembly guidance; Multichannel
   human-computer interaction
ID NOISE ANNOYANCE; MUSIC; MOOD; EXPOSURE
AB Most augmented reality (AR) assembly guidance systems only utilize visual information. Regarding the sound, the human binaural effect helps users quickly identify the general direction of sound sources. At the same time, pleasant sounds can give people a sense of pleasure and relaxation. However, the effect on workers is still unknown when stereo sound and visual information are used together for assembly guidance. To assess the combination of sound and vision in AR assembly guidance, we constructed a stereo sound-assisted guidance system (SAG) based on AR. In our SAG system, we used the tone of a soft instrument called the Chinese lute as the sound source. To determine if SAG has an impact on assembly efficiency and user experience, we conducted a usability test to compare SAG with visual information alone. Results showed that the SAG system significantly improves the efficiency of assembly guidance. Moreover, simultaneous visual and auditory information processing does not increase user workload or learning difficulty. Additionally, in a noisy environment, pleasant sounds help to reduce mental strain.
C1 [Feng, Shuo; He, Xinjing; He, Weiping; Billinghurst, Mark] Northwestern Polytech Univ, Sch Mech Engn, Cyber Phys Interact Lab, Xian, Shaanxi, Peoples R China.
   [Billinghurst, Mark] Univ South Australia, Empath Comp Lab, Adelaide, SA, Australia.
C3 Northwestern Polytechnical University; University of South Australia
RP Feng, S; He, WP (corresponding author), Northwestern Polytech Univ, Sch Mech Engn, Cyber Phys Interact Lab, Xian, Shaanxi, Peoples R China.
EM fengshuo9707@gmail.com; weiping@nwpu.edu.cn
RI Billinghurst, Mark/AAJ-4236-2020
OI Billinghurst, Mark/0000-0003-4172-6759; Feng, Shuo/0000-0002-1414-6401
FU National Key R&D Program of China [2019YFB1703800]
FX ! This work is partly supported by the National Key R&D Program of China
   (Grant No. 2019YFB1703800).
CR [Anonymous], Vuforia Engine
   [Anonymous], SOUND RETRIEVAL SYST
   Aouam D., 2018, 2018 3rd International Conference on Pattern Analysis and Intelligent Systems, P1, DOI DOI 10.1109/PAIS.2018.8598516
   Arbeláez JC, 2019, INT J INTERACT DES M, V13, P673, DOI 10.1007/s12008-019-00532-3
   Berger CC, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00021
   BERTELSON P, 1981, PERCEPT PSYCHOPHYS, V29, P578, DOI 10.3758/BF03207374
   Bode M, 2019, THESIS U TWENTE
   BRADLEY JV, 1958, J AM STAT ASSOC, V53, P525, DOI 10.2307/2281872
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Bruscia K.E., 1998, DEFINING MUSIC THERA
   Caudell T. P., 1992, P HAW INT C SYST SCI, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   Chen ZR., 2018, P CAADRIA, V2018, P349
   COLAVITA FB, 1974, PERCEPT PSYCHOPHYS, V16, P409, DOI 10.3758/BF03203962
   Danielsson O, 2018, PROC CIRP, V72, P45, DOI 10.1016/j.procir.2018.03.153
   Devlin A, 2003, ENVIRON BEHAV, V35, P665, DOI 10.1177/0013916503255102
   DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067
   Di GQ, 2011, ACTA ACUST UNITED AC, V97, P1034, DOI 10.3813/AAA.918483
   Dini G, 2015, PROC CIRP, V38, P14, DOI 10.1016/j.procir.2015.07.044
   EICH E, 1995, PSYCHOL SCI, V6, P67, DOI 10.1111/j.1467-9280.1995.tb00309.x
   Guski R, 1999, J SOUND VIB, V223, P513, DOI 10.1006/jsvi.1998.2173
   Guski R, 1997, ACUSTICA, V83, P765
   Hamidia M, 2015, 2015 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING (ICEE), P387
   HART S G, 1988, P139
   Heinrich F, 2020, 2020 IEEE INT S MIXE
   Hirose S, 2017, ASIAPAC SIGN INFO PR, P464, DOI 10.1109/APSIPA.2017.8282076
   Huang YF, 2008, APPL ACOUST, V69, P1205, DOI 10.1016/j.apacoust.2007.10.006
   Jakovjevic B, 2009, ENVIRON INT, V35, P552, DOI 10.1016/j.envint.2008.10.001
   Lam KC, 2008, ACTA ACUST UNITED AC, V94, P553, DOI 10.3813/AAA.918064
   Lang M, 2016, COGNITIVE SCI, V40, P1797, DOI 10.1111/cogs.12302
   Lehtinen V, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P445
   Lukas S, 2010, PSYCHOL RES-PSYCH FO, V74, P255, DOI 10.1007/s00426-009-0246-y
   McCraty R, 1998, ALTERN THER HEALTH M, V4, P75
   Nishihara A, 2015, 2015 SAI INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P400, DOI 10.1109/IntelliSys.2015.7361172
   Niven K, 2015, J APPL SOC PSYCHOL, V45, P132, DOI 10.1111/jasp.12282
   Ologe FE, 2008, J LARYNGOL OTOL, V122, P786, DOI 10.1017/S0022215107000242
   Ong SK, 2007, CIRP ANN-MANUF TECHN, V56, P49, DOI 10.1016/j.cirp.2007.05.014
   PICK HL, 1969, PERCEPT PSYCHOPHYS, V6, P203, DOI 10.3758/BF03207017
   PIGNATIELLO MF, 1986, J ABNORM PSYCHOL, V95, P295, DOI 10.1037/0021-843X.95.3.295
   POSNER MI, 1976, PSYCHOL REV, V83, P157, DOI 10.1037/0033-295X.83.2.157
   Ratcliffe E, 2013, J ENVIRON PSYCHOL, V36, P221, DOI 10.1016/j.jenvp.2013.08.004
   Rauscher FH, 1998, NEUROL RES, V20, P427
   Rey D., 2011, Wilcoxon-Signed-Rank Test, P1658, DOI [DOI 10.1007/978-3-642-04898-2616, 10.1007/978-3-642-04898-2616]
   Schmidt LA, 2001, COGNITION EMOTION, V15, P487, DOI 10.1080/0269993004200187
   Scurati GW, 2018, COMPUT IND, V98, P68, DOI 10.1016/j.compind.2018.02.001
   Serge SR, 2017, LECT NOTES COMPUT SC, V10280, P556, DOI 10.1007/978-3-319-57987-0_45
   Sheldon A, 2019, 24 CAADRIA C
   Sloboda J, 1999, PSYCHOLOGIST, V12, P450
   Sun F, 2021, 12 INT C GRAPHICS IM
   Sun MM, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P42, DOI 10.1109/ISMAR-Adjunct.2019.00026
   Tang A., 2003, COMP EFFECTIVENESS A, P73, DOI [10.1145/642611.642626, DOI 10.1145/642611.642626]
   Unity, DISC MOR TOOLS PROD
   Vovk A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173783
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Wang X., 2016, MULTIMODAL AUGMENTED
   Wang Z, 2020, INT J ADV MANUF TECH, V106, P603, DOI 10.1007/s00170-019-04538-9
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Wiesenthal DL, 2000, J APPL SOC PSYCHOL, V30, P1709, DOI 10.1111/j.1559-1816.2000.tb02463.x
   Wilcox R.R., 2003, Applying contemporary statistical techniques, P285, DOI [DOI 10.1016/B978-012751541-0/50030-4, 10.1016/B978-012751541-0/50030-4]
   Williamson Victoria., 2014, You Are the Music: How Music Reveals What It Means to Behuman
   Zhang J, 2011, INT J PROD RES, V49, P3919, DOI 10.1080/00207543.2010.492802
   Zhao JH, 2020, INT CONF IMAG VIS, DOI 10.1109/ivcnz51579.2020.9290643
NR 62
TC 6
Z9 6
U1 6
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 591
EP 601
DI 10.1007/s10055-022-00680-0
EA JUL 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000832848800001
DA 2024-07-18
ER

PT J
AU Checa, D
   Miguel-Alonso, I
   Bustillo, A
AF Checa, David
   Miguel-Alonso, Ines
   Bustillo, Andres
TI Immersive virtual-reality computer-assembly serious game to enhance
   autonomous learning
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Educational game; e-Learning; Active learning; Computer
   science; Game engine; Head mounted display
AB Immersive virtual reality (VR) environments create a very strong sense of presence and immersion. Nowadays, especially when student isolation and online autonomous learning is required, such sensations can provide higher satisfaction and learning rates than conventional teaching. However, up until the present, learning outcomes with VR tools have yet to prove their advantageous aspects over conventional teaching. The project presents a VR serious game for teaching concepts associated with computer hardware assembly. These concepts are often included in any undergraduate's introduction to Computer Science. The learning outcomes are evaluated using a pre-test of previous knowledge, a satisfaction/usability test, and a post-test on knowledge acquisition, structured with questions on different knowledge areas. The results of the VR serious game are compared with another two learning methodologies adapted to online learning: (1) an online conventional lecture; and (2) playing the same serious game on a desktop PC. An extensive sample of students (n = 77) was formed for this purpose. The results showed the strong potential of VR serious games to improve student well-being during spells of confinement, due to higher learning satisfaction. Besides, ease of usability and the use of in-game tutorials are directly related with game-user satisfaction and performance. The main novelty of this research is related to academic performance. Although a very limited effect was noted for learning theoretical knowledge with the VR application in comparison with the other methodologies, this effect was significantly improved through visual knowledge, understanding and making connections between different concepts. It can therefore be concluded that the proposed VR serious game has the potential to increase student learning and therefore student satisfaction, by imparting a deeper understanding of the subject matter to students.
C1 [Checa, David; Miguel-Alonso, Ines; Bustillo, Andres] Univ Burgos, Dept Ingn Informat, Burgos, Spain.
C3 Universidad de Burgos
RP Bustillo, A (corresponding author), Univ Burgos, Dept Ingn Informat, Burgos, Spain.
EM dcheca@ubu.es; imalonso@ubu.es; abustillo@ubu.es
RI Checa Cruz, David/J-2839-2017; Bustillo, Andres/I-1403-2015
OI Checa Cruz, David/0000-0001-6623-3614; , Ines
   Miguel-Alonso/0000-0001-8882-7587; Bustillo, Andres/0000-0003-2855-7532
FU Consejeria de Empleo of the Junta de Castilla y Leon (Spain)
   [INVESTUN/18/BU/0002]; European Commission [2020-1-ES01-KA204-081847];
   Centro para el Desarrollo Tecnologico e Industrial (CDTI) [IDI-20191008]
FX This work was partially supported by the GruaRV project (Reference
   Number INVESTUN/18/BU/0002) of the Consejeria de Empleo of the Junta de
   Castilla y Leon (Spain), the Erasmus+ RISKREAL Project (Reference Number
   2020-1-ES01-KA204-081847) of the European Commission and the SMART-EASY
   project (Reference Number IDI-20191008) funded by the Centro para el
   Desarrollo Tecnologico e Industrial (CDTI).
CR Abich J IV, 2021, VIRTUAL REAL-LONDON, V25, P919, DOI 10.1007/s10055-020-00498-8
   Akbulut A, 2018, COMPUT APPL ENG EDUC, V26, P918, DOI 10.1002/cae.21935
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Bennett N., 1984, British Journal of Educational Studies, V32, P274, DOI DOI 10.2307/3121583
   Bharathi Ajay Karthic B., 2015, P ASME 2015 INT DES, V10, DOI [10.1115/detc2015-47388, DOI 10.1115/DETC2015-47388]
   Bhattacharjee D, 2018, COMPUT ELECTR ENG, V65, P236, DOI 10.1016/j.compeleceng.2017.08.023
   Birckhead B, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/11973
   Bloom B., 1956, Taxonomy of educational objectives: the classification of educational goals, handbook 1, cognitive domain
   Borsci S, 2016, VIRTUAL REAL-LONDON, V20, P41, DOI 10.1007/s10055-015-0281-5
   Bujdosó G, 2017, INT CONF COGN INFO, P79, DOI 10.1109/CogInfoCom.2017.8268220
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Cruz DC, 2021, DYNA-BILBAO, V96, P620, DOI 10.6036/10241
   Checa D, 2020, LECT NOTES COMPUT SC, V12243, P220, DOI 10.1007/978-3-030-58468-9_17
   Checa D, 2020, VIRTUAL REAL-LONDON, V24, P151, DOI 10.1007/s10055-019-00389-7
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chen SN, 2013, MULTIMED TOOLS APPL, V62, P633, DOI 10.1007/s11042-011-0864-4
   Dale Edgar., 1946, Audiovisual Methods in Teaching
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   De Paolis LT, 2020, VIRTUAL REAL-LONDON, V24, P483, DOI 10.1007/s10055-019-00409-6
   Dengel A, 2018, PR IEEE INT CONF TEA, P1107, DOI 10.1109/TALE.2018.8615288
   Excell PS, 2000, IEEE T EDUC, V43, P250, DOI 10.1109/13.865196
   Greenwald SW, 2018, J UNIVERS COMPUT SCI, V24, P220
   Horst Robin, 2019, Advances in Visual Computing. 14th International Symposium on Visual Computing, ISVC 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11844), P494, DOI 10.1007/978-3-030-33720-9_38
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Johnson CI, 2009, J EDUC PSYCHOL, V101, P621, DOI 10.1037/a0015183
   Koumaditis K, 2020, IEEE COMPUT GRAPH, V40, P41, DOI 10.1109/MCG.2020.3006330
   Kowalski S., 2020, World Transactions on Engineering and Technology Education, V18, P197
   Liu DJ, 2017, SMART COMPUT INTELL, P105, DOI 10.1007/978-981-10-5490-7_7
   Looi CK, 2009, COMPUT EDUC, V53, P1120, DOI 10.1016/j.compedu.2009.05.021
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Mayer RE, 2014, COMPUTER GAMES FOR LEARNING: AN EVIDENCE-BASED APPROACH, P1
   Mayer RE, 2010, J EDUC COMPUT RES, V42, P241, DOI 10.2190/EC.42.3.a
   Molina-Carmona R, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10041074
   Moro C, 2017, ANAT SCI EDUC, V10, P549, DOI 10.1002/ase.1696
   Pirker Johanna., 2020, 26 ACM S VIRTUAL REA, P1, DOI [DOI 10.1145/3385956.3418947, 10.1145/3385956.3418947]
   Pritchard A., 2017, Ways of learning: Learning theories for the classroom, DOI DOI 10.4324/9781315460611
   Puttawong N, 2017, PROC INT CONF INF TE, P241
   Ray AB, 2016, IEEE CONF TECHNOL ED, P68, DOI [10.1109/T4E.2016.022, 10.1109/T4E.2016.21]
   Roussos M, 1999, PRESENCE-TELEOP VIRT, V8, P247, DOI 10.1162/105474699566215
   Tanielu T, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P92, DOI 10.1145/3300115.3309513
   TCHATOKEY K, 2016, INT J VIRTUAL REAL, DOI DOI 10.1145/2927929.2927955
   Wolfartsberger J, 2019, AUTOMAT CONSTR, V104, P27, DOI 10.1016/j.autcon.2019.03.018
   Zhou Y, 2018, PROCEDIA COMPUT SCI, V130, P239, DOI 10.1016/j.procs.2018.04.035
NR 43
TC 37
Z9 37
U1 9
U2 51
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3301
EP 3318
DI 10.1007/s10055-021-00607-1
EA DEC 2021
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000734139700001
PM 34961808
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Hadjipanayi, C
   Michael-Grigoriou, D
AF Hadjipanayi, Christos
   Michael-Grigoriou, Despina
TI Arousing a wide range of emotions within educational virtual reality
   simulation about major depressive disorder affects knowledge retention
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Game narrative; Affective states; Knowledge retention;
   Major depressive disorder
ID MOTIVATIONAL INTENSITY; INDIVIDUAL-DIFFERENCES; VALENCE FOCUS; EMPATHY;
   EMBODIMENT; IMMERSION; AFRICAN; MEMORY; SENSE; MIND
AB The experience of using an educational application, concerning a major depressive disorder simulation, could be anything but pleasant, so the challenges of creating such an application are ample. In this research, the effects of the emotional experience of the players, deriving from the positive ending of the virtual reality (VR) simulation's embedded narrative or the lack of it, are evaluated. Alongside the investigation of a possible link between the emotional impact of the simulation and information retention, the overall effect of the application in relation to VR presence and body ownership is appraised. Thirty participants over 18 years old tested the application, using an Oculus Rift head-mounted display with a joystick, and their data were recorded by a pre- and a post-questionnaire. The 30 participants have been separated into groups of 15, where the positive ending was accessible to only one of the two groups. The group which experienced the positive ending reported a significant correlation of emotional impact and knowledge retention.
C1 [Hadjipanayi, Christos; Michael-Grigoriou, Despina] Cyprus Univ Technol, Dept Multimedia & Graph Arts, GET Lab, Limassol, Cyprus.
   [Hadjipanayi, Christos; Michael-Grigoriou, Despina] CYENS Ctr Excellence, Nicosia, Cyprus.
C3 Cyprus University of Technology
RP Michael-Grigoriou, D (corresponding author), Cyprus Univ Technol, Dept Multimedia & Graph Arts, GET Lab, Limassol, Cyprus.; Michael-Grigoriou, D (corresponding author), CYENS Ctr Excellence, Nicosia, Cyprus.
EM despina.grigoriou@cut.ac.cy
RI Hadjipanayi, Christos/GZH-0878-2022; Michael-Grigoriou,
   Despina/ABE-5748-2022
OI Michael-Grigoriou, Despina/0000-0003-0824-7684; Hadjipanayi,
   Christos/0000-0001-7444-5406
CR [Anonymous], 2004, The central nervous system: structure and function
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   AShamaluevMusic, 2017, NEED INSTR BACKGR MU
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Baños RM, 2008, CYBERPSYCHOL BEHAV, V11, P1, DOI 10.1089/cpb.2007.9936
   Baron-Cohen S, 2002, TRENDS COGN SCI, V6, P248, DOI 10.1016/S1364-6613(02)01904-6
   Barrett LF, 1998, COGNITION EMOTION, V12, P579, DOI 10.1080/026999398379574
   Bazalgette C, 2013, LITERACY, V47, P95, DOI 10.1111/j.1741-4369.2012.00666.x
   Beck AT, 2009, DEPRESSION: CAUSES AND TREATMENT, SECOND EDITION, P1
   Bizzocchi J., 2012, B SCI TECHNOL SOC, V32, P393, DOI [DOI 10.1177/0270467612463796, 10.1177/0270467612463796]
   BOWER GH, 1981, J EXP PSYCHOL GEN, V110, P451, DOI 10.1037/0096-3445.110.4.451
   Bradley MM, 2001, EMOTION, V1, P276, DOI 10.1037//1528-3542.1.3.276
   BRADLEY MM, 1992, J EXP PSYCHOL LEARN, V18, P379, DOI 10.1037/0278-7393.18.2.379
   Brown JSL, 2011, INT J SOC PSYCHIATR, V57, P362, DOI 10.1177/0020764009357400
   Caligiuri MP, 2000, J AFFECT DISORDERS, V57, P83, DOI 10.1016/S0165-0327(99)00068-3
   Cameron CD, 2019, J EXP PSYCHOL GEN, V148, P962, DOI 10.1037/xge0000595
   Chittaro L., 2014, DESKTOP VIRTUAL REAL, P141, DOI DOI 10.1145/2671015.2671025
   CHRISTIANSON SA, 1992, PSYCHOL BULL, V112, P284, DOI 10.1037/0033-2909.112.2.284
   Christofi M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01242
   Consalvo M., 2003, Television & New Media, V4, P321, DOI 10.1177/1527476403253993
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Decety J, 2006, BRIDGING SOCIAL PSYCHOLOGY: BENEFITS OF TRANSDISCIPLINARY APPROACHES, P103
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Dunlap K., 2018, Proceedings of the 2018 Connected Learning Summit, P77
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   FELDMAN LA, 1995, J PERS SOC PSYCHOL, V69, P153, DOI 10.1037/0022-3514.69.1.153
   Fine C, 2008, NEUROETHICS-NETH, V1, P69, DOI 10.1007/s12152-007-9004-2
   Frasca Gonzalo., 2013, The video game theory reader, P243, DOI DOI 10.4324/9780203700457-17
   Freeman J., 2005, PRESENCE, P213
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gallagher S, 2012, SCI CONTEXT, V25, P355, DOI 10.1017/S0269889712000117
   Green MJ, 2010, BRIT MED J, V340, DOI 10.1136/bmj.c863
   Hadjipanayi C, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e04145
   Hammond H.K., 2009, Graphic novels and multimodal literacy: A reader response study
   Harmon-Jones C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0159915
   Harmon-Jones E, 2013, CURR DIR PSYCHOL SCI, V22, P301, DOI 10.1177/0963721413481353
   Harmon-Jones E, 2012, FRONT INTEGR NEUROSC, V6, DOI 10.3389/fnint.2012.00073
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Highet NJ, 2002, MED J AUSTRALIA, V176, pS63
   Hudson DL, 2018, AM J MENS HEALTH, V12, P126, DOI 10.1177/1557988316654864
   IZARD CE, 1992, PSYCHOL REV, V99, P561, DOI 10.1037/0033-295X.99.3.561
   JOHNSTON WA, 1986, ANNU REV PSYCHOL, V37, P43, DOI 10.1146/annurev.ps.37.020186.000355
   Jun J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174175
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kiropoulos LA, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.1527
   Kress G., 2010, MULTIMODALITY SOCIAL
   Lauber C, 2003, ACTA PSYCHIAT SCAND, V108, P96, DOI 10.1034/j.1600-0447.108.s418.19.x
   Lee JER, 2014, CYBERPSYCH BEH SOC N, V17, P248, DOI 10.1089/cyber.2013.0358
   Libkuman TM, 2004, MEMORY, V12, P237, DOI 10.1080/09658210244000630
   Lopez C, 2008, NEUROPHYSIOL CLIN, V38, P149, DOI 10.1016/j.neucli.2007.12.006
   Ma K, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00604
   Marsh R, 2010, NEUROPSYCHOLOGIA, V48, P2912, DOI 10.1016/j.neuropsychologia.2010.05.033
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Moser C, 2015, INT J HUM-COMPUT INT, V31, P146, DOI 10.1080/10447318.2014.986639
   Muller DA, 2017, EXTENDED ABSTRACTS PUBLICATION OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY'17 EXTENDED ABSTRACTS), P599, DOI 10.1145/3130859.3130862
   OSullivan James, 2019, Towards a Digital Poetics: Electronic Literature & Literary Games, P77
   Panksepp J., 2004, Affective Neuroscience: The Foundations of Human and Animal Emotions
   Qin H, 2009, INT J HUM-COMPUT INT, V25, P107, DOI 10.1080/10447310802546732
   Rao NJ, 2019, LECT NOTES COMPUT SC, V11869, P395, DOI 10.1007/978-3-030-33894-7_42
   Richter M, 2013, SOC PERSONAL PSYCHOL, V7, P1, DOI 10.1111/spc3.12007
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Salen Katie, 2004, RULES PLAY GAME DESI
   Schimelpfening, 2018, GRIEF VS DEPRESSION
   Schimmenti A, 2019, CURR PSYCHOL, V38, P100, DOI 10.1007/s12144-017-9588-6
   Schott G., 2017, DiGRA'17 - Proceedings of the 2017 DiGRA International Conference, P1
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395
   Shaw D, 2003, J AESTHET ART CRITIC, V61, P206
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Steed A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00112
   Summerell E, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02665
   Tanenbaum K, 2010, DIGIT CREAT, V21, P11, DOI 10.1080/14626261003654509
   Tsitsas G., 2012, The psychometric tools in Greece
   Urban EJ, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203574
   Villani D., 2009, INT J HUMAN COMPUTER, V1, P35
   Walton GM, 2003, J EXP SOC PSYCHOL, V39, P456, DOI 10.1016/S0022-1031(03)00019-2
NR 81
TC 3
Z9 3
U1 4
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 343
EP 359
DI 10.1007/s10055-021-00568-5
EA AUG 2021
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000691648100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Alves, JB
   Marques, B
   Ferreira, C
   Dias, P
   Santos, BS
AF Alves, Joao Bernardo
   Marques, Bernardo
   Ferreira, Carlos
   Dias, Paulo
   Santos, Beatriz Sousa
TI Comparing augmented reality visualization methods for assembly
   procedures
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; User study; Mobile augmented reality; Indirect
   augmented reality; Head-mounted display; Computer-aided manufacturing
AB Assembly processes require now more than ever a systematic way to improve efficiency complying with increasing product demand. Several industrial scenarios have been using augmented reality (AR) to enhance environments with different types of information and influence the overall user satisfaction and performance. The purpose of this work is to evaluate three different AR-based methods that can be used to support users during the execution of assembly procedures. The AR methods evaluated are handheld mobile AR, indirect AR (showing the augmented scene on a monitor) and see-through head-mounted display. A user study was performed to assess performance, mental and physical workload, as well as acceptance of the aforementioned methods. Results from a thirty participants study did not reveal a best method in terms of performance and user preference, showing that all methods are adequate to support users. However, the study highlights the strengths and weaknesses of each method, which may lead to potential advantages in specific use cases.
C1 [Alves, Joao Bernardo; Marques, Bernardo; Dias, Paulo; Santos, Beatriz Sousa] Univ Aveiro, IEETA, DETI, Campus Univ Santiago, Aveiro, Portugal.
   [Ferreira, Carlos] Univ Aveiro, DEGEIT, IEETA, Aveiro, Portugal.
C3 Universidade de Aveiro; Universidade de Aveiro
RP Alves, JB (corresponding author), Univ Aveiro, IEETA, DETI, Campus Univ Santiago, Aveiro, Portugal.
EM jbga@ua.pt
RI Dias, Paulo PMD/G-3681-2013; Marques, Bernardo/AGY-4340-2022
OI Dias, Paulo PMD/0000-0002-3754-2749; Alves, Joao/0000-0002-3430-5211;
   Marques, Bernardo/0000-0002-4454-710X; Ferreira,
   Carlos/0000-0002-2799-643X
FU IEETA - Institute of Electronics and Informatics Engineering of Aveiro -
   FCT - Foundation for Science and Technology [UID/CEC/00127/2019]; 
   [POCI-01- 0247-FEDER-024541]
FX We would like to thank the reviewers for their thoughtful comments and
   suggestions that helped improve an earlier version of this manuscript.
   We thank everyone involved in discussion groups and case studies for
   their time and expertise. This research was developed in the scope of
   Produtech - SIF - Solutions for the Industry of the Future [POCI-01-
   0247-FEDER-024541]. This study was also supported by IEETA - Institute
   of Electronics and Informatics Engineering of Aveiro, funded by National
   Funds through the FCT - Foundation for Science and Technology, in the
   context of the project [UID/CEC/00127/2019].
CR Alves J, 2019, IEEE INT CONF AUTON, P168
   Alves JB, 2021, INT J ADV MANUF TECH, V115, P105, DOI 10.1007/s00170-021-07049-8
   [Anonymous], 2000, Understanding robust and exploratory data analysis
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baumeister J, 2017, IEEE T VIS COMPUT GR, V23, P2378, DOI 10.1109/TVCG.2017.2735098
   Blattgerste J, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P75, DOI 10.1145/3056540.3056547
   Bosch T, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P412, DOI 10.1145/3056540.3076189
   Bottani E, 2019, IISE TRANS, V51, P284, DOI 10.1080/24725854.2018.1493244
   Büttner S, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P433, DOI 10.1145/3056540.3076193
   Khuong BM, 2014, 2014 IEEE VIRTUAL REALITY (VR), P57, DOI 10.1109/VR.2014.6802051
   Chowdhury SA, 2013, LECT NOTES COMPUT SC, V8237, P418, DOI 10.1007/978-3-319-02958-0_38
   Cortes G, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00093
   Daling L, 2020, ADV INTELL SYST, V972, P755, DOI 10.1007/978-3-030-19135-1_74
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Dünser A, 2011, HANDBOOK OF AUGMENTED REALITY, P289, DOI 10.1007/978-1-4614-0064-6_13
   Fiorentino M, 2014, COMPUT IND, V65, P270, DOI 10.1016/j.compind.2013.11.004
   Funk M, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P222, DOI 10.1145/3056540.3056548
   Funk M, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P934, DOI 10.1145/2971648.2971706
   Funk M, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P253, DOI 10.1145/2836041.2836067
   Gibbons JD., 2011, Nonparametric Statistical Inference, P977
   Groover MP., 2016, Automation, Production Systems, and Computer-Integrated Manufacturing
   Guimaraes MD, 2014, SYMP VIRTUAL AUGMENT, P45, DOI 10.1109/SVR.2014.17
   Hair JF, 2010, Multivariate data analysis
   Hakkarainen M, 2008, INT SYM MIX AUGMENT, P167, DOI 10.1109/ISMAR.2008.4637349
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Havard V, 2021, VIRTUAL REAL-LONDON, V25, P999, DOI 10.1007/s10055-020-00493-z
   HENDERSON S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI DOI 10.1109/TVCG.2010.245
   Kosch T, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P1006, DOI 10.1145/3123024.3124395
   Loch F, 2016, INT CONF INTEL ENVIR, P147, DOI 10.1109/IE.2016.31
   Marques Bernardo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427324
   Muller Jens., 2019, Proceedings of Mensch und Computer, P399, DOI [10.1145/3340764.3340773, DOI 10.1145/3340764.3340773]
   Neumann U, 1998, P IEEE VIRT REAL ANN, P4, DOI 10.1109/VRAIS.1998.658416
   Rashid MFF, 2012, INT J ADV MANUF TECH, V59, P335, DOI 10.1007/s00170-011-3499-8
   Swift K., 2013, MANUFACTURING PROCES, P393, DOI [10.1016/B978-0-08-099360-7.00013-6, DOI 10.1016/B978-0-08-099360-7.00013-6]
   Tabachnick B., 2008, EXPT DESIGNS USING A
   Tang A., 2003, COMP EFFECTIVENESS A, P73, DOI [10.1145/642611.642626, DOI 10.1145/642611.642626]
   Uva AE, 2018, INT J ADV MANUF TECH, V94, P509, DOI 10.1007/s00170-017-0846-4
   Wu LC, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P95, DOI 10.1145/2856400.2856416
NR 38
TC 16
Z9 18
U1 7
U2 34
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 235
EP 248
DI 10.1007/s10055-021-00557-8
EA JUL 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000671921300001
DA 2024-07-18
ER

PT J
AU Holzwarth, V
   Schneider, J
   Handali, J
   Gisler, J
   Hirt, C
   Kunz, A
   Brocke, JV
AF Holzwarth, Valentin
   Schneider, Johannes
   Handali, Joshua
   Gisler, Joy
   Hirt, Christian
   Kunz, Andreas
   Brocke, Jan vom
TI Towards estimating affective states in Virtual Reality based on
   behavioral data
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality; Affective VR; Sensor Data; Affective States
ID RECOGNITION; EXPRESSION; MOVEMENTS; EMOTION; POSTURE; HEAD
AB Inferring users' perceptions of Virtual Environments (VEs) is essential for Virtual Reality (VR) research. Traditionally, this is achieved through assessing users' affective states before and after being exposed to a VE, based on standardized, self-assessment questionnaires. The main disadvantage of questionnaires is their sequential administration, i.e., a user's affective state is measured asynchronously to its generation within the VE. A synchronous measurement of users' affective states would be highly favorable, e.g., in the context of adaptive systems. Drawing from nonverbal behavior research, we argue that behavioral measures could be a powerful approach to assess users' affective states in VR. In this paper, we contribute by providing methods and measures evaluated in a user study involving 42 participants to assess a users' affective states by measuring head movements during VR exposure. We show that head yaw significantly correlates with presence, mental and physical demand, perceived performance, and system usability. We also exploit the identified relationships for two practical tasks that are based on head yaw: (1) predicting a user's affective state, and (2) detecting manipulated questionnaire answers, i.e., answers that are possibly non-truthful. We found that affective states can be predicted significantly better than a naive estimate for mental demand, physical demand, perceived performance, and usability. Further, manipulated or non-truthful answers can also be estimated significantly better than by a naive approach. These findings mark an initial step in the development of novel methods to assess user perception of VEs.
C1 [Holzwarth, Valentin; Schneider, Johannes; Handali, Joshua; Brocke, Jan vom] Univ Liechtenstein, Inst Informat Syst, Vaduz, Liechtenstein.
   [Gisler, Joy; Hirt, Christian; Kunz, Andreas] Swiss Fed Inst Technol, Innovat Ctr Virtual Real, Zurich, Switzerland.
C3 University of Liechtenstein; Swiss Federal Institutes of Technology
   Domain; ETH Zurich
RP Kunz, A (corresponding author), Swiss Fed Inst Technol, Innovat Ctr Virtual Real, Zurich, Switzerland.
EM valentin.holzwarth@uni.li; johannes.schneider@uni.li;
   joshua.handali@uni.li; gisler@iwf.mavt.ethz.ch; hirtc@iwf.mavt.ethz.ch;
   kunz@iwf.mavt.ethz.ch; jan.vom.brocke@uni.li
RI Hirt, Christian/AAM-3523-2020; Kunz, Andreas/B-9241-2008
OI Hirt, Christian/0000-0003-4396-1496; Kunz, Andreas/0000-0002-6495-4327;
   Holzwarth, Valentin/0000-0002-4930-5169
FU Hilti Family Foundation in Schaan, Liechtenstein; RhySearch in Buchs SG,
   Switzerland
FX This work was supported by a project financed by the Hilti Family
   Foundation in Schaan, Liechtenstein and RhySearch in Buchs SG,
   Switzerland. Additionally, the authors would like to thank Hilti AG for
   the fruitful collaboration and the equipment provided.
CR Bangor A, 2009, J USABILITY STUD, V4, P114
   Barfield W., 1995, VIRTUAL ENV ADV INTE, P473, DOI [DOI 10.1093/OSO/9780195075557.001.0001, 10.1093/oso/9780195075557.001.0001]
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Chang CW, 2019, IEEE ACCESS, V7, P43637, DOI 10.1109/ACCESS.2019.2905143
   Chen S, 2020, IEEE T VIS COMPUT GR, V26, P2775, DOI 10.1109/TVCG.2019.2904069
   Chen SY, 2019, IEEE J BIOMED HEALTH, V23, P2464, DOI 10.1109/JBHI.2019.2893945
   Chmielewski M, 2020, SOC PSYCHOL PERS SCI, V11, P464, DOI 10.1177/1948550619875149
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   EKMAN P, 1967, PERCEPT MOTOR SKILL, V24, P711, DOI 10.2466/pms.1967.24.3.711
   Fusco, 2019, INT JOINT C ART INT
   Gillham B., 2007, Developing a questionnaire, V2nd
   Gisler J, 2020, 2020 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2020), P125, DOI 10.1109/CW49994.2020.00026
   Harms P, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3301423
   HART S G, 1988, P139
   Hirt C, 2020, J AMB INTEL HUM COMP, V11, P5977, DOI 10.1007/s12652-020-01845-y
   Hirt C, 2019, IEEE ICCE, P337, DOI [10.1109/ICCE-Berlin47944.2019.8966169, 10.1109/icce-berlin47944.2019.8966169]
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Karg M, 2013, IEEE T AFFECT COMPUT, V4, P341, DOI 10.1109/T-AFFC.2013.29
   Kleinsmith A, 2006, INTERACT COMPUT, V18, P1371, DOI 10.1016/j.intcom.2006.04.003
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Lambert D.M., 1990, J BUS LOGIST, V11, DOI DOI 10.1007/978-3-319-10966-4
   MacKenzie I.S., 2013, Human-Computer Interaction, P157, DOI [10.1016/B978-0-12-405865-1.00005-4, DOI 10.1016/B978-0-12-405865-1.00005-4]
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Marín-Morales J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185163
   MEHRABIA.A, 1969, J CONSULT CLIN PSYCH, V33, P330, DOI 10.1037/h0027576
   Mertens, 2017, QUANTITATIVE DATA AN, P135, DOI [10.1007/978-3-319-42700-3_8, DOI 10.1007/978-3-319-42700-3_8]
   Meske C, 2022, INFORM SYST MANAGE, V39, P53, DOI 10.1080/10580530.2020.1849465
   Mu, 2020, ARXIV200510161
   Newsted PR, 1998, MIS QUART, V22, P553, DOI 10.2307/249555
   Norouzian F., 2019, P 2019 20 IN TERNATI, P1, DOI DOI 10.23919/IRS.2019.8767461
   Pfeuffer K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300340
   Pomplun M., 2003, PUPIL DILATION INDIC
   Qiu J, 2012, HUM FACTORS, V54, P626, DOI 10.1177/0018720812437275
   Schneider J, 2020, LECT NOTES COMPUT SC, V12080, P431, DOI 10.1007/978-3-030-44584-3_34
   Schroeder R, 2006, PRESENCE-VIRTUAL AUG, V15, P655, DOI 10.1162/pres.15.6.655
   Sivo SA, 2006, J ASSOC INF SYST, V7, P351, DOI 10.17705/1jais.00093
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Vidal K., 2013, CHI 13 EXTENDED ABST, P3147, DOI DOI 10.1145/2468356.2479632
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Won AS, 2016, CYBERPSYCH BEH SOC N, V19, P380, DOI 10.1089/cyber.2015.0326
   Wu CL, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P193, DOI 10.1145/3083187.3083210
   Yaremych HE, 2019, J EXP SOC PSYCHOL, V85, DOI 10.1016/j.jesp.2019.103845
   Zenner A, 2020, IEEE T VIS COMPUT GR, V26, P2104, DOI 10.1109/TVCG.2020.2973476
   Zhang WZ, 2017, I C VIRTUAL REALITY, P311, DOI 10.1109/ICVRV.2017.00072
NR 48
TC 9
Z9 11
U1 2
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1139
EP 1152
DI 10.1007/s10055-021-00518-1
EA APR 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000638580300001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Li, XD
   Shan, YF
   Chen, WQ
   Wu, Y
   Hanesen, P
   Perrault, S
AF Li, Xiangdong
   Shan, Yifei
   Chen, Wenqian
   Wu, Yue
   Hanesen, Preben
   Perrault, Simon
TI Predicting user visual attention in virtual reality with a deep learning
   model
SO VIRTUAL REALITY
LA English
DT Article
DE Visual attention; Virtual reality; Deep learning model; Eye tracking
ID VIDEO; SALIENCY
AB Recent studies show that user's visual attention during virtual reality museum navigation can be effectively estimated with deep learning models. However, these models rely on large-scale datasets that usually are of high structure complexity and context specific, which is challenging for nonspecialist researchers and designers. Therefore, we present the deep learning model, ALRF, to generalise on real-time user visual attention prediction in virtual reality context. The model combines two parallel deep learning streams to process the compact dataset of temporal-spatial salient features of user's eye movements and virtual object coordinates. The prediction accuracy outperformed the state-of-the-art deep learning models by reaching record high 91.03%. Importantly, with quick parametric tuning, the model showed flexible applicability across different environments of the virtual reality museum and outdoor scenes. Implications for how the proposed model may be implemented as a generalising tool for adaptive virtual reality application design and evaluation are discussed.
C1 [Li, Xiangdong; Shan, Yifei; Chen, Wenqian; Wu, Yue] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
   [Hanesen, Preben] Stockholm Univ, Dept Comp Sci & Syst, Stockholm, Sweden.
   [Perrault, Simon] Singapore Univ Technol & Design, ISTD, Singapore, Singapore.
C3 Zhejiang University; Stockholm University; Singapore University of
   Technology & Design
RP Li, XD (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
EM axli@zju.edu.cn; shanyf@zju.edu.cn; chenwenqian@zju.edu.cn;
   yuewu0910@zju.edu.cn; preben@dsv.su.se; simon_perrault@sutd.edu.sg
RI WU, YUE/HHN-3268-2022
FU Natural Science Foundation of China [61802341]; ZJU-SUTD IDEA programme
   [IDEA006]
FX The work is supported by Natural Science Foundation of China (61802341)
   and ZJU-SUTD IDEA programme (IDEA006).
CR [Anonymous], 2017, P 27 NOSSDAV, DOI DOI 10.1145/3083165.3083180
   Barbieri L, 2018, INT J INTERACT DES M, V12, P561, DOI 10.1007/s12008-017-0414-z
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chaabouni S, 2016, IEEE IMAGE PROC, P1604, DOI 10.1109/ICIP.2016.7532629
   Cummings JL, 2003, J ENG TECHNOL MANAGE, V20, P39, DOI 10.1016/S0923-4748(03)00004-3
   Cutting J, 2017, EXTENDED ABSTRACTS PUBLICATION OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY'17 EXTENDED ABSTRACTS), P695, DOI 10.1145/3130859.3133221
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Fan CL, 2020, IEEE T MULTIMEDIA, V22, P744, DOI 10.1109/TMM.2019.2931807
   Fang YM, 2017, IEEE T IMAGE PROCESS, V26, P4684, DOI 10.1109/TIP.2017.2721112
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Frutos-Pascual M, 2015, SENSORS-BASEL, V15, P11092, DOI 10.3390/s150511092
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Green CS, 2003, NATURE, V423, P534, DOI 10.1038/nature01647
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Haber J, 2001, COMPUT GRAPH FORUM, V20, pC142, DOI 10.1111/1467-8659.00507
   Han HL, 2017, I C VIRTUAL REALITY, P294, DOI 10.1109/ICVRV.2017.00067
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hell S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P153, DOI 10.1109/AIVR.2018.00032
   Hillaire S., 2009, P 16 ACM S VIRT REAL, DOI [10.1145/1643928.1643941, DOI 10.1145/1643928.1643941]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   John B, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281538
   Karim F, 2019, NEURAL NETWORKS, V116, P237, DOI 10.1016/j.neunet.2019.04.014
   Karim F, 2018, IEEE ACCESS, V6, P1662, DOI 10.1109/ACCESS.2017.2779939
   Laprade, 2020, ARXIV200809192
   Li L, 2015, OPT COMMUN, V350, P33, DOI 10.1016/j.optcom.2015.03.065
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lin T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2273
   Lo WC, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P211, DOI 10.1145/3083187.3083219
   Low T, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P273, DOI 10.1145/3020165.3022131
   Mahdi A, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102662
   Mnih V, 2014, ADV NEUR IN, V27
   Moniri MM, 2016, INT CONF INTEL ENVIR, P238, DOI 10.1109/IE.2016.54
   Nielsen LT, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P229, DOI 10.1145/2993369.2993405
   Ouyang, 2014, ARXIV14093505, DOI [10.1016/j.patcog.2018.02.004, DOI 10.1016/J.PATCOG.2018.02.004]
   Ozcinar C, 2018, INT WORK QUAL MULTIM, P1
   Schubert T, 2015, ACTA PSYCHOL, V157, P200, DOI 10.1016/j.actpsy.2015.03.005
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Sun GD, 2014, IEEE T VIS COMPUT GR, V20, P1753, DOI 10.1109/TVCG.2014.2346919
   Sun LY, 2018, MULTIMED TOOLS APPL, V77, P29013, DOI 10.1007/s11042-018-6091-5
   Upenik E, 2017, IEEE INT CONF MULTI
   Walter R, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1263, DOI 10.1145/2750858.2804255
   Wang W, 2020, IEEE T CYBERNETICS, V50, P3973, DOI 10.1109/TCYB.2019.2917078
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Wenguan Wang, 2018, IEEE Transactions on Image Processing, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wood G, 2016, J APPL RES MEM COGN, V5, P454, DOI 10.1016/j.jarmac.2016.04.009
   Xinwei Chen, 2020, IEEE Networking Letters, V2, P81, DOI 10.1109/LNET.2020.2977124
   Xu YY, 2018, PROC CVPR IEEE, P5333, DOI 10.1109/CVPR.2018.00559
   Yan YJ, 2018, PATTERN RECOGN, V79, P65, DOI 10.1016/j.patcog.2018.02.004
   Yang FY, 2013, COMPUT EDUC, V62, P208, DOI 10.1016/j.compedu.2012.10.009
   Yang Q, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173704
   Yosinski J, 2014, ADV NEUR IN, V27
   Yu L-F., 2016, SIGGRAPH ASIA VIRT R, DOI [10.1145/2992138.2992152, DOI 10.1145/2992138.2992152]
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zhao YC, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P741, DOI 10.1109/VR.2018.8446581
   Zhou, 2019, PERSONALISED VIRTUAL, DOI [10.1515/9783110552485-008, DOI 10.1515/9783110552485-008]
   Zhou YZ, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365738
   Zhu YC, 2018, SIGNAL PROCESS-IMAGE, V69, P15, DOI 10.1016/j.image.2018.05.010
NR 59
TC 5
Z9 5
U1 7
U2 65
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1123
EP 1136
DI 10.1007/s10055-021-00512-7
EA APR 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000636920300001
DA 2024-07-18
ER

PT J
AU Bermejo-Berros, J
   Martínez, MAG
AF Bermejo-Berros, Jesus
   Gil Martinez, Miguel Angel
TI The relationships between the exploration of virtual space, its presence
   and entertainment in virtual reality, 360o and 2D
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality; Virtual Space; Presence; Entertainment; Navigation
ID SPATIAL PRESENCE; SHORT-FORM; MODEL
AB This research investigates the relationships between the way virtual space is explored, the perception of presence and the degree of entertainment experienced during the experience. All participants (N = 147) interact with an omnidirectional video clip in three different conditions (VR, 360o, 2D). Throughout the two experimental sessions, affective, cognitive, and behavioural information is collected from the participant, which allows us to relate their interactive behaviour, their perception of presence and degree of entertainment. The possible influence of experience with interactive systems on current interactive behaviour is also analysed. The results highlight the complex relationships between these nuclear dimensions of VR and indicate the existence of two types of exploratory behaviour that we have called interface dependent and interface independent. When the first is present, there is no connection with the positive perception of presence and entertainment, but there is in the second. This typology shows the need to consider the learning processes in the access to the content through the interface in digital interactive systems such as VR and 360o.
C1 [Bermejo-Berros, Jesus; Gil Martinez, Miguel Angel] Univ Valladolid, Fac Social Sci Law & Commun, Lispimedia Lab, Segovia 40002, Spain.
C3 Universidad de Valladolid
RP Martínez, MAG (corresponding author), Univ Valladolid, Fac Social Sci Law & Commun, Lispimedia Lab, Segovia 40002, Spain.
EM jesus.bermejo@uva.es; miguelangel.gil.martinez@uva.es
OI Gil Martinez, Miguel Angel/0000-0001-6217-5314; Bermejo-Berros,
   Jesus/0000-0002-2830-604X
CR Biocca F, 1997, SECOND INTERNATIONAL CONFERENCE ON COGNITIVE TECHNOLOGY, PROCEEDINGS, P12, DOI 10.1109/CT.1997.617676
   Bruner G.C., 2009, Marketing Scales Handbook: A Compilation of Multi-Item Measures for Consumer Behavior Advertising Research
   CHATTOPADHYAY A, 1990, J MARKETING RES, V27, P466, DOI 10.2307/3172631
   Corbillon X, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P199, DOI 10.1145/3083187.3083215
   De Abreu A., 2017, PROC IEEE 9 INT C QU, P1, DOI 10.1109/QoMEX.2017.7965634
   de Castell S, 2019, ACTA PSYCHOL, V199, DOI 10.1016/j.actpsy.2019.102895
   Dorado J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P896, DOI [10.1109/vr.2019.8798344, 10.1109/VR.2019.8798344]
   Draper JV, 1998, HUM FACTORS, V40, P354, DOI 10.1518/001872098779591386
   Duanmu F., 2018, 2018 IEEE International Conference on Multimedia and Expo (ICME), P1
   Eden A., 2017, INT ENCY MEDIA EFFEC, P1, DOI [10.1002/9781118783764.wbieme0163, DOI 10.1002/9781118783764.WBIEME0163]
   Fremerey S, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P403, DOI 10.1145/3204949.3208134
   Frey F, 2018, COMMUN THEOR, V28, P487, DOI 10.1093/ct/qty010
   Fuchs Philippe., 2017, VIRTUAL REALITY HEAD
   Gargurevich R., 2010, PERSONA, V13, P31, DOI [10.26439/persona2010.n013.263, DOI 10.26439/PERSONA2010.N013.263]
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Haans A, 2012, INTERACT COMPUT, V24, P211, DOI 10.1016/j.intcom.2012.04.010
   Hartmann T., 2010, Immersed in media: Telepresence in everyday life, P137
   Hartmann T., 2020, OXFORD HDB ENTERTAIN
   Hartmann T., 2011, Vice city virtue: Moral issues in digital game play, P135
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Jiang JJ, 2017, PACIS 2017 P, P189
   Karim J, 2011, PROCD SOC BEHV, V15, P2016, DOI 10.1016/j.sbspro.2011.04.046
   Kien G., 2009, Identity, learning and support in virtual environments, P9, DOI [10.1163/9789087909949_003, DOI 10.1163/9789087909949_003]
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Klimmt C, 2009, COMMUN THEOR, V19, P351, DOI 10.1111/j.1468-2885.2009.01347.x
   Kuksa I, 2014, CHANDOS INF PROF SER, P1
   LANG A, 1990, COMMUN RES, V17, P275, DOI 10.1177/009365090017003001
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Mahzari A, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P173, DOI 10.1145/3240508.3240680
   Merz EL, 2013, J AFFECT DISORDERS, V151, P942, DOI 10.1016/j.jad.2013.08.011
   Nasrabadi AT, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P273, DOI 10.1145/3304109.3325812
   Pavel A, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P289, DOI 10.1145/3126594.3126636
   Quaglia JT, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P65, DOI 10.1109/VR.2018.8446546
   Ratan RA, 2016, COMMUN RES, V43, P1065, DOI 10.1177/0093650215570652
   Rossi S, 2019, INT CONF ACOUST SPEE, P4020, DOI 10.1109/ICASSP.2019.8683854
   Seibert J, 2018, VIRTUAL REAL-LONDON, V22, P79, DOI 10.1007/s10055-017-0316-1
   Sheikh A., 2016, Directing attention in 360-degree video, DOI DOI 10.1049/IBC.2016.0029
   Tenbrink T, 2016, J EXP PSYCHOL HUMAN, V42, P683, DOI 10.1037/xhp0000178
   Thompson ER, 2007, J CROSS CULT PSYCHOL, V38, P227, DOI 10.1177/0022022106297301
   Tussyadiah IP, 2018, TOURISM MANAGE, V66, P140, DOI 10.1016/j.tourman.2017.12.003
   Upenik Evgeniy, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P73, DOI 10.1109/ICMEW.2017.8026231
   Vorderer P, 2003, LEA COMMUN SER, P131
   Wideström J, 2019, LECT NOTES COMPUT SC, V11613, P186, DOI 10.1007/978-3-030-25965-5_15
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Wu CL, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P193, DOI 10.1145/3083187.3083210
   Wu DY, 2018, COMMUN RES REP, V35, P434, DOI 10.1080/08824096.2018.1525349
   Zillmann D., 2008, INT ENCY COMMUNICATI, DOI DOI 10.1002/9781405186407.WBIECE049
NR 47
TC 9
Z9 9
U1 5
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1043
EP 1059
DI 10.1007/s10055-021-00510-9
EA MAR 2021
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000629853500001
DA 2024-07-18
ER

PT J
AU Zhou, ZY
   Jiang, S
   Yang, ZY
   Xu, B
   Jiang, BW
AF Zhou, Zeyang
   Jiang, Shan
   Yang, Zhiyong
   Xu, Bin
   Jiang, Bowen
TI Surgical navigation system for brachytherapy based on mixed reality
   using a novel stereo registration method
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed reality; Brachytherapy; Surgical navigation; Stereo registration
AB In this study, we present a novel mixed reality navigation system to facilitate brachytherapy, which is an effective method for curing cancer. The accuracy of needle positioning is a vital problem in brachytherapy that can influence the treatment effect. The purpose of the developed system is to help doctors more quickly and easily position the needles and improve seed accuracy in brachytherapy surgery. Based on mixed reality and a multi-information fusion method, a successful fusion of medical images and a preoperative plan for real patients was achieved, allowing doctors to gain an intuitive understanding of the tumor. Image recognition and pose estimation were used to track the needle punctures in real time and perform registration processes. After global registration using an iterative closest-point algorithm with a pattern tracker, medical images and volume renderings of organs, needles and seeds were aligned with the patient. Based on a phantom experiment, the average needle location error was 0.961 mm, and the angle error was 1.861 degrees. The accuracy of needle insertion was 1.586 mm, and the angle error was 2.429 degrees. This research presents the design and validation of a surgical navigation system for thoracoabdominal brachytherapy based on mixed reality. The proposed system was validated through both phantom and animal experiments. The results indicated that the proposed system achieves clinically acceptable accuracy and can aid doctors in performing surgery based on a visualized plan.
C1 [Zhou, Zeyang; Jiang, Shan; Yang, Zhiyong; Xu, Bin; Jiang, Bowen] Tianjin Univ, Sch Mech Engn, Tianjin 300350, Peoples R China.
   [Jiang, Shan] Tianjin Univ, Ctr Adv Mech & Robot, Tianjin 300350, Peoples R China.
C3 Tianjin University; Tianjin University
RP Jiang, S (corresponding author), Tianjin Univ, Sch Mech Engn, Tianjin 300350, Peoples R China.; Jiang, S (corresponding author), Tianjin Univ, Ctr Adv Mech & Robot, Tianjin 300350, Peoples R China.
EM shanjmri@tju.edu.cn
RI Zhou, Zeyang/AAX-9853-2020
FU National Natural Science Foundation of China [51775368, 81871457,
   51811530310, 8167071354]; Technology Planning Project of Guangdong
   Province, China [2017B020210004]
FX This research was partially supported by the National Natural Science
   Foundation of China (Grant No. 51775368, 81871457, 51811530310,
   8167071354) and the Technology Planning Project of Guangdong Province,
   China (Grant No. 2017B020210004).
CR Arnolli MM, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1877
   Audenaert E, 2011, COMPUT AIDED SURG, V16, P304, DOI 10.3109/10929088.2011.613951
   Chaudhary A, 2019, IEEE COMPUT GRAPH, V39, P26, DOI 10.1109/MCG.2018.2880818
   Chen XJ, 2015, J BIOMED INFORM, V55, P124, DOI 10.1016/j.jbi.2015.04.003
   Chu YK, 2017, MED IMAGE ANAL, V42, P241, DOI 10.1016/j.media.2017.08.003
   Chusetthagarn D., 2018, 2018 22 INT COMP SCI, P1
   Dontschewa M, 2018, 2018 IEEE 27 INT SCI, P1
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Fabbri R, 2012, LECT NOTES COMPUT SC, V7575, P231, DOI 10.1007/978-3-642-33765-9_17
   Funk M, 2017, IOT'17: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON THE INTERNET OF THINGS, P142, DOI [10.1145/3131542.3131559, 10.1145/3131542.3140267]
   Furlan R, 2016, IEEE SPECTRUM, V53, P21, DOI 10.1109/MSPEC.2016.7473143
   Gsaxner C, 2019, LECT NOTES COMPUT SC, V11768, P236, DOI 10.1007/978-3-030-32254-0_27
   Hast A., 2013, J WSCG
   Jiang Shan, 2018, Journal of Tianjin University (Science and Technology), V51, P373, DOI 10.11784/tdxbz201706028
   Kanzaki H, 2015, JPN J CLIN ONCOL, V45, P688, DOI 10.1093/jjco/hyv050
   Lacey G, 2007, IEEE MULTIMEDIA, V14, P76, DOI 10.1109/MMUL.2007.79
   Lee CD, 2014, BRIT J RADIOL, V87, DOI 10.1259/bjr.20140146
   Ma LF, 2019, MED BIOL ENG COMPUT, V57, P47, DOI 10.1007/s11517-018-1861-9
   Ma XD, 2019, J MED DEVICES, V13, DOI 10.1115/1.4042542
   Navab N, 2007, IEEE COMPUT GRAPH, V27, P10, DOI 10.1109/MCG.2007.117
   Panchal P. M., 2013, Int. J. Innovative Res. Comput. Commun. Eng, V1, P323
   Pepe A, 2019, J DIGIT IMAGING, V32, P1008, DOI 10.1007/s10278-019-00272-6
   Pepe A, 2018, BIOMED ENG INT CONF
   Qian L., 2017, ARXIV170305834
   Stewart A, 2016, BRACHYTHERAPY, V15, P1, DOI 10.1016/j.brachy.2015.09.006
   Sylos Labini Mauro, 2019, Intelligent Computing Methodologies. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11645), P716, DOI 10.1007/978-3-030-26766-7_65
   Tanderup K, 2017, ADV DRUG DELIVER REV, V109, P15, DOI 10.1016/j.addr.2016.09.002
   Wang JC, 2019, INT J COMPUT ASS RAD, V14, P763, DOI 10.1007/s11548-019-01921-5
NR 28
TC 6
Z9 9
U1 5
U2 39
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 975
EP 984
DI 10.1007/s10055-021-00503-8
EA FEB 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000618186500001
DA 2024-07-18
ER

PT J
AU Liberatore, MJ
   Wagner, WP
AF Liberatore, Matthew J.
   Wagner, William P.
TI Virtual, mixed, and augmented reality: a systematic review for immersive
   systems research
SO VIRTUAL REALITY
LA English
DT Review
DE Immersive systems; Virtual reality; VR; Augmented reality; AR; Mixed
   reality; MR; Empirical research; Systematic review
ID POSTTRAUMATIC-STRESS-DISORDER; RANDOMIZED CONTROLLED-TRIAL; IN-VIVO
   EXPOSURE; EXPERIENCE; THERAPY; STROKE; TECHNOLOGY; BALANCE; GAIT;
   ENVIRONMENTS
AB Immersive systems can be used to capture new data, create new experiences, and provide new insights by generating virtual elements of physical and imagined worlds. Immersive systems are seeing increased application across a broad array of fields. However, in many situations it is unknown if an immersive application performs as well or better than the existing application in accomplishing a specific task. The purpose of this study is to conduct a systematic review of the literature that addresses the performance of immersive systems. This review assesses those applications where experiments, tests, or clinical trials have been performed to evaluate the proposed application. This research addresses a broad range of application areas and considers studies that compared one or more immersive systems with a control group or evaluated performance data for the immersive system pre- and post-test. The results identify those applications that have been successfully tested and also delineate areas of future research where more data may be needed to assess the effectiveness of proposed applications.
C1 [Liberatore, Matthew J.] Villanova Univ, Dept Management & Operat, Villanova Sch Business, Villanova, PA 19085 USA.
   [Wagner, William P.] Villanova Univ, Villanova Sch Business, Dept Accounting & Informat Syst, Villanova, PA 19085 USA.
C3 Villanova University; Villanova University
RP Liberatore, MJ (corresponding author), Villanova Univ, Dept Management & Operat, Villanova Sch Business, Villanova, PA 19085 USA.
EM matthew.liberatore@villanova.edu; william.wagner@villanova.edu
CR Abdullah M, 2018, INT J ADV COMPUT SC, V9, P162
   [Anonymous], 1996, Possible Worlds: The Social Dynamic of Virtual Reality Technology
   Anstadt SP, 2013, INT REV RES OPEN DIS, V14, P160
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Blum J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02172
   Boas Y.A. G. V., 2013, INTERACTIVE MULTIMED
   Boell SK, 2015, J INF TECHNOL-UK, V30, P161, DOI 10.1057/jit.2014.26
   Bogicevic V, 2019, TOURISM MANAGE, V74, P55, DOI 10.1016/j.tourman.2019.02.009
   Bordnick PS, 2012, RES SOCIAL WORK PRAC, V22, P293, DOI 10.1177/1049731511426880
   Borsci S, 2016, VIRTUAL REAL-LONDON, V20, P41, DOI 10.1007/s10055-015-0281-5
   Bouzit M, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P145, DOI 10.1109/HAPTIC.2002.998952
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bramley I, 2018, INT J MARKET RES, V60, P344, DOI 10.1177/1470785318767287
   Cardos RAI, 2017, COMPUT HUM BEHAV, V72, P371, DOI 10.1016/j.chb.2017.03.007
   Carlson P, 2015, IEEE T VIS COMPUT GR, V21, P770, DOI 10.1109/TVCG.2015.2393871
   Juan MC, 2011, INT J HUM-COMPUT INT, V27, P436, DOI 10.1080/10447318.2011.552059
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Caro A., 2006, Decisions Marketing, V41, P43, DOI DOI 10.7193/DM.041.43.52
   Choi SH, 2008, COMPUT IND, V59, P477, DOI 10.1016/j.compind.2007.12.003
   Corbetta D, 2015, J PHYSIOTHER, V61, P117, DOI 10.1016/j.jphys.2015.05.017
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   CyberGlove Systems, 2020, CYBERGRASP
   Czub M, 2018, INT J HUM-COMPUT INT, V34, P1045, DOI 10.1080/10447318.2017.1412144
   de Rooij IJM, 2016, PHYS THER, V96, P1905, DOI 10.2522/ptj.20160054
   Dobrowolski P, 2014, CYBERPSYCH BEH SOC N, V17, P125, DOI 10.1089/cyber.2012.0613
   Dunn J, 2017, VISUAL HIST NINTENDO
   Ferrer-Garcia M, 2019, CYBERPSYCH BEH SOC N, V22, P60, DOI 10.1089/cyber.2017.0675
   Fink A., 2005, CONDUCTING RES LIT R
   Flavián C, 2019, J TRAVEL TOUR MARK, V36, P847, DOI 10.1080/10548408.2019.1618781
   Fodor LA, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28113-6
   Gerçeker GÖ, 2018, J PERIANESTH NURS, V33, P981, DOI 10.1016/j.jopan.2017.12.010
   Gleasure R, 2016, J ASSOC INF SYST, V17, P708, DOI 10.17705/1jais.00439
   Glennon C, 2018, ONCOL NURS FORUM, V45, P545, DOI 10.1188/18.ONF.545-552
   Glueck AC, 2020, VIRTUAL REAL-LONDON, V24, P223, DOI 10.1007/s10055-019-00392-y
   Gonzalez-Franco M, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00003
   Gordon NS, 2011, COMPUT HUM BEHAV, V27, P2123, DOI 10.1016/j.chb.2011.06.006
   Gumaa M, 2019, PHYS THER, V99, P1304, DOI 10.1093/ptj/pzz093
   Guo CL, 2015, J CLIN NURS, V24, P115, DOI 10.1111/jocn.12626
   Huang TL, 2019, J RETAIL CONSUM SERV, V47, P251, DOI 10.1016/j.jretconser.2018.11.016
   Igna R, 2014, J EVID-BASED PSYCHOT, V14, P229
   igroup.org, 2016, IGR PRES QUEST IPQ O
   Ijsselsteijn W, 2003, EMERG COMMUNICAT, V5, P3
   Israel K, 2019, J HOSP TOUR TECHNOL, V10, P473, DOI [10.1108/jhtt-03-2018-0020, 10.1108/JHTT-03-2018-0020]
   Javornik A, 2016, J RETAIL CONSUM SERV, V30, P252, DOI 10.1016/j.jretconser.2016.02.004
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jo D, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-018-0162-5
   Kalawsky RS, 1996, AGOCG REPORT EXPLOIT
   Karafotias G, 2018, IEEE T HAPTICS, V11, P185, DOI 10.1109/TOH.2017.2781693
   Kawulich BB, 2019, VIRTUAL REAL-LONDON, V23, P375, DOI 10.1007/s10055-018-0353-4
   Kim IC, 2012, J PHYS THER SCI, V24, P755, DOI 10.1589/jpts.24.755
   Krumins A, 2017, HAPTIC BODYSUITS STR
   Ku J, 2019, CYBERPSYCH BEH SOC N, V22, P132, DOI 10.1089/cyber.2018.0261
   Kumar R, 2017, US Patent, Patent No. [9,600,067 B2, 9600067]
   Laha B, 2012, IEEE T VIS COMPUT GR, V18, P597, DOI 10.1109/TVCG.2012.42
   Latif UK, 2020, VISUAL COMPUT, V36, P1491, DOI 10.1007/s00371-019-01745-z
   Lau KW, 2015, LEARN ORGAN, V22, P289, DOI 10.1108/TLO-11-2014-0063
   Lee CH, 2014, HONG KONG PHYSIOTHER, V32, P51, DOI 10.1016/j.hkpj.2014.04.002
   Lee Jin, 2017, J Phys Ther Sci, V29, P1586, DOI 10.1589/jpts.29.1586
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Li CY, 2017, IEEE T VIS COMPUT GR, V23, P1388, DOI 10.1109/TVCG.2017.2656958
   Liberati N, 2016, AI SOC, V31, P17, DOI 10.1007/s00146-014-0543-x
   Liberati N, 2012, INT SYM MIX AUGMENT, DOI 10.1109/ISMAR-AMH.2012.6483983
   Lima J, 2018, BEHAV COGN PSYCHOTH, V46, P251, DOI 10.1017/S1352465817000674
   Lombard M., 2013, MEASURING PRESENCE T
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Loreto-Quijada D, 2014, CYBERPSYCH BEH SOC N, V17, P353, DOI 10.1089/cyber.2014.0057
   Manzoni GM, 2016, CYBERPSYCH BEH SOC N, V19, P134, DOI 10.1089/cyber.2015.0208
   Martínez-Navarro J, 2019, J BUS RES, V100, P475, DOI 10.1016/j.jbusres.2018.10.054
   Maskey M, 2019, J AUTISM DEV DISORD, V49, P1912, DOI 10.1007/s10803-018-3861-x
   Mclay RN, 2017, CYBERPSYCH BEH SOC N, V20, P218, DOI 10.1089/cyber.2016.0554
   McLay RN, 2011, CYBERPSYCH BEH SOC N, V14, P223, DOI 10.1089/cyber.2011.0003
   McMahan A., 2003, The Video Game Reader, V67, P86
   Meng FX, 2014, BEHAV INFORM TECHNOL, V33, P132, DOI 10.1080/0144929X.2013.857432
   Merel T, 2017, REALITY VR AR GROWTH
   Michaliszyn D, 2010, CYBERPSYCH BEH SOC N, V13, P689, DOI 10.1089/cyber.2009.0277
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Montero-López E, 2016, BEHAV RES METHODS, V48, P223, DOI 10.3758/s13428-015-0565-4
   Motraghi TE, 2014, J CLIN PSYCHOL, V70, P197, DOI 10.1002/jclp.22051
   Muhanna MA, 2015, J KING SAUD UNIV-COM, V27, P344, DOI 10.1016/j.jksuci.2014.03.023
   Murcia-López M, 2018, IEEE T VIS COMPUT GR, V24, P1574, DOI 10.1109/TVCG.2018.2793638
   Narayan M., 2005, P ACM S VIRT REAL SO, P78, DOI DOI 10.1145/1101616.1101632
   Negut A, 2016, COMPUT HUM BEHAV, V54, P414, DOI 10.1016/j.chb.2015.08.029
   Ng YL, 2019, COMPUT HUM BEHAV, V99, P278, DOI 10.1016/j.chb.2019.05.026
   Nilsson N.C., 2016, HUMAN TECHNOLOGY, V12, P108, DOI [10.17011/ht/urn.201611174652, DOI 10.17011/HT/URN.201611174652]
   Nilsson S, 2011, IEEE T VIS COMPUT GR, V17, P1380, DOI 10.1109/TVCG.2010.249
   Okoli C, 2020, PREV CHRONIC DIS, V17, DOI 10.5888/pcd17.190359
   Oleksy T, 2016, COMPUT HUM BEHAV, V57, P11, DOI 10.1016/j.chb.2015.12.014
   Paré G, 2007, J AM MED INFORM ASSN, V14, P269, DOI 10.1197/jamia.M2270
   Paré G, 2016, EUR J INFORM SYST, V25, P493, DOI 10.1057/s41303-016-0020-3
   Paré G, 2015, INFORM MANAGE-AMSTER, V52, P183, DOI 10.1016/j.im.2014.08.008
   Parsons TD, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7040042
   Parveau M, 2018, PROCEDIA COMPUT SCI, V141, P263, DOI 10.1016/j.procs.2018.10.180
   Perry J.S., 2018, IBM developerWorks, P1
   Pickering C, 2015, STUD HIGH EDUC, V40, P1756, DOI 10.1080/03075079.2014.914907
   Pickering C, 2014, HIGH EDUC RES DEV, V33, P534, DOI 10.1080/07294360.2013.841651
   Piskorz J., 2014, POL PSYCHOL BULL, V45, P480
   Regenbrecht H, 2002, PRESENCE-TELEOP VIRT, V11, P425, DOI 10.1162/105474602760204318
   Reger GM, 2016, J CONSULT CLIN PSYCH, V84, P946, DOI 10.1037/ccp0000134
   Rehman U, 2020, BEHAV INFORM TECHNOL, V39, P1225, DOI 10.1080/0144929X.2019.1660805
   Repetto C, 2013, PERS UBIQUIT COMPUT, V17, P253, DOI 10.1007/s00779-011-0467-0
   Rodríguez C, 2018, INT J CLIN HLTH PSYC, V18, P254, DOI 10.1016/j.ijchp.2018.06.003
   Ronchi E, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1873
   Rowe F, 2014, EUR J INFORM SYST, V23, P241, DOI 10.1057/ejis.2014.7
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Sadowski W, 2002, HUM FAC ER, P791
   Schoonheim M, 2014, BMC MED EDUC, V14, DOI 10.1186/1472-6920-14-36
   Schryen G, 2015, COMMUN ASSOC INF SYS, V37, P286
   Schryen Guido., 2017, Communications of the Association for Information Systems, V41, DOI [DOI 10.17705/1CAIS.04130, 10.17705/1CAIS.04130]
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Solomon B., 2014, Facebook Buys Oculus, Virtual Reality Gaming Startup, For $2 Billion
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Suso-Ribera C, 2019, CYBERPSYCH BEH SOC N, V22, P31, DOI 10.1089/cyber.2017.0672
   Tang YM, 2020, VIRTUAL REAL-LONDON, V24, P797, DOI 10.1007/s10055-020-00427-9
   Teel E, 2016, NEUROPSYCHOLOGY, V30, P474, DOI 10.1037/neu0000261
   Templier M, 2018, EUR J INFORM SYST, V27, P503, DOI 10.1080/0960085X.2017.1398880
   Thompson C, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00129
   Thompson T, 2011, INT J CLIN EXP HYP, V59, P122, DOI 10.1080/00207144.2011.522917
   Turk V, 2016, FACE ELECTRODES LET
   UQO Cyberpsychology Lab, 2002, PRES QUEST
   Valtchanov D, 2010, CYBERPSYCH BEH SOC N, V13, P503, DOI 10.1089/cyber.2009.0308
   Van Baren J, 2004, MEASURING PRESENCE G
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
   vom Brocke J, 2015, COMMUN ASSOC INF SYS, V37, P205
   Webster J, 2002, MIS QUART, V26, pXIII
   Wechsler TF, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01758
   Westerfield G, 2015, INT J ARTIF INTELL E, V25, P157, DOI 10.1007/s40593-014-0032-x
   Wiederhold MD, 2019, CYBERPSYCH BEH SOC N, V22, P122, DOI 10.1089/cyber.2018.0027
   Wilkerson W, 2008, ACAD EMERG MED, V15, P1152, DOI 10.1111/j.1553-2712.2008.00223.x
   Wissmath B, 2010, VIRTUAL REAL-LONDON, V14, P43, DOI 10.1007/s10055-009-0127-0
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yang S, 2019, J MANAGE INFORM SYST, V36, P789, DOI 10.1080/07421222.2019.1628894
   Yang Z, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01703
   Yoo SC, 2018, NONPROFIT MANAG LEAD, V29, P11, DOI 10.1002/nml.21315
NR 140
TC 49
Z9 54
U1 16
U2 125
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 773
EP 799
DI 10.1007/s10055-020-00492-0
EA JAN 2021
PG 27
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000604533200001
DA 2024-07-18
ER

PT J
AU Nguyen, TV
   Kamma, S
   Adari, V
   Lesthaeghe, T
   Boehnlein, T
   Kramb, V
AF Nguyen, Tam V.
   Kamma, Somaraju
   Adari, Vamsi
   Lesthaeghe, Tyler
   Boehnlein, Thomas
   Kramb, Victoria
TI Mixed reality system for nondestructive evaluation training
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed reality; Nondestructive evaluation; Virtual reality; Simulation
ID AUGMENTED REALITY
AB nondestructive evaluation (NDE) is an analysis technique used to evaluate the properties of a material, component, structure or system without causing damage. In this paper, we introduce a novel mixed reality system for NDE training. In particular, we model and simulate the inspected object and the inspection probe. The operator trainees with the wearable headsets are able to move and zoom the inspected object in a mixed environment, i.e., reality with virtual objects overlaid. In addition, the trainees use their gaze, gesture, and voice to control and interact with the virtual objects within the NDE training session. They can also access the help manual in order to follow the training instruction. The system is successfully operated on HoloLens, the state-of-the-art mixed reality headset. Evaluational results demonstrate that the use of mixed reality training provides significant benefit for the potential technician trainees.
C1 [Nguyen, Tam V.; Kamma, Somaraju; Adari, Vamsi] Univ Dayton, Dept Comp Sci, Dayton, OH 45469 USA.
   [Lesthaeghe, Tyler; Boehnlein, Thomas; Kramb, Victoria] Univ Dayton, Res Inst, NDE Engn Grp, Dayton, OH 45469 USA.
C3 University System of Ohio; University of Dayton; University System of
   Ohio; University of Dayton
RP Nguyen, TV (corresponding author), Univ Dayton, Dept Comp Sci, Dayton, OH 45469 USA.
EM tamnguyen@udayton.edu
RI Nguyen, Tam/AAU-6504-2020
OI Nguyen, Tam/0000-0003-0236-7992; Adari, Vamsi Charan/0000-0002-0727-5635
FU National Science Foundation (NSF) [2025234]; UD/UDRI Research Fellowship
   Program
FX This project is funded under National Science Foundation (NSF) under
   Grant No. 2025234 and UD/UDRI Research Fellowship Program.
CR Amza CG, 2018, AIP CONF PROC, V1932, DOI 10.1063/1.5024152
   [Anonymous], 2009, 21 CENTURY COMMUNICA
   [Anonymous], 2003, PRESENCE-VIRTUAL AUG, DOI [DOI 10.1162/105474603322955950, 10.1162/105474603322955950]
   Avgoustinov N., 2011, GLOBAL PRODUCT DEV, P705, DOI DOI 10.1007/978-3-642-15973-2_71
   Bozgeyikli L, 2018, LECT NOTES COMPUT SC, V10908, P48, DOI 10.1007/978-3-319-92052-8_5
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chicioreanu TD, 2018, ELEARN SOFTW EDUC, P13, DOI 10.12753/2066-026X-18-143
   Christou CG, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P531, DOI 10.1109/VR.2018.8446535
   De Crescenzio F, 2011, IEEE COMPUT GRAPH, V31, P96, DOI 10.1109/MCG.2011.4
   Eschen H, 2018, PROCEDIA MANUF, V19, P156, DOI 10.1016/j.promfg.2018.01.022
   Fiorentino M, 2014, COMPUT IND, V65, P270, DOI 10.1016/j.compind.2013.11.004
   Gopalan V., 2016, REV FACULT INGEN, V31, P27
   HENDERSON S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI DOI 10.1109/TVCG.2010.245
   Henderson SJ, 2009, INT SYM MIX AUGMENT, P135, DOI 10.1109/ISMAR.2009.5336486
   Kaur K, 1997, HUMAN-COMPUTER INTERACTION - INTERACT '97, P636
   Kim J, 1996, REV PROG Q, V15, P897
   Ma Minhua., 2014, Virtual, Augmented Reality and Serious Games for Healthcare 1, V1, DOI DOI 10.1007/978-3-642-54816-1
   Microsoft HoloLens, MIX REAL TECHN
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Moro C, 2017, ANAT SCI EDUC, V10, P549, DOI 10.1002/ase.1696
   Nguyen TV, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2964284.2973807
   Nguyen TV, 2016, MULTIMED TOOLS APPL, V75, P12351, DOI 10.1007/s11042-016-3435-x
   Nguyen Tam V., 2012, PROC ACM INT C MULTI, P239
   Nguyen TV, 2018, P INT C UB INF MAN C, P3
   Omer, 2018, P EUR C COMP MECH, P1
   Suárez-Warden F, 2015, PROCEDIA COMPUT SCI, V75, P17, DOI 10.1016/j.procs.2015.12.190
   Urbas U, 2019, PROC CIRP, V81, P832, DOI 10.1016/j.procir.2019.03.208
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
NR 28
TC 9
Z9 10
U1 4
U2 41
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 709
EP 718
DI 10.1007/s10055-020-00483-1
EA NOV 2020
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000591269300001
DA 2024-07-18
ER

PT J
AU Wang, YB
   Hu, YZ
   Chen, Y
AF Wang, Yanbin
   Hu, Yizhou
   Chen, Yu
TI An experimental investigation of menu selection for immersive virtual
   environments: fixed versus handheld menus
SO VIRTUAL REALITY
LA English
DT Article
DE Menu interface; 3D selection; Virtual environment
ID DESIGN; GAZE
AB With the development of consumer-grade virtual reality (VR) systems, the interface and interaction design for immersive virtual environments have become a critical issue for VR application designers and developers. The previous design experience from conventional VR applications may not be effective anymore. This work investigated two types of menu interfaces (fixed menu and handheld menu) and three selection techniques, hand pointing with button press (Hand-BP), head pointing with button press (Head-BP), and head pointing with dwell (Head-DW), based on performance and subjective assessment. Results showed that the best performing selection technique for fixed menu was Hand-BP, while Head-BP was the most suitable and preferred selection technique for handheld menu. The limitations of different menu interfaces and selection techniques were discussed, and solutions were proposed to overcome the limitations that were found in the experiment. Based on the findings of this study, design guidelines were provided to help designers and developers choose the right menu interface and selection technique for different contexts of use and user groups.
C1 [Wang, Yanbin; Hu, Yizhou; Chen, Yu] Nanjing Univ Aeronaut & Astronaut, Dept Ind Design, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Wang, YB (corresponding author), Nanjing Univ Aeronaut & Astronaut, Dept Ind Design, Nanjing, Jiangsu, Peoples R China.
EM feihongie@gmail.com
RI Chen, Yu/B-7473-2013
OI Chen, Yu/0000-0001-9545-6761; Wang, Yanbin/0000-0003-0459-7388
FU Fundamental Research Funds for the Central Universities of China
   [3082018NS2018034]
FX The authors are grateful to the study participants for their
   contributions to the research. We also want to thank the anonymous
   reviewers for their valuable comments. This work was supported by the
   Fundamental Research Funds for the Central Universities of China
   (Project NO. 3082018NS2018034).
CR [Anonymous], 2004, P 8 INT IMMERSIVE PR
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Bowman D. A., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P26, DOI 10.1145/323663.323667
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman DA, 2001, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2001.913781
   Bowman DA, 1998, PRESENCE-TELEOP VIRT, V7, P478, DOI 10.1162/105474698565866
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Choe M, 2019, INT J HUM-COMPUT INT, V35, P620, DOI 10.1080/10447318.2018.1484054
   Fang YM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163215
   Figueiredo L, 2018, COMPUT GRAPH-UK, V77, P108, DOI 10.1016/j.cag.2018.10.006
   Gerber D., 2004, IPT 2004, P149
   Hand C, 1997, COMPUT GRAPH FORUM, V16, P269, DOI 10.1111/1467-8659.00194
   Harms P, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3301423
   HART S G, 1988, P139
   Jacob R.J., 1990, P SIGCHI C HUM FACT, P11, DOI DOI 10.1145/97243.97246
   Jeong S, 2016, INT J IND ERGONOM, V53, P205, DOI 10.1016/j.ergon.2016.01.001
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Lin CHJ, 2015, APPL ERGON, V48, P154, DOI 10.1016/j.apergo.2014.12.001
   Lindeman RW, 1999, P IEEE VIRT REAL ANN, P205, DOI 10.1109/VR.1999.756952
   Myers A., 2012, Experimental Psychology, V7th
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Salomoni P, 2017, J MULTIMODAL USER IN, V11, P173, DOI 10.1007/s12193-016-0236-5
   Statista, 2018, SHAR VIRT REAL HEAD
   Steed A, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P103, DOI 10.1109/TRIDUI.2006.1618279
   Wang Y, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P577, DOI 10.1109/ICIVC.2017.7984621
   Wang YB, 2013, VISUAL COMPUT, V29, P323, DOI 10.1007/s00371-012-0735-7
   Wingrave C. A., 2005, P HCI INT, P61
   Wolf D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376876
   Yan YK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173616
NR 29
TC 8
Z9 8
U1 11
U2 39
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 409
EP 419
DI 10.1007/s10055-020-00464-4
EA AUG 2020
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000558882800001
DA 2024-07-18
ER

PT J
AU Brivio, E
   Serino, S
   Cousa, EN
   Zini, A
   Riva, G
   De Leo, G
AF Brivio, Eleonora
   Serino, Silvia
   Negro Cousa, Erica
   Zini, Andrea
   Riva, Giuseppe
   De Leo, Gianluca
TI Virtual reality and 360° panorama technology: a media comparison to
   study changes in sense of presence, anxiety, and positive emotions
SO VIRTUAL REALITY
LA English
DT Article
DE Computer-simulated environment; 360 degrees Technology; Anxiety; Sense
   of presence; Virtual reality; Mood; Case comparison
ID HEART-RATE-VARIABILITY; EXPOSURE THERAPY; ENVIRONMENTS; MEMORY;
   PERFORMANCE; VALIDATION; IMMERSION; DISORDER; INCREASE
AB Recently, 360 degrees panorama technologies have been used to create videos and pictures of real and virtual environments, thus opening new possibilities for psychological research. The aim of this study is to compare a 360 degrees real panorama environment to a computer-simulated one to verify if they are equally efficient in generating sense of presence, emotions, and relaxation in individuals. The study employs a 3 x 2 mixed factorial design. Forty participants took part in the study and were assessed on self-reported anxiety and mood levels before and during the virtual reality (VR) experience of a relaxing video in computer graphics or shot in 360 degrees. After the experience, sense of presence and experience ratings were also collected. Heart rate data during the experience were also used. Both inferential and Bayesian analyses showed a lack of effect of the manipulation: there is no difference between a 360 degrees panorama environment and a simulated environment in generating sense of presence, anxiety reduction, and in improving emotional states. These results highlight the feasibility of using a 360 degrees real panorama VR if the participants' task is passive and requires no active exploration of the environment, as the development of the 360 degrees video is easier and cheaper than the one required by a computer-simulated environment.
C1 [Brivio, Eleonora; Negro Cousa, Erica; Zini, Andrea; De Leo, Gianluca] Augusta Univ, Coll Allied Hlth Sci, Augusta, GA 30912 USA.
   [Brivio, Eleonora; Riva, Giuseppe] Univ Cattolica Sacro Cuore, Ctr Studi & Ric Psicol Comunicaz, Dept Psychol, Milan, Italy.
   [Serino, Silvia] Univ Hosp Lausanne CHUV, Dept Clin Neurosci, MySpace Lab, Lausanne, Switzerland.
   [Riva, Giuseppe] Ist Auxol Italiano IRCCS, Appl Technol Neuropsychol Lab, Milan, Italy.
C3 University System of Georgia; Augusta University; Catholic University of
   the Sacred Heart; University of Lausanne; Centre Hospitalier
   Universitaire Vaudois (CHUV); IRCCS Istituto Auxologico Italiano
RP Brivio, E (corresponding author), Augusta Univ, Coll Allied Hlth Sci, Augusta, GA 30912 USA.; Brivio, E (corresponding author), Univ Cattolica Sacro Cuore, Ctr Studi & Ric Psicol Comunicaz, Dept Psychol, Milan, Italy.
EM eleonora.brivio@unicatt.it
RI Brivio, Eleonora/F-3057-2013; Riva, Giuseppe/C-5917-2008; Serino,
   Silvia/AAM-5297-2020
OI Brivio, Eleonora/0000-0002-7305-6457; Riva,
   Giuseppe/0000-0003-3657-106X; Serino, Silvia/0000-0002-8422-1358
CR Aardema F, 2010, CYBERPSYCH BEH SOC N, V13, P429, DOI 10.1089/cyber.2009.0164
   Aitamurto T, 2018, P 2018 CHI C HUM FAC, P1
   Alsina-Jurnet I, 2010, INT J HUM-COMPUT ST, V68, P788, DOI 10.1016/j.ijhcs.2010.07.001
   Anderson PL, 2013, J CONSULT CLIN PSYCH, V81, P751, DOI 10.1037/a0033559
   [Anonymous], KEN EDG
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Baños RM, 2000, CYBERPSYCHOL BEHAV, V3, P327, DOI 10.1089/10949310050078760
   Baños RM, 2008, CYBERPSYCHOL BEHAV, V11, P1, DOI 10.1089/cpb.2007.9936
   Baños RM, 2006, LECT NOTES COMPUT SC, V3962, P7
   Barnes SJ, 2016, IMPLIC POTENTIAL, DOI [10.2139/ssrn.2909100, DOI 10.2139/SSRN.2909100]
   Baus O, 2017, VIRTUAL REAL-LONDON, V21, P59, DOI 10.1007/s10055-016-0299-3
   Bessa M, 2016, PROCEEDINGS OF THE XVII INTERNATIONAL CONFERENCE ON HUMAN COMPUTER INTERACTION INTERACCION 2016, DOI 10.1145/2998626.2998669
   Bindman SW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174031
   Bissonnette J, 2016, VIRTUAL REAL-LONDON, V20, P71, DOI 10.1007/s10055-016-0283-y
   Bouchard S, 2017, BRIT J PSYCHIAT, V210, P276, DOI 10.1192/bjp.bp.116.184234
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Calvo RA, 2013, COMPUT INTELL-US, V29, P527, DOI 10.1111/j.1467-8640.2012.00456.x
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   Clarke S, 2014, BMC MED EDUC, V14, DOI 10.1186/1472-6920-14-153
   Cousa EN, 2019, CYBERPSYCH BEH SOC N, V22, P76, DOI 10.1089/cyber.2017.0720
   Coxon M, 2016, VIRTUAL REAL-LONDON, V20, P203, DOI 10.1007/s10055-016-0292-x
   Csikszentmihalyi M., 1998, Finding flow: The psychology of engagement with everyday life
   Cummings B, 2012, TLS-TIMES LIT SUPPL, P24
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Davey HM, 2007, J CLIN EPIDEMIOL, V60, P356, DOI 10.1016/j.jclinepi.2006.07.015
   De Leo G, 2014, SIMUL HEALTHC, V9, P1, DOI 10.1097/SIH.0b013e3182a99dd9
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Dimitriev DA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146131
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Dishman RK, 2000, INT J PSYCHOPHYSIOL, V37, P121, DOI 10.1016/S0167-8760(00)00085-4
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Felnhofer A, 2014, CYBERPSYCH BEH SOC N, V17, P310, DOI 10.1089/cyber.2013.0472
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Gorini Alessandra, 2008, Expert Rev Neurother, V8, P215, DOI 10.1586/14737175.8.2.215
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P290, DOI 10.1162/pres.1996.5.3.290
   Homma I, 2008, EXP PHYSIOL, V93, P1011, DOI 10.1113/expphysiol.2008.042424
   Kang H, 2013, KOREAN J ANESTHESIOL, V64, P402, DOI 10.4097/kjae.2013.64.5.402
   Krijn M, 2004, CLIN PSYCHOL REV, V24, P259, DOI 10.1016/j.cpr.2004.04.001
   Luyk N H, 1988, Anesth Prog, V35, P121
   Mania K, 2001, CYBERPSYCHOL BEHAV, V4, P247, DOI 10.1089/109493101300117938
   McCarthy PJ, 2010, J CLIN SPORT PSYCHOL, V4, P53, DOI 10.1123/jcsp.4.1.53
   Nelson R.J., 2013, Traumatology, V19, P171
   Noteboom JT, 2001, J APPL PHYSIOL, V91, P2093, DOI 10.1152/jappl.2001.91.5.2093
   Padrino-Barrios Carmelo, 2015, J Dent Hyg, V89, P372
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Paterniti S, 1999, PSYCHOSOM MED, V61, P77, DOI 10.1097/00006842-199901000-00013
   PRICE DD, 1983, PAIN, V17, P45, DOI 10.1016/0304-3959(83)90126-4
   Quintana DS, 2018, BMC PSYCHIATRY, V18, DOI 10.1186/s12888-018-1761-4
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Riva G, 2011, NEW IDEAS PSYCHOL, V29, P24, DOI 10.1016/j.newideapsych.2009.11.002
   Riva G, 2007, STUD HEALTH TECHNOL, V125, P394
   RUSSELL JA, 1985, J PERS SOC PSYCHOL, V48, P1290, DOI 10.1037/0022-3514.48.5.1290
   Sauzéon H, 2012, EXP PSYCHOL, V59, P99, DOI 10.1027/1618-3169/a000131
   See ZS, 2015, VIRTUAL REAL-LONDON, V19, P71, DOI 10.1007/s10055-014-0258-9
   Shen SH, 2016, NURS HEALTH SCI, V18, P223, DOI 10.1111/nhs.12257
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Smolentsev A, 2017, VIRTUAL REAL-LONDON, V21, P153, DOI 10.1007/s10055-017-0305-4
   Spielberger C.D., 1971, REV INTERAMERICANA P, V5, P145, DOI DOI 10.30849/RIP/IJP.V5I34.620
   Stupar-Rutenfrans S, 2017, CYBERPSYCH BEH SOC N, V20, P624, DOI 10.1089/cyber.2017.0174
   Triberti S, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02052
   Unity Technologies, 2015, UN SOFTW
   Van Doorn J., 2019, The JASP guidelines for conducting and reporting a Bayesian analysis, DOI [10.31234/osf.io/yqxfr, DOI 10.31234/OSF.IO/YQXFR]
   Villani D, 2012, INTERACT COMPUT, V24, P265, DOI 10.1016/j.intcom.2012.04.008
   Villani D., 2009, INT J HUMAN COMPUTER, V1, P35
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wiederhold MD, 2014, CYBERPSYCH BEH SOC N, V17, P359, DOI 10.1089/cyber.2014.0203
NR 66
TC 48
Z9 48
U1 2
U2 42
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 303
EP 311
DI 10.1007/s10055-020-00453-7
EA JUL 2020
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000546922500001
DA 2024-07-18
ER

PT J
AU De Gauquier, L
   Brengman, M
   Willems, K
   Van Kerrebroeck, H
AF De Gauquier, Laurens
   Brengman, Malaika
   Willems, Kim
   Van Kerrebroeck, Helena
TI Leveraging advertising to a higher dimension: experimental research on
   the impact of virtual reality on brand personality impressions
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Advertising; Brand personality; Brand attitude;
   Purchase intentions
ID PURCHASE INTENTIONS; MEDIATING ROLE; INFORMATION-TECHNOLOGY;
   CONSUMER-BEHAVIOR; COLLEGE-STUDENTS; USER ACCEPTANCE; EXPERIENCE;
   VIVIDNESS; ATTITUDE; STORE
AB As new advertising formats emerge, research regarding their effectiveness is called for. Since the emergence of virtual reality (VR) technology, several brands have started implementing VR advertising in their communication strategies. The research objective of this study is to examine whether mobile VR advertising can positively impact managerially relevant brand outcome variables [brand personality (BP) impressions, brand attitude and purchase intentions] compared to traditional 2D advertising. An experimental between-subjects design comprising 160 respondents reveals a significant difference in impact between 2D and VR advertising on three out of five BP dimensions (namely 'excitement', 'sophistication' and a marginal effect on 'ruggedness'). Furthermore, mobile VR advertising evokes significantly more positive consumer attitudes and higher purchase intentions than mobile 2D ads. The findings of this study imply that mobile VR advertising can be effective for brand managers who are in search of bringing their brands to life and who aim to obtain more positive consumer attitudes and higher purchase intentions towards their brands.
C1 [De Gauquier, Laurens; Brengman, Malaika; Willems, Kim; Van Kerrebroeck, Helena] Vrije Univ Brussel, Dept Business Mkt & Consumer Behav, Pl Laan 2 C2-12, B-1050 Brussels, Belgium.
   [Brengman, Malaika; Willems, Kim] Hasselt Univ, Dept Mkt & Strategy, Agoralaan Bldg D, B-3590 Diepenbeek, Belgium.
C3 Vrije Universiteit Brussel; Hasselt University
RP De Gauquier, L (corresponding author), Vrije Univ Brussel, Dept Business Mkt & Consumer Behav, Pl Laan 2 C2-12, B-1050 Brussels, Belgium.
EM laurens.de.gauquier@vub.be; malaika.brengman@vub.be; kim.willems@vub.be
OI De Gauquier, Laurens/0000-0002-4343-1412; Willems,
   Kim/0000-0002-0941-8599; Brengman, Malaika/0000-0001-9860-7107
CR Aaker DA, 2001, J MARKETING RES, V38, P485, DOI 10.1509/jmkr.38.4.485.18905
   Aaker JL, 1999, J MARKETING RES, V36, P45, DOI 10.2307/3151914
   Aaker JL, 1997, J MARKETING RES, V34, P347, DOI 10.2307/3151897
   Alcantara A, 2016, 12 TYPES NEW GADGETS
   Alvarez E, 2016, ENGADGET
   Anandkumar V., 2011, The International Research Journal of Social Science and Management, V1, P30
   Ang SH, 2006, J ADVERTISING, V35, P39, DOI 10.1080/00913367.2006.10639226
   [Anonymous], 2016, ADAGE
   [Anonymous], 2016, GARTNERS 2016 HYPE C
   Ataman B., 2003, Journal of Product & Brand Management, V12, P237, DOI 10.1108/10610420310485041
   Austin J.R., 2003, Journal of Strategic Marketing, V11, P77, DOI [DOI 10.1080/0965254032000104469, 10.1080/0965254032000104469]
   Avis M, 2011, ACR ASIA PACIFIC ADV
   Azoulay Audrey., 2003, BRAND MANAGEMENT, V11, P143, DOI DOI 10.1057/PALGRAVE.BM.2540162
   Barack L, 2016, BEST NEW YORK VR GUI
   Barnes S., 2016, SSRN ERN INNOVATION, DOI DOI 10.2139/SSRN.2909100
   Barton C., 2012, Millennial passions: Food, fashion, and friends
   Bhardwaj V, 2010, INT REV RETAIL DISTR, V20, P165, DOI 10.1080/09593960903498300
   Bhat B., 2001, CREAT INNOV MANAG, V10, P26
   Bonetti F, 2018, PROGR IS, P119, DOI 10.1007/978-3-319-64027-3_9
   Borsci S, 2016, VIRTUAL REAL-LONDON, V20, P41, DOI 10.1007/s10055-015-0281-5
   Bosmans A, 2006, J MARKETING, V70, P32, DOI 10.1509/jmkg.70.3.32
   Brakus JJ, 2009, J MARKETING, V73, P52, DOI 10.1509/jmkg.73.3.52
   Bromiley K, 2017, H M RELEASES NEW SPO
   Bruce M, 2006, J FASH MARK MANAG, V10, P329, DOI 10.1108/13612020610679303
   Caprara GV, 2001, J ECON PSYCHOL, V22, P377, DOI 10.1016/S0167-4870(01)00039-3
   Chen CS, 1998, P ACM S VIRT REAL SO, P1
   Chiu CM, 2014, INFORM SYST J, V24, P85, DOI 10.1111/j.1365-2575.2012.00407.x
   Chodorge S, 2018, USINE DIGITALE
   Choi YK, 2014, J BUS RES, V67, P2164, DOI 10.1016/j.jbusres.2014.04.026
   Coyle JR, 2001, J ADVERTISING, V30, P65, DOI 10.1080/00913367.2001.10673646
   Crabtree J., 2016, CNBC
   d'Astous A, 2007, J BUS RES, V60, P231, DOI 10.1016/j.jbusres.2006.11.005
   Davies Gary., 2004, CORP REPUT REV, V7, P125, DOI [10.1057/palgrave.crr.1540216, DOI 10.1057/PALGRAVE.CRR.1540216]
   Davis Ben., 2016, Econsultancy
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Toldos-Romero MD, 2015, EUR BUS REV, V27, P462, DOI 10.1108/EBR-03-2013-0046
   Debbabi S, 2010, J MARKET MANAG, V26, P967, DOI 10.1080/02672570903498819
   Dolatabadi H. R., 2012, INT J ACAD RES BUSIN, V2, P294
   Dolbec PY, 2013, J RETAILING, V89, P460, DOI 10.1016/j.jretai.2013.06.003
   Doucé L, 2013, J ENVIRON PSYCHOL, V36, P65, DOI 10.1016/j.jenvp.2013.07.006
   Dua T, 2014, DIGIDAY
   Edwards Steven M., 2001, Journal of Interactive Advertising, V2, P10
   Eisend M, 2013, MARKET LETT, V24, P205, DOI 10.1007/s11002-013-9232-7
   Epley N, 2007, PSYCHOL REV, V114, P864, DOI 10.1037/0033-295X.114.4.864
   Fennis BM, 2012, J BUS RES, V65, P861, DOI 10.1016/j.jbusres.2011.01.008
   Ferrandi J.-M., 2000, Proceedings of the 2000 Academy of Marketing Science Annual Conference, P7
   Field M, 2017, 10 BEST VIRTUAL REAL
   Fortin DR, 2005, J BUS RES, V58, P387, DOI 10.1016/S0148-2963(03)00106-1
   Fournier S, 1998, J CONSUM RES, V24, P343, DOI 10.1086/209515
   Freling TH, 2005, J BRAND MANAG, V13, P148, DOI 10.1057/palgrave.bm.2540254
   Garaus M, 2017, PSYCHOL MARKET, V34, P138, DOI 10.1002/mar.20980
   Gartner, 2017, GARTN HYP CYCL
   Geuens M, 2009, INT J RES MARK, V26, P97, DOI 10.1016/j.ijresmar.2008.12.002
   Goldsmith Elizabeth., 2012, AM J MANAGEMENT, P11
   Goldsmith R.E., 1991, Journal of the Academy of Marketing Science, V19, P209, DOI [DOI 10.1007/BF02726497, 10.1007/bf02726497, 10.1007/BF02726497]
   Govers Pascalle C. M., 2004, P 4 INT C DES EM ANK
   Grohmann B, 2009, J MARKETING RES, V46, P105, DOI 10.1509/jmkr.46.1.105
   Guppta K., 2015, FORBES
   Hartmann T, 2010, TELEPRESENCE MEDIA E
   Hess S., 2007, European Marketing Academy 36th Conference Proceedings, P22
   HOMER PM, 1990, J MARKETING RES, V27, P78, DOI 10.2307/3172553
   Hosany S, 2006, J BUS RES, V59, P638, DOI 10.1016/j.jbusres.2006.01.001
   Jaunt VR, 2015, N FAC CLIMB
   Jin SAA, 2010, CYBERPSYCH BEH SOC N, V13, P307, DOI 10.1089/cyber.2009.0098
   Keller K.L., 2009, Journal of Marketing Communications, V15, P139, DOI [10.1080/13527260902757530, DOI 10.1080/13527260902757530]
   Keller KA, 2001, TOXICOLOGY TESTING HANDBOOK, P1
   Keller PA, 1997, J CONSUM RES, V24, P295, DOI 10.1086/209511
   Kim CK, 2001, JPN PSYCHOL RES, V43, P195, DOI 10.1111/1468-5884.00177
   Kim H-S., 2000, J FASH MARK MANAG, V4, P243, DOI DOI 10.1108/EB022593
   King KW, 2017, AM ACAD ADVERTISING, P94
   Klein LR, 2003, J INTERACT MARK, V17, P41, DOI 10.1002/dir.10046
   Kwon JH, 2013, INT J HUM-COMPUT ST, V71, P978, DOI 10.1016/j.ijhcs.2013.07.003
   Landicho J, 2017, IMPROVE CUSTOMER EXP
   Lau K.W., 2016, ADV ADVERTISING RES, V6, P75
   Lee CW, 2017, EURASIA J MATH SCI T, V13, P3083, DOI 10.12973/eurasia.2017.00706a
   Lee H.J., 2013, ACAD MARKETING STUDI, V17, P85
   Lee HS, 2009, J SPORT MANAGE, V23, P41, DOI 10.1123/jsm.23.1.41
   Li H., 2001, Journal of Interactive Marketing, V15, P13, DOI [10.1002/dir.1013, DOI 10.1002/DIR.1013]
   Lim EAC, 2008, J BUS RES, V61, P225, DOI 10.1016/j.jbusres.2007.06.004
   Lin LY, 2010, J PROD BRAND MANAG, V19, P4, DOI 10.1108/10610421011018347
   Litvin X, 2016, TOURISM TRAVEL RES A
   Mandelbaum A, 2015, HOTELEXECUTIVE
   Mathwick C, 2001, J RETAILING, V77, P39, DOI 10.1016/S0022-4359(00)00045-2
   Mazaheri E, 2012, J SERV MARK, V26, P535, DOI 10.1108/08876041211266503
   McKnight CG, 2002, PSYCHOL SCHOOLS, V39, P677, DOI 10.1002/pits.10062
   Meenaghan T., 1995, J PROD BRAND MANAG, V4, P23, DOI DOI 10.1108/10610429510097672
   Microsoft, 2018, OC RIFT TOUCH
   Mikropoulos T.A., 2006, VIRTUAL REAL-LONDON, V10, P197, DOI DOI 10.1007/S10055-006-0039-1
   Milas G, 2007, J BUS RES, V60, P620, DOI 10.1016/j.jbusres.2006.06.011
   Millennialmedia, 2015, N FAC EXPL NEW CHANN
   Mooy S., 2002, J PRODUCT BRAND MANA, V11, P432, DOI DOI 10.1108/10610420210451625
   Morwitz VG, 2007, INT J FORECASTING, V23, P347, DOI 10.1016/j.ijforecast.2007.05.015
   Mueller S, 2011, INT J WINE BUS RES, V23, P125, DOI 10.1108/17511061111142990
   Murphy S, 2016, MCDONALDS HAPPY MEAL
   Muzellec L, 2017, J ADVERTISING RES, V57
   Mybryonic, 2016, 10 BEST US VIRT REAL
   Nah FFH, 2011, MIS QUART, V35, P731
   Nam J, 1997, BIOMETRICS, V53, P1422, DOI 10.2307/2533508
   Nandan S, 2005, J BRAND MANAG, V12, P264, DOI 10.1057/palgrave.bm.2540222
   Overmars S, 2015, INT REV RETAIL DISTR, V25, P236, DOI 10.1080/09593969.2014.988279
   Pantano E, 2014, INT J INFORM MANAGE, V34, P344, DOI 10.1016/j.ijinfomgt.2014.03.002
   Parasuraman A, 2015, J SERV RES-US, V18, P59, DOI 10.1177/1094670514539730
   Park SE, 2005, INT J HUM-COMPUT INT, V19, P7, DOI 10.1207/s15327590ijhc1901_3
   Petersen JA, 2015, J MARKETING RES, V52, P268, DOI 10.1509/jmr.14.0174
   Peterson RA, 2001, J CONSUM RES, V28, P450, DOI 10.1086/323732
   Peterson RA, 2014, J BUS RES, V67, P1035, DOI 10.1016/j.jbusres.2013.08.010
   Pine BJ, 1998, HARVARD BUS REV, V76, P97
   PUTO CP, 1984, ADV CONSUM RES, V11, P638
   Ramaseshan B, 2007, J BRAND MANAG, V14, P458, DOI 10.1057/palgrave.bm.2550090
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Segijn CM, 2017, HUM COMMUN RES, V43, P295, DOI 10.1111/hcre.12106
   Serrano B, 2016, COMPUT HUM BEHAV, V55, P1, DOI 10.1016/j.chb.2015.08.007
   Sharar Sam R, 2008, Expert Rev Neurother, V8, P1667, DOI 10.1586/14737175.8.11.1667
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Sherry JL, 2004, COMMUN THEOR, V14, P328, DOI 10.1093/ct/14.4.328
   SHIH C.F., 1998, EUR J MARKETING, V32, P655
   Simonson I, 2001, ANNU REV PSYCHOL, V52, P249, DOI 10.1146/annurev.psych.52.1.249
   SIRGY MJ, 1982, J CONSUM RES, V9, P287, DOI 10.1086/208924
   Spears N., 2004, Journal of Current Issues Research in Advertising, V26, P53, DOI DOI 10.1080/10641734.2004.10505164
   Statista, 2017, WORLDW RET E COMM SA
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stoyanova J., 2015, IEEE International Symposium on Innovations in Intelligent Systems and Applications (INISTA), P1
   Sung YJ, 2010, PSYCHOL MARKET, V27, P639, DOI 10.1002/mar.20349
   Supphellen M., 2003, International Journal of Advertising, V22, P203, DOI [DOI 10.1080/02650487.2003.11072849, https://doi.org/10.1080/02650487.2003.11072849]
   The North Face, 2017, N FAC MAIN PAG
   Thomas B.J., 2008, Vikalpa, V33, P49, DOI [DOI 10.1177/0256090920080304, 10.1177/0256090920080304.]
   Valette-Florence P, 2011, J BUS RES, V64, P24, DOI 10.1016/j.jbusres.2009.09.015
   van der Heijden H, 2003, EUR J INFORM SYST, V12, P41, DOI 10.1057/palgrave.ejis.3000445
   Van Kerrebroeck H, 2017, THESIS
   Van Kerrebroeck H, 2017, COMPUT HUM BEHAV, V77, P437, DOI 10.1016/j.chb.2017.07.019
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
   Van Kerrebroeck H, 2017, INT J RETAIL DISTRIB, V45, P892, DOI 10.1108/IJRDM-09-2016-0156
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2012, MIS QUART, V36, P157
   Verhagen T, 2011, INFORM MANAGE-AMSTER, V48, P201, DOI 10.1016/j.im.2011.02.004
   Walsh K. R., 2002, COMMUNICATIONS ASS I, V8, P20
   Wang RJH, 2015, J RETAILING, V91, P217, DOI 10.1016/j.jretai.2015.01.002
   Wijayanto G, 2015, P 2015 1 INT C EC BA
   Willems K, 2017, TECHNOL FORECAST SOC, V124, P228, DOI 10.1016/j.techfore.2016.10.066
   Willems K, 2017, INT J RETAIL DISTRIB, V45, P910, DOI 10.1108/IJRDM-10-2016-0177
   Willems K, 2012, J BUS RES, V65, P1487, DOI 10.1016/j.jbusres.2011.10.015
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yin A, 2015, NY TIMES
   Zarantonello L, 2013, INT J RES MARK, V30, P46, DOI 10.1016/j.ijresmar.2012.09.001
NR 145
TC 44
Z9 46
U1 14
U2 120
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2019
VL 23
IS 3
SI SI
BP 235
EP 253
DI 10.1007/s10055-018-0344-5
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA IR5QR
UT WOS:000481490500004
DA 2024-07-18
ER

PT J
AU Wu, CM
   Hsu, CW
   Lee, TK
   Smith, S
AF Wu, Chien-Min
   Hsu, Chih-Wen
   Lee, Tzu-Kuei
   Smith, Shana
TI A virtual reality keyboard with realistic haptic feedback in a fully
   immersive virtual environment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality haptic keyboard; Realistic haptic feedback; Simulated
   vibrations
AB This study presents a 3D virtual reality (VR) keyboard system with realistic haptic feedback. The system uses two five-fingered data gloves to track finger positions and postures, uses micro-speakers to create simulated vibrations, and uses a head-mounted display (HMD) for 3D display. When users press a virtual key in the VR environment, the system can provide realistic simulated key click haptic feedback to users. The results of this study show that the advantages of the haptic VR keyboard are that users can use it when wearing HMDs (users do not need to remove HMDs to use the VR keyboard), the haptic VR keyboard can pop-up display at any location in the VR environments (users do not need to go to a specific location to use an actual physical keyboard), and the haptic VR keyboard can be used to provide realistic key click haptic feedback (which other studies have shown enhances user performance). The results also show that the haptic VR keyboard system can be used to create complex vibrations that simulate measured vibrations from a real keyboard and enhance keyboard interaction in a fully immersive VR environment.
C1 [Wu, Chien-Min; Hsu, Chih-Wen; Lee, Tzu-Kuei; Smith, Shana] Natl Taiwan Univ, Dept Mech Engn, Taipei, Taiwan.
C3 National Taiwan University
RP Smith, S (corresponding author), Natl Taiwan Univ, Dept Mech Engn, Taipei, Taiwan.
EM ssmith@ntu.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST 104-2221-E-002 -066
   -MY2]
FX The authors would like to thank the Ministry of Science and Technology
   of Taiwan for providing support for this research under Contract MOST
   104-2221-E-002 -066 -MY2.
CR Aoki T., 2009, P INT C ADV COMP ENT, P115
   Bensmaïa S, 2005, PERCEPT PSYCHOPHYS, V67, P828, DOI 10.3758/BF03193536
   Chaparro BS, 2014, J USABILITY STUD, V9, P70
   Choi KS, 2014, LECT NOTES COMPUT SC, V8548, P244, DOI 10.1007/978-3-319-08599-9_37
   Du H, 2008, EUROGR TECH REP SER, P170
   Fontana F, 2014, P 2014 INT COMP MUS, P654
   Fukumoto M., 2001, CHI 01 EXTENDED ABST, P121, DOI DOI 10.1145/634067.634141
   Hashimoto Yuki., 2009, Proceedings of the International Conference on Advances in Computer Enterntainment Technology, P124
   Hayward V., 2000, P 8 S HAPTIC INTERFA, P1309
   Kim S., 2004, P 2004 ACM SIGGRAPH, P336
   Koskinen E, 2008, SPAA'08: PROCEEDINGS OF THE TWENTIETH ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P297
   Kyung KU, 2004, IEEE INT CONF ROBOT, P776
   Lylykangas J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3281
   Markov-Vetter D, 2012, P ACM SIGGRAPH VRCAI, P287
   Minamizawa K, 2007, P ACM SIGGRAPH 2007
   Olsson Pontus, 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P361, DOI 10.1007/978-3-642-31401-8_33
   Park G., 2011, P INT C HUM COMP INT, P11
   Romano JM, 2012, IEEE T HAPTICS, V5, P109, DOI [10.1109/TOH.2011.38, 10.1109/ToH.2011.38]
   Smith S, 2015, J VIBROENG, V17, P1004
   Sziebig G, 2009, C HUM SYST INTERACT, P403, DOI 10.1109/HSI.2009.5091014
   Tashiro K, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P1, DOI 10.1109/WHC.2009.4810877
   Tzafestas CS, 2008, PRESENCE-VIRTUAL AUG, V17, P212, DOI 10.1162/pres.17.2.212
   Wu Y, 2012, IDETC CIE 2012, P1481
NR 23
TC 51
Z9 58
U1 3
U2 40
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2017
VL 21
IS 1
BP 19
EP 29
DI 10.1007/s10055-016-0296-6
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA EN6MV
UT WOS:000396119000002
DA 2024-07-18
ER

PT J
AU Kim, S
   King, R
   Kamekawa, T
AF Kim, Sungyoung
   King, Richard
   Kamekawa, Toru
TI A cross-cultural comparison of salient perceptual characteristics of
   height channels for a virtual auditory environment
SO VIRTUAL REALITY
LA English
DT Article
DE Height-channel perception; Multichannel-reproduced virtual auditory
   environment; Cross-cultural comparison
AB Perceptual characteristics of virtual auditory environments from three listener groups were compared. To generate convincing and pleasing virtual auditory environments, acoustic impulse responses were measured in two venues using an innovative microphone array and convolved with two anechoic recordings. Subsequently, the convolved sound sources were assigned to loudspeakers (five horizontal channels and four height channels), and inter-channel level balances were optimized. The authors conducted a controlled listening test with two variables: height-channel configurations (eight conditions) and stimuli (four conditions-two musical selections times and two target venues) to determine the influence of (1) two control variables on the perceived appropriateness of virtual auditory environments and (2) the cultural background of three listener groups composed of participants from Canada (group 1, 11 subjects), the USA (group 2, 12 subjects), and Japan (group 3, 14 subjects). The data analysis revealed that the configuration variable (the height position of the loudspeakers) has a greater influence on perceived appropriateness than the stimulus variable for all three groups. In addition, the results showed that although group 1 data had a similar listening response pattern to group 2, the response of group 3 was different. A subsequent analysis of reported descriptors found that groups 1 and 2 chose height configurations that generated a "frontal" and "narrow" impression as a more appropriate virtual auditory environment, while group 3 chose the same characteristics but as a less appropriate environment. Groups 1 and 2 also described a less appropriate auditory environment with "wide, spacious, and surrounding" images that again were described by group 3 as more appropriate. While room acoustics and loudspeaker size also contributed to the overall modulation of listeners' judgment, the findings support the idea that cultural background affects perceptual responses to spatial sound and is therefore important in rendering a homogeneous experience of a virtual auditory environment for listeners in remote spaces.
C1 [Kim, Sungyoung] Rochester Inst Technol, Rochester, NY 14618 USA.
   [King, Richard] McGill Univ, Montreal, PQ, Canada.
   [Kamekawa, Toru] Tokyo Univ Arts, Tokyo, Japan.
C3 Rochester Institute of Technology; McGill University; Tokyo University
   of the Arts
RP Kim, S (corresponding author), Rochester Inst Technol, Rochester, NY 14618 USA.
EM sxkiee@rit.edu; richard.king@mcgill.ca; kamekawa@ms.geidai.ac.jp
CR ALWIN DF, 1985, PUBLIC OPIN QUART, V49, P535, DOI 10.1086/268949
   Anderson L. M., 1984, Journal of Arboriculture, V10, P45
   AURO Technologies, 2013, AURO 3D LIST FORM
   Blesser B., 2006, SPACES SPEAKS ARE YO
   Feys J, 2015, npIntFactRep: nonparametric interaction tests for factorial designs with repeated measures
   Giragama CNW, 2003, P AUD ENG SOC 115 IN
   Hamasaki K., 2005, P AUD ENG SOC 118 IN
   Herrington J.D., 1996, Journal of Services Marketing, V10, P26, DOI DOI 10.1108/08876049610114249
   Holman T., 2007, MUSIC TECHNOLOGY SER
   ITU-R, 2012, MULT STER PHON SOUND
   Iwamiya S., 1997, Journal of the Acoustical Society of Japan (E), V18, P319, DOI 10.1250/ast.18.319
   Karampourniotis A, 2014, J ACOUST SOC AM, V135, P2282
   Kim S., 2007, P 13 REG CONV AES TO
   Kim S, 2013, P AUD ENG SOC 135 IN
   Kim S, 2006, P AUD ENG SOC 28 INT
   Koichiro H, 2002, P AUD ENG SOC 113 IN
   Martens WL, 2008, J ACOUST SOC AM, V123, P3690
   Martens WL, 2007, P AUD ENG SOC 122 IN
   Namba S., 1991, Journal of the Acoustical Society of Japan (E), V12, P19, DOI 10.1250/ast.12.19
   OLIVE SE, 1989, J AUDIO ENG SOC, V37, P539
   Olive SE, 2004, P AUD ENG SOC 116 IN
   Olive SE, 2014, P AUD ENG SOC 135 IN
   Olive SE, 2004, P AUD ENG SOC 117 IN
   RUMSEY F, 2001, SPATIAL AUDIO MUSIC
   Varnum MEW, 2010, CURR DIR PSYCHOL SCI, V19, P9, DOI 10.1177/0963721409359301
   Woszczyk W, 2009, P 16 INT C SOUND VIB
NR 26
TC 8
Z9 9
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 149
EP 160
DI 10.1007/s10055-015-0269-1
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800002
DA 2024-07-18
ER

PT J
AU Choi, YJ
   Lee, JH
AF Choi, Yoon Jung
   Lee, Jang-Han
TI The effect of virtual covert sensitization on reducing alcohol craving
   in heavy social drinkers
SO VIRTUAL REALITY
LA English
DT Article
DE Covert sensitization; Virtual reality; Alcohol craving; Implicit
   cognition; Eye movement
ID ATTENTIONAL BIAS; IMPLICIT COGNITION; DEPENDENCE; AVERSION; REALITY;
   CUES; DRINKING; SMOKERS
AB Covert sensitization is an imagery-based aversive treatment for decreasing craving and inducing aversion toward abused substances. In the present study, we used virtual reality to enhance the effects of covert sensitization. The aim was to verify the effectiveness of virtual covert sensitization treatment in reducing heavy social drinkers' alcohol craving. The explicit and implicit measurements included a self-report questionnaire, alcohol-Implicit Association Test, eye-tracking test, and alcohol-Stroop test. To determine the baseline, we measured the alcohol craving in heavy social drinkers (N = 20) and light drinkers (N = 20). Furthermore, virtual covert sensitization treatment was administered to each participant for 10 min. Afterward, the same measurements as at baseline were repeated. Despite the one-time nature of the administered treatment, our results confirm the effectiveness of virtual covert sensitization based on the participants' changed implicit craving and explicit, self-reported craving. Therefore, virtual covert sensitization may be an effective intervention technique for alcohol addiction treatment.
C1 [Choi, Yoon Jung; Lee, Jang-Han] Chung Ang Univ, Dept Psychol, Seoul 156756, South Korea.
C3 Chung Ang University
RP Lee, JH (corresponding author), Chung Ang Univ, Dept Psychol, 221 Heukseok Dong, Seoul 156756, South Korea.
EM choiyj2010@hanmail.net; clipsy@cau.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2012-R1A1A2-008215]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (No. 2012-R1A1A2-008215).
CR ANANT SS, 1967, CAN PSYCHOLOG-PSYCHO, VA  8, P19, DOI 10.1037/h0083124
   Anderson PL, 2001, B MENNINGER CLIN, V65, P78, DOI 10.1521/bumc.65.1.78.18713
   [Anonymous], 1999, J KOREAN ACAD FAM ME
   Anton RF, 1999, ALCOHOL RES HEALTH, V23, P165
   ASHEM B, 1968, BEHAV RES THER, V6, P7, DOI 10.1016/0005-7967(68)90034-X
   Bordnick PS, 2008, ADDICT BEHAV, V33, P743, DOI 10.1016/j.addbeh.2007.12.010
   Bradley BP, 2003, PSYCHOL ADDICT BEHAV, V17, P66, DOI 10.1037/0893-164X.17.1.66
   CAUTELA JR, 1967, PSYCHOL REP, V20, P459, DOI 10.2466/pr0.1967.20.2.459
   Cho S, 2008, CYBERPSYCHOL BEHAV, V11, P302, DOI 10.1089/cpb.2007.0149
   Cox WM, 1999, DRUG ALCOHOL DEPEN, V55, P85, DOI 10.1016/S0376-8716(98)00186-0
   Czyzewska Maria, 2008, Eat Behav, V9, P303, DOI 10.1016/j.eatbeh.2007.10.008
   Draine S. C, 2004, INQUISIT 2 0 50401 C
   Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464
   Greenwald AG, 2003, J PERS SOC PSYCHOL, V85, P197, DOI 10.1037/0022-3514.85.2.197
   Houben K, 2007, ALCOHOL ALCOHOLISM, V42, P301, DOI 10.1093/alcalc/agm015
   Howard MO, 2001, AM J DRUG ALCOHOL AB, V27, P561, DOI 10.1081/ADA-100104519
   Kearney AJ, 2006, COGN BEHAV PRACT, V13, P167, DOI 10.1016/j.cbpra.2006.02.002
   Kraft T., 2005, Contemporary Hypnosis, V22, P202, DOI DOI 10.1002/CH.10
   Lusher J, 2004, DRUG ALCOHOL DEPEN, V75, P225, DOI 10.1016/j.drugalcdep.2004.03.004
   Maïano C, 2011, COMPUT HUM BEHAV, V27, P169, DOI 10.1016/j.chb.2010.07.020
   MEHRABIAN A, 1978, PSYCHOL REP, V43, P803, DOI 10.2466/pr0.1978.43.3.803
   Mogg K, 2003, ADDICTION, V98, P825, DOI 10.1046/j.1360-0443.2003.00392.x
   Mogg K, 2002, J PSYCHOPHARMACOL, V16, P385, DOI 10.1177/026988110201600416
   Ostafin BD, 2008, BEHAV RES THER, V46, P1210, DOI 10.1016/j.brat.2008.08.003
   Parks G.A., 2001, INT HDB ALCOHOL DEPE, P557
   Pieters S, 2010, ADDICT BEHAV, V35, P471, DOI 10.1016/j.addbeh.2009.12.022
   Riva G, 1999, J BEHAV THER EXP PSY, V30, P221, DOI 10.1016/S0005-7916(99)00018-X
   ROBINSON TE, 1993, BRAIN RES REV, V18, P247, DOI 10.1016/0165-0173(93)90013-P
   Rosenberg H, 2009, CLIN PSYCHOL REV, V29, P519, DOI 10.1016/j.cpr.2009.06.002
   Ryan F, 2002, ADDICT BEHAV, V27, P471, DOI 10.1016/S0306-4603(01)00183-6
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   SAUNDERS JB, 1993, ADDICTION, V88, P791, DOI 10.1111/j.1360-0443.1993.tb02093.x
   Smith JW, 1997, J ADDICT DIS, V16, P5, DOI 10.1300/J069v16n01_02
   SMITH JW, 1993, J SUBST ABUSE TREAT, V10, P359, DOI 10.1016/0740-5472(93)90021-S
   Tiffany ST, 2000, ADDICTION, V95, pS145, DOI 10.1046/j.1360-0443.95.8s2.3.x
   TIFFANY ST, 1990, PSYCHOL REV, V97, P147, DOI 10.1037/0033-295X.97.2.147
   Townshend JM, 2001, PSYCHOPHARMACOLOGY, V157, P67, DOI 10.1007/s002130100764
   Whitworth AB, 1996, LANCET, V347, P1438, DOI 10.1016/S0140-6736(96)91682-7
   Wiers RW, 2007, PHARMACOL BIOCHEM BE, V86, P263, DOI 10.1016/j.pbb.2006.09.021
   Wiers RW, 2006, CURR DIR PSYCHOL SCI, V15, P292, DOI 10.1111/j.1467-8721.2006.00455.x
   Wiers RW, 2002, J ABNORM PSYCHOL, V111, P648, DOI 10.1037/0021-843X.111.4.648
   Williams JMG, 1996, PSYCHOL BULL, V120, P3, DOI 10.1037/0033-2909.120.1.3
NR 42
TC 24
Z9 25
U1 0
U2 36
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2015
VL 19
IS 2
BP 111
EP 117
DI 10.1007/s10055-015-0264-6
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA CJ9MO
UT WOS:000355826700004
DA 2024-07-18
ER

PT J
AU See, ZS
   Cheok, AD
AF See, Zi Siang
   Cheok, Adrian David
TI Virtual reality 360 interactive panorama reproduction obstacles and
   issues
SO VIRTUAL REALITY
LA English
DT Article
DE Spherical panorama; High dynamic range imaging; Image reproduction;
   Virtual reality; Augmented reality
AB The research studies obstacles and issues for spherical panorama image reproduction. Virtual reality 360 interactive panorama presentation involves accurately reproduced spherical panorama images which can deliver pre-produced image information of the real-world location that allows user-controlled interactivity in virtual reality digital platforms with up to three hundred and sixty degrees of visibility. Spherical panorama image is also useful in various mixed and augmented reality applications. However, the photographic reproduction of spherical panorama image may tolerate various obstacles and issues that can cause visual abnormality. These can include parallax error, nadir angle difficulty, inconsistent white balance, insufficient dynamic range in multiple angle images, ghosting effect when working with high dynamic range imaging, high amount of multiple angle source images to manage correctly and overall lengthy acquisition time. Biased reproduction of spherical panorama would be inadequate to record and report authentic visual information. This case study investigation provides an overview of the occurrence of potential obstacles and issues with the intention of acquiring high-fidelity spherical panorama photographic reproduction.
C1 [See, Zi Siang] Reina Imaging, Kuala Lumpur, Malaysia.
   [See, Zi Siang] Univ Tunku Abdul Rahman, Kuala Lumpur, Malaysia.
   [Cheok, Adrian David] City Univ London, London EC1V 0HB, England.
C3 Universiti Tunku Abdul Rahman (UTAR); City University London
RP See, ZS (corresponding author), Reina Imaging, Kuala Lumpur, Malaysia.
EM zisiang@reina.com.my; adriancheok@mixedrealitylab.org
RI Cheok, Adrian David/AAT-6141-2021; See, Zi Siang/AGA-4453-2022
OI Cheok, Adrian David/0000-0001-6316-2339; See, Zi
   Siang/0000-0002-6079-176X
CR Andrews P, 2003, 360 DEGREE IMAGING P
   [Anonymous], THE PANORAMA
   [Anonymous], 1995, ART CASE STUDY RES
   Archos, 2014, ARCH VR GLASS JUMP M
   Arth C, 2011, 2011 10 IEEE INT S M
   Benosman R., 2001, PANORAMIC VISION SEN
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Chen E., 1995, SIGGRAPH 95
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   DiVerdi S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P19
   DiVerdi S, 2009, COMPUT GRAPH-UK, V33, P73, DOI 10.1016/j.cag.2008.11.002
   Felinto D, 2012, 38 LAT AM C INF CLEI
   Gardner R, 2012, DIGITAL TONES EXPOSU
   Gledhill D, 2003, COMPUT GRAPH-UK, V27, P435, DOI 10.1016/S0097-8493(03)00038-4
   Guan X-Y, 2009, 2009 INT C CYBERWORL
   Heidrich Wolfgang, ERIK REINHARD
   Imatest, 2012, IM US STEPCH
   Jacobs C., 2004, Interactive panoramas: Techniques for digital panoramic photography
   Langlotz T, 2014, P IEEE, V102, P155, DOI 10.1109/JPROC.2013.2294255
   Langlotz T, 2012, IEEE PERVAS COMPUT, V11, P56, DOI 10.1109/MPRV.2010.69
   Ravine M, 2012, MARS ROVER CAMERA PR
   Rehm L, 2009, D3X IN DEPTH REV
   Samsung, 2014, GEAR VR
   Schmidt Lutz, 2007, WHATS MEANING VR PHO, P1
   Ventura J, 2013, VIRTUAL REAL-LONDON, V17, P147, DOI 10.1007/s10055-012-0208-3
   Wagner D, 2010, P IEEE VIRT REAL ANN, P211, DOI 10.1109/VR.2010.5444786
   Warrington C, 2007, THESIS U OTTAWA
   Whiston S.C., 1993, J CAREER DEV, V19, P175
   Zang AR, 2012, SIGGR AS 2012
NR 29
TC 11
Z9 12
U1 2
U2 33
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2015
VL 19
IS 2
BP 71
EP 81
DI 10.1007/s10055-014-0258-9
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CJ9MO
UT WOS:000355826700001
DA 2024-07-18
ER

PT J
AU Ponto, K
   Kohlmann, J
   Tredinnick, R
AF Ponto, Kevin
   Kohlmann, Joe
   Tredinnick, Ross
TI DSCVR: designing a commodity hybrid virtual reality system
SO VIRTUAL REALITY
LA English
DT Article
DE Hybrid reality; Virtual reality; Display wall; Immersive systems;
   Commodity hardware; 3D; High resolution; Passive stereo
ID USER PERFORMANCE; DISPLAY; VISUALIZATION; MULTIMEDIA; IMMERSION; SIZE
AB This paper presents the design considerations, specifications, and lessons learned while building DSCVR, a commodity hybrid reality environment. Consumer technology has enabled a reduced cost for both 3D tracking and screens, enabling a new means for the creation of immersive display environments. However, this technology also presents many challenges, which need to be designed for and around. We compare the DSCVR System to other existing VR environments to analyze the trade-offs being made.
C1 [Ponto, Kevin; Kohlmann, Joe; Tredinnick, Ross] Wisconsin Inst Discovery, Madison, WI 53715 USA.
RP Ponto, K (corresponding author), Wisconsin Inst Discovery, Room 3176,330 N Orchard St, Madison, WI 53715 USA.
EM kponto@discovery.wisc.edu; jkohlmann@discovery.wisc.edu;
   rtredinnick@discovery.wisc.edu
FU Living Environments Laboratory; School of Human Ecology; UW-Madison
   Graduate School; Wisconsin Institute for Discovery
FX We would like to acknowledge the support of the Living Environments
   Laboratory, the School of Human Ecology, the UW-Madison Graduate School
   and the Wisconsin Institute for Discovery. We would specifically like to
   thank Vito Freese for his assistance with installation and Patricia
   Brennan, Kendra Kreutz, Andrew Wagner, John Hilgers, and Roberto Rengel
   for their support and assistance in this project.
CR Ainsworth R. A., 2011, ACQUISITION STEREO P
   Amatriain X, 2009, IEEE MULTIMEDIA, V16, P64, DOI 10.1109/MMUL.2009.35
   Arthur K., 1996, Conference Companion on Human Factors in Computing Systems, P29
   AVERY B, 2005, P 6 AUSTR C US INT A, V40, P79
   Bacim F., 2013, P GRAPH INT, P25
   Basu A., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P97, DOI 10.1109/3DUI.2012.6184191
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Clark RA, 2012, GAIT POSTURE, V36, P372, DOI 10.1016/j.gaitpost.2012.03.033
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   DeFanti TA, 2011, OPEN ENG, V1, P16, DOI 10.2478/s13531-010-0002-5
   Doerr KU, 2011, IEEE T VIS COMPUT GR, V17, P320, DOI 10.1109/TVCG.2010.59
   Eilemann S, 2009, IEEE T VIS COMPUT GR, V15, P436, DOI 10.1109/TVCG.2008.104
   Febretti A, 2013, IS T SPIE ELECT IMAG
   Heddle Bob., The new generation kinect for windows sensor is coming next year
   Higgins T., 2010, UNITY 3D GAME ENGINE
   Hong H, 2010, J SOC INF DISPLAY, V18, P8, DOI 10.1889/JSID18.1.8
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   Johnson GP, 2012, IEEE INT C CL COMP, P239, DOI 10.1109/CLUSTER.2012.78
   Kim T, 2011, IEEE T CONSUM ELECTR, V57, P1471, DOI 10.1109/TCE.2011.6131113
   Knox C, 2005, AGU FALL M, V1, P1140
   Laha B, 2012, IEEE T VIS COMPUT GR, V18, P597, DOI 10.1109/TVCG.2012.42
   Lange B, 2012, DISABIL REHABIL, V34, P1863, DOI 10.3109/09638288.2012.670029
   Leigh J, 2013, P IEEE, V101, P115, DOI 10.1109/JPROC.2012.2191609
   Livingston MA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P119, DOI 10.1109/VR.2012.6180911
   Luo JL, 2010, VISUAL COMPUT, V26, P457, DOI 10.1007/s00371-010-0479-1
   Margolis T, 2011, IS T SPIE ELECT IMAG
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Meyer-Spradow J, 2009, IEEE COMPUT GRAPH, V29, P6, DOI 10.1109/MCG.2009.130
   Pausch R., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P265, DOI 10.1145/108844.108913
   Polys NF, 2007, COMPUT ANIMAT VIRT W, V18, P19, DOI 10.1002/cav.159
   Ponto K, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P201, DOI 10.1109/ISM.2009.90
   Ponto K, 2010, FUTURE GENER COMP SY, V26, P693, DOI 10.1016/j.future.2009.12.007
   Prabhat, 2008, IEEE T VIS COMPUT GR, V14, P551, DOI 10.1109/TVCG.2007.70433
   Ragan ED, 2013, IEEE T VIS COMPUT GR, V19, P886, DOI 10.1109/TVCG.2012.163
   Rash C E, 1999, RTO HFM S CURR AER I
   Renambot L, 2009, FUTURE GENER COMP SY, V25, P161, DOI 10.1016/j.future.2008.07.004
   Rosson MB., 2001, Usability engineering: scenario-based development of human-computer interaction
   Sampaio PNM, 2008, LECT NOTES ARTIF INT, V5179, P465, DOI 10.1007/978-3-540-85567-5_58
   Schou TorbenH., 2007, OZCHI'07: Proceedings of the 19th Australasian conference on Computer-Human Interaction, P231
   Shupp L, 2009, HUM-COMPUT INTERACT, V24, P230, DOI 10.1080/07370020902739429
   Simon A, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P3, DOI 10.1109/PCCGA.2002.1167834
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   Teather RJ, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P43, DOI 10.1109/3DUI.2009.4811204
   WELLS MJ, 1990, OPT ENG, V29, P870, DOI 10.1117/12.55672
   Williams SCP, 2013, P NATL ACAD SCI USA, V110, P4438, DOI 10.1073/pnas.1302989110
   Woods AJ., 2010, Keynote Presentation at the Three-Dimensional Systems and Applications Conference, Tokyo, Japan, P19
NR 48
TC 6
Z9 7
U1 0
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2015
VL 19
IS 1
BP 57
EP 70
DI 10.1007/s10055-014-0254-0
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CB5CS
UT WOS:000349645700005
DA 2024-07-18
ER

PT J
AU Sung, RCW
   Ritchie, JM
   Lim, T
   Kosmadoudi, Z
AF Sung, Raymond C. W.
   Ritchie, James M.
   Lim, Theodore
   Kosmadoudi, Zoe
TI Automated generation of engineering rationale, knowledge and intent
   representations during the product life cycle
SO VIRTUAL REALITY
LA English
DT Article
DE Knowledge capture; Cable harness design; Knowledge representation; User
   logging; Design rationale; Design task analysis
ID DESIGN; MANAGEMENT; INFORMATION; ACQUISITION
AB One of the biggest challenges in engineering design and manufacturing environments is the effective capture of and decoding of tacit knowledge. Fundamental to Life Cycle Engineering is the capture of engineering information and knowledge created at all stages of the product development process, from conceptual design through to product support and disposal. Consider this-the amount of vital information and knowledge lost when key design personnel retire-hence the need to capture meta-cognitive task-related strategies, particularly to support knowledge reuse and training. Many methods have been tried and tested with the successful few found to be very time consuming and expensive to implement and carry out; consequently, there is a need to investigate alternative paradigms for knowledge and information capture. This paper reports on a current industrial case study on knowledge capture methods employed by industrial partners in the design and manufacture of a variety of electro-mechanical products. The results suggest the need for new kinds and forms of knowledge capture methods and representation, particularly those associated with individual design engineering tasks. Following the findings, the paper presents a knowledge capture methodology for automatic real-time logging, capture and post-processing of design data from a virtual reality design system. Task-based design experiments were carried out with industrial partners to demonstrate the effective, unobtrusive and automatic capture and representation of various forms of design knowledge and information. Qualitative and quantitative evaluation of knowledge representations were also performed to determine which method was most effective at conveying design knowledge and information for other engineers.
C1 [Sung, Raymond C. W.; Ritchie, James M.; Lim, Theodore; Kosmadoudi, Zoe] Heriot Watt Univ, Scottish Mfg Inst, Edinburgh, Midlothian, Scotland.
C3 Heriot Watt University
RP Sung, RCW (corresponding author), Heriot Watt Univ, Scottish Mfg Inst, Edinburgh, Midlothian, Scotland.
EM r.c.w.sung@hw.ac.uk
OI Lim, Theodore/0000-0001-8931-2745
FU Engineering and Physical Research Council (EPSRC) [EP/C534220/1];
   Economic and Social Research Council (ESRC) [RES-331-27-0006];
   Heriot-Watt University's Innovative Design and Manufacturing Research
   Centre (IMRC) [GR/S12395/01]; EPSRC [EP/F02553X/1] Funding Source: UKRI
FX The work presented herein was undertaken under the aegis of the
   Knowledge and Information Management (KIM) Through-Life Grand Challenge
   Project (www.kimproject.org) funded primarily by the Engineering and
   Physical Research Council (EPSRC-Grant No EP/C534220/1), the Economic
   and Social Research Council (ESRC-Grant No RES-331-27-0006) and
   Heriot-Watt University's Innovative Design and Manufacturing Research
   Centre (IMRC-Grant No GR/S12395/01). The authors would finally like to
   offer their gratitude to the industrial collaborators for their
   involvement in the research.
CR [Anonymous], 2009, Extensible markup language (XML)
   [Anonymous], 1998, THINKING LEAN MULTIP
   [Anonymous], 2009, INTEGRATED DEFINITIO
   Bernard A, 2009, 3 INT C DES MOD MECH
   Bock Conrad., 2004, SOFTW SYST MODEL, V4, P209
   Bolisani E, 1999, TECHNOVATION, V19, P209, DOI 10.1016/S0166-4972(98)00109-6
   Brandt SC, 2008, COMPUT CHEM ENG, V32, P320, DOI 10.1016/j.compchemeng.2007.04.013
   Coombs R, 1998, RES POLICY, V27, P237, DOI 10.1016/S0048-7333(98)00036-5
   Dalkir K., 2011, KNOWLEDGE MANAGEMENT
   Dani TH, 1997, COMPUT AIDED DESIGN, V29, P555, DOI 10.1016/S0010-4485(96)00091-7
   Davenport TH., 1997, Information Ecology: Mastering the Information and Knowledge Environment
   Desroches CM, 2007, THESIS U JOHANNESBUR
   Grossman Martin, 2008, VINE, V38, P118, DOI 10.1108/03055720810870932
   Henriksen LB, 2001, TECHNOVATION, V21, P595, DOI 10.1016/S0166-4972(01)00023-2
   Hicks BJ, 2002, INT J INFORM MANAGE, V22, P263, DOI 10.1016/S0268-4012(02)00012-9
   Hofer-Alfeis Josef, 2008, Journal of Knowledge Management, V12, P44, DOI 10.1108/13673270810884246
   Jin Y, 2006, INT J PROD RES, V44, P2813, DOI 10.1080/00207540600654533
   Kim S, 2004, INT WORKSH APPL LANG
   Koners U, 2007, J PROD INNOVAT MANAG, V24, P242, DOI 10.1111/j.1540-5885.2007.00248.x
   Kwong E, 2009, J KNOWL MANAG, V13, P35, DOI 10.1108/13673270910942682
   LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745
   Lockwood K, 2009, THESIS NW U EVANSTON
   Marsh SJ, 2003, J PROD INNOVAT MANAG, V20, P136, DOI 10.1111/1540-5885.2002006
   McAdam R, 2008, TECHNOVATION, V28, P245, DOI 10.1016/j.technovation.2007.07.003
   McElroy M. W., 1999, ICM C KNOWL MAN MIAM
   Meyer MH, 1996, SLOAN MANAGE REV, V37, P43
   Mulder U., 2007, Journal of Knowledge Management, V11, P68, DOI 10.1108/13673270710728240
   Ng FM, 2000, J MATER PROCESS TECH, V107, P37, DOI 10.1016/S0924-0136(00)00725-1
   Nightingale P, 1998, RES POLICY, V27, P689, DOI 10.1016/S0048-7333(98)00078-X
   Oliver N., 2004, Journal of High Technology Management Research, V15, P249, DOI [10.1016/j.hitech.2004.03.006, DOI 10.1016/J.HITECH.2004.03.006]
   Philbin S.P., 2008, J HIGH TECHNOLOGY MA, V19, P114, DOI DOI 10.1016/J.HITECH.2008.10.004
   Regli WC, 2011, COMPUT AIDED DESIGN, V43, P820, DOI 10.1016/j.cad.2010.11.012
   Richter H, 1999, P 1 WORK IFIP C SOFT
   Ritchie J., 1999, PICMET '99: Portland International Conference on Management of Engineering and Technology. Technology and Innovation Management (IEEE Cat. No. 99CH36310), P285, DOI 10.1109/PICMET.1999.787817
   Ritchie James M., 2007, Virtual Reality, V11, P261, DOI 10.1007/s10055-007-0073-7
   Robinson G, 2007, COMPUT AIDED DESIGN, V39, P245, DOI 10.1016/j.cad.2006.12.001
   Sainter P, 2000, P DETC 00 ASME 2000
   Sanderson M., 2001, Records Management Journal, V11, P7, DOI [DOI 10.1108/EUM0000000007263, 10.1108/EUM0000000007263]
   Schulz M., 2001, J HIGH TECHNOLOGY MA, V12, P139, DOI DOI 10.1016/S1047-8310(00)00043-2
   Schwartz Maxim, 2007, P 2007 WORKSH PERF M, P280
   Sherwood AL, 2008, J PROD INNOVAT MANAG, V25, P162, DOI 10.1111/j.1540-5885.2008.00292.x
   Shipman FM, 1997, AI EDAM, V11, P141, DOI 10.1017/S089006040000192X
   Sung RCW, 2009, COMPUT AIDED DESIGN, V41, P1082, DOI 10.1016/j.cad.2009.09.006
   Szykman S., 2006, ACM Transactions on Internet Technology, V6, P85, DOI 10.1145/1125274.1125278
   Vijaykumar G, 2008, J COMPUT INF SCI ENG, V8, DOI 10.1115/1.2840776
   Wiig K.M., 1994, KNOWLEDGE MANAGEMENT
   Wong WLP, 2000, TECHNOL ANAL STRATEG, V12, P493, DOI 10.1080/713698497
NR 47
TC 12
Z9 12
U1 0
U2 30
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2012
VL 16
IS 1
SI SI
BP 69
EP 85
DI 10.1007/s10055-011-0196-8
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 897NL
UT WOS:000300657600008
DA 2024-07-18
ER

PT J
AU Uchiyama, H
   Saito, H
   Servières, M
   Moreau, G
AF Uchiyama, Hideaki
   Saito, Hideo
   Servieres, Myriam
   Moreau, Guillaume
TI Camera tracking by online learning of keypoint arrangements using LLAH
   in augmented reality applications
SO VIRTUAL REALITY
LA English
DT Article
DE LLAH; Feature descriptor; Camera tracking; Augmented reality
AB We propose a camera-tracking method by on-line learning of keypoint arrangements in augmented reality applications. As target objects, we deal with intersection maps from GIS and text documents, which are not dealt with by the popular SIFT and SURF descriptors. For keypoint matching by keypoint arrangement, we use locally likely arrangement hashing (LLAH), in which the descriptors of the arrangement in a viewpoint are not invariant to the wide range of viewpoints because the arrangement is changeable with respect to viewpoints. In order to solve this problem, we propose online learning of descriptors using new configurations of keypoints at new viewpoints. The proposed method allows keypoint matching to proceed under new viewpoints. We evaluate the performance and robustness of our tracking method using view changes.
C1 [Uchiyama, Hideaki; Saito, Hideo] Keio Univ, Kohoku Ku, Tokyo 2238522, Japan.
   [Servieres, Myriam; Moreau, Guillaume] Ecole Cent Nantes CERMA IRSTV, F-44321 Nantes 3, France.
C3 Keio University; Nantes Universite; Ecole Centrale de Nantes
RP Uchiyama, H (corresponding author), Keio Univ, Kohoku Ku, 3-14-1 Hiyoshi, Tokyo 2238522, Japan.
EM uchiyama@hvrl.ics.keio.ac.jp; saito@hvrl.ics.keio.ac.jp;
   myriam.servieres@ec-nantes.fr; guillaume.moreau@ec-nantes.fr
RI Myriam, Servières/H-6071-2012; Saito, Hideo/D-6223-2014; Moreau,
   Guillaume/I-3153-2013
OI Myriam, Servières/0000-0001-5749-1590; Saito, Hideo/0000-0002-2421-9862;
   Moreau, Guillaume/0000-0003-2215-1865
FU Ministry of Education, Culture, Sport, Science, and Technology in Japan
FX We thank Dr. Julien Pilet for the discussion. This work was supported in
   part by Grant-in-Aid for JSPS Fellows and a Grant-in-Aid for the Global
   Center of Excellence for high-Level Global Cooperation for Leading-Edge
   Platform on Access Spaces from the Ministry of Education, Culture,
   Sport, Science, and Technology in Japan.
CR Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DRUMMOND T, 1999, P BMVC, P574
   Fiala M, 2005, PROC CVPR IEEE, P590
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hull JJ, 2007, 17TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE, ICAT 2007, PROCEEDINGS, P205, DOI 10.1109/ICAT.2007.49
   Kato H., 1999, P IWAR
   Klein G, 2008, LECT NOTES COMPUT SC, V5303, P802, DOI 10.1007/978-3-540-88688-4_59
   Kotake D., 2007, P ISMAR, P239
   Lamdan Y., 1988, PROC 2 INT C COMPUTE, P238
   Lepetit V, 2004, PROC CVPR IEEE, P244
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nakai T, 2006, LECT NOTES COMPUT SC, V3872, P541
   Nakai T., 2005, INT WORKSHOP CAMERA, P87
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   PENTENRIEDER K, 2007, P ISMAR, P1
   Rosten E., 2006, P 2006 9 EUR C COMP, P430, DOI DOI 10.1007/11744023_34
   Sinha S., 2006, P EDGE
   Uchiyama H., 2009, P MVA, P382
   UCHIYAMA H, 2008, P ICAT, P218
   Uchiyama H, 2009, INT SYM MIX AUGMENT, P95, DOI 10.1109/ISMAR.2009.5336491
   Wagner D, 2008, INT SYM MIX AUGMENT, P121, DOI 10.1109/ISMAR.2008.4637337
   Wagner D, 2008, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2008.4637338
   *WILL, 2010, OPENCV 2 0
NR 27
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 109
EP 117
DI 10.1007/s10055-010-0173-7
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kruszynski, KJ
   van Liere, R
AF Kruszynski, Krzysztof Jakub
   van Liere, Robert
TI Tangible props for scientific visualization: concept, requirements,
   application
SO VIRTUAL REALITY
LA English
DT Article
DE Tangible user interfaces; Haptics; Augmented reality; Rapid prototyping
AB In this paper, we explore the use of printed tangible props as input devices for scientific visualization. Three-dimensional printing technology is used to create a physical representation of data. The object is then used as a tangible input prop, which exactly matches the data. In addition, two-handed interaction with a stylus is performed on the prop without the use of buttons, instead relying on the detection of contact between the stylus and the prop through precise calibration and tracking. This allows the sense of touch to be harnessed to create a more efficient and natural interaction method for scientific visualizations in virtual and augmented reality. We explain the concept of tangible props and where it can be applied. We also consider the technical requirements of systems using such props. Finally, we present our example application, which uses printed tangible props for interactive measurement of marine coral data. The use of tangible props is found to improve the usability of the application.
C1 [Kruszynski, Krzysztof Jakub; van Liere, Robert] Ctr Wiskunde & Informat, NL-1098 XG Amsterdam, Netherlands.
   [van Liere, Robert] Tech Univ Eindhoven, NL-5600 MB Eindhoven, Netherlands.
C3 Eindhoven University of Technology
RP Kruszynski, KJ (corresponding author), Ctr Wiskunde & Informat, Sci Pk 123, NL-1098 XG Amsterdam, Netherlands.
EM chris.kruszynski@cwi.nl
FU Dutch Ministry of Education, Culture and Science (OCW); Ministry of
   Economic Affairs (EZ)
FX This work was carried out in the context of the Virtual Laboratory for
   e-Science project (http://www.vl-e.nl). This project is supported by a
   BSIK grant from the Dutch Ministry of Education, Culture and Science
   (OC&W) and is part of the ICT innovation program of the Ministry of
   Economic Affairs (EZ).
CR CONNER BD, 1992, SI3D 92 P 1992 S INT, P183
   Couture N., 2008, Proceedings of the 2nd international conference on Tangible and embedded interaction, P89
   Fitzmaurice GeorgeW., 1995, CHI 95, P442, DOI DOI 10.1145/223904.223964
   Gillet A, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P235, DOI 10.1109/VISUAL.2004.7
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   ISHII H, 2008, TEI 08 P 2 INT C TAN
   Jurado F, 2005, ETFA 2005: 10TH IEEE INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES AND FACTORY AUTOMATION, VOL 2, PROCEEDINGS
   Kok AJF, 2004, P IEEE VIRT REAL ANN, P233, DOI 10.1109/VR.2004.1310085
   Kruszyñski KJ, 2007, CORAL REEFS, V26, P831, DOI 10.1007/s00338-007-0270-6
   KRUSZYNSKI KJ, 2008, EGVE 08 P EUR S VIRT, P89
   Mulder JD, 2006, PRESENCE-TELEOP VIRT, V15, P93, DOI 10.1162/pres.2006.15.1.93
NR 12
TC 18
Z9 21
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2009
VL 13
IS 4
SI SI
BP 235
EP 244
DI 10.1007/s10055-009-0126-1
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XF
UT WOS:000208104400003
DA 2024-07-18
ER

PT J
AU Barfield, W
AF Barfield, Woodrow
TI On money, taxes, and property in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
EM Jbar5377@aol.com
CR [Anonymous], 2004, BBC NEWS
   Barfield Woodrow., 2006, Akron Law Review, V39, P649
   Fairfield JAT, 2005, BOSTON U LAW REV, V85, P1047
   LICHTAROWIECZ A, 2002, BBC NEWS
   2002, VIRTUAL EC SURPASS R
NR 5
TC 1
Z9 2
U1 4
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2009
VL 13
IS 1
BP 37
EP 39
DI 10.1007/s10055-008-0097-7
PG 3
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XC
UT WOS:000208104100005
DA 2024-07-18
ER

PT J
AU Shakeri, M
   Park, H
   Jeon, I
   Sadeghi-Niaraki, A
   Woo, W
AF Shakeri, Maryam
   Park, Hyerim
   Jeon, Ikbeom
   Sadeghi-Niaraki, Abolghasem
   Woo, Woontack
TI User behavior modeling for AR personalized recommendations in spatial
   transitions
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Personalized recommendation; Tour trajectory; User
   behavior model; Spatial transitions
ID AUGMENTED REALITY; CONTEXT; SYSTEM
AB There have been studies on personalized augmented reality (AR) systems taking users' contexts and histories into account. However, there is insufficient research on incorporating real-time user behavior and interactions into the personalized recommendations in spatial transitions, which can be used for new users without user history data. The spatial transitions, distances between two Point of Interests (POIs) of an AR tour trajectory through which users should pass to visit AR contents, need to be filled using the personalized AR contents to reduce the discontinuity experience. This paper aims to propose a user behavior model to recommend personalized contents in the AR tour trajectory to create a personalized experience. First, we model three interactions, including staring, skipping, and liking, using mathematical methods; and two spatial behaviors, including standing and moving, using a rule engine. Second, a content filtering-based recommendation method is presented to apply the proposed user model to recommend personalized AR contents in the spatial transitions. The experiment results showed that the proposed real-time user behavior model brought notable improvements in creating a personal experience of the AR tour system. The proposed method outperformed the conventional method in terms of recommendation performance metrics, so that it achieved an average of 15% more precision and recall scores and an average of 32% more personalization scores than those of the conventional method. Furthermore, the level of personalization perceived by the proposed user model demonstrated significant positive relationships with the level of decision effectiveness, system trustworthiness, and perceived recommendation transparency. The findings showed the effectiveness of the proposed framework in solving the cold-start recommendation problem.
C1 [Shakeri, Maryam] KN Toosi Univ Technol, Geodesy & Geomat Engn, Tehran, Iran.
   [Park, Hyerim; Jeon, Ikbeom; Woo, Woontack] KAIST UVR Lab, 2325,N5,291,Daehak ro, Daejeon, South Korea.
   [Sadeghi-Niaraki, Abolghasem] Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Sadeghi-Niaraki, Abolghasem] Sejong Univ, Convergence Engn Intelligent Drone, Seoul, South Korea.
   [Woo, Woontack] KAIST KI ITC Augmented Real Res Ctr, 303,E4,291,Daehak ro, Daejeon, South Korea.
C3 K. N. Toosi University of Technology; Korea Advanced Institute of
   Science & Technology (KAIST); Sejong University; Sejong University
RP Sadeghi-Niaraki, A (corresponding author), Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.; Sadeghi-Niaraki, A (corresponding author), Sejong Univ, Convergence Engn Intelligent Drone, Seoul, South Korea.
EM a.sadeghi@sejong.ac.kr
RI Woo, Woontack/C-3696-2012
OI Woo, Woontack/0000-0002-5501-4421; Sadeghi-Niaraki,
   Abolghasem/0000-0002-0048-8216; PARK, HYERIM/0000-0001-6764-4490
FU Ministry of Culture, Sports and Tourism and Korea Creative Content
   Agency [R2021080001]; Institute of Information & communications
   Technology Planning & Evaluation (IITP) - Korea government (MSIT)
   [2019-0-01270]
FX This research is supported by Ministry of Culture, Sports and Tourism
   and Korea Creative Content Agency (Project No.: R2021080001). This work
   was also supported by Institute of Information & communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (No. 2019-0-01270, WISE AR UI/UX Platform Development
   for Smart glasses).
CR Aksenov P, 2016, SMART INNOV SYST TEC, V55, P525, DOI 10.1007/978-3-319-39345-2_46
   Ali SM, 2018, LECT NOTE NETW SYST, V38, P85, DOI 10.1007/978-981-10-8360-0_8
   Alqahtani H, 2017, P 9 INT C COMP AUT E, P1
   Andri C., 2018, Int. J. Eng. Technol, V7, P64
   Andri C, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND INTELLIGENT SYSTEMS (I2CACIS), P161, DOI [10.1109/i2cacis.2019.8825054, 10.1109/I2CACIS.2019.8825054]
   Benford S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P709
   Bleier A, 2015, J RETAILING, V91, P390, DOI 10.1016/j.jretai.2015.04.001
   Bristow RS, 2020, TOURISM GEOGR, V22, P219, DOI 10.1080/14616688.2020.1725618
   Brousseau B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020543
   Brousseau B, 2018, 2018 9TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P951, DOI 10.1109/UEMCON.2018.8796799
   Byung-Kuk Seo, 2010, Computer Vision - ACCV 2010 Workshops. ACCV 2010 International Workshops. Revised Selected Papers, P276, DOI 10.1007/978-3-642-22819-3_28
   Chen L, 2019, ACM T INTERACT INTEL, V9, DOI 10.1145/3282878
   Cui ZH, 2020, IEEE T SERV COMPUT, V13, P685, DOI 10.1109/TSC.2020.2964552
   Dhelim S, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106227
   Duan Z, 2020, 2020 21 IEEE INT C M, ppp729
   Fogli A, 2019, PERS UBIQUIT COMPUT, V23, P215, DOI 10.1007/s00779-018-01189-7
   Gao KY, 2020, IEEE ACCESS, V8, P52404, DOI 10.1109/ACCESS.2020.2980982
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Jaller C, 2020, DIGIT CREAT, V31, P213, DOI 10.1080/14626268.2020.1779091
   Jung T, 2015, TOURISM MANAGE, V49, P75, DOI 10.1016/j.tourman.2015.02.013
   Kaghat FZ, 2020, COMPUT ELECTR ENG, V84, DOI 10.1016/j.compeleceng.2020.106606
   Kaghat FZ, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Kelley MJ, 2014, GEOJOURNAL, V79, P15, DOI 10.1007/s10708-013-9482-1
   Kim H, 2017, MULTIMED TOOLS APPL, V76, P26001, DOI 10.1007/s11042-017-4868-6
   Kim H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173913
   Koo S, 2019, ACM J COMPUT CULT HE, V12, DOI 10.1145/3317552
   Kourouthanassis P, 2015, PERVASIVE MOB COMPUT, V18, P71, DOI 10.1016/j.pmcj.2014.08.009
   Lee CI, 2020, AUGMENTED REALITY VI, ppp161
   Li X, 2016, TRANSPORT RES B-METH, V91, P332, DOI 10.1016/j.trb.2016.05.013
   Makolkina M, 2020, INTERNET THINGS SMAR, ppp217
   Olsson T, 2011, INT SYM MIX AUGMENT
   Park H, 2017, 2017 IEEE INT C CONS, ppp388
   Park H, 2022, VIRTUAL REAL-LONDON, V26, P1059, DOI 10.1007/s10055-021-00617-z
   Park H, 2018, 2018 3RD DIGITAL HERITAGE INTERNATIONAL CONGRESS (DIGITALHERITAGE) HELD JOINTLY WITH 2018 24TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS & MULTIMEDIA (VSMM 2018), P253
   Park H, 2018, LECT NOTES COMPUT SC, V10905, P167, DOI 10.1007/978-3-319-92046-7_15
   Park H, 2015, INT SYM MIX AUGMENT, P40, DOI 10.1109/ISMAR-MASHD.2015.12
   Pavlidis G., 2018, INT C VR TECHN CULT, P60
   Prandi C, 2020, MOBILE NETW APPL, V25, P945, DOI 10.1007/s11036-019-01238-2
   Qaiser S., 2018, International Journal of Computer Applications, V181, P25, DOI [10.5120/ijca2018917395, DOI 10.5120/IJCA2018917395]
   Ramos CM, 2016, HDB RES HUMAN COMPUT, ppp245
   Rana C, 2015, ARTIF INTELL REV, V43, P141, DOI 10.1007/s10462-012-9359-6
   Renjith S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102078
   Rezaee S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11136047
   Shakeri M, 2022, AUGMENTED REALITY BA
   Sharma L, 2021, 2021 5 INT C INT COM, ppp928
   Shin D, 2019, INFORM COMMUN SOC, V22, P1212, DOI 10.1080/1369118X.2017.1411519
   Smink AR, 2020, J BUS RES, V118, P474, DOI 10.1016/j.jbusres.2020.07.018
   Tam KY, 2005, INFORM SYST RES, V16, P271, DOI 10.1287/isre.1050.0058
   Thornton PR, 1997, ENVIRON PLANN A, V29, P1847, DOI 10.1068/a291847
   Torres-Ruiz M, 2020, VIRTUAL REAL-LONDON, V24, P175, DOI 10.1007/s10055-018-0366-z
   Tsai CH, 2018, COMPUT STAND INTER, V55, P171, DOI 10.1016/j.csi.2017.08.003
   Tsai SP, 2020, CURR ISSUES TOUR, V23, P1078, DOI 10.1080/13683500.2019.1598950
   Vlahakis V, 2002, IEEE COMPUT GRAPH, V22, P52, DOI 10.1109/MCG.2002.1028726
   Xu K, 2018, J COMPUT SCI-NETH, V26, P87, DOI 10.1016/j.jocs.2018.04.001
   Yavuz M, 2021, TECHNOL SOC, V66, DOI 10.1016/j.techsoc.2021.101598
   Yoon H, 2012, PERS UBIQUIT COMPUT, V16, P469, DOI 10.1007/s00779-011-0419-8
   Yu F, 2016, PHYSICA A, V452, P192, DOI 10.1016/j.physa.2016.02.021
   Zanker M, 2019, INT J HUM-COMPUT ST, V131, P160, DOI 10.1016/j.ijhcs.2019.06.006
   Zhang J, 2019, IEEE T MULTIMEDIA, V21, P2762, DOI 10.1109/TMM.2019.2912124
   Zhang ZG, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON ENERGY, P173
   Zheng WM, 2017, TOURISM MANAGE, V62, P335, DOI 10.1016/j.tourman.2017.05.006
NR 61
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3033
EP 3050
DI 10.1007/s10055-023-00852-6
EA OCT 2023
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001088194700001
DA 2024-07-18
ER

PT J
AU Calvert, J
   Hume, M
AF Calvert, James
   Hume, Margee
TI Improving student learning outcomes using narrative virtual reality as
   pre-training
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Education; Narrative
ID EMOTIONAL DESIGN; ACHIEVEMENT; EXPERIENCE; ENGAGEMENT
AB Our research focuses on incorporating narrative immersive virtual reality (IVR) into a classroom setting and assessing its impact when used as pre-training material before a multimedia lesson. Narrative experiences in IVR can be highly informative and affecting; however, our understanding of the educational impact of narratives in IVR is rudimentary. To address this, our study examines the cognitive and affective benefits of utilising a narrative-based IVR experience titled Thin Ice VR, as pre-training for students studying polar history and climate change. To further enhance our understanding of the relationships between IVR design and learning outcomes, key design elements of the narrative IVR experience used in the study are described. A between-groups experiments was conducted with 139 high school students to determine if those that viewed narrative IVR before continuing their learning with multimedia materials would show increased knowledge transfer (achieving a better understanding of the material presented), knowledge acquisition (new knowledge added to memory), engagement, motivation and emotional reaction. Results showed a significant increase in knowledge transfer when narrative IVR was used as pre-training material. However, using narrative IVR as pre-training had minimal impact on knowledge acquisition, engagement and motivation. Afforded by the sense of presence in IVR, the immersive narrative experience was heightened and able to elicit an emotional reaction. Utilising the sense of presence in IVR to place students in the narrative positions IVR as an effective medium for telling stories in classroom settings. When students use narrative IVR before further study, the experience significantly benefits both cognitive and affective learning outcomes.
C1 [Calvert, James; Hume, Margee] Torrens Univ Australia, Adelaide, Australia.
C3 Torrens University Australia
RP Calvert, J (corresponding author), Torrens Univ Australia, Adelaide, Australia.
EM jcalvert@torrens.edu.au; margee.hume@torrens.edu.au
OI Calvert, James/0000-0002-4899-2761; Hume, Margee/0000-0003-2627-1629
FU David A. Wilson Award for Excellence in Teaching and Learning; South
   Australian Film Corporation; Screen Australia; Adelaide Film Festival;
   Kathmandu, One Ocean Expeditions; Documentary Australia
FX The data gathering phase of this research was supported in parts by
   funds received from the David A. Wilson Award for Excellence in Teaching
   and Learning, which was created by the Laureate International
   Universities network to support research focused on teaching and
   learning. For more information on the award or Laureate, please visit
   www.laureate.net. The work Thin Ice VR was financed and developed with
   the assistance of the South Australian Film Corporation, Screen
   Australia and Adelaide Film Festival. Supported by Kathmandu, One Ocean
   Expeditions and Documentary Australia. Major partner, Torrens University
   Australia.
CR Abadia R, 2018, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON EDUCATION TECHNOLOGY AND COMPUTERS (ICETC 2018), P268, DOI 10.1145/3290511.3290558
   Albus P, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104154
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Alrehaili EA, 2022, INTERACT LEARN ENVIR, V30, P922, DOI 10.1080/10494820.2019.1703008
   [Anonymous], 2010, Cognitive Load Theory
   Artino AR, 2014, MED TEACH, V36, P463, DOI 10.3109/0142159X.2014.889814
   Bower M, 2020, BRIT J EDUC TECHNOL, V51, P1981, DOI 10.1111/bjet.13038
   Broomell SB, 2017, WEATHER CLIM SOC, V9, P563, DOI 10.1175/WCAS-D-17-0003.1
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Calvert J, 2021, THIN ICE
   Calvert J, 2022, AUSTRALAS J EDUC TEC, V38, P45
   Calvert J, 2020, COMPUT EDUC, V159, DOI 10.1016/j.compedu.2020.104005
   Carini RM, 2006, RES HIGH EDUC, V47, P1, DOI 10.1007/s11162-005-8150-9
   Cheng KH, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103600
   Clark C., 2008, NEW DIRECTIONS ADULT, P61, DOI DOI 10.1002/ACE.306
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Dettori G, 2009, TECHNOLOGY-ENHANCED LEARNING: PRINCIPLES AND PRODUCTS, P55, DOI 10.1007/978-1-4020-9827-7_4
   Di Natale AF, 2020, BRIT J EDUC TECHNOL, V51, P2006, DOI 10.1111/bjet.13030
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Dubovi I, 2022, COMPUT EDUC, V183, DOI 10.1016/j.compedu.2022.104495
   Guan JQ, 2023, INTERACT LEARN ENVIR, V31, P2016, DOI 10.1080/10494820.2021.1871631
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Jicol C., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, P1, DOI DOI 10.1145/3411764.3445588
   Klingenberg S, 2020, BRIT J EDUC TECHNOL, V51, P2115, DOI 10.1111/bjet.13029
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Kuh G.D., 2003, CHANGE, V35, P24, DOI [DOI 10.1080/00091380309604090, 10.1080/00091380309604090]
   Lee SWY, 2022, COMPUT EDUC, V182, DOI 10.1016/j.compedu.2022.104456
   Lin HCS, 2021, INTERACT LEARN ENVIR, V29, P1272, DOI 10.1080/10494820.2019.1624579
   Liu RX, 2020, BRIT J EDUC TECHNOL, V51, P2034, DOI 10.1111/bjet.13028
   Makransky G, 2021, J EDUC PSYCHOL, V113, P719, DOI 10.1037/edu0000473
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Mayer RE., 2014, The Cambridge Handbook of Multimedia Learning. Cambridge Handbooks in psychology, V2, P316, DOI [DOI 10.1017/CBO9780511816819.012, 10.1017/CBO9781139547369.016, DOI 10.1017/CBO9781139547369.016]
   Mayer RE, 2014, LEARN INSTR, V33, P12, DOI 10.1016/j.learninstruc.2014.02.004
   Mayer RE, 2014, LEARN INSTR, V29, P171, DOI 10.1016/j.learninstruc.2013.04.003
   Mayer RE, 2009, MULTIMEDIA LEARNING, 2ND EDITION, P223
   Misak John, 2018, Computers and Composition, V50, P39, DOI 10.1016/j.compcom.2018.07.007
   Moreno R, 2006, J COMPUT ASSIST LEAR, V22, P149, DOI 10.1111/j.1365-2729.2006.00170.x
   Nowak GJ, 2020, VACCINE, V38, P1225, DOI 10.1016/j.vaccine.2019.11.009
   Park B, 2014, LEARN INSTR, V29, P125, DOI 10.1016/j.learninstruc.2013.05.005
   Parong J, 2021, J COMPUT ASSIST LEAR, V37, P226, DOI 10.1111/jcal.12482
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   PEKRUN R, 1992, APPL PSYCHOL-INT REV, V41, P359, DOI 10.1111/j.1464-0597.1992.tb00712.x
   Pellas N, 2021, VIRTUAL REAL-LONDON, V25, P835, DOI 10.1007/s10055-020-00489-9
   Petersen GB, 2020, BRIT J EDUC TECHNOL, V51, P2098, DOI 10.1111/bjet.12991
   Petersen GB, 2022, COMPUT EDUC, V179, DOI 10.1016/j.compedu.2021.104429
   Plass JL, 2014, LEARN INSTR, V29, P128, DOI 10.1016/j.learninstruc.2013.02.006
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Shao W, 2016, RISK ANAL, V36, P2136, DOI 10.1111/risa.12571
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Sisco MR, 2017, CLIMATIC CHANGE, V143, P227, DOI 10.1007/s10584-017-1984-2
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Tsai MJ, 2022, COMPUT HUM BEHAV REP, V6, DOI 10.1016/j.chbr.2022.100188
   Tyng CM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01454
   Um E, 2012, J EDUC PSYCHOL, V104, P485, DOI 10.1037/a0026609
   Vogt A, 2021, COMPUT EDUC, V171, DOI 10.1016/j.compedu.2021.104235
   Walker S., 2018, MENT HLTH PRACT, V21, P28, DOI [10.7748/mhp.2018.e1259, DOI 10.7748/MHP.2018.E1259]
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Weber EU, 2013, NAT CLIM CHANGE, V3, P312, DOI 10.1038/nclimate1859
   Wilson HR, 2020, INT J PERF ART DIGIT, V16, P114, DOI 10.1080/14794713.2020.1770531
   Wonglorsaichon B, 2014, PROCD SOC BEHV, V116, P1748, DOI 10.1016/j.sbspro.2014.01.467
NR 63
TC 1
Z9 1
U1 19
U2 33
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2633
EP 2648
DI 10.1007/s10055-023-00830-y
EA JUL 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:001027327800001
DA 2024-07-18
ER

PT J
AU Ventura, S
   Marchetti, P
   Baños, R
   Tessari, A
AF Ventura, Sara
   Marchetti, Pierclaudio
   Banos, Rosa
   Tessari, Alessia
TI Body ownership illusion through virtual reality as modulator variable
   for limbs rehabilitation after stroke: a systematic review
SO VIRTUAL REALITY
LA English
DT Review
DE Stroke; Motor rehabilitation; Body ownership illusion; Virtual reality;
   Systematic review
ID MOTOR IMAGERY; GAIT; REPRESENTATIONS; METAANALYSIS; PLASTICITY;
   IMITATION; RECOVERY; DEFICITS; BALANCE; WALKING
AB Stroke is the leading cause of motor impairments and generates distortion of body representation. Hence, stroke can modulate the sense of embodiment, namely the feeling of being inside the body (ownership), in the place where the body is located (location), and moving the body according to its own intentions (agency). A growing number of studies have adopted virtual reality (VR) to train motor abilities. However, the impact of the body illusion on the rehabilitation outcome is not fully understood. The present systematic review investigates the modulating role of the body illusion elicited by VR on motor rehabilitation in post-stroke patients after embodying a virtual avatar. The research was led in the main databases-PubMed, Scopus, PsychINFO, and Web of Science-and four studies matched the inclusion criteria (e.g., to have a sample of adult post-stroke patients, to use VR as an instrument for motor rehabilitation, to adopt the paradigm of the body illusion as a modulator for motor rehabilitation, to test the sense of body illusion outcome). Research outcomes demonstrated that two studies adopted the immersive and two the non-immersive embodied VR; three studies focused on the upper limb, and one on lower limb rehabilitation. Two studies compare VR training with traditional therapy, and two are pilot studies with only one experimental group. The studies demonstrated the feasibility of the body illusion as an accelerator for motor rehabilitation compared to the non-embodied condition, and as a positive correlator of the rehabilitation outcome. The finding should be taken with caution due to the limited studies included; however, they are encouraging to justify further research efforts in this area.
C1 [Ventura, Sara; Marchetti, Pierclaudio; Tessari, Alessia] Alma Mater Studiorum Univ Bologna, Dept Psychol, Viale Berti Pichat 5, Bologna, Italy.
   [Ventura, Sara; Banos, Rosa] Univ Valencia, Inst Polibienestar, Carrer Serpis 29, Valencia 46022, Spain.
   [Banos, Rosa] Univ Valencia, Dept Personal Evaluat & Psychol Treatments, Avd Blasco Ibanez 21, Valencia, Spain.
   [Banos, Rosa] Inst Salud Carlos III, ISCIII Ctr Invest Biomed Red Fisiopatol Obes & Nut, CIBEROBN, Madrid, Spain.
   [Tessari, Alessia] Alma Mater Res Inst Human Ctr Artificial Intellige, Viale Berti Pichat 5, Bologna, Italy.
C3 University of Bologna; University of Valencia; University of Valencia;
   Instituto de Salud Carlos III; CIBER - Centro de Investigacion Biomedica
   en Red; CIBEROBN
RP Ventura, S (corresponding author), Alma Mater Studiorum Univ Bologna, Dept Psychol, Viale Berti Pichat 5, Bologna, Italy.; Ventura, S (corresponding author), Univ Valencia, Inst Polibienestar, Carrer Serpis 29, Valencia 46022, Spain.
EM sara.ventura7@unibo.it
RI Marchetti, Pierclaudio/HSH-8026-2023; VENTURA, SARA/ABG-4477-2020
OI VENTURA, SARA/0000-0002-3851-7246
FU Margarita Salas postdoctoral fellowship, Ministry of Universities of the
   Government of Spain (European Union NextGeneration EU) [UP2021-044];
   Alma Mater Studiorum - Universita di Bologna within the CRUI-CARE
   Agreement
FX This work was supported by the Margarita Salas postdoctoral fellowship,
   Ministry of Universities of the Government of Spain (European Union
   NextGeneration EU, ref. UP2021-044).Open access funding provided by Alma
   Mater Studiorum - Universita di Bologna within the CRUI-CARE Agreement.
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Augenstein TE, 2022, VIRTUAL REAL-LONDON, P1
   BERG KO, 1992, CAN J PUBLIC HEALTH, V83, pS7
   Bloom, 2018, EMBODIED SELF MOVEME, DOI [10.4324/9780429481598, DOI 10.4324/9780429481598]
   Bohannon RW, 1997, AGE AGEING, V26, P15, DOI 10.1093/ageing/26.1.15
   Borrego A, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.01061
   Burin D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209899
   Cha K, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00957-6
   Chen HW, 2010, PM&R, V2, pS306, DOI 10.1016/j.pmrj.2010.10.006
   Chen XW, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000013387
   Connell LA, 2008, CLIN REHABIL, V22, P758, DOI 10.1177/0269215508090674
   Corradi-Dell'Acqua C, 2010, NEUROPSYCHOLOGIA, V48, P689, DOI 10.1016/j.neuropsychologia.2009.11.029
   Critchley HD, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0237282
   Ertelt D, 2007, NEUROIMAGE, V36, pT164, DOI 10.1016/j.neuroimage.2007.03.043
   Ferreira Bruno, 2019, 2019 5th Experiment@ International Conference (exp.at'19). Proceedings, P383, DOI 10.1109/EXPAT.2019.8876493
   Fregna G, 2022, FRONT ROBOT AI, V9, DOI 10.3389/frobt.2022.906424
   FUGLMEYER AR, 1975, SCAND J REHABIL MED, V7, P13
   Gervasi O, 2010, VIRTUAL REAL-LONDON, V14, P131, DOI 10.1007/s10055-009-0149-7
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Hatem SM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00442
   Henderson A, 2007, TOP STROKE REHABIL, V14, P52, DOI 10.1310/tsr1402-52
   Hosp JA, 2011, NEURAL PLAST, V2011, DOI 10.1155/2011/871296
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Hsu SY, 2022, NEUROREHAB NEURAL RE, V36, P335, DOI 10.1177/15459683221081430
   Impellizzeri F, 2022, PHYSIOTHER THEOR PR, V38, P2603, DOI 10.1080/09593985.2021.1964117
   In T, 2016, MED SCI MONITOR, V22, P4046, DOI 10.12659/MSM.898157
   Jones CJ, 1999, RES Q EXERCISE SPORT, V70, P113, DOI 10.1080/02701367.1999.10608028
   Juan M, 2022, VIRTUAL REAL-LONDON, P1
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Langhorne P, 2009, LANCET NEUROL, V8, P741, DOI 10.1016/S1474-4422(09)70150-4
   Lee HY, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/9461960
   Lo TLT, 2023, BMJ OPEN, V13, DOI 10.1136/bmjopen-2022-066597
   Maenza C, 2020, NEUROREHAB NEURAL RE, V34, P39, DOI 10.1177/1545968319875951
   Marchetti GF, 2008, PHYS THER, V88, P640, DOI 10.2522/ptj.20070130
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Matamala-Gomez M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08917-3
   Matamala-Gomez M, 2021, J CLIN MED, V10, DOI 10.3390/jcm10010139
   Matamala-Gomez M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01962
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Moseley GL, 2004, PAIN, V108, P192, DOI 10.1016/j.pain.2004.01.006
   Mulder T, 2007, J NEURAL TRANSM, V114, P1265, DOI 10.1007/s00702-007-0763-z
   Murphy TH, 2009, NAT REV NEUROSCI, V10, P861, DOI 10.1038/nrn2735
   Nair KPS, 2003, CLIN REHABIL, V17, P797, DOI 10.1191/0269215503cr679oa
   Ottoboni G, 2022, PARADOXICAL DECREASE, P2022
   Perez-Marcos D, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0461-0
   Perez-Marcos D, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0328-9
   PODSIADLO D, 1991, J AM GERIATR SOC, V39, P142, DOI 10.1111/j.1532-5415.1991.tb01616.x
   Riva G, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00164
   Rodriquez AA, 1996, ARCH PHYS MED REHAB, V77, P801, DOI 10.1016/S0003-9993(96)90260-9
   Rumiatil RI, 2005, J COGNITIVE NEUROSCI, V17, P1420, DOI 10.1162/0898929054985374
   Sale P, 2012, EUR J PHYS REHAB MED, V48, P313
   Saposnik G, 2011, STROKE, V42, P1380, DOI 10.1161/STROKEAHA.110.605451
   Schwoebel J, 2004, COGN NEUROPSYCHOL, V21, P285, DOI 10.1080/02643290342000348
   Shin JH, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-32
   Song M, 2019, IEEE T NEUR SYS REH, V27, P477, DOI 10.1109/TNSRE.2019.2895029
   Tambone R, 2021, PSYCHOL SCI, V32, P655, DOI 10.1177/0956797620975774
   Tessari A, 2021, COGN NEUROPSYCHOL, V38, P515, DOI 10.1080/02643294.2022.2043264
   Tosi G, 2018, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00617
   Tsao CW, 2022, CIRCULATION, V145, pE153, DOI 10.1161/CIR.0000000000001052
   Velickovic P, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020321
   Ventura S, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.845508
   Ventura S, 2022, VIRTUAL REAL-LONDON, V26, P323, DOI 10.1007/s10055-021-00567-6
   Verghese J, 2007, ARCH PHYS MED REHAB, V88, P50, DOI 10.1016/j.apmr.2006.10.007
   Wallwork SB, 2016, BRIT J SPORT MED, V50, P990, DOI 10.1136/bjsports-2015-095356
   Weber LM, 2019, AM J PHYS MED REHAB, V98, P783, DOI 10.1097/PHM.0000000000001190
   Yang Y, 2018, NEUROSCIENCE, V390, P318, DOI 10.1016/j.neuroscience.2018.06.044
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
NR 70
TC 1
Z9 1
U1 13
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2481
EP 2492
DI 10.1007/s10055-023-00820-0
EA JUN 2023
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001014724400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, ZJ
   Mao, ZX
   Li, YX
   Yu, L
   Zou, LM
AF Wang, Zijia
   Mao, Zixuan
   Li, Yongxing
   Yu, Liang
   Zou, Linmu
TI VR-based fire evacuation in underground rail station considering staff's
   behaviors: model, system development and experiment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Fire emergency; Evacuation; Underground rail station
ID VIRTUAL-REALITY
AB As an enclosed and normally crowded environment, underground rail station is a dangerous place when fire emergency happens. Traditional methods usually adopt simulation or drill to evaluate station design or contingency plans, which differ far from real situations in both parameters and people's complicated behavior in an emergency, especially the staff's guiding action. Staff's behaviors are enormously important for evacuation, because evacuation path is complex and smoking diffusing is in the same direction with the path to some extent. In this regard, a fire evacuation system considering staff's behavior in virtual reality environment was developed. The distinguished features of the system embodied in three aspects. First, it provided a vivid, interactive and immersed platform for staff to practice and optimize evacuation plan. Second, staff's behaviors and their implication on passengers' evacuation were modeled. Passengers were treated as multi-agent that can feel the surrounding environment including staff's guiding, and they can change their paths in real-time which implemented by a dynamic path choice model. Third, input and visualization of the fire data extracted from fire simulation, and the 3D station model, provide quite real evacuation environment. Recruiting staff from operation company as subjects, the platform was applied for fire evacuation test considering staff's intervention. The results demonstrate that the proposed model and developed system can be effectively used for contingency plan evaluation and improvement.
C1 [Wang, Zijia; Mao, Zixuan; Yu, Liang; Zou, Linmu] Beijing Jiaotong Univ, Sch Civil Engn, Beijing 100044, Peoples R China.
   [Li, Yongxing] Beijing Univ Technol, Beijing Key Lab Traff Engn, Beijing 100124, Peoples R China.
C3 Beijing Jiaotong University; Beijing University of Technology
RP Li, YX (corresponding author), Beijing Univ Technol, Beijing Key Lab Traff Engn, Beijing 100124, Peoples R China.
EM zjwang@bitu.edu.cn; 20125970@bjtu.edu.cn; liyx@bjut.edu.cn;
   20121214@bjtu.edu.cn; 20121223@bjtu.edu.cn
OI Yu, Liang/0000-0003-4915-2980
FU Beijing Municipal Commission of Transport; Fundamental Research Funds
   for the Central Universities [2022JBZY039]; National Engineering
   Laboratory project for the Safety Technology of Urban Rail Transit
   System (Development and Reform Office High Technology) [583]
FX The authors acknowledge the data support from Beijing Municipal
   Commission of Transport, and the research is supported by the
   Fundamental Research Funds for the Central Universities (2022JBZY039)
   and the National Engineering Laboratory project for the Safety
   Technology of Urban Rail Transit System (Development and Reform Office
   High Technology [2016] No. 583).
CR Ahir Kunjal, 2019, Augmented Human Research, V5, P1, DOI [DOI 10.1007/S41133-019-0025-2, 10.1007/s41133-019-0025-2]
   Alaraj Ali, 2011, Surg Neurol Int, V2, P52, DOI 10.4103/2152-7806.80117
   Albis K.A., 2015, Am. J. Energy Eng, V3, P52, DOI [10.11648/j.ajee.s.2015030401.14, DOI 10.11648/J.AJEE.S.2015030401.14]
   Bourhim E, 2020, INT J HUM-COMPUT ST, V142, DOI 10.1016/j.ijhcs.2020.102484
   Çakiroglu Ü, 2019, COMPUT EDUC, V133, P56, DOI 10.1016/j.compedu.2019.01.014
   Cao LJ, 2019, COMPUT HUM BEHAV, V90, P37, DOI 10.1016/j.chb.2018.08.041
   Chae Jin, 2018, [Fire Science and Engineering, 한국화재소방학회 논문지], V32, P108, DOI 10.7731/KIFSE.2018.32.1.108
   Cornes FE, 2021, PHYSICA A, V568, DOI 10.1016/j.physa.2021.125744
   Dalladaku Y., 2020, P 2020 ANN GEN DONAL
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Elmqaddem N, 2019, INT J EMERG TECHNOL, V14, P234, DOI 10.3991/ijet.v14i03.9289
   Izard SG, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0900-2
   Hassannayebi E, 2020, J SIMUL, V14, P204, DOI 10.1080/17477778.2019.1664267
   Jin T., 1970, Bull. Japan Assoc. Fire Sci. Eng., V19, P1
   Kang ZX, 2019, APPL MATH COMPUT, V348, P355, DOI 10.1016/j.amc.2018.12.001
   Kinateder M, 2013, TRANSPORT RES F-TRAF, V17, P20, DOI 10.1016/j.trf.2012.09.001
   Li CY, 2017, IEEE T VIS COMPUT GR, V23, P1388, DOI 10.1109/TVCG.2017.2656958
   Li L, 2017, AM J TRANSL RES, V9, P3867
   Li S., 2009, J RES URBAN RAIL TRA, V12, P41
   Lovreglio R, 2021, VIRTUAL REAL-LONDON, V25, P133, DOI 10.1007/s10055-020-00447-5
   [陆君安 Lu Janan], 2002, [武汉大学学报. 工学版, Engineering journal of wuhan university], V35, P66
   Mossberg A, 2021, FIRE SAFETY J, V120, DOI 10.1016/j.firesaf.2020.103091
   Pantelidis V.S., 2010, THEMES SCI TECHNOLOG, V2, P59
   Pulijala Y, 2018, INT J ORAL MAX SURG, V47, P1199, DOI 10.1016/j.ijom.2018.01.005
   Purser D, 1993, P INT, P579
   Purser D, 1989, N90175811003 SEE AGA
   Purser D.A., 2002, TOXIC ASSESSMENT COM, V2, P83
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Sermet Y, 2019, SIGGRAPH '19 - ACM SIGGRAPH 2019 POSTERS, DOI 10.1145/3306214.3338550
   Sharma S, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR HUMAN-LIKE INTELLIGENCE (CIHLI), P1
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   Tao R, 2017, COMM COM INF SC, V752, P249, DOI 10.1007/978-981-10-6502-6_22
   Tichon J., 2011, J HLTH SAFETY RES PR, V3, P33
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Van Wyk E., 2009, P 6 INT C COMP GRAPH, P53, DOI DOI 10.1145/1503454.1503465
   Wang JH, 2015, CHIN CONT DECIS CONF, P232, DOI 10.1109/CCDC.2015.7161696
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   Woolley A, 2020, OCEAN ENG, V207, DOI 10.1016/j.oceaneng.2020.107351
   Xinxiong Liu, 2018, IOP Conference Series: Earth and Environmental Science, V170, DOI 10.1088/1755-1315/170/3/032155
   Zhang K, 2017, FED CONF COMPUT SCI, P1297, DOI 10.15439/2017F376
   Zhou B., 2011, J NAT DISS, V5, P008
NR 41
TC 3
Z9 3
U1 15
U2 54
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1145
EP 1155
DI 10.1007/s10055-022-00718-3
EA NOV 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000886887900001
DA 2024-07-18
ER

PT J
AU Tan, JI
   Kannis-Dymand, L
   Jones, C
AF Tan, Janice
   Kannis-Dymand, Lee
   Jones, Christian
TI Examining the potential of VR program Tilt Brush in reducing anxiety
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Flow; Presence; Anxiety; Tilt Brush; Drawing
ID VIRTUAL-REALITY TECHNOLOGY; ALPHA-ACTIVITY; TRAIT ANXIETY; FLOW;
   EXPERIENCE; EEG; PERFORMANCE; ART; REHABILITATION; VALIDATION
AB Recent advancement in technology has made virtual reality (VR) more accessible and immersive than ever before, resulting in its increasing utility in various industries. Despite this, VR has remained an underutilised tool within clinical psychology. This study aimed to explore the potential of using VR for therapeutic benefits through examining the level of flow and anxiety-reducing effects of freeform drawing in real life (on paper) versus drawing in VR (using Tilt Brush) via a randomised-controlled trial with 40 participants. State and trait anxiety was measured using the State-Trait Anxiety Inventory, level of flow was measured using the Long Flow State Scale, and level of presence was measured using the iGroup Presence Questionnaire. Overall level of flow was not significantly different between both groups, implying drawing in VR induces as much flow as drawing in real life. Level of flow was positively correlated to level of presence experienced in the VR group (p < .01). Although there was no significant interaction effect, both groups experienced an overall decrease in state anxiety, with the VR group experiencing a significant reduction of state anxiety from pre- to post-test (p < .01).
C1 [Tan, Janice; Kannis-Dymand, Lee] Univ Sunshine Coast, Sch Hlth & Behav Sci, Maroochydore, Qld, Australia.
   [Jones, Christian] Univ Sunshine Coast, Sch Law & Soc, Maroochydore, Qld, Australia.
C3 University of the Sunshine Coast; University of the Sunshine Coast
RP Jones, C (corresponding author), Univ Sunshine Coast, Sch Law & Soc, Maroochydore, Qld, Australia.
EM cmjones@usc.edu.au
RI Kannis-Dymand, Lee/N-3610-2017
OI Kannis-Dymand, Lee/0000-0002-1882-6121; Tan, Janice/0000-0002-5135-4445;
   Jones, Christian/0000-0003-4048-2545
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions. The authors did not receive support from any organisation
   for the submitted work.
CR Alsop T, 2022, VIRTUAL REALITY VR S
   Arpaia P, 2022, MINDFULNESS, V13, P556, DOI 10.1007/s12671-021-01783-6
   Bachen CM, 2016, COMPUT HUM BEHAV, V64, P77, DOI 10.1016/j.chb.2016.06.043
   Baghaei N, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/29681
   Bandelow B, 2015, INT CLIN PSYCHOPHARM, V30, P183, DOI 10.1097/YIC.0000000000000078
   Banyan Mental Health, 2022, SHORT TERM LONG TERM
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Belkofer CM, 2014, ART THER, V31, P61, DOI 10.1080/07421656.2014.903821
   Bisso E, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17176111
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Botella P, 2003, HUM PSYCHOPHARM CLIN, V18, P141, DOI 10.1002/hup.444
   Brice CF, 2002, PSYCHOPHARMACOLOGY, V164, P188, DOI 10.1007/s00213-002-1175-2
   Cahn BR, 2006, PSYCHOL BULL, V132, P180, DOI 10.1037/0033-2909.132.2.180
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Chan EY, 2018, J NUTR HEALTH AGING, V22, P1238, DOI 10.1007/s12603-018-1098-1
   Chan SHM, 2023, VIRTUAL REAL-LONDON, V27, P3285, DOI 10.1007/s10055-021-00604-4
   Chávez-Eakle RA, 2007, NEUROIMAGE, V38, P519, DOI 10.1016/j.neuroimage.2007.07.059
   Damasio A., 2000, FEELING WHAT HAPPENS, V1st ed.
   Dietrich A, 2004, CONSCIOUS COGN, V13, P746, DOI 10.1016/j.concog.2004.07.002
   Dietrich A., 2010, Effortless Attention: A New Perspective in the Cognitive Science of Attention and Action, P160, DOI [DOI 10.7551/MITPRESS/9780262013840.003.0008, 10.7551/mitpress/9780262013840.003.0008]
   Dietrich A, 2011, NEUROSCI BIOBEHAV R, V35, P1305, DOI 10.1016/j.neubiorev.2011.02.001
   Drake CR., 2014, American Journal of Applied Psychology, V2, P69, DOI [DOI 10.12691/AJAP-2-3-3, 10.12691/ajap-2-3-3]
   Eijlers R, 2019, ANESTH ANALG, V129, P1344, DOI 10.1213/ANE.0000000000004165
   Ercan I, 2015, REV ARGENT CLIN PSIC, V24, P143
   Evans J., 2020, Caffeine
   Falconer CJ, 2016, BJPSYCH OPEN, V2, P74, DOI 10.1192/bjpo.bp.115.002147
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Ferraz-Torres M, 2022, VIRTUAL REAL-LONDON, V26, P1307, DOI 10.1007/s10055-022-00633-7
   Fink A, 2006, EUR J NEUROSCI, V23, P2241, DOI 10.1111/j.1460-9568.2006.04751.x
   Garcia-Hernandez N, 2021, VIRTUAL REAL-LONDON, V25, P669, DOI 10.1007/s10055-020-00481-3
   GAUDRY E, 1975, MULTIVAR BEHAV RES, V10, P331, DOI 10.1207/s15327906mbr1003_6
   Gerçeker GÖ, 2018, J PERIANESTH NURS, V33, P981, DOI 10.1016/j.jopan.2017.12.010
   Geys J, 2006, TOXICOL LETT, V160, P218, DOI 10.1016/j.toxlet.2005.07.005
   Gold JI, 2018, J PEDIATR PSYCHOL, V43, P266, DOI 10.1093/jpepsy/jsx129
   Grant SS, 2018, INT J PSYCHOPHYSIOL, V133, P193, DOI 10.1016/j.ijpsycho.2018.07.001
   Hacmun I, 2021, ART PSYCHOTHER, V72, DOI 10.1016/j.aip.2020.101745
   Hacmun I, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02082
   Han I, 2022, J COMPUT ASSIST LEAR, V38, P1115, DOI 10.1111/jcal.12669
   Hanton S, 2002, RES Q EXERCISE SPORT, V73, P87, DOI 10.1080/02701367.2002.10608995
   Hefferon K.M., 2006, RES DANC EDUC, V7, P141, DOI DOI 10.1080/14647890601029527
   Holt NJ, 2018, ANN C BPS CONSCIOUSN
   igroup, 2016, IGR PRES QUEST IPQ F
   Jackson S., 2010, FLOW MANUAL MANUAL F
   Jackson S. A., 2002, Journal of Sport & Exercise Psychology, V24, P133
   Jackson SA, 1996, RES Q EXERCISE SPORT, V67, P76, DOI 10.1080/02701367.1996.10607928
   Jackson SA, 1996, J SPORT EXERCISE PSY, V18, P17, DOI 10.1123/jsep.18.1.17
   Jackson SA, 2008, J SPORT EXERCISE PSY, V30, P561, DOI 10.1123/jsep.30.5.561
   Jackson SA, 2001, J APPL SPORT PSYCHOL, V13, P129, DOI 10.1080/104132001753149865
   Store SJ, 2022, ART THER, V39, P173, DOI 10.1080/07421656.2021.2003144
   Jausovec N, 1996, INTELLIGENCE, V23, P159, DOI 10.1016/S0160-2896(96)90001-X
   Jiménez-Rodríguez C, 2023, VIRTUAL REAL-LONDON, V27, P385, DOI 10.1007/s10055-021-00605-3
   Jin SAA, 2011, J BROADCAST ELECTRON, V55, P114, DOI 10.1080/08838151.2011.546248
   Kaimal G, 2020, ART THER, V37, P16, DOI 10.1080/07421656.2019.1659662
   Kaimal G, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.589461
   Katahira K, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00300
   Kirchner JM, 2008, MED PROBL PERFORM AR, V23, P59
   Knyazev GG, 2007, NEUROSCI BIOBEHAV R, V31, P377, DOI 10.1016/j.neubiorev.2006.10.004
   Kothgassner OD, 2019, EUR J PSYCHOTRAUMATO, V10, DOI 10.1080/20008198.2019.1654782
   Lagopoulos J, 2009, J ALTERN COMPLEM MED, V15, P1187, DOI 10.1089/acm.2009.0113
   Laurer M, 2015, ART THER, V32, P177, DOI 10.1080/07421656.2015.1092731
   Li L, 2017, AM J TRANSL RES, V9, P3867
   Liszio S, 2019, ANN REV CYBERTHERAPY, V17, P65
   Lomas T, 2015, NEUROSCI BIOBEHAV R, V57, P401, DOI 10.1016/j.neubiorev.2015.09.018
   Mao YH, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12072987
   Maples-Keller JL, 2017, HARVARD REV PSYCHIAT, V25, P103, DOI 10.1097/HRP.0000000000000138
   Matamala-Gomez M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00279
   Mausbach BT, 2012, AGING MENT HEALTH, V16, P27, DOI 10.1080/13607863.2011.615738
   Miller S, 2003, CYBERPSYCHOL BEHAV, V6, P623, DOI 10.1089/109493103322725397
   Moral-Bofill L, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.899621
   Morganti F., 2004, CYBERTHERAPY INTERNE, P85
   Nijs L, 2012, INTERACT COMPUT, V24, P237, DOI 10.1016/j.intcom.2012.05.002
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Phelan I, 2023, VIRTUAL REAL-LONDON, V27, P201, DOI 10.1007/s10055-021-00552-z
   Phelan I, 2023, VIRTUAL REAL-LONDON, V27, P173, DOI 10.1007/s10055-021-00522-5
   Piskorz J, 2018, J SPEC PEDIATR NURS, V23, DOI 10.1111/jspn.12201
   Reiss S, 1997, J ANXIETY DISORD, V11, P201, DOI 10.1016/S0887-6185(97)00006-6
   Reynolds F., 2006, BRIT J OCCUP THER, V69, P255, DOI [https://doi.org/10.1177/030802260606900603, DOI 10.1177/030802260606900603]
   Richesin MT, 2021, ART PSYCHOTHER, V75, DOI 10.1016/j.aip.2021.101823
   Riva G, 2000, REHABIL PSYCHOL, V45, P81, DOI 10.1037/0090-5550.45.1.81
   Riva Giuseppe, 2004, J Neuroeng Rehabil, V1, P9, DOI 10.1186/1743-0003-1-9
   Riva G, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00164
   Riva G, 2016, CYBERPSYCH BEH SOC N, V19, P63, DOI 10.1089/cyber.2016.29025.gri
   Rizzo AA, 1997, J HEAD TRAUMA REHAB, V12, P1, DOI 10.1097/00001199-199712000-00002
   Robillard G, 2003, CYBERPSYCHOL BEHAV, V6, P467, DOI 10.1089/109493103769710497
   Roepke SK, 2008, AM J GERIAT PSYCHIAT, V16, P310, DOI 10.1097/JGP.0b013e3181662a80
   Rothbaum BO, 2002, J CONSULT CLIN PSYCH, V70, P428, DOI 10.1037//0022-006X.70.2.428
   Rowland DP, 2022, PSYCHOSOC INTERV, V31, P1, DOI 10.5093/pi2021a8
   Ryu JH, 2017, BRIT J SURG, V104, P1628, DOI 10.1002/bjs.10684
   Sandmire DA, 2012, ART THER, V29, P68, DOI 10.1080/07421656.2012.683748
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert T., 1999, VISUAL REPRESENTATIO, P269, DOI [DOI 10.1007/978-1-4471-0563-3_30, 10.1007/978-1-4471-0563-3_30]
   Snoswell AaronJ., 2019, JMIR BIOMEDICAL ENG, V4, DOI DOI 10.2196/15025
   Spiegel B, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219115
   Spielberger C. D., 1985, SO PSYCHOL, V2, P6
   Spielberger C. D., 1983, Manual for the State-Trait-Anxiety Inventory: STAI (Form Y)
   Swingle P.G., 2008, Biofeedback for the Brain: How Neurotherapy Effectively Treats Depression, ADHD, Autism, and More
   Tarrant J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01280
   Tse DCK, 2022, J HAPPINESS STUD, V23, P2517, DOI 10.1007/s10902-022-00514-5
   Vilalta-Abella F, 2015, STUD HEALTH TECHNOL, V219, P158, DOI 10.3233/978-1-61499-595-1-158
   Weibel D, 2011, INT J COMPUT GAMES T, V2011, DOI 10.1155/2011/282345
   White MP, 2018, NEUROPSYCH DIS TREAT, V14, P3001, DOI 10.2147/NDT.S179038
   White NE, 2009, INTRODUCTION TO QUANTITATIVE EEG AND NEUROFEEDBACK: ADVANCED THEORY AND APPLICATIONS, 2ND EDITION, P143, DOI 10.1016/B978-0-12-374534-7.00006-X
   Winston A.P., 2005, Advances in Psychiatric Treatment, V11, P432, DOI DOI 10.1192/APT.11.6.432
   Yang S, 2022, CYBERPSYCH BEH SOC N, V25, P101, DOI 10.1089/cyber.2021.0037
   Yin L., 2012, Proceedings of the International Conference on the Foundations of Digital Games - FDG'12, P41, DOI [DOI 10.1145/2282338.2282351, 10.1145/2282338.228.2351, DOI 10.1145/2282338.228.2351]
NR 106
TC 1
Z9 1
U1 5
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3379
EP 3391
DI 10.1007/s10055-022-00711-w
EA NOV 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000882672000001
PM 36405877
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Ustun, AB
   Karaoglan-Yilmaz, FG
   Yilmaz, R
AF Ustun, Ahmet Berk
   Karaoglan-Yilmaz, Fatma Gizem
   Yilmaz, Ramazan
TI Educational UTAUT-based virtual reality acceptance scale: a validity and
   reliability study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Technology acceptance; Virtual reality scale; Virtual
   reality acceptance; UTAUT
ID TECHNOLOGY ACCEPTANCE; USER ACCEPTANCE; INFORMATION-TECHNOLOGY; MODEL;
   TAM
AB This study aims to fill a gap in current research on virtual reality (VR) by developing a valid and reliable educational VR acceptance scale based on the unified theory of acceptance and use of technology (UTAUT) model to measure the level of students' acceptance and use of VR systems. In three phases, the reliability and validity studies of the scale were performed with a total sample of 440 second, third, and fourth-year undergraduate students studying at various faculties in the 2021-2022 academic year. The face validity and content validity of the scale were examined by obtaining expert opinions. Exploratory factor analysis (EFA) was carried out with the first group of samples (n = 186) and confirmatory factor analysis (CFA) was carried out with the second group of samples (n = 219). After conducting EFA, the scale had four factors with 18 items, explaining 67.62 percent of the total variance. According to CFA, the construct of the 4-factor with 21 items scale had a good fit with the data. Cronbach's alpha coefficient and test-retest methods reliability coefficient of scale that were calculated to determine the reliability of the measurements were found to be .88 and .89, respectively. The discriminatory power of the items was examined by comparing the participants' bottom 27 percent and top 27 percent and calculating adjusted item-total correlations. The findings revealed that the educational UTAUT-based virtual reality acceptance scale was a valid and reliable instrument to measure students' acceptance and use of VR systems.
C1 [Ustun, Ahmet Berk; Karaoglan-Yilmaz, Fatma Gizem; Yilmaz, Ramazan] Bartin Univ, Fac Sci, Dept Comp Technol & Informat Syst, Bartin, Turkey.
C3 Bartin University
RP Ustun, AB (corresponding author), Bartin Univ, Fac Sci, Dept Comp Technol & Informat Syst, Bartin, Turkey.
EM ustun.ab@gmail.com; gkaraoglanyilmaz@gmail.com;
   ramazanyilmaz067@gmail.com
RI Ustun, Ahmet Berk/AAQ-1271-2021; Yilmaz, Ramazan/HMP-0486-2023;
   Karaoglan Yilmaz, Fatma Gizem/W-2168-2017; Yilmaz, Ramazan/F-9517-2019
OI Ustun, Ahmet Berk/0000-0002-1640-4291; Yilmaz,
   Ramazan/0000-0002-2041-1750; Karaoglan Yilmaz, Fatma
   Gizem/0000-0003-4963-8083; Yilmaz, Ramazan/0000-0002-2041-1750
FU Scientific Research Coordinator of Bartin University [2020-SOS-A-002]
FX The present study was based on a part of a scientific research project
   funded by the Scientific Research Coordinator of Bartin University
   (Grant Number: 2020-SOS-A-002)
CR Akbulut Y., 2010, Sosyal bilimlerde SPSS uygulamalari: Sik kullanilan istatistiksel analizler ve aciklamali SPSS cozumleri
   Al-Emran M, 2018, COMPUT EDUC, V125, P389, DOI 10.1016/j.compedu.2018.06.008
   Alfadil M, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103893
   Alshehri A, 2019, INT J DIST EDUC, V17, P1, DOI 10.4018/IJDET.2019070101
   Alwahaishi Saleh, 2013, Journal of Technology Management & Innovation, V8, P61
   [Anonymous], 2010, DATA ANAL HDB SOCIAL
   Bonde MT, 2014, NAT BIOTECHNOL, V32, P694, DOI 10.1038/nbt.2955
   Buabeng-Andoh C, 2020, INTERACT TECHNOL SMA, V17, P455, DOI 10.1108/ITSE-02-2020-0028
   Burdea G. C., 2003, Virtual reality technology
   Byrne B, 2010, INTERNATIONAL HANDBOOK OF PSYCHOLOGY IN EDUCATION, P3
   Cattell R. B., 1978, The scientific use of factor analysis in behavioral life sciences
   Cokluk O., 2012, Sosyal Bilimler Icin Cok Degiskenli Istatistik: SPSS ve Lisrel Uygulamalari
   Comrey A. L., 1992, A first course in factor analysis, DOI DOI 10.4324/9781315827506-16
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   El Beheiry M, 2019, J MOL BIOL, V431, P1315, DOI 10.1016/j.jmb.2019.01.033
   Erkus A., 2012, Psikolojide Olcme Ve Olcek Gelistirme
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Fraenkel J.R., 2012, How to design and evaluate research in education, V8th
   Fransson G, 2020, EDUC INF TECHNOL, V25, P3383, DOI 10.1007/s10639-020-10119-1
   Gadelha R., 2018, CHILDHOOD EDUC, V94, P40, DOI [DOI 10.1080/00094056.2018.1420362, 10.1080/00094056.2018.1420362, 10.1080/00094056.2018, DOI 10.1080/00094056.2018]
   Garone A, 2019, BRIT J EDUC TECHNOL, V50, P2466, DOI 10.1111/bjet.12867
   Granic A, 2019, BRIT J EDUC TECHNOL, V50, P2572, DOI 10.1111/bjet.12864
   Hair JF., 1979, Multivariate data analysis: With readings
   Hanson K, 2008, EDUC TECHNOL SOC, V11, P118
   Hooper D, 2007, Electronic Journal of Business Research Methods, V6, P53, DOI [DOI 10.21427/D7CF7R, 10.21427/D7CF7R]
   Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Huang KT, 2019, CYBERPSYCH BEH SOC N, V22, P105, DOI 10.1089/cyber.2018.0150
   Ilhan M, 2014, EGIT BILIM, V39, P31
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Kaminska D, 2019, INFORMATION, V10, DOI 10.3390/info10100318
   Karaoglan-Yilmaz FG, 2024, INTERACT LEARN ENVIR, V32, P447, DOI 10.1080/10494820.2022.2091603
   Kline R.B., 1994, EASY GUIDE FACTOR AN
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Macedo IM, 2017, COMPUT HUM BEHAV, V75, P935, DOI 10.1016/j.chb.2017.06.013
   Magsamen-Conrad K, 2015, COMPUT HUM BEHAV, V50, P186, DOI 10.1016/j.chb.2015.03.032
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Manis KT, 2019, J BUS RES, V100, P503, DOI 10.1016/j.jbusres.2018.10.021
   Marangunic N, 2015, UNIVERSAL ACCESS INF, V14, P81, DOI 10.1007/s10209-014-0348-1
   McGovern E, 2020, J EDUC BUS, V95, P490, DOI 10.1080/08832323.2019.1703096
   Moon JW, 2001, INFORM MANAGE-AMSTER, V38, P217, DOI 10.1016/S0378-7206(00)00061-6
   Norris MW., 2019, Professional Safety, V64, P36
   Pallant J., 2005, SPSS Survival Manual. A Step by Step Guide to Data Analysis Using IBM SPSS, DOI 10.4324/9781003117452
   Pan XQ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.564294
   Papanastasiou G, 2019, VIRTUAL REAL-LONDON, V23, P425, DOI 10.1007/s10055-018-0363-2
   Parsons S, 2016, EDUC RES REV-NETH, V19, P138, DOI 10.1016/j.edurev.2016.08.001
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Rogers Sol., 2019, FORBES
   Sánchez-Cabrero R, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01338
   Sezer B, 2019, AUSTRALAS J EDUC TEC, V35, P15, DOI 10.14742/ajet.3959
   Shiferaw Kirubel Biruk, 2019, Informatics in Medicine Unlocked, V17, P26, DOI 10.1016/j.imu.2019.100182
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Tabachnick B.G., 2012, Using multivariate statistics, V6th
   Taherdoost H, 2018, PROCEDIA MANUF, V22, P960, DOI 10.1016/j.promfg.2018.03.137
   Tezbasaran A.A., 1997, Likert type scale preparation guide
   Tondeur J., 2020, ENCY TEACHER ED, P1, DOI [https://doi.org/10.1007/978-981-13-1179-6111-1, DOI 10.1007/978-981-13-1179-6_111-1]
   Tyng CM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01454
   Ustun AB, 2020, Mobile devices and smart gadgets in medical sciences, P56
   Ustun AB., 2022, YABANC DIL RETIMINDE, P127
   Ustun AB, 2021, EDUC INF TECHNOL, V26, P4751, DOI 10.1007/s10639-021-10500-8
   Velev D., 2017, INT J LEARN TEACH, V3, P33, DOI DOI 10.18178/IJLT.3.1.33-37
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2012, MIS QUART, V36, P157
   Yu CS, 2012, J ELECTRON COMMER RE, V13, P104
   Zhang MS, 2018, INT J EMERG TECHNOL, V13, P138, DOI 10.3991/ijet.v13i01.7773
NR 69
TC 7
Z9 8
U1 11
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1063
EP 1076
DI 10.1007/s10055-022-00717-4
EA NOV 2022
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000882672000002
DA 2024-07-18
ER

PT J
AU Lee, Y
   Park, D
   Kim, YM
AF Lee, Yushin
   Park, Donggun
   Kim, Yong Min
TI The effect of wearing a head-mounted display on the boundaries of the
   cervical range of motion based on perceived comfort in a static posture
SO VIRTUAL REALITY
LA English
DT Article
DE Head-mounted display; Virtual reality; Perceived comfort; Cervical range
   of motion
ID VIRTUAL-REALITY; NATURAL INTERACTION; JOINT RANGE; NECK PAIN;
   DISCOMFORT; DISORDERS; EXPOSURE; GENDER; ROSA; AGE
AB The head-mounted display (HMD) for virtual reality (VR) systems is becoming more popular due to technological advancements, providing users with a more immersive experience. Since an HMD is a wearable device, head movement may be restricted, compared to situations in which an HMD is not worn, and perceived discomfort during head movement may increase. Thus, this study recruited 30 participants and investigated the effects on perceived comfort from wearing an HMD, considering the cervical range of motion (CROM) in four head movement directions (flexion, extension, lateral bending, and rotation). We propose angle boundaries for joint isocomfort in order to evaluate the appropriateness of working postures in an HMD-based VR environment. Although the maximum CROM for head movement in all directions was not significantly limited by wearing the HMD, the main effects of wearing HMD on perceived discomfort were observed from extension and lateral bending. Based on the perceived CROM comfort score, appropriate ranges for each head movement direction are proposed. This study contributes to the establishment of ergonomic guidelines on the use of HMDs and the development of VR content.
C1 [Lee, Yushin] Pukyong Natl Univ, Dept Ind & Data Engn, Ind Data Sci & Engn, Busan, South Korea.
   [Park, Donggun] Pukyong Natl Univ, Media Sch, Busan, South Korea.
   [Kim, Yong Min] Hoseo Univ, Dept Big Data & AI, Asan, South Korea.
C3 Pukyong National University; Pukyong National University; Hoseo
   University
RP Kim, YM (corresponding author), Hoseo Univ, Dept Big Data & AI, Asan, South Korea.
EM ysl@pknu.ac.kr; dgpark@pknu.ac.kr; ymk@hoseo.edu
OI Kim, Yong Min/0000-0003-4796-490X
FU Basic Science Research Programs through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2021R1I1A3052745]; National
   Research Foundation of Korea(NRF) - Korea government(MSIT)
   [2022R1G1A1011526]
FX This research was supported by Basic Science Research Programs through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (No. 2021R1I1A3052745). This work was supported by the
   National Research Foundation of Korea(NRF) grant funded by the Korea
   government(MSIT) (No. 2022R1G1A1011526).
CR Ball C, 2021, TELEMAT INFORM, V65, DOI 10.1016/j.tele.2021.101728
   Bodine K, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P57, DOI 10.1109/ISWC.2003.1241394
   Brondi R, 2016, INFORM-J COMPUT INFO, V40, P311
   Chowdhury Nabila, 2017, Occupational Ergonomics, V13, P37, DOI 10.3233/OER-170252
   Coenen P, 2016, ERGONOMICS, V59, P1182, DOI 10.1080/00140139.2015.1130862
   Colim Ana., 2019, Occupational and Environmental Safety and Health, P409
   Diaconescu C, 2019, COMM COM INF SC, V904, P109, DOI 10.1007/978-3-030-05819-7_9
   Doriot N, 2006, ERGONOMICS, V49, P269, DOI 10.1080/00140130500489873
   Dunnagan CL, 2020, J CHEM EDUC, V97, P3060, DOI 10.1021/acs.jchemed.0c00548
   Field A, 2018, Discovering Statistics Using IBM SPSS Statistics, Vfifth
   Gao Z, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061986
   Gartner, 2020, GARTNER 2020 MAGIC Q
   Gemperle F, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P116, DOI 10.1109/ISWC.1998.729537
   Grabowski, 2021, VIRTUAL REALITY VIRT
   Harrison MF, 2015, AEROSP MED HUM PERF, V86, P46, DOI 10.3357/AMHP.4027.2015
   Haynes MJ, 2002, J MANIP PHYSIOL THER, V25, P579, DOI 10.1067/mmt.2002.128370
   Hignett S, 2000, APPL ERGON, V31, P201, DOI 10.1016/S0003-6870(99)00039-3
   Hu HT, 2006, INT J IND ERGONOM, V36, P861, DOI 10.1016/j.ergon.2006.06.012
   Huang KT, 2020, CYBERPSYCH BEH SOC N, V23, P143, DOI 10.1089/cyber.2019.0269
   Jankowski J, 2015, INT J HUM-COMPUT INT, V31, P882, DOI 10.1080/10447318.2015.1039909
   Karl KA, 2022, SMALL GR RES, V53, P343, DOI 10.1177/10464964211015286
   Kee D, 2001, ERGONOMICS, V44, P614, DOI 10.1080/00140130110038044
   Kee D, 2012, APPL ERGON, V43, P277, DOI 10.1016/j.apergo.2011.06.002
   Kim E, 2021, ERGONOMICS, V64, P891, DOI 10.1080/00140139.2020.1869320
   Knight JF, 2005, HUM FACTORS, V47, P77, DOI 10.1518/0018720053653875
   Knight JF, 2004, AVIAT SPACE ENVIR MD, V75, P123
   Krantz JH, 2015, US
   Kushwaha DK, 2016, INT J IND ERGONOM, V52, P29, DOI 10.1016/j.ergon.2015.08.003
   Laaki H, 2019, IEEE ACCESS, V7, P20325, DOI 10.1109/ACCESS.2019.2897018
   Laeser K. L., 1998, Journal of Research on Computing in Education, V31, P173
   Lombardo JM, 2019, INT J INTERACT MULTI, V5, P54, DOI 10.9781/ijimai.2019.07.003
   MCATAMNEY L, 1993, APPL ERGON, V24, P91, DOI 10.1016/0003-6870(93)90080-S
   Ogutu J, 2015, WORK, V52, P19, DOI 10.3233/WOR-141946
   Pallavicini F, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P195, DOI 10.1145/3341215.3355736
   Park W, 2010, ERGONOMICS, V53, P102, DOI 10.1080/00140130903311617
   Pears M, 2020, SCOT MED J, V65, P112, DOI 10.1177/0036933020956317
   Pérez-Escamirosa F, 2020, SURG INNOV, V27, P549, DOI 10.1177/1553350620952183
   Punnett L, 2004, J ELECTROMYOGR KINES, V14, P13, DOI 10.1016/j.jelekin.2003.09.015
   Rahman MNA, 2017, ADV SCI LETT, V23, P7597, DOI 10.1166/asl.2017.9531
   Reynolds J, 2009, EUR SPINE J, V18, P863, DOI 10.1007/s00586-009-0894-z
   Rhiu I, 2020, INT J IND ERGONOM, V79, DOI 10.1016/j.ergon.2020.103002
   Richardson AR, 2007, HUM FACTORS, V49, P507, DOI 10.1518/001872007X200139
   Riva G, 2020, CYBERPSYCH BEH SOC N, V23, P277, DOI 10.1089/cyber.2020.29183.gri
   Seng KY, 2002, CLIN BIOMECH, V17, P545, DOI 10.1016/S0268-0033(02)00067-0
   Shirer M., 2020, WORLDWIDE SPENDING A
   Singh RP, 2020, DIABETES METAB SYND, V14, P661, DOI 10.1016/j.dsx.2020.05.011
   Smith K, 2008, MANUAL THER, V13, P552, DOI 10.1016/j.math.2007.07.005
   SNIJDERS CJ, 1991, J BIOMECH, V24, P783, DOI 10.1016/0021-9290(91)90303-5
   Sonne M, 2012, APPL ERGON, V43, P98, DOI 10.1016/j.apergo.2011.03.008
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Standaert W, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2020.103393
   Steinicke Frank, 2020, SUI '20: Symposium on Spatial User Interaction, DOI 10.1145/3385959.3422699
   Talwar S, 2023, J SUSTAIN TOUR, V31, P2564, DOI 10.1080/09669582.2022.2029870
   Tvaryanas A., 2019, COMPARING EFFECTS US
   Wiederhold BK, 2020, CYBERPSYCH BEH SOC N, V23, P437, DOI 10.1089/cyber.2020.29188.bkw
NR 55
TC 3
Z9 3
U1 6
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 815
EP 828
DI 10.1007/s10055-022-00684-w
EA SEP 2022
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000854736900001
DA 2024-07-18
ER

PT J
AU Al-Jundi, HA
   Tanbour, EY
AF Al-Jundi, Hamza A.
   Tanbour, Emad Y.
TI Design and evaluation of a high- fidelity virtual reality manufacturing
   planning system
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Manufacturing planning; Fidelity; Digital twin; Virtual
   prototyping; Simulation
ID 3D VISUALIZATION; INDUSTRY; ENVIRONMENTS; FUTURE
AB Manufacturing applications of virtual reality (VR) technology are growing. The challenge is to design, integrate, and evaluate VR simulation for manufacturing Systems that improves the effectiveness of the planning process. In this paper, we discuss the technical infrastructure necessary to design a collaborative virtual manufacturing planning system. We describe the VR system setup and the integration of hardware and software to produce high-fidelity virtual simulation for manufacturing planning purposes. The designing guidelines are demonstrated by a high-fidelity VR simulation of a stamping process. The VR simulation also presents a method of visualizing computer-aided engineering content. Also, this paper assesses the factors that affect overall fidelity of the VR simulation. Objective evaluation of the VR simulation was conducted using the fidelity framework and the scales, whereas the subjective evaluation methods used were VR-simulation-driven data interpretation. The VR simulation was evaluated by a selective sample of 33 senior engineering students using a highly reliable scale (Cronbach's Alpha = .93) questionnaire that was designed to evaluate functionality, performance, and experience. The results of the subjective evaluation validate the evaluation of objective scales to be high-medium for the VR system used (M = 5.24, M = 5.11) respectively. Significant positive relationships were found between all factors, except distraction, which had a significant negative relationship with fidelity. Overall, the realism and sensory systems factors were found to be the main significant factors affecting the fidelity of the VR system.
C1 [Al-Jundi, Hamza A.; Tanbour, Emad Y.] Eastern Michigan Univ EMU, Coll Engn & Technol, Ypsilanti, MI 48197 USA.
RP Al-Jundi, HA (corresponding author), Eastern Michigan Univ EMU, Coll Engn & Technol, Ypsilanti, MI 48197 USA.
EM haljundi@emich.edu; etanbour@emich.edu
OI Al-Jundi, Hamza/0000-0002-5287-7061
FU Eastern Michigan University
FX This work was funded by Eastern Michigan University.
CR Abidi MH, 2019, INT J ADV MANUF TECH, V105, P3743, DOI 10.1007/s00170-019-03801-3
   Akpan IJ, 2017, COMPUT IND ENG, V112, P197, DOI 10.1016/j.cie.2017.08.020
   Al-Jundi H, 2021, VIRE D 20 00236R3
   Al-Jundi HA, 2022, VIRTUAL REAL-LONDON, V26, P1103, DOI 10.1007/s10055-021-00618-y
   Alcácer V, 2019, ENG SCI TECHNOL, V22, P899, DOI 10.1016/j.jestch.2019.01.006
   [Anonymous], 2017, Project management body of knowledge (pmbok guide)
   Azizi A, 2019, INT J INTERACT DES M, V13, P373, DOI 10.1007/s12008-018-0501-9
   Bendul JC, 2019, COMPUT IND, V105, P260, DOI 10.1016/j.compind.2018.10.010
   Büttner S, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P433, DOI 10.1145/3056540.3076193
   Cabrera ME, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00008
   Cecil, 2017, IEEE T SYST MAN CY-S, P1
   Cecil J, 2007, INT J ADV MANUF TECH, V31, P846, DOI 10.1007/s00170-005-0267-7
   CHUNG C, 2003, P INT C AG MAN ICAM, P369
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   Damiani L, 2018, IFAC PAPERSONLINE, V51, P624, DOI 10.1016/j.ifacol.2018.08.388
   Elor Aviv, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3396249
   Franzluebbers A, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P16, DOI 10.1145/3267782.3267790
   Ghobakhloo M, 2018, J MANUF TECHNOL MANA, V29, P910, DOI 10.1108/JMTM-02-2018-0057
   Grieve RJ, 1994, COMPUTERISED MANUFAC
   Groover M.P., 2015, Automation, production systems, and computer-integrated manufacturing
   Guo ZY, 2020, COMPUT IND ENG, V140, DOI 10.1016/j.cie.2019.106227
   HART S G, 1988, P139
   Hoogenes Jennifer, 2018
   Ioannidis C, 2020, INT ARCH PHOTOGRAMM, V44-4, P57, DOI 10.5194/isprs-archives-XLIV-4-W1-2020-57-2020
   Jain S, 2017, INT J PROD RES, V55, P5450, DOI 10.1080/00207543.2017.1321799
   Jayaram S, 1999, IEEE COMPUT GRAPH, V19, P44, DOI 10.1109/38.799739
   Jones A, 2021, USE VIRTUAL REALITY, DOI [10.1007/978-3-030-72781-9_10, DOI 10.1007/978-3-030-72781-9_10]
   Kern AC, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00020
   Kesavadas T., 1999, Industrial Virtual Reality: Manufacturing and Design Tool for the Next Millennium. NIST-ASME Industrial Virtual Reality Symposium. Symposium on Virtual Environment for Manufacturing, P201
   Lindquist M, 2020, LANDSCAPE URBAN PLAN, V202, DOI 10.1016/j.landurbplan.2020.103884
   Liu HX, 2019, IEEE INT CONF ROBOT, P5180, DOI [10.1109/icra.2019.8794230, 10.1109/ICRA.2019.8794230]
   Malik AA, 2020, INT J COMPUT INTEG M, V33, P22, DOI 10.1080/0951192X.2019.1690685
   Massoth C, 2019, BMC MED EDUC, V19, DOI 10.1186/s12909-019-1464-7
   Menzies RJ, 2016, VIRTUAL REAL-LONDON, V20, P173, DOI 10.1007/s10055-016-0288-6
   Mourtzis D, 2020, INT J PROD RES, V58, P1927, DOI 10.1080/00207543.2019.1636321
   Nåfors D, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131911102
   Nunnally JC, 1978, PSYCHOMETRIC THEORY
   Oyekan JO, 2019, ROBOT CIM-INT MANUF, V55, P41, DOI 10.1016/j.rcim.2018.07.006
   Pala P, 2021, TRANSPORT RES F-TRAF, V82, P15, DOI [10.1016/j.trf.2021.07.016, DOI 10.1016/J.TRF.2021.07.016]
   Paritala PK, 2017, PROCEDIA ENGINEER, V174, P982, DOI 10.1016/j.proeng.2017.01.250
   Perez L, 2019, COMPUT IND, V109, P114, DOI 10.1016/j.compind.2019.05.001
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Rosa E, 2021, THEOR ISS ERGON SCI, V22, P83, DOI 10.1080/1463922X.2020.1758830
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smith RP, 1999, INT J PROD RES, V37, P3941, DOI 10.1080/002075499189853
   Söderberg R, 2017, CIRP ANN-MANUF TECHN, V66, P137, DOI 10.1016/j.cirp.2017.04.038
   Srinivasan H, 1999, ROBOT CIM-INT MANUF, V15, P231, DOI 10.1016/S0736-5845(99)00023-X
   Tabachnick, 2007, USING MULTIVARIATE S, V5th
   Tao F, 2019, INT J PROD RES, V57, P3935, DOI 10.1080/00207543.2018.1443229
   Taylor F, 2000, INT DESIGN ENG TECHN, V35111, P737
   Tseng M. M., 1998, Integrated Manufacturing Systems, V9, P334, DOI 10.1108/09576069810238682
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Volonte M, 2021, J MULTIMODAL USER IN, V15, P109, DOI 10.1007/s12193-020-00341-z
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yazdi PG, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11051454
   Yazdi PG, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10093031
   Zizza C, 2018, CONSUM COMM NETWORK
   Zotter F., 2019, Ambisonics: A Practical 3D Audio Theory for Recording, Studio Production,Sound Reinforcement, and Virtual Reality, P1, DOI [10.1007/978-3-030-17207-7, DOI 10.1007/978-3-030-17207-7]
NR 62
TC 2
Z9 2
U1 1
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 677
EP 697
DI 10.1007/s10055-022-00683-x
EA AUG 2022
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000844003400001
DA 2024-07-18
ER

PT J
AU Rojo, A
   Cortina, J
   Sánchez, C
   Urendes, E
   García-Carmona, R
   Raya, R
AF Rojo, Ana
   Cortina, Javier
   Sanchez, Cristina
   Urendes, Eloy
   Garcia-Carmona, Rodrigo
   Raya, Rafael
TI Accuracy study of the Oculus Touch v2 versus inertial sensor for a
   single-axis rotation simulating the elbow's range of motion
SO VIRTUAL REALITY
LA English
DT Article
DE Accuracy; Elbow; Inertial measurement unit; Range of motion;
   Rehabilitation; Virtual reality
ID REHABILITATION; RELIABILITY; STROKE; SYSTEM
AB Virtual reality (VR) has emerged as a valid addition to conventional therapy in rehabilitation and sports medicine. This has enabled the development of novel and affordable rehabilitation strategies. However, before VR devices can be used in these situations, they must accurately capture the range of motion of the body-segment where they are mounted. This study aims to state the accuracy of the Oculus Touch v2 controller when used to measure the elbow's motion in the sagittal plane. The controller is benchmarked against an inertial sensor (ENLAZA (TM)), which has already been validated as a reliable measurement device. We have developed a virtual environment that matches both the Oculus Touch v2 and the inertial sensor orientations using a digital goniometer. We have also collected the orientation measurements given by each system for a set of 17 static angles that cover the full range of normal elbow flexion and hyperextension motion, in 10 degrees intervals from - 10 degrees (hyperextension) to 150 degrees (flexion). We have applied the intra-rater reliability test to assess the level of agreement between the measurements of these devices, obtaining a value of 0.999, with a 95% confidence interval ranged from 0.996 to 1.000. By analyzing the angle measurement outcomes, we have found that the accuracy degrades at flexion values between 70 degrees and 110 degrees, peaking at 90 degrees. The accuracy of Oculus Touch v2 when used to capture the elbow's flexion motion is good enough for the development of VR rehabilitation applications based on it. However, the flaws in the accuracy that have been revealed in this experimental study must be considered when designing such applications.
C1 [Rojo, Ana; Cortina, Javier; Sanchez, Cristina; Urendes, Eloy; Garcia-Carmona, Rodrigo; Raya, Rafael] Univ San Pablo CEU, Dept Tecnol Informac, Escuela Politecn Super, CEU Univ, Madrid 28668, Spain.
   [Rojo, Ana] Spanish Natl Res Council, Cajal Inst, Neural Rehabil Grp, Madrid 28002, Spain.
C3 San Pablo CEU University; Consejo Superior de Investigaciones
   Cientificas (CSIC); CSIC - Instituto Cajal (IC)
RP Rojo, A (corresponding author), Univ San Pablo CEU, Dept Tecnol Informac, Escuela Politecn Super, CEU Univ, Madrid 28668, Spain.; Rojo, A (corresponding author), Spanish Natl Res Council, Cajal Inst, Neural Rehabil Grp, Madrid 28002, Spain.
EM ana.rojoagusti@usp.ceu.es; javier.cortinamonton@usp.ceu.es;
   cristina.sanchezlopezpablo@ceu.es; eloyjose.urendesjimenez@ceu.es;
   rodrigo.garciacarmona@ceu.es; rafael.rayalopez@ceu.es
RI Raya, Rafael/AFR-7593-2022; Sánchez, Cristina/K-7561-2017; Garcia
   Carmona, Rodrigo/L-8787-2014
OI Raya, Rafael/0000-0001-7176-6984; Sanchez, Cristina/0000-0002-3415-0088;
   Garcia Carmona, Rodrigo/0000-0003-4427-9579; Urendes Jimenez,
   Eloy/0000-0003-3385-5307; Rojo Agusti, Ana/0000-0002-3047-5731
FU SPANISH GOVERNMENT (FEDER/Ministry of Science and Innovation/AEI)
   [RTI2018-097122-A-I00]
FX This research was funded by the SPANISH GOVERNMENT (FEDER/Ministry of
   Science and Innovation/AEI.), Grant Number RTI2018-097122-A-I00.
CR Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Borresen A, 2019, INT J TELEREHABILITA, V11, P23, DOI 10.5195/ijt.2019.6275
   Boyd LA, 2001, NEUROSCI LETT, V298, P65, DOI 10.1016/S0304-3940(00)01734-1
   Brandao AF, 2020, LECT NOTES COMPUT SC, V12255, P757, DOI 10.1007/978-3-030-58820-5_54
   Brodie MA, 2008, COMPUT METHOD BIOMEC, V11, P235, DOI 10.1080/10255840802125526
   Calabro RS, 2020, NEUROL SCI, V41, P933, DOI 10.1007/s10072-019-04194-7
   Camomilla V, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030873
   Campeau-Lecours A, 2020, J BIOMECH ENG-T ASME, V142, DOI 10.1115/1.4046203
   CAREN, 2021, WHY CAREN
   Cha YR, 2017, ADV SCI LETT, V23, P12807, DOI 10.1166/asl.2017.10904
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Constine J., 2015, TechCrunch
   Costa V, 2020, PEERJ, V8, DOI 10.7717/peerj.9687
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Cui JJ, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/7681237
   Oña ED, 2018, IEEE INT CONF SERIOU
   De Luca R, 2020, APPL NEUROPSYCH-CHIL, V9, P282, DOI 10.1080/21622965.2019.1576525
   Dempsey Paul, 2016, Engineering & Technology, V11, P80
   Dhawan AP, 2016, IEEE J TRANSL ENG HE, V4, DOI 10.1109/JTEHM.2016.2635126
   Ertzgaard P, 2016, MANUAL THER, V21, P241, DOI 10.1016/j.math.2015.09.004
   Farahani Navid, 2016, J Pathol Inform, V7, P22, DOI 10.4103/2153-3539.181766
   Fitzgerald D, 2007, P ANN INT IEEE EMBS, P4870, DOI 10.1109/IEMBS.2007.4353431
   Jerald J., 2015, VR BOOK HUMAN CENTER, DOI 10.1145/2792790
   Jost TA, 2021, DISABIL REHABIL-ASSI, V16, P632, DOI 10.1080/17483107.2019.1688398
   Kalron A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0124-y
   Kim JN, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/168078
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   LLC A, 2021, ANT
   Maillot P, 2012, PSYCHOL AGING, V27, P589, DOI 10.1037/a0026268
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Passos DE, 2020, INT C HUM INT, P1926
   Patil AK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185342
   Porciuncula F, 2018, PM&R, V10, pS220, DOI 10.1016/j.pmrj.2018.06.013
   Postolache O, 2019, INT SYMP ADV TOP, P16
   Premerlani W., 2009, Direction cosine matrix imu: Theory, P13
   Raaen K, 2015, LECT NOTES COMPUT SC, V9353, P457, DOI 10.1007/978-3-319-24589-8_40
   Rachitskaya A, 2020, OPHTHALMOL RETINA, V4, P613, DOI 10.1016/j.oret.2019.11.007
   Rind AR, 2006, 10TH IEEE INTERNATIONAL MULTITOPIC CONFERENCE 2006, PROCEEDINGS, P337
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Serrano M, 2014, CAMBIO MNIMO CLNICAM
   Shahmoradi L, 2021, J BODYW MOV THER, V26, P113, DOI 10.1016/j.jbmt.2020.10.006
   Shum L.C., 2019, JMIR BIOMEDICAL ENG, V4, pe12291, DOI [10.2196/12291, DOI 10.2196/12291]
   Soucie JM, 2011, HAEMOPHILIA, V17, P500, DOI 10.1111/j.1365-2516.2010.02399.x
   Spitzley KA, 2019, J BIOMECH, V87, P172, DOI 10.1016/j.jbiomech.2019.02.015
   Wu G, 2005, J BIOMECH, V38, P981, DOI 10.1016/j.jbiomech.2004.05.042
   YOUDAS JW, 1991, PHYS THER, V71, P98, DOI 10.1093/ptj/71.2.98
NR 47
TC 5
Z9 5
U1 1
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1651
EP 1662
DI 10.1007/s10055-022-00660-4
EA MAY 2022
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000801118900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Caserman, P
   Garcia-Agundez, A
   Zerban, AG
   Göbel, S
AF Caserman, Polona
   Garcia-Agundez, Augusto
   Zerban, Alvar Gamez
   Goebel, Stefan
TI Cybersickness in current-generation virtual reality head-mounted
   displays: systematic review and outlook
SO VIRTUAL REALITY
LA English
DT Review
DE Immersive virtual reality; Head-mounted display; Cybersickness; Visually
   induced motion sickness
ID INDUCED MOTION SICKNESS; ENVIRONMENT; SYMPTOMS; PERFORMANCE; ADAPTATION;
   VALIDATION
AB Cybersickness (CS) is a term used to refer to symptoms, such as nausea, headache, and dizziness that users experience during or after virtual reality immersion. Initially discovered in flight simulators, commercial virtual reality (VR) head-mounted displays (HMD) of the current generation also seem to cause CS, albeit in a different manner and severity. The goal of this work is to summarize recent literature on CS with modern HMDs, to determine the specificities and profile of immersive VR-caused CS, and to provide an outlook for future research areas. A systematic review was performed on the databases IEEE Xplore, PubMed, ACM, and Scopus from 2013 to 2019 and 49 publications were selected. A summarized text states how different VR HMDs impact CS, how the nature of movement in VR HMDs contributes to CS, and how we can use biosensors to detect CS. The results of the meta-analysis show that although current-generation VR HMDs cause significantly less CS (p < 0.001), some symptoms remain as intense. Further results show that the nature of movement and, in particular, sensory mismatch as well as perceived motion have been the leading cause of CS. We suggest an outlook on future research, including the use of galvanic skin response to evaluate CS in combination with the golden standard (Simulator Sickness Questionnaire, SSQ) as well as an update on the subjective evaluation scores of the SSQ.
C1 [Caserman, Polona; Garcia-Agundez, Augusto; Zerban, Alvar Gamez; Goebel, Stefan] Tech Univ Darmstadt, Multimedia Commun Lab, D-64283 Darmstadt, Germany.
C3 Technical University of Darmstadt
RP Caserman, P (corresponding author), Tech Univ Darmstadt, Multimedia Commun Lab, D-64283 Darmstadt, Germany.
EM Polona.Caserman@kom.tu-darmstadt.de;
   Augusto.Garcia-Agundez@kom.tu-darmstadt.de;
   Alvar.Zerban@kom.tu-darmstadt.de; Stefan.Gobel@kom.tu-darmstadt.de
RI Garcia-Agundez, Augusto/AAK-5829-2021
OI Garcia-Agundez, Augusto/0000-0002-5440-1032; Caserman,
   Polona/0000-0002-3252-4533
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR [Anonymous], 2005, Introduction to and review of simulator sickness research
   [Anonymous], 1975, Motion sickness
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bos JE, 2011, DISPLAYS, V32, P189, DOI 10.1016/j.displa.2010.09.005
   Bruck S, 2011, DISPLAYS, V32, P153, DOI 10.1016/j.displa.2011.07.002
   Caserman P, 2019, LECT NOTES COMPUT SC, V11863, P57, DOI 10.1007/978-3-030-34644-7_5
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen Y, 2015, PHARMACOGN MAG, V11, P435, DOI 10.4103/0973-1296.160444
   Chowdhury TI, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139143
   Chowdhury TI, 2017, INT CONF GAMES VIRTU, P125, DOI 10.1109/VS-GAMES.2017.8056580
   Christensen JV, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234297
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   David-Grignot Stephane, 2014, Proceedings 2014 IEEE International Test Conference (ITC), DOI 10.1109/TEST.2014.7035301
   Deb S, 2017, APPL ERGON, V65, P449, DOI 10.1016/j.apergo.2017.03.007
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dennison MS, 2017, APPL ERGON, V58, P215, DOI 10.1016/j.apergo.2016.06.014
   DiZio P, 1997, ADV HUM FACT ERGON, V21, P893
   DiZio P., 2000, Motion Sickness Side Effects and Aftereffects of Immersive Virtual Environments Created with Helmet-Mounted Visual Displays
   Dorado JL, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P47, DOI 10.1109/3DUI.2014.6798841
   EBENHOLTZ SM, 1994, AVIAT SPACE ENVIR MD, V65, P1032
   Farmani Y, 2018, P 44 GRAPH INT C, P168, DOI [DOI 10.20380/GI2018.23, 10.20380/GI2018.23, 10.20380/GI2018.21]
   Frommel J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102082
   Fuchs Philippe, 2017, Virtual Reality Headsets-A Theoretical and Pragmatic Approach, DOI [10.1201/9781315208244, DOI 10.1201/9781315208244]
   Garcia-Agundez A., 2019, IJVR, V19, P1, DOI DOI 10.20870/IJVR.2019.19.1.2907
   Garcia-Agundez A, 2019, GAMES HEALTH J, V8, P439, DOI 10.1089/g4h.2019.0045
   Garcia-Agundez A, 2017, LECT NOTES COMPUT SC, V10622, P203, DOI 10.1007/978-3-319-70111-0_19
   Garde, 2018, 2018 CHI C HUM FACT, DOI 10.1145/3170427.3188638
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Golding JF, 2015, CURR OPIN NEUROL, V28, P83, DOI 10.1097/WCO.0000000000000163
   Hecht H, 2015, P DRIV SIM C
   Hettinger L.J., 1992, Presence: Teleoperators & Virtual Environments, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Howarth PA, 1997, DISPLAYS, V18, P107, DOI 10.1016/S0141-9382(97)00011-5
   Hu SQ, 1999, AVIAT SPACE ENVIR MD, V70, P766
   Hunt X, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P598, DOI 10.1145/3292147.3292225
   Imai K, 2006, J PHYSIOL SCI, V56, P341, DOI 10.2170/physiolsci.RP005306
   Iskenderova A, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P561, DOI 10.1145/3116595.3116618
   Jacob Habgood M. P., 2018, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P371, DOI 10.1109/VR.2018.8446130
   Jin WN, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P382, DOI 10.1109/GEM.2018.8516469
   John NW, 2018, IEEE T VIS COMPUT GR, V24, P1867, DOI 10.1109/TVCG.2017.2700273
   Kennedy R., 1992, INT J AVIAT PSYCHOL, V2, P23, DOI [DOI 10.1207/S15327108IJAP0201_2, 10.1207/s15327108ijap02012, DOI 10.1207/S15327108IJAP02012]
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim JM, 2015, FRONT PLANT SCI, V6, DOI [10.3389/fpls.2015.00114, 10.3389/fpsyg.2015.00248]
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kiryu T, 2014, 2014 IEEE 3RD GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P254, DOI 10.1109/GCCE.2014.7031258
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Krekhov A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P243, DOI 10.1145/3242671.3242704
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   LAMPTON DR, 1994, HUM FAC ERG SOC P, P1154
   Lee JY, 2017, SIGGRAPH ASIA 2017 POSTERS (SA'17), DOI 10.1145/3145690.3145697
   Llorach Gerard., 2014, P 20 ACM S VIRTUAL R, P137, DOI DOI 10.1145/2671015.2671120
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   Lubeck AJA, 2015, DISPLAYS, V38, P55, DOI 10.1016/j.displa.2015.03.001
   Luks R, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P280, DOI 10.1145/3316782.3321535
   Maloca PM, 2018, TRANSL VIS SCI TECHN, V7, DOI 10.1167/tvst.7.4.2
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Mirhosseini S, 2017, P IEEE VIRT REAL ANN, P29, DOI 10.1109/VR.2017.7892228
   Mittelstädt JM, 2019, HUM FACTORS, V61, P322, DOI 10.1177/0018720818804382
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Mondellini M, 2018, P 2018 IEEE 6 INT C, P1, DOI DOI 10.1109/SEGAH.2018.8401313
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Nogalski M, 2016, P IEEE VIRT REAL ANN, P245, DOI 10.1109/VR.2016.7504745
   Oishi E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P47, DOI 10.1145/2983310.2985749
   Onuki Y, 2017, P IEEE VIRT REAL ANN, P323, DOI 10.1109/VR.2017.7892307
   Plouzeau J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P661, DOI 10.1109/VR.2018.8446192
   Porter J, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P405, DOI 10.1145/3242671.3242677
   Rangelova S, 2020, ADV INTELL SYST COMP, V973, P192, DOI 10.1007/978-3-030-20476-1_20
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Regan C., 1995, VIRTUAL REAL-LONDON, V1, P17, DOI DOI 10.1007/BF02009710
   Regan EC, 1995, DISPLAYS, V16, P135, DOI 10.1016/0141-9382(96)81213-3
   Reis L, 2015, PROCEDIA MANUF, V3, P6599, DOI 10.1016/j.promfg.2015.07.722
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Rieder R, 2011, LECT NOTES COMPUT SC, V6948, P662, DOI 10.1007/978-3-642-23765-2_45
   Rietzler M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P99, DOI 10.1145/3196709.3196755
   Roberts W.K., 2005, P HUM FACTORS ERGON, P2230, DOI [10.1177/154193120504902603, DOI 10.1177/154193120504902603]
   Ryge AN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P675, DOI 10.1109/VR.2018.8446206
   Sargunam SP, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P74, DOI 10.1145/3191801.3191815
   Sawada Y, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-64302-y
   Schwarzer G., 2015, Meta-analysis with R, P187, DOI [DOI 10.1007/978-3-319-21416-0, 10.1007/978-3-319-21416-0_8]
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   So RHY, 1999, P IEEE VIRT REAL ANN, P237, DOI 10.1109/VR.1999.756957
   Sra M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300905
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Steinicke F, 2014, P 2 ACM S SPAT US IN, P66, DOI DOI 10.1145/2659766.2659767
   Tran TQ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281510
   Tregillus S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4063, DOI 10.1145/3025453.3025521
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   von Mammen S, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P325, DOI 10.1145/2993369.2996349
   Walch M, 2017, P 2017 CHI C HUM FAC, P2982, DOI [DOI 10.1145/3027063.3053202, 10.1145/3027063.3053202]
   Watanabe T, 2003, SURG NEUROL, V59, P429, DOI 10.1016/S0090-3019(03)00068-5
   Weidner F, 2017, P IEEE VIRT REAL ANN, P281, DOI 10.1109/VR.2017.7892286
   Whittinghill DavidMatthew., 2015, Games Developers Conference (GDC), page, P74
   Wienrich C., 2018, 2018 10th International Conference on Virtual Worlds and Games for Serious Applications, P1, DOI [DOI 10.1109/VS-GAMES.2018.8493408, DOI 10.1109/VS-GAMES.2018, 10.1109/VS-Games.2018.8493408]
   Wilson G, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173673
   Wilson JR, 1996, SAFETY SCI, V23, P39, DOI 10.1016/0925-7535(96)00026-4
   Yu XY, 2016, I C VIRTUAL REALITY, P426, DOI 10.1109/ICVRV.2016.78
   Ziegler P, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P743, DOI 10.1109/VR.2018.8446221
NR 108
TC 109
Z9 111
U1 9
U2 54
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1153
EP 1170
DI 10.1007/s10055-021-00513-6
EA APR 2021
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000638828900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Lau, KW
   Lee, PY
AF Lau, Kung Wong
   Lee, Pui Yuen
TI Using virtual reality for professional training practices: exploring the
   factors of applying stereoscopic 3D technologies in knowledge transfer
SO VIRTUAL REALITY
LA English
DT Article
DE Professional training; Learning science; Knowledge transfer; Virtual
   reality; Stereoscopic 3D technology
ID INFORMATION-TECHNOLOGY; INTERACTIVITY; ONLINE; COMMUNICATION;
   ENVIRONMENT; WORLDS; MODEL; TRANSFORMATION; ORGANIZATION; RATIONALITY
AB Current research has constantly highlighted the significance of developing a learning culture with a robust knowledge sharing and transfer process in knowledge-based societies. The emergence of stereoscopic 3D virtual technologies provides organizations with an opportunity to develop immersive and virtual professional training practices for employees' transformative learning. This research gathered data from a survey of 326 respondents to investigate employees' virtual learning experiences in a virtual learning environment (VLE). The results show that a successful VLE model could possibly enhance employees' learning motivation, process and satisfaction. The empirical evidence of this research suggests that there are three key components of framework for actual implementation; they are (1) the careful selection of VLE; (2) the appropriate design of pedagogical strategies; and (3) the effective use of virtual stimuli which involves the factors of the stereoscopic 3D visualization, telepresence and multisensory interactions.
C1 [Lau, Kung Wong; Lee, Pui Yuen] Hong Kong Polytech Univ, Hung Hom, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Lau, KW (corresponding author), Hong Kong Polytech Univ, Hung Hom, Kowloon, Hong Kong, Peoples R China.
EM laukungwong@gmail.com; py.lee@polyu.edu.hk
RI LAU, Kung Wong/G-3653-2010
OI LAU, Kung Wong/0000-0003-4896-264X
CR Afonso AP., 2006, MANAGING LEARNING VI
   Agarwal R, 1998, INFORM SYST RES, V9, P204, DOI 10.1287/isre.9.2.204
   Aluja-Banet T, 2019, J COMPUT SCI-NETH, V36, DOI 10.1016/j.jocs.2017.03.007
   Amitabh A.A., 2012, INT J ADV CORPORATE, V5, P10, DOI 10.3991/ijac.v5i2.2111
   Anderson EG, 2014, ORGAN SCI, V25, P356, DOI 10.1287/orsc.2013.0854
   [Anonymous], 1996, ORG LEARNING II
   [Anonymous], 1985, Strategy, Change, and Defensive Routines
   [Anonymous], 2000, SERIOUS PLAY WORLDS
   Argote L, 2011, ORGAN SCI, V22, P1123, DOI 10.1287/orsc.1100.0621
   Argyris C., 1996, Organizational Learning II Theory, Method, and Practice
   Bailey DE, 2012, ORGAN SCI, V23, P1485, DOI 10.1287/orsc.1110.0703
   Barkur G, 2007, LEARN ORGAN, V14, P510, DOI 10.1108/09696470710825123
   Bechky BA, 2003, ORGAN SCI, V14, P312, DOI 10.1287/orsc.14.3.312.15162
   Becker BE, 2006, J MANAGE, V32, P898, DOI 10.1177/0149206306293668
   Bernard P, 2014, P 2014 INT C INF ADV
   Biocca F., 2006, Journal of Computer-Mediated Communication., V3, DOI DOI 10.1111/J.1083-6101.1997.TB00070.X
   Blascovich J., 2006, VIRTUAL DECISIONS DI, P229, DOI DOI 10.4324/9781410617200
   Bogusevschi D., 2020, J COMPUT MATH SCI TE, V39, P5
   Boudreau MC, 2005, ORGAN SCI, V16, P3, DOI 10.1287/orsc.1040.0103
   BOURGEOIS LJ, 1984, ACAD MANAGE REV, V9, P586, DOI 10.2307/258482
   Bransford J.D., 2000, How People Learn; Brain, Mind, Experience, and School
   Brown AD, 2000, ACAD MANAGE REV, V25, P102, DOI 10.2307/259265
   Brown J. S., 2003, Foreword: Innovating innovation. Open innovation
   Bujak KR, 2013, COMPUT EDUC, V68, P536, DOI 10.1016/j.compedu.2013.02.017
   Bunderson JS, 2011, ORGAN SCI, V22, P1182, DOI 10.1287/orsc.1100.0590
   Cameron K., 2005, GREAT MINDS MANAGEME, P304
   Castronova E., 2007, EXODUS VIRTUAL WORLD
   Castronova Edward., 2005, Synthetic Worlds: The Business and Culture of Online Games
   Chaturvedi AR, 2011, MIS QUART, V35, P673
   Czerniawska F., 2001, BUSINESS VIRTUAL WOR
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   de Pablos P.Ordonez., 2008, Journal of Knowledge Management, V12, P48
   Dekleva S, 1997, INFORM SYST RES, V8, P95, DOI 10.1287/isre.8.1.95
   Deming W.Edwards., 1986, OUT CRISIS
   Di Serio A, 2013, COMPUT EDUC, V68, P586, DOI 10.1016/j.compedu.2012.03.002
   DIMAGGIO PJ, 1983, AM SOCIOL REV, V48, P147, DOI 10.2307/2095101
   DODGSON M, 1993, ORGAN STUD, V14, P375, DOI 10.1177/017084069301400303
   Dodgson M, 2007, ORGAN SCI, V18, P849, DOI 10.1287/orsc.1070.0287
   Dodgson M, 2013, ORGAN SCI, V24, P1358, DOI 10.1287/orsc.1120.0807
   Dodgson Mark., 2005, Think, Play, Do Technology, Innovation, and Organization
   Duffy T., 2000, Handbook of Research for Educational Communications and Technology, P170
   Easterby-Smith M, 2000, J MANAGE STUD, V37, P783, DOI 10.1111/1467-6486.00203
   Edmondson A, 1999, ADMIN SCI QUART, V44, P350, DOI 10.2307/2666999
   Entwistle N., 2009, Teaching for understanding at university, DOI [10.1007/978-1-137-09106-2, DOI 10.1007/978-1-137-09106-2]
   Farago J, 1995, LEARN ORGAN
   Fetscherin M, 2008, J ELECTRON COMMER RE, V9, P192
   FINGER M., 1999, ORG LEARNING LEARNIN
   Fiore AM, 2005, J INTERACT MARK, V19, P38, DOI 10.1002/dir.20042
   Fortin DR, 2005, J BUS RES, V58, P387, DOI 10.1016/S0148-2963(03)00106-1
   Gabbard RB, 2000, CYBERPSYCHOL BEHAV, V3, P103, DOI 10.1089/109493100316283
   Garau M, 2006, COMP SUPP COMP W SER, V34, P17
   Goldberg S.L., 1997, VIRTUAL REALITY TRAI, P41, DOI [10.1007/978-1-4899-0038-8_5, DOI 10.1007/978-1-4899-0038-8_5]
   Govindarajan V, 2011, J PROD INNOVAT MANAG, V28, P121, DOI 10.1111/j.1540-5885.2011.00865.x
   Grandy G, 2010, LEARN ORGAN, V17, P178, DOI 10.1108/09696471011019880
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hemp P, 2006, HARVARD BUS REV, V84, P48
   Heorhiadi A., 2014, [Organization Development] OD Practitioner, V46, P5
   Hoffman DL, 1996, J MARKETING, V60, P50, DOI 10.2307/1251841
   Hue P., 1997, Virtual reality, training's future?, P69, DOI DOI 10.1007/978-1-4899-0038-8_8
   ISAACS WN, 1993, ORGAN DYN, V22, P24, DOI 10.1016/0090-2616(93)90051-2
   Jaaron AAM, 2017, SYST PRACT ACT RES, V30, P317, DOI 10.1007/s11213-016-9397-0
   Jakobsson M, 2006, COMP SUPP COMP W SER, V34, P209
   Jiang Z., 1994, Journal of Computers in Mathematics and Science Teaching, V13, P197
   Johnson D, 2020, VIRTUAL REAL-LONDON, V24, P303, DOI 10.1007/s10055-019-00388-8
   Jonassen D, 1999, INSTRUCTIONAL-DESIGN THEORIES AND MODELS, VOL II, P215
   Kane GC, 2007, ORGAN SCI, V18, P796, DOI 10.1287/orsc.1070.0286
   Kang SC, 2007, ACAD MANAGE REV, V32, P236, DOI 10.2307/20159290
   Kareem J., 2016, The IUP Journal of Organizational Behavior, V15, P7
   Kegan R., 2000, LEARNING TRANSFORMAT, P35
   Kellogg RT, 2009, EDUC PSYCHOL-US, V44, P250, DOI 10.1080/00461520903213600
   Kelly P. R., 1997, Journal of Educational Technology Systems, V26, P345, DOI 10.2190/TXEB-LPCP-L8W2-Q362
   Khlaisang J, 2019, TECHNOL KNOWL LEARN, V24, P41, DOI 10.1007/s10758-017-9310-7
   Kim H, 2013, INFORM MANAGE-AMSTER, V50, P169, DOI 10.1016/j.im.2013.02.003
   Kim T., 1997, Journal of Computer-Mediated Communication, V3, P2, DOI DOI 10.1111/J.1083-6101.1997.TB00073.X
   Kirschner PA, 2006, EDUC PSYCHOL-US, V41, P75, DOI 10.1207/s15326985ep4102_1
   Klein LR, 2003, J INTERACT MARK, V17, P41, DOI 10.1002/dir.10046
   Kohler T, 2011, MIS QUART, V35, P773
   Kohler T, 2009, TECHNOVATION, V29, P395, DOI 10.1016/j.technovation.2008.11.004
   Kolb D.A., 2000, EXPERIENTIAL LEARNIN
   Laird TFN, 2010, RES HIGH EDUC, V51, P248, DOI 10.1007/s11162-009-9154-7
   Lapointe J. J., 1998, La 5eme discipline: l'organisation apprenante. Syllabus de cours, Faculte des sciencesdel'education
   Lau KW, 2017, INT J INF LEARN TECH, V34, P242, DOI 10.1108/IJILT-05-2016-0016
   Lau KW, 2015, INTERACT LEARN ENVIR, V23, P3, DOI 10.1080/10494820.2012.745426
   Lau KW, 2009, DES J, V12, P153, DOI 10.2752/175630609X433111
   Lau KW., 2016, INT J KNOWL MANAGE S, V7, P216, DOI [10.1504/IJKMS.2016.082342, DOI 10.1504/IJKMS.2016.082342]
   LAWRENCE E., 1999, Strategic thinking: a discussion paper. [Web:]
   Lee HY, 2004, COMPUT BIOL MED, V34, P719, DOI 10.1016/j.compbiomed.2003.10.004
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Li HR, 2003, J CONSUM PSYCHOL, V13, P395, DOI 10.1207/S15327663JCP1304_07
   LISSITZ RW, 1975, J APPL PSYCHOL, V60, P10, DOI 10.1037/h0076268
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Magee L.E., 1997, Virtual Reality, Training's Future?, P19
   Mantovani F., 2001, Towards cyberpsychology: Mind, cognition and society in the internet age, P207
   March J.G., 1976, AMBIGUITY CHOICE ORG
   Marketer, 2019, VIRTUAL AUGMENTED RE
   McMillan SJ, 2002, J ADVERTISING, V31, P29, DOI 10.1080/00913367.2002.10673674
   McShane S.L., 2013, Organizational behavior: Emerging knowledge, global reality, V6th
   MINTZBERG H, 1994, HARVARD BUS REV, V72, P107
   Myers CG, 2018, ACAD MANAGE REV, V43, P610, DOI 10.5465/amr.2016.0202
   Nah FFH, 2011, MIS QUART, V35, P731
   Nevo S, 2011, MIT SLOAN MANAGE REV, V52, P14
   Nonaka I, 1995, KNOWLEDGE CREATING C
   Oestreicher-Singer G, 2013, MIS QUART, V37, P591, DOI 10.25300/MISQ/2013/37.2.12
   ORLIKOWSKI WJ, 1995, ORGAN SCI, V6, P423, DOI 10.1287/orsc.6.4.423
   Orlikowski WJ, 2000, ORGAN SCI, V11, P404, DOI 10.1287/orsc.11.4.404.14600
   Osberg KM, 1992, VIRTUAL REALITY ED L
   Peppard J, 2004, J STRATEGIC INF SYST, V13, P167, DOI 10.1016/j.jsis.2004.02.002
   PRAWAT RS, 1994, EDUC PSYCHOL-US, V29, P37, DOI 10.1207/s15326985ep2901_4
   Prensky M., 2005, Handbook of Computer Game Studies
   Ravichandran N, 2018, INT J HEALTHCARE MAN, V11, P233, DOI 10.1080/20479700.2017.1336835
   Rosenberg M., 2006, Beyond e-learning: Approaches and technologies to enhance organizational knowledge, learning, and performance
   Rutten N, 2012, COMPUT EDUC, V58, P136, DOI 10.1016/j.compedu.2011.07.017
   Ryan E, 2019, J MED IMAGING RADIAT, V50, P408, DOI 10.1016/j.jmir.2019.04.005
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Sastry L., 1998, Virtual Reality, V3, P235, DOI 10.1007/BF01408704
   Saunders C, 2011, MIS QUART, V35, P1079
   Selden SC, 2004, J PUBL ADM RES THEOR, V14, P395, DOI 10.1093/jopart/muh025
   Senge P. M., 1990, 5 DISCIPLINE ART PRA
   Senge P.M., 1998, Executive Excellence, V15, P11
   Sherman WilliamR., 2003, UNDERSTANDING VIRTUA
   SHIH C.F., 1998, EUR J MARKETING, V32, P655
   Sicilia M, 2005, J ADVERTISING, V34, P31, DOI 10.1080/00913367.2005.10639202
   Simon HA, 1991, ORGAN SCI, V2, P125, DOI 10.1287/orsc.2.1.125
   Sinclair NT, 2017, J LIBR ADM, V57, P683, DOI 10.1080/01930826.2017.1291183
   Slater M, 2002, COMP SUPP COMP W SER, P146
   St-Amant G, 2004, 12 C ASS AIMS VALL S, P2
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Suh KS, 2011, MIS QUART, V35, P711
   Suh KS, 2006, BEHAV INFORM TECHNOL, V25, P99, DOI 10.1080/01449290500330398
   Tapscott Don, 2006, Wikinomics: How Mass Collaboration Changes Everything
   Thomke SH, 1998, MANAGE SCI, V44, P743, DOI 10.1287/mnsc.44.6.743
   Vaill PB, 2007, J MANAG EDUC, V31, P321, DOI 10.1177/1052562906298444
   Van de Ven A., 1999, INNOVATION JOURNEY
   Velazquez LE, 2011, LEARN ORGAN, V18, P36, DOI 10.1108/09696471111095984
   VENKATRAMAN N, 1994, SLOAN MANAGE REV, V35, P73
   Vygotsky L. S., 1978, Mind in Society: The Development of Higher Psychological Processes, DOI 10.2307/j.ctvjf9vz4
   Wang P, 2009, MIS QUART, V33, P709
   Watkins KE, 2018, HUM RESOUR DEV Q, V29, P15, DOI 10.1002/hrdq.21293
   Weldy TG, 2009, LEARN ORGAN, V16, P58, DOI 10.1108/09696470910927678
   Willingham D.T., 2009, Why don't students like school: A cognitive scientist answers questions about how the mind works and what it means for the classroom
   Woolfolk A.E., 1998, EDUC PSYCHOL-UK, Vseventh
   Xu SX, 2013, MIS QUART, V37, P1043, DOI 10.25300/MISQ/2013/37.4.03
   Zhang XJ, 2013, MIS QUART, V37, P695, DOI 10.25300/MISQ/2013/37.3.02
NR 143
TC 6
Z9 6
U1 3
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 985
EP 998
DI 10.1007/s10055-021-00504-7
EA FEB 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000618898300001
DA 2024-07-18
ER

PT J
AU Rockstroh, C
   Blum, J
   Göritz, AS
AF Rockstroh, Christoph
   Blum, Johannes
   Goeritz, Anja S.
TI A mobile VR-based respiratory biofeedback game to foster diaphragmatic
   breathing
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Respiratory biofeedback; Diaphragmatic breathing;
   Serious game; Stress reduction; Self-efficacy
ID HEART-RATE-VARIABILITY; VIRTUAL-REALITY; MANAGEMENT
AB Virtual reality (VR) has become popular in mental health research. Several studies have explored the use of VR in the context of biofeedback protocols. In the present paper, we report on the development and evaluation of a VR-based respiratory biofeedback game to foster diaphragmatic breathing. The game integrates respiratory biofeedback, restorative VR and gamification. The game is designed to run on a mobile, all-in-one VR headset. Notably, an integrated VR hand controller is utilized as a sensor to detect respiration-induced movements of the diaphragm. In a longitudinal within-subjects study, we explored the feasibility of the game and tested the effectiveness of six training sessions. Participants reported a pleasant user experience. Moreover, the results show that the brief VR-based breathing training increased perceived breath awareness, improved diaphragmatic breathing, increased relaxation, decreased perceived stress, reduced symptoms of burnout and boosted relaxation-related self-efficacy. Future studies need to address the generalizability and long-term stability of the results, compare the approach with existing treatments and fine-tune the training components.
C1 [Rockstroh, Christoph; Blum, Johannes; Goeritz, Anja S.] Albert Ludwigs Univ Freiburg, Dept Occupat & Consumer Psychol, Engelbergerstr 41, D-79106 Freiburg, Germany.
C3 University of Freiburg
RP Rockstroh, C (corresponding author), Albert Ludwigs Univ Freiburg, Dept Occupat & Consumer Psychol, Engelbergerstr 41, D-79106 Freiburg, Germany.
EM christoph.rockstroh@psychologie.uni-freiburg.de;
   johannes.blum@psychologie.uni-freiburg.de;
   goeritz@psychologie.uni-freiburg.de
RI Göritz, Anja S./HLX-7829-2023
OI Göritz, Anja S./0000-0002-4638-0489; Blum, Johannes/0000-0003-1368-1573
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL. This research
   did not receive any grant from funding agencies in the public,
   commercial or not-for-profit sectors.
CR Berger AM, 2018, NEUROSCIENCE, V378, P189, DOI 10.1016/j.neuroscience.2017.06.007
   Blum J, 2020, APPL PSYCHOPHYS BIOF, V45, P153, DOI 10.1007/s10484-020-09468-x
   Blum J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02172
   Bowler Diana E, 2010, BMC Public Health, V10, P456, DOI 10.1186/1471-2458-10-456
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Chandrasiri A, 2020, VIRTUAL REAL-LONDON, V24, P143, DOI 10.1007/s10055-019-00380-2
   Chen YF, 2017, PERSPECT PSYCHIATR C, V53, P329, DOI 10.1111/ppc.12184
   COHEN S, 1983, J HEALTH SOC BEHAV, V24, P385, DOI 10.2307/2136404
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Gaume A, 2016, NEUROSCI BIOBEHAV R, V68, P891, DOI 10.1016/j.neubiorev.2016.06.012
   Giardino ND, 2004, APPL PSYCHOPHYS BIOF, V29, P121, DOI 10.1023/B:APBI.0000026638.64386.89
   Giggins OM, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-60
   Goldberg DP., 1988, USERS GUIDE GEN HLTH
   Gradl S, 2018, INT CONF WEARAB IMPL, P152, DOI 10.1109/BSN.2018.8329681
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   HOlledig ML, 2018, THESIS
   Hopper Susan I, 2019, JBI Database System Rev Implement Rep, V17, P1855, DOI 10.11124/JBISRIR-2017-003848
   Houzangbe S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P982, DOI [10.1109/vr.2019.8797759, 10.1109/VR.2019.8797759]
   Keshavarz B, 2014, APPL ERGON, V45, P521, DOI 10.1016/j.apergo.2013.07.009
   Kosunen I, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P208, DOI 10.1145/2856767.2856796
   Kothgassner O.D., 2012, TUI (Technology Usage Inventory) Manual
   Kristensen TS, 2005, WORK STRESS, V19, P192, DOI 10.1080/02678370500297720
   Ma X, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00874
   Mallari B, 2019, J PAIN RES, V12, P2053, DOI 10.2147/JPR.S200498
   McMahan EA, 2015, J POSIT PSYCHOL, V10, P507, DOI 10.1080/17439760.2014.994224
   Navarro-Haro MV, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187777
   Ohly H, 2016, J TOXICOL ENV HEAL B, V19, P305, DOI 10.1080/10937404.2016.1196155
   Paul M, 2012, APPL PSYCHOPHYS BIOF, V37, P131, DOI 10.1007/s10484-012-9185-2
   Perciavalle V, 2017, NEUROL SCI, V38, P451, DOI 10.1007/s10072-016-2790-8
   Riches S, 2019, CYBERPSYCH BEH SOC N, V22, P288, DOI 10.1089/cyber.2018.0128
   Roche K., 2019, Mental Health and Family Medicine, V14, P811
   ROCKSTROH C, 2020, J MEDIA PSYCHOL
   Rockstroh C, 2019, INT J HUM-COMPUT ST, V130, P209, DOI 10.1016/j.ijhcs.2019.06.011
   Russell MEB, 2014, APPL PSYCHOPHYS BIOF, V39, P269, DOI 10.1007/s10484-014-9265-6
   Scapin S, 2018, BURNS, V44, P1403, DOI 10.1016/j.burns.2017.11.002
   Sherlin LH., 2011, J NEUROTHER, V15, P292, DOI DOI 10.1080/10874208.2011.623089
   Soyka F., 2016, P ACM S APPL PERC PR, P85, DOI [10.1145/2931002.2931017., DOI 10.1145/2931002.2931017, 10.1145/2931002.2931017]
   Sra M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173914
   Stromberg SE, 2015, AEROSP MED HUM PERF, V86, P452, DOI 10.3357/AMHP.4152.2015
   Subbalakshmi NK, 2014, J DIABETES INVEST, V5, P456, DOI 10.1111/jdi.12163
   Teufel M, 2013, APPL PSYCHOPHYS BIOF, V38, P177, DOI 10.1007/s10484-013-9223-8
   Tinga AM, 2019, APPL PSYCHOPHYS BIOF, V44, P51, DOI 10.1007/s10484-018-9421-5
   van Rooij M., 2016, J. Anxiety Disord., P1989, DOI [10.1145/2851581.2892452, DOI 10.1145/2851581.2892452]
   Vaschillo EG, 2006, APPL PSYCHOPHYS BIOF, V31, P129, DOI 10.1007/s10484-006-9009-3
   Weerdmeester J, 2017, EXTENDED ABSTRACTS PUBLICATION OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY'17 EXTENDED ABSTRACTS), P453, DOI 10.1145/31308593131299
   Yasuma F, 2004, CHEST, V125, P683, DOI 10.1378/chest.125.2.683
   Yu B., 2018, Frontiers in ICT, V5, P23, DOI [10.3389/fict.2018.00023, DOI 10.3389/FICT.2018.00023]
   Zaccaro A, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00353
NR 48
TC 23
Z9 24
U1 5
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 539
EP 552
DI 10.1007/s10055-020-00471-5
EA OCT 2020
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000575340400001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Rogers, JM
   Jensen, J
   Valderrama, JT
   Johnstone, SJ
   Wilson, PH
AF Rogers, Jeffrey M.
   Jensen, Jenny
   Valderrama, Joaquin T.
   Johnstone, Stuart J.
   Wilson, Peter H.
TI Single-channel EEG measurement of engagement in virtual rehabilitation:
   a validation study
SO VIRTUAL REALITY
LA English
DT Article
DE Engagement; Presence; Electroencephalogram; Rehabilitation; Virtual
   reality
ID FRONTAL-MIDLINE-THETA; TRAUMATIC BRAIN-INJURY; PATIENT ENGAGEMENT;
   DELTA/ALPHA RATIO; POSITIVE EMOTION; SPATIAL PRESENCE; MENTAL WORKLOAD;
   TASK ENGAGEMENT; VIDEO GAMES; REALITY
AB Stroke rehabilitation suffers from low levels of patient engagement, impeding recovery. Virtual rehabilitation (VR) approaches can improve patient outcomes; however, there is limited understanding of the participant's user experience and the field lacks a validated, objective measure of VR engagement. A neurophysiological measure of engagement in healthy adults was therefore examined, to inform future clinical studies. Twenty-four participants (M(age)26.7 years, range 18-47) interacted with a tabletop VR system (ElementsDNA, or EDNA), after which they rated their experience on the presence questionnaire (PQ). Separately, participants completed tasks eliciting low (restingeyes-open and -closed) and high (EDNA VR and roller coastersimulation) levels of engagement while continuous electroencephalogram (EEG) was recorded from a single, left pre-frontal electrode. EEG differences between therestingandsimulationconditions included an increase in theta power (p < 0.01) and a decrease in alpha power (p < 0.01). Importantly, theta power insimulationconditions correlated with PQ scores expressing the hands-on EDNA VR experience (r(s) = 0.38-0.48). In conclusion, the current results provide proof of concept that increased frontal theta power in healthy adults provides a valid measure of user engagement in VR simulation and participation. As the practical potential of VR is increasingly realised in stroke rehabilitation, objective EEG-based measures of engagement may provide a convenient and sensitive technique to assist in evaluating these interventions.
C1 [Rogers, Jeffrey M.] Univ Sydney, Fac Med & Hlth, Sydney, NSW, Australia.
   [Jensen, Jenny; Wilson, Peter H.] Australian Catholic Univ, Sch Behav & Hlth Sci, 115 Victoria Parade, Melbourne, Vic 3450, Australia.
   [Valderrama, Joaquin T.] Natl Acoust Labs, Sydney, NSW, Australia.
   [Valderrama, Joaquin T.] Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.
   [Valderrama, Joaquin T.] HEARing CRC, Melbourne, Vic, Australia.
   [Johnstone, Stuart J.] Univ Wollongong, Sch Psychol & Brain & Behav Res Inst, Wollongong, NSW, Australia.
   [Wilson, Peter H.] Australian Catholic Univ, Ctr Disabil & Dev Res, 115 Victoria Parade, Melbourne, Vic 3450, Australia.
C3 University of Sydney; Australian Catholic University; National Acoustic
   Laboratories; Macquarie University; University of Wollongong; Australian
   Catholic University
RP Wilson, PH (corresponding author), Australian Catholic Univ, Sch Behav & Hlth Sci, 115 Victoria Parade, Melbourne, Vic 3450, Australia.; Wilson, PH (corresponding author), Australian Catholic Univ, Ctr Disabil & Dev Res, 115 Victoria Parade, Melbourne, Vic 3450, Australia.
EM peterh.wilson@acu.edu.au
RI Valderrama, Joaquin T/O-3394-2014; Wilson, Peter/E-2881-2018
OI Valderrama, Joaquin T/0000-0002-5529-8620; Johnstone,
   Stuart/0000-0001-5380-9952; Wilson, Peter/0000-0003-3747-0287
CR Aminov A, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0370-2
   Badcock NA, 2013, PEERJ, V1, DOI 10.7717/peerj.38
   Barello S, 2012, NURS RES PRACT, V2012, DOI 10.1155/2012/905934
   Barry RJ, 2007, CLIN NEUROPHYSIOL, V118, P2765, DOI 10.1016/j.clinph.2007.07.028
   Barry RJ, 2014, INT J PSYCHOPHYSIOL, V94, P236, DOI 10.1016/j.ijpsycho.2014.08.915
   Bartur G, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/9071568
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Baumgartner T, 2007, NEUROREPORT, V18, P261, DOI 10.1097/WNR.0b013e328012272e
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   Beardsely M., 1982, AESTHETIC POINT VIEW
   Berka C, 2007, AVIAT SPACE ENVIR MD, V78, pB231
   Borghini C., 2011, ITAL J AEROSP MED, V5, P34
   Brackney DE, 2017, J NURS MEAS, V25, pE66, DOI 10.1891/1061-3749.25.2.E66
   Brett CE, 2017, NEUROPSYCHOL REHABIL, V27, P959, DOI 10.1080/09602011.2015.1090459
   Bright FAS, 2015, DISABIL REHABIL, V37, P643, DOI 10.3109/09638288.2014.933899
   Burke JW, 2009, VISUAL COMPUT, V25, P1085, DOI 10.1007/s00371-009-0387-4
   Calabrò RS, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0268-4
   Cavanagh JF, 2014, TRENDS COGN SCI, V18, P414, DOI 10.1016/j.tics.2014.04.012
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   Deutsch JE, 2013, J NEUROL PHYS THER, V37, P118, DOI 10.1097/NPT.0b013e3182a0a078
   Doppelmayr A, 2008, NEUROPSYCHOLOGIA, V46, P1463, DOI 10.1016/j.neuropsychologia.2007.12.026
   Palma GCD, 2017, TOP STROKE REHABIL, V24, P269, DOI 10.1080/10749357.2016.1250373
   Duckworth J, 2015, LECT NOTES COMPUT SC, V9177, P420, DOI 10.1007/978-3-319-20684-4_41
   Dussault C, 2005, AVIAT SPACE ENVIR MD, V76, P344
   Ekandem JI, 2012, ERGONOMICS, V55, P592, DOI 10.1080/00140139.2012.662527
   Ewing KC, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00223
   Fairclough SH, 2006, BIOL PSYCHOL, V71, P100, DOI 10.1016/j.biopsycho.2005.03.007
   Fairclough SH, 2005, INT J PSYCHOPHYSIOL, V56, P171, DOI 10.1016/j.ijpsycho.2004.11.003
   Feigin VL, 2017, CIRC RES, V120, P439, DOI 10.1161/CIRCRESAHA.116.308413
   Finnigan S, 2016, CLIN NEUROPHYSIOL, V127, P1452, DOI 10.1016/j.clinph.2015.07.014
   Freeman J, 1999, PRESENCE-TELEOP VIRT, V8, P1, DOI 10.1162/105474699566017
   Gamito P, 2010, STUD HEALTH TECHNOL, V154, P128, DOI 10.3233/978-1-60750-561-7-128
   Green D, 2012, DISABIL REHABIL, V34, P593, DOI 10.3109/09638288.2011.613520
   Green K, 2014, HISTORY OF WOMEN'S POLITICAL THOUGHT IN EUROPE, 1700-1800, P203
   Gundel Alexander, 1992, Brain Topography, V5, P17, DOI 10.1007/BF01129966
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Hsieh LT, 2014, NEUROIMAGE, V85, P721, DOI 10.1016/j.neuroimage.2013.08.003
   Imam B, 2014, REHABIL RES PRACT, V2014, DOI 10.1155/2014/594540
   Imms C, 2017, DEV MED CHILD NEUROL, V59, P16, DOI 10.1111/dmcn.13237
   Jäncke L, 2009, FRONT NEUROSCI-SWITZ, V3, P52, DOI 10.3389/neuro.01.006.2009
   Johnstone SJ, 2012, CLIN EEG NEUROSCI, V43, P112, DOI 10.1177/1550059411435857
   Kao SC, 2013, J SPORT EXERCISE PSY, V35, P470, DOI 10.1123/jsep.35.5.470
   Klimesch W, 1999, BRAIN RES REV, V29, P169, DOI 10.1016/S0165-0173(98)00056-3
   Kober SE, 2012, INT J PSYCHOPHYSIOL, V83, P365, DOI 10.1016/j.ijpsycho.2011.12.003
   Lalmas M., 2014, Synthesis Lectures on Information Concepts, Retrieval, and Services, V6, P1, DOI [DOI 10.2200/S00605ED1V01Y201410ICR038, 10.2200/s00605ed1v01y201410icr038]
   Langhorne P, 2011, LANCET, V377, P1693, DOI 10.1016/S0140-6736(11)60325-5
   Laver KE, 2017, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub4
   Lee SH, 2015, J PHYS THER SCI, V27, P2285, DOI 10.1589/jpts.27.2285
   Leiker AM, 2016, JMIR SERIOUS GAMES, V4, pE4, DOI 10.2196/games.5460
   Lenze EJ, 2004, ARCH PHYS MED REHAB, V85, P1599, DOI 10.1016/j.apmr.2004.03.027
   Lequerica AH, 2010, AM J PHYS MED REHAB, V89, P415, DOI 10.1097/PHM.0b013e3181d8ceb2
   Lequerica AH, 2009, DISABIL REHABIL, V31, P753, DOI 10.1080/09638280802309095
   Levin MF, 2011, EXPERT REV NEUROTHER, V11, P153, DOI [10.1586/ern.10.201, 10.1586/ERN.10.201]
   Lewis GN, 2012, DISABIL REHABIL, V34, P1880, DOI 10.3109/09638288.2012.670036
   Li C, 2016, ENG APPL ARTIF INTEL, V51, P182, DOI 10.1016/j.engappai.2016.01.021
   Li C, 2014, INT J REHABIL RES, V37, P334, DOI 10.1097/MRR.0000000000000076
   Lohse KR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093318
   Maclean N, 2000, BMJ-BRIT MED J, V321, P1051, DOI 10.1136/bmj.321.7268.1051
   Maier M, 2019, NEUROREHAB NEURAL RE, V33, P112, DOI 10.1177/1545968318820169
   McMahan T, 2015, PROCEDIA MANUF, V3, P2303, DOI 10.1016/j.promfg.2015.07.376
   Miller BW, 2015, EDUC PSYCHOL-US, V50, P31, DOI 10.1080/00461520.2015.1004068
   Mumford N, 2012, BRAIN INJURY, V26, P166, DOI 10.3109/02699052.2011.648706
   Mumford N, 2010, BRAIN INJURY, V24, P780, DOI 10.3109/02699051003652807
   Nagendra H, 2017, COGN SYST RES, V42, P42, DOI 10.1016/j.cogsys.2016.11.007
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   Ostir GV, 2008, PSYCHOSOM MED, V70, P404, DOI 10.1097/PSY.0b013e31816fd7d0
   Perez MA, 2004, EXP BRAIN RES, V159, P197, DOI 10.1007/s00221-004-1947-5
   POPE AT, 1995, BIOL PSYCHOL, V40, P187, DOI 10.1016/0301-0511(95)05116-3
   Ratti E, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00398
   Reinecke K, 2011, APPL PSYCHOPHYS BIOF, V36, P265, DOI 10.1007/s10484-011-9166-x
   Rogers JM, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0531-y
   Rogers JM, 2016, INT J PSYCHOPHYSIOL, V106, P87, DOI 10.1016/j.ijpsycho.2016.06.006
   Ruffino C, 2017, NEUROSCIENCE, V341, P61, DOI 10.1016/j.neuroscience.2016.11.023
   Salminen M, 2008, NEUROSCI LETT, V435, P69, DOI 10.1016/j.neulet.2008.02.009
   Schleiger E, 2014, INT J PSYCHOPHYSIOL, V94, P19, DOI 10.1016/j.ijpsycho.2014.06.012
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   Seale GS, 2010, REHABIL PSYCHOL, V55, P33, DOI 10.1037/a0018744
   de Oliveira SMS, 2018, NEUROL RES, V40, P160, DOI 10.1080/01616412.2017.1420584
   Slobounov SM, 2015, INT J PSYCHOPHYSIOL, V95, P254, DOI 10.1016/j.ijpsycho.2014.11.003
   Slobounov SM, 2000, COGNITIVE BRAIN RES, V9, P287, DOI 10.1016/S0926-6410(00)00009-4
   Smith ME, 2001, HUM FACTORS, V43, P366, DOI 10.1518/001872001775898287
   Stephenson W., 1967, PLAY THEORY MASS COM, P45
   Toms EG, 2002, J AM SOC INF SCI TEC, V53, P855, DOI 10.1002/asi.10094
   Triberti S, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02052
   Valderrama JT, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aa8d95
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wright RA, 2008, SOC PERSONAL PSYCHOL, V2, P682, DOI 10.1111/j.1751-9004.2008.00093.x
   Yamada F, 1998, ERGONOMICS, V41, P678, DOI 10.1080/001401398186847
   Zappasodi F, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141995
   Zimmerli L, 2013, ARCH PHYS MED REHAB, V94, P1737, DOI 10.1016/j.apmr.2013.01.029
NR 91
TC 10
Z9 11
U1 8
U2 39
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 357
EP 366
DI 10.1007/s10055-020-00460-8
EA JUL 2020
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000551380500001
DA 2024-07-18
ER

PT J
AU Koutitas, G
   Smith, S
   Lawrence, G
AF Koutitas, George
   Smith, Scott
   Lawrence, Grayson
TI Performance evaluation of AR/VR training technologies for EMS first
   responders
SO VIRTUAL REALITY
LA English
DT Article
DE First responders; Training; Augmented reality; Virtual reality; Learning
   technologies; Evaluation
ID MASS-CASUALTY INCIDENTS; AUGMENTED REALITY
AB The first responder training sector presents crucial difficulties on adopting "future of work" online training principles because physical (muscle) memory is considered as important as cognitive memory. It is obvious that physical memory cannot be obtained by existing screen- and paper-based trainings. This paper presents a novel training framework for first responders that leverages augmented reality and virtual reality technologies. The framework incorporates novel design thinking processes that are implemented for the design of the training experiences. In addition, a qualitative and quantitative analysis of various metrics such as performance, time on task, accuracy and learning rate are developed to analyze the effectiveness of the proposed framework. A special use case of the emergency medical services called the ambulance bus is investigated and it is shown that the proposed training methodology improved the accuracy of the first responders by a factor of 46% and the speed on executing tasks by 29%.
C1 [Koutitas, George] Texas State Univ, Elect & Comp Engn, San Marcos, TX 78666 USA.
   [Smith, Scott] Augmented Training Syst Inc, Austin, TX USA.
   [Lawrence, Grayson] Texas State Univ, Commun Design, San Marcos, TX USA.
C3 Texas State University System; Texas State University San Marcos; Texas
   State University System; Texas State University San Marcos
RP Koutitas, G (corresponding author), Texas State Univ, Elect & Comp Engn, San Marcos, TX 78666 USA.
EM george.koutitas@txstate.edu; Scott@AugmentedTrainingSystems.com
CR Ali AA, 2019, IEEE T LEARN TECHNOL, V12, P321, DOI 10.1109/TLT.2019.2926727
   [Anonymous], 2019, AR VR DEMO AMBUS
   Daher S, 2017, IEEE VIRTUAL REALITY, DOI [10.1109/VR.2017.7892354, DOI 10.1109/VR.2017.7892354]
   Forrester Total Economic Impact, 2018, TOT EC IMP IBMS DES
   Gibbons S., 2016, Design thinking
   Heinrichs WL, 2010, PREHOSP DISASTER MED, V25, P424, DOI 10.1017/S1049023X00008517
   Kang SH., 2016, Policy Insights from the Behavioral and Brain Sciences, V3, P12, DOI DOI 10.1177/2372732215624708
   Kim Y, 2010, INT S HIGH PERF COMP, P43
   Koutitas G, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P299, DOI 10.1145/3316782.3321542
   Lankford A, 2016, VIOLENCE VICTIMS, V31, P187, DOI 10.1891/0886-6708.VV-D-15-00093
   Léger É, 2017, HEALTHC TECHNOL LETT, V4, P188, DOI 10.1049/htl.2017.0062
   National Centers for Environmental Information, 2017, BILL DOLL WEATH CLIM
   Ouadoud M, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT 2017)
   Santos MEC, 2014, IEEE T LEARN TECHNOL, V7, P38, DOI 10.1109/TLT.2013.37
   Schenk E, 2014, PREHOSP EMERG CARE, V18, P408, DOI 10.3109/10903127.2014.882999
   Schmidt M., 2014, NY TIMES
   Sebillo M, 2016, MULTIMED TOOLS APPL, V75, P9609, DOI 10.1007/s11042-015-2955-0
   Squire LR, 1996, P NATL ACAD SCI USA, V93, P13515, DOI 10.1073/pnas.93.24.13515
   Stansfield S, 2010, IEEE PRESENCE TELEOP, V9, P524, DOI [10.1162/105474600300040376, DOI 10.1162/105474600300040376]
   Sutherland C, 2013, IEEE T BIO-MED ENG, V60, P3009, DOI 10.1109/TBME.2012.2236091
   Tabbarah M, 2002, J GERONTOL A-BIOL, V57, pM228, DOI 10.1093/gerona/57.4.M228
   U.S. Fire Administration, 2016, FIR FIGHT FAT US 201
   Vandierendonck A, 2017, BEHAV RES METHODS, V49, P653, DOI 10.3758/s13428-016-0721-5
   Wilkerson W, 2008, ACAD EMERG MED, V15, P1152, DOI 10.1111/j.1553-2712.2008.00223.x
   Wüller H, 2017, STUD HEALTH TECHNOL, V245, P823, DOI 10.3233/978-1-61499-830-3-823
   Yuan Y, 2018, IEEE CONSUM ELECTR M, V7, P117, DOI 10.1109/MCE.2017.2755338
NR 26
TC 31
Z9 32
U1 9
U2 40
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 83
EP 94
DI 10.1007/s10055-020-00436-8
EA APR 2020
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000523076600001
DA 2024-07-18
ER

PT J
AU Wood, G
   Wright, DJ
   Harris, D
   Pal, A
   Franklin, ZC
   Vine, SJ
AF Wood, G.
   Wright, D. J.
   Harris, D.
   Pal, A.
   Franklin, Z. C.
   Vine, S. J.
TI Testing the construct validity of a soccer-specific virtual reality
   simulator using novice, academy, and professional soccer players
SO VIRTUAL REALITY
LA English
DT Article
DE Football; Simulation; Training; Perceptual-cognitive expertise; Skill
   acquisition
ID ATTENTIONAL CONTROL; PERFORMANCE; EXPERTISE; FACE
AB Virtual reality (VR) provides the potential for immersive and engaging training solutions for improving sport performance. However, if VR training is to be adopted and used in an effective and evidence-based fashion, a more rigorous assessment of the validity of the simulation is required. Construct validity is the degree to which the simulation provides an accurate representation of core features of the task. In the context of sport, if the training drills in the VR environment are a true representation of the skills needed in the real world, then those that excel at the sport in the real world should also excel in the virtual one. In this experiment, we examined the construct validity of a soccer-specific VR simulator by recruiting professional, academy, and novice players. Seventeen participants in each group completed four VR soccer drills, and the VR software provided scores relating to performance and process (e.g., passing accuracy, composure, reaction time, and adaptability). Based on these scores, an algorithm gave a diagnostic score relating to the predicted ability of the player. Results showed that this VR platform successfully differentiated between participants of differing skill levels. These results provide some support for the construct validity of this VR simulator and suggest at least partial overlap between the perceptual-cognitive and motor skills needed to perform well across 'real' and virtual environments. Further work is needed to explore the validity and fidelity of the simulation before its adoption as a training device can be fully endorsed.
C1 [Wood, G.; Pal, A.; Franklin, Z. C.] Manchester Metropolitan Univ, Res Ctr Musculoskeletal Sci & Sports Med, Dept Sport & Exercise Sci, Manchester, Lancs, England.
   [Wright, D. J.] Manchester Metropolitan Univ, Fac Hlth Psychol & Social Care, Res Ctr Musculoskeletal Sci & Sports Med, Manchester, Lancs, England.
   [Harris, D.; Vine, S. J.] Univ Exeter, Coll Life & Environm Sci, Sch Sport & Hlth Sci, Exeter, Devon, England.
C3 Manchester Metropolitan University; Manchester Metropolitan University;
   University of Exeter
RP Wood, G (corresponding author), Manchester Metropolitan Univ, Res Ctr Musculoskeletal Sci & Sports Med, Dept Sport & Exercise Sci, Manchester, Lancs, England.
EM greg.wood@mmu.ac.uk
RI Harris, David/H-9114-2019
OI Harris, David/0000-0003-3880-3856; Franklin, Zoe/0000-0001-6130-8787;
   Wood, Greg/0000-0003-0851-7090; Wright, David/0000-0001-9568-0237
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Bright E, 2012, INT J SURG, V10, P163, DOI 10.1016/j.ijsu.2012.02.012
   Burdea G.C., 2003, Virtual Reality Technology, V2
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Casanova F., 2009, REV PORT 101 NCIAS D, V9, P115, DOI DOI 10.5628/RPCD.09.01.115
   Dessing JC, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013161
   Dicks M, 2010, ATTEN PERCEPT PSYCHO, V72, P706, DOI 10.3758/APP.72.3.706
   FURLEY P, 2015, FRONT PSYCHOL, V6
   Furley P, 2016, J APPL RES MEM COGN, V5, P415, DOI 10.1016/j.jarmac.2016.05.001
   Gray R, 2002, J EXP PSYCHOL HUMAN, V28, P1131, DOI 10.1037//0096-1523.28.5.1131
   Gray R., 2019, Anticipation and Decision Making in Sport
   GRAY R, 2017, FRONT PSYCHOL, V8
   Gurusamy K, 2008, BRIT J SURG, V95, P1088, DOI 10.1002/bjs.6344
   Haque S, 2006, IEEE T INF TECHNOL B, V10, P51, DOI 10.1109/TITB.2005.855529
   Harris D., 2019, Testing the fidelity and validity of a virtual reality golf putting simulator
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   HARRIS DJ, 2019, TESTING EFFECTS VIRT
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Lammfromm R., 2011, BIOWEB C, V1, P00054, DOI [10.1051/bioconf/20110100054, DOI 10.1051/BIOCONF/20110100054]
   Lerner MA, 2010, J ENDOUROL, V24, P467, DOI 10.1089/end.2009.0190
   Mann DTY, 2007, J SPORT EXERCISE PSY, V29, P457, DOI 10.1123/jsep.29.4.457
   McGuckian TB, 2019, ECOL PSYCHOL, V31, P30, DOI 10.1080/10407413.2018.1495548
   McGuckian TB, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02520
   Michalski SC, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02159
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Pinder RA, 2011, J SPORT EXERCISE PSY, V33, P146, DOI 10.1123/jsep.33.1.146
   Roberts PG, 2017, KNEE SURG SPORT TR A, V25, P616, DOI 10.1007/s00167-016-4114-1
   Sanz FA, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00010
   Sigrist R, 2015, EXP BRAIN RES, V233, P909, DOI 10.1007/s00221-014-4167-7
   Stinson C, 2014, IEEE T VIS COMPUT GR, V20, P606, DOI 10.1109/TVCG.2014.23
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Vestberg T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170845
   Vestberg T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034731
   Vine SJ, 2015, ANXIETY STRESS COPIN, V28, P467, DOI 10.1080/10615806.2014.986722
   Vine SJ, 2014, SURG ENDOSC, V28, P1788, DOI 10.1007/s00464-013-3387-4
   Wilson MR, 2009, J SPORT EXERCISE PSY, V31, P761, DOI 10.1123/jsep.31.6.761
   Wood G, 2015, J SPORT SCI, V33, P1758, DOI 10.1080/02640414.2015.1012103
   Wood G, 2010, J SPORT SCI, V28, P937, DOI 10.1080/02640414.2010.495995
NR 39
TC 37
Z9 39
U1 6
U2 30
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 43
EP 51
DI 10.1007/s10055-020-00441-x
EA APR 2020
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000523406700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Ríos, A
   Pelechano, N
AF Rios, Alejandro
   Pelechano, Nuria
TI Follower behavior under stress in immersive VR
SO VIRTUAL REALITY
LA English
DT Article
DE Crowd following; Immersive VR; Studies of human behavior
ID CROWD
AB Understanding human decision making is a key requirement to improve crowd simulation models so that they can better mimic real human behavior. It is often difficult to study human decision making during dangerous situations because of the complexity of the scenarios and situations to be simulated. Immersive virtual reality offers the possibility to carry out such experiments without exposing participants to real danger. In the real world, it has often been observed that people tend to follow others in certain situations (e.g., unfamiliar environments or stressful situations). In this paper, we study human following behavior when it comes to exit choice during an evacuation of a train station. We have carried out immersive VR experiments under different levels of stress (alarm only or alarm plus fire), and we have observed how humans consistently tend to follow the crowd regardless of the levels of stress. Our results show that decision making is strongly influenced by the behavior of the virtual crowd: the more virtual people running, the more likely are participants to simply follow others. The results of this work could improve behavior simulation models during crowd evacuation, and thus build more plausible scenarios for training firefighters.
C1 [Rios, Alejandro; Pelechano, Nuria] Univ Politecn Cataluna, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Ríos, A (corresponding author), Univ Politecn Cataluna, Barcelona, Spain.
EM arios@cs.upc.edu; npelechano@cs.upc.edu
RI Rios Jerez, Alejandro/GLT-3685-2022; Jerez, Alejandro
   Ríos/AAU-4157-2020; Alidadi, Mehdi/HJZ-0235-2023; Pelechano,
   Nuria/K-4288-2014
OI Jerez, Alejandro Ríos/0000-0003-1210-8951; Alidadi,
   Mehdi/0000-0001-5183-7829; Pelechano, Nuria/0000-0002-1437-245X
FU Spanish Ministry of Economy, Industry and Competitiveness
   [TIN2017-88515-C2-1-R]
FX This work was partly funded by the Spanish Ministry of Economy, Industry
   and Competitiveness under Grant No. TIN2017-88515-C2-1-R.
CR Ahn Junghyun., 2012, P 11 ACM SIGGRAPH IN, P231
   Argelaguet F, 2015, VR
   B HAWORTH., 2015, P 8 ACM SIGGRAPH C M, P91
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   Cassol VJ, 2017, IEEE COMPUT GRAPH, V37, P60, DOI 10.1109/MCG.2017.3271454
   Cialdini R. B., 2007, INFLUENCE PSYCHOL PE
   Coultas JC, 2004, GROUP PROCESS INTERG, V7, P317, DOI 10.1177/1368430204046141
   Ennis C, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870078
   Ennis C, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P75
   Gonzalez-Franco M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209704
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Gupta Naman, 2017, P 54 ANN DES AUT C, P1
   Guy S J, 2010, P 2011 ACM SIGGRAPH, P43
   Guy SJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366209
   Guy SJ, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P115, DOI 10.1145/1810959.1810981
   Kazdin A. E., 2000, ENCY PSYCHOL, V2
   Knob P, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P233, DOI 10.1145/3267851.3267871
   Kyriakou M, 2018, P 11 ANN INT C MOT I, P12
   Lerner A, 2010, COMPUT GRAPH FORUM, V29, P2197, DOI 10.1111/j.1467-8659.2010.01808.x
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Maples-Keller JL, 2017, NEUROTHERAPEUTICS, V14, P554, DOI 10.1007/s13311-017-0534-y
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   Narang S, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P91, DOI 10.1145/2993369.2993378
   Olivier AH, 2014, TRANSP RES PROC, V2, P114, DOI 10.1016/j.trpro.2014.09.015
   Olivier AH, 2013, GAIT POSTURE, V38, P751, DOI 10.1016/j.gaitpost.2013.03.017
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Pelechano Nuria, 2016, 2016 IEEE Virtual Humans and Crowds for Immersive Environments (VHCIE), P17, DOI 10.1109/VHCIE.2016.7563568
   Pelechano N., 2007, P PRESENCE 2007, P373
   Pelechano N, 2006, IEEE COMPUT GRAPH, V26, P80, DOI 10.1109/MCG.2006.133
   Pelechano Nuria., 2008, P 7 INT JOINT C AUTO, V1, P136
   Rios A, 2018, P 11 ANN INT C MOT I, P15
   Rios Alejandro, 2018, VIRTUAL HUMANS CROWD
   Rojas F. A., 2013, P 12 ACM SIGGRAPH IN, P31, DOI DOI 10.1145/2534329.2534336
   Sohre N., 2017, 2017 IEEE Virtual Humans and Crowds for Immersive Environments (VHCIE), P1
   Steed A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00112
   Turner A, 2002, ENVIRON PLANN B, V29, P473, DOI 10.1068/b12850
   Turner A., 2007, Pedestrian and Evacuation Dynamics 2005, P411, DOI [10.1007/978-3-540-47064-9_39, DOI 10.1007/978-3-540-47064-9_39]
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
NR 39
TC 12
Z9 12
U1 4
U2 30
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 683
EP 694
DI 10.1007/s10055-020-00428-8
EA MAR 2020
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000562308600001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Martín-Barrio, A
   Roldán, JJ
   Terrile, S
   del Cerro, J
   Barrientos, A
AF Martin-Barrio, Andres
   Roldan, Juan Jesus
   Terrile, Silvia
   del Cerro, Jaime
   Barrientos, Antonio
TI Application of immersive technologies and natural language to
   hyper-redundant robot teleoperation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Augmented reality; Mixed reality; Natural language;
   Hyper-redundant robot; Soft robot; Teleoperation
ID VIRTUAL-REALITY; INTERFACES; KINEMATICS; SYSTEM
AB This work presents an analysis of immersive realities and natural language applied to the teleoperation of hyper-redundant robots. Such devices have a large number of degrees of freedom, so they often exhibit complex configurations frustrating their spatial understanding. This work aims to contrast two hypotheses; first, if immersive interfaces enhance the telepresence and efficiency against conventional ones; and second, if natural language reduces workload and improves performance against other conventional tools. A total of 2 interfaces and 6 interaction tools have been tested by 50 people. As a result, immersive interfaces were more efficient, improved situational awareness and visual feedback, and were chosen by 94% of participants against conventional ones. On the other hand, participants performed better using natural language than conventional tools despite having less previous experience with the first ones. Additionally, according to 52% of the population, the preferred interaction tool was a mixed strategy that combined voice recognition and hand gestures. Therefore, it is concluded that immersive realities and natural language should play a very important role in the near future of hyper-redundant robots and their teleoperation.
C1 [Martin-Barrio, Andres; Roldan, Juan Jesus; Terrile, Silvia; del Cerro, Jaime; Barrientos, Antonio] Univ Politecn Madrid, CSIC, CAR, C Jose Gutierrez Abascal 2, E-28006 Madrid, Spain.
C3 Universidad Politecnica de Madrid; Consejo Superior de Investigaciones
   Cientificas (CSIC)
RP Martín-Barrio, A (corresponding author), Univ Politecn Madrid, CSIC, CAR, C Jose Gutierrez Abascal 2, E-28006 Madrid, Spain.
EM andres.mb@upm.es
RI Terrile, Silvia/IWE-0831-2023; Terrile, Silvia/AAA-2790-2019; Del Cerro,
   Jaime/AAA-3608-2019; Roldán-Gómez, Juan Jesús/ABG-8875-2021; Barrientos,
   Antonio/B-4053-2013
OI Terrile, Silvia/0000-0003-3900-4108; Del Cerro,
   Jaime/0000-0003-4893-2571; Barrientos, Antonio/0000-0003-1691-3907;
   ROLDAN GOMEZ, JUAN JESUS/0000-0001-8863-4419
FU RoboCity2030-DIH-CM project (RoboCity2030 - Madrid Robotics Digital
   Innovation Hub) [P2018/NMT-4331]; UPM Program project [VJIDOCUPM18JCG];
   project PRIC (Proteccion Robotizada de Infraestructuras Criticas) -
   Ministry of Economy and Competitiveness (Government of Spain)
   [DPI2014-56985-R]
FX The present work is the result of research activities carried out at the
   Centre for Automation and Robotics, CAR (CSIC-UPM), within the Robotics
   and Cybernetics research group (RobCib). Supported by the
   RoboCity2030-DIH-CM project (RoboCity2030 - Madrid Robotics Digital
   Innovation Hub, P2018/NMT-4331), the UPM Program project VJIDOCUPM18JCG,
   and by the project PRIC (Proteccion Robotizada de Infraestructuras
   Criticas, DPI2014-56985-R), funded by the Ministry of Economy and
   Competitiveness (Government of Spain). Also, our special thanks to all
   the participants that made possible the experimentation of this work.
CR [Anonymous], 2000, The Humane Interface: New directions for designing interactive systems
   [Anonymous], 2019, ROBOT OPERATING SYST
   [Anonymous], 2015, P 3 INT C HUM AG INT
   Aracil R, 2002, CONTROL ENG PRACT, V10, P1271, DOI 10.1016/S0967-0661(02)00182-X
   BARRIENTOS ANTONIO., 2007, Fundamentos de Robotica
   Bhattacherjee S, 2018, PROCEDIA COMPUT SCI, V133, P879, DOI 10.1016/j.procs.2018.07.106
   Britton N, 2015, SPRINGER TRAC ADV RO, V105, P259, DOI 10.1007/978-3-319-07488-7_18
   Bugalia N, 2015, P 2015 C ADV ROB, P49
   Chen JYC, 2007, IEEE T SYST MAN CY C, V37, P1231, DOI 10.1109/TSMCC.2007.905819
   Chirikjian G. S., 1994, IEEE Robotics & Automation Magazine, V1, P22, DOI 10.1109/100.388263
   Collins T, 2016, PASO INTEGRATED SCAL
   Daniel W.W., 1990, APPL NONPARAMETRIC S, V2
   Ding Cheng-jun, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P2024, DOI 10.1109/ICAL.2009.5262601
   Draper M., 2003, 47th Annual Meeting of the Human Factors and Ergonomics Society, V47, P109, DOI DOI 10.1177/154193120304700123
   Dutta P, 2017, FUSION ENG DES, V118, P73, DOI 10.1016/j.fusengdes.2017.03.047
   Endsley M. R., 1988, Proceedings of the IEEE 1988 National Aerospace and Electronics Conference: NAECON 1988 (Cat. No.88CH2596-5), P789, DOI 10.1109/NAECON.1988.195097
   Endsley M. R., 1988, P HUM FACT SOC ANN M, V32, P97, DOI DOI 10.1177/154193128803200221
   Espinoza M. S., 2012, 2012 Brazilian Robotics Symposium and Latin American Robotics Symposium (SBR-LARS 2012), P125, DOI 10.1109/SBR-LARS.2012.28
   Ferre M., 2007, ADV TELEROBOTICS STA, V31, P11
   Ferre M., 2007, Advances in Telerobotics
   Frigola M, 2003, IEEE INT CONF ROBOT, P386
   Gravagne I. A., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P19, DOI 10.1109/ROBOT.2000.844034
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hedayati H, 2018, ACMIEEE INT CONF HUM, P78, DOI 10.1145/3171221.3171251
   Hu C, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1560
   Roldán JJ, 2019, ROBOT CIM-INT MANUF, V59, P305, DOI 10.1016/j.rcim.2019.05.004
   Roldán JJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081720
   Kapadia AD, 2012, IEEE INT C INT ROBOT, P3105, DOI 10.1109/IROS.2012.6385990
   Koizumi Satoshi, 2006, P 15 IEEE INT S ROB, P145, DOI [10.1109/ROMAN.2006.314409, DOI 10.1109/ROMAN.2006.314409]
   Kot T, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881417751545
   Kuno Y, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P2590, DOI 10.1109/ROBOT.1999.773987
   Labonte D, 2010, IEEE T SYST MAN CY B, V40, P1331, DOI 10.1109/TSMCB.2009.2038357
   Lipton JI, 2018, IEEE ROBOT AUTOM LET, V3, P179, DOI 10.1109/LRA.2017.2737046
   Lok KH, 2010, IEEE INT CON MULTI, P814, DOI 10.1109/ICME.2010.5582567
   Lueth T. C., 1994, Proceedings. 3rd IEEE International Workshop on Robot and Human Communication. RO-MAN '94 Nagoya (Cat. No.94TH0679-1), P106, DOI 10.1109/ROMAN.1994.365947
   Mantecón T, 2016, LECT NOTES COMPUT SC, V10016, P47, DOI 10.1007/978-3-319-48680-2_5
   Marques L, 2009, 11 SPAN PORT C EL EN
   Martín A, 2018, REV IBEROAM AUTOM IN, V15, P351, DOI 10.4995/riai.2018.9207
   Martín A, 2018, SOFT ROBOT, V5, P242, DOI 10.1089/soro.2017.0009
   Martin-Barrio A, 2019, MODELING SOFT ROBOT
   Mashood A, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY RESEARCH (ICTRC), P298, DOI 10.1109/ICTRC.2015.7156481
   Matuszek Cynthia, 2013, EXPT ROBOTICS
   Michalos G, 2016, PROC CIRP, V41, P370, DOI 10.1016/j.procir.2015.12.005
   Mostefa Masmoudi., 2015, IEEE International Conference on Control, Engineering Information Technology (CEIT'15), P1
   Nielsen CW, 2007, IEEE T ROBOT, V23, P927, DOI 10.1109/TRO.2007.907479
   Pessaux P, 2015, LANGENBECK ARCH SURG, V400, P381, DOI 10.1007/s00423-014-1256-9
   Poncela A, 2015, ROBOTICA, V33, P1, DOI 10.1017/S0263574714000010
   Ren LX, 2017, IEEE ENG MED BIO, P4343, DOI 10.1109/EMBC.2017.8037817
   Rheingold H., 1991, VIRTUAL REALITY EXPL
   Rininsland H, 1999, EUR J CARDIO-THORAC, V16, pS106, DOI 10.1016/S1010-7940(99)00282-1
   Sayers C., 1999, Remote Control Robotics
   Shilling RD, 2002, HUM FAC ER, P65
   Shirwalkar S., 2013, 2013 INT C CONTR AUT, P1
   Stern G, 2007, TRIQUARTERLY, P57
   Yoshino M., 2001, P OHAN FSAN YOK JAP, P1
   Young StephenJ., 1982, Real Time Languages: Design and Development
   [No title captured]
NR 58
TC 11
Z9 12
U1 0
U2 33
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 541
EP 555
DI 10.1007/s10055-019-00414-9
EA DEC 2019
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000500864700001
DA 2024-07-18
ER

PT J
AU Cruz, E
   Orts-Escolano, S
   Gomez-Donoso, F
   Rizo, C
   Rangel, JC
   Mora, H
   Cazorla, M
AF Cruz, Edmanuel
   Orts-Escolano, Sergio
   Gomez-Donoso, Francisco
   Rizo, Carlos
   Rangel, Jose Carlos
   Mora, Higinio
   Cazorla, Miguel
TI An augmented reality application for improving shopping experience in
   large retail stores
SO VIRTUAL REALITY
LA English
DT Article
DE Smart shopping; Deep learning; Augmented reality; Retail stores; User
   experience; Human-computer interaction; 3D visualization
AB In several large retail stores, such as malls, sport or food stores, the customer often feels lost due to the difficulty in finding a product. Although these large stores usually have visual signs to guide customers toward specific products, sometimes these signs are also hard to find and are not updated. In this paper, we propose a system that jointly combines deep learning and augmented reality techniques to provide the customer with useful information. First, the proposed system learns the visual appearance of different areas in the store using a deep learning architecture. Then, customers can use their mobile devices to take a picture of the area where they are located within the store. Uploading this image to the system trained for image classification, we are able to identify the area where the customer is located. Then, using this information and novel augmented reality techniques, we provide information about the area where the customer is located: route to another area where a product is available, 3D product visualization, user location, analytics, etc. The system developed is able to successfully locate a user in an example store with 98% accuracy. The combination of deep learning systems together with augmented reality techniques shows promising results toward improving user experience in retail/commerce applications: branding, advance visualization, personalization, enhanced customer experience, etc.
C1 [Cruz, Edmanuel; Orts-Escolano, Sergio; Gomez-Donoso, Francisco; Rizo, Carlos; Rangel, Jose Carlos; Mora, Higinio; Cazorla, Miguel] Univ Alicante, Inst Univ Invest Informat, Alicante, Spain.
C3 Universitat d'Alacant
RP Cazorla, M (corresponding author), Univ Alicante, Inst Univ Invest Informat, Alicante, Spain.
EM miguel.cazorla@ua.es
RI Cazorla, Miguel/B-4464-2013; Cruz, Edmanuel/AAC-4552-2019; Rizo-Maestre,
   Carlos/AAA-4142-2019; Gomez-Donoso, Francisco/H-7539-2016; Mora,
   Higinio/L-3347-2014
OI Cazorla, Miguel/0000-0001-6805-3633; Cruz, Edmanuel/0000-0002-7988-3293;
   Rizo-Maestre, Carlos/0000-0002-9570-9818; Gomez-Donoso,
   Francisco/0000-0002-7830-2661; Mora, Higinio/0000-0002-8591-0710
FU Spanish Government [TIN2016-76515-R]; Feder funds; University of
   Alicante [GRE16-19]
FX This work has been supported by the Spanish Government TIN2016-76515-R
   Grant, supported with Feder funds. It has also been supported by the
   University of Alicante Project GRE16-19.
CR Ahn J, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808207
   Akgul O, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P47, DOI 10.1109/SITIS.2016.17
   [Anonymous], CLAR AMPL INT VIS
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Blázquez M, 2014, INT J ELECTRON COMM, V18, P97, DOI 10.2753/JEC1086-4415180404
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Goldman A, 2001, J RETAILING, V77, P221, DOI 10.1016/S0022-4359(01)00044-6
   Grewal D, 2017, J RETAILING, V93, P1, DOI 10.1016/j.jretai.2016.12.008
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   King DB, 2015, ACS SYM SER, V1214, P1
   Klein G, 2009, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2009.5336495
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lemon KN, 2016, J MARKETING, V80, P69, DOI 10.1509/jm.15.0420
   Li Zhizhong, 2016, LEARNING FORGETTING, P614
   Likavec S, 2015, INT J SEMANT WEB INF, V11, P1, DOI 10.4018/IJSWIS.2015100101
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Martínez-Gómez J, 2015, INT J ROBOT RES, V34, P1681, DOI 10.1177/0278364915596058
   Martínez-Gómez J, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58900
   Narzt W., 2006, Universal Access in the Information Society, V4, P177, DOI 10.1007/s10209-005-0017-5
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Ortiz-Catalan M, 2016, LANCET, V388, P2885, DOI 10.1016/S0140-6736(16)31598-7
   Pascanu R., 2012, ABS12115063 CORR
   Pauly O, 2015, COMPUT MED IMAG GRAP, V41, P55, DOI 10.1016/j.compmedimag.2014.06.007
   Rangel JC, 2016, ADV ROBOTICS, V30, P758, DOI 10.1080/01691864.2016.1164621
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Veijalainen J, 2008, INT J SEMANT WEB INF, V4, P20, DOI 10.4018/jswis.2008010102
   Willems K, 2017, TECHNOL FORECAST SOC, V124, P228, DOI 10.1016/j.techfore.2016.10.066
   Wu JX, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4763, DOI 10.1109/IROS.2009.5354164
NR 33
TC 43
Z9 52
U1 5
U2 63
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2019
VL 23
IS 3
SI SI
BP 281
EP 291
DI 10.1007/s10055-018-0338-3
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA IR5QR
UT WOS:000481490500007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chiarovano, E
   McGarvie, LA
   Szmulewicz, D
   MacDougall, HG
AF Chiarovano, Elodie
   McGarvie, Leigh A.
   Szmulewicz, David
   MacDougall, Hamish G.
TI RETRACTED: Subjective visual vertical in virtual reality (Curator SVV):
   validation and normative data (Retracted article. See OCT, 2022)
SO VIRTUAL REALITY
LA English
DT Article; Retracted Publication
DE SVV; Curator; Upright; Samsung Gear VR; Vestibular; Otolith
ID DIFFERENT ANGLES; ROLL-TILT; PERCEPTION; BUCKET; COMPENSATION; POSITION
AB Subjective visual vertical (SVV) assesses the ability to perceive verticality, which is a measure of vestibular otolithic function. Vestibular lesions influence this perception of verticality. We developed a method using virtual reality (VR) display and an Android software application named 'Curator SVV'. The virtual reality SVV (Curator SVV) consisted of ten readily identifiable artworks projected by a Samsung phone S6 which is inserted into a virtual reality headset. In the first study, 20 patients had there SVV assessed with two devices: (1) a commercially available SVV measurement device (VestiTest(A (R))) and (2) a virtual reality SVV using the Curator SVV application. In a second study, 32 healthy subjects had their SVV assessed by the Curator SVV application whilst sitting in a chair. In the first study, there was no significant difference (p = 0.44, paired t test and p = 0.01, test of equivalence) between results obtained by Curator SVV and the commercially available device. In the second study, the average angle measured for healthy subjects was 0.00A degrees A +/- 0.85A degrees. The normal range (mean +/- 2 SD) was +/- 2A degrees in standard upright position. We were able to demonstrate that the Curator SVV can be readily employed as an objective, non-invasive and affordable means of assessing otolith function in the clinical context. We validated this novel methodology by finding strong quantitative parity between a standard commercial SVV unit and the VR Curator SVV method. Our very lightweight and mobile device can be employed in clinical contexts including at the bedside and in different head and body positions.
C1 [Chiarovano, Elodie; McGarvie, Leigh A.; MacDougall, Hamish G.] Univ Sydney, Sch Psychol, Sydney, NSW, Australia.
   [McGarvie, Leigh A.] Royal Prince Alfred Hosp, Sydney, NSW, Australia.
   [Szmulewicz, David] Royal Victorian Eye & Ear Hosp, Melbourne, Vic, Australia.
C3 University of Sydney; University of Sydney; NSW Health; Royal Prince
   Alfred Hospital; Royal Victorian Eye & Ear Hospital
RP Chiarovano, E (corresponding author), Univ Sydney, Sch Psychol, Sydney, NSW, Australia.
EM elodie.chiarovano@sydney.edu.au
OI Chiarovano, Elodie/0000-0002-3738-0700; MacDougall,
   Hamish/0000-0001-6201-1707
FU NHMRC of Australia; Garnett Passe and Rodney Williams Memorial
   Foundation
FX HGM is currently receiving a project grant from NHMRC of Australia and
   from the Garnett Passe and Rodney Williams Memorial Foundation.
CR Batuecas-Caletrio A, 2013, ACTA OTO-LARYNGOL, V133, P475, DOI 10.3109/00016489.2012.757798
   Bergenius J, 1996, BRAIN RES BULL, V40, P385, DOI 10.1016/0361-9230(96)00131-1
   Bergenius J, 1996, BRAIN RES BULL, V40, P391, DOI 10.1016/S0361-9230(96)90389-5
   Brodsky JR, 2015, INT J PEDIATR OTORHI, V79, P2094, DOI 10.1016/j.ijporl.2015.09.020
   Bronstein AM, 2003, NEUROLOGY, V61, P1260, DOI 10.1212/01.WNL.0000086815.22816.DC
   Chiarovano E, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00005
   Curthoys IS, 2011, ANN NY ACAD SCI, V1233, P231, DOI 10.1111/j.1749-6632.2011.06147.x
   CURTHOYS IS, 1991, ACTA OTO-LARYNGOL, P5
   CURTHOYS IS, 1991, EXP BRAIN RES, V85, P218
   DAI MJ, 1989, EXP BRAIN RES, V77, P315, DOI 10.1007/BF00274989
   FERNANDEZ C, 1972, J NEUROPHYSIOL, V35, P978, DOI 10.1152/jn.1972.35.6.978
   Ferreira MM, 2016, BRAZ J OTORHINOLAR, V82, P442, DOI 10.1016/j.bjorl.2015.08.027
   Hafström A, 2004, ACTA OTO-LARYNGOL, V124, P165, DOI 10.1080/00016480410016630
   Lopez C, 2008, NEUROPSYCHOLOGIA, V46, P2435, DOI 10.1016/j.neuropsychologia.2008.03.017
   Luyat M, 1997, ACTA PSYCHOL, V95, P181, DOI 10.1016/S0001-6918(96)00015-7
   MacDougall HG, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061488
   Mittelstaedt H, 1999, ANN NY ACAD SCI, V871, P334, DOI 10.1111/j.1749-6632.1999.tb09196.x
   Ogawa Y, 2010, ACTA OTO-LARYNGOL, V130, P576, DOI 10.3109/00016480903352967
   Saj A, 2005, STROKE, V36, P2203, DOI 10.1161/01.STR.0000182236.73502.19
   Sun DQ, 2014, ACTA OTO-LARYNGOL, V134, P382, DOI 10.3109/00016489.2013.867456
   Tesio L, 2011, INT J REHABIL RES, V34, P307, DOI 10.1097/MRR.0b013e32834c45bc
   Zwergal A, 2009, NEUROLOGY, V72, P1689, DOI 10.1212/WNL.0b013e3181a55ecf
NR 22
TC 7
Z9 7
U1 0
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2018
VL 22
IS 4
BP 315
EP 320
DI 10.1007/s10055-018-0336-5
PG 6
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GV4NM
UT WOS:000446076600004
DA 2024-07-18
ER

PT J
AU Kefi, M
   Hoang, TN
   Richard, P
   Verhulst, E
AF Kefi, Marounene
   Hoang, Thuong N.
   Richard, Paul
   Verhulst, Eulalie
TI An evaluation of multimodal interaction techniques for 3D layout
   constraint solver in a desktop-based virtual environment
SO VIRTUAL REALITY
LA English
DT Article
DE Interaction techniques; Constraint solver; 3D layout; Virtual
   environments; Multimodality
AB We propose a new approach to the 3D layout problems based on the integration of constraint programming and virtual reality interaction techniques. Our method uses an open-source constraint solver integrated in a popular 3D game engine. We designed multimodal interaction techniques for the system, based on gesture and voice input. We conducted a user study with an interactive task of laying out room furniture to compare and evaluate the mono- and multimodal interaction techniques. Results showed that voice command provided the best performance and was most preferred by participants, based on the analysis of both objective and subjective data. Results also revealed that there was no significant difference between the voice and multimodal input (voice and gesture). Our original approach opens the way to multidisciplinary theoretical work and promotes the development of high-level applications for the VR applications.
C1 [Kefi, Marounene; Richard, Paul; Verhulst, Eulalie] Univ Angers, LARIS, Angers, France.
   [Hoang, Thuong N.] Deakin Univ, Sch Informat Technol, Melbourne, Vic, Australia.
C3 Universite d'Angers; Deakin University
RP Hoang, TN (corresponding author), Deakin Univ, Sch Informat Technol, Melbourne, Vic, Australia.
EM thuong.hoang@deakin.edu.au
RI Hoang, Thuong/IQV-0997-2023
OI Hoang, Thuong/0000-0001-7354-260X
CR García VMA, 2010, J NETW COMPUT APPL, V33, P603, DOI 10.1016/j.jnca.2010.03.005
   [Anonymous], 2013, 4 WORKSHOP SPEECH LA
   [Anonymous], 1999, THESIS
   Azenkot Shiri, 2013, P 15 INT ACM SIGACCE, P8
   Billinghurst M., 1998, Computer Graphics, V32, P60, DOI 10.1145/307710.307730
   Bolt R. A., 1992, UIST. Fifth Annual Symposium on User Interface Software and Technology. Proceedings, P7, DOI 10.1145/142621.142623
   Calderon C, 2003, LECT NOTES COMPUT SC, V2733, P112
   Calì C, 2016, J COMP NEUROL, V524, P23, DOI 10.1002/cne.23852
   Chun LM, 2015, 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS 2015, P59, DOI 10.1109/ICEEI.2015.7352470
   Fages F, 2004, CONSTRAINTS, V9, P241, DOI 10.1023/B:CONS.0000049203.53383.c1
   Fernando T., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P147, DOI 10.1145/323663.323686
   Gao SM, 2000, COMPUT GRAPH-UK, V24, P191, DOI 10.1016/S0097-8493(99)00154-5
   Goel V, 2015, EUR J OPER RES, V241, P662, DOI 10.1016/j.ejor.2014.09.048
   HART S G, 1988, P139
   Honda K, 1995, C ART INT APPL
   ISO/IEC, 2011, 25010 2011 SYST SOFT
   Jacob R.J. K., 1994, ACM Transactions Computer-Human Interaction, V1, P3, DOI [DOI 10.1145/174630.174631, 10.1145/174630.174631]
   Jacquenot G, 2009, THESIS
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Kefi M, 2012, PROC INT C TOOLS ART, P199, DOI 10.1109/ICTAI.2012.35
   Kulyukin V., 2004, HUMAN ROBOT INTERACT
   Medjdoub B, 2004, J INF TECHNOL CONSTR, V243, P627
   Patrick E, 2000, P SIGCHI C HUM FACT
   Pei-Ying Ku, 2013, Human-Computer Interaction: Applications and Services. 15th International Conference, HCI International 2013. Proceedings. LNCS 8005, P606, DOI 10.1007/978-3-642-39262-7_68
   PFEFFERKORN CE, 1975, COMMUN ACM, V18, P286, DOI 10.1145/360762.360817
   Pires J., 2006, Industrial Robots Programming: Building Applications for the Factories of the Future
   Regin JC, 2004, MODLISATION CONTRAIN
   Rogalski T, 2010, AEROSP SCI TECHNOL, V14, P321, DOI 10.1016/j.ast.2010.02.006
   Rogowski A, 2012, ROBOT CIM-INT MANUF, V4, P77
   Rogowski A, 2012, ROBOT CIM-INT MANUF, V28, P303, DOI 10.1016/j.rcim.2011.09.010
   Rossi F, 2006, FOUND ARTIF INTELL, P1
   Sanchez S, 2003, CONSTRAINT BASED 3D, V3IA
   Schulte C, 2013, MODELING GECODE
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Tim T, 2009, P CASA WORKSH 3D ADV, P212
   Turk M, 2014, PATTERN RECOGN LETT, V36, P189, DOI 10.1016/j.patrec.2013.07.003
   Weyrich M, 1999, COMPUT IND, V38, P5, DOI 10.1016/S0166-3615(98)00104-3
   Xu K, 2002, PROC GRAPH INTERF, P25
   Zhao W., 2005, P 10 ANN INT C IND E
NR 39
TC 2
Z9 2
U1 0
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2018
VL 22
IS 4
BP 339
EP 351
DI 10.1007/s10055-018-0337-4
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GV4NM
UT WOS:000446076600006
DA 2024-07-18
ER

PT J
AU Park, J
AF Park, Juyeon
TI Emotional reactions to the 3D virtual body and future willingness: the
   effects of self-esteem and social physique anxiety
SO VIRTUAL REALITY
LA English
DT Article
DE 3D body scanning; Virtual reality; Emotions; Body image
ID SCALE; DIMENSIONALITY; REALITY; IMAGE; MODEL
AB This study examined how the participant's self-esteem and social physique anxiety affected the emotional reactions to viewing their own virtual body and willingness to participate in the virtual experience in the future. Three-dimensional body scanning technology was used as a virtual reality tool. Ninety-three (51 males and 42 females) subjects participated in the experiment, who were 18+ years old, both genders, and had no history of musculoskeletal or mental problems. The experiment consisted of the three phases, including the pre-scanning survey, 3D body scanning, and post-scanning evaluation. The results verified causal relationships that led to certain types of emotions after viewing the 3D virtual body and the willingness to participate in a future session, within the domains of self-esteem and social physique anxiety. Specifically, self-confidence (positive dimension of self-esteem) was strongly associated with positive emotions. The "other-oriented" perspective of social physique anxiety exhibited positive correlations with negative emotions. The participants who showed positive emotions indicated a strong willingness to participate in another session of 3D body scanning in the future, but those with negative emotions also showed their positive willingness to participate in the future session. It signified that regardless of their emotional responses (positive or negative) to viewing their 3D virtual body, the participants were willing to experience their 3D virtual body in the future. The findings suggested that this virtual reality approach could be used as a potentially effective, clinical tool for patients with body image-related disorders. Study limitations and future research were also discussed.
C1 [Park, Juyeon] Colorado State Univ, Dept Design & Merchandising, Coll Hlth & Human Sci, Human Body Dimensioning Lab, 1574 Campus Delivery, Ft Collins, CO 80523 USA.
C3 Colorado State University
RP Park, J (corresponding author), Colorado State Univ, Dept Design & Merchandising, Coll Hlth & Human Sci, Human Body Dimensioning Lab, 1574 Campus Delivery, Ft Collins, CO 80523 USA.
EM Juyeon.Park@colostate.edu
CR Baranik LE, 2008, J APPL SOC PSYCHOL, V38, P1867, DOI 10.1111/j.1559-1816.2008.00372.x
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Bruchon-Schweitzer M, 1992, PSICOLOGIA CUERPO
   Cash T., 1990, Body images: Development, deviance and change
   Cash Thomas F, 2004, Body Image, V1, P1, DOI 10.1016/S1740-1445(03)00011-1
   Dovidio JF, 2000, SOCIAL PSYCHOLOGY OF STIGMA, P1
   Eisinga R, 2013, INT J PUBLIC HEALTH, V58, P637, DOI 10.1007/s00038-012-0416-3
   Ferrer-García M, 2012, BODY IMAGE, V9, P1, DOI 10.1016/j.bodyim.2011.10.001
   Fontaine Kevin R, 2004, Eat Behav, V5, P85, DOI 10.1016/S1471-0153(03)00059-X
   Fox K.R., 1998, ADV SPORT EXERCISE P, P295
   Friedman KE, 2005, OBES RES, V13, P907, DOI 10.1038/oby.2005.105
   Frith U, 2005, CONSCIOUS COGN, V14, P719, DOI 10.1016/j.concog.2005.04.006
   Gardner RM, 2002, BODY IMAGE: A HANDBOOK OF THEORY, RESEARCH, AND CLINICAL PRACTICE, P127
   Greenberger E, 2003, PERS INDIV DIFFER, V35, P1241, DOI 10.1016/S0191-8869(02)00331-8
   HART EA, 1989, J SPORT EXERCISE PSY, V11, P94, DOI 10.1123/jsep.11.1.94
   Link BG, 2006, LANCET, V367, P528, DOI 10.1016/S0140-6736(06)68184-1
   Loker S., 2004, Clothing and Textiles Research Journal, V22, P151, DOI [10.1177/0887302X0402200401, DOI 10.1177/0887302X0402200401]
   Mannarini S, 2010, TPM-TEST PSYCHOM MET, V17, P229
   Martin KA, 1997, J SPORT EXERCISE PSY, V19, P359, DOI 10.1123/jsep.19.4.359
   McKinnon L, 1999, ANN M INT TEXT APP A
   OWENS TJ, 1993, SOC PSYCHOL QUART, V56, P288, DOI 10.2307/2786665
   Perpina C, 1999, Cyberpsychol Behav, V2, P149, DOI 10.1089/cpb.1999.2.149
   Riva G, 2012, STUD HEALTH TECHNOL, V181, P278, DOI 10.3233/978-1-61499-121-2-278
   Riva Giuseppe, 2011, J Diabetes Sci Technol, V5, P283
   SCHLENKER BR, 1982, PSYCHOL BULL, V92, P641, DOI 10.1037/0033-2909.92.3.641
   Sheasby JE, 2000, PSYCHOL REP, V86, P1139, DOI 10.2466/pr0.2000.86.3c.1139
   Song HR, 2011, ASIAN J SOC PSYCHOL, V14, P176, DOI 10.1111/j.1467-839X.2011.01347.x
   Von Bergen C.W., 1996, COLL STUD J, V30, P418
NR 28
TC 9
Z9 11
U1 4
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2018
VL 22
IS 1
BP 1
EP 11
DI 10.1007/s10055-017-0314-3
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA FX0UJ
UT WOS:000425762200001
DA 2024-07-18
ER

PT J
AU Baus, O
   Bouchard, S
AF Baus, Oliver
   Bouchard, Stephane
TI Exposure to an unpleasant odour increases the sense of Presence in
   virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Presence; Olfaction; Odours; Reality; Realism
ID ENVIRONMENTS; EXPERIENCE
AB While olfactory cues affect the everyday human experience in the physical world, few studies have empirically examined the effect they could have on the human experience in virtual reality (VR). This project's goal was to determine whether the exposure to olfactory stimuli would affect the senses of Presence (primary measure), Reality and Realism (exploratory measures) in VR. In a virtual kitchen devoid of obvious visual cues linking the visual scene to an odour, three groups of 20 randomly assigned participants (12 females and 8 males per group), unaware of the potential exposure to olfactory stimuli, were exposed to either ambient air, a pleasant odour, or an unpleasant odour. The results reveal that the unpleasant odour had a statistically significant effect on the sense of Presence (as measured by repeated brief measures of Presence and the Independent Television Commission Sense of Presence Inventory), but the pleasant one did not. The lower perceived intensity of the pleasant odour may have contributed to its lower detection rate which, in turn, may have contributed to the pleasant odour's lack of effect on the sense of Presence. Neither of the olfactory stimuli had an effect on either the sense of Reality or the sense of Realism.
C1 [Baus, Oliver] Univ Ottawa, Ottawa, ON, Canada.
   [Baus, Oliver; Bouchard, Stephane] Univ Quebec Outaouais, Dept Psychoeduc & Psychol, Pavillon Alexandre Tache,283 Blvd Alexandre Tache, Gatineau, PQ J8X 3X7, Canada.
C3 University of Ottawa; University of Quebec; University Quebec Outaouais
RP Baus, O (corresponding author), Univ Ottawa, Ottawa, ON, Canada.; Baus, O (corresponding author), Univ Quebec Outaouais, Dept Psychoeduc & Psychol, Pavillon Alexandre Tache,283 Blvd Alexandre Tache, Gatineau, PQ J8X 3X7, Canada.
EM obaus@yahoo.ca
OI Bouchard, Stephane/0000-0002-5995-340X
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   NSERC; Canada Foundation for Innovation (CFI); Canada Research Chairs
FX This research was supported by a Natural Sciences and Engineering
   Research Council of Canada (NSERC) scholarship awarded to the first
   author, as well as by grants from the NSERC, the Canada Foundation for
   Innovation (CFI) and the Canada Research Chairs awarded to the second
   author.
CR AlaouiIsmaili O, 1997, CHEM SENSES, V22, P237, DOI 10.1093/chemse/22.3.237
   [Anonymous], 1992, PRESENCE
   Aymerich-Franch L, 2010, CYBERPSYCH BEH SOC N, V13, P649, DOI 10.1089/cyber.2009.0412
   Bangay S, 1998, ST HEAL T, V58, P43
   Baños RM, 2000, CYBERPSYCHOL BEHAV, V3, P327, DOI 10.1089/10949310050078760
   Barfield W, 1995, PRESENCE-TELEOP VIRT, V5, P109, DOI 10.1162/pres.1996.5.1.109
   BAUS O, 2010, J CYBERTHERAPY REHAB, V3, P31
   Baus O, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00112
   Bouchard S, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P59, DOI 10.1109/HAVE.2004.1391882
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Chen Y, 2006, P 16 INT C ART REAL
   Delplanque S, 2008, CHEM SENSES, V33, P469, DOI 10.1093/chemse/bjn014
   Demattè ML, 2009, CHEM SENSES, V34, P103, DOI 10.1093/chemse/bjn055
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Doop M, 2006, OLFACTION AND BRAIN
   Ferrier L, 2009, ANN PSYCHOL, V109, P361
   Freeman J, 2000, PRESENCE-TELEOP VIRT, V9, P149, DOI 10.1162/105474600566691
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P274, DOI 10.1162/pres.1996.5.3.274
   HIRSCH AR, 1995, PSYCHOL MARKET, V12, P585, DOI 10.1002/mar.4220120703
   Ijsselsteijn W., 2001, VIRTUALLY THERE VISI
   Jackman AH, 2005, LARYNGOSCOPE, V115, P2209, DOI 10.1097/01.mlg.0000183194.17484.bb
   Jacob TJC, 2006, PHYSIOL BEHAV, V87, P500, DOI 10.1016/j.physbeh.2005.11.018
   Jamieson G. A., 2005, Australian Journal of Clinical and Experimental Hypnosis, V33, P119, DOI DOI 10.1037/T14465-000
   Jamieson GA, 2013, EMPIRICAL TEST TELLE
   Jones L, 2004, HUMAN PERFORMANCE, SITUATION AWARENESS AND AUTOMATION: CURRENT RESEARCH AND TRENDS, VOL 2, P282
   Kalawsky R. S., 2000, PRES 2000 INT WORKSH
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   KIRKSMITH MD, 1990, CHEM SIGNAL, V5, P48
   Köster EP, 2002, CHEM SENSES, V27, P191, DOI 10.1093/chemse/27.3.191
   Laurel Brenda., 1993, Computers as Theatre
   Lauria R, 1997, J COMPUT MEDIAT COMM, V3
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Li W, 2007, PSYCHOL SCI, V18, P1044, DOI 10.1111/j.1467-9280.2007.02023.x
   Lombard M, 1997, J COMPUT MEDIAT COMM, V3
   Mantovani F, 2003, EMERG COMMUNICAT, V5, P167
   Minsky M., 1980, OMNI, V2, P45, DOI DOI 10.1145/566654.566630
   Nicovich SG, 2005, J COMPUT-MEDIAT COMM, V10
   PRATT DR, 1995, COMPUTER, V28, P17
   Ratey J., 2001, A user's guide to the brain
   RATTAZ C, 2001, BIENN M SOC RES CHIL
   Sacau A, 2008, COMPUT HUM BEHAV, V24, P2255, DOI 10.1016/j.chb.2007.11.001
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sas C, 2004, LECT NOTES COMPUT SC, V3038, P1017
   Schank R., 1997, VIRTUAL LEARNING REV
   SCHIFFMAN SS, 1974, SCIENCE, V185, P112, DOI 10.1126/science.185.4146.112
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie MJ, 2003, THESIS
   Seigneuric A, 2010, PERCEPTION, V39, P1541, DOI 10.1068/p6740
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Siegel S, 1999, TOXICOL IND HEALTH, V15, P323, DOI 10.1191/074823399678846772
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M, 1995, 5 95 FRAMEWORK IMMER
   Slater M., 1993, Presence, V2, P221, DOI [DOI 10.1162/PRES.1993.2.3.221, 10.1162/pres.1993.2.3.221]
   Slater M., 2003, PRESENCE CONNECT, P3
   Slater M, 2009, ANU PSICOL, V40, P193
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   TELLEGEN A, 1974, J ABNORM PSYCHOL, V83, P268, DOI 10.1037/h0036681
   Thornson CA, 2009, INT J HUM-COMPUT ST, V67, P62, DOI 10.1016/j.ijhcs.2008.08.006
   Van Schaik P, 2004, CYBERPSYCHOL BEHAV, V7, P540, DOI 10.1089/1094931042403145
   Washburn D. A., 2003, MODELING SIMULATION, V2, P19
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zybura M., 1999, OLFACTION VIRTUAL RE
NR 65
TC 64
Z9 70
U1 8
U2 66
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2017
VL 21
IS 2
BP 59
EP 74
DI 10.1007/s10055-016-0299-3
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA EV3ZT
UT WOS:000401698600001
DA 2024-07-18
ER

PT J
AU Borsci, S
   Lawson, G
   Salanitri, D
   Jha, B
AF Borsci, Simone
   Lawson, Glyn
   Salanitri, Davide
   Jha, Bhavna
TI When simulated environments make the difference: the effectiveness of
   different types of training of car service procedures
SO VIRTUAL REALITY
LA English
DT Article
DE Automotive; Car service maintenance; Training effectiveness; Training
   evaluation; Virtual reality
ID TOP VIRTUAL-REALITY; AUGMENTED REALITY; DESK-TOP; USABILITY; RETENTION;
   SYSTEMS; ACQUISITION; RESIDENTS; TRUST
AB An empirical analysis was performed to compare the effectiveness of different approaches to training a set of procedural skills to a sample of novice trainees. Sixty-five participants were randomly assigned to one of the following three training groups: (1) learning-by-doing in a 3D desktop virtual environment, (2) learning-by-observing a video (show-and-tell) explanation of the procedures, and (3) trial-and-error. In each group, participants were trained on two car service procedures. Participants were recalled to perform a procedure either 2 or 4 weeks after the training. The results showed that: (1) participants trained through the virtual approach of learning-by-doing performed both procedures significantly better (i.e. p < .05 in terms of errors and time) than people of non-virtual groups, (2) the virtual training group, after a period of non-use, were more effective than non-virtual training (i.e. p < .05) in their ability to recover their skills, (3) after a (simulated) long period from the training-i.e. up to 12 weeks-people who experienced 3D environments consistently performed better than people who received other kinds of training. The results also suggested that independently from the training group, trainees' visuospatial abilities were a predictor of performance, at least for the complex service procedure, adj R (2) = .460, and that post-training performances of people trained through virtual learning-by-doing are not affected by learning styles. Finally, a strong relationship (p < .001, R (2) = .441) was identified between usability and trust in the use of the virtual training tool-i.e. the more the system was perceived as usable, the more it was perceived as trustable to acquire the competences.
C1 [Borsci, Simone] Univ London Imperial Coll Sci Technol & Med, St Marys Hosp, Dept Surg & Canc, Diagnost Evidence Cooperat London, South Wharf Rd, London W2 1NY, England.
   [Lawson, Glyn; Salanitri, Davide] Univ Nottingham, Fac Engn, Human Factors Res Grp, Nottingham NG7 2RD, England.
   [Jha, Bhavna] Jaguar Land Rover, Abbey Rd, Coventry CV3 4LF, W Midlands, England.
C3 Imperial College London; University of Nottingham; Jaguar Land Rover
RP Borsci, S (corresponding author), Univ London Imperial Coll Sci Technol & Med, St Marys Hosp, Dept Surg & Canc, Diagnost Evidence Cooperat London, South Wharf Rd, London W2 1NY, England.
EM simone.borsci@gmail.com
RI Borsci, Simone/GRS-3540-2022; Borsci, Simone/AAB-2369-2019
OI Borsci, Simone/0000-0002-3591-3577; Borsci, Simone/0000-0002-3591-3577;
   Lawson, Glyn/0000-0002-8906-4873; Salanitri, Davide/0000-0001-5151-3103
FU Live Augmented Reality Training Environments (LARTE) [101509];
   Technology Strategy Board
FX This paper was completed as part of Live Augmented Reality Training
   Environments (LARTE)-101509 project. The authors would like to
   acknowledge the Technology Strategy Board for funding the work.
CR Ahlberg G, 2007, AM J SURG, V193, P797, DOI 10.1016/j.amjsurg.2006.06.050
   Akins Ralitsa B, 2005, BMC Med Res Methodol, V5, P37, DOI 10.1186/1471-2288-5-37
   Alippi C, 2003, IEEE T SYST MAN CY C, V33, P259, DOI 10.1109/TSMCC.2003.814035
   Anastassova M, 2005, INT J IND ERGONOM, V35, P67, DOI 10.1016/j.ergon.2004.08.005
   Anastassova M, 2009, APPL ERGON, V40, P713, DOI 10.1016/j.apergo.2008.06.008
   ANDERSON JR, 1982, PSYCHOL REV, V89, P369, DOI 10.1037/0033-295X.89.4.369
   [Anonymous], 2011, BIO WEB C, DOI DOI 10.1051/BIOCONF/20110100029
   Arthur W, 1997, J APPL PSYCHOL, V82, P783, DOI 10.1037/0021-9010.82.5.783
   Arthur W, 1998, HUM PERFORM, V11, P57, DOI 10.1207/s15327043hup1101_3
   Bandura A., 1992, Encyclopedia of learning and memory
   Belardinelli C, 2008, COGN PROCESS, V9, P217, DOI 10.1007/s10339-008-0216-0
   Borsci S, 2015, COMPUT IND, V67, P17, DOI 10.1016/j.compind.2014.12.002
   Borsci S, 2009, COGN PROCESS, V10, P193, DOI 10.1007/s10339-009-0268-9
   Bowman DA, 2002, PRESENCE-TELEOP VIRT, V11, P404, DOI 10.1162/105474602760204309
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Carlson P, 2015, IEEE T VIS COMPUT GR, V21, P770, DOI 10.1109/TVCG.2015.2393871
   Fitts P. M., 1967, Human performance
   Flavián C, 2006, INFORM MANAGE-AMSTER, V43, P1, DOI 10.1016/j.im.2005.01.002
   Garg AX, 2002, ACAD MED, V77, pS97, DOI 10.1097/00001888-200210001-00030
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Good P, 2000, Permutation Tests: A Practical Guide to Resampling Methods for Testing Hypotheses, VSecond
   Hall CR, 1998, P IEEE VIRT REAL ANN, P184, DOI 10.1109/VRAIS.1998.658488
   Hamilton EC, 2002, SURG ENDOSC, V16, P406, DOI 10.1007/s00464-001-8149-z
   HART S G, 1988, P139
   Jayaram Sankar, 2007, Virtual Reality, V11, P217, DOI 10.1007/s10055-007-0070-x
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kolb A.Y., 2005, BOSTON MA, P72
   Kolb D.A., 2000, EXPERIENTIAL LEARNIN
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Lewis JR, 2014, INT J HUM-COMPUT INT, V30, P663, DOI 10.1080/10447318.2014.930311
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Li JR, 2003, COMPUT IND, V52, P109, DOI 10.1016/S0166-3615(03)00103-9
   Lippert SK, 2005, J INF SCI, V31, P340, DOI 10.1177/0165551505055399
   McKnight D. H., 2011, Trans. Manag. Inf. Syst., V2, P1, DOI [10.1145/1985347.1985353, DOI 10.1145/1985347.1985353]
   Michalos G, 2010, CIRP J MANUF SCI TEC, V2, P81, DOI 10.1016/j.cirpj.2009.12.001
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nagendran M, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006575.pub3
   Ottosson S, 2002, J ENG DESIGN, V13, P159, DOI 10.1080/09544820210129823
   Parry G, 2011, SERV SCI RES INNOV S, P19, DOI 10.1007/978-1-4419-8321-3_2
   Parsons TD, 2004, NEUROPSYCHOLOGIA, V42, P555, DOI 10.1016/j.neuropsychologia.2003.08.014
   PETERS M, 1995, BRAIN COGNITION, V28, P39, DOI 10.1006/brcg.1995.1032
   Roy MC, 2001, INTERNET RES, V11, P388, DOI 10.1108/10662240110410165
   Sasse M.A., 2005, Trust and crime in information societies, P319
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Stefanidis D, 2005, SURGERY, V138, P165, DOI 10.1016/j.surg.2005.06.002
   Stefanidis D, 2007, SURG ENDOSC, V21, P1158, DOI 10.1007/s00464-006-9112-9
   Stone RT, 2011, HUM FACTORS, V53, P558, DOI 10.1177/0018720811413389
   Stork A., 2012, 2012 18th International Conference on Virtual Systems and Multimedia (VSMM 2012). Proceedings, P347, DOI 10.1109/VSMM.2012.6365944
   Tang A., 2003, COMP EFFECTIVENESS A, P73, DOI [10.1145/642611.642626, DOI 10.1145/642611.642626]
   Wayne DB, 2006, ACAD MED, V81, pS9, DOI 10.1097/00001888-200610001-00004
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Xu Wu, 2011, 2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference (ITAIC 2011), P167, DOI 10.1109/ITAIC.2011.6030177
   Yuviler-Gavish N, 2011, INT J HUM-COMPUT ST, V69, P113, DOI 10.1016/j.ijhcs.2010.11.005
   [No title captured]
NR 55
TC 8
Z9 11
U1 0
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2016
VL 20
IS 2
BP 83
EP 99
DI 10.1007/s10055-016-0286-8
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DM1GA
UT WOS:000376092200001
OA Green Accepted, Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Ruminski, D
AF Ruminski, Dariusz
TI An experimental study of spatial sound usefulness in searching and
   navigating through AR environments
SO VIRTUAL REALITY
LA English
DT Article
DE Spatial sound; Augmented reality; 3D sound in AR; Audio augmented
   reality; AR; HCI; CARE; CARL
ID SUPPORT
AB This paper presents an experimental study of spatial sound usefulness in searching and navigating through augmented reality environments. Participants were asked to find three objects hidden within no-sound and spatial sound AR environments. The experiment showed that the participants of the spatialized sound group performed faster and more efficiently than working in no-sound configuration. What is more, 3D sound was a valuable cue for navigation in AR environment. The collected data suggest that the use of spatial sound in AR environments can be a significant factor in searching and navigating for hidden objects within indoor AR scenes. To conduct the experiment, the CARE approach was applied, while its CARL language was extended with new elements responsible for controlling audio in 3D space.
C1 Poznan Univ Econ, Dept Informat Technol, PL-61875 Poznan, Poland.
C3 Poznan University of Economics & Business
RP Ruminski, D (corresponding author), Poznan Univ Econ, Dept Informat Technol, Al Niepodleglosci 10, PL-61875 Poznan, Poland.
EM ruminski@kti.ue.poznan.pl
RI Rumiński, Dariusz/J-7983-2019
OI Rumiński, Dariusz/0000-0001-8179-9894
FU Polish National Science Centre (NCN) [DEC-2012/07/B/ST6/01523]
FX This research work has been supported by the Polish National Science
   Centre (NCN) Grants No. DEC-2012/07/B/ST6/01523.
CR [Anonymous], VIRTUAL ENV ADV INTE
   [Anonymous], VRCAI 10, DOI DOI 10.1145/1900179.1900198
   [Anonymous], SIGGRAPH 03
   Billinghurst M, 1998, P IEEE VIRT REAL ANN, P20, DOI 10.1109/VRAIS.1998.658418
   Cohen M., 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P273, DOI 10.1109/ISVRI.2011.5759650
   Flotynski J, 2015, VISUAL COMPUT, V31, P1287, DOI 10.1007/s00371-014-1011-9
   Hatala M, 2005, J WEB SEMANT, V3, P5, DOI 10.1016/j.websem.2005.05.004
   Jones M, 2008, PERS UBIQUIT COMPUT, V12, P513, DOI 10.1007/s00779-007-0155-2
   Mariette Nicholas, 2013, Human Factors Research in Audio Augmented Reality, P11, DOI [10.1007/978-1-4614-4205-92, DOI 10.1007/978-1-4614-4205-92]
   Murphy D, 2011, SPATIAL SOUND COMPUT
   Poeschl S, 2013, P IEEE VIRT REAL ANN, P129, DOI 10.1109/VR.2013.6549396
   Qualcomm, 2015, VUF
   Regenbrecht H, 2004, PRESENCE-TELEOP VIRT, V13, P338, DOI 10.1162/1054746041422334
   Ruminski D, 2014, INT SYM MIX AUGMENT, P401
   Ruminski D, 2014, IFIP ADV INF COMM TE, V423, P183
   Ruminski D, 2014, 5TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS, IISA 2014, P329, DOI 10.1109/IISA.2014.6878808
   Sodnik J., 2006, P 18 AUSTR C COMPUTE, P111, DOI DOI 10.1145/1228175.1228197
   Walczak K, 2014, P I CON VIR SYS MULT, P353, DOI 10.1109/VSMM.2014.7136656
   Zhou ZY, 2004, INTERACT COMPUT, V16, P1043, DOI 10.1016/j.intcom.2004.06.016
NR 19
TC 15
Z9 15
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2015
VL 19
IS 3-4
SI SI
BP 223
EP 233
DI 10.1007/s10055-015-0274-4
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CU9KG
UT WOS:000363862800007
OA hybrid
DA 2024-07-18
ER

PT J
AU Hwang, I
   Yim, S
   Choi, S
AF Hwang, Inwook
   Yim, Sunghoon
   Choi, Seungmoon
TI Haptic discrimination of virtual surface slope
SO VIRTUAL REALITY
LA English
DT Article
DE Discrimination; Surface slope; Haptic rendering; Virtual surface; Mesh
   simplification; Mesh manipulation
ID OBJECT SHAPE; PERCEPTION; POSITION; INTEGRATION; THRESHOLDS; VIBRATION;
   TEXTURE; HUMANS; HAND
AB We report the difference thresholds of the slope of a virtual surface rendered via a force-feedback haptic interface with the body frontal plane as a reference. The factors varied in experiments were the stiffness of a virtual plane, the lateral velocity with which the haptic probe scanned the plane, the length of a scanning interval, the movement direction of the probe to the body frontal plane (toward or away from the body), and lateral scanning direction (left-to-right or right-to-left). Measured slope thresholds ranged from 8.33A degrees to 12.74A degrees and were generally higher than or similar to previously published thresholds for haptic orientation or angle discrimination. The results suggested that haptic slope discriminability was independent of surface stiffness and lateral scanning velocity. Slope discrimination was largely affected by the lateral scan distance, indicating that the terminal difference of probe normal position can be an important sensory cue. In terms of scan direction, inward or rightward scans resulted in better slope discrimination than outward or leftward scans, respectively. These thresholds and findings have implications for haptics applications that involve geometric model modification or simplification of virtual objects while preserving their perceptual properties.
C1 [Hwang, Inwook; Yim, Sunghoon; Choi, Seungmoon] Pohang Univ Sci & Technol POSTECH, Dept Comp Sci & Engn, Hapt & Virtual Real Lab, Pohang, Gyeongsangbuk D, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Hwang, I (corresponding author), Pohang Univ Sci & Technol POSTECH, Dept Comp Sci & Engn, Hapt & Virtual Real Lab, Pohang, Gyeongsangbuk D, South Korea.
EM inux@postech.ac.kr; algorab@postech.ac.kr; choism@postech.ac.kr
OI Choi, Seungmoon/0000-0002-5889-1083; Hwang, Inwook/0000-0002-2382-7575
FU National Research Foundation of Korea (NRF) grant [2013R1A2A-2A01016907,
   2011-0027995]; ITRC (Information Technology Research Center) support
   program [NIPA-2013-H0301-13-3005]; Korea government (MSIP)
FX This work was supported in part by the National Research Foundation of
   Korea (NRF) grant (No. 2013R1A2A-2A01016907 and No. 2011-0027995) and by
   the ITRC (Information Technology Research Center) support program
   (NIPA-2013-H0301-13-3005) supervised by the NIPA (National IT Industry
   Promotion Agency), all funded by the Korea government (MSIP).
CR [Anonymous], 2008, HAPTIC RENDERING FDN
   Barbagli F., 2006, ACM T APPL PERCEPT, V3, P125, DOI [10.1145/1141897.1141901, DOI 10.1145/1141897.1141901]
   Brisben AJ, 1999, J NEUROPHYSIOL, V81, P1548, DOI 10.1152/jn.1999.81.4.1548
   Cheon J, 2008, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2008, PROCEEDINGS, P193
   Chib VS, 2006, J NEUROPHYSIOL, V95, P1068, DOI 10.1152/jn.00610.2005
   Choi S, 2004, PRESENCE-TELEOP VIRT, V13, P395, DOI 10.1162/1054746041944867
   Choi S., 2005, ACM Transactions on Applied Perception, V2, P89, DOI DOI 10.1145/1060581.10
   Drewing K, 2006, BRAIN RES, V1078, P92, DOI 10.1016/j.brainres.2005.12.026
   Fasse ED, 2000, BIOL CYBERN, V82, P69, DOI 10.1007/PL00007962
   Garland M., 1999, EUROGRAPHICS STATE A, P111
   Giachritsis CD, 2009, ATTEN PERCEPT PSYCHO, V71, P1628, DOI 10.3758/APP.71.7.1628
   Haggard P, 2000, PERCEPT PSYCHOPHYS, V62, P363, DOI 10.3758/BF03205556
   Henriques DYP, 2003, EXP BRAIN RES, V150, P95, DOI 10.1007/s00221-003-1402-z
   Hinterseer P, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P35
   Kappers AML, 1999, PERCEPTION, V28, P781, DOI 10.1068/p2930
   Knill DC, 1998, VISION RES, V38, P1683, DOI 10.1016/S0042-6989(97)00325-8
   Knox JJ, 2005, EXP BRAIN RES, V165, P107, DOI 10.1007/s00221-005-2293-y
   Kontsevich LL, 1999, VISION RES, V39, P2729, DOI 10.1016/S0042-6989(98)00285-5
   Kuschel M, 2006, IEEE INT CONF ROBOT, P2933, DOI 10.1109/ROBOT.2006.1642147
   LEEK MR, 1992, PERCEPT PSYCHOPHYS, V51, P247, DOI 10.3758/BF03212251
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Louw S, 2002, PERCEPT PSYCHOPHYS, V64, P1108, DOI 10.3758/BF03194760
   Louw S, 2000, EXP BRAIN RES, V132, P369, DOI 10.1007/s002210000350
   Morioka M, 2005, SOMATOSENS MOT RES, V22, P281, DOI 10.1080/08990220500420400
   MUSSAIVALDI FA, 1985, J NEUROSCI, V5, P2732
   Payandeh S., 2005, ACM TRANSACTION APPL, V2, P15
   Prattichizzo D, 2007, IEEE MULTIMEDIA, V14, P84, DOI 10.1109/MMUL.2007.58
   SHELTON BR, 1984, PERCEPT PSYCHOPHYS, V35, P385, DOI 10.3758/BF03206343
   van Beers RJ, 1998, EXP BRAIN RES, V122, P367, DOI 10.1007/s002210050525
   van der Horst BJ, 2007, EXP BRAIN RES, V177, P304, DOI 10.1007/s00221-006-0670-9
   Voisin J, 2002, EXP BRAIN RES, V145, P239, DOI 10.1007/s00221-002-1117-6
   Voisin J, 2002, EXP BRAIN RES, V145, P251, DOI 10.1007/s00221-002-1118-5
   Weisstein E.W., 2010, POINT PLANE DISTANCE
   Zadeh MH, 2008, MULTIMEDIA SYST, V13, P275, DOI 10.1007/s00530-007-0106-9
NR 34
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2013
VL 17
IS 3
BP 205
EP 218
DI 10.1007/s10055-013-0226-9
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 214EM
UT WOS:000324113800004
DA 2024-07-18
ER

PT J
AU Quarles, J
   Lampotang, S
   Fischler, I
   Fishwick, P
   Lok, B
AF Quarles, John
   Lampotang, Samsun
   Fischler, Ira
   Fishwick, Paul
   Lok, Benjamin
TI Experiences in mixed reality-based collocated after action review
SO VIRTUAL REALITY
LA English
DT Review
DE Mixed reality; After action review; Anesthesia machine; Human patient
   simulator; User studies; Skin prepping
AB After action review (AAR) is a widely used training practice in which trainees and trainers review past training experiences and performance for the purpose of learning. AAR has often been conducted with video-based systems whereby a video of the action is reviewed afterward, usually at another location. This paper proposes collocated AAR of training experiences through mixed reality (MR). Collocated AAR allows users to review past training experiences in situ with the user's current, real-world experience, i.e., the AAR is conducted at the same location where the action being reviewed occurred. MR enables a user-controlled egocentric viewpoint, augmentation such as a visual overlay of virtual information like conceptual visualizations, and playback of recorded training experiences collocated with the user's current experience or that of an expert. Collocated AAR presents novel challenges for MR, such as collocating time, interactions, and visualizations of previous and current experiences. We created a collocated AAR system for anesthesia education, the augmented anesthesia machine visualization, and interactive debriefing system. The system enables collocated AAR in two applications related to anesthesia training: anesthesia machine operation training and skin disinfection training with a mannequin patient simulator. Collocated AAR was evaluated in two informal pilot studies by students (n = 19) and an educator (n = 1) not directly affiliated with the project. We review the anecdotal data collected from the studies and point toward ways to refine and improve collocated AAR.
C1 [Quarles, John] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78254 USA.
   [Lampotang, Samsun] Univ Florida, Dept Anesthesiol, Gainesville, FL 32610 USA.
   [Fischler, Ira] Univ Florida, Dept Psychol, Gainesville, FL 32611 USA.
   [Fishwick, Paul; Lok, Benjamin] Univ Florida, Dept CISE, Gainesville, FL 32611 USA.
C3 University of Texas System; University of Texas at San Antonio (UTSA);
   State University System of Florida; University of Florida; State
   University System of Florida; University of Florida; State University
   System of Florida; University of Florida
RP Quarles, J (corresponding author), Univ Texas San Antonio, Dept Comp Sci, 1 UTSA Circle, San Antonio, TX 78254 USA.
EM jpq@cs.utsa.edu
RI Lampotang, Samsun/ABA-4147-2021; Lok, Benjamin/AAW-6501-2021
OI Lampotang, Samsun/0000-0003-0986-1969; Lok, Benjamin/0000-0002-1190-3729
FU National Science Foundation [IIS-0643557]
FX This research is supported in part by National Science Foundation Grant
   IIS-0643557. A special thanks goes to Nikolaus Gravenstein, David
   Lizdas, Andrew Raij, Kyle Johnsen, Cynthia Kaschub, and the study
   participants. Some of the technology mentioned here is UF patent
   pending.
CR Bier EA., 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques, P73
   Chua PT, 2003, P IEEE VIRT REAL ANN, P87
   Department of the Army, 1993, 2520 DEP ARM
   Fischler IS, 2008, SIMUL HEALTHC, V3, P26, DOI 10.1097/SIH.0b013e31816366d3
   Fishwick P. A., 1995, Simulation model design and execution: Building digital worlds
   Fishwick PA, 2004, SIMUL-T SOC MOD SIM, V80, P421, DOI 10.1177/0037549704044081
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Keen R.E., 1992, Computer Simulation in Biology: A BASIC Introduction
   Kester L, 2006, CONTEMP EDUC PSYCHOL, V31, P167, DOI 10.1016/j.cedpsych.2005.04.002
   Knerr BW, 2002, INTERSERVICE IND TRA
   Lampotang S., 2006, Educational Technology, V46, P55
   Lizdas DE, 2009, SIMUL HEALTHC, V4, P193
   Looser Julian., 2004, P 2 INT C COMPUTER G, P204, DOI DOI 10.1145/988834.988870
   Lynch C., 2006, P WORKSHOP INTELLIGE, P1
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Morie JF, 2005, APPL PSYCHOPHYS BIOF, V30, P319, DOI 10.1007/s10484-005-6386-y
   Park M, 2005, SIMUL-T SOC MOD SIM, V81, P795, DOI 10.1177/0037549705064359
   Quarles J, 2008, MIXED REALITY APPROA, P27
   Quarles J, 2008, TANGIBEL USER INTERF, P11
   Quarles J, 2008, INT SYM MIX AUGMENT, P107, DOI 10.1109/ISMAR.2008.4637335
   Raij AB, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P91
   Sielhorst T, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P38
   SMITH R, 1994, WSC 94, P845
   Suebnukarn S, 2006, ARTIF INTELL MED, V38, P5, DOI 10.1016/j.artmed.2005.04.003
   Viega John., 1996, Proc. of the ACM Symp. on User Interfaces and Technology (UIST), P51
   Yamnill S., 2001, HUM RESOUR DEV Q, V12, P195, DOI DOI 10.1002/HRDQ.7
NR 26
TC 5
Z9 5
U1 1
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2013
VL 17
IS 3
BP 239
EP 252
DI 10.1007/s10055-013-0229-6
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 214EM
UT WOS:000324113800006
DA 2024-07-18
ER

PT J
AU Edirisinghe, C
   Zhu, KN
   Ranasinghe, N
   Khoo, ET
   Srivatsan, VE
   Wijesena, JP
   Fernando, ONN
   Cheok, AD
AF Edirisinghe, Chamari
   Zhu, Kening
   Ranasinghe, Nimesha
   Khoo, Eng Tat
   Srivatsan, Vidyarth Eluppai
   Wijesena, Janaka Prasad
   Fernando, Owen Noel Newton
   Cheok, Adrian David
TI Modeling literary culture through interactive digital media
SO VIRTUAL REALITY
LA English
DT Article
DE Cultural computing; Social interaction; Literature; SMS; Mobile culture;
   Digital media; Interactive computing system
AB In the rapidly transforming landscape of modern world, people unconsciously refrain from interacting in public spaces, containing their communications that are extensive and universal, within home and relatively individually. The mass connectivity and technological advancement created new cultural values, thus altering the human perception of the world around him. This state of affairs is jeopardizing some of the cultural identities that have surmounted few centuries, shaping the values and associated customs of numerous generations. Furthermore, the computer technology became integrated exceedingly with the modern culture, which prompted us to introduce and explore the avenues of cultural computing that is the familiar ground of the modern society. With the intention of promoting values of distinct cultures, which will greatly assist in enhancing the social relationship, we have developed a framework to communicate literature through digital media, which introduced the platform to create Poetry Mix-up.
C1 [Edirisinghe, Chamari; Zhu, Kening; Ranasinghe, Nimesha; Khoo, Eng Tat; Srivatsan, Vidyarth Eluppai; Wijesena, Janaka Prasad; Fernando, Owen Noel Newton; Cheok, Adrian David] Natl Univ Singapore, Mixed Real Lab, Singapore 117548, Singapore.
   [Cheok, Adrian David] Keio Univ, Grad Sch Media Design, Tokyo, Japan.
C3 National University of Singapore; Keio University
RP Edirisinghe, C (corresponding author), Natl Univ Singapore, Mixed Real Lab, Singapore 117548, Singapore.
EM chamari@mixedrealitylab.org
RI Zhu, Kening/AAI-8826-2020; Cheok, Adrian David/AAT-6141-2021
OI Zhu, Kening/0000-0001-6740-4921; Cheok, Adrian
   David/0000-0001-6316-2339; Fernando, Owen Noel
   Newton/0000-0003-1486-1314
CR Amoore Louise., 2005, The global resistance reader
   Bakardjieva M, 2003, MEDIA CULT SOC, V25, P291, DOI 10.1177/0163443703025003472
   Boguraev B., 1997, ADV AUTOMATIC TEXT S, P2
   Carey JamesW., 1992, COMMUNICATION CULTUR
   CHEOK AD, 2008, SIGGRAPH 08, P11
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Geertz C., 2000, The Interpretation of Cultures
   Hannerz U., 1992, CULTURAL COMPLEXITY
   Hu J, 2008, INT J ARTS TECHNOL, V1, P102, DOI 10.1504/IJART.2008.019885
   Manovich Lev, 2001, The Language of new media
   Pacey A., 1983, The Culture of Technology
   SONG M, 2003, GRAPHITE 03, P223
   Song M., 2004, VRCAI 04, P163
   TOSA N, 2004, SIGGRAPH 04 ACM SIGG, P11
   TOSA N, 2007, SIGGRAPH 07, P250
   Williams Raymond, 1965, LONG REVOLUTION
NR 16
TC 0
Z9 0
U1 1
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2011
VL 15
IS 4
SI SI
BP 239
EP 247
DI 10.1007/s10055-009-0147-9
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IC
UT WOS:000296280300001
DA 2024-07-18
ER

PT J
AU Lee, H
   Banerjee, A
AF Lee, Hyunsoo
   Banerjee, Amarnath
TI A self-configurable large-scale virtual manufacturing environment for
   collaborative designers
SO VIRTUAL REALITY
LA English
DT Article
DE Large-scale virtual manufacturing environment (LSVME); Metaearth
   architecture; Self-reconfiguration; Collaborative construction
AB As manufacturing environments are getting distributed and increasing in size, the related virtual environments are getting larger and more closely networked together. This trend has led to a new paradigm-large-scale virtual manufacturing environment (LSVME). It supports networked and distributed virtual manufacturing to meet manufacturing system requirements. Since it contains a large number of virtual components, an effective data structure and collaborative construction methodology are needed. A metaearth architecture is proposed as the data structure for representing LSVME. This architecture consists of virtual space layer, mapping layer, library layer and ontology layers, which describe interaction among virtual components and has the ability to analyze the characteristics of virtual environment. In addition, it increases reusability of virtual components and supports self-reconfiguration for manufacturing simulation. A heuristic construction method based on graph theory is proposed using this architecture. It prevents redundant design of virtual components and contributes to an effective construction scheduling technique for collaborative designers.
C1 [Lee, Hyunsoo; Banerjee, Amarnath] Texas A&M Univ, Dept Ind & Syst Engn, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station
RP Banerjee, A (corresponding author), Texas A&M Univ, Dept Ind & Syst Engn, 3131 TMAUS, College Stn, TX 77843 USA.
EM banerjee@tamu.edu
RI Banerjee, Amarnath/I-6560-2012
OI Banerjee, Amarnath/0000-0002-9814-0989; Lee, Hyunsoo/0000-0001-5512-2986
CR [Anonymous], 2001, Int. Arch. Photogramm, Remote Sens., DOI DOI 10.5194/ISPRSARCHIVES-XL-5-W2-207-2013
   Banerjee A, 2000, IEEE T ROBOTIC AUTOM, V16, P218, DOI 10.1109/70.850640
   Chan DSK, 2006, ENG LET, V13
   Chawla R, 2001, WSC'01: PROCEEDINGS OF THE 2001 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P991, DOI 10.1109/WSC.2001.977404
   Chen CL, 2009, COMPUT OPER RES, V36, P3073, DOI 10.1016/j.cor.2009.02.004
   Chu CCP, 1998, IIE TRANS, V30, P629, DOI 10.1080/07408179808966507
   Chung CH, 2008, COMPUT IND, V59, P82, DOI 10.1016/j.compind.2007.06.004
   Diestel R., 2005, GRAPH THEORY
   FREY D, 2008, WORKSH MMVE IEEE VIR
   GARDNER L, 1985, ASTM STP, V862
   Goh WT, 2003, J MATER PROCESS TECH, V139, P103, DOI 10.1016/S0924-0136(03)00189-4
   GRUEN A, 2003, INT ARCH PHOTOGRAMME
   GUNADI CR, 2002, P 1 INT S 3D DAT PRO
   HAALA N, 1997, P SPIE C, P212
   HARIRI B, 2008, DISTRIBUTED INTEREST
   Hu SY, 2006, IEEE NETWORK, V20, P22, DOI 10.1109/MNET.2006.1668400
   JAYNES C, 2003, EGVE 03, P115
   KELLER J, 2003, INT C PAR DISTR TECH
   Lamotte Wim, 2008, Campus-Wide Information Systems, V25, P329, DOI 10.1108/10650740810921475
   Macedonia M.R., 1994, PRESENCE, V3, P265, DOI 10.1162/pres.1994.3.4.265
   Morse KL, 2000, PRESENCE-TELEOP VIRT, V9, P52, DOI 10.1162/105474600566619
   Offodile OF, 2002, INT J PROD ECON, V75, P147, DOI 10.1016/S0925-5273(01)00188-8
   Park SC, 2005, COMPUT IND, V56, P734, DOI 10.1016/j.compind.2005.04.002
   Rottensteiner F, 2003, IEEE COMPUT GRAPH, V23, P42, DOI 10.1109/MCG.2003.1242381
   RUSSO KL, 1995, 13 WORKSH STAND INT, P587
   Seo YH, 2006, INT J ADV MANUF TECH, V28, P101, DOI 10.1007/s00170-004-2422-y
   SHAN J, 2002, URISA, V14, P19
   SMITH J, 1995, 12 WORKSH STAND INT, P175
   STEPENSON N, 1993, SNOW CRASH
   Stone RJ, 2001, LECT NOTES COMPUT SC, V2058, P1
   ULM K, 2002, IMPROVED 3D CITY MOD
   VOSSELMAN G, 2002, P INT GEOSC REM SENS
   VRABLIK R, 1995, COMMUNICATION
   Wang LY, 2006, LECT NOTES COMPUT SC, V3942, P818, DOI 10.1007/11736639_102
   XIAOFENG Z, 2008, P IEEE INT C AUT LOG, P2852
NR 35
TC 14
Z9 14
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2011
VL 15
IS 1
SI SI
BP 21
EP 40
DI 10.1007/s10055-009-0151-0
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HZ
UT WOS:000296280000003
DA 2024-07-18
ER

PT B
AU Otmane, S
   Domingues, C
   Davesne, F
   Mallem, M
AF Otmane, Samir
   Domingues, Christophe
   Davesne, Frederic
   Mallem, Malik
BE Kim, JJ
TI Collaborative 3D Interaction in Virtual Environments: a Workflow-Based
   Approach
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
C1 [Otmane, Samir; Domingues, Christophe; Davesne, Frederic; Mallem, Malik] Univ Evry, IBISC Lab, Evry, France.
C3 Universite Paris Saclay
RP Otmane, S (corresponding author), Univ Evry, IBISC Lab, Evry, France.
RI MALLEM, Malik/P-6389-2017
OI MALLEM, Malik/0000-0002-2471-7028; Davesne, Frederic/0000-0001-9100-7109
CR Aguerreche L., 2009, JOINT VIRT REAL C EG
   BENFORD S, 1993, PROCEEDINGS OF THE THIRD EUROPEAN CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK ( ECSCW 93 ), P109
   Bharadwaj V., 2005, INTEGRATING AWARENES, P18
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Ding Dawei, 2003, P ACM S VIRTUAL REAL, P223
   Duval T., 2004, MEC IND, V5, P129
   Duval T., 2009, WEB3D 09 P 14 INT C
   Duval T., 2006, P 3D US INT 3DUI 06
   Fuchs P., 2003, RALIT VIRTUELLE SES, P3
   Gerhard M., 2001, Intelligent Virtual Agents. Third International Workshop, IVA 2001. Proceedings (Lecture Notes in Artificial Intelligence Vol.2190), P137
   Greenhalgh C, 1999, PRESENCE-TELEOP VIRT, V8, P14, DOI 10.1162/105474699566026
   Greenhalgh Chris., 1997, Large scale collaborative virtual environments
   Noma H., 1997, Proceedings of the ASME Dynamic Systems and Control Division, P101
   Otmane S., 2000, Proceedings 33rd Annual Simulation Symposium (SS 2000), P185, DOI 10.1109/SIMSYM.2000.844915
   Otmane S, 2007, INT C COMP SUPP COOP, P198
   Pinho M. S., 2002, VRST 02, P171
   Prada R, 2009, VIRTUAL REAL-LONDON, V13, P117, DOI 10.1007/s10055-009-0115-4
   Riege K., 2006, BENT PICK RAY EXTEND, P62
   Rodden T., 1996, Proceedings of the 1996 ACM Conference on Computer Supported Cooperative Work, P87
   Sandor O, 1997, PROCEEDINGS OF THE FIFTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P221
   Ullah Sehat, 2009, International Journal of Virtual Reality, V8, P79
   Ullah S., 2008, P 7 ACM SIGGRAPH INT
NR 22
TC 0
Z9 0
U1 0
U2 2
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 49
EP 68
D2 10.5772/553
PG 20
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400004
DA 2024-07-18
ER

PT J
AU Kim, MJ
   Kang, Y
AF Kim, Mary Jinyoung
   Kang, Younah
TI Older adults' user experience of virtual tourism: exploring presence and
   experiential value with respect to age difference
SO VIRTUAL REALITY
LA English
DT Article
DE Human-centered computing; Human-computer interaction (HCI); Interaction
   paradigms; Virtual reality
ID REALITY; CYBERSICKNESS; FEASIBILITY; TECHNOLOGY; MEMORY; TRAVEL
AB Virtual tourism or VR tourism has attracted great attention for its ability to simulate real-world experiences at a much lower cost and safer than actual travel. However, previous studies have mainly targeted young people or studies on older adults did not compare different age groups with both quantitative and qualitative methods. This study analyzed empirical user experiences of VR tourism via head-mounted displays (HMDs) by age group, with particular focus on experiential values, presence, and cybersickness. It was found that older adults perceived higher experiential values and presence than younger people and experienced less cybersickness, which is in contrast to previous research suggesting that susceptibility to VR sickness may increase with age. Furthermore, many older adults considered that virtual tourism can be an alternative to actual travel. This study addresses the effectiveness and applicability of VR tourism in older demographics and its potential contribution to their welfare.
C1 [Kim, Mary Jinyoung] Yonsei Univ, Design Intelligence, Seoul, South Korea.
   [Kang, Younah] Yonsei Univ, Underwood Int Coll, Veritas C 418,85 Songdogwahak Ro, Seoul 406840, South Korea.
C3 Yonsei University; Yonsei University
RP Kang, Y (corresponding author), Yonsei Univ, Underwood Int Coll, Veritas C 418,85 Songdogwahak Ro, Seoul 406840, South Korea.
EM marykim1013@gmail.com; yakang@yonsei.ac.kr
OI Kang, Youn Ah/0000-0003-4981-6329
FU Ministry of Trade, Industry and Energy [N0001436]
FX The Funding was supported by Ministry of Trade, Industry and Energy,
   N0001436
CR Ali A, 2014, J HOSP TOUR TECHNOL, V5, P2, DOI 10.1108/JHTT-12-2012-0034
   Ankomah P, 2018, ENCYCLOPEDIA OF INFORMATION SCIENCE AND TECHNOLOGY, 4TH EDITION, P4113, DOI 10.4018/978-1-5225-2255-3.ch356
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Beck J, 2019, TOUR REV, V74, P586, DOI 10.1108/TR-03-2017-0049
   Benoit M, 2015, NEUROPSYCH DIS TREAT, V11, P557, DOI 10.2147/NDT.S73179
   Bogicevic V, 2019, TOURISM MANAGE, V74, P55, DOI 10.1016/j.tourman.2019.02.009
   Boley BB, 2015, TOUR PLAN DEV, V12, P208, DOI 10.1080/21568316.2014.925489
   Bonetti F, 2018, PROGR IS, P119, DOI 10.1007/978-3-319-64027-3_9
   Chang S, 2018, TOURISM MANAGE, V64, P55, DOI 10.1016/j.tourman.2017.08.004
   CHEONG R, 1995, TOURISM MANAGE, V16, P417, DOI 10.1016/0261-5177(95)00049-T
   Chung Donghun, 2012, [JOURNAL OF BROADCAST ENGINEERING, 방송공학회 논문지], V17, P49
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   Loureiro SMC, 2019, J BUS RES, V100, P514, DOI 10.1016/j.jbusres.2018.10.055
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Dewailly J.M., 1999, Tourism Geographies, V1, P41, DOI DOI 10.1080/14616689908721293
   Dieck C., 2019, Augmented Reality and Virtual Reality - The Power of AR and VR for Business, P89, DOI [10.1007/978-3-030-06246-0_7, DOI 10.1007/978-3-030-06246-0_7]
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Fiocco AJ, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250761
   Gallace Alberto, 2012, Multiple sensorial media advances and applications, P1, DOI DOI 10.4018/978-1-60960-821-7.CH001
   García-Betances RI, 2015, AM J ALZHEIMERS DIS, V30, P49, DOI 10.1177/1533317514545866
   Gibson C, 2009, PROG HUM GEOG, V33, P527, DOI 10.1177/0309132508099797
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   Haans A, 2012, INTERACT COMPUT, V24, P211, DOI 10.1016/j.intcom.2012.04.010
   Han Jong-Sung, 2015, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V15, P40, DOI 10.5392/JKCA.2015.15.03.040
   Hayoung Byun, 2019, [Korean Journal of Otorhinolaryngology-Head and Neck Surgery, 대한이비인후-두경부외과학회지], V62, P545
   Huygelier H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41200-6
   Jacobsen J. K. S., 2001, Scandinavian Journal of Hospitality and Tourism, V1, P99, DOI 10.1080/150222501317244029
   Jaeger B.K., 2001, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V45, P1896, DOI DOI 10.1177/154193120104502709
   Jeng MY, 2017, APPL RES QUAL LIFE, V12, P49, DOI 10.1007/s11482-016-9452-0
   Jung Timothy., 2016, INFORM COMMUNICATION, P621, DOI [DOI 10.1007/978-3-319-28231-2_45, 10.1007/978-3-319-28231-245, DOI 10.1007/978-3-319-28231-245]
   Jung TH, 2018, INT J CONTEMP HOSP M, V30, P1621, DOI [10.1108/ijchm-02-2017-0084, 10.1108/IJCHM-02-2017-0084]
   Kang M, 2012, TOURISM MANAGE, V33, P440, DOI 10.1016/j.tourman.2011.05.005
   Kask S, 2018, THESIS
   Kazeminia A, 2015, J TRAVEL RES, V54, P80, DOI 10.1177/0047287513506290
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim A, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0225-2
   Kim Cheong-Seok, 2003, [Journal of the Korea Gerontological Society, 한국노년학], V23, P43
   Larsson P, 2001, CYBERPSYCHOL BEHAV, V4, P239, DOI 10.1089/109493101300117929
   Lee Hang ah, 2019, [Journal of Tourism and Leisure Research, 관광레저연구], V31, P53
   Lee JK, 2016, TRY LIVING JEJU ISLA
   Lee KM, 2004, PRESENCE-TELEOP VIRT, V13, P494, DOI 10.1162/1054746041944830
   Lin CX, 2018, LECT NOTES COMPUT SC, V10927, P89, DOI 10.1007/978-3-319-92037-5_8
   Lin CS, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15040663
   Liu CL, 2007, LECT NOTES COMPUT SC, V4555, P666
   Liu CL, 2011, LECT NOTES COMPUT SC, V6764, P490, DOI 10.1007/978-3-642-21619-0_61
   Liu L, 1999, Cyberpsychol Behav, V2, P567, DOI 10.1089/cpb.1999.2.567
   Marasco A, 2018, J DESTIN MARK MANAGE, V9, P138, DOI 10.1016/j.jdmm.2017.12.002
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Miller KJ, 2014, AGE AGEING, V43, P188, DOI 10.1093/ageing/aft194
   Mollen A, 2010, J BUS RES, V63, P919, DOI 10.1016/j.jbusres.2009.05.014
   Moorhouse N, 2018, PROGR IS, P133, DOI 10.1007/978-3-319-64027-3_10
   Nayyar A., 2018, International Journal of Engineering and Technology, V7, P156, DOI [10.14419/ijet.v7i2.21.11858, DOI 10.14419/IJET.V7I2.21.11858]
   Nielsen J., 2012, Thinking aloud: the #1 usability tool
   Noh Ghee Young, 2014, [Journal of Cybercommunication Academic Society, 사이버커뮤니케이션학보], V31, P45
   Oh H. M., 2007, Journal of Travel Research, V46, P119, DOI 10.1177/0047287507304039
   Olson KE, 2011, AGEING INT, V36, P123, DOI 10.1007/s12126-010-9077-9
   Optale G, 2010, NEUROREHAB NEURAL RE, V24, P348, DOI 10.1177/1545968309353328
   Ouwehand C, 2007, CLIN PSYCHOL REV, V27, P873, DOI 10.1016/j.cpr.2006.11.003
   이수경, 2019, [Journal of Cybercommunication Academic Society, 사이버커뮤니케이션학보], V36, P89
   Pearce PL, 2005, ASPEC TOUR, V27, pVII
   Petri K, 2020, Am J Biomed Sci, V12
   Pine BJ, 1998, HARVARD BUS REV, V76, P97
   Rahimizhian S, 2020, TECHNOL SOC, V63, DOI 10.1016/j.techsoc.2020.101411
   Rand D, 2005, PRESENCE-TELEOP VIRT, V14, P147, DOI 10.1162/1054746053967012
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Song HJ., 2011, KOREAN J TOURISM RES, V25, P179
   Sorensen F, 2015, TOURISM MANAGE, V46, P336, DOI 10.1016/j.tourman.2014.07.009
   Srifar D, 2018, ARXIV
   Sternberg E, 1997, ANN TOURISM RES, V24, P951, DOI 10.1016/S0160-7383(97)00053-4
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sussmann S., 2000, Proceedings of the 8th European Conference on Information Systems, P1077
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   Tiiro A., 2018, EFFECT VISUAL REALIS
   Tromp P, 2017, VIRTUAL REALITY WILL
   Tussyadiah IP, 2018, TOURISM MANAGE, V66, P140, DOI 10.1016/j.tourman.2017.12.003
   United Nations Department of Economic and Social Affairs Population Division, 2020, World Mortality 2019
   WILLIAMS P, 1995, TOURISM MANAGE, V16, P423, DOI 10.1016/0261-5177(95)00050-X
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu HC, 2018, J HOSP TOUR RES, V42, P26, DOI [10.1177/1096348014563396, 10.14177/j.cnki.32-1397n.2018.42.01.004]
   Xiaojun Lai, 2019, Cross-Cultural Design. Culture and Society. 11th International Conference, CCD 2019 Held as Part of the 21st HCI International Conference, HCII 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11577), P159, DOI 10.1007/978-3-030-22580-3_13
   Youth, 2019, MINISTRY EMPLOYMENT
   Yuan YH, 2008, J HOSP TOUR RES, V32, P387, DOI 10.1177/1096348008317392
   최덕윤, 2019, [International Journal of Tourism Management and Sciences, 관광연구], V34, P185
NR 89
TC 0
Z9 0
U1 16
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 2967
EP 2987
DI 10.1007/s10055-023-00849-1
EA SEP 2023
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001065767500003
DA 2024-07-18
ER

PT J
AU Jurado-Rodriguez, D
   Muñoz-Salinas, R
   Garrido-Jurado, S
   Romero-Ramirez, FJ
   Medina-Carnicer, R
AF Jurado-Rodriguez, David
   Munoz-Salinas, Rafael
   Garrido-Jurado, Sergio
   Romero-Ramirez, Francisco J.
   Medina-Carnicer, Rafael
TI 3D model-based tracking combining edges, keypoints and fiducial markers
SO VIRTUAL REALITY
LA English
DT Article
DE 3D model-based tracking; Keypoints; Fiducial markers
ID OBJECT RECOGNITION; AUGMENTED REALITY; TEXTURE; FRAMEWORK; IMAGE
AB Model-based tracking is an essential task in fields such as Augmented Reality. State-of-the-art approaches rely on the model's edges, sometimes combined with image keypoints and color. Nevertheless, these image features are not considered part of the model but as temporary information discarded every time the tracking process is restarted. This paper proposes a novel approach that employs an enhanced model that combines edges, keypoints, and fiducial markers for robust and real-time tracking. The experiments conducted show that our method outperforms state-of-the-art model-based approaches and suggest that fiducial markers are a good choice for texturing models.
C1 [Jurado-Rodriguez, David; Munoz-Salinas, Rafael; Romero-Ramirez, Francisco J.; Medina-Carnicer, Rafael] Univ Cordoba, Dept Informat & Anal Numer, Edificio Einstein Campus Rabanales, Cordoba 14071, Spain.
   [Jurado-Rodriguez, David; Garrido-Jurado, Sergio] Seabery R&D, Doctor Emilio Haya Prats 13, Huelva 21005, Spain.
   [Munoz-Salinas, Rafael; Medina-Carnicer, Rafael] Inst Maimonides Invest Biomed IMIBIC, Ave Menendez Pidal S-N, Cordoba 14004, Spain.
C3 Universidad de Cordoba
RP Muñoz-Salinas, R (corresponding author), Univ Cordoba, Dept Informat & Anal Numer, Edificio Einstein Campus Rabanales, Cordoba 14071, Spain.; Muñoz-Salinas, R (corresponding author), Inst Maimonides Invest Biomed IMIBIC, Ave Menendez Pidal S-N, Cordoba 14004, Spain.
EM jrdavidrj@gmail.com; in1musar@uco.es; sgj@seaberyat.com;
   fj.romero@uco.es; rmedina@uco.es
RI Romero-Ramirez, Francisco J./JVE-2018-2024; Jurado Rodríguez,
   David/JXM-5045-2024; Medina-Carnicer, Rafael RM/G-3401-2015;
   Munoz-Salinas, Rafael/K-5999-2014
OI Romero-Ramirez, Francisco J./0000-0002-9572-0128; Jurado Rodríguez,
   David/0000-0003-2408-4926; Munoz-Salinas, Rafael/0000-0002-8773-8571
FU Cordoba University; Spanish Ministry of Economy, Industry and
   Competitiveness [PID2019-103871GB-I00]; FEDER;  [1380047-F
   UCOFEDER-2021]
FX This research was funded by the Industrial PhD Program of Cordoba
   University with Seabery R &D and Project PID2019-103871GB-I00 of the
   Spanish Ministry of Economy, Industry and Competitiveness, and FEDER and
   Project 1380047-F UCOFEDER-2021 of Andalusia.
CR Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   BOUTHEMY P, 1989, IEEE T PATTERN ANAL, V11, P499, DOI 10.1109/34.24782
   Cavallaro R, 1997, IEEE COMPUT GRAPH, V17, P6, DOI 10.1109/38.574652
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Choi C, 2012, INT J ROBOT RES, V31, P498, DOI 10.1177/0278364912437213
   Choi C, 2010, IEEE INT CONF ROBOT, P4048, DOI 10.1109/ROBOT.2010.5509171
   Collet A, 2009, IEEE INT CONF ROBOT, P3534
   Comport AI, 2006, IEEE T VIS COMPUT GR, V12, P615, DOI 10.1109/TVCG.2006.78
   Drummond T, 1999, BMVC, P1
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Foxlin E, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P212, DOI 10.1109/ISMAR.2004.32
   Gao X, 2018, DIRECT SPARSE ODOMET
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Gordon I, 2006, LECT NOTES COMPUT SC, V4170, P67
   Han P., 2019, Virtual Real. Intell. Hardw, V1, P580, DOI DOI 10.1016/J.VRIH.2019.10.001
   Harris C., 1990, BMVC90 Proceedings of the British Machine Vision Conference, P73
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Muñoz FII, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P24, DOI 10.1109/IROS.2016.7758090
   Issac J, 2016, IEEE INT CONF ROBOT, P608, DOI 10.1109/ICRA.2016.7487184
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Kyrki V, 2005, IEEE INT CONF ROBOT, P1554
   Marchand É, 2005, IEEE ROBOT AUTOM MAG, V12, P40, DOI 10.1109/MRA.2005.1577023
   Muñoz-Salinas R, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2019.107193
   Muñoz-Salinas R, 2019, PATTERN RECOGN, V86, P156, DOI 10.1016/j.patcog.2018.09.003
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Nee AYC, 2012, CIRP ANN-MANUF TECHN, V61, P657, DOI 10.1016/j.cirp.2012.05.010
   Olson E, 2011, IEEE INT CONF ROBOT
   PATERSON MS, 1990, DISCRETE COMPUT GEOM, V5, P485, DOI 10.1007/BF02187806
   Petit A, 2014, IEEE INT CONF ROBOT, P4115, DOI 10.1109/ICRA.2014.6907457
   Pfrommer B, 2019, ARXIV
   Pressigout M, 2006, IEEE INT CONF ROBOT, P2726, DOI 10.1109/ROBOT.2006.1642113
   Pressigout M, 2007, INT J ROBOT RES, V26, P689, DOI 10.1177/0278364907080477
   Ren Carl Yuheng, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P47, DOI 10.1109/3DV.2014.39
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rey D., 2011, Wilcoxon-Signed-Rank Test, P1658, DOI [DOI 10.1007/978-3-642-04898-2616, 10.1007/978-3-642-04898-2616]
   Romero-Ramirez FJ, 2018, IMAGE VISION COMPUT, V76, P38, DOI 10.1016/j.imavis.2018.05.004
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sun Y, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P825, DOI 10.1109/ICIP.2002.1039099
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Trinh S, 2018, IEEE INT C INT ROBOT, P89, DOI 10.1109/IROS.2018.8594003
   Vacchetti L, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P48, DOI 10.1109/ISMAR.2004.24
   Ye E, 2019, IEEE INT C INTELL TR, P1128, DOI 10.1109/ITSC.2019.8917226
   Yovcheva Z., 2012, e-Review of Tourism Research, V10, P63
NR 46
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3051
EP 3065
DI 10.1007/s10055-023-00853-5
EA SEP 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001060683600001
DA 2024-07-18
ER

PT J
AU Stefan, H
   Mortimer, M
   Horan, B
AF Stefan, Hans
   Mortimer, Michael
   Horan, Ben
TI Evaluating the effectiveness of virtual reality for safety-relevant
   training: a systematic review
SO VIRTUAL REALITY
LA English
DT Review
DE Virtual reality; Evaluation methodologies; Safety training; Training
   evaluation; Training delivery method; Training effectiveness
ID CONSTRUCTION SECTOR; LEARNING OUTCOMES; HIGHER-EDUCATION; SERIOUS GAMES;
   SIMULATION; RISK; MAINTENANCE; OPERATION; ENVIRONMENTS; PERFORMANCE
AB The commercial release of affordable, low-cost, and consumer-ready virtual reality (VR) devices has increased the accessibility for researchers to investigate the benefits of VR technology including those aimed at education and training. VR technology provides several opportunities that may provide benefits over traditional training methods, this is particularly relevant for safety training due to its ability to safely simulate dangerous scenarios that would otherwise be difficult to access. When implementing a new technology, it is important to evaluate and validate its effectiveness. This paper presents a systematic review of VR safety-relevant training studies that perform an evaluation of their effectiveness. This comprehensive review includes 136 studies published between 2016 and August 2021. Results presented in this paper include application domains, study objectives, study designs, and evaluation measures. Results show that the majority of studies were applicable to health services with the majority focusing on effectiveness evaluation using true- or quasi-experimental design. This study then categorizes each reported evaluation measure into one of the four levels in Kirkpatrick's model for training evaluation, results showed that the majority of studies evaluated learning (72.06%) and reaction (66.18%) levels with very few studies evaluating behavior and results levels. This study concludes by providing insights and recommendations to help future researchers make informed decisions when designing an effectiveness evaluation study for VR safety-relevant training applications.
C1 [Stefan, Hans; Mortimer, Michael; Horan, Ben] Deakin Univ, 75 Pigdons Rd, Waurn Ponds, Vic 3216, Australia.
C3 Deakin University
RP Stefan, H (corresponding author), Deakin Univ, 75 Pigdons Rd, Waurn Ponds, Vic 3216, Australia.
EM h.stefan@deakin.edu.au; m.mortimer@deakin.edu.au;
   ben.horan@deakin.edu.au
OI Stefan, Hans/0000-0002-7073-8479
FU CAUL
FX & nbsp;Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Abich J IV, 2021, VIRTUAL REAL-LONDON, V25, P919, DOI 10.1007/s10055-020-00498-8
   Adami P, 2021, ADV ENG INFORM, V50, DOI 10.1016/j.aei.2021.101431
   Agrawal Ravi, 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P1995, DOI 10.1177/1541931213601994
   Ahn S, 2020, ADV CIV ENG, V2020, DOI 10.1155/2020/2473138
   Aïm F, 2016, ARTHROSCOPY, V32, P224, DOI 10.1016/j.arthro.2015.07.023
   Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   ALLIGER GM, 1989, PERS PSYCHOL, V42, P331, DOI 10.1111/j.1744-6570.1989.tb00661.x
   Alvarez K., 2004, HUM RESOUR DEV REV, V3, P385, DOI DOI 10.1177/1534484304270820
   Asghar I, 2019, PROCEEDINGS OF 9TH INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND MANAGEMENT (ICICM 2019), P57, DOI 10.1145/3357419.3357443
   Avveduto G, 2017, LECT NOTES COMPUT SC, V10324, P148, DOI 10.1007/978-3-319-60922-5_11
   García AA, 2016, VIRTUAL REAL-LONDON, V20, P27, DOI 10.1007/s10055-015-0280-6
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191
   Barré J, 2019, OBES SURG, V29, P1309, DOI 10.1007/s11695-018-03680-9
   Bates R, 2004, EVAL PROGRAM PLANN, V27, P341, DOI 10.1016/j.evalprogplan.2004.04.011
   Beh HJ, 2022, ENG CONSTR ARCHIT MA, V29, P2854, DOI 10.1108/ECAM-02-2021-0174
   Benda NC, 2020, JMIR SERIOUS GAMES, V8, P101, DOI 10.2196/21123
   Benvegnu G, 2021, EUROPEAN C COGNITIVE, P1, DOI [10.1145/3452853.3452881, DOI 10.1145/3452853.3452881]
   Bhagwat K, 2021, J CIV ENG EDUC, V147, DOI 10.1061/(ASCE)EI.2643-9115.0000034
   Bing EG, 2019, J GLOB ONCOL, V5, DOI 10.1200/JGO.18.00263
   Blake M.W., 1996, 1996 Flight Simulation Technologies Conference, P385, DOI DOI 10.2514/6.1996-3518
   Borsci S, 2016, VIRTUAL REAL-LONDON, V20, P41, DOI 10.1007/s10055-015-0281-5
   BRADLEY DR, 1995, BEHAV RES METH INS C, V27, P152, DOI 10.3758/BF03204721
   Bramer WM, 2016, J MED LIBR ASSOC, V104, P240, DOI 10.3163/1536-5050.104.3.014
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Brown C, 2019, J LAPAROENDOSC ADV S, V29, P1128, DOI 10.1089/lap.2019.0332
   Bunæs TH, 2019, PROC EUR CONF GAME, P119, DOI 10.34190/GBL.19.095
   Bureau of Labor Statistics, 2016, NAT CENS FAT OCC INJ
   Bureau of Labor Statistics, 2021, National census of fatal occupational injuries in 2020: Technical report
   Burigat S, 2016, INT J HUM-COMPUT ST, V87, P92, DOI 10.1016/j.ijhcs.2015.11.004
   Burke MJ, 2011, J APPL PSYCHOL, V96, P46, DOI 10.1037/a0021838
   Burke MJ, 2006, AM J PUBLIC HEALTH, V96, P315, DOI 10.2105/AJPH.2004.059840
   Butt AL, 2018, CLIN SIMUL NURS, V16, P25, DOI 10.1016/j.ecns.2017.09.010
   Buttussi F, 2021, IEEE T LEARN TECHNOL, V14, pC, DOI 10.1109/TLT.2020.3033766
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Caporusso N., 2019, Advances in Human Factors in Wearable Technologies and Game Design: Proceedings of the AHFE 2018 International Conferences on Human Factors and Wearable Technologies, and Human Factors in Game Design and Virtual Environments, Held on July 21-25, 2018, P88, DOI [10.1007/978-3-319-94619-1_9, DOI 10.1007/978-3-319-94619-1_9]
   Casso G, 2019, ANESTH ANALG, V129, P1258, DOI 10.1213/ANE.0000000000003316
   Cavalcanti J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144663
   Cecil J, 2021, ANN IEEE SYST CONF, DOI 10.1109/SysCon48628.2021.9447090
   Chae CJ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135919
   Chan HY, 2021, J CLIN NURS, V30, P1874, DOI 10.1111/jocn.15701
   Chang CY, 2022, INTERACT LEARN ENVIR, V30, P400, DOI 10.1080/10494820.2019.1661854
   Chapman LJ, 2008, J SAFETY RES, V39, P171, DOI 10.1016/j.jsr.2008.02.008
   Chen HS, 2021, AUTOMAT CONSTR, V125, DOI 10.1016/j.autcon.2021.103631
   Chen QY, 2020, PR IEEE INT CONF TEA, P873, DOI 10.1109/TALE48869.2020.9368468
   Chittaro L, 2018, SAFETY SCI, V102, P159, DOI 10.1016/j.ssci.2017.10.012
   Clifford RMS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P181, DOI [10.1109/VR.2019.8797889, 10.1109/vr.2019.8797889]
   Colombo S, 2016, SAFETY SCI, V84, P46, DOI 10.1016/j.ssci.2015.11.021
   Comu S, 2021, ADV ENG INFORM, V49, DOI 10.1016/j.aei.2021.101353
   Cooper N, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248225
   Cyma-Wejchenig M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133731
   Czarnek G, 2020, INT J HUM-COMPUT INT, V36, P464, DOI 10.1080/10447318.2019.1655905
   Detmer Felicitas J, 2017, IEEE Rev Biomed Eng, V10, P78, DOI 10.1109/RBME.2017.2749527
   Dhalmahapatra K, 2021, SAFETY SCI, V139, DOI 10.1016/j.ssci.2021.105241
   Di Vece C, 2021, INT J COMPUT ASS RAD, V16, P639, DOI 10.1007/s11548-021-02341-0
   Din ZU, 2019, SAFETY SCI, V115, P176, DOI 10.1016/j.ssci.2019.02.005
   Dorozhkin D, 2017, SURG ENDOSC, V31, P3527, DOI 10.1007/s00464-016-5379-7
   Druzhinina M. V., 2019, IOP Conference Series: Materials Science and Engineering, V483, DOI 10.1088/1757-899X/483/1/012078
   Durlach N., 1995, Virtual Reality: Scientific and Technological Challenges, DOI 10.17226/4761
   Dzeng RJ, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P2453, DOI 10.1109/FSKD.2015.7382339
   Edwards TC, 2021, ARCH ORTHOP TRAUM SU, V141, P2313, DOI 10.1007/s00402-021-04050-4
   Eiris R, 2020, SAFETY SCI, V127, DOI 10.1016/j.ssci.2020.104703
   Erel E, 2003, MICROSURG, V23, P147, DOI 10.1002/micr.10106
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Francone A, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.4.2
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Frendo M, 2021, COCHLEAR IMPLANTS IN, V22, P330, DOI 10.1080/14670100.2021.1940629
   Fu SX, 2017, INDIAN J SURG, V79, P288, DOI 10.1007/s12262-016-1468-z
   Fu Y, 2020, DMSVIV 2020 P 26 INT, P34, DOI [10.18293/DMSVIVA20-020, DOI 10.18293/DMSVIVA20-020]
   Ganier F, 2014, ERGONOMICS, V57, P828, DOI 10.1080/00140139.2014.899628
   Gao YF, 2019, COMPUT EDUC, V138, P101, DOI 10.1016/j.compedu.2019.05.003
   Gawecki W, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103197
   Gibson ME, 2020, EXP BRAIN RES, V238, P1861, DOI 10.1007/s00221-020-05841-8
   Gupta A., 2020, P INT S AUT ROB CONS, P892
   Gurusamy K, 2008, BRIT J SURG, V95, P1088, DOI 10.1002/bjs.6344
   Gurusamy KS, 2009, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006575.pub2
   Pham HC, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10072262
   Hauschild J, 2021, ORTHOP J SPORTS MED, V9, DOI 10.1177/23259671211003873
   Havemann MC, 2019, J ROBOT SURG, V13, P99, DOI 10.1007/s11701-018-0811-8
   Herrington A, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7030026
   Hill R., 2003, Kunstliche Intelligenz (KI Journal), V17, P5, DOI DOI 10.1002/J.2162-6057.20041B01234.X
   Holton E.F., 1996, Human Resource Development Quarterly, V7, P5, DOI DOI 10.1002/HRDQ.3920070103
   Hoogenes J, 2018, UROLOGY, V111, P110, DOI 10.1016/j.urology.2017.09.023
   Hsien-Tang Wu, 2020, Proceedings of the IEEE 2nd International Conference on Architecture, Construction, Environment and Hydraulics (ICACEH 2020), P36, DOI 10.1109/ICACEH51803.2020.9366218
   Hsu E.B., 2013, PLoS Curr, V5, P1, DOI DOI 10.1371/CURRENTS.DIS.1EA2B2E71237D5337FA53982A38B2AFF
   Hui Z, 2017, INT J MIN SCI TECHNO, V27, P717, DOI 10.1016/j.ijmst.2017.05.005
   Truong H, 2022, SURG ENDOSC, V36, P3059, DOI 10.1007/s00464-021-08602-y
   International Labour Organization, IND SECT
   Jaskiewicz F, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000023374
   Jeelani I, 2020, ENG CONSTR ARCHIT MA, V27, P1853, DOI 10.1108/ECAM-07-2019-0391
   Jeelani I, 2017, COMPUTING IN CIVIL ENGINEERING 2017: SENSING, SIMULATION, AND VISUALIZATION, P407
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jensen UJ, 2016, EUROINTERVENTION, V11, P1503, DOI 10.4244/EIJY15M06_05
   Joda T, 2019, COMPUT BIOL MED, V108, P93, DOI 10.1016/j.compbiomed.2019.03.012
   Joshi S, 2021, APPL ERGON, V90, DOI 10.1016/j.apergo.2020.103286
   Jung Jin-Ki, 2017, [Journal of the ergonomics society of Korea, 대한인간공학회지], V36, P385, DOI 10.5143/JESK.2017.36.5.385
   Jung JK, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1812
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kessler D, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P231, DOI 10.1109/AIVR50618.2020.00048
   Kim J, 2020, CONSTRUCTION RESEARCH CONGRESS 2020: COMPUTER APPLICATIONS, P336, DOI 10.1061/9780784482865.036
   Kirkpatrick D.L., 2007, IMPLEMENTING 4 LEVEL, V1st
   Kirkpatrick D.L., 1976, TRAINING DEV HDB GUI, V2nd, P301
   Knowles M.S., 1980, MODERN PRACTICE ADUL, V2nd
   KRAIGER K, 1993, J APPL PSYCHOL, V78, P311, DOI 10.1037/0021-9010.78.2.311
   Kraiger K., 2002, CREATING IMPLEMENTIN, P331
   Kwegyir-Afful E, 2021, ADV INTELLIGENT SYST, V1206, P167, DOI [10.1007/978-3-030-51064-0_22, DOI 10.1007/978-3-030-51064-0_22]
   Kwon C, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144932
   Lacko J, 2020, PROCEEDINGS OF THE 2020 30TH INTERNATIONAL CONFERENCE CYBERNETICS & INFORMATICS (K&I '20), DOI 10.1109/ki48306.2020.9039854
   Lang YN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P297, DOI 10.1109/VR.2018.8448290
   Leder J, 2019, SAFETY SCI, V111, P271, DOI 10.1016/j.ssci.2018.07.021
   Li CY, 2017, IEEE T VIS COMPUT GR, V23, P1388, DOI 10.1109/TVCG.2017.2656958
   Li H, 2015, AUTOMAT CONSTR, V49, P163, DOI 10.1016/j.autcon.2014.10.010
   Li X, 2018, AUTOMAT CONSTR, V86, P150, DOI 10.1016/j.autcon.2017.11.003
   Liang H., 2020, INT J PERFORM ENG, V16, P107, DOI [https://doi.org/10.23940/ijpe.20.01.p12.107117, DOI 10.23940/IJPE.20.01.P12.107117]
   Liang H, 2019, 8 INT C NETW COMM CO, P168, DOI [10.1145/3375998.3376013, DOI 10.1145/3375998.3376013]
   Liang H, 2018, PROCEEDINGS OF THE 16TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2018), DOI 10.1145/3284398.3284417
   Liang ZP, 2019, IEEE ACCESS, V7, P118639, DOI 10.1109/ACCESS.2019.2934990
   Liu Xiang, 2016, Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), V9740, P416, DOI [10.1007/978-3-319-39907-2\_40, DOI 10.1007/978-3-319-39907-2]
   Logishetty K, 2019, BONE JOINT J, V101B, P1585, DOI 10.1302/0301-620X.101B12.BJJ-2019-0643.R1
   LoJacono C.T., 2018, Journal of Motor Learning and Development, V6, P234, DOI DOI 10.1123/JMLD.2017-0019
   Lovreglio R, 2021, VIRTUAL REAL-LONDON, V25, P133, DOI 10.1007/s10055-020-00447-5
   Makransky G, 2019, J COMPUT ASSIST LEAR, V35, P691, DOI 10.1111/jcal.12375
   McBain-Rigg KE, 2017, J AGROMEDICINE, V22, P347, DOI 10.1080/1059924X.2017.1353935
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Mirauda D, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12030757
   Mondragon-Bernal I.F., 2020, Ing. Univ, V24, P1, DOI [10.11144/javeriana.iued24.sime, DOI 10.11144/JAVERIANA.IUED24.SIME]
   Moore HF, 2019, COMPUTING IN CIVIL ENGINEERING 2019: VISUALIZATION, INFORMATION MODELING, AND SIMULATION, P55
   Narciso D, 2021, MULTIMED TOOLS APPL, V80, P13195, DOI 10.1007/s11042-020-10454-y
   Neis F, 2016, SURG ENDOSC, V30, P4954, DOI 10.1007/s00464-016-4837-6
   Next World Enterprises, 2022, VR TRAIN COURS
   Nilsson C, 2017, SURG ENDOSC, V31, P2131, DOI 10.1007/s00464-016-5210-5
   Nykänen M, 2020, J SAFETY RES, V75, P205, DOI 10.1016/j.jsr.2020.09.015
   Oh SM, 2020, AESTHET PLAST SURG, V44, P1833, DOI 10.1007/s00266-020-01872-2
   Orland MD, 2020, CLIN ORTHOP RELAT R, V478, P2170, DOI 10.1097/CORR.0000000000001362
   Ouyang SG, 2018, COMPUT APPL ENG EDUC, V26, P91, DOI 10.1002/cae.21863
   Page RayL., 2000, SimTecT 2000 Proceedings, P11
   Pedram S, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103891
   Pelargos PE, 2017, J CLIN NEUROSCI, V35, P1, DOI 10.1016/j.jocn.2016.09.002
   Pellas N, 2021, VIRTUAL REAL-LONDON, V25, P835, DOI 10.1007/s10055-020-00489-9
   Phillips P, 2003, THESIS U SO MISSISSI
   Piromchai P, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010198.pub2
   Pixo VR, VIRTUAL REALITY CONS
   Polivka BJ, 2019, GAMES HEALTH J, V8, P121, DOI 10.1089/g4h.2018.0068
   Prasolova-Forland E, 2017, PR IEEE INT CONF TEA, P461, DOI 10.1109/TALE.2017.8252380
   Prendinger H, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2883617
   Radhakrishnan U, 2021, BEHAV INFORM TECHNOL, V40, P1310, DOI 10.1080/0144929X.2021.1954693
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Rahouti A, 2021, FIRE TECHNOL, V57, P3041, DOI 10.1007/s10694-021-01098-x
   Reio TG, 2017, NEW HORIZ ADULT EDUC, V29, P35, DOI 10.1002/nha3.20178
   Renganayagalu SK, 2021, TECHNOL KNOWL LEARN, V26, P999, DOI 10.1007/s10758-020-09489-9
   Ricci F, 2016, J WORKPLACE LEARN, V28, P355, DOI 10.1108/JWL-11-2015-0087
   Robson LS, 2012, SCAND J WORK ENV HEA, V38, P193, DOI 10.5271/sjweh.3259
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Rossler KL, 2019, NURS EDUC, V44, P88, DOI 10.1097/NNE.0000000000000551
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Safe Work Australia, 2021, WORK REL INJ FAT KEY
   Safe Work Australia, 2016, WORK REL TRAUM INJ F
   Safe Work Australia, 2016, WORK HLTH SAF AGR IN
   Saghafian M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.593466
   Salas E, 2012, PSYCHOL SCI PUBL INT, V13, P74, DOI 10.1177/1529100612436661
   Salcedo Julie N., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P184, DOI 10.1007/978-3-319-39907-2_18
   Sankaranarayanan G, 2016, SURG ENDOSC, V30, P730, DOI 10.1007/s00464-015-4267-x
   SATAVA RM, 1995, J MED SYST, V19, P275, DOI 10.1007/BF02257178
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schulz GB, 2019, J SURG EDUC, V76, P568, DOI 10.1016/j.jsurg.2018.08.001
   Sebastian K, 2018, J COMPUT ASSIST LEAR, V34, P787, DOI 10.1111/jcal.12285
   Shannon HS, 1999, SAFETY SCI, V31, P161, DOI 10.1016/S0925-7535(98)00063-0
   Sharma S., 2020, INT S ELECT IMAG SCI, V13, P223, DOI [10.2352/ISSN.2470-1173.2020.13.ERVR-223, DOI 10.2352/ISSN.2470-1173.2020.13.ERVR-223]
   Shewaga R, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180660
   Shi YM, 2020, CONSTRUCTION RESEARCH CONGRESS 2020: INFRASTRUCTURE SYSTEMS AND SUSTAINABILITY, P79, DOI 10.1061/9780784482858.010
   Shi YM, 2019, AUTOMAT CONSTR, V104, P197, DOI 10.1016/j.autcon.2019.04.015
   Shim JS, 2018, UROLOGY, V122, P32, DOI 10.1016/j.urology.2018.08.013
   SIM ZA, 2019, P IEEE 89 VEH TECHN, P1
   Simpson TG, 2020, LECT NOTES COMPUT SC, V12242, P203, DOI 10.1007/978-3-030-58465-8_16
   Sinitsky DM, 2020, AM J SURG, V219, P613, DOI 10.1016/j.amjsurg.2019.04.020
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smith J, 2019, WMU J MARIT AFF, V18, P425, DOI 10.1007/s13437-019-00174-y
   Smith J, 2019, ASCE-ASME J RISK UNC, V5, DOI 10.1115/1.4040660
   Song H, 2021, AUTOMAT CONSTR, V122, DOI 10.1016/j.autcon.2020.103506
   Sportillo D, 2018, ACCIDENT ANAL PREV, V118, P102, DOI 10.1016/j.aap.2018.06.003
   Sugand K, 2016, INJURY, V47, P448, DOI 10.1016/j.injury.2015.09.036
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Suto H., 2020, Electronic Imaging, V2020, P380, DOI [10.2352/ISSN.2470-1173.2020.13.ERVR-380, DOI 10.2352/ISSN.2470-1173.2020.13.ERVR-380]
   Ta F, 2019, PERSONALISED LEARNIN, P292
   Tang YM, 2021, J COMPUT ASSIST LEAR, V37, P359, DOI 10.1111/jcal.12494
   Tannenbaum S, 1993, 93001 NAV TRAIN SYST
   Tawadrous M, 2017, MULTIMED TOOLS APPL, V76, P7301, DOI 10.1007/s11042-016-3394-2
   Tichon J., 2011, J HLTH SAFETY RES PR, V3, P33
   Torres-Guerrero F, 2019, LECT N MECH ENG, P319, DOI 10.1007/978-3-030-18715-6_27
   Tsuboi Hiroki, 2018, Augmented Cognition. Intelligent Technologies. 12th International Conference, AC 2018 Held as Part of HCI International 2018. Proceedings: LNAI 10915, P444, DOI 10.1007/978-3-319-91470-1_35
   U. S. General Services Administration, USABILITY EVALUATION
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vahdatikhaki F, 2019, AUTOMAT CONSTR, V106, DOI 10.1016/j.autcon.2019.102853
   Vaughan N, 2016, MED ENG PHYS, V38, P59, DOI 10.1016/j.medengphy.2015.11.021
   Wang KC, 2021, J AM ACAD ORTHOP SUR, V29, P255, DOI 10.5435/JAAOS-D-19-00225
   Wang Y, 2018, MED BIOL ENG COMPUT, V56, P25, DOI 10.1007/s11517-017-1666-2
   Waterman BR, 2016, ORTHOPEDICS, V39, pE479, DOI 10.3928/01477447-20160427-02
   Weber Anika, 2020, Digital Human Modeling and Applications in Health, Safety, Ergonomics and Risk Management. Posture, Motion and Health. 11th International Conference, DHM 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12198), P276, DOI 10.1007/978-3-030-49904-4_20
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Worksafe Victoria, 2022, IND
   Wu SH, 2020, J EDUC EVAL HEALTH P, V17, DOI 10.3352/jeehp.2020.17.1
   Xiao X, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P557, DOI [10.1109/vr46266.2020.1581028031480, 10.1109/VR46266.2020.00-27, 10.1109/VR46266.2020.1581028031480]
   Xin BQ, 2020, INT ORTHOP, V44, P927, DOI 10.1007/s00264-020-04488-y
   Xin BQ, 2019, WORLD NEUROSURG, V124, pE324, DOI 10.1016/j.wneu.2018.12.090
   Xu JX, 2019, INTERACT COMPUT, V31, P577, DOI 10.1093/iwc/iwz037
   Xu S., 2019, 36 INT S AUTOMATION, DOI DOI 10.22260/ISARC2019/0003
   Xu Z, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13010243
   Yang C, 2018, SURG ENDOSC, V32, P4132, DOI 10.1007/s00464-018-6156-6
   Yau YW, 2021, ANN ACAD MED SINGAP, V50, DOI 10.47102/annals-acadmedsg.2020431
   Yiannakopoulou E, 2015, INT J SURG, V13, P60, DOI 10.1016/j.ijsu.2014.11.014
   Yu M, 2021, ASIAN NURS RES, V15, P189, DOI 10.1016/j.anr.2021.03.002
   Zhang K, 2017, FED CONF COMPUT SCI, P1297, DOI 10.15439/2017F376
   Zhao D, 2016, J CIV ENG MANAG, V22, P800, DOI 10.3846/13923730.2014.914099
NR 213
TC 6
Z9 6
U1 23
U2 44
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 2839
EP 2869
DI 10.1007/s10055-023-00843-7
EA AUG 2023
PG 31
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001050725300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Bruni, F
   Mancuso, V
   Greci, L
   Arlati, S
   Cavallo, M
   Riva, G
   Goulene, K
   Stramba-Badiale, M
   Pedroli, E
AF Bruni, Francesca
   Mancuso, Valentina
   Greci, Luca
   Arlati, Sara
   Cavallo, Marco
   Riva, Giuseppe
   Goulene, Karine
   Stramba-Badiale, Marco
   Pedroli, Elisa
TI A cross-platform application for the ecological and remote assessment of
   memory impairment in aging: ECO-MEMORY
SO VIRTUAL REALITY
LA English
DT Article
DE Assessment; Virtual reality; 360 & DEG; video; Memory; Aging
ID MENTAL-STATE-EXAMINATION; NEUROPSYCHOLOGICAL ASSESSMENT;
   ALZHEIMERS-DISEASE; VIRTUAL-REALITY; OLDER-ADULTS; FRAILTY; INSTITUTE;
   CARE
AB This work aims to present the first step of a creation of an instrument to assess memory deficits responding to the needs imposed by the inability to access clinical care, such as physical or geographical constraints or still limitations imposed during the pandemic era. The older population, who would benefit from these services, may be at risk as access to services that support psychological and neuropsychological needs, which are not considered essential, has frequently been restricted in recent years. Moreover, because deficits are commonly mistaken for the effects of physiological aging, the early signs of cognitive decline might be ignored. On these bases, we used the potential of 360-degree media to create an application for memory assessment without the physical presence of clinicians: ECO-MEMORY. Firstly, we developed the application and evaluated its usability. ECO-MEMORY is divided into four sections, each addressing a different memory task: recognizing objects and faces, learning a path, and creating an allocentric map. Thirteen older adults who used the tablet application provided usability data as well as qualitative feedback on their experience. After the performance, the System Usability Scale, the Senior Technology Acceptance Model, and the Independent Television Commission Sense of Presence were administered. We performed a qualitative analysis and descriptive statistics, which showed that ECO-MEMORY is a usable instrument. Also, it was enjoyable for users who generally accepted technology in their life. ECO-MEMORY may therefore offer a promising approach to memory evaluation by including real-world scenarios.
C1 [Bruni, Francesca; Mancuso, Valentina; Cavallo, Marco; Pedroli, Elisa] eCampus Univ, Fac Psychol, Via Isimbardi 10, I-22060 Novedrate, CO, Italy.
   [Greci, Luca] CNR, Inst Intelligent Ind Technol & Syst Adv Mfg, Milan, Italy.
   [Arlati, Sara] CNR, Inst Intelligent Ind Technol & Syst Adv Mfg, Lecce, Italy.
   [Riva, Giuseppe] IRCCS Ist Auxol Italiano, Appl Technol Neuropsychol Lab, Milan, Italy.
   [Riva, Giuseppe] Univ Cattolica Sacro Cuore, Human Technol Lab, Milan, Italy.
   [Goulene, Karine; Stramba-Badiale, Marco; Pedroli, Elisa] IRCCS Ist Auxol Italiano, Dept Geriatr & Cardiovasc Med, Milan, Italy.
C3 Universita Ecampus; Consiglio Nazionale delle Ricerche (CNR); Consiglio
   Nazionale delle Ricerche (CNR); IRCCS Istituto Auxologico Italiano;
   Catholic University of the Sacred Heart; IRCCS Istituto Auxologico
   Italiano
RP Bruni, F (corresponding author), eCampus Univ, Fac Psychol, Via Isimbardi 10, I-22060 Novedrate, CO, Italy.
EM francesca.bruni3@studenti.uniecampus.it
RI Pedroli, Elisa/AAC-5927-2022; Arlati, Sara/P-8502-2018; Mancuso,
   Valentina/AAZ-5090-2020; Bruni, Francesca/JVZ-5772-2024; Pedroli,
   Elisa/K-5751-2016
OI Mancuso, Valentina/0000-0002-4198-3723; Pedroli,
   Elisa/0000-0003-4012-262X; Cavallo, Marco/0000-0002-4784-0803; Bruni,
   Francesca/0000-0001-9911-0573
FU Italian Ministry of Health [39C801_2018, FISR2020IP_04509]
FX This work was supported by the research project A cross -platform
   application for the ecological and remote assessment of memory
   impairment in elderly: ECO-MEMORY' (FISR2020IP_04509) and partially
   supported by the Italian Ministry of Health (POSTECH: 39C801_2018).
CR Albert MS, 2011, ALZHEIMERS DEMENT, V7, P270, DOI 10.1016/j.jalz.2011.03.008
   Arango C, 2020, LANCET PSYCHIAT, V7, P1013, DOI 10.1016/S2215-0366(20)30480-6
   Argent R, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/mhealth.8518
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Beschin N, 2013, RBMT 3 RIVERMEAD BEH
   Bilder RM, 2019, CLIN NEUROPSYCHOL, V33, P220, DOI 10.1080/13854046.2018.1521993
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Borghesi F., 2022, Handbook of research on implementing digital reality and interactive technologies to achieve society 5.0, P549, DOI [10.4018/978-1-6684-4854-0.ch023, DOI 10.4018/978-1-6684-4854-0.CH023]
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Bruni F, 2022, FRONT AGING NEUROSCI, V14, DOI 10.3389/fnagi.2022.875748
   Bruni F, 2022, FRONT AGING NEUROSCI, V14, DOI 10.3389/fnagi.2022.909029
   Casaletto KB, 2017, J INT NEUROPSYCH SOC, V23, P778, DOI 10.1017/S1355617717001060
   Cavedoni S, 2022, VIRTUAL REAL-LONDON, V26, P1663, DOI 10.1007/s10055-022-00648-0
   Chan RJ, 2021, ANN ONCOL, V32, P1552, DOI 10.1016/j.annonc.2021.09.001
   Chaytor N, 2003, NEUROPSYCHOL REV, V13, P181, DOI 10.1023/B:NERV.0000009483.91468.fb
   Chen K, 2020, INNOV AGING, V4, DOI 10.1093/geroni/igaa016
   Cipresso P, 2016, BMC MED INFORM DECIS, V16, DOI 10.1186/s12911-016-0276-5
   Cipresso P, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00405
   Clegg A, 2013, LANCET, V381, P752, DOI 10.1016/S0140-6736(12)62167-9
   Colón-Emeric CS, 2013, AM FAM PHYSICIAN, V88, P388
   Dartigues JF, 2014, J NUTR HEALTH AGING, V18, P95, DOI 10.1007/s12603-013-0437-5
   de Vries NM, 2011, AGEING RES REV, V10, P104, DOI 10.1016/j.arr.2010.09.001
   Delrieu J, 2016, J Prev Alzheimers Dis, V3, P151
   Fried LP, 2001, J GERONTOL A-BIOL, V56, pM146, DOI 10.1093/gerona/56.3.M146
   Guillén-Climent S, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00837-z
   Kinsella K., 2005, Population Bulletin, V60, P1
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Lewis C., 1982, USING THINKING ALOUD
   Lukas H, 2020, ACS NANO, V14, P16180, DOI 10.1021/acsnano.0c08494
   Magni E, 1996, EUR J NEUROL, V3, P198, DOI 10.1111/j.1468-1331.1996.tb00423.x
   Mancuso V, 2023, COMPUT HUM BEHAV, V146, DOI 10.1016/j.chb.2023.107812
   Mancuso V, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.566731
   McEwen BS, 2016, ANN NY ACAD SCI, V1373, P56, DOI 10.1111/nyas.13020
   MEASSO G, 1993, DEV NEUROPSYCHOL, V9, P77, DOI 10.1080/87565649109540545
   Mitnitski A B, 2001, ScientificWorldJournal, V1, P323
   Miyamura K, 2019, REV LAT-AM ENFERM, V27, DOI 10.1590/1518-8345.3189.3202
   Mondini S, 2016, SEMEIOTICA DIAGNOSI
   Negut A, 2016, CLIN NEUROPSYCHOL, V30, P165, DOI 10.1080/13854046.2016.1144793
   Pedroli E, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.898633
   Pieri L, 2022, VIRTUAL REAL-LONDON, V26, P639, DOI 10.1007/s10055-021-00526-1
   Pinals DA, 2020, PSYCHIAT SERV, V71, P1070, DOI 10.1176/appi.ps.202000264
   Realdon O, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42201-1
   Riva G., 2014, Dans Interacting with Presence, P9, DOI DOI 10.2478/9783110409697
   Riva G, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.563319
   Riva G, 2020, EXPERT REV MED DEVIC, V17, P1035, DOI 10.1080/17434440.2020.1825939
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Salthouse TA, 2010, J INT NEUROPSYCH SOC, V16, P754, DOI 10.1017/S1355617710000706
   Sbordone R.J., 1996, ECOLOGICAL VALIDITY, P15
   Serino S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01878
   Serino S, 2014, AGEING RES REV, V16, P32, DOI 10.1016/j.arr.2014.04.004
   Silverberg Nina B, 2011, Alzheimers Dement, V7, pe60
   Starace F, 2020, EPIDEMIOL PSYCH SCI, V29, DOI 10.1017/S2045796020000372
   Tuena C, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00093
   VIRZI RA, 1992, HUM FACTORS, V34, P457, DOI 10.1177/001872089203400407
   Walston J, 2006, J AM GERIATR SOC, V54, P991, DOI 10.1111/j.1532-5415.2006.00745.x
NR 55
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2757
EP 2767
DI 10.1007/s10055-023-00826-8
EA AUG 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001043038600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Tesarová, A
   Herout, A
   Bambusek, D
   Jurík, V
AF Tesarova, Alena
   Herout, Adam
   Bambusek, Daniel
   Jurik, Vojtech
TI How to shoot yourself right with a smartphone?
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Self-capture; Sports training app; Virtual avatar;
   Visual aid
AB This article presents a new use case of using handheld augmented reality to set up a smartphone camera for taking a self-photograph needed for evaluating the user's sports exercise. The problem addressed is that of settings up the rear smartphone camera so that users can take photographs of themselves performing sports poses without the need for assistance from another person. The proposed solution uses an augmented reality avatar with the same body properties as the user, which is placed into the scene so that the user can set up the camera to best capture the avatar. We also propose a straightforward mode of interaction for placing the avatar into the scene and setting up the camera for the desired purpose. We conducted a user study to explore the usability and user experience of the proposed solution. The results showed that the augmented reality visual aids, especially the avatar, enhanced the effectiveness of taking the self-photograph and that users perceived augmented reality elements favorably.
C1 [Tesarova, Alena; Herout, Adam; Bambusek, Daniel] Brno Univ Technol, Fac Informat Technol, Bozetechova 2, Brno 61200, Czech Republic.
   [Jurik, Vojtech] Masaryk Univ, Fac Arts, Dept Psychol, Arne Novaka 1-1, Brno 60200, Czech Republic.
C3 Brno University of Technology; Masaryk University Brno
RP Tesarová, A (corresponding author), Brno Univ Technol, Fac Informat Technol, Bozetechova 2, Brno 61200, Czech Republic.
EM atesarova@fit.vut.cz; herout@fit.vut.cz; bambusekd@fit.vut.cz;
   jurik.vojtech@mail.muni.cz
RI Juřík, Vojtěch/KVY-1548-2024; Juřík, Vojtěch/KVY-1534-2024; Juřík,
   Vojtěch/AAW-4983-2020
OI Juřík, Vojtěch/0000-0001-8779-1666; Juřík, Vojtěch/0000-0001-8779-1666;
   Juřík, Vojtěch/0000-0001-8779-1666; Tesarova, Alena/0000-0002-9071-7253
FU National Technical Library in Prague
FX Open access publishing supported by the National Technical Library in
   Prague
CR Alturki R, 2019, EAI SPRINGER INNOVAT, P67, DOI 10.1007/978-3-319-96139-2_7
   [Anonymous], 2013, Behaviormetrika, DOI [DOI 10.2333/BHMK.40.129, 10.2333/bhmk.40.129]
   Bewick Viv, 2004, Crit Care, V8, P196, DOI 10.1186/cc2857
   Ceci L, 2022, NUMBER MHLTH APPS AV
   Cehovin F, 2017, THESIS COPENHAGEN BU
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Feigl T, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 1: GRAPP, P307, DOI 10.5220/0008989903070318
   Garbett Andrew, 2021, DIS '21: Designing Interactive Systems Conference 2021, P1619, DOI 10.1145/3461778.3462094
   Infivolve Inc., 2022, INF AI FITN PERS TRA
   Jebb AT, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.637547
   Jin Q, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P611, DOI 10.1145/3202185.3210784
   Kim J, 2022, IEEE ACCESS, V10, P14149, DOI 10.1109/ACCESS.2022.3145355
   Linowes J., 2021, Augmented reality with unity AR foundation
   Liu HM, 2018, PROC CVPR IEEE, P1974, DOI 10.1109/CVPR.2018.00211
   Neupane A, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5020005
   Nowacki Pawel, 2020, Engineering in Dependability of Computer Systems and Networks. Proceedings of the Fourteenth International Conference on Dependability of Computer Systems DepCoS-RELCOMEX. Advances in Intelligent Systems and Computing (AISC 987), P358, DOI 10.1007/978-3-030-19501-4_36
   Onyx Inc, 2022, ON HOM WORK APP STOR
   Ozturkcan Selcen, 2021, Journal of Information Technology Teaching Cases, V11, P8, DOI 10.1177/2043886920947110
   Passer M., 2021, RES METHODS CONCEPTS
   Rothkrantz L., 2021, PERSONALIZED DIGITAL, P123
   Ruscio J, 2012, METHODOLOGY-EUR, V8, P1, DOI 10.1027/1614-2241/a000034
   Scargill T, 2021, ARXIV
   Schrepp M., 2019, User Experience Questionnaire Handbook Version 2, P1
   Smith J. A., 2015, Qualitative psychology: A practical guide to research methods
   Soltani P, 2020, COMPUT EDUC, V155, DOI 10.1016/j.compedu.2020.103923
   Swilley E, 2016, DEV MKT SCI, P675
   Taketomi T, 2017, IPSJ Trans. Comput. Vis. Appl, V9, P1, DOI [10.1186/s41074-017-0027-2, DOI 10.1186/S41074-017-0027-2]
   Tavares BF, 2020, INFORMATION, V11, DOI 10.3390/info11070343
   Terashima T, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P73, DOI 10.23919/MVA.2017.7986779
   Turner A, 2022, MOBILE USER STAT DIS
   Uchiyama H, 2007, 17TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE, ICAT 2007, PROCEEDINGS, P172, DOI 10.1109/ICAT.2007.35
   Vay Inc., 2022, VAY 1 HUM MOT AN
   Woniak, 2020, EXPLORING UNDERSTAND, DOI [10.1145/3419249.3420131, DOI 10.1145/3419249.3420131]
   Zenia Inc., 2022, COV ART ZEN INT FITN
NR 34
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2357
EP 2369
DI 10.1007/s10055-023-00812-0
EA MAY 2023
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001033240100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Gölz, MS
   Finkel, L
   Kehlbeck, R
   Herschbach, A
   Bauer, I
   Scheib, JPP
   Deussen, O
   Randerath, J
AF Goelz, Milena S.
   Finkel, Lisa
   Kehlbeck, Rebecca
   Herschbach, Anne
   Bauer, Isabel
   Scheib, Jean P. P.
   Deussen, Oliver
   Randerath, Jennifer
TI From virtual to physical environments when judging action opportunities:
   are diagnostics and trainings transferable?
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual environments; Affordance judgment training; Equivalence testing;
   Detection theory; Affordances
ID PERCEIVED REACHABILITY; REALITY; EQUIVALENCE; PERCEPTION; MEMORY;
   AFFORDANCES; PROGRAM; MODELS; SCALE; BODY
AB The proper evaluation of whether our given bodily capabilities and environmental properties allow particular actions is indispensable for pertinent decisions, so-called affordance judgments. These can be impacted by older age or brain damage. Virtual Environments (VEs) may provide an efficient opportunity to offer trainings. But do people make affordance judgments in VEs in the same way that they do in Physical Environments (PEs)? And are these decisions trainable by use of VEs? We investigated 24 healthy young adults' judgment performance of whether or not they could fit their hand into a given aperture. They were presented with a set of opening-increments and indicated their judgments by pressing a yes- or no-button. The stimuli were presented in PE using an aperture apparatus and in VE displayed by use of Oculus Rift goggles. Our results demonstrated the level of equivalence to be specific to the variable: While we found equivalence between VE and PE for the accuracy parameter, results were uncertain or non-equivalent for perceptual sensitivity and for judgment tendency, respectively. When applying training in VE, judgment accuracy improved significantly when tested subsequently within VE. Improvement appeared detectable in PE only on a descriptive level. Furthermore, equivalence testing post-training revealed that perceptual sensitivity performance in VE approached a PE-level. Promisingly, the VE training approach appeared applicable and efficacious within the VE. Future studies need to specify factors that enhance equivalence for detection theory variables and that facilitate transfer from VEs to PEs when judging action opportunities.
C1 [Goelz, Milena S.; Finkel, Lisa; Herschbach, Anne; Bauer, Isabel; Scheib, Jean P. P.; Randerath, Jennifer] Univ Konstanz, Dept Psychol, Constance, Germany.
   [Goelz, Milena S.; Finkel, Lisa; Herschbach, Anne; Bauer, Isabel; Scheib, Jean P. P.; Randerath, Jennifer] Lurija Inst Rehabil Sci & Hlth Res, Allensbach, Germany.
   [Kehlbeck, Rebecca; Deussen, Oliver] Univ Konstanz, Ctr Adv Study Collect Behav, Dept Comp & Informat Sci, Constance, Germany.
   [Herschbach, Anne] Med Univ Hosp Tuebingen, Dept Psychosomat Med & Psychotherapy, Tubingen, Germany.
   [Randerath, Jennifer] Univ Vienna, Fac Psychol, Outpatient Unit Res Teaching & Practice, Vienna, Austria.
C3 University of Konstanz; University of Konstanz; Eberhard Karls
   University of Tubingen; Eberhard Karls University Hospital; University
   of Vienna
RP Randerath, J (corresponding author), Univ Konstanz, Dept Psychol, Constance, Germany.; Randerath, J (corresponding author), Lurija Inst Rehabil Sci & Hlth Res, Allensbach, Germany.; Randerath, J (corresponding author), Univ Vienna, Fac Psychol, Outpatient Unit Res Teaching & Practice, Vienna, Austria.
EM J_Randerath@hotmail.com
RI Deussen, Oliver/HKF-2004-2023; Randerath, Jennifer/AAC-1530-2019
OI Randerath, Jennifer/0000-0002-0794-5571; Scheib, Jean Patrick
   Philippe/0009-0000-7212-0368
FU EU FP7 Marie Curie Zukunftskolleg Incoming Fellowship Programme at the
   University of Konstanz [291784]; Deutsche Forschungsgemeinschaft (DFG)
   [438470816]; Deutsche Forschungsgemeinschaft (DFG, German Research
   Foundation) under Germany's Excellence Strategy [EXC 2117 - 422037984]
FX This work was supported by the EU FP7 Marie Curie Zukunftskolleg
   Incoming Fellowship Programme at the University of Konstanz (291784) and
   by the Deutsche Forschungsgemeinschaft (DFG, Grant No. 438470816)
   awarded to JR. Further, the project was supported by the Deutsche
   Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's
   Excellence Strategy -EXC 2117 - 422037984. We thank the reviewers and
   Prof. Klaus Willmes for their helpful comments on this manuscript.
CR Andersson HC, 2010, EFSA J, V8, DOI 10.2903/j.efsa.2010.1250
   Bhargava A, 2020, VIRTUAL REAL-LONDON, V24, P713, DOI 10.1007/s10055-020-00432-y
   Blin F, 2016, LANG STUD SCI ENGINE, V2, P41, DOI 10.1075/lsse.2.03bli
   Bliss JP, 1997, PRESENCE-TELEOP VIRT, V6, P73, DOI 10.1162/pres.1997.6.1.73
   Bodenheimer B, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P115, DOI 10.1145/2804408.2804426
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Buckingham G, 2019, Q J EXP PSYCHOL, V72, P2168, DOI 10.1177/1747021819835808
   Choudhury Nusrat, 2013, World Neurosurg, V80, pe9, DOI 10.1016/j.wneu.2012.08.022
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cooper RA, 2005, ASSIST TECHNOL, V17, P159, DOI 10.1080/10400435.2005.10132105
   Creem-Regehr SH, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00096
   Creem-Regehr SH, 2015, PSYCHOL LEARN MOTIV, V62, P195, DOI 10.1016/bs.plm.2014.09.006
   da Silva GT, 2009, BIOL BLOOD MARROW TR, V15, P120, DOI 10.1016/j.bbmt.2008.10.004
   Day BM, 2015, ACTA PSYCHOL, V158, P26, DOI 10.1016/j.actpsy.2015.03.010
   EpicGames, UNR ENG
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Field A, 2018, Discovering Statistics Using IBM SPSS Statistics, Vfifth
   Finkel L, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0226729
   Finkel L, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212709
   Fox JR, 2004, COMMUN RES, V31, P524, DOI 10.1177/0093650204267931
   Franchak JM, 2012, EXP BRAIN RES, V223, P301, DOI 10.1007/s00221-012-3261-y
   Franchak JM, 2010, VISION RES, V50, P2758, DOI 10.1016/j.visres.2010.09.019
   Gabbard C, 2005, BRAIN COGNITION, V58, P172, DOI 10.1016/j.bandc.2004.10.001
   Gabbard C, 2006, J MOTOR BEHAV, V38, P423, DOI 10.3200/JMBR.38.6.423-429
   Gagnon HC, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P798, DOI 10.1109/VR50410.2021.00107
   Gerig N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0189275
   Geuss Michael., 2010, P 7 S APPL PERCEPTIO, P61, DOI [10.1145/1836248.1836259, DOI 10.1145/1836248.1836259]
   Geuss MN, 2015, HUM FACTORS, V57, P1235, DOI 10.1177/0018720815590300
   GOODALE MA, 1994, NEUROPSYCHOLOGIA, V32, P1159, DOI 10.1016/0028-3932(94)90100-7
   Grechkin TY, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823744
   Green D. M., 1966, SIGNAL DETECTION THE
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   Howard MC, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103707
   Hui Z, 2017, INT J MIN SCI TECHNO, V27, P717, DOI 10.1016/j.ijmst.2017.05.005
   HyLownConsultingLLC, 2013, POW SAMPL
   Interrante V, 2008, PRESENCE-TELEOP VIRT, V17, P176, DOI 10.1162/pres.17.2.176
   Ishak S, 2008, J EXP PSYCHOL HUMAN, V34, P1501, DOI 10.1037/a0011393
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Jun E, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2811266
   Kumar AA, 2021, PSYCHON B REV, V28, P40, DOI 10.3758/s13423-020-01792-x
   Kwok TCY, 2011, CLIN INTERV AGING, V6, P83, DOI 10.2147/CIA.S16802
   Lakens D, 2018, ADV METH PRACT PSYCH, V1, P259, DOI 10.1177/2515245918770963
   Lang JI, 1983, SLACK INC THOR
   Lang JI., 1988, AM ORTHOPT J, V38, P48, DOI DOI 10.1080/0065955X.1988.11981769
   Lin QF, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2720020
   Lindner P, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00176
   Linkenauger SA, 2015, NEUROPSYCHOLOGIA, V70, P393, DOI 10.1016/j.neuropsychologia.2014.10.034
   Luyat M, 2008, PSYCHOL NEUROPSYCHIA, V6, P287, DOI 10.1684/pnv.2008.0149
   Machin D., 2011, Sample size tables for clinical studies
   Macmillan N. A., 2004, DETECTION THEORY USE, DOI [DOI 10.4324/9781410611147, 10.4324/9781410611147]
   Mahncke HW, 2006, P NATL ACAD SCI USA, V103, P12523, DOI 10.1073/pnas.0605194103
   Mascha EJ, 2011, ANESTH ANALG, V112, P678, DOI 10.1213/ANE.0b013e318206f872
   Muroi D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170119
   Oxley JA, 2005, ACCIDENT ANAL PREV, V37, P962, DOI 10.1016/j.aap.2005.04.017
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Pereira C, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239837
   Randerath J, 2021, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.531893
   Randerath J, 2018, NEUROPSYCHOLOGIA, V108, P92, DOI 10.1016/j.neuropsychologia.2017.11.031
   Randerath J, 2016, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00674
   ROGERS JL, 1993, PSYCHOL BULL, V113, P553, DOI 10.1037/0033-2909.113.3.553
   Rohrbach N, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.711900
   SALMASO D, 1983, PERCEPT MOTOR SKILL, V57, P1039, DOI 10.2466/pms.1983.57.3f.1039
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Thomas BJ, 2017, PERCEPTION, V46, P586, DOI 10.1177/0301006616679172
   Tieri G, 2018, EXPERT REV MED DEVIC, V15, P107, DOI 10.1080/17434440.2018.1425613
   Wagman JB, 2019, Q J EXP PSYCHOL, V72, P1200, DOI 10.1177/1747021818784403
   Waller D, 1998, PRESENCE-TELEOP VIRT, V7, P129, DOI 10.1162/105474698565631
   Williams RL, 2002, CLIN PHARMACOL THER, V72, P229, DOI 10.1067/mcp.2002.126705
   Wilson CJ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/151702
   Zivotofsky AZ, 2012, HUM FACTORS, V54, P600, DOI 10.1177/0018720812447945
NR 72
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1697
EP 1715
DI 10.1007/s10055-023-00765-4
EA FEB 2023
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000933439400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Lu, AS
   Pelarski, V
   Alon, D
   Baran, A
   McGarrity, E
   Swaminathan, N
   Sousa, CV
AF Lu, Amy Shirong
   Pelarski, Victoria
   Alon, Dar
   Baran, Aleksandra
   McGarrity, Emma
   Swaminathan, Neha
   Sousa, Caio Victor
TI The effect of narrative element incorporation on physical activity and
   game experience in active and sedentary virtual reality games
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Active video game; Exergame; Narrative; Story; Physical
   activity; Game experience
ID BEHAVIOR-CHANGE; EXERCISE; HEALTH; OBESITY; TRANSPORTATION; CALIBRATION;
   TELEVISION; PREVALENCE; INTENSITY; ENJOYMENT
AB Narratives are pervasive in video games and have been found to increase physical activity in active video games. However, the effect of incorporating narrative elements has seldom been examined in fully immersive virtual reality games. We investigated the effect of narrative element incorporation (between-subject: narrative vs. no narrative) in active virtual reality and sedentary virtual reality games (within-subject) and examined between- and within-subject effects on physical activity behavior, game experience, and physical activity engagement. We randomized 36 sedentary college students to either the narrative or the non-narrative group. All participants played an active virtual reality and a sedentary virtual reality game in counter-balanced order. Before each game session, they either watched a 5-min narrative video (narrative) or directly played the original virtual reality games without narratives (non-narrative). We collected participants' physical activity data using wrist-worn accelerometers; we obtained their game experience and physical activity engagement via questionnaires. The narrative group spent a greater proportion of time in moderate-to-vigorous physical activity (%) and had less non-movement time during the active virtual reality gameplay than the non-narrative group (all p values < .05). The active virtual reality sessions induced a greater positive affect and greater physical activity engagement ratings than the sedentary virtual reality sessions. The incorporation of narrative elements in active virtual reality increased the relative time spent in moderate-to-vigorous physical activity and reduced non-movement time, compared to the non-narrative group. Active virtual reality encouraged more activity by participants and offered them a more enjoyable gaming experience in which they engaged more. Active virtual reality is a feasible physical activity promotion option among sedentary adults; the incorporation of narrative elements in active virtual reality helps increase relative moderate-to-vigorous physical activity and should be further explored for its efficacy.
C1 [Lu, Amy Shirong; Baran, Aleksandra; McGarrity, Emma; Swaminathan, Neha] Northeastern Univ, Coll Arts Media & Design, Bouve Coll Hlth Sci, Hlth Technol Lab, Boston, MA 02115 USA.
   [Pelarski, Victoria] Johns Hopkins Univ, Bloomberg Sch Publ Hlth, Baltimore, MD 21205 USA.
   [Alon, Dar] Harvard Univ, Harvard TH Chan Sch Publ Hlth, Boston, MA 02115 USA.
   [Sousa, Caio Victor] Loyola Marymount Univ, Frank R Seaver Coll Sci & Engn, Hlth & Human Sci, Los Angeles, CA 90045 USA.
C3 Northeastern University; Johns Hopkins University; Johns Hopkins
   Bloomberg School of Public Health; Harvard University; Harvard T.H. Chan
   School of Public Health; Loyola Marymount University
RP Lu, AS (corresponding author), Northeastern Univ, Coll Arts Media & Design, Bouve Coll Hlth Sci, Hlth Technol Lab, Boston, MA 02115 USA.
EM a.lu@northeastern.edu
RI Sousa, Caio Victor/D-7060-2016; Lu, Amy Shirong/ITV-5174-2023
OI Sousa, Caio Victor/0000-0002-0499-2372; Lu, Amy
   Shirong/0000-0002-8230-9049
FU National Institutes of Health [R01DK109316]; Northeastern University's
   Interdisciplinary Research Sabbatical
FX This study was partly funded by a grant from the National Institutes of
   Health (R01DK109316) and Northeastern University's Interdisciplinary
   Research Sabbatical, awarded to Amy Shirong Lu.
CR Amresh A, 2017, P 50 HAW INT C SYST
   [Anonymous], 2020, The state of obesity: Better policies for a healthier America 2020
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Bailey BW, 2011, ARCH PEDIAT ADOL MED, V165, P597, DOI 10.1001/archpediatrics.2011.15
   Bailey E, 2019, ENTERTAIN COMPUT, V31, DOI 10.1016/j.entcom.2019.100299
   Barthes R, 1982, BARTHES READER, P265, DOI DOI 10.2307/468419
   Beat Games, 2019, Beat Saber
   Blackwell Debra L, 2018, Natl Health Stat Report, P1
   Booth M, 2000, Res Q Exerc Sport, V71 Suppl 2, P114, DOI 10.1080/02701367.2000.11082794
   Bowen DJ, 2009, AM J PREV MED, V36, P452, DOI 10.1016/j.amepre.2009.02.002
   Brown RichardHarvey., 1987, SOC TEXT ESSAYS RHET
   Burwick K, 2019, M HAMILL BELIEVES ST
   Campo-Prieto P, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5090052
   Cao LZ, 2021, VIRTUAL REAL-LONDON, V25, P597, DOI 10.1007/s10055-020-00477-z
   Caputo EL, 2020, J PHYS ACT HEALTH, V17, P1275, DOI 10.1123/jpah.2020-0406
   Christensen JV, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234297
   Chtourou H, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01708
   Crewe H, 2008, EUR J APPL PHYSIOL, V103, P569, DOI 10.1007/s00421-008-0741-7
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dempsey PC, 2018, HYPERTENSION, V72, P1037, DOI 10.1161/HYPERTENSIONAHA.118.11190
   Dredge S, 2015, OCULUS VR CLASSROOMS
   Dredge S, 2015, PIXAR COFOUNDER WARN
   Drool, 2016, THUMP
   Dunton GF, 2020, PREV MED REP, V20, DOI 10.1016/j.pmedr.2020.101241
   Ellison-Barnes A, 2021, JAMA-J AM MED ASSOC, V326, P2073, DOI 10.1001/jama.2021.16685
   Entertainment Software Association, 2020, 2020 ESS FACTS COMP
   Evans J, 2016, VR IS TERRIBLE TRADI
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Finke M., 2008, Proceedings of the 3rd International Conference on Digital Interactive Media in Entertainment and Arts, P26, DOI DOI 10.1145/1413634.1413644
   Fortune Business Insights, 2021, VIRT REAL VR GAM MAR
   Freedson PS, 1998, MED SCI SPORT EXER, V30, P777, DOI 10.1097/00005768-199805000-00021
   Freina L, 2015, PROC EUR CONF GAME, P195
   Gelman A, 2005, ANN STAT, V33, P1, DOI 10.1214/009053604000001048
   Gomez DH, 2018, GAMES HEALTH J, V7, P310, DOI 10.1089/g4h.2018.0012
   Graves LEF, 2010, PEDIATR EXERC SCI, V22, P535, DOI 10.1123/pes.22.4.535
   Green MC, 2000, J PERS SOC PSYCHOL, V79, P701, DOI 10.1037/0022-3514.79.5.701
   Green MC, 2004, DISCOURSE PROCESS, V38, P247, DOI 10.1207/s15326950dp3802_5
   Hamilton K., 2016, STATE VIRTUAL REALIT
   Hamilton MT, 2014, MED SPORT SCI, V60, P11, DOI 10.1159/000357332
   Hinyard LJ, 2007, HEALTH EDUC BEHAV, V34, P777, DOI 10.1177/1090198106291963
   Hwang J, 2019, PEDIATR EXERC SCI, V31, P438, DOI 10.1123/pes.2019-0006
   Hwang JY, 2018, J CLIN MED, V7, DOI 10.3390/jcm7090268
   Hwang JY, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29274-0
   IJsselsteijn WA., 2013, GAME EXPERIENCE QUES, P3
   Jacobs RN, 2002, NARRATIVE IMPACT: SOCIAL AND COGNITIVE FOUNDATIONS, P205
   KENDZIERSKI D, 1991, J SPORT EXERCISE PSY, V13, P50, DOI 10.1123/jsep.13.1.50
   Kim KJ, 2013, CYBERPSYCH BEH SOC N, V16, P329, DOI 10.1089/cyber.2012.0500
   Labov William, 1972, Language in the inner city: Studies in the Black English research
   Lee IM, 2012, LANCET, V380, P219, DOI 10.1016/S0140-6736(12)61031-9
   Liang B, 2018, TRANSPORT RES F-TRAF, V58, P93, DOI 10.1016/j.trf.2018.05.024
   Lin T, 2006, LECT NOTES COMPUT SC, V4073, P257
   Lombard M, 2000, HUM COMMUN RES, V26, P75, DOI 10.1111/j.1468-2958.2000.tb00750.x
   Lu AS, 2018, GAMES HEALTH J, V7, P1, DOI 10.1089/g4h.2017.0095
   Lu AS, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.6538
   Lu AS, 2015, GAMES HEALTH J, V4, P19, DOI 10.1089/g4h.2014.0090
   Lu AS, 2012, GAMES HEALTH J, V1, P199, DOI 10.1089/g4h.2011.0012
   Maher CA, 2013, OBESITY, V21, pE730, DOI 10.1002/oby.20430
   Matthews CE, 2005, MED SCI SPORT EXER, V37, pS512, DOI 10.1249/01.mss.0000185659.11982.3d
   McDonough DJ, 2018, J CLIN MED, V7, DOI 10.3390/jcm7110433
   Mitchell MK, 2022, 10 BEST RHYTHEM VR G
   Moyer-Gusé E, 2010, HUM COMMUN RES, V36, P26, DOI 10.1111/j.1468-2958.2009.01367.x
   Murphy ST, 2015, AM J PUBLIC HEALTH, V105, P2117, DOI 10.2105/AJPH.2014.302332
   Onwuegbuzie A.J., 2004, Understanding Statistics, V3, P201, DOI DOI 10.1207/S15328031US0304_1
   Owen N, 2011, AM J PREV MED, V41, P189, DOI 10.1016/j.amepre.2011.05.013
   Packer R., 2002, Multimedia: From Wagner to Virtual Reality
   Parschau L, 2014, HEALTH EDUC BEHAV, V41, P414, DOI 10.1177/1090198114529132
   Paw MJMCA, 2008, J SCI MED SPORT, V11, P163, DOI 10.1016/j.jsams.2007.06.001
   Peng X, 2022, PSYCHOL RES BEHAV MA, V15, P1741, DOI 10.2147/PRBM.S369020
   Piercy KL, 2018, CIRC-CARDIOVASC QUAL, V11, DOI 10.1161/CIRCOUTCOMES.118.005263
   Presser R, 2022, WHY IS GAMING PLATFO
   Reynolds C.R., 1983, SCHOOL PSYCHOL REV, V12, P324
   Rimmon-Kenan Shlomith, 2002, NARRATIVE FICTION CO, V2nd
   Rose EA, 2012, SCAND J MED SCI SPOR, V22, P265, DOI 10.1111/j.1600-0838.2010.01161.x
   Rottentomatoes.com, 2019, ALL STAR WARS MOV RA
   Rubin P, 2022, STAR WARS UNIVERSES
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Slater MD, 2002, COMMUN THEOR, V12, P173, DOI 10.1111/j.1468-2885.2002.tb00265.x
   Snow B, 2011, WHY MOST PEOPLE DONT
   Sousa CV, 2022, J SPORT HEALTH SCI, V11, P164, DOI 10.1016/j.jshs.2021.05.002
   Sousa CV, 2020, J MED INTERNET RES, V22, DOI 10.2196/17994
   Strath SJ, 2013, CIRCULATION, V128, P2259, DOI 10.1161/01.cir.0000435708.67487.da
   Suduiko A, 2015, LISTEN MY STORY PROB
   Sundar SS, 2017, CYBERPSYCH BEH SOC N, V20, P672, DOI 10.1089/cyber.2017.0271
   Surmelian L., 1969, Techniques of fiction writing
   Valve Corporation, 2022, STEAM STOR
   Varma VR, 2017, PREV MED, V101, P102, DOI 10.1016/j.ypmed.2017.05.030
   WANKEL LM, 1993, INT J SPORT PSYCHOL, V24, P151
   Ward ZJ, 2019, NEW ENGL J MED, V381, P2440, DOI 10.1056/NEJMsa1909301
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Yee N, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P2, DOI 10.1145/2967934.2967937
   Yoo S, 2016, PROCEEDINGS OF THE 28TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2016), DOI 10.1145/3010915.3010987
NR 91
TC 5
Z9 5
U1 17
U2 52
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1607
EP 1622
DI 10.1007/s10055-023-00754-7
EA JAN 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000922523200001
PM 36742343
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Pieterse, AD
   Hierck, BP
   de Jong, PGM
   Ginn, TF
   Hamoen, EC
   Reinders, MEJ
AF Pieterse, Arianne D.
   Hierck, Beerend P.
   de Jong, Peter G. M.
   Ginn, Thomas F.
   Hamoen, Esther C.
   Reinders, Marlies E. J.
TI User experiences of medical students with 360-degree virtual reality
   applications to prepare them for the clerkships
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Extended reality; Medical education; Technology
   enhanced learning; Active learning; Clerkships
ID TRANSITION
AB For medical students, the transition from the preclinical to the clinical phase of their curriculum (clerkships) can result in increased levels of stress and anxiety. This is partly caused by low self-perception of preparedness. By using 360 & DEG; video-based virtual reality it is possible to provide learners virtual access to clinical situations ahead of time. This technique can provide active and contextual user experiences and offers opportunities to demonstrate both behavioral skills and subject knowledge. We developed two 360 & DEG; video-based virtual reality applications for medical students transitioning to the clerkships. In this study, we describe the development and evaluated the user experiences. Two virtual reality applications were developed for use in a small group learning session. One of the applications is an interactive virtual tour of a hospital ward, in which learners explore the Internal Medicine ward and learn about the roles of different health care professionals and their mutual interactions. In each room, the learners listen to a voice-over and look at hotspots to gather additional information. The other application has been developed to train students in observing (un)professional behavior of healthcare providers in their daily activities. An evaluation was performed by an anonymous explorative questionnaire with open and closed questions (Likert scales) regarding the user experience and cybersickness symptoms. In our study, 171 students used the applications and completed the questionnaire. For 63% of the respondents, this was their first experience with a virtual reality headset. Qualitative analysis showed that students evaluated the learning method as realistic, informative and enjoyable. Most students evaluated virtual reality as a good (59%) or excellent (26%) tool for learning. Forty-five percent of the students experienced physical discomfort, such as nausea, dizziness, headache and disorientation. In most cases, these complaints were mild, although a small number experienced severe nausea (n = 6) or severe headache (n = 2). Students suggested several areas of improvement including increase of display resolution and decrease of ambient noise causing distraction. 360 & DEG; video-based virtual reality can successfully be implemented in the medical curriculum to create a realistic learning experience to prepare students for the clerkships.
C1 [Pieterse, Arianne D.; Hamoen, Esther C.; Reinders, Marlies E. J.] Leiden Univ, Dept Internal Med, Med Ctr, Leiden, Netherlands.
   [Hierck, Beerend P.] Leiden Univ, Dept Anat & Embryol, Med Ctr, Leiden, Netherlands.
   [Hierck, Beerend P.; de Jong, Peter G. M.] Leiden Univ, Ctr Innovat Med Educ, Med Ctr, Leiden, Netherlands.
   [Ginn, Thomas F.] Leiden Univ, Ctr Innovat, The Hague, Netherlands.
   [Reinders, Marlies E. J.] Erasmus MC Univ Med Ctr, Div Nephrol & Transplantat, Dept Internal Med, Rotterdam, Netherlands.
   [Reinders, Marlies E. J.] Erasmus MC Univ Med Ctr, Erasmus MC Transplant Inst, Rotterdam, Netherlands.
   [Hierck, Beerend P.] Univ Utrecht, Fac Vet Med, Dept Anat & Physiol, Clin Sci, Utrecht, Netherlands.
C3 Leiden University; Leiden University Medical Center (LUMC); Leiden
   University - Excl LUMC; Leiden University - Excl LUMC; Leiden
   University; Leiden University Medical Center (LUMC); Leiden University -
   Excl LUMC; Leiden University; Leiden University Medical Center (LUMC);
   Leiden University - Excl LUMC; Leiden University; Erasmus University
   Rotterdam; Erasmus MC; Erasmus University Rotterdam; Erasmus MC; Erasmus
   MC Transplant Institute; Utrecht University
RP Pieterse, AD (corresponding author), Leiden Univ, Dept Internal Med, Med Ctr, Leiden, Netherlands.
EM A.D.Pieterse@lumc.nl
RI ; Hierck, Beerend/A-6488-2013
OI Hamoen, Esther/0000-0001-5407-8266; Reinders,
   Marlies/0000-0001-9543-567X; Hierck, Beerend/0000-0002-7170-1686; de
   Jong, Peter GM/0000-0001-9038-3137; Pieterse,
   Arianne/0000-0002-7267-267X
CR Atherley A, 2019, MED EDUC, V53, P559, DOI 10.1111/medu.13883
   Blair C, 2021, BMC MED EDUC, V21, DOI 10.1186/s12909-021-03013-y
   Buchman SA, 2018, NURSING ED RES C 201
   Chan V, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.14260
   Chittenden EH, 2009, ACAD MED, V84, P872, DOI 10.1097/ACM.0b013e3181a815e9
   Harrington CM, 2018, J SURG EDUC, V75, P993, DOI 10.1016/j.jsurg.2017.10.010
   HOEKS TWM, 1988, MED EDUC, V22, P308, DOI 10.1111/j.1365-2923.1988.tb00758.x
   Huber T, 2017, SURG ENDOSC, V31, P4472, DOI 10.1007/s00464-017-5500-6
   Johnson CDL, 2018, TEACH THEOL RELIG, V21, P228, DOI 10.1111/teth.12446
   Lee SH, 2017, J EDUC BUS, V92, P153, DOI 10.1080/08832323.2017.1308308
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Miles M. B., 1984, Qualitative data analysis: An expanded sourcebook
   MOSS F, 1992, MED EDUC, V26, P17, DOI 10.1111/j.1365-2923.1992.tb00116.x
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   O'Brien BC, 2010, ACAD MED, V85, P1862, DOI 10.1097/ACM.0b013e3181fa2353
   Pieterse AD, 2018, TRANSPL IMMUNOL, V49, P5, DOI 10.1016/j.trim.2018.03.001
   Pottle Jack, 2019, Future Healthc J, V6, P181, DOI 10.7861/fhj.2019-0036
   Radcliffe C, 2003, MED EDUC, V37, P32, DOI 10.1046/j.1365-2923.2003.01405.x
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Rupp MA, 2019, COMPUT EDUC, V128, P256, DOI 10.1016/j.compedu.2018.09.015
   Snelson C, 2020, TECHTRENDS, V64, P404, DOI 10.1007/s11528-019-00474-3
   Sultan L, 2019, ADV MED EDUC PRACT, V10, P907, DOI 10.2147/AMEP.S219344
   Surmon L, 2016, BMC MED EDUC, V16, DOI 10.1186/s12909-016-0615-3
   Yoganathan S, 2018, INT J SURG, V54, P24, DOI 10.1016/j.ijsu.2018.04.002
NR 25
TC 4
Z9 4
U1 11
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1381
EP 1389
DI 10.1007/s10055-022-00731-6
EA JAN 2023
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000912230900002
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Kelly, NJ
AF Kelly, Nathan James
TI Using interpretative phenomenological analysis to gain a qualitative
   understanding of presence in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality (VR); Virtual environment (VE); Presence; Interpretive
   phenomenological analysis (IPA); Immersion
ID PHYSICAL-THERAPY; PAIN CONTROL; ENVIRONMENTS; IMMERSION; EXPERIENCE;
   SENSE
AB Quantitative methods have thus far been the predominant methodological stance of virtual presence research, leaving much to be desired in terms of qualitative understanding. Yet, virtual experiences are a highly personal engagement, unique to each individual, and their presence in virtual reality can be viewed in terms of its experiential individuality. This aspect of the virtual experience is overlooked by conventional quantitative methods, which clusters ratings or scores to form group deductions. Therefore, to address the qualitative gap in the literature and provide an appropriate examination of virtual experiences from the perspective of the individual, an Interpretative Phenomenological Approach was undertaken. This alternate methodology sought to reveal which aspects of virtual experiences users identify as enabling feelings of presence. Examination of common themes among accounts of individuals were performed, to investigate the generation of feelings of presence in virtual reality. Online recruitment provided six interviewees who participated in online semi-structured interviews, prior to Interpretive Phenomenological Analysis. Three superordinate themes were identified: visual satisfaction, freedom of interaction and suspension of real life. Expectance, realism and prevention of disbelief are among the sub-themes identified that contributed to the interviewee's highly present experiences. The identified themes demonstrated the greatest influences of enabling a deeper sense of presence, in turn enhancing their experiences within virtual reality. In acknowledging these mitigating influences, it is hoped this may enable future virtual systems to build upon the research provided and produce consistently high-presence experiences. Consequently, this can aid educational, therapeutic and entertainment applications of virtual reality.
C1 [Kelly, Nathan James] Univ Derby, Alumni Master Res Psychol, Derby, England.
C3 University of Derby
RP Kelly, NJ (corresponding author), Univ Derby, Alumni Master Res Psychol, Derby, England.
EM Nathankelly55@hotmail.com
CR Alase A., 2017, IJELS: International Journal of Education and Literacy Studies, V5, P9, DOI DOI 10.7575/AIAC.IJELS.V.5N.2P.9
   Alexa, 2020, TOP SIT
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Baños RM, 2000, CYBERPSYCHOL BEHAV, V3, P327, DOI 10.1089/10949310050078760
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Breakwell G.M., 2008, Doing social psychology research
   Brocki JM, 2006, PSYCHOL HEALTH, V21, P87, DOI 10.1080/14768320500230185
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Finlay L, 2011, PHENOMENOLOGY FOR THERAPISTS: RESEARCHING THE LIVED WORLD, P139
   Freeman J, 1999, PRESENCE-TELEOP VIRT, V8, P1, DOI 10.1162/105474699566017
   Frohlich Julia, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P159, DOI 10.1007/978-3-642-39405-8_19
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Heidegger Martin., 1992, The Concept of Time
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Hoffman HG, 2001, INT J HUM-COMPUT INT, V13, P1, DOI 10.1207/S15327590IJHC1301_1
   Hoffman HG, 2001, CLIN J PAIN, V17, P229, DOI 10.1097/00002508-200109000-00007
   Hoffman HG, 2006, J PAIN, V7, P843, DOI 10.1016/j.jpain.2006.04.006
   Ijsselsteijn W, 2003, EMERG COMMUNICAT, V5, P3
   Jerome C. J., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2197
   Kardong-Edgren S, 2019, CLIN SIMUL NURS, V31, P28, DOI 10.1016/j.ecns.2019.02.006
   Kim H, 2021, J HOSP TOUR MANAG, V48, P200, DOI 10.1016/j.jhtm.2021.06.008
   Kodama R, 2017, IEEE SYMP 3D USER, P130, DOI 10.1109/3DUI.2017.7893329
   Krijn M, 2004, BEHAV RES THER, V42, P229, DOI 10.1016/S0005-7967(03)00139-6
   Laukkanen T, 2022, INT J INFORM MANAGE, V63, DOI 10.1016/j.ijinfomgt.2021.102455
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Lewis S, 2015, HEALTH PROMOT PRACT, V16, P473, DOI 10.1177/1524839915580941
   Li YL, 2019, ASIAN J SOC PSYCHOL, V22, P193, DOI 10.1111/ajsp.12358
   Lombard M., 2000, P 3 INT WORKSH PRES, V240, P2
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Miles J., 2005, A Handbook of Research Methods for Clinical and Health Psychology
   Pietkiewicz I., 2014, PSYCHOL J, V20, P7, DOI [DOI 10.14691/CPPJ.20.1.7, https://doi.org/10.14691/cppj.20.1.7]
   Pillai A.S., 2019, Virtual and Augmented Reality in Mental Health Treatment, P17
   Raaen K, 2015, LECT NOTES COMPUT SC, V9353, P457, DOI 10.1007/978-3-319-24589-8_40
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schroeder Ralph, 2012, The social life of avatars: Presence and interaction in shared virtual environments
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395
   Sharar SR, 2007, ARCH PHYS MED REHAB, V88, pS43, DOI 10.1016/j.apmr.2007.09.004
   Shatz I, 2017, SOC SCI COMPUT REV, V35, P537, DOI 10.1177/0894439316650163
   Sheridan TB, 1996, PRESENCE-TELEOP VIRT, V5, P241, DOI 10.1162/pres.1996.5.2.241
   Singer Michael J., 1994, 1014 ARI
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Smith J., 2009, INTERPRETATIVE PHENO
   Smith JA, 2017, J POSIT PSYCHOL, V12, P303, DOI 10.1080/17439760.2016.1262622
   Uno S, 1997, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VRAIS.1997.583050
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yung R, 2021, CURR ISSUES TOUR, V24, P1505, DOI 10.1080/13683500.2020.1820454
NR 53
TC 4
Z9 4
U1 3
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1173
EP 1185
DI 10.1007/s10055-022-00719-2
EA DEC 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000895033800002
PM 36533193
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Gruosso, M
   Capece, N
   Erra, U
AF Gruosso, Monica
   Capece, Nicola
   Erra, Ugo
TI Egocentric upper limb segmentation in unconstrained real-life scenarios
SO VIRTUAL REALITY
LA English
DT Article
DE Semantic segmentation; Image processing; Subtraction techniques; Neural
   networks; Egocentric vision
ID HAND GESTURE RECOGNITION; SYSTEM
AB The segmentation of bare and clothed upper limbs in unconstrained real-life environments has been less explored. It is a challenging task that we tackled by training a deep neural network based on the DeepLabv3+ architecture. We collected about 46 thousand real-life and carefully labeled RGB egocentric images with a great variety of skin tones, clothes, occlusions, and lighting conditions. We then widely evaluated the proposed approach and compared it with state-of-the-art methods for hand and arm segmentation, e.g., Ego2Hands, EgoArm, and HGRNet. We used our test set and a subset of the EgoGesture dataset (EgoGestureSeg) to assess the model generalization level on challenging scenarios. Moreover, we tested our network on hand-only segmentation since it is a closely related task. We made a quantitative analysis through standard metrics for image segmentation and a qualitative evaluation by visually comparing the obtained predictions. Our approach outperforms all comparing models in both tasks and proving the robustness of the proposed approach to hand-to-hand and hand-to-object occlusions, dynamic user/camera movements, different lighting conditions, skin colors, clothes, and limb/hand poses.
C1 [Gruosso, Monica; Capece, Nicola; Erra, Ugo] Univ Basilicata, Dept Math Comp Sci & Econ, Via Ateneo Lucano 10, I-85100 Potenza, Italy.
C3 University of Basilicata
RP Capece, N (corresponding author), Univ Basilicata, Dept Math Comp Sci & Econ, Via Ateneo Lucano 10, I-85100 Potenza, Italy.
EM monica.gruosso@unibas.it; nicola.capece@unibas.it; ugo.erra@unibas.it
RI Capece, Nicola/U-1110-2019; Gruosso, Monica/AAC-5804-2021; Erra,
   Ugo/X-3889-2019
OI Capece, Nicola/0000-0002-1544-3977; Gruosso, Monica/0000-0001-9609-8919;
   Erra, Ugo/0000-0003-2942-7131
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Alletto S, 2015, PATTERN RECOGN, V48, P4082, DOI 10.1016/j.patcog.2015.06.006
   Bambach S, 2015, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2015.226
   Bandini A, 2023, IEEE T PATTERN ANAL, V45, P6846, DOI 10.1109/TPAMI.2020.2986648
   Betancourt A, 2017, COMPUT VIS IMAGE UND, V154, P73, DOI 10.1016/j.cviu.2016.09.005
   Betancourt A, 2015, IEEE T CIRC SYST VID, V25, P744, DOI 10.1109/TCSVT.2015.2409731
   Bojja AK, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P151, DOI 10.1109/CRV.2019.00028
   Caggianese G, 2020, INT J HUM-COMPUT INT, V36, P1734, DOI 10.1080/10447318.2020.1785151
   Caggianese G, 2015, LECT NOTES COMPUT SC, V9254, P399, DOI 10.1007/978-3-319-22888-4_29
   Cai MJ, 2017, IEEE T HUM-MACH SYST, V47, P524, DOI 10.1109/THMS.2017.2681423
   Capece N, 2020, ARCHAEO PUZZLE ED GA
   Chalasani T, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P109, DOI 10.1109/ISMAR-Adjunct.2018.00045
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dadashzadeh A, 2019, IET COMPUT VIS, V13, P700, DOI 10.1049/iet-cvi.2018.5796
   Dave Ishan R., 2019, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2017. Advances in Intelligent Systems and Computing (AISC 714), P393, DOI 10.1007/978-981-13-0224-4_35
   Fathi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3281, DOI 10.1109/CVPR.2011.5995444
   Ferracani A, 2016, P 1 INT WORKSH MULT, P21, DOI DOI 10.1145/2983298.2983307
   Gonzalez-Sosa E, 2020, IEEE ACCESS, V8, P146887, DOI 10.1109/ACCESS.2020.3013016
   Gruosso M, 2021, SMART TOOLS APPS GRA, DOI [10.2312/stag.20211483, DOI 10.2312/STAG.20211483]
   Gruosso M, 2021, PROCEEDINGS OF THE 26TH ACM INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, WEB3D 2021, DOI 10.1145/3485444.3495179
   Gruosso M, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P380, DOI 10.1109/AIVR50618.2020.00079
   Gruosso M, 2021, MULTIMED TOOLS APPL, V80, P1175, DOI 10.1007/s11042-020-09425-0
   Haria A, 2017, PROCEDIA COMPUT SCI, V115, P367, DOI 10.1016/j.procs.2017.09.092
   Harkat H, 2020, PROC SPIE, V11533, DOI 10.1117/12.2573902
   Herumurti D, 2017, INT CONF INFORM COMM, P303, DOI 10.1109/ICTS.2017.8265688
   Ju ZJ, 2017, IEEE SYST J, V11, P1326, DOI 10.1109/JSYST.2015.2468231
   Kapidis G, 2019, 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019), P922, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00185
   Khan AU, 2018, PROC CVPR IEEE, P4710, DOI 10.1109/CVPR.2018.00495
   Kim TK, 2018, P IEEE C COMPUTER VI
   Kok VJ, 2017, IEEE T CYBERNETICS, V47, P1157, DOI 10.1109/TCYB.2016.2538765
   Kong YY, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030454
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Lee K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300566
   Lee S, 2014, IEEE COMPUT SOC CONF, P557, DOI 10.1109/CVPRW.2014.86
   Li C, 2013, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2013.458
   Li Y, 2015, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2015.7298625
   Li YL, 2019, NEUROCOMPUTING, V334, P11, DOI 10.1016/j.neucom.2018.12.010
   Lin F, 2020, ARXIV
   Lin FQ, 2021, IEEE WINT CONF APPL, P2372, DOI 10.1109/WACV48630.2021.00242
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Maricchiolo F, 2005, P C INT SOC GESTURE
   Matilainen M, 2016, INT CONF IMAG PROC
   Maurya J, 2018, IEEE IMAGE PROC, P4023, DOI 10.1109/ICIP.2018.8451213
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Minjie Cai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14380, DOI 10.1109/CVPR42600.2020.01440
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Narasimhaswamy S, 2019, IEEE I CONF COMP VIS, P9566, DOI 10.1109/ICCV.2019.00966
   Neroni Pietro., 2015, 2015 IEEE INT C MULT, P1
   Papandreou G, 2015, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2015.7298636
   Paul Soumi, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P775, DOI 10.1007/978-981-13-7403-6_68
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Poularakis S, 2016, IEEE T CYBERNETICS, V46, P2094, DOI 10.1109/TCYB.2015.2464195
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ren Y, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107297
   Rogez G, 2015, LECT NOTES COMPUT SC, V8925, P356, DOI 10.1007/978-3-319-16178-5_25
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma S, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107892
   Shilkrot Roy., 2019, BMVC, P258
   Tang YS, 2019, IEEE T CIRC SYST VID, V29, P3001, DOI 10.1109/TCSVT.2018.2875441
   Thalmann D, 2016, COMM COM INF SC, V598, P3, DOI 10.1007/978-3-319-29971-6_1
   Nguyen THC, 2018, LECT NOTES COMPUT SC, V10882, P390, DOI 10.1007/978-3-319-93000-8_44
   Valli A, 2008, MULTIMED TOOLS APPL, V38, P295, DOI 10.1007/s11042-007-0190-z
   Wang J, 2021, COMPUT METH PROG BIO, V207, DOI 10.1016/j.cmpb.2021.106210
   Wang W, 2019, IEEE I CONF COMP VIS, P2142, DOI 10.1109/ICCV.2019.00223
   Wenfeng Wu, 2021, ICCBN 2021: 2021 9th International Conference on Communications and Broadband Networking, P34, DOI 10.1145/3456415.3456422
   Yuan S, 2017, ARXIV
   Yueming W, 2007, SECOND WORKSHOP ON DIGITAL MEDIA AND ITS APPLICATION IN MUSEUM & HERITAGE, PROCEEDINGS, P395, DOI 10.1109/DMAMH.2007.39
   Zhang YF, 2018, IEEE T MULTIMEDIA, V20, P1038, DOI 10.1109/TMM.2018.2808769
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 74
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3421
EP 3433
DI 10.1007/s10055-022-00725-4
EA DEC 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000893537900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Stamenkovic, A
   Underation, M
   Cloud, LJ
   Pidcoe, PE
   Baron, MS
   Hand, R
   France, CR
   van der Veen, SM
   Thomas, JS
AF Stamenkovic, Alexander
   Underation, Matthew
   Cloud, Leslie J.
   Pidcoe, Peter E.
   Baron, Mark S.
   Hand, Robert
   France, Christopher R.
   van der Veen, Susanne M.
   Thomas, James S.
TI Assessing perceptions to a virtual reality intervention to improve trunk
   control in Parkinson's disease: a preliminary study
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual rehabilitation; Posture; Parkinson's disease; Trunk control;
   Immersion; Game development
ID DEEP BRAIN-STIMULATION; BACK-PAIN; POSTURAL CONTROL; BALANCE; LEVODOPA;
   FEAR; REHABILITATION; PERTURBATIONS; INDIVIDUALS; PROGRESSION
AB Trunk control and postural instability remain critical markers of functional status in Parkinson's Disease (PD). As pharmacological and invasive neuro-stimulation interventions provide only limited benefits for trunk and postural control, exercise-based interventions may provide the only effective path to improving functional outcomes for balance in PD. We describe the framework for a virtual reality (VR) graded exercise-based intervention focused on improving trunk mobility and control, including preliminary outcomes on perceptions and motion capabilities of individuals with PD. The study collected whole-body motion capture from 11 PD participants (8M, 3F; H&Y Stage I-III) as they performed tasks within a custom-designed set of VR therapies. Therapies involved static interactions (e.g., matching a cube sequence set to anthropometrically relevant locations to elicit specific trunk motions-Matchality), and more dynamic tasks (e.g., intercepting virtual fish jumping from a lake-Fishality, or a virtual session of dodgeball-Dodgeality). Participants were able to safely complete all tasks while performing trunk excursions requiring functionally relevant ranges of motion, and which altered across VR environment (F-(1,F-10) = 8.319, p = 0.016). Overall, satisfaction with the MoVR therapy suite was high with 96% of responses showing agreement to questions relating to 'immersion,' 'fun,' and elements of player engagement. These results provide early safety, usability, and feasibility outcomes for VR interventions that require specific trunk excursions. Future work should confirm the effectiveness of VR interventions longitudinally on PD-specific trunk outcomes (e.g., trunk rigidity) and global balance/mobility measures associated with improved functional status.
C1 [Stamenkovic, Alexander; Underation, Matthew; Pidcoe, Peter E.; van der Veen, Susanne M.; Thomas, James S.] Virginia Commonwealth Univ, Coll Hlth Profess, Dept Phys Therapy, 900 E Leigh St,Box 980224, Richmond, VA 23298 USA.
   [Cloud, Leslie J.; Baron, Mark S.; Hand, Robert] Virginia Commonwealth Univ Hlth Syst, Parkinsons & Movement Disorders Ctr, Richmond, VA USA.
   [Cloud, Leslie J.; Baron, Mark S.; Hand, Robert] Virginia Commonwealth Univ, Sch Med, Dept Neurol, Richmond, VA 23298 USA.
   [France, Christopher R.] Ohio Univ, Ohio Musculoskeletal & Neurol Inst OMNI, Athens, OH 45701 USA.
   [France, Christopher R.] Ohio Univ, Dept Psychol, Athens, OH 45701 USA.
C3 Virginia Commonwealth University; Virginia Commonwealth University;
   Virginia Commonwealth University; University System of Ohio; Ohio
   University; University System of Ohio; Ohio University
RP Stamenkovic, A (corresponding author), Virginia Commonwealth Univ, Coll Hlth Profess, Dept Phys Therapy, 900 E Leigh St,Box 980224, Richmond, VA 23298 USA.
EM astamenkovic@vcu.edu
RI Stamenkovic, Alexander/HHD-2237-2022; Stamenkovic, Alexander/B-7395-2013
OI Stamenkovic, Alexander/0000-0002-1010-9347; Cloud, MD, MSc, Leslie
   Jameleh/0000-0001-5414-549X
FU NIH [R01HD088417, R01AT006978]; VCU Parkinson's and Movement Disorders
   Center Pilot Grant; National Center for Research Resources [UL1TR002649]
FX AS was supported by NIH R01HD088417 and VCU Parkinson's and Movement
   Disorders Center Pilot Grant. JST and CRF were supported by NIH
   R01AT006978, R01HD088417. MU and SV were supported by NIH R01HD088417.
   National Center for Research Resources (Grant No. UL1TR002649)
CR Adkin AL, 2003, MOVEMENT DISORD, V18, P496, DOI 10.1002/mds.10396
   Bäckström D, 2018, NEUROLOGY, V91, pE2045, DOI 10.1212/WNL.0000000000006576
   Bakdash JZ, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01201
   Bordeleau M, 2022, J PAIN, V23, P175, DOI 10.1016/j.jpain.2021.08.001
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cano-de-la-Cuerda R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092482
   Cano-de-la-Cuerda R, 2017, NEUROREHABILITATION, V40, P569, DOI 10.3233/NRE-171444
   Carpenter MG, 2004, J NEUROL NEUROSUR PS, V75, P1245, DOI 10.1136/jnnp.2003.021147
   Colebatch JG, 2019, EXP BRAIN RES, V237, P1853, DOI 10.1007/s00221-019-05553-8
   Craig CE, 2020, MOVEMENT DISORD, V35, P1199, DOI 10.1002/mds.28051
   Curtze C, 2015, MOVEMENT DISORD, V30, P1361, DOI 10.1002/mds.26269
   Di Giulio I, 2016, J NEUROPHYSIOL, V116, P493, DOI 10.1152/jn.00996.2015
   Dockx K, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010760.pub2
   Dorsey ER, 2007, NEUROLOGY, V68, P384, DOI 10.1212/01.wnl.0000247740.47667.03
   Phan D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020495
   France CR, 2018, CONTEMP CLIN TRIALS, V69, P83, DOI 10.1016/j.cct.2018.05.001
   George RJS, 2010, NEUROLOGY, V75, P1292, DOI 10.1212/WNL.0b013e3181f61329
   Gil-Gómez JA, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071589
   Hadjistavropoulos T, 2011, J AGING HEALTH, V23, P3, DOI 10.1177/0898264310378039
   Harris D, 2020, VIRTUAL REAL-LONDON, V24, P557, DOI 10.1007/s10055-019-00422-9
   HART S G, 1988, P139
   Holmes JD, 2013, PHYS OCCUP THER GERI, V31, P241, DOI 10.3109/02703181.2013.814743
   Horak FB, 1996, J NEUROPHYSIOL, V75, P2380, DOI 10.1152/jn.1996.75.6.2380
   Horak FB, 2005, EXP NEUROL, V193, P504, DOI 10.1016/j.expneurol.2004.12.008
   Kearney E, 2019, DISABIL REHABIL, V41, P995, DOI 10.1080/09638288.2017.1419292
   Kerr GK, 2010, NEUROLOGY, V75, P116, DOI 10.1212/WNL.0b013e3181e7b688
   Keus SHJ, 2007, MOVEMENT DISORD, V22, P451, DOI 10.1002/mds.21244
   Khobkhun F, 2020, PHYS THER REV, V25, P283, DOI 10.1080/10833196.2020.1816127
   King LA, 2012, PARKINSONS DIS-US, V2012, DOI 10.1155/2012/375419
   Kowal SL, 2013, MOVEMENT DISORD, V28, P311, DOI 10.1002/mds.25292
   Lajoie Y, 2004, ARCH GERONTOL GERIAT, V38, P11, DOI 10.1016/S0167-4943(03)00082-7
   Lau B, 2019, NEUROLOGY, V92, pE2559, DOI 10.1212/WNL.0000000000007562
   Leddy AL, 2011, J NEUROL PHYS THER, V35, P90, DOI 10.1097/NPT.0b013e31821a620c
   López-de-Uralde-Villanueva I, 2016, PAIN MED, V17, P172, DOI 10.1111/pme.12882
   Mancini M, 2012, GAIT POSTURE, V36, P471, DOI 10.1016/j.gaitpost.2012.04.010
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Park JH, 2015, J MOV DISORD, V8, P109, DOI 10.14802/jmd.15018
   Park SH, 2015, J PHYS THER SCI, V27, P3929, DOI 10.1589/jpts.27.3929
   Peebles AT, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/32027
   Post B, 2007, MOVEMENT DISORD, V22, P1839, DOI 10.1002/mds.21537
   Rocchi L, 2002, J NEUROL NEUROSUR PS, V73, P267, DOI 10.1136/jnnp.73.3.267
   Sarlegna FR, 2015, VISION RES, V110, P144, DOI 10.1016/j.visres.2014.07.001
   Schoneburg B, 2013, MOVEMENT DISORD, V28, P1474, DOI 10.1002/mds.25613
   Stamenkovic A, 2020, FRONT AGING NEUROSCI, V12, DOI 10.3389/fnagi.2020.00241
   Thomas AA, 2010, J NEUROL, V257, P1124, DOI 10.1007/s00415-010-5475-x
   Thomas JS, 2007, SPINE, V32, pE801, DOI 10.1097/BRS.0b013e31815d0003
   Thomas JS, 2007, SPINE, V32, pE460, DOI 10.1097/BRS.0b013e3180bc1f7b
   Thomas JS, 2016, IEEE J TRANSL ENG HE, V4, DOI 10.1109/JTEHM.2016.2623787
   Thomas JS, 2016, J PAIN, V17, P1302, DOI 10.1016/j.jpain.2016.08.011
   Thomas JS, 2016, JMIR SERIOUS GAMES, V4, DOI 10.2196/games.6476
   Thomas JS, 1998, J MOTOR BEHAV, V30, P98, DOI 10.1080/00222899809601327
   Thomas JS, 2005, J NEUROPHYSIOL, V93, P352, DOI 10.1152/jn.00582.2004
   Thomas JS, 2003, EXP BRAIN RES, V148, P377, DOI 10.1007/s00221-002-1287-2
   Trost Z, 2008, PAIN, V137, P26, DOI 10.1016/j.pain.2007.08.005
   Ustinova KI, 2010, ACTA PSYCHOL, V133, P180, DOI 10.1016/j.actpsy.2009.11.006
   van der Veen SM, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/18888
   van der Veen SM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173632
   Wright WG, 2007, EXP NEUROL, V208, P38, DOI 10.1016/j.expneurol.2007.07.002
   Yelshyna D, 2016, BEHAV BRAIN RES, V296, P384, DOI 10.1016/j.bbr.2015.08.017
NR 59
TC 1
Z9 1
U1 5
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 465
EP 479
DI 10.1007/s10055-022-00657-z
EA AUG 2022
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000840271200001
DA 2024-07-18
ER

PT J
AU Morosi, F
   Caruso, G
AF Morosi, Federico
   Caruso, Giandomenico
TI Configuring a VR simulator for the evaluation of advanced human-machine
   interfaces for hydraulic excavators
SO VIRTUAL REALITY
LA English
DT Article
DE Excavator coordinated control; Virtual reality simulator; Haptic
   control; Human-machine interface; Multi-sensory feedbacks
ID OF-THE-ART; VIRTUAL-REALITY; ENVIRONMENT; TRENDS; MODEL
AB This study is aimed at evaluating the impact of different technical solutions of a virtual reality simulator to support the assessment of advanced human-machine interfaces for hydraulic excavator based on a new coordinated control paradigm and haptic feedbacks. By mimicking the end-effector movements, the control is conceived to speed up the learning process for novice operators and to reduce the mental overload on those already trained. The design of the device can fail if ergonomics, usability and performance are not grounded on realistic simulations where the combination of visual, auditory and haptic feedbacks make the users feel like being in a real environment rather than a computer-generated one. For this reason, a testing campaign involving 10 subjects was designed to discriminate the optimal set-up for the hardware to ensure a higher immersion into the VR experience. Both the audio-video configurations of the simulator (head-mounted display and surround system vs. monitor and embedded speakers) and the two types of haptic feedback for the soil-bucket interaction (contact vs. shaker) are compared in three different scenarios. The performance of both the users and simulator are evaluated by processing subjective and objective data. The results show how the immersive set-up improves the users' efficiency and ergonomics without putting any extra mental or physical effort on them, while the preferred haptic feedback (contact) is not the more efficient one (shaker).
C1 [Morosi, Federico; Caruso, Giandomenico] Politecn Milan, Mech Engn Dept, Milan, Italy.
C3 Polytechnic University of Milan
RP Morosi, F (corresponding author), Politecn Milan, Mech Engn Dept, Milan, Italy.
EM federico.morosi@polimi.it; giandomenico.caruso@polimi.it
RI Morosi, Federico/AAU-5078-2020; Caruso, Giandomenico/A-1694-2016
OI Morosi, Federico/0000-0001-8233-4992; Caruso,
   Giandomenico/0000-0003-2654-093X
CR Akyeampong J, 2014, INT J IND ERGONOM, V44, P374, DOI 10.1016/j.ergon.2013.12.002
   Andreano J, 2009, CYBERPSYCHOL BEHAV, V12, P309, DOI 10.1089/cpb.2009.0104
   [Anonymous], 2016, Oculus VR
   [Anonymous], 2021, SPSS Statistics
   [Anonymous], 2002, Proc. Eurohaptics
   Bachman P, 2019, ADV INTELL SYST, V835, P563, DOI 10.1007/978-3-319-97490-3_54
   Bommer SC, 2018, INT J IND ERGONOM, V63, P7, DOI 10.1016/j.ergon.2016.10.007
   Burdea GRIGORE, 1996, Force and touch feedback for virtual reality
   Chacko V, 2014, INT C ADV MECH SYST, P481, DOI 10.1109/ICAMechS.2014.6911593
   Cohen J., 1988, STAT POWER ANAL BEHA
   Dadhich S, 2016, AUTOMAT CONSTR, V68, P212, DOI 10.1016/j.autcon.2016.05.009
   Dopico D, 2010, P 5 AS C MULT DYN 20, V1, P325, DOI [10.1299/jsmeacmd.2010.5._63245-1_, DOI 10.1299/JSMEACMD.2010.5._63245-1]
   Feng H, 2019, AUTOMAT CONSTR, V106, DOI 10.1016/j.autcon.2019.102897
   Frankel, 2004, THESIS GEORGIA I TEC
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   González M, 2009, WINVR2009: PROCEEDINGS OF THE ASME/AFM WORLD CONFERENCE ON INNOVATIVE VIRTUAL REALITY - 2009, P75
   HART S G, 1988, P139
   Hayn H, 2010, ADVANCES IN HAPTICS, P199
   Hughes K, 2010, HUM FACTOR ERGON MAN, V20, P408, DOI 10.1002/hfm.20191
   Kim D, 2009, AUTOMAT CONSTR, V18, P173, DOI 10.1016/j.autcon.2008.07.002
   Kot Tomas, 2014, Applied Mechanics and Materials, V555, P199, DOI 10.4028/www.scientific.net/AMM.555.199
   Kuijt-Evers LFM, 2003, APPL ERGON, V34, P265, DOI 10.1016/S0003-6870(03)00032-2
   Leap Motion, 2012, ULTR
   Lee J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224853
   Meera CS, 2020, J MECH DESIGN, V142, DOI 10.1115/1.4048462
   Morosi F, 2019, AUTOMAT CONSTR, V105, DOI 10.1016/j.autcon.2019.102848
   Nezami EG, 2007, INT J NUMER ANAL MET, V31, P1147, DOI 10.1002/nag.594
   Ni T, 2013, COMPUT ELECTR ENG, V39, P2112, DOI 10.1016/j.compeleceng.2013.06.010
   Pla-Castells M, 2009, C ESP INF GRAF CEIG, P4
   Potyondy DO, 2015, GEOSYSTEM ENG, V18, P1, DOI 10.1080/12269328.2014.998346
   Quang Hoan Le, 2015, INT C CONTR AUTOMAT, P841, DOI 10.1109/ICCAS.2015.7364738
   Sekizuka R, 2019, IEEE INT C INT ROBOT, P3229, DOI [10.1109/IROS40897.2019.8968213, 10.1109/iros40897.2019.8968213]
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P8
   So JCY, 2013, HUM FACTORS, V55, P449, DOI 10.1177/0018720812454292
   Stahl M, 2011, GRANUL MATTER, V13, P417, DOI 10.1007/s10035-010-0239-y
   Torres-Rodríguez HI, 2004, 2004 1st International Conference on Electrical and Electronics Engineering (ICEEE), P350
   Ueda Y, 2004, P INT S ROB AUT, P8
   Unity 3D, 2019, UN TECHN
   Wang X., 2011, P 28 INT S AUT ROB C, P631
   Winck RC, 2015, AUTOMAT CONSTR, V51, P46, DOI 10.1016/j.autcon.2014.12.012
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yihai Fang, 2014, Construction in a Global Network. 2014 Construction Research Congress. Proceedings, P31
   Zhang YX, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103311
NR 43
TC 5
Z9 5
U1 1
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 801
EP 816
DI 10.1007/s10055-021-00598-z
EA OCT 2021
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000712218200001
DA 2024-07-18
ER

PT J
AU Ueyama, Y
   Harada, M
AF Ueyama, Yuki
   Harada, Masanori
TI Effects of first- and third-person perspectives created using a
   head-mounted display on dart-throwing accuracy
SO VIRTUAL REALITY
LA English
DT Article
DE HMD; Motor control; Skill transfer; Human performance; Visual
   perspective; Body ownership; Agency; Size perception; Distance
   perception
ID PERFORMANCE
AB The first-person perspective (1PP) and third-person perspective (3PP) have both been adopted in video games. The 1PP can induce a strong sense of immersion, and the 3PP allows players to perceive distances easily. Virtual reality technologies have also adopted both perspectives to facilitate skill acquisition. However, how 1PP and 3PP views affect motor skills in the real world, as opposed to in games and virtual environments, remains unclear. This study examined the effects of the 1PP and 3PP on real-world dart-throwing accuracy after head-mounted display (HMD)-based practice tasks involving either the 1PP or 3PP. The 1PP group showed poorer dart-throwing performance, whereas the 3PP task had no effect on performance. Furthermore, while the effect of the 1PP task persisted for some time, that of task 3PP disappeared immediately. Therefore, the effects of 1PP HMD-based practice tasks on motor control transfer more readily to the real world than do those of 3PP tasks.
C1 [Ueyama, Yuki; Harada, Masanori] Natl Def Acad Japan, Dept Mech Engn, 1-10-20 Hashirimizu, Yokosuka, Kanagawa 2398686, Japan.
C3 National Defense Academy - Japan
RP Ueyama, Y (corresponding author), Natl Def Acad Japan, Dept Mech Engn, 1-10-20 Hashirimizu, Yokosuka, Kanagawa 2398686, Japan.
EM ueyama@nda.ac.jp
RI Ueyama, Yuki/AAK-6679-2020
OI Ueyama, Yuki/0000-0002-1415-8875
FU Hayao Nakayama Foundation for Science & Technology and Culture
   [R1-A1-32]; JSPS KAKENHI [JP16K12518, JP19K20745]
FX We would like to thank Yu Maeda for his help in the experiments. A part
   of this work was supported by Hayao Nakayama Foundation for Science &
   Technology and Culture under Grant Number R1-A1-32, and JSPS KAKENHI
   under Grant Numbers JP16K12518 and JP19K20745.
CR Arzy S, 2019, TRENDS COGN SCI, V23, P476, DOI 10.1016/j.tics.2019.04.003
   Tran BN, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223837
   CALVIN WH, 1982, ETHOL SOCIOBIOL, V3, P115, DOI 10.1016/0162-3095(82)90010-3
   Covaci A, 2015, IEEE COMPUT GRAPH, V35, P55, DOI 10.1109/MCG.2015.95
   Debarba HG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190109
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Engbert K, 2008, COGNITION, V107, P693, DOI 10.1016/j.cognition.2007.07.021
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Hays R. T., 1992, MIL PSYCHOL, V4, P63, DOI DOI 10.1207/S15327876MP0402_1
   Hong MS, 2021, VIRTUAL REAL-LONDON, V25, P491, DOI 10.1007/s10055-020-00469-z
   Howard MC, 2021, VIRTUAL REAL-LONDON, V25, P1221, DOI 10.1007/s10055-021-00524-3
   Ikegami T, 2014, SCI REP-UK, V4, DOI 10.1038/srep06989
   Koutitas G, 2021, VIRTUAL REAL-LONDON, V25, P83, DOI 10.1007/s10055-020-00436-8
   Lee JH, 2020, VIRTUAL REAL-LONDON, V24, P211, DOI 10.1007/s10055-019-00390-0
   Lim K, 2021, VIRTUAL REAL-LONDON, V25, P331, DOI 10.1007/s10055-020-00457-3
   Lohse KR, 2010, HUM MOVEMENT SCI, V29, P542, DOI 10.1016/j.humov.2010.05.001
   MENDOZA D, 1978, PERCEPT MOTOR SKILL, V47, P1195, DOI 10.2466/pms.1978.47.3f.1195
   Michalski SC, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02159
   Miles HC, 2012, COMPUT GRAPH-UK, V36, P714, DOI 10.1016/j.cag.2012.04.007
   Mittelstaedt JM, 2019, VIRTUAL REAL-LONDON, V23, P143, DOI 10.1007/s10055-018-0370-3
   Moore J, 2008, CONSCIOUS COGN, V17, P136, DOI 10.1016/j.concog.2006.12.004
   Moore JW, 2009, CONSCIOUS COGN, V18, P1056, DOI 10.1016/j.concog.2009.05.004
   Mosley E, 2017, PHYSIOL BEHAV, V179, P116, DOI 10.1016/j.physbeh.2017.05.030
   Nasu D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088536
   Osti F, 2021, VIRTUAL REAL-LONDON, V25, P523, DOI 10.1007/s10055-020-00470-6
   Pastel S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239226
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Roach NT, 2013, NATURE, V498, P483, DOI 10.1038/nature12267
   Salamin P, 2010, IEEE T LEARN TECHNOL, V3, P272, DOI 10.1109/TLT.2010.13
   Schorer J, 2012, EXP BRAIN RES, V217, P287, DOI 10.1007/s00221-011-2992-5
   Seinfeld S, 2021, HUM-COMPUT INTERACT, V36, P400, DOI 10.1080/07370024.2020.1724790
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Smeets JBJ, 2002, EXP BRAIN RES, V144, P268, DOI 10.1007/s00221-002-1072-2
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Ueyama Y, 2017, J COMPUT NEUROSCI, V43, P93, DOI 10.1007/s10827-017-0650-z
   Ueyama Y, 2017, ADV ROBOTICS, V31, P107, DOI 10.1080/01691864.2016.1266966
   Ueyama Y, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00119
   Ueyama Y, 2013, CURR BIOINFORM, V8, P16
   Ueyama Y, 2014, IEEE T IND ELECTRON, V61, P1044, DOI 10.1109/TIE.2013.2273473
   van Beers RJ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064332
   van Beers RJ, 2009, NEURON, V63, P406, DOI 10.1016/j.neuron.2009.06.025
   Vogeley K, 2003, TRENDS COGN SCI, V7, P38, DOI 10.1016/S1364-6613(02)00003-7
   Wolpert DM, 1998, TRENDS COGN SCI, V2, P338, DOI 10.1016/S1364-6613(98)01221-2
   YAMADA T, 1988, J ANTHROPOL SOC NIP, V96, P7
   Zhang ZR, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006013
NR 48
TC 5
Z9 5
U1 0
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 687
EP 695
DI 10.1007/s10055-021-00562-x
EA JUL 2021
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000679285000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fussell, SG
   Truong, D
AF Fussell, Stephanie G.
   Truong, Dothang
TI Using virtual reality for dynamic learning: an extended technology
   acceptance model
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Dynamic learning; Aviation education; Education
   technology; Technology acceptance model; Student perception
ID PERCEIVED EASE; PASSENGERS INTENTIONS; USER ACCEPTANCE; SIMULATION
AB Virtual reality (VR) is being researched and incorporated into curricula and training programs to expand educational opportunities and enhance learning across many fields. Although researchers are exploring the learning affordances associated with VR, research surrounding students' perceptions of the technology, and intentions to use it for training has been neglected. The goal of this research was to determine the factors that influence students' intention to use VR in a dynamic learning environment. An extended Technology Acceptance Model (TAM) was developed that incorporates factors related to education and the use of VR technology in training environments. Confirmatory factor analysis (CFA) and structural equation modeling (SEM) processes were employed. Nine of 14 hypotheses in the original model were supported, and eight of the nine predictor factors of the model were determined to directly or indirectly impact behavioral intention (BI). The original TAM factors had the strongest relationships. Relationships between factors particularly relevant to VR technology and learning were also supported. The results of this study may guide other educators interested in incorporating VR into a dynamic learning environment.
C1 [Fussell, Stephanie G.] Kent State Univ, Grad Studies, Coll Aeronaut & Engn, Kent, OH 44242 USA.
   [Truong, Dothang] Embry Riddle Aeronaut Univ, Sch Grad Studies, Coll Aviat, Daytona Beach, FL USA.
C3 University System of Ohio; Kent State University; Kent State University
   Salem; Kent State University Kent; Embry-Riddle Aeronautical University
RP Fussell, SG (corresponding author), Kent State Univ, Grad Studies, Coll Aeronaut & Engn, Kent, OH 44242 USA.
EM Sfussel2@kent.edu
OI Fussell, Stephanie/0000-0002-7793-8908
CR Abdullah F, 2016, COMPUT HUM BEHAV, V63, P75, DOI 10.1016/j.chb.2016.05.014
   Abdullah F, 2016, COMPUT HUM BEHAV, V56, P238, DOI 10.1016/j.chb.2015.11.036
   Ahadzadeh Ashraf Sadat, 2015, J Med Internet Res, V17, pe45, DOI 10.2196/jmir.3564
   AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   [Anonymous], 2017, What is virtual reality?
   BANDURA A, 1991, ORGAN BEHAV HUM DEC, V50, P248, DOI 10.1016/0749-5978(91)90022-L
   Burki-Cohen J, 2007, P AIAA MOD SIM TECN, DOI 10.2514/6.2007-6564
   Burki-Cohen J, 2005, P AIAA MOD SIM TECHN, DOI 10.2514/6.2005-6109
   Byrne B, 2010, INTERNATIONAL HANDBOOK OF PSYCHOLOGY IN EDUCATION, P3
   Cardullo FM, 2011, P AIAA MOD SIM TECN, DOI 10.2514/6.2011-6349
   Chang CW, 2018, IEEE ACCESS, V6, P66590, DOI 10.1109/ACCESS.2018.2878270
   Cheung R, 2013, COMPUT EDUC, V63, P160, DOI 10.1016/j.compedu.2012.12.003
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Duggan M., 2015, GAMING AND GAMERS
   Eastgate RM, 2015, HUM FACTORS ERGON, P353
   Esteban-Millat I, 2018, INTERACT LEARN ENVIR, V26, P895, DOI 10.1080/10494820.2017.1421560
   Folkinshteyn D., 2016, J INF TECHNOL CASE A, V18, P220, DOI DOI 10.1080/15228053.2016.1275242
   Fussell Stephanie G., 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P2303, DOI 10.1177/1071181319631494
   Fussell S G., 2021, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V65, P1124, DOI [DOI 10.1177/1071181321651096, 10.1177/1071181321651096]
   Fussell SG, 2020, INT J AVIAT AERONAUT, V7
   Gong M., 2004, Journal of Information Systems Education, V15, P365
   Hair JF, 2010, Multivariate data analysis
   Henseler J, 2015, J ACAD MARKET SCI, V43, P115, DOI 10.1007/s11747-014-0403-8
   Hight, 2021, J AVIATION AEROSPACE
   Huang FH, 2020, VIRTUAL REAL-LONDON, V24, P635, DOI 10.1007/s10055-019-00424-7
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jerald J., 2016, VR BOOK HUMAN CENTER
   King WR, 2006, INFORM MANAGE-AMSTER, V43, P740, DOI 10.1016/j.im.2006.05.003
   Kline R.B., 2016, Principles and Practice of Structural Equation Modeling, VFourth
   Koglbauer I., 2016, Cognition, Brain, Behavior, V20, P357
   Landman A, 2018, HUM FACTORS, V60, P793, DOI 10.1177/0018720818779928
   Lee CC, 2018, J AIR TRANSP MANAG, V72, P20, DOI 10.1016/j.jairtraman.2018.07.004
   Lee J, 2019, TELEMAT INFORM, V39, P37, DOI 10.1016/j.tele.2018.12.006
   Leland R, 2009, DOTFAAAM0917
   Lewis C.C., 2013, INT J HIGHER ED, V2, P22, DOI [DOI 10.5430/IJHE.V2N2P22, 10.5430/ijhe.v2n2p22]
   Lewis J., 2018, P INT IND TRAIN SIM
   Lin PH, 2019, INT J HUM-COMPUT INT, V35, P1736, DOI 10.1080/10447318.2019.1571784
   Lindgren R, 2016, COMPUT EDUC, V95, P174, DOI 10.1016/j.compedu.2016.01.001
   Lu JL, 2009, TRANSPORT RES E-LOG, V45, P345, DOI 10.1016/j.tre.2008.09.006
   Macchiarella N.D., 2005, P HUMAN FACTORS ERGO, P2174, DOI DOI 10.1177/154193120504902512
   Macchiarella ND, 2008, J AVIATION AEROSPACE, V18
   Macchiarella ND, 2008, COLLEGIATE AVIATION, V26, DOI 10.1109/dasc.2005.1563375
   Mahalil I, 2020, 8 INT C INF TECHN MU, DOI 10.1109/ICIMU49871.2020.9243571
   Makransky G., 2017, Learning and Instruction, V60, P225, DOI [DOI 10.1016/J.LEARNINSTRUC.2017.12.007, 10.1016/j.learninstruc.2017.12.007]
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   MANIS K, 2018, J BUSINESS RES
   Maraj C.S., 2015, P INT IND TRAIN SIM
   McLean GMT, 2016, INT J AVIAT PSYCHOL, V26, P36, DOI 10.1080/10508414.2016.1235364
   Myers PL, 2020, J INTELL ROBOT SYST, V100, P1617, DOI 10.1007/s10846-020-01232-x
   Palla A., 2018, P INT IND TRAIN SIM
   Pan JY, 2018, J AIR TRANSP MANAG, V69, P38, DOI 10.1016/j.jairtraman.2018.01.006
   Park SY, 2009, EDUC TECHNOL SOC, V12, P150
   Pool DM, 2016, J GUID CONTROL DYNAM, V39, P889, DOI 10.2514/1.G001603
   Reweti S, 2017, J INF TECHNOL EDUC-R, V16, P127, DOI 10.28945/3682
   Richardson C, 2019, INT J AEROSP PSYCHOL, V29, P28, DOI 10.1080/24721840.2019.1596745
   Rogers R.O., 2010, International Journal of Applied Aviation Studies, V10, P153
   Sagnier C, 2020, INT J HUM-COMPUT INT, V36, P993, DOI 10.1080/10447318.2019.1708612
   Shen C. W., 2018, VIRTUAL REAL-LONDON, P1
   Sitzmann T, 2011, PERS PSYCHOL, V64, P489, DOI 10.1111/j.1744-6570.2011.01190.x
   Smith J.W., 2017, P INT IND TRAIN SIM
   Soper D.S., 2020, A-priori Sample Size Calculator for Structural Equation Models
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Taylor H.L., 2005, International Symposium on Aviation Psychology, P736
   Taylor H.L., 2004, AHFD0412FAA0405
   Venkatesh V, 2000, INFORM SYST RES, V11, P342, DOI 10.1287/isre.11.4.342.11872
   Wang Y, 2016, INT J AVIAT AERONAUT, V3, DOI 10.15394/ijaaa.2016.1144
   Westland JC, 2010, ELECTRON COMMER R A, V9, P476, DOI 10.1016/j.elerap.2010.07.003
   Women In Aviation, CONV RAT STUD PIL
   Yang YQ, 2015, IND MANAGE DATA SYST, V115, P253, DOI 10.1108/IMDS-08-2014-0243
   Zaal PMT, 2015, J AIRCRAFT, V52, P1971, DOI 10.2514/1.C033115
NR 71
TC 57
Z9 61
U1 17
U2 99
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 249
EP 267
DI 10.1007/s10055-021-00554-x
EA JUL 2021
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000671652700001
PM 34276237
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Milleville-Pennel, I
   Mars, F
   Pouliquen-Lardy, L
AF Milleville-Pennel, Isabelle
   Mars, Franck
   Pouliquen-Lardy, Lauriane
TI Sharing spatial information in a virtual environment: How do visual cues
   and configuration influence spatial coding and mental workload?
SO VIRTUAL REALITY
LA English
DT Article
DE Common spatial frame of reference; Spatial coding; Mental workload;
   Least collaborative effort; Virtual environments
ID PERSPECTIVE; REPRESENTATIONS
AB When sharing virtual collaborative environments, operators exchange spatial statements that refer to the objects' positions in the virtual space. If operators are to understand each other, they need to develop a common spatial frame of reference and then choose a space coding to describe the objects' positions. In this paper, we consider how the content of a virtual environment can influence communication between users. We designed two studies in which one participant (the speaker) had to indicate the position of one object to another participant (the addressee). The virtual environment was sometimes enriched by additional (proximal and distal) visual cues. In study 1, we considered statements production. We observed that the speakers most often used the avatar of their partner as a spatial reference to indicate a localization in the virtual space (i.e., Addressee-Centered coding) despite it increases their mental workload. Nevertheless, in complex situations, they also used distal cues to speak to the addressees (i.e., Exocentric coding of the space). In study 2, we considered statements comprehension. Addressee-Centered coding and Exocentric coding were used by the speakers in various spatial configurations to indicate the object position. We observed that Exocentric coding is the most difficult to manage for the addressee. These results indicate that speakers implemented the principle of less collaborative effort by adopting a way of exchanging information based on an asymmetrical cognitive cost, taking into consideration each other's difficulties. This allows a balanced mental workload to be maintained between the two operators throughout the task.
C1 [Milleville-Pennel, Isabelle; Mars, Franck; Pouliquen-Lardy, Lauriane] Univ Nantes, LS2N, Cent Nantes, CNRS, BP 92101, F-44321 Nantes 03, France.
C3 Nantes Universite; Ecole Centrale de Nantes; Centre National de la
   Recherche Scientifique (CNRS)
RP Milleville-Pennel, I (corresponding author), Univ Nantes, LS2N, Cent Nantes, CNRS, BP 92101, F-44321 Nantes 03, France.
EM Isabelle.milleville@ls2n.fr
RI Mars, Franck/O-8100-2019
OI Mars, Franck/0000-0002-4140-0049
CR [Anonymous], GROUNDING COMMUNICAT
   Bryant DJ, 1999, Q J EXP PSYCHOL-A, V52, P487, DOI 10.1080/027249899391160
   Bryant DJ, 1999, J EXP PSYCHOL LEARN, V25, P137, DOI 10.1037/0278-7393.25.1.137
   Cegarra J, 2009, EPIQUE 2009, P233
   Chellali A, 2013, VIRTUAL REAL-LONDON, V17, P1, DOI 10.1007/s10055-012-0214-5
   CLARK HH, 1986, COGNITION, V22, P1, DOI 10.1016/0010-0277(86)90010-7
   Duran N, 2016, TOP COGN SCI, V8, P761, DOI 10.1111/tops.12219
   Duran ND, 2011, COGNITION, V121, P22, DOI 10.1016/j.cognition.2011.06.009
   Galati A, 2015, COGNITIVE SCI, V39, P739, DOI 10.1111/cogs.12173
   GAVER W, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P335
   Hegarty M, 2002, INTELLIGENCE, V30, P425, DOI 10.1016/S0160-2896(02)00116-2
   Heldal I, 2005, PRESENCE-VIRTUAL AUG, V14, P563, DOI 10.1162/105474605774918679
   Hindmarsh J., 1998, ACM 1998 Conference on Computer Supported Cooperative Work. Proceedings. CSCW 98, P217, DOI 10.1145/289444.289496
   Hoc JH, 2001, INT J HUM-COMPUT ST, V54, P509, DOI 10.1006/ijhc.2000.0454
   McNamara TP, 2003, LECT NOTES COMPUTER
   Michelon P, 2006, PERCEPT PSYCHOPHYS, V68, P327, DOI 10.3758/BF03193680
   Mou WM, 2006, J EXP PSYCHOL LEARN, V32, P1274, DOI 10.1037/0278-7393.32.6.1274
   Pouliquen-Lardy L, 2016, VIRTUAL REAL-LONDON, V20, P213, DOI 10.1007/s10055-016-0294-8
   Pouliquen-Lardy L, 2015, COGN PROCESS, V16, pS337, DOI 10.1007/s10339-015-0672-2
   Schroeder R, 2006, PRESENCE-VIRTUAL AUG, V15, P655, DOI 10.1162/pres.15.6.655
   Spante M, 2004, P 7 INT WORKSH PRES, P190
   Tversky B, 2009, COGNITION, V110, P124, DOI 10.1016/j.cognition.2008.10.008
   VANDENBERG SG, 1978, PERCEPT MOTOR SKILL, V47, P599, DOI 10.2466/pms.1978.47.2.599
NR 23
TC 2
Z9 4
U1 2
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 695
EP 712
DI 10.1007/s10055-020-00430-0
EA MAR 2020
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000562539000001
DA 2024-07-18
ER

PT J
AU Pollard, KA
   Oiknine, AH
   Files, BT
   Sinatra, AM
   Patton, D
   Ericson, M
   Thomas, J
   Khooshabeh, P
AF Pollard, Kimberly A.
   Oiknine, Ashley H.
   Files, Benjamin T.
   Sinatra, Anne M.
   Patton, Debbie
   Ericson, Mark
   Thomas, Jerald
   Khooshabeh, Peter
TI Level of immersion affects spatial learning in virtual environments:
   results of a three-condition within-subjects study with long
   intersession intervals
SO VIRTUAL REALITY
LA English
DT Article
DE Spatial learning; Virtual reality; Longitudinal design; Immersion;
   Head-mounted display; Spatial audio
ID HEAD-MOUNTED DISPLAY; DESK-TOP; PEDAGOGICAL AGENTS; REALITY; KNOWLEDGE;
   SYSTEM; ENOUGH
AB Virtual reality and immersive technologies are used in a variety of learning and training applications. However, higher levels of immersion do not always improve learning. The mixed results in the literature may partly arise from the use of between-subjects designs, insufficient time intervals between sessions in within-subjects designs, and/or overreliance on binary comparisons of immersion levels. Our study examined the influence of three levels of audiovisual immersive technology on spatial learning in virtual environments, using a within-subjects design with long intersession intervals. Performance on object recognition and discrimination was improved in the highest immersion condition, whereas performance on directional bearings showed a U-shaped relationship with level of immersion. Examination of our data suggests that these results likely would not have been found had we used a between-subjects design or a binary comparison, thus demonstrating the value of our approach. Results suggest that different levels of immersion may be better suited to more or less cognitively complex types of spatial learning. We discuss challenges and opportunities for future work.
C1 [Pollard, Kimberly A.; Files, Benjamin T.; Khooshabeh, Peter] US Army, Combat Capabil Dev Command, Res Lab, Los Angeles, CA 90017 USA.
   [Oiknine, Ashley H.; Khooshabeh, Peter] Univ Calif Santa Barbara, Dept Psychol & Brain Sci, Santa Barbara, CA 93106 USA.
   [Oiknine, Ashley H.] DCS Corp, Los Angeles, CA USA.
   [Sinatra, Anne M.] Combat Capabil Dev Command Soldier Ctr, Simulat & Training Technol Ctr, Orlando, FL USA.
   [Patton, Debbie] Data & Anal Ctr, Combat Capabil Dev Command, Aberdeen Proving Ground, MD USA.
   [Ericson, Mark] US Army, Combat Capabil Dev Command, Res Lab, Aberdeen Proving Ground, MD USA.
   [Thomas, Jerald] Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.
C3 United States Department of Defense; US Army Research, Development &
   Engineering Command (RDECOM); US Army Research Laboratory (ARL);
   University of California System; University of California Santa Barbara;
   United States Department of Defense; US Army Research, Development &
   Engineering Command (RDECOM); US Army Research Laboratory (ARL);
   University of Minnesota System; University of Minnesota Twin Cities
RP Pollard, KA (corresponding author), US Army, Combat Capabil Dev Command, Res Lab, Los Angeles, CA 90017 USA.
EM kimberly.a.pollard.civ@mail.mil; aoiknine@dcscorp.com;
   benjamin.t.files.civ@mail.mil; anne.m.sinatra.civ@mail.mil;
   debra.j.patton4.civ@mail.mil; mark.a.ericson.civ@mail.mil;
   thoma891@d.umn.edu; peter.khooshabehadeh2.civ@mail.mil
OI Pollard, Kimberly/0000-0002-5849-1987; Thomas,
   Jerald/0000-0002-0931-6920
FU United States Army Research Laboratory's Human Sciences Campaign
FX We thank Jason Moss and Antony D. Passaro who contributed to the
   conceptualization and development of the study, and Bianca Dalangin who
   helped conduct the study. This work was funded by the United States Army
   Research Laboratory's Human Sciences Campaign. The views and conclusions
   contained in this document are those of the authors and should not be
   interpreted as representing the official policies, either expressed or
   implied, of the Army Research Laboratory or U.S. Government. The U.S.
   Government is authorized to reproduce and distribute reprints for
   Government purposes notwithstanding any copyright notation herein.
CR Alexander A.L., 2005, DARWARS Training Impact Group, V5, P1, DOI [DOI 10.1016/J.ATHORACSUR.2004.02.012, DOI 10.5171/2012.800962]
   Andre A.D., 1995, ERGON DES, V3, P10, DOI 10.1177/106480469500300403
   Andreasen A, 2019, IEEE T VIS COMPUT GR, V25, P1876, DOI 10.1109/TVCG.2019.2898787
   [Anonymous], 2016, THESIS
   Baylor A.L., 2003, P WORLD C ED MULTIME, P452
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Boccia M, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00574
   Bowman DA, 2009, JOINT VIRT REAL C EG
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brown RB, 2016, ENHANCING REALISTIC
   Carlson G, 2019, ADV INTELL SYST, V785, P108, DOI 10.1007/978-3-319-93882-0_11
   Chandrasiri A, 2020, VIRTUAL REAL-LONDON, V24, P143, DOI 10.1007/s10055-019-00380-2
   Cho Y.H., 2018, THESIS
   Christensen C, 2016, SYMP LARG DATA ANAL, P1, DOI 10.1109/LDAV.2016.7874304
   Craig SD, 2002, J EDUC PSYCHOL, V94, P428, DOI 10.1037//0022-0663.94.2.428
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Darken RP, 2002, HUM FAC ER, P493
   Davis ET, 1999, HUM FAC ERG SOC P, P1197
   Files BT, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00726
   Files BT, 2019, P APPL HUM FACT ERG
   Frechette C., 2010, Journal of Media Psychology: Theories, Methods Applications, V22, P61, DOI DOI 10.1027/1864-1105/A000009
   Freeman A., 2016, NMC technology outlook for Cooperative 4-H Extension. 2016-2021: A Horizon Project sector report
   Government Accountability Office USGAO, 2016, ARM TRAIN EFF ADJ TR
   Horowitz J, 2018, WALMART BUYS 17000 O
   Hsieh TJ, 2018, COMM COM INF SC, V852, P38, DOI 10.1007/978-3-319-92285-0_6
   Huang Y, 2015, ANN MED SURG, V4, P1, DOI 10.1016/j.amsu.2014.07.006
   Jeelani I, 2017, COMPUTING IN CIVIL ENGINEERING 2017: SENSING, SIMULATION, AND VISUALIZATION, P407
   Jeffs T.L., 2010, Themes in science and technology education, V2, P253
   Kasap Z, 2012, VISUAL COMPUT, V28, P87, DOI 10.1007/s00371-011-0630-7
   Khooshabeh P, 2017, P IEEE VIRT REAL ANN, P333, DOI 10.1109/VR.2017.7892312
   Kraemer DJM, 2017, J EXP PSYCHOL LEARN, V43, P611, DOI 10.1037/xlm0000314
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Landers RN, 2014, SIMULAT GAMING, V45, P769, DOI 10.1177/1046878114563662
   Landers RN, 2014, SIMULAT GAMING, V45, P752, DOI 10.1177/1046878114563660
   Lanyi C.S., 2006, The International Journal of Virtual Reality, V5, P55
   Lee KM, 2005, MEDIA PSYCHOL, V7, P31, DOI 10.1207/S1532785XMEP0701_2
   Lewis T, 2017, VIRTUAL REALITY HELP
   Mania K, 2001, CYBERPSYCHOL BEHAV, V4, P247, DOI 10.1089/109493101300117938
   Mania K, 2006, FIDELITY METRICS VIR, DOI DOI 10.1162/105474603765879549
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   McMahan Ryan P., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P59, DOI 10.1007/978-3-319-39907-2_6
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Mizell DW, 2002, TECHNICAL REPORT
   Moreno R, 2004, J EDUC PSYCHOL, V96, P165, DOI 10.1037/0022-0663.96.1.165
   Moreno R, 2000, J EDUC PSYCHOL, V92, P724, DOI 10.1037//0022-0663.92.4.724
   Morey RD, 2008, TUTOR QUANT METHODS, V4, P61, DOI 10.20982/tqmp.04.2.p061
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Moss JD, 2011, DISPLAYS, V32, P159, DOI 10.1016/j.displa.2011.05.010
   Mossel A, 2017, P IEEE VIRT REAL ANN, P357, DOI 10.1109/VR.2017.7892324
   Nys M, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01522
   Oiknine A, 2019, WEB BASED MEASUREMEN, P1
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Patton D, 2016, LECT NOTES ARTIF INT, V9743, P372, DOI 10.1007/978-3-319-39955-3_35
   Patton D, 2014, LECT NOTES COMPUT SC, V8534, P245, DOI 10.1007/978-3-319-07527-3_23
   Picciano A., 2002, Journal of Asynchronous Learning Networks, V6, P20
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Regan C., 1995, VIRTUAL REAL-LONDON, V1, P17, DOI DOI 10.1007/BF02009710
   Ruminski D, 2015, VIRTUAL REAL-LONDON, V19, P223, DOI 10.1007/s10055-015-0274-4
   Schomaker J, 2015, NEUROSCI BIOBEHAV R, V55, P268, DOI 10.1016/j.neubiorev.2015.05.002
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Siegel A W, 1975, Adv Child Dev Behav, V10, P9, DOI 10.1016/S0065-2407(08)60007-5
   Sinatra AM, 2019, LECT NOTES COMPUT SC, V11597, P340, DOI 10.1007/978-3-030-22341-0_27
   Sintia R, 2018, US NEWS
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Stansfield S, 1998, P IEEE VIRT REAL ANN, P198, DOI 10.1109/VRAIS.1998.658490
   STERN E, 1988, GEOGR ANAL, V20, P140
   Stevens J, 2015, J DEF MODEL SIMUL-AP, V12, P519, DOI 10.1177/1548512915569742
   Summers J.E., 2012, J. Wash. Acad. Sci, V98, P9
   Swindells C, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P420, DOI 10.1109/CGI.2004.1309243
   Taillade M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067193
   Taylor GS, 2013, HUM FACTORS, V55, P672, DOI 10.1177/0018720812466892
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   Tong X, 2016, STUD HEALTH TECHNOL, V220, P424, DOI 10.3233/978-1-61499-625-5-424
   Tse A., 2017, Was I There?: Impact of Platform and Headphones on 360 Video Immersion, P2967, DOI [10.1145/3027063.3053225, DOI 10.1145/3027063.3053225]
   van der Ham IJM, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00637
   Von Der Putten A.M., 2009, 12 ANN INT WORKSH PR
   Walker A., 2009, Human Factors and Ergonomics Society Annual Meeting Proceedings, V53, P1206, DOI DOI 10.1177/154193120905301809
   Waller D, 1998, PRESENCE-TELEOP VIRT, V7, P129, DOI 10.1162/105474698565631
   Wang N, 2008, INT J HUM-COMPUT ST, V66, P98, DOI 10.1016/j.ijhcs.2007.09.003
   Wang X, 2004, P 21 INT S AUT ROB C, P393
   Warton DI, 2011, ECOLOGY, V92, P3, DOI 10.1890/10-0340.1
   Wei L, 2019, VIRTUAL REAL-LONDON, V23, P217, DOI 10.1007/s10055-018-0349-0
   Witmer B.G., 1995, Technical Report 1022
   Zhong JY, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00122
   Zhou ZY, 2004, INTERACT COMPUT, V16, P1043, DOI 10.1016/j.intcom.2004.06.016
NR 88
TC 24
Z9 27
U1 1
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 783
EP 796
DI 10.1007/s10055-019-00411-y
EA FEB 2020
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000517004400002
DA 2024-07-18
ER

PT J
AU Abdullah, J
   Mohd-Isa, WN
   Samsudin, MA
AF Abdullah, Junaidi
   Mohd-Isa, Wan Noorshahida
   Samsudin, Mohd Ali
TI Virtual reality to improve group work skill and self-directed learning
   in problem-based learning narratives
SO VIRTUAL REALITY
LA English
DT Article
DE Problem-based learning; Virtual reality; VR scenario; Biodiversity;
   Self-directed learning; Learning interaction
ID STUDENTS
AB Problem-based learning (PBL) is a type of student-centred educational approach where students learn a topic via their experience in solving open-ended problems. In PBL, elements of active, interactive, and collaborative learning are incorporated to allow teachers to observe their students' learning process. The contexts of problems in PBL are in the form of cases and narratives of the real world where there are no right or wrong answers. Virtual reality (VR) is a part of mixed reality where a real-world environment is made to be virtual online. In VR, real-world elements are rendered as 3D objects. By adopting VR technologies in PBL, this will enable teachers to form virtual world narratives and cases akin to problems in a real world. VR allows elements of active, interactive, and collaborative to be integrated in students' learning process. This study explores how VR may be adopted to enable PBL and improve group work skill as well as self-directed learning. The gained research results indicated that PBL with the presentation problem scenario in VR environment is effective in enhancing the group work skills and self-directed learning among students.
C1 [Abdullah, Junaidi; Mohd-Isa, Wan Noorshahida] Multimedia Univ, Cyberjaya, Malaysia.
   [Samsudin, Mohd Ali] Univ Sains Malaysia, George Town, Malaysia.
C3 Multimedia University; Universiti Sains Malaysia
RP Abdullah, J (corresponding author), Multimedia Univ, Cyberjaya, Malaysia.
EM junaidi.abdullah@mmu.edu.my; wan.noorshahida@mmu.edu.my;
   alisamsudin@usm.my
RI Samsudin, Mohd Ali/I-2343-2012; Abdullah, Junaidi/AAU-2731-2021;
   Mohd-Isa, Wan-Noorshahida/B-3677-2010
OI Samsudin, Mohd Ali/0000-0001-8231-5775; Mohd-Isa,
   Wan-Noorshahida/0000-0001-9060-0250; Abdullah,
   Junaidi/0000-0001-8820-2472
CR Abdelkhalek N, 2010, MED TEACH, V32, P123, DOI 10.3109/01421590903548539
   [Anonymous], THESIS
   [Anonymous], 1997, The Challenge of Problem-Based Learning
   Antepohl W, 2003, MED EDUC, V37, P155, DOI 10.1046/j.1365-2923.2003.01401.x
   Baptiste S., 2003, Problem-based learning: A self-directed journey
   Barrows HS., 1980, Problem-based learning: An approach to medical education
   Berge Z, 2016, COMPUTER MEDIATED CO
   Campbell DT., 1963, EXPT QUASIEXPERIMENT
   Creedy D., 1997, The challenge of problem-based learning, V2nd, P218
   Derry SJ, 1999, RUTG INV SYMP EDUC S, P197
   Dewey J., 1989, JOHN DEWEY, V9, P1
   Driver R., 1994, Educational Researcher, V23, P5, DOI [DOI 10.3102/0013189X023007005, 10.2307/1176933, DOI 10.2307/1176933]
   Grady R, 2009, EUR J DENT EDUC, V13, P190, DOI 10.1111/j.1600-0579.2009.00572.x
   Harlen, 2006, TEACHING LEARNING AS, P5
   Heard MJ, 2016, AM BIOL TEACH, V78, P733, DOI 10.1525/abt.2016.78.9.733
   Jonassen D, 1999, INSTRUCTIONAL-DESIGN THEORIES AND MODELS, VOL II, P215
   Kalina CJ., 2009, Education, V130, P241, DOI DOI 10.1037/0022-0663.93.3.571
   Knowles M.S., 1975, J CONTIN EDUC NURS
   Lambros A., 2004, PROBLEM BASED LEARNI
   Lateh H, 2010, PROCD SOC BEHV, V2, P1896, DOI 10.1016/j.sbspro.2010.03.1005
   McMahon M., 1997, ASCILITE conference, V327
   Nelson LM, 1999, INSTRUCTIONAL-DESIGN THEORIES AND MODELS, VOL II, P241
   Osman K, 2013, P WSEAS C REC ADV ED, P67
   Othman S, 2013, PHILOS STUDENT CENTR
   Phang L, 2011, THESIS
   Rajkoomar M., 2016, Research Reviews: Journal of Educational Studies, V2, P1
   Reeves S., 2004, BRIT J OCCUP THER, V67, P323, DOI DOI 10.1177/030802260406700707
   Rideout E., 2001, TRANSFORMING NURSING
   Samsudin MA, 2009, P 2 INT PBL S, P247
   Savin-Baden M., 2000, PROBLEM BASED LEARNI
   Savin-Baden M., 2004, FDN PROBLEM BASED LE
   Schmidt HG, 2000, PROBLEM-BASED LEARNING, P19
   Seymour A, 2013, J FURTH HIGH EDUC, V37, P1, DOI 10.1080/0309877X.2011.643774
   Shea P., 2007, Blended Learning Research Perspectives, P19
   Suh S, 2005, THESIS
   Tarhan L., 2007, Research in Science Technological Education, V25, P351, DOI [10.1080/02635140701535299, 10.1080/02635140701535299., DOI 10.1080/02635140701535299]
   Tatar E, 2011, RES SCI TECHNOL EDUC, V29, P315, DOI 10.1080/02635143.2011.599318
   Vygotsky L.S., 1978, MIND SOC DEV HIGHER, P57
   Wilkie K., 2000, Problem based learning in nursing: A new model for a new context? icinde s, P11
   Zimmerman B.J., 2001, Self-regulated learning and academic achievement: Theoretical perspectives, V2nd, P322
NR 40
TC 32
Z9 35
U1 4
U2 104
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 461
EP 471
DI 10.1007/s10055-019-00381-1
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300012
DA 2024-07-18
ER

PT J
AU Kawulich, BB
   D'Alba, A
AF Kawulich, Barbara B.
   D'Alba, Adriana
TI Teaching qualitative research methods with Second Life, a 3-dimensional
   online virtual environment
SO VIRTUAL REALITY
LA English
DT Article
DE Qualitative and ethnographic research; Pedagogical tools; Virtual
   environments for learning; Teaching online
ID WORLDS; NETNOGRAPHY
AB Since the 1950s, 3-dimensional virtual environments (3DVEs) have been developed to simulate real-world experiences. These virtual worlds have evolved with realistic graphics and large numbers of users with whom to engage in virtual representations of real-life situations. This study investigated how students perceived the usefulness of Second Life (SL) as a tool for teaching research methods to a doctoral-level qualitative research class. Two classes of doctoral students were assigned to groups of three students and were charged with conducting an ethnographic study in a SL community. Students conducted observations and interviews of community members as a simulation of conducting ethnographic research in an unfamiliar culture. Data sources included an end-of-course survey, observation field notes, interview transcriptions, journals, discussion board posts, and video conferencing. Nineteen students agreed to have their data included for analysis. Results indicate that SL provided an innovative means for teaching important aspects of qualitative research, such as securing key informants, gatekeeping, observing and taking field notes, and interviewing, among others. Students experienced the affective aspects of conducting research as well, including how to handle rejection and frustration, the need for flexibility, interacting in a strange world, and how to handle awkward situations, sometimes with hilarious results. While the majority of students found SL to be an innovative way to learn research skills, a few experienced technical glitches, causing frustration that hindered their learning. Students created a list of tips for new users of SL to ease their transition into the virtual environment.
C1 [Kawulich, Barbara B.; D'Alba, Adriana] Univ West Georgia, 1601 Maple St, Carrollton, GA 30118 USA.
C3 University System of Georgia; University of West Georgia
RP Kawulich, BB (corresponding author), Univ West Georgia, 1601 Maple St, Carrollton, GA 30118 USA.
EM bkawulic@westga.edu; adalba@westga.edu
RI Kawulich, Barbara/ABC-7393-2020
CR Angrosino Michael., 2007, DOING ETHNOGRAPHIC O
   [Anonymous], 2000, The Virtual Community, revised edition: Homesteading on the Electronic Frontier
   [Anonymous], 1996, Computer-mediated communication: Linguistic, social, and crosscultural perspectives
   Anstadt SP, 2013, INT REV RES OPEN DIS, V14, P160
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Boellstorff T, 2008, COMING OF AGE IN SECOND LIFE: AN ANTHROPOLOGIST EXPLORES THE VIRTUALLY HUMAN, P1
   Botterbusch HR, 2008, TECHTRENDS, V52, P7
   Boulos MNK, 2007, HEALTH INFO LIBR J, V24, P233, DOI 10.1111/J.1471-1842.2007.00733.x
   Bowler GM, 2010, QUAL REP, V15, P1270
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Duffy T.M., 1996, HDB RES ED COMMUNICA
   Felix U., 2005, ReCALL, V17, P85, DOI 10.1017/S0958344005000716
   Fetterman D.M., 1998, ETHNOGRAPHY STEP STE
   Fosnot CT., 1996, Constructivism: Theory, perspectives, and practice, P8
   Hine C., 2000, Virtual ethnography
   Houliez C, 2013, VIRTUAL REAL-LONDON, V17, P263, DOI 10.1007/s10055-012-0218-1
   JANESICK VJ, 1983, ANTHROPOL EDUC QUART, V14, P198, DOI 10.1525/aeq.1983.14.3.05x1709s
   Jarmon L, 2008, EDUC MEDIA INT, V45, P157, DOI 10.1080/09523980802283889
   Kawulich BB., 2017, The BERA/SAGE handbook of educational research
   Langer R, 2005, QUAL MARK RES, V8, P189, DOI 10.1108/13522750510592454
   LeCompte M.D., 2010, Designing and Conducting Ethnographic Research, V2nd
   Minocha S., 2008, RES LEARN TECHNOL, V16, P181, DOI [DOI 10.1080/09687760802526699, 10.1080/09687760802526699]
   O'Donohoe S, 2010, INT J ADVERT, V29, P328, DOI 10.2501/S026504871020118X
   Paccagnella L, 1997, J COMPUT-MEDIAT COMM, V3, P267
   Parks MR, 1996, J COMMUN, V46, P80, DOI 10.1111/j.1460-2466.1996.tb01462.x
   Phillips D.C., 1995, Educational Researcher, V24, P5, DOI DOI 10.3102/0013189X024007005
   Rheingold H., 1991, VIRTUAL REAL-LONDON
   Sade-Beck Liav., 2004, International Journal of Qualitative Methods, V3, P45
   Sangasubana N, 2011, QUAL REP, V16, P567
   Schoonheim M, 2014, BMC MED EDUC, V14, DOI 10.1186/1472-6920-14-36
   Singleton R. A., 2005, APPROACHES SOCIAL RE
   Vygotsky L. S., 1978, Mind in Society: The Development of Higher Psychological Processes, DOI 10.2307/j.ctvjf9vz4
   Warburton S, 2009, BRIT J EDUC TECHNOL, V40, P414, DOI 10.1111/j.1467-8535.2009.00952.x
   Wittel A, 2002, FORUM QUAL SOC RES, V1
   Wright KB, 2005, J COMPUT-MEDIAT COMM, V10
   Xun J., 2010, J TARGETING MEASUREM, V18, P17, DOI [10.1057/jt.2009.29, DOI 10.1057/JT.2009.29]
   Yee N, 2007, CYBERPSYCHOL BEHAV, V10, P115, DOI 10.1089/cpb.2006.9984
NR 37
TC 14
Z9 20
U1 2
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 375
EP 384
DI 10.1007/s10055-018-0353-4
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300005
DA 2024-07-18
ER

PT J
AU Mittelstaedt, JM
   Wacker, J
   Stelling, D
AF Mittelstaedt, Justin Maximilian
   Wacker, Jan
   Stelling, Dirk
TI VR aftereffect and the relation of cybersickness and cognitive
   performance
SO VIRTUAL REALITY
LA English
DT Article
DE Cybersickness; Cognitive performance; Head-mounted displays; Reaction
   times
ID DRIVING PERFORMANCE; SIMULATOR SICKNESS; SEX-DIFFERENCES; MOTION; TASK
AB The purpose of the study was the investigation of VR-induced aftereffects on various basic cognitive abilities and its relationship with cybersickness. Previous studies suggest an adverse effect of VR exposure on simple reaction times. Aftereffects on other basic cognitive abilities have rarely been studied. Sixty participants performed a test battery, that consisted of five different tests, prior and after the immersion into a VR bike application. Participants were assigned to three different experimental conditions using different kinds of displays, motion control devices. Twenty additional participants acted as a control group. Reaction times of simple ((2)(3)=140.77; p<.001) and choice reaction tasks (two choice: (2)(3)=66.87; p<.001; four choice: (2)(3)=55.48; p<.001) deteriorated after VR exposure but remained stable or improved in the control group not exposed to VR. Changes in performance were only weakly related to degrees of cybersickness (.04<r<.28). We propose a general aftereffect of VR exposure on reaction times that is only slightly related to subjective degrees of cybersickness. Taken together, however, usage of VR systems, even if inducing moderate levels of cybersickness, leads only to minor decrements of cognitive performance.
C1 [Mittelstaedt, Justin Maximilian; Stelling, Dirk] German Aerosp Ctr DLR, Sportallee 54a, D-22335 Hamburg, Germany.
   [Wacker, Jan] Univ Hamburg, Edmund Siemers Allee 1, D-20146 Hamburg, Germany.
C3 Helmholtz Association; German Aerospace Centre (DLR); University of
   Hamburg
RP Mittelstaedt, JM (corresponding author), German Aerosp Ctr DLR, Sportallee 54a, D-22335 Hamburg, Germany.
EM justin.mittelstaedt@dlr.de
OI Stelling, Dirk/0000-0003-3346-6141
CR [Anonymous], 1975, Motion sickness
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bertolini G, 2016, FRONT NEUROL, V7, DOI 10.3389/fneur.2016.00014
   Bos JE, 2015, J VESTIBUL RES-EQUIL, V25, P23, DOI 10.3233/VES-150541
   Corsi P.M., 1972, Human memory and the medial temporal region of the brain
   Dahlman J, 2009, HUM FACTORS, V51, P56, DOI 10.1177/0018720809332848
   Deary IJ, 2011, BEHAV RES METHODS, V43, P258, DOI 10.3758/s13428-010-0024-1
   Fernandez-Ruiz J, 2011, BEHAV BRAIN RES, V219, P8, DOI 10.1016/j.bbr.2010.11.060
   Ganis G, 2015, J OPEN PSYCHOL DATA
   GOLDING JF, 1992, AVIAT SPACE ENVIR MD, V63, P491
   Harm DL., 2007, ADAPTIVE CHANGES SEN
   Helland A, 2016, ACCIDENT ANAL PREV, V94, P180, DOI 10.1016/j.aap.2016.05.008
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Johnson DM, 2005, SIMULATOR SICKNESS R
   KENNEDY RS, 1993, AVIAT SPACE ENVIR MD, V64, P912
   Kennedy RS, 1987, AGARD C P, V433
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kessels R P, 2000, Appl Neuropsychol, V7, P252, DOI 10.1207/S15324826AN0704_8
   Klosterhalfen S, 2008, AVIAT SPACE ENVIR MD, V79, P384, DOI 10.3357/ASEM.2187.2008
   Kolasinski EM, 1995, 91027 USA RES I
   Levine ME, 2002, PERCEPT MOTOR SKILL, V95, P425, DOI 10.2466/PMS.95.5.425-431
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Lo S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01171
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Mittelstaedt J, 2018, DISPLAYS, V51, P43, DOI 10.1016/j.displa.2018.01.002
   Mullen NW, 2010, AM J OCCUP THER, V64, P288, DOI 10.5014/ajot.64.2.288
   Muth ER, 2009, HUM FACTORS, V51, P752, DOI 10.1177/0018720809353320
   Muttray A, 2013, INT J OCCUP MED ENV, V26, P949, DOI 10.2478/s13382-013-0164-5
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Parker D E, 1992, Presence (Camb), V1, P329
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701
   Smith AP, 2004, ERGONOMICS, V47, P363, DOI 10.1080/0014013032000157887
   Stoet G, 2011, EVOL HUM BEHAV, V32, P416, DOI 10.1016/j.evolhumbehav.2011.03.001
   Sugano Y, 2010, EXP BRAIN RES, V201, P393, DOI 10.1007/s00221-009-2047-3
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Uliano KC, 1986, 85D00261 NAVTRASYSCE
   Van Den Berg J, 2006, PERCEPT MOTOR SKILL, V102, P589, DOI 10.2466/PMS.102.2.589-599
   Walker AD, 2007, P 51 ANN M HUM FACT
   Waltemate T, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P27, DOI 10.1145/2993369.2993381
   Warner HD, 1993, ALHRTR19930056 AIRCR
   Welford A.T., 1980, REACTION TIME, P321
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3
NR 46
TC 51
Z9 53
U1 2
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2019
VL 23
IS 2
BP 143
EP 154
DI 10.1007/s10055-018-0370-3
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA HZ5RO
UT WOS:000468910500003
DA 2024-07-18
ER

PT J
AU Boylan, P
   Kirwan, GH
   Rooney, B
AF Boylan, Patrick
   Kirwan, Grainne H.
   Rooney, Brendan
TI Self-reported discomfort when using commercially targeted virtual
   reality equipment in discomfort distraction
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Pain distraction; Gaming; Active distraction; Passive
   distraction
ID COLD-PRESSOR PAIN; PHYSICAL-THERAPY; PEDIATRIC BURN; MODULATION
AB Commercially targeted virtual reality (VR) equipment is gaining popularity and might be a viable tool for pain distraction. This experimental research aimed to discover whether active distraction techniques (such as commercially targeted VR and video games) result in reduced subjective discomfort relative to passive distraction techniques. The study examined a healthy adult population who experienced an experimentally induced discomfort task. Participants were 27 adults, 14 females and 13 males. Participants completed four tasks, a baseline measure of physical discomfort, video clip distraction (passive distraction), video game distraction (active distraction) and exploring a VR world using an Oculus Rift head-mounted display (active distraction). In all four test conditions, participants were asked to sit on a chair holding their non-dominant leg at a height of approximately 30 cm from the floor, up to a maximum of 5 min. Counterbalancing of task order was conducted to reduce effects of participant fatigue. The participants indicated significantly reduced self-reported discomfort in the active distraction tasks when compared to the passive distraction tasks. While the findings demonstrate the effectiveness of a commercially targeted VR technology in increasing pain tolerance, the relative benefits of this technology over non-immersive video games are not apparent.
C1 [Boylan, Patrick] Dublin City Univ, Sch Nursing & Human Sci, Dublin, Ireland.
   [Kirwan, Grainne H.] Inst Art Design & Technol, Dept Technol & Psychol, Dun Laoghaire, Dublin, Ireland.
   [Rooney, Brendan] Univ Coll Dublin, UCD Sch Psychol, Dublin, Ireland.
C3 Dublin City University; University College Dublin
RP Kirwan, GH (corresponding author), Inst Art Design & Technol, Dept Technol & Psychol, Dun Laoghaire, Dublin, Ireland.
EM patrick.boylan@dcu.ie; grainne.kirwan@iadt.ie; brendan.rooney@ucd.ie
RI rooney, brendan/U-1041-2019; Boylan, Patrick J/A-5289-2010
OI rooney, brendan/0000-0001-9842-1492; 
CR Castro-Lopes C, 2009, CURR TOP PAIN 12 WOR
   Chan EA, 2007, J CLIN NURS, V16, P786, DOI 10.1111/j.1365-2702.2006.01719.x
   Dahlquist LM, 2007, HEALTH PSYCHOL, V26, P794, DOI 10.1037/0278-6133.26.6.794
   Dahlquist LM, 2010, CYBERPSYCH BEH SOC N, V13, P587, DOI 10.1089/cyber.2009.0263
   Das Debashish A, 2005, BMC Pediatr, V5, P1, DOI 10.1186/1471-2431-5-1
   Gold JI, 2007, CYBERPSYCHOL BEHAV, V10, P536, DOI 10.1089/cpb.2007.9993
   Goossens MEJB, 2005, CLIN J PAIN, V21, P18, DOI 10.1097/00002508-200501000-00003
   Hoffman HG, 2000, CLIN J PAIN, V16, P244, DOI 10.1097/00002508-200009000-00010
   Hoffman HG, 2007, ANESTH ANALG, V105, P1776, DOI 10.1213/01.ane.0000270205.45146.db
   Hoffman HG, 2014, CYBERPSYCH BEH SOC N, V17, P397, DOI 10.1089/cyber.2014.0058
   Hoffman HG, 2011, ANN BEHAV MED, V41, P183, DOI 10.1007/s12160-010-9248-7
   Hoffman HG, 2009, CYBERPSYCHOL BEHAV, V12, P47, DOI 10.1089/cpb.2008.0056
   Jameson E, 2011, PAIN RES MANAG, V16, P27, DOI 10.1155/2011/856014
   Kalso E, 2006, MASSACHUSETTS GEN HO, P28
   Le D, 2011, J PAIN, V12, P79
   Li A, 2011, PAIN MANAG, V1, P147, DOI 10.2217/PMT.10.15
   Mahrer NE, 2009, CURR PAIN HEADACHE R, V13, P100, DOI 10.1007/s11916-009-0019-8
   MCCAUL KD, 1984, PSYCHOL BULL, V95, P516, DOI 10.1037/0033-2909.95.3.516
   MELZACK R, 1965, SCIENCE, V150, P971, DOI 10.1126/science.150.3699.971
   Mühlberger A, 2007, CYBERPSYCHOL BEHAV, V10, P516, DOI 10.1089/cpb.2007.9996
   Schneider SM, 2011, SUPPORT CARE CANCER, V19, P555, DOI 10.1007/s00520-010-0852-7
   SEYREK SK, 1984, J AM DENT ASSOC, V108, P327, DOI 10.14219/jada.archive.1984.0034
   Sil S, 2014, J BEHAV MED, V37, P156, DOI 10.1007/s10865-012-9479-0
   Staats PS, 2001, PAIN MED, V2, P267, DOI 10.1046/j.1526-4637.2001.01046.x
   Sulea Camelia, 2014, Cyberpsychol Behav Soc Netw, V17, P402, DOI 10.1089/cyber.2014.1514
   Villemure C, 2002, PAIN, V95, P195, DOI 10.1016/S0304-3959(02)00007-6
   Wickens CD, 2008, HUM FACTORS, V50, P397, DOI 10.1518/001872008X288420
   WIEDERHOLD BK, 2005, AM PSYCHOL ASS ANN C
   Wiederhold MD, 2007, PAIN MED, V8, pS182, DOI 10.1111/j.1526-4637.2007.00381.x
NR 29
TC 8
Z9 11
U1 0
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2018
VL 22
IS 4
BP 309
EP 314
DI 10.1007/s10055-017-0329-9
PG 6
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA GV4NM
UT WOS:000446076600003
DA 2024-07-18
ER

PT J
AU Crocetta, TB
   de Araújo, LV
   Guarnieri, R
   Massetti, T
   Ferreira, FHIB
   de Abreu, LC
   Monteiro, CBD
AF Crocetta, Tania Brusque
   de Araujo, Luciano Vieira
   Guarnieri, Regiani
   Massetti, Thais
   Inocncio Borba Ferreira, Fernando Henrique
   de Abreu, Luiz Carlos
   de Mello Monteiro, Carlos Bandeira
TI Virtual reality software package for implementing motor learning and
   rehabilitation experiments
SO VIRTUAL REALITY
LA English
DT Article
DE Rehabilitation games; Virtual reality rehabilitation; Man-machine
   interface
ID UPPER-LIMB REHABILITATION; MEASURING REACTION-TIME; VIDEO GAMES; TASK;
   INDIVIDUALS; CHILDREN; BALANCE; DESIGN
AB Virtual reality games for rehabilitation are attracting increasing growth. In particular, there is a demand for games that allow therapists to identify an individual's difficulties and customize the control of variables, such as speed, size, distance, as well as visual and auditory feedback. This study presents and describes a virtual reality software package (Bridge Games) to promote rehabilitation of individuals living with disabilities and highlights preliminary researches of its use for implementing motor learning and rehabilitation. First, the study presents seven games in the software package that can be chosen by the rehabilitation team, considering the patient's needs. All game characteristics are described including name, function presentation, objective and valuable measurements for rehabilitation. Second, preliminary results illustrate some applications of two games, considering 343 people with various disabilities and health status. Based on the results, in the Coincident Timing game, there was a main effect of movement sensor type (in this instance the most functional device was the keyboard when compared with Kinect and touch screen) on average time reached by sample analyzed, F(2, 225) = 4.42, p < 0.05. Similarly, in the Challenge! game, a main effect was found for movement sensor type. However, in this case, touch screen provided better performance than Kinect and Leap Motion, F(2, 709) = 5.90, p < 0.01. Thus, Bridge Games is a possible software game to quantify motor learning. Moreover, the findings suggest that motor skills might be practiced differently depending on the environmental interface in which the game may be used.
C1 [Crocetta, Tania Brusque; Guarnieri, Regiani; de Abreu, Luiz Carlos; de Mello Monteiro, Carlos Bandeira] FMABC, Ave Principe Gales 821, BR-09060650 Santo Andre, SP, Brazil.
   [de Araujo, Luciano Vieira; Inocncio Borba Ferreira, Fernando Henrique; de Mello Monteiro, Carlos Bandeira] Univ Sao Paulo, EACH, Rua Arlindo Bettio 1000, BR-03828000 Sao Paulo, SP, Brazil.
   [Massetti, Thais] Univ Sao Paulo, Programa Posgrad Ciencias Reabilitacao, Fac Med, Rua Cipotanea 51,Cidade Univ, BR-05360160 Sao Paulo, SP, Brazil.
C3 Faculdade de Medicina do ABC; Universidade de Sao Paulo; Universidade de
   Sao Paulo
RP Crocetta, TB (corresponding author), FMABC, Ave Principe Gales 821, BR-09060650 Santo Andre, SP, Brazil.
EM tania.crocetta@udesc.br; lvaraujo@usp.br; regianig1@gmail.com;
   thaismassetti@terra.com.br; fer.henrique@gmail.com; cdh.fsp@gmail.com;
   carlosfisi@uol.com.br
RI Massetti, Thais/W-1111-2018; de Abreu, Luiz Carlos/AAL-8219-2021; de
   Mello Monteiro, Carlos Bandeira/P-2474-2016; Crocetta, Tania
   B/I-6179-2017
OI de Abreu, Luiz Carlos/0000-0002-7618-2109; de Mello Monteiro, Carlos
   Bandeira/0000-0002-2661-775X; Crocetta, Tania B/0000-0001-7670-8943
FU UNIEDU Post graduation Program, Santa Catarina State, Brazil
FX The author TBC gratefully acknowledge grant financial support from
   UNIEDU Post graduation Program, Santa Catarina State, Brazil.
CR Anderson F, 2010, STUD HEALTH TECHNOL, V154, P229, DOI 10.3233/978-1-60750-561-7-229
   Anderson Kelly R, 2015, Arch Phys Med Rehabil, V96, P973, DOI 10.1016/j.apmr.2014.09.008
   Bieryla KA, 2016, AGING CLIN EXP RES, V28, P451, DOI 10.1007/s40520-015-0452-y
   Bonnechere B, 2017, INT J SERIOUS GAMES, V4, P3, DOI 10.17083/ijsg.v4i1.121
   Antunes TPC, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000005954
   CRABTREE DA, 1988, PERCEPT MOTOR SKILL, V66, P363, DOI 10.2466/pms.1988.66.2.363
   Crocetta Tânia Brusque, 2015, Fisioter. mov., V28, P823, DOI 10.1590/0103-5150.028.004.AR01
   Crocetta TB, 2015, REV PSICOL DEPORTE, V24, P341
   da Gama A., 2012, 2012 14th Symposium on Virtual and Augmented Reality (SVR), P191, DOI 10.1109/SVR.2012.15
   da Silva TD, 2015, PARALISIA CEREBRAL T, P484
   Monteiro CBD, 2017, BMC NEUROL, V17, DOI 10.1186/s12883-017-0852-z
   Monteiro CBD, 2014, RES DEV DISABIL, V35, P2430, DOI 10.1016/j.ridd.2014.06.006
   Herrero D., 2015, INT J NEUROREHABILIT, V02, P1, DOI 10.4172/2376-0281.1000189
   Hocine N, 2015, USER MODEL USER-ADAP, V25, P65, DOI 10.1007/s11257-015-9154-6
   Hondori HM, 2016, NEUROREHAB NEURAL RE, V30, P258, DOI 10.1177/1545968315593805
   IWASAKI Y, 1990, ACTA NEUROL SCAND, V81, P141
   Juanes JA, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0495-4
   Kim R, 2013, PERCEPT MOTOR SKILL, V117, P319, DOI 10.2466/10.23.PMS.117x17z9
   Levac D, 2015, PHYS THER, V95, P426, DOI 10.2522/ptj.20130618
   Lohse K, 2013, J NEUROL PHYS THER, V37, P166, DOI 10.1097/NPT.0000000000000017
   Lv ZH, 2016, NEUROCOMPUTING, V208, P290, DOI 10.1016/j.neucom.2015.12.128
   [Microsoft Library N. F. C.], 2015, TIM CLASS NET FRAM 4
   Mousavi Hondori Hossein, 2014, J Med Eng, V2014, P846514, DOI 10.1155/2014/846514
   Nooijen CFJ, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0004-x
   Pastor I, 2012, IEEE ENG MED BIO, P1286, DOI 10.1109/EMBC.2012.6346173
   Patrizia M, 2009, INT C REHAB ROBOT, P1070
   Malheiros SRP, 2016, NEUROPSYCH DIS TREAT, V12, P41, DOI 10.2147/NDT.S87735
   Rodrigues PC, 2009, EUR J SPORT SCI, V9, P115, DOI 10.1080/17461390802603903
   Stanmore E, 2017, NEUROSCI BIOBEHAV R, V78, P34, DOI 10.1016/j.neubiorev.2017.04.011
   Thomson K, 2014, INT J STROKE, V9, P479, DOI 10.1111/ijs.12263
NR 30
TC 29
Z9 29
U1 1
U2 50
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2018
VL 22
IS 3
BP 199
EP 209
DI 10.1007/s10055-017-0323-2
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GP1TD
UT WOS:000440598900002
DA 2024-07-18
ER

PT J
AU Lara, G
   De Antonio, A
   Peña, A
AF Lara, Graciela
   De Antonio, Angelica
   Pena, Adriana
TI A computational model of perceptual saliency for 3D objects in virtual
   environments
SO VIRTUAL REALITY
LA English
DT Article
DE Reference object; Perceptual salience; Virtual environment; 3D object's
   features extraction
ID STRUCTURAL SALIENCE; COLOR; LANDMARKS
AB When giving directions to the location of an object, people typically use other attractive objects as reference, that is, reference objects. With the aim to select proper reference objects, useful for locating a target object within a virtual environment (VE), a computational model to identify perceptual saliency is presented. Based on the object's features with the major stimulus for the human visual system, three basic features of a 3D object (i.e., color, size, and shape) are individually evaluated and then combined to get a degree of saliency for each 3D object in a virtual scenario. An experiment was conducted to evaluate the extent to which the proposed measure of saliency matches with the people's subjective perception of saliency; the results showed a good performance of this computational model.
C1 [Lara, Graciela; Pena, Adriana] Univ Guadalajara, CUCEI, Ave Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
   [De Antonio, Angelica] Univ Politecn Madrid, Escuela Tecn Super Ingn Informat, Campus Montegancedo, Boadilla Del Monte 28660, Spain.
C3 Universidad de Guadalajara; Universidad Politecnica de Madrid
RP Peña, A (corresponding author), Univ Guadalajara, CUCEI, Ave Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
EM graciela.lara@red.cucei.udg.mx; angelica@fi.upm.es;
   adriana.pena@cucei.udg.mx
RI Peña Pérez Negrón, Adriana/AFK-8243-2022; de Antonio,
   Angélica/B-2584-2009
OI Peña Pérez Negrón, Adriana/0000-0001-6823-2367; de Antonio,
   Angélica/0000-0002-8936-9095
FU UDG, Mexico [UDG-685]
FX Graciela Lara holds a PROMEP scholarship in partnership with the UDG
   (UDG-685), Mexico. We also thank the students Adrian Calle Murillo,
   Roberto Mendoza Vasquez, and Alvaro Iturmendi Munoz for their help in
   the implementation of the metric and the experimental software
   application and materials.
CR [Anonymous], 1982, COLOR SCI CONCEPTS M
   [Anonymous], 2006, MANAGE DECIS, DOI [10.1108/00251740610673332, DOI 10.1108/00251740610673332]
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Byron Donna, 2007, THESIS
   Caduff D, 2008, COGN PROCESS, V9, P249, DOI 10.1007/s10339-007-0199-2
   Cheng G., 2008, TRANSPORTATION RES B, P1
   CHOUNGOURIAN A, 1968, PERCEPT MOTOR SKILL, V26, P1203, DOI 10.2466/pms.1968.26.3c.1203
   Connolly C, 1997, IEEE T IMAGE PROCESS, V6, P1046, DOI 10.1109/83.597279
   de I'Eclairage CI, 1978, CIE PUBLICATION, V15, p[1971, 1]
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Gapp KP, 1995, LECT NOTES COMPUT SC, V988, P519
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2006, VIS COGN, V14, P959, DOI 10.1080/13506280500195672
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Klippel A, 2005, LECT NOTES COMPUT SC, V3693, P347
   Lara G, 2016, ADV INTELL SYST, V405, P235, DOI 10.1007/978-3-319-26285-7_20
   Li J, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.86
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   López F, 2005, LECT NOTES COMPUT SC, V3523, P666
   MANGOLD R, 1986, SENSORISCHE FAKTOREN
   Oliva A., 2003, Image Processing, V1, P1
   Raubal M., 2002, Geographic Information Science. Second International Conference, GIScience 2002. Proceedings (Lecture Notes in Computer Science Vol.2478), P243
   Röser F, 2012, J SPAT SCI, V57, P37, DOI 10.1080/14498596.2012.686362
   Röser F, 2011, COGN PROCESS, V12, P209, DOI 10.1007/s10339-011-0390-3
   Roser F., 2013, Experimental Psychology and Cognitive Science, P3315
   Rossel RAV, 2006, GEODERMA, V133, P320, DOI 10.1016/j.geoderma.2005.07.017
   Saleh A, 2003, PROCEEDINGS OF THE 46TH IEEE INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS & SYSTEMS, VOLS 1-3, P1575
   Sampedro MJ, 2010, ENFOQUE PLURIDISCIPL, P91
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Song R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2530691
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Undurraga C, 2010, MODELO SALIENCIA UTI
   Undurraga C, 2011, LECT NOTES COMPUT SC, V7042, P141, DOI 10.1007/978-3-642-25085-9_16
   Wu JL, 2013, GRAPH MODELS, V75, P255, DOI 10.1016/j.gmod.2013.05.002
   Yitian Zhao, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P108, DOI 10.1007/978-3-642-40246-3_14
   Yuan JCC, 2007, J PROSTHET DENT, V98, P110, DOI 10.1016/S0022-3913(07)60044-4
NR 38
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2018
VL 22
IS 3
BP 221
EP 234
DI 10.1007/s10055-017-0326-z
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GP1TD
UT WOS:000440598900004
DA 2024-07-18
ER

PT J
AU Coxon, M
   Kelly, N
   Page, S
AF Coxon, Matthew
   Kelly, Nathan
   Page, Sarah
TI Individual differences in virtual reality: Are spatial presence and
   spatial ability linked?
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Spatial presence; Immersive virtual reality; Head-mounted
   display; Spatial cognition; Cognition
ID MENTAL ROTATIONS
AB One aim of virtual reality technology is to immerse the user in a digital environment that is distinct from physical reality. Feeling spatially located in this digital environment is central to the experience and is more formally known as spatial presence. Experiences of spatial presence differ between individuals; prominent theories assume that these differences may, in part, be explained by differences in more general spatial abilities. Whilst there is some support for this claim with desktop systems, there is currently no direct empirical evidence to support this with more immersive technologies such as head-mounted displays (HMDs). In this study, participants completed three different measures of spatial ability before experiencing two virtual environments. These measures included a self-report of visuospatial imagery; the mental rotations test; and a test of topographical memory. After completing the measures, participants briefly experienced a virtual city and a virtual train ride through a HMD. The user's head movements were tracked, and visual displays were updated to give the sense of a full 360A degrees environment. After each experience, the participants reported how present they felt and the extent to which they had a mental model of the environment. Self-reports of imagery were positively correlated with reports of spatial presence, consistent with the previous literature. However, spatial presence was not related to performance on either of the more objective tests. Whilst this provides confirmatory evidence that self-reports of imagery can predict presence, it is still unclear which more basic spatial abilities, if any, could underlie this relationship.
C1 [Coxon, Matthew; Kelly, Nathan; Page, Sarah] York St John Univ, Sch Psychol & Social Sci, York, N Yorkshire, England.
C3 York Saint John University
RP Coxon, M (corresponding author), York St John Univ, Sch Psychol & Social Sci, York, N Yorkshire, England.
EM m.coxon@yorksj.ac.uk
OI Coxon, Matthew/0000-0001-5882-0966
CR Alsina-Jurnet I, 2010, INT J HUM-COMPUT ST, V68, P788, DOI 10.1016/j.ijhcs.2010.07.001
   [Anonymous], IST200137661 MEC EUR
   Bland M., 1995, INTRO MED STAT, V2nd
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Hartley T, 2007, HIPPOCAMPUS, V17, P34, DOI 10.1002/hipo.20240
   Hartley T, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00338
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Hofer M, 2012, MEDIA PSYCHOL, V15, P373, DOI 10.1080/15213269.2012.723118
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kosslyn S.M., 1999, IMAGE BRAIN
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Minsky M., 1980, Omni, V2, P44
   PETERS M, 1995, BRAIN COGNITION, V28, P39, DOI 10.1006/brcg.1995.1032
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   VANDENBERG SG, 1978, PERCEPT MOTOR SKILL, V47, P599, DOI 10.2466/pms.1978.47.2.599
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
NR 18
TC 59
Z9 64
U1 6
U2 71
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2016
VL 20
IS 4
BP 203
EP 212
DI 10.1007/s10055-016-0292-x
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DY6FF
UT WOS:000385201100002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Tarng, W
   Tsai, CF
   Lin, CM
   Lee, CY
   Liou, HH
AF Tarng, Wernhuar
   Tsai, Chi-Fen
   Lin, Chih-Ming
   Lee, Chi-Young
   Liou, Hsin-Hun
TI Development of an educational virtual transmission electron microscope
   laboratory
SO VIRTUAL REALITY
LA English
DT Article
DE Nanostructure; Transmission electron microscope; Virtual reality;
   Diffraction pattern; 3D crystal structure
AB In recent years, many high-tech instruments have been developed to investigate the nanostructures of materials. For example, the transmission electron microscope (TEM) is capable of imaging at a significantly higher resolution than light microscopes, enabling scientists to examine the very fine detail of materials even as small as a single column of atoms. It can also be used as a diffractometer to obtain the scattering pattern of a material for analysis of its 3D crystal structure. However, the TEM is a very expensive apparatus such that many students do not have a chance to operate it personally, thus causing the difficulty of understanding its principle and operating procedure. In this study, a virtual TEM laboratory has been developed to help students learn how to analyze the 3D crystal structures of different materials such as diamond, graphite, and anatase according to their diffraction patterns. A teaching experiment was conducted to study the learning effectiveness of using the virtual TEM laboratory for educational applications. The results showed that the virtual TEM laboratory could improve students' learning motivation and achievement in nanostructure analysis.
C1 [Tarng, Wernhuar; Tsai, Chi-Fen] Natl Hsinchu Univ Educ, Grad Inst E Learning Technol, Hsinchu, Taiwan.
   [Lin, Chih-Ming] Natl Hsinchu Univ Educ, Dept Appl Sci, Hsinchu, Taiwan.
   [Lee, Chi-Young] Natl Tsing Hua Univ, Dept Mat Sci & Engn, Hsinchu, Taiwan.
   [Liou, Hsin-Hun] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli, Taiwan.
C3 National Tsing Hua University; National Tsing Hua University; National
   Tsing Hua University; National Central University
RP Tarng, W (corresponding author), Natl Hsinchu Univ Educ, Grad Inst E Learning Technol, Hsinchu, Taiwan.
EM wtarng@mail.nhcue.edu.tw; patabow0805@gmail.com;
   cmlin@mail.nhcue.edu.tw; cylee@mx.nthu.edu.tw; viviliu0501@gmail.com
RI Tarng, Wernhuar/KCX-9561-2024
OI Tarng, Wernhuar/0000-0002-6657-5566
FU National Science Council of Taiwan [NSC 102-2120-S-007-008, NSC
   103-2120-S-007-005]
FX The authors would like to thank for the financial support by National
   Science Council of Taiwan under the contract numbers NSC
   102-2120-S-007-008 and NSC 103-2120-S-007-005.
CR Annett MK, 2010, PRESENCE-TELEOP VIRT, V19, P131, DOI 10.1162/pres.19.2.131
   [Anonymous], THEORIES ED
   [Anonymous], INT J MULTIMED APPL
   [Anonymous], EXAM WKLY
   [Anonymous], NANO COMMUN
   [Anonymous], ATOMIC FORCE MICROSC
   [Anonymous], VIRTUAL REAL
   [Anonymous], GO MOBILE
   [Anonymous], ITRC NEWSL
   Bossard Cyril, 2008, Virtual Reality, V12, P151, DOI 10.1007/s10055-008-0093-y
   Brown J., 1989, Educational Researcher, V18, P32, DOI [DOI 10.3102/0013189X018001032, 10.3102/0013189X018001032, DOI 10.2307/1176008]
   Burdea G. C., 2003, Virtual reality technology
   Feynman R., 1960, CalTech Engineering and Science, V23, P5
   Jin HH, 2012, MATER LETT, V89, P133, DOI 10.1016/j.matlet.2012.08.069
   Kim G.J., 2005, Designing virtual reality systems the structured approach
   Kolb D.A., 2000, EXPERIENTIAL LEARNIN
   Neogy S, 2006, INDIAN J PURE AP PHY, V44, P119
   RUGAR D, 1990, J APPL PHYS, V68, P1169, DOI 10.1063/1.346713
   Tarng W, 2011, INT J COMPUT SCI ENG, V6, P175, DOI 10.1504/IJCSE.2011.042021
   Wang R.K., 2009, Taipei County Education, V69, P87
   Wernhuar Tarng, 2012, International Journal of Computer Science & Information Technology, V4, P37, DOI 10.5121/ijcsit.2012.4604
   Williams D. B., 1996, Transmission Electron Microscopy: A Textbook for Materials Science, V2
   Yannier N, 2008, IEEE T HAPTICS, V1, P130, DOI 10.1109/ToH.2008.16
NR 23
TC 6
Z9 7
U1 1
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2015
VL 19
IS 1
BP 33
EP 44
DI 10.1007/s10055-014-0253-1
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CB5CS
UT WOS:000349645700003
DA 2024-07-18
ER

PT J
AU Lesk, VE
   Shamsuddin, SNW
   Walters, ER
   Ugail, H
AF Lesk, Valerie E.
   Shamsuddin, Syadiah Nor Wan
   Walters, Elizabeth R.
   Ugail, Hassan
TI Using a virtual environment to assess cognition in the elderly
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Spatial memory; Mild cognitive impairment; Spatial
   navigation
ID MINI-MENTAL-STATE; ALZHEIMERS-DISEASE; PERFORMANCE; DIAGNOSIS; REALITY;
   MEMORY; REHABILITATION; DEMENTIA; BEHAVIOR
AB Early diagnosis of Alzheimer's disease (AD) is essential if treatments are to be administered at an earlier point in time before neurons degenerate to a stage beyond repair. In order for early detection to occur tools used to detect the disorder must be sensitive to the earliest of cognitive impairments. Virtual reality technology offers opportunities to provide products which attempt to mimic daily life situations, as much as is possible, within the computational environment. This may be useful for the detection of cognitive difficulties. We develop a virtual simulation designed to assess visuospatial memory in order to investigate cognitive function in a group of healthy elderly participants and those with a mild cognitive impairment (MCI). Participants were required to guide themselves along a virtual path to reach a virtual destination which they were required to remember. The preliminary results indicate that this virtual simulation has the potential to be used for detection of early AD since significant correlations of scores on the virtual environment with existing neuropsychological tests were found. Furthermore, the test discriminated between healthy elderly participants and those with a MCI.
C1 [Lesk, Valerie E.; Walters, Elizabeth R.] Univ Bradford, Div Psychol, Sch Social & Int Studies, Bradford BD7 1DP, W Yorkshire, England.
   [Shamsuddin, Syadiah Nor Wan] Univ Sultan Zainal Abidin, Sch Informat & Comp, Kuala Lumpur, Malaysia.
   [Ugail, Hassan] Univ Bradford, Sch Comp Informat & Media, Bradford BD7 1DP, W Yorkshire, England.
C3 University of Bradford; Universiti Sultan Zainal Abidin; University of
   Bradford
RP Walters, ER (corresponding author), Univ Bradford, Div Psychol, Sch Social & Int Studies, Bradford BD7 1DP, W Yorkshire, England.
EM E.Walters@bradford.ac.uk
OI Walters, Elizabeth/0000-0003-4009-3996
FU School of Computing, Informatics and Media, University of Bradford;
   School of Social and International Studies, Rebecca Durrans in the
   Division of Psychology, University of Bradford; University of Sultan
   Zainal Abidin (UniSZA)
FX The authors would like to express their gratitude to the School of
   Computing, Informatics and Media, School of Social and International
   Studies, Rebecca Durrans in the Division of Psychology, University of
   Bradford and University of Sultan Zainal Abidin (UniSZA) for the support
   and facilities provided. We also thank Nick Farrar from Adult and
   Community Services at Bradford Metropolitan District Council and all the
   participants for taking part.
CR Baños RM, 2002, IEEE T INF TECHNOL B, V6, P206, DOI 10.1109/TITB.2002.802380
   Blackwell AD, 2004, DEMENT GERIATR COGN, V17, P42, DOI 10.1159/000074081
   Chandler J.M., 2008, ALZHEIMERS DEMENT, V4, pT551, DOI DOI 10.1016/J.JALZ.2008.05.1676
   Cherrier MM, 2001, NEUROPSY NEUROPSY BE, V14, P159
   Coelho CM, 2009, J ANXIETY DISORD, V23, P563, DOI 10.1016/j.janxdis.2009.01.014
   Cullum S, 2000, INT J GERIATR PSYCH, V15, P853, DOI 10.1002/1099-1166(200009)15:9<853::AID-GPS211>3.3.CO;2-K
   Cushman LA, 2008, NEUROLOGY, V71, P888, DOI 10.1212/01.wnl.0000326262.67613.fe
   De Jager CA, 2008, ALZHEIMERS DEMENT, V4, pT554
   Dening T, 2009, MATURITAS, V64, P59, DOI 10.1016/j.maturitas.2009.08.014
   Dubois B, 2007, LANCET NEUROL, V6, P734, DOI 10.1016/S1474-4422(07)70178-3
   Duffy CJ, 2009, ANN NY ACAD SCI, V1170, P736, DOI 10.1111/j.1749-6632.2009.04021.x
   Égerházi A, 2007, PROG NEURO-PSYCHOPH, V31, P746, DOI 10.1016/j.pnpbp.2007.01.011
   Fields JA, 2011, NAT REV NEUROL, V7, P677, DOI 10.1038/nrneurol.2011.173
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Forlenza OV, 2010, BMC MED, V8, DOI 10.1186/1741-7015-8-89
   Garcia-Palacios A, 2002, BEHAV RES THER, V40, P983, DOI 10.1016/S0005-7967(01)00068-7
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Jacova C, 2007, ALZHEIMERS DEMENT, V3, P299, DOI 10.1016/j.jalz.2007.07.011
   Klein DA, 1999, INT J GERIATR PSYCH, V14, P272, DOI 10.1002/(SICI)1099-1166(199904)14:4<272::AID-GPS896>3.0.CO;2-P
   Marques A, 2008, P INT C DIS VIRT REA, P39
   MCKENNA P, 1980, J NEUROL NEUROSUR PS, V43, P781, DOI 10.1136/jnnp.43.9.781
   Moffat SD, 2001, NEUROBIOL AGING, V22, P787, DOI 10.1016/S0197-4580(01)00251-2
   Pasquier F, 1999, J NEUROL, V246, P6, DOI 10.1007/s004150050299
   Pengas G, 2012, FRONT AGING NEUROSCI, V4, DOI 10.3389/fnagi.2012.00017
   Pengas G, 2010, J ALZHEIMERS DIS, V21, P1347, DOI 10.3233/JAD-2010-100654
   Petersen RC, 2001, ARCH NEUROL-CHICAGO, V58, P1985, DOI 10.1001/archneur.58.12.1985
   Petersen RC, 2011, NEW ENGL J MED, V364, P2227, DOI 10.1056/NEJMcp0910237
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   SHAMSUDDIN SNW, 2011, P 2 VIS INF SUST RES, V7067, P13
   Singh-Manoux A, 2010, AGE, V32, P509, DOI 10.1007/s11357-010-9147-7
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Tippett WJ, 2009, J CLIN EXP NEUROPSYC, V31, P447, DOI 10.1080/13803390802251360
   TOMBAUGH TN, 1992, J AM GERIATR SOC, V40, P922, DOI 10.1111/j.1532-5415.1992.tb01992.x
   Wan Shamsuddin S, 2011, WORLD C INF TECHN AN
   Werner P, 2009, DEMENT GERIATR COGN, V27, P301, DOI 10.1159/000204915
NR 35
TC 16
Z9 17
U1 1
U2 41
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2014
VL 18
IS 4
BP 271
EP 279
DI 10.1007/s10055-014-0252-2
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA AT0AZ
UT WOS:000344600500004
OA Green Published
DA 2024-07-18
ER

PT B
AU Kawasaki, H
   Koide, S
   Mouri, T
   Endo, T
AF Kawasaki, Haruhisa
   Koide, Shinya
   Mouri, Tetuya
   Endo, Takahiro
BE Kim, JJ
TI Development of a Finger Pad Force Display for a Hand Haptic Interface
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID DESIGN
C1 [Kawasaki, Haruhisa; Koide, Shinya; Mouri, Tetuya; Endo, Takahiro] Gifu Univ, Gifu, Japan.
C3 Gifu University
RP Kawasaki, H (corresponding author), Gifu Univ, Gifu, Japan.
RI Endo, Takahiro/IZE-8644-2023
OI Endo, Takahiro/0000-0002-2231-5359
CR Alhalabi MO, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P623
   AOKI T, 2009, TVRSJ, V14, P421
   Bouzit M, 2002, IEEE-ASME T MECH, V7, P256, DOI 10.1109/TMECH.2002.1011262
   ENDO T, 2007, P 13 INT C VIRT SYST
   Fontana M., 2008, P ICRA2009, P1074
   GRIEVE T, 2009, P 3 JOINT EUR C S HA, P411
   Inaba G., 2006, P EUROHAPTICS
   Kawasaki H., 1993, J ROBOTICS MECHATRON, V5, P79
   Kawasaki H., 1999, Journal of Robotics and Mechatronics, P269
   Kawasaki H, 2007, IEEE T ROBOT, V23, P909, DOI 10.1109/TRO.2007.906258
   Koo IM, 2008, IEEE T ROBOT, V24, P549, DOI 10.1109/TRO.2008.921561
   Koyama T, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2229
   Lederman S.J., 1991, ENCY HUMAN BIOL, V7, P51
   MINAMIZAWA K, 2008, TVRSJ, V13
   UEDA Y, 2004, P INT C INT ROB SYST, P2886
   Walairacht S, 2001, IEICE T INF SYST, VE84D, P365
   YOSHIKAWA T, 2000, P SYROCO 00, P427
   [No title captured]
   [No title captured]
NR 19
TC 0
Z9 0
U1 0
U2 0
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 93
EP 106
D2 10.5772/553
PG 14
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400006
DA 2024-07-18
ER

PT B
AU Smith, S
AF Smith, Shana
BE Kim, JJ
TI Integrating Low-Cost Virtual Reality into Engineering Design Curricula
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
C1 [Smith, Shana] Natl Taiwan Univ, Taipei, Taiwan.
C3 National Taiwan University
RP Smith, S (corresponding author), Natl Taiwan Univ, Taipei, Taiwan.
CR [Anonymous], 1997, J ENG EDUC, DOI [10.1002/j.2168-9830.1997.tb00278.x, DOI 10.1002/J.2168-9830.1997.TB00278.X]
   Ausburn L., 2004, J IND TEACHER ED, V41, P33
   Crosier I. K., 2000, Education and Information Technologies, V5, P329, DOI 10.1023/A:1012009725532
   Deno J.A., 1995, Engineering Design Graphics Journal, V59, P5
   Devon R., 1994, ENG DES GRAPHIC J, V58, P4
   Hegarty M, 2004, INTELLIGENCE, V32, P175, DOI 10.1016/j.intell.2003.12.001
   Riva G, 2003, METHOD INFORM MED, V42, P524
   Salzman M., 1999, MODEL UNDERSTANDING
   Sorby S., 1999, ENG DESIGN GRAPHICS, V63, P21
   Sulbaran T., 2000, 30 ASSEE IEEE FRONT
   WINN W, 1997, M AM ED RES ASS CHIC
NR 11
TC 0
Z9 0
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 539
EP 546
D2 10.5772/553
PG 8
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400027
DA 2024-07-18
ER

PT J
AU Gillies, M
   Pan, XN
   Slater, M
AF Gillies, Marco
   Pan, Xueni
   Slater, Mel
TI Piavca: a framework for heterogeneous interactions with virtual
   characters
SO VIRTUAL REALITY
LA English
DT Article
AB This paper presents a virtual character animation system for real-time multimodal interaction in an immersive virtual reality setting. Human to human interaction is highly multimodal, involving features such as verbal language, tone of voice, facial expression, gestures and gaze. This multimodality means that, in order to simulate social interaction, our characters must be able to handle many different types of interaction and many different types of animation, simultaneously. Our system is based on a model of animation that represents different types of animations as instantiations of an abstract function representation. This makes it easy to combine different types of animation. It also encourages the creation of behavior out of basic building blocks, making it easy to create and configure new behaviors for novel situations. The model has been implemented in Piavca, an open source character animation system.
C1 [Gillies, Marco] Univ London, Dept Comp, Goldsmiths Coll, London, England.
   [Pan, Xueni] UCL, Dept Comp Sci, London, England.
   [Slater, Mel] ICREA Univ Barcelona, Barcelona, Spain.
C3 University of London; Goldsmiths University London; University of
   London; University College London; ICREA
RP Gillies, M (corresponding author), Univ London, Dept Comp, Goldsmiths Coll, London, England.
EM m.gillies@gold.ac.uk
RI Pan, Xueni/B-4307-2013; Slater, Mel/M-5210-2014
OI Slater, Mel/0000-0002-6223-0050; Pan, Xueni/0000-0002-1282-1469
FU European Union [27731]; UK Engineering and Physical Sciences Research
   Council; ICREA Funding Source: Custom
FX We would like to thank the funders of this work: BT plc, the European
   Union FET project PRESENCIA (contract number 27731) and the Empathic
   Avatars project funded by the UK Engineering and Physical Sciences
   Research Council. We also would like to thank the members of the
   University College London Department of Computer Science Virtual
   Environments and Graphics Group.
CR Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   [Anonymous], ACM CHI 99 C P
   [Anonymous], 2006, EUROGRAPHICS
   Argyle M., 1976, Gaze and Mutual Gaze
   Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606
   Badler N. I., 1993, Simulating humans: computer graphics animation and control
   Bui T, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P284
   Cassell J., 1999, Psychological Models of Communication in Collaborative Systems. Papers from the 1999 AAAI Fall Symposium (TR FS-99-03), P34
   CASSELL J, 1999, P COMP AN SIM 99
   Egges A, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P121, DOI 10.1109/PCCGA.2004.1348342
   ELLIOTT C, 1994, P SIGGRAPH 94, P421
   FIGUEROA P, 2002, P WEB3D 02
   GILLIES M, 2003, 4 WORKSH INT VIRT AG
   Grassia F. S., 1998, J. Graph. Tools, V6, DOI [10.1080/10867651.1998.10487493, DOI 10.1080/10867651.1998.10487493]
   GRATCH J, 2001, AGENTS 01, P278
   Guye-Vuilleme A., 1999, Virtual Reality, V4, P49, DOI 10.1007/BF01434994
   KENDON A, 1970, ACTA PSYCHOL, V32, P100
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   KOPP S, 2005, INT C MULT INT ICMI, P97
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   KSHIRSAGAR S, 2002, 2 INT S SMART GRAPH, P107
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lee SP, 2002, ACM T GRAPHIC, V21, P637
   MAATMAN RM, 2005, INTELLIGENT VIRTUAL
   PAN X, 2007, PRESENCE 2007, P101
   Pan XN, 2008, LECT NOTES COMPUT SC, V5208, P89
   Poggi I, 2005, TEXT SPEECH LANG TEC, V27, P3, DOI 10.1007/1-4020-3051-7_1
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   SLATER M, 1994, ARTIFICIAL LIFE AND VIRTUAL REALITY, P125
   Stone M, 2004, ACM T GRAPHIC, V23, P506, DOI 10.1145/1015706.1015753
   Thorisson K. R., 1998, Proceedings of the Second International Conference on Autonomous Agents, P16, DOI 10.1145/280765.280769
   VILHJALMSSON HH, 2005, 6 ANN MIN PERS CONV
   Vinayagamoorthy V, 2004, COMPUT GRAPH FORUM, V23, P1, DOI 10.1111/j.1467-8659.2004.00001.x
   WITKIN A, 1995, ANN C SERIES, P105
NR 34
TC 2
Z9 3
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2010
VL 14
IS 4
BP 221
EP 228
DI 10.1007/s10055-010-0167-5
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HX
UT WOS:000296279800001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Brunzini, A
   Mazzoli, A
   Pagnoni, M
   Mandolini, M
AF Brunzini, Agnese
   Mazzoli, Alida
   Pagnoni, Mario
   Mandolini, Marco
TI An innovative mixed reality approach for maxillofacial osteotomies and
   repositioning
SO VIRTUAL REALITY
LA English
DT Article
DE Maxillofacial surgery; Mixed reality; Augmented reality; Hololens;
   Surgical guide
ID AUGMENTED REALITY; SURGERY; HOLOLENS
AB Craniomaxillofacial surgeries are performed using custom-made physical cutting guides and resin dental splints that present several drawbacks (e.g. time and cost required for their design and production). The literature commonly provides augmented/mixed reality (AR/MR) solutions for assisting maxillofacial osteotomies and repositioning without any interactive guide. This work proposes a new MR application, useful for osteotomy and repositioning, providing interactive, fast, and intuitive feedback to the surgeon, who is then supported in performing the bone fragment resection and replacement frame by frame. The proposed application speeds up the surgery and reduces under/overshooting errors. Moreover, the idea of integrating osteotomy and repositioning assistance in the same MR application is rarely found in the literature. It is an entirely novel approach to craniomaxillofacial surgery. The MR application has been designed with a three-button menu. The "App Start" calibrates the app, the "Osteotomy Mode" visualises the holograms of the cutting lines and drilling points, and the "Repositioning Mode" visualises the step-by-step real-time feedback to precisely support the surgeon placing the osteotomised bone fragment towards the final pre-planned position. The MR app has been developed in Unity and deployed on Microsoft HoloLens V2. A laboratory test bench was realised to validate the accuracy of the proposed MR-based approach. The validation protocol consists of two tasks to test the osteotomy and repositioning modes using a 3D-printed skull phantom. For osteotomy, the accuracy is 0.89 mm (genioplasty), 1.24 mm (maxillary osteotomy), 1.33 mm (orthognathic surgery), and 2.89 mm (mandibular angle osteotomy). For repositioning, the accuracy is 0.6 mm (anteroposterior deviation), 0.7 mm (mediolateral deviation), and 0.6 degrees (angular deviation).
C1 [Brunzini, Agnese; Mandolini, Marco] Univ Politecn Marche, Dept Ind Engn & Math Sci, Via Brecce Bianche 12, I-60131 Ancona, Italy.
   [Mazzoli, Alida] Univ Politecn Marche, Dept Mat Environm Sci & Urban Planning, Via Brecce Bianche 12, Ancona 60131, Italy.
   [Pagnoni, Mario] YourFACE, Clin Ars Biomed, Via Luigi Bodio 58, I-00191 Rome, Italy.
C3 Marche Polytechnic University; Marche Polytechnic University
RP Brunzini, A (corresponding author), Univ Politecn Marche, Dept Ind Engn & Math Sci, Via Brecce Bianche 12, I-60131 Ancona, Italy.
EM a.brunzini@staff.univpm.it
RI ; Mandolini, Marco/L-3016-2013; PAGNONI, MARIO/G-5258-2012
OI Mazzoli, Alida/0000-0001-9082-8407; Brunzini,
   Agnese/0000-0003-0450-2510; Mandolini, Marco/0000-0003-0962-5982;
   PAGNONI, MARIO/0000-0001-5621-687X
FU The authors would like to acknowledge Eng. Andrea Danieli for his
   contribution to this research.
FX The authors would like to acknowledge Eng. Andrea Danieli for his
   contribution to this research.
CR Ackermann J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031228
   Afif FN., 2013, International Journal of Interactive Digital Media, V1, P46
   Andrews CM, 2021, IEEE J TRANSL ENG HE, V9, DOI 10.1109/JTEHM.2020.3045642
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Badiali G, 2020, IEEE ACCESS, V8, P59015, DOI 10.1109/ACCESS.2020.2973298
   Benmahdjoub M, 2022, VIRTUAL REAL-LONDON, V26, P1637, DOI 10.1007/s10055-022-00653-3
   Brunzini A, 2022, LECT N MECH ENG, P133, DOI 10.1007/978-3-030-91234-5_13
   Brunzini A, 2022, VIRTUAL REAL-LONDON, V26, P1257, DOI 10.1007/s10055-022-00632-8
   Ceccariglia F, 2022, J PERS MED, V12, DOI 10.3390/jpm12122047
   Cortese A, 2012, ROLE OF OSTEOTOMY IN THE CORRECTION OF CONGENITAL AND ACQUIRED DISORDERS OF THE SKELETON, P23
   Dad A., 2017, International journal of engineering research and technology, V5, P1
   Frantz T, 2018, HEALTHC TECHNOL LETT, V5, P221, DOI 10.1049/htl.2018.5079
   Gao Y, 2019, J CRANIO MAXILL SURG, V47, P1242, DOI 10.1016/j.jcms.2019.04.005
   García-Mato D, 2021, COMP M BIO BIO E-IV, V9, P392, DOI 10.1080/21681163.2020.1834876
   Itamiya Tomoki, 2018, EPiC Ser Eng, V1, P26, DOI DOI 10.29007/WJJX
   Jiang TR, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36457-2
   Jiang WP, 2018, INT J ORAL MAX IMPL, V33, P1219, DOI 10.11607/jomi.6638
   Kanithi PK, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010023
   Kashani H., 2016, A Textbook of Advanced Oral and Maxillofacial Surgery Volume, V3, P617, DOI DOI 10.5772/63345
   Koyachi M, 2021, INT J ORAL MAX SURG, V50, P782, DOI 10.1016/j.ijom.2020.09.026
   Kramers Matthew, 2014, Stud Health Technol Inform, V196, P204
   Lin L, 2016, J CRANIO MAXILL SURG, V44, P215, DOI 10.1016/j.jcms.2015.10.024
   Lin YK, 2015, CLIN IMPLANT DENT R, V17, P543, DOI 10.1111/cid.12119
   Mehrotra Divya, 2021, J Oral Biol Craniofac Res, V11, P486, DOI 10.1016/j.jobcr.2021.06.002
   Meng FH, 2021, J STOMATOL ORAL MAXI, V122, pE45, DOI 10.1016/j.jormas.2021.01.005
   Meulstee JW, 2019, SURG INNOV, V26, P86, DOI 10.1177/1553350618799552
   Mitsuno D, 2019, PLAST RECONSTR SURG, V143, P647, DOI 10.1097/PRS.0000000000005215
   Park S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167259
   Pietruski P, 2019, J CRANIO MAXILL SURG, V47, P854, DOI 10.1016/j.jcms.2019.03.004
   Piramide C, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12168154
   Rae E, 2018, C IM GUID PROC ROB I
   Rassweiler-Seyfried MC, 2020, WORLD J UROL, V38, P447, DOI 10.1007/s00345-019-02801-y
   Schlosser PD, 2021, INT J HUM-COMPUT ST, V154, DOI 10.1016/j.ijhcs.2021.102628
   Schmalstieg D, 2016, AR TXB TOBIAS
   Stryker Craniomaxillofacial, 2011, LEIB STRYK LIT NUMB
   Syamlan A, 2022, VIRTUAL REAL-LONDON, V26, P1795, DOI 10.1007/s10055-022-00666-y
   Tsukada S, 2019, J EXP ORTHOP, V6, DOI 10.1186/s40634-019-0212-6
   Vávra P, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4574172
   Zhou CZ, 2017, AESTHET PLAST SURG, V41, P1228, DOI 10.1007/s00266-017-0900-5
   Zlatanova S., 2002, Augmented reality technology
NR 40
TC 2
Z9 2
U1 6
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3221
EP 3237
DI 10.1007/s10055-023-00867-z
EA OCT 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001088163900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Choi, H
   Kim, SN
AF Choi, Hansol
   Kim, Seung-Nam
TI Training street-level "sense of scale" as a spatial perception ability
   in recorded virtual reality: A Solomon four-group design approach
SO VIRTUAL REALITY
LA English
DT Article
DE Design education; Spatial perception ability; Sense of scale; Scale
   practice Virtual reality; Solomon four-group design
ID MENTAL ROTATIONS; EDUCATION; RELIABILITY; STATE
AB Although spatial perception abilities are essential for improving architectural and urban design competence, the lack of appropriate educational tools has prevented them from being taught in higher education settings; accordingly, many students struggle with identifying such spatial characteristics. Using a Solomon four-group design approach, this study aimed to verify the effectiveness of virtual reality (VR)-aided training for "sense of scale," which despite being one of the most critical abilities in design competence, is difficult to teach both in the classroom and on-site. We recruited 80 first- and second-year university students majoring in physical planning, and conducted two street-level sense of scale training sessions, as well as pre- and post-tests. We measured the sense of scale accuracy (i.e., the difference between the actual and reported values) using mean absolute percentage error, and the effect of experimental treatment was analyzed. The results demonstrated that the training was significantly effective at estimating dimensions for street width and building height but not D/H ratio. This suggests that a sense of "absolute" scale can be acquired through two VR-aided training sessions. Additional post hoc questionnaire surveys also demonstrated that the participants felt that VR-aided training was more effective for scale practice than traditional learning methods. The findings demonstrate that for spatial perception abilities that are difficult to teach with conventional teaching methods, VR-aided training could be utilized as an effective education technique.
C1 [Choi, Hansol] Seoul Inst, Seoul 06756, South Korea.
   [Kim, Seung-Nam] Chung Ang Univ, Sch Civil & Environm Engn, Dept Urban Design & Studies, Seoul 06974, South Korea.
C3 Chung Ang University
RP Kim, SN (corresponding author), Chung Ang Univ, Sch Civil & Environm Engn, Dept Urban Design & Studies, Seoul 06974, South Korea.
EM foreversh92@cau.ac.kr; snkim@cau.ac.kr
RI Kim, Seung-Nam/O-4505-2014
OI Kim, Seung-Nam/0000-0003-3577-1000
FU The authors are grateful for the useful comments from the three
   anonymous referees and the editor.
FX The authors are grateful for the useful comments from the three
   anonymous referees and the editor.
CR Akita M., 2005, J ARCHIT PLAN, V70, P235, DOI [10.3130/aija.70.235_2, DOI 10.3130/AIJA.70.235_2]
   Alexander C., 1977, PATTERN LANGUAGE TOW
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Arslan A R., 2017, International Journal for the Scholarship of Teaching and Learning, V11, P1, DOI DOI 10.20429/IJSOTL.2017.110215
   Barmaki R, 2019, ANAT SCI EDUC, V12, P599, DOI 10.1002/ase.1858
   Berg LP, 2017, J COMPUT INF SCI ENG, V17, DOI 10.1115/1.4034267
   Berkowitz M, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.609363
   Bethlehem JR, 2014, INT J HEALTH GEOGR, V13, DOI 10.1186/1476-072X-13-52
   Blumenfeld Hans., 1953, TOWN PLAN REV, V24, P35
   BRAVER MCW, 1988, PSYCHOL BULL, V104, P150, DOI 10.1037/0033-2909.104.1.150
   Calabrese L., 2006, COGN PROCESS, V7, P118, DOI DOI 10.1007/S10339-006-0094-2
   Campbell DT., 1963, EXPT QUASIEXPERIMENT
   Carroll J.B., 1993, HUMAN COGNITIVE ABIL, DOI DOI 10.1017/CBO9780511571312
   Cho JY, 2019, J INTERIOR DES, V44, P141, DOI 10.1111/joid.12143
   CogniFit, 2016, SPATIAL PERCEPTION C
   Colby C.L., 2001, International Encyclopedia of the Social Behavioral Sciences, DOI DOI 10.1016/B0-08-043076-7/03501-4
   D'Oliveira TC, 2004, INT J AVIAT PSYCHOL, V14, P19, DOI 10.1207/s15327108ijap1401_2
   Darwish M, 2023, AIN SHAMS ENG J, V14, DOI 10.1016/j.asej.2022.102104
   di Lanzo JA, 2020, COMPUT APPL ENG EDUC, V28, P748, DOI 10.1002/cae.22243
   Ekstrom R., 1976, Kit of factor-referenced cognitive tests
   Emmons Paul., 2005, ARQ-ARCHIT RES Q, V9, P227, DOI [10.1017/S135913550500028X, DOI 10.1017/S135913550500028X]
   Ewing R, 2009, J URBAN DES, V14, P65, DOI 10.1080/13574800802451155
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gehl J., 2010, CITIES PEOPLE
   Goodwin P, 1999, INT J FORECASTING, V15, P405, DOI 10.1016/S0169-2070(99)00007-2
   Hegarty M, 2004, INTELLIGENCE, V32, P175, DOI 10.1016/j.intell.2003.12.001
   Helmstadter G.C., 1970, Research concepts in human behavior
   Ho C.-H., 2006, SPATIAL COGNITION IN DESIGN
   HolonI Q, 2020, GLOBAL EDTECH MARKET
   Horvat N, 2022, VIRTUAL REAL-LONDON, V26, P1227, DOI 10.1007/s10055-022-00630-w
   Horvat Nikola, 2019, P DES SOC INT C ENG, V1, P1923, DOI 10.1017/dsi.2019.198
   HUCK SW, 1975, PSYCHOL BULL, V82, P511, DOI 10.1037/h0076767
   HUCK SW, 1973, J EXP EDUC, V42, P54, DOI 10.1080/00220973.1973.11011460
   Huette S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058464
   Jacobs AB, 1993, Great streets
   Jacobs Jane, 1961, DEATH LIFE GREAT AM
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jeong YJ, 2011, METHODOLOGY SOCIAL S
   Johns Hopkins CTY, 2012, WHAT IS SPAT AB WHY
   Jones MG, 2009, J RES SCI TEACH, V46, P460, DOI 10.1002/tea.20288
   Jun, 2000, J EDUC RES, V21, P183
   KATO N, 1965, JPN PSYCHOL RES, V7, P120, DOI 10.4992/psycholres1954.7.120
   Kim CS., 2013, UNDERSTANDING SPACE
   Kim J, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16050865
   Kim JL, 1998, STRUCTURE, V6, P89, DOI 10.1016/S0969-2126(98)00010-0
   Kim SN, 2022, LANDSCAPE URBAN PLAN, V218, DOI 10.1016/j.landurbplan.2021.104290
   Kim S, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12166440
   Korea planning association, 2005, URBAN PLANNING THEOR
   LINN MC, 1985, CHILD DEV, V56, P1479, DOI 10.1111/j.1467-8624.1985.tb00213.x
   Lowrie T, 2019, J COGN DEV, V20, P729, DOI 10.1080/15248372.2019.1653298
   Lynch K, 1960, PUBLICATIONS JOINT C, P194
   Lynch K., 1984, SITE PLANNING, V3rd
   McCambridge J, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025223
   Moon SY., 2012, J KOREAN I ED FACIL, V19, P3, DOI [10.7859/kief.2012.19.5.003, DOI 10.7859/KIEF.2012.19.5.003]
   Mouratidis K, 2020, CITIES, V97, DOI 10.1016/j.cities.2019.102499
   Oh SH, 2013, SCALE PRACTICE ARCHI
   Ostwald Michael., 2001, Nexus Network Journal, V3, P145, DOI DOI 10.1007/S00004-000-0015-0
   Paes D, 2021, AUTOMAT CONSTR, V130, DOI 10.1016/j.autcon.2021.103849
   Paes D, 2017, AUTOMAT CONSTR, V84, P292, DOI 10.1016/j.autcon.2017.09.016
   Pellas N, 2021, VIRTUAL REAL-LONDON, V25, P835, DOI 10.1007/s10055-020-00489-9
   Pellas N, 2020, IEEE T LEARN TECHNOL, V13, P748, DOI 10.1109/TLT.2020.3019405
   PETERS M, 1995, BRAIN COGNITION, V28, P39, DOI 10.1006/brcg.1995.1032
   Pólrolniczak M, 2021, BUILD ENVIRON, V202, DOI 10.1016/j.buildenv.2021.108016
   Psotka J, 1995, INSTR SCI, V23, P405, DOI 10.1007/BF00896880
   Psotka J., 1993, P 1993 C INT COMP AI, P285
   Qiao R., 2018, J KOREA GAME SOC, V18, P15, DOI [10.7583/JKGS.2018.18.4.15, DOI 10.7583/JKGS.2018.18.4.15]
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Ritter KA, 2022, VIRTUAL REAL-LONDON, V26, P571, DOI 10.1007/s10055-021-00502-9
   SAWILOWSKY S, 1994, J EXP EDUC, V62, P361, DOI 10.1080/00220973.1994.9944140
   Schneider S, 2020, TRANSPORT RES F-TRAF, V68, P231, DOI 10.1016/j.trf.2019.11.005
   Seoul Metropolitan Government, 2017, SEOUL STREET DES MAN
   SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701
   Sitte C., 1965, BIRTH MODERN CITY PL
   SOLOMON RL, 1949, PSYCHOL BULL, V46, P137, DOI 10.1037/h0062958
   Spiro K., 1999, CITY ASSEMBLED ELEME
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Suh J, 2020, THINK SKILLS CREAT, V35, DOI 10.1016/j.tsc.2020.100628
   Swamidass P.M., 2000, Encyclopedia of Production and Manufacturing Management, P462, DOI [DOI 10.1007/1-4020-0612-8_580, 10.1007/1-4020-0612-8_580]
   Tan NC, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.847590
   Turgut M, 2015, QUAL QUANT, V49, P1997, DOI 10.1007/s11135-014-0086-8
   VANDENBERG SG, 1978, PERCEPT MOTOR SKILL, V47, P599, DOI 10.2466/pms.1978.47.2.599
   Voss P, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01960
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   Weerasinghe M, 2023, VIRTUAL REAL-LONDON, V27, P51, DOI 10.1007/s10055-022-00673-z
   Yilmaz H.B., 2009, INTERNATIONALELECTRO, V1, P83
NR 85
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3149
EP 3164
DI 10.1007/s10055-023-00861-5
EA SEP 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001093115000001
DA 2024-07-18
ER

PT J
AU Horsak, B
   Simonlehner, M
   Dumphart, B
   Siragy, T
AF Horsak, Brian
   Simonlehner, Mark
   Dumphart, Bernhard
   Siragy, Tarique
TI Overground walking while using a virtual reality head mounted display
   increases variability in trunk kinematics and reduces dynamic balance in
   young adults
SO VIRTUAL REALITY
LA English
DT Article
DE Gait analysis; Dynamic stability; Postural control; Motion capturing;
   Immersive virtual reality
ID OLDER-ADULTS; LATERAL BALANCE; FALL RISK; GAIT; OSCILLATIONS;
   PERFORMANCE; STABILITY; FEEDBACK
AB This study analyzed the effects of walking freely in virtual reality (VR) compared to walking in the real-world on dynamic balance and postural control. For this purpose, nine male and twelve female healthy participants underwent standard 3D gait analysis while walking randomly in a real laboratory and in a room-scale overground VR environment resembling the real laboratory. The VR was delivered to participants by a head-mounted-display which was operated wirelessly and calibrated to the real-world. Dynamic balance and postural control were assessed with (1) the margin of stability (MOS) in the anteroposterior (AP-MOS) and mediolateral (ML-MOS) directions at initial-contact, (2) the relationship between the mediolateral center of mass (COM) position and acceleration at mid-stance with subsequent step width, (3) and trunk kinematics during the entire gait cycle. We observed increased mediolateral (ML) trunk linear velocity variability, an increased coupling of the COM position and acceleration with subsequent step width, and a decrease in AP-MOS while walking in VR but no change in ML-MOS when walking in VR. Our findings suggest that walking in VR may result in a less reliable optical flow, indicated by increased mediolateral trunk kinematic variability, which seems to be compensated by the participants by slightly reweighing sensorimotor input and thereby consciously tightening the coupling between the COM and foot placement to avoid a loss of balance. Our results are particularly valuable for future developers who want to use VR to support gait analysis and rehabilitation.
C1 [Horsak, Brian; Simonlehner, Mark; Dumphart, Bernhard; Siragy, Tarique] St Polten Univ Appl Sci, Ctr Digital Hlth & Social Innovat, Campus-Pl 1, A-3100 St Polten, Austria.
   [Horsak, Brian; Simonlehner, Mark; Dumphart, Bernhard] St Polten Univ Appl Sci, Inst Hlth Sci, Campus-Pl 1, A-3100 St Polten, Austria.
C3 St. Polten University of Applied Sciences; St. Polten University of
   Applied Sciences
RP Horsak, B (corresponding author), St Polten Univ Appl Sci, Ctr Digital Hlth & Social Innovat, Campus-Pl 1, A-3100 St Polten, Austria.; Horsak, B (corresponding author), St Polten Univ Appl Sci, Inst Hlth Sci, Campus-Pl 1, A-3100 St Polten, Austria.
EM brian.horsak@fhstp.ac.at
RI Horsak, Brian/HZJ-8906-2023
OI Horsak, Brian/0000-0002-9296-3212; Dumphart,
   Bernhard/0000-0001-5796-9910; Siragy, Tarique/0000-0002-0808-0450
FU We would like to thank Lukas Richter for his thoughts and comments
   regarding the multiple linear regression analysis.
FX We would like to thank Lukas Richter for his thoughts and comments
   regarding the multiple linear regression analysis.
CR Ahn S, 2019, J EXERC REHABIL, V15, P358, DOI 10.12965/jer.1938174.087
   Akiduki H, 2003, NEUROSCI LETT, V340, P197, DOI 10.1016/S0304-3940(03)00098-3
   Alhirsan SM, 2023, ARCH REHAB RES CLIN, V5, DOI 10.1016/j.arrct.2023.100265
   Allen Micah, 2019, Wellcome Open Res, V4, P63, DOI 10.12688/wellcomeopenres.15191.1
   [Anonymous], 2013, Measuring Walking. A Handbook of Clinical Gait Analysis, DOI DOI 10.1111/DMCN.12288
   Anson E, 2014, EXP BRAIN RES, V232, P1941, DOI 10.1007/s00221-014-3885-1
   Bauby CE, 2000, J BIOMECH, V33, P1433, DOI 10.1016/S0021-9290(00)00101-9
   Benham S, 2019, OTJR-OCCUP PART HEAL, V39, P90, DOI 10.1177/1539449218817291
   Brepohl PCA, 2023, VIRTUAL REAL-LONDON, V27, P71, DOI 10.1007/s10055-022-00654-2
   Bruijn SM, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2017.0816
   Canessa A, 2019, HUCAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 2: HUCAPP, P121, DOI 10.5220/0007380901210128
   Canning CG, 2020, NAT REV NEUROL, V16, P409, DOI 10.1038/s41582-020-0370-2
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen B, 2021, COMPLEMENT THER MED, V58, DOI 10.1016/j.ctim.2021.102676
   Darter BJ, 2011, PHYS THER, V91, P1385, DOI 10.2522/ptj.20100360
   DAVIS RB, 1991, HUM MOVEMENT SCI, V10, P575, DOI 10.1016/0167-9457(91)90046-Z
   de Oliveira JM, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/8984379
   de Vries AW, 2020, GAMES HEALTH J, V9, P227, DOI 10.1089/g4h.2019.0036
   Delgado F, 2021, GAMES HEALTH J, V10, P2, DOI 10.1089/g4h.2019.0159
   Dingwell JB, 2006, J BIOMECH, V39, P444, DOI 10.1016/j.jbiomech.2004.12.014
   Hausdorff JM, 2001, ARCH PHYS MED REHAB, V82, P1050, DOI 10.1053/apmr.2001.24893
   Herman T, 2005, GAIT POSTURE, V21, P178, DOI 10.1016/j.gaitpost.2004.01.014
   Hof AL, 2007, GAIT POSTURE, V25, P250, DOI 10.1016/j.gaitpost.2006.04.013
   Horsak B, 2021, FRONT BIOENG BIOTECH, V9, DOI 10.3389/fbioe.2021.780314
   Hurt CP, 2010, GAIT POSTURE, V31, P461, DOI 10.1016/j.gaitpost.2010.02.001
   Imaizumi LFI, 2020, NEUROSCI LETT, V737, DOI 10.1016/j.neulet.2020.135333
   Janeh O, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.717291
   Janeh O, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3022731
   Kainz H, 2016, GAIT POSTURE, V46, P30, DOI 10.1016/j.gaitpost.2016.02.011
   Lee K, 2021, GERIATRICS-BASEL, V6, DOI 10.3390/geriatrics6010001
   Lu Y-T., 2021, Sci. Rep, V11, P1, DOI [10.21203/rs.3.rs-255702/v1, DOI 10.21203/RS.3.RS-255702/V1]
   MACKINNON CD, 1993, J BIOMECH, V26, P633, DOI 10.1016/0021-9290(93)90027-C
   Maki BE, 1997, J AM GERIATR SOC, V45, P313, DOI 10.1111/j.1532-5415.1997.tb00946.x
   Martelli D, 2019, GAIT POSTURE, V67, P251, DOI 10.1016/j.gaitpost.2018.10.029
   McAndrew PM, 2011, J BIOMECH, V44, P644, DOI 10.1016/j.jbiomech.2010.11.007
   McAndrew PM, 2010, J BIOMECH, V43, P1470, DOI 10.1016/j.jbiomech.2010.02.003
   Mirelman A, 2010, GAIT POSTURE, V31, P433, DOI 10.1016/j.gaitpost.2010.01.016
   Osoba MY, 2019, LARYNGOSCOPE INVEST, V4, P143, DOI 10.1002/lio2.252
   Palacios-Navarro G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041111
   Palmisano S, 2023, VIRTUAL REAL-LONDON, V27, P1293, DOI 10.1007/s10055-022-00732-5
   Pataky TC, 2012, COMPUT METHOD BIOMEC, V15, P295, DOI 10.1080/10255842.2010.527837
   Peng QC, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.639535
   Perry JA, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.160627
   Rebêlo FL, 2021, EXP GERONTOL, V149, DOI 10.1016/j.exger.2021.111308
   Rosenblatt NJ, 2010, GAIT POSTURE, V31, P380, DOI 10.1016/j.gaitpost.2010.01.002
   Siragy T, 2020, J BIOMECH, V99, DOI 10.1016/j.jbiomech.2019.109529
   Siragy T, 2018, FRONT AGING NEUROSCI, V10, DOI 10.3389/fnagi.2018.00387
   Statista, 2021, Extended Reality (XR): AR, VR, MR-statistics & facts
   Triegaardt J, 2020, NEUROL SCI, V41, P529, DOI 10.1007/s10072-019-04144-3
   Verghese J, 2009, J GERONTOL A-BIOL, V64, P896, DOI 10.1093/gerona/glp033
   Wang Y, 2014, BIOL LETTERS, V10, DOI 10.1098/rsbl.2014.0405
   Willaert J, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-019-0628-3
   WINTER DA, 1995, GAIT POSTURE, V3, P193
   Wu JL, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/30882
   Yamagami M, 2023, DISABIL REHABIL-ASSI, V18, P266, DOI 10.1080/17483107.2020.1842920
   Yang F, 2016, J ELECTROMYOGR KINES, V31, P81, DOI 10.1016/j.jelekin.2016.09.004
   Zahedian-Nasab N, 2021, BMC GERIATR, V21, DOI 10.1186/s12877-021-02462-w
NR 57
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3021
EP 3032
DI 10.1007/s10055-023-00851-7
EA SEP 2023
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001057084400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Oliveira, J
   Gamito, P
   Pereira, R
   Salvador, A
   Bourbon-Teles, J
   Dias, F
   Galhordas, J
   Fantasia, A
AF Oliveira, Jorge
   Gamito, Pedro
   Pereira, Rita
   Salvador, Agata
   Bourbon-Teles, Jose
   Dias, Fabio
   Galhordas, Joao
   Fantasia, Antonio
TI Virtual and real ATM use performance in patients with acquired brain
   injury and healthy controls
SO VIRTUAL REALITY
LA English
DT Article
DE Activities of daily living (ADL); Acquired brain injury (ABI); Virtual
   environment (VE); Computerized cognitive assessment; Functionality
ID FRONTAL ASSESSMENT BATTERY; COGNITIVE ASSESSMENT; REHABILITATION;
   DISEASE; FAB
AB The acquired brain injuries (ABI) have consequences that affect the patients' autonomy, particularly regarding activities of daily living (ADL). To reduce the impact that these changes will have on the patient's life, it is important to develop diversified tasks with which individuals can train and improve their impaired abilities and strengthen those that are preserved. Therefore, this study aimed to validate a virtual ATM (Automated Teller Machine) task to be used to train patients with cognitive impairments. The sample consisted of 34 participants with ABI and 66 healthy controls. These participants performed the task either virtually or with a real ATM. Beyond revealing that the type of environment did not influence task performance, the results showed a relationship between the results of cognitive screening measures and the time to complete the task, in which participants with the lowest results had worse performance in the task. Also, the virtual ATM was more sensitive in discriminating the clinical group than the real task.
C1 [Oliveira, Jorge; Gamito, Pedro; Pereira, Rita; Salvador, Agata; Bourbon-Teles, Jose; Dias, Fabio] Univ Lusofona, HEI Lab EPCV, Campo Grande 376, Lisbon, Portugal.
   [Galhordas, Joao; Fantasia, Antonio] Ctr Med Reabil Alcoitao CMRA, Lisbon, Portugal.
C3 Lusofona University
RP Oliveira, J (corresponding author), Univ Lusofona, HEI Lab EPCV, Campo Grande 376, Lisbon, Portugal.
EM jorge.oliveira@ulusofona.pt
RI gamito, pedro/G-4353-2013; Oliveira, Jorge/F-4476-2015
OI gamito, pedro/0000-0003-0585-8447; Oliveira, Jorge/0000-0002-3467-4981;
   Bourbon Teles, Jose/0000-0001-7892-1908
FU Foundation for Science and Technology FCT [UIDB/05380/2020]
FX Open access funding provided by FCT|FCCN (b-on). This study was funded
   by the Foundation for Science and Technology FCT under the reference
   UIDB/05380/2020.
CR Andrade Luciene Miranda de, 2009, Rev. esc. enferm. USP, V43, P37
   Barman A, 2016, INDIAN J PSYCHOL MED, V38, P172, DOI 10.4103/0253-7176.183086
   Caprio FZ, 2019, MED CLIN N AM, V103, P295, DOI 10.1016/j.mcna.2018.10.001
   Cattelani R, 2010, NEUROPSYCHOL REV, V20, P52, DOI 10.1007/s11065-009-9125-y
   Cooper N, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248225
   Corps KN, 2015, JAMA NEUROL, V72, P355, DOI 10.1001/jamaneurol.2014.3558
   Dobrowolski P., 2021, FRONTIERS VIRTUAL RE, P40, DOI DOI 10.3389/FRVIR.2020.604008
   Dores AR, 2016, VIRTUAL AUGMENTED RE
   Doria JW, 2019, CURR NEUROL NEUROSCI, V19, DOI 10.1007/s11910-019-0957-4
   Dubois B, 2000, NEUROLOGY, V55, P1621, DOI 10.1212/WNL.55.11.1621
   Ebaid D, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00116
   Ekechukwu END, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00337
   Faria AL, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0204-z
   Fong KNK, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-19
   Freitas S, 2011, J CLIN EXP NEUROPSYC, V33, P989, DOI 10.1080/13803395.2011.589374
   Gamito P., 2011, Int. J. Disabil. Hum. Dev, V10, P309, DOI DOI 10.1515/IJDHD.2011.049
   Gamito P, 2023, VIRTUAL REAL-LONDON, V27, P439, DOI 10.1007/s10055-022-00650-6
   Gamito P, 2017, DISABIL REHABIL, V39, P385, DOI 10.3109/09638288.2014.934925
   Gilmore Natalie, 2021, Perspect ASHA Spec Interest Groups, V6, P714, DOI 10.1044/2021_persp-21-00013
   Gracey F, 2017, NEUROREHAB NEURAL RE, V31, P323, DOI 10.1177/1545968316680484
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Hawryluk Gregory W J, 2015, Handb Clin Neurol, V127, P15, DOI 10.1016/B978-0-444-52892-6.00002-7
   Kalisch T, 2011, CLIN INTERV AGING, V6, P37, DOI 10.2147/CIA.S15433
   Kogan E, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-019-1010-x
   LAWTON MP, 1969, GERONTOLOGIST, V9, P179, DOI 10.1093/geront/9.3_Part_1.179
   Lima C, 2008, J NEUROL, V255, P1756, DOI 10.1007/s00415-008-0024-6
   Meyerbröker K, 2021, CLIN PSYCHOL PSYCHOT, V28, P463, DOI 10.1002/cpp.2616
   Nakling AE, 2017, DEMENT GER COGN D EX, V7, P283, DOI 10.1159/000478851
   Oliveira J, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18105290
   Oliveira J, 2018, APPL NEUROPSYCH-ADUL, V25, P555, DOI 10.1080/23279095.2017.1349661
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Pavan LS., 2015, DISTURBIOS COMUNICAC, V27, P831
   Pei L, 2016, Int J Nurs Sci, V3, P29, DOI 10.1016/j.ijnss.2016.01.002
   Ponte AS, 2016, CIENC SAUDE COLETIVA, V21, P3170, DOI 10.1590/1413-812320152110.19162016
   Rizzo AA, 1997, ST HEAL T, V44, P123
   Shin H, 2015, J PHYS THER SCI, V27, P2999, DOI 10.1589/jpts.27.2999
   Shively S, 2012, ARCH NEUROL-CHICAGO, V69, P1245, DOI 10.1001/archneurol.2011.3747
   Silva E., 2010, THESIS FACULDADE MED
   Simoes MR., 2008, MONTREAL COGNITIVE A
   Soccini AM, 2022, J ROBOT MECHATRON, V34, P756, DOI 10.20965/jrm.2022.p0756
   Srivastava P, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00050
   Starns JJ, 2010, PSYCHOL AGING, V25, P377, DOI 10.1037/a0018022
   Stevens J, 2015, J DEF MODEL SIMUL-AP, V12, P519, DOI 10.1177/1548512915569742
   White H., 2016, Traumatic brain injury. Oxford textbook of neurocritical care, P210
NR 44
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2431
EP 2440
DI 10.1007/s10055-023-00819-7
EA JUN 2023
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001009368500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Breves, P
   Stein, JP
AF Breves, Priska
   Stein, Jan-Philipp
TI Cognitive load in immersive media settings: the role of spatial presence
   and cybersickness
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive media; Immersion; Virtual reality; Cognitive load; Spatial
   presence; Cybersickness
ID VIRTUAL-REALITY GAMES; PURCHASE INTENTION; OUTCOMES; QUESTIONNAIRE;
   PERFORMANCE; TECHNOLOGY; KNOWLEDGE; SICKNESS; ATTITUDE; AROUSAL
AB Faced with the ongoing diversification and commercial success of highly immersive media technologies (e.g., VR headsets), both content producers and scientific scholars have become highly invested in understanding the psychological consequences of experiencing media in these new and lifelike ways. While many studies underscore positive effects of high media immersivity-such as increased enjoyment or persuasive success-others warn about the intense cognitive load that technologies such as VR might put on their users. In a laboratory experiment with N = 121 participants, we compare the cognitive load experienced while watching a 360 degrees video on a laptop screen or via an immersive VR head-mounted display. Furthermore, we scrutinize two prominent explanations for the additional cognitive load in immersive media settings, i.e., the role of spatial presence and cybersickness. As expected, the VR condition results in higher cognitive load, spatial presence, and cybersickness than the 2D condition. However, by means of a parallel mediation model, we observe that only cybersickness emerges as a meaningful mediator of participants' strained cognitive capacity; spatial presence, on the other hand, remains statistically irrelevant in this regard. We discuss our findings considering implications for media producers and future research.
C1 [Breves, Priska] Univ Amsterdam, Amsterdam Sch Commun Res, POB 15791, NL-1001 NG Amsterdam, Netherlands.
   [Breves, Priska] Julius Maximilian Univ Wuerzburg, Media & Business Commun, Wurzburg, Germany.
   [Stein, Jan-Philipp] Julius Maximilian Univ Wuerzburg, Psychol Commun & New Media, Oswald Kuelpe Weg 82, D-97074 Wurzburg, Germany.
C3 University of Amsterdam; University of Wurzburg; University of Wurzburg
RP Breves, P (corresponding author), Univ Amsterdam, Amsterdam Sch Commun Res, POB 15791, NL-1001 NG Amsterdam, Netherlands.; Breves, P (corresponding author), Julius Maximilian Univ Wuerzburg, Media & Business Commun, Wurzburg, Germany.
EM p.1.breves@uva.nl; jan-philipp.stein@uni-wuerzburg.de
RI Stein, Jan-Philipp/AAT-6178-2020
OI Stein, Jan-Philipp/0000-0003-3874-0277
CR Ahn SJ, 2019, MEDIA PSYCHOL, V22, P626, DOI 10.1080/15213269.2018.1492939
   Ahn SJ, 2018, J MEDIA PSYCHOL-GER, V30, P91, DOI 10.1027/1864-1105/a000184
   Albus P, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104154
   [Anonymous], 1975, Motion sickness
   Baceviciute S, 2021, COMPUT EDUC, V164, DOI 10.1016/j.compedu.2020.104122
   Bailey R, 2009, CYBERPSYCHOL BEHAV, V12, P277, DOI 10.1089/cpb.2008.0292
   Barreda-Angeles M, 2021, COMMUN MONOGR, V88, P154, DOI 10.1080/03637751.2020.1803496
   Bolin JH, 2014, J EDUC MEAS, V51, P335, DOI 10.1111/jedm.12050
   Bracken CC, 2014, AI SOC, V29, P533, DOI 10.1007/s00146-013-0494-7
   Breves P, 2021, MULTIMED TOOLS APPL, V80, P27299, DOI 10.1007/s11042-021-11057-x
   Breves P, 2021, COMPUT HUM BEHAV, V119, DOI 10.1016/j.chb.2021.106723
   Breves P, 2021, COMPUT HUM BEHAV, V115, DOI 10.1016/j.chb.2020.106606
   Breves P, 2020, NONPROF VOLUNT SEC Q, V49, P1015, DOI 10.1177/0899764020903101
   Breves P, 2019, INT J ADVERT, V38, P1264, DOI 10.1080/02650487.2019.1622326
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   CHANDLER P, 1991, COGNITION INSTRUCT, V8, P293, DOI 10.1207/s1532690xci0804_2
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Davis Simon., 2014, P 2014 C INTERACTIVE, p8:1
   Drolet A, 2004, J CONSUM RES, V31, P63, DOI 10.1086/383424
   Ebenholtz S.M., 1992, Teleoperators and Virtual Environments, V1, P302, DOI DOI 10.1162/PRES.1992.1.3.302
   Eilers K., 1986, Zeitschrift fur Arbeitswissenschaft, V40, P215
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Feng Y, 2019, J ADVERTISING, V48, P137, DOI 10.1080/00913367.2019.1585305
   Gao W, 2018, BEHAV INFORM TECHNOL, V37, P786, DOI 10.1080/0144929X.2018.1484514
   Groth C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P169, DOI 10.1109/VRW52623.2021.00039
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Hu PJH, 2017, MIS QUART, V41, P975
   Huang CL, 2020, J EDUC COMPUT RES, V58, P596, DOI 10.1177/0735633119867422
   Hwang GJ, 2013, COMPUT EDUC, V69, P121, DOI 10.1016/j.compedu.2013.07.008
   International Society for Presence Research, 2000, EXPL PRES
   Israel K, 2019, LECT NOTES COMPUT SC, V11588, P206, DOI 10.1007/978-3-030-22335-9_14
   Jeong EJ, 2011, J ADVERTISING, V40, P59, DOI 10.2753/JOA0091-3367400305
   JungHa Park, 2020, The International Journal of Advanced Culture Technology, V8, P89
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lang A, 2000, J COMMUN, V50, P46, DOI 10.1111/j.1460-2466.2000.tb02833.x
   Leder J, 2019, SAFETY SCI, V111, P271, DOI 10.1016/j.ssci.2018.07.021
   Lee KM, 2004, PRESENCE-TELEOP VIRT, V13, P494, DOI 10.1162/1054746041944830
   Lee S., 2004, P 7 INT WORKSH PRES, P20
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Li HR, 2002, J ADVERTISING, V31, P43, DOI 10.1080/00913367.2002.10673675
   Lin JJW, 2005, ERGONOMICS, V48, P608, DOI 10.1080/00140130400029100
   Litleskare S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02436
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Ma ZX, 2020, MEDIA PSYCHOL, V23, P865, DOI 10.1080/15213269.2019.1651655
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   Makransky G, 2021, J EDUC PSYCHOL, V113, P719, DOI 10.1037/edu0000473
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Mayer RE, 2003, WEB-BASED LEARNING: WHAT DO WE KNOW? WHERE DO WE GO?, P23
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Meijers MHC, 2022, ENVIRON COMMUN, V16, P1, DOI 10.1080/17524032.2021.1943700
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Mittelstaedt JM, 2019, VIRTUAL REAL-LONDON, V23, P143, DOI 10.1007/s10055-018-0370-3
   Monteiro D, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1830
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Oh J., 2018, Journal of Interactive Advertising, V18, P110, DOI DOI 10.1080/15252019.2018.1491812
   Paas F, 2003, EDUC PSYCHOL-US, V38, P63, DOI 10.1207/S15326985EP3801_8
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Panksepp J., 1998, Affective Neuroscience: The Foundations of Human and Animal Emotions
   Parong J, 2021, J COMPUT ASSIST LEAR, V37, P226, DOI 10.1111/jcal.12482
   Parong J, 2020, COMPUT HUM BEHAV, V107, DOI 10.1016/j.chb.2020.106290
   Porcino T., 2021, Journal on Interactive Systems, V12, P269, DOI DOI 10.5753/JIS.2021.2058
   Roettl J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200724
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sauro J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1599
   Schnotz W, 2007, EDUC PSYCHOL REV, V19, P469, DOI 10.1007/s10648-007-9053-4
   Schrader C, 2012, COMPUT HUM BEHAV, V28, P648, DOI 10.1016/j.chb.2011.11.011
   Schubert TW, 2009, COMMUN THEOR, V19, P161, DOI 10.1111/j.1468-2885.2009.01340.x
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Seibert J, 2018, VIRTUAL REAL-LONDON, V22, P79, DOI 10.1007/s10055-017-0316-1
   Sevinc V, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102958
   Shafer D. M., 2017, MEDIA PSYCHOL REV, V11, P1
   Shafer DM, 2019, GAMES HEALTH J, V8, P15, DOI 10.1089/g4h.2017.0190
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Sweller J, 2019, EDUC PSYCHOL REV, V31, P261, DOI 10.1007/s10648-019-09465-5
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
   Uhm JP, 2020, SPORT MANAG REV, V23, P588, DOI 10.1016/j.smr.2019.10.003
   van Berlo ZMC, 2021, J BUS RES, V122, P458, DOI 10.1016/j.jbusres.2020.09.006
   Van Berlo ZMC, 2020, Augmented Reality and Virtual Reality: Changing Realities in a Dynamic World, P11, DOI [10.1007/978-3-030-37869-1_2, DOI 10.1007/978-3-030-37869-1_2]
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
   Varmaghani S, 2022, VIRTUAL REAL-LONDON, V26, P659, DOI 10.1007/s10055-021-00535-0
   Vettehen PH, 2019, COMPUT HUM BEHAV, V91, P24, DOI 10.1016/j.chb.2018.09.018
   Waiguny MKJ, 2014, J CONSUM POLICY, V37, P257, DOI 10.1007/s10603-013-9227-z
   Wehden LO, 2021, MEDIA COMMUN-LISBON, V9, P5, DOI 10.17645/mac.v9i1.3170
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Wissmath Bartholomaus., 2009, Journal of Media Psychology, V21, P114, DOI DOI 10.1027/1864-1105.21.3.114
   Yeo NL, 2020, J ENVIRON PSYCHOL, V72, DOI 10.1016/j.jenvp.2020.101500
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Yim MYC, 2012, J ADVERTISING, V41, P113, DOI 10.2753/JOA0091-3367410208
   ZDF, 2017, IUV UNT FLUCHTL MITT
NR 93
TC 9
Z9 11
U1 7
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1077
EP 1089
DI 10.1007/s10055-022-00697-5
EA NOV 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000884538300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Cáceres-Criado, I
   García-Molina, DF
   Mesas-Carrascosa, FJ
   Triviño-Tarradas, P
AF Caceres-Criado, Irene
   Francisco Garcia-Molina, Diego
   Javier Mesas-Carrascosa, Francisco
   Trivino-Tarradas, Paula
TI New approach for optimizing the interpretation and representation of the
   degree of historical-archaeological evidence in the virtual
   reconstructions
SO VIRTUAL REALITY
LA English
DT Article
DE Baker's house; Virtual reconstruction; Historical-archaeological
   evidence scale; Quantitative-qualitative study
ID PREFERENCES; HERITAGE
AB Virtual reconstruction is defined as the visual recovery of a building or object through the creation of a three-dimensional model of the asset to be reconstructed, in a historical context. To provide the degree of veracity to the virtual reconstructions performed in the scope of heritage, the so-called historical-archaeological evidence scale emerged. Some authors have already used this methodology to provide their reconstructions with the degree of evidence, although none of the current propositions of evidence scales have been standardised to date. Moreover, it is still important to disseminate such scales as much as possible, since it has been shown that neither experts in this field of knowledge nor common users know about this methodology. The aim of this study was to design and create a new proposition of historical-archaeological evidence scale based on the achromatism and implement it in the 'Baker's House' at the archaeological site of Torreparedones (Baena, Cordoba, Spain). To carry out this investigation, it was essential to compare and analyse each proposition of historical-archaeological evidence scale. The qualitative and quantitative studies about the existing scale propositions also played a fundamental role in the realisation of this work. These results, in addition to the chromatic study, support the creation of a new proposition of historical-archaeological evidence scale, designed for any type of viewer. Each phase of the study met the quality standards established for this type of research.
C1 [Caceres-Criado, Irene] Univ Cordoba, Doctoral Program Agr Food Forestry & Rural Dev En, Cordoba, Spain.
   [Francisco Garcia-Molina, Diego] Univ Jaen, Dept Graph Engn Design & Engn Projects, Jaen, Spain.
   [Javier Mesas-Carrascosa, Francisco; Trivino-Tarradas, Paula] Univ Cordoba, Dept Graph Engn & Geomat, Cordoba, Spain.
C3 Universidad de Cordoba; Universidad de Jaen; Universidad de Cordoba
RP Cáceres-Criado, I (corresponding author), Univ Cordoba, Doctoral Program Agr Food Forestry & Rural Dev En, Cordoba, Spain.
EM ig2trtap@uco.es
OI Trivino Tarradas, Paula Maria/0000-0003-1212-0926; Garcia Molina, Diego
   Francisco/0000-0001-8038-3248
CR Adam J.P.L., 1996, construccion Romana, materiales y tecnicas
   [Anonymous], BYZANTIUM 1200
   Aparicio P., 2016, REV OTARQ OTRAS ARQU, V1, P325, DOI [10.23914/otarq.v0i1.102, DOI 10.23914/OTARQ.V0I1.102]
   APARICIO-RESCO P., 2016, Otarq, V1, P235, DOI [10.23914/otarq.v0i1.96, DOI 10.23914/OTARQ.V0I1.96]
   Aparicio-Resco P, 2021, VIRTUAL ARCHAEOL REV, V12, P158, DOI 10.4995/var.2021.14940
   Baz?n B., 2018, REV SONDA INVESTIGAC, V7, P275
   Bustamante Alvarez M., 2014, ANEJOS AESPA, P333
   Caceres-Criado, 2022, LECT NOTES MECH ENG
   Caceres-criado Irene, 2022, Digital Applications in Archaeology and Cultural Heritage, V24, DOI 10.1016/j.daach.2022.e00218
   Cáceres-Criado I, 2022, HERIT SCI, V10, DOI 10.1186/s40494-022-00670-0
   de Mota JGCL, 2018, VIRTUAL ARCHAEOL REV, V9, P76, DOI 10.4995/var.2018.9418
   Corbin JA, 2017, PSICOLOGIA MENTE
   Corrales A., 2016, ANTIQUITAS, V18, P65
   D?az F., 2014, 10 LIBROS ARQUITECTU
   De Grandis L., 1985, Teoria y uso del color
   Dittmar M, 2001, GERONTOLOGY, V47, P219, DOI 10.1159/000052802
   Edwards Betty., 2004, Color by Betty Edwards: A Course in Mastering the Art of Mixing Colors
   Fernandez Diaz A., 2005, ANALES PREHISTORIA A, V21, P127
   Flores FJ, 1993, MOLINO PIEDRA PIEDRA
   Gonz?lez JA., 2003, REV ARQUEOMURCIA REV, V18, P6
   Hammady R, 2021, VIRTUAL REAL-LONDON, V25, P895, DOI 10.1007/s10055-020-00497-9
   Bendicho VMLM, 2011, VIRTUAL ARCHAEOL REV, V2, P71
   Luzon JM, 1975, ITALICA ADRIANO
   Machete R, 2021, J CULT HERIT, V49, P94, DOI 10.1016/j.culher.2021.02.010
   Mezqu?riz MA., 2004, TRABAJOARQUEOLOGIA, V17, P127
   Mohebbi M, 2014, PROCD SOC BEHV, V112, P827, DOI 10.1016/j.sbspro.2014.01.1238
   Morales SM., 2008, B ASOC PROV MUS LOCA, V9, P131
   Morena JA, 2016, BAENA ARQUEOLOGICA B, P2
   Morena JA, 2019, ACTIVIDAD ARQUEOLOGI
   Moreno S., 2015, ARQUEOL TERRIT, V12, P75
   Moskvin A, 2021, J CULT HERIT, V49, P48, DOI 10.1016/j.culher.2021.03.003
   Ortiz-Cordero R, 2018, J CULT HERIT, V30, P10, DOI 10.1016/j.culher.2017.10.006
   Puig A, 2020, VIRTUAL REAL-LONDON, V24, P343, DOI 10.1007/s10055-019-00391-z
   Rahimi FB, 2022, VIRTUAL REAL-LONDON, V26, P1471, DOI 10.1007/s10055-022-00643-5
   Rebec KM, 2022, J CULT HERIT, V55, P30, DOI 10.1016/j.culher.2022.02.005
   Rodríguez-Hernández J, 2021, ARQUEOL ARQUIT, DOI 10.3989/arq.arqt.2021.015
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Schaie KW., 1988, COLOR PERSONALITY
   SEAV (Sociedad Espanola de Arqueologia Virtual), 2011, 3ER FORUM INT ARQUEO
   Sharpe D.T., 1974, The Psychology of Color and Design
   SIERRA B., 2000, DISTRIBUCI N CONSUMO, P5
   TERWOGT MM, 1995, J GEN PSYCHOL, V122, P5, DOI 10.1080/00221309.1995.9921217
   The London Charter, US
   WILSON GD, 1966, PERCEPT MOTOR SKILL, V23, P947, DOI 10.2466/pms.1966.23.3.947
NR 44
TC 4
Z9 4
U1 2
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 967
EP 983
DI 10.1007/s10055-022-00707-6
EA OCT 2022
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000865677500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Obukhov, AD
   Krasnyanskiy, MN
   Dedov, DL
   Nazarova, AO
AF Obukhov, Artem D.
   Krasnyanskiy, Mikhail N.
   Dedov, Denis L.
   Nazarova, Alexandra O.
TI The study of virtual reality influence on the process of professional
   training of miners
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Cybersickness; Professional training; Negative factors
   of interaction with virtual reality; Quantitative metrics; Qualitative
   metrics
ID HIGHER-EDUCATION; FEEDBACK; TRENDS
AB Virtual reality technologies are actively applied for the organization of professional training in various industries, as well as in distance learning. However, numerous studies show the presence of a large number of negative factors that limit the effectiveness of using these technologies (united by the concept of "cybersickness"). The study, identification and reduction in the influence of these negative factors will increase the immersiveness and quality of the professional training process. Within the framework of this study, several hypotheses have been put forward regarding the negative and positive impact of VR technologies on the process of professional training, the coal and mining industry has been chosen as the subject area. Thus, the problem of effective training of miners for activities in regular and emergency situations is considered, in the latter case, VR technologies would allow forming the necessary set of skills and knowledge about actions in emergency situations. To confirm the declared hypotheses, an experimental group of 30 people was formed, corresponding to the trained miners by age characteristics. Based on the analysis, a list of quantitative and qualitative metrics for evaluating interaction with virtual reality was formed, the software of virtual scenes for two tasks (moving simple objects and a set of exercises in a virtual mine) was developed. The experimental group repeatedly performed these exercises, which allowed us to analyze the dynamics of changes in the average values of quantitative and qualitative metrics. The data obtained were processed by statistical tests (Shapiro-Wilk, Kruskal-Wallis, Mann-Whitney), which allowed us to assess the impact of the selected configurations (with and without VR) and the number of attempts on the selected metrics. The obtained results partially or completely confirmed the declared hypotheses and allowed us to form a list of recommendations for the organization of high-quality professional training using virtual reality technologies.
C1 [Obukhov, Artem D.; Krasnyanskiy, Mikhail N.; Dedov, Denis L.; Nazarova, Alexandra O.] Tambov State Tech Univ, Tambov, Russia.
C3 Tambov State Technical University
RP Obukhov, AD (corresponding author), Tambov State Tech Univ, Tambov, Russia.
EM obuhov.ad@tstu.ru; krasnyansky.mn@mail.tstu.ru; hammer68@mail.ru;
   nazarova.al.ol@yandex.ru
RI Obukhov, Artem/M-9836-2019; Krasnyanskiy, Mikhail/E-8692-2014
OI Obukhov, Artem/0000-0002-3450-5213; Nazarova,
   Aleksandra/0000-0002-4741-1451; Krasnyanskiy,
   Mikhail/0000-0002-8751-7445
FU laboratory of medical VR simulator systems for training, diagnostics and
   rehabilitation of Tambov State Technical University
FX The study was carried out with the support of the laboratory of medical
   VR simulator systems for training, diagnostics and rehabilitation of
   Tambov State Technical University.
CR Afanasyev A, 2018, EDULEARN PROC, P10220
   Almeida A, 2018, ADV INTELL SYST, V588, P26, DOI 10.1007/978-3-319-60582-1_3
   [Anonymous], 1975, Motion sickness
   Awang Z., 2015, MODERN APPL SCI, V9, P58, DOI DOI 10.5539/MAS.V9N9P58
   Belyakova A., 2019, RUSSIAN AUTOM HIGHWA, V16, P558
   Benlamine MS, 2021, USER MODEL USER-ADAP, V31, P287, DOI 10.1007/s11257-020-09286-0
   Bockelman P, 2017, CCIS, P3, DOI DOI 10.1007/978-3-319-58753-0_1
   Boletsis C, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7020031
   Caramenti M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195781
   Chassignol M, 2018, PROCEDIA COMPUT SCI, V136, P16, DOI 10.1016/j.procs.2018.08.233
   Choi JY, 2021, DEV MED CHILD NEUROL, V63, P480, DOI 10.1111/dmcn.14762
   Curry C, 2020, INT J HUM-COMPUT INT, V36, P1161, DOI 10.1080/10447318.2020.1726108
   Dobre I, 2015, PROCD SOC BEHV, V180, P313, DOI 10.1016/j.sbspro.2015.02.122
   Dremliuga R., 2020, AZIMUTH SCIENTIF RES, V9, P22, DOI [10.26140/anie-2020-0901-0003, DOI 10.26140/ANIE-2020-0901-0003]
   Feick M., 2020, ADJUNCT P ANN ACM S, P68, DOI [DOI 10.1145/3379350.3416188, 10.1145/3379350.3416188]
   Bernardes SMF, 2015, PROCEDIA MANUF, V3, P6313, DOI 10.1016/j.promfg.2015.07.946
   Gaggioli A, 2020, ANN REV CYBERTHERAPY, V18, P73
   Goh Poh-Sun, 2020, MedEdPublish (2016), V9, P49, DOI 10.15694/mep.2020.000049.1
   Grassini S, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5030007
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Grech V, 2018, EARLY HUM DEV, V123, P48, DOI 10.1016/j.earlhumdev.2018.04.014
   Hu-Au E., 2017, INT J INNOVATION ED, V4, P215, DOI [DOI 10.1504/IJIIE.2017.10012691, 10.1504/ijiie.2017, DOI 10.1504/IJIIE.2017, https://doi.org/10.1504/IJIIE.2017.10012691]
   Johnson D, 2018, INT J HUM-COMPUT ST, V118, P38, DOI 10.1016/j.ijhcs.2018.05.003
   Keenan JC, 2016, J BUS ETHICS, V135, P607, DOI 10.1007/s10551-014-2376-4
   Kim H, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91573-w
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   Krasnyanskiy M., 2018, J APPL ENG SCI, V16, P487, DOI [10.5937/jaes16-17627, DOI 10.5937/JAES16-17627]
   Krasnyanskiy M, 2020, INT J EMERG TECHNOL, V15, P86, DOI 10.3991/ijet.v15i02.11584
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Liang ZP, 2019, IEEE ACCESS, V7, P118639, DOI 10.1109/ACCESS.2019.2934990
   Likitweerawong Kookiet, 2018, 2018 International Conference on Digital Arts, Media and Technology (ICDAMT), P158, DOI 10.1109/ICDAMT.2018.8376515
   Mareev O., 2018, J SCI ARTICL HLTH ED, V20, P92, DOI [10.26787/nydha-2226-7425-2018-20-1-103-107, DOI 10.26787/NYDHA-2226-7425-2018-20-1-103-107]
   McGrath JL, 2018, ACAD EMERG MED, V25, P186, DOI 10.1111/acem.13308
   Miclaus R, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10090655
   Nam SH, 2018, J SENSORS, V2018, DOI 10.1155/2018/9054758
   Nemtinov V., 2020, VYSSH OBRAZ ROSS, V29, P159, DOI [10.31992/0869-3617-2020-29-2-159-168, DOI 10.31992/0869-3617-2020-29-2-159-168]
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   [Парфенов В.А. Parfenov V.A.], 2016, [Неврология, нейропсихиатрия, психосоматика, Nevrologiya, neiropsikhiatriya, psikhosomatika], V8, P17, DOI 10.14412/2074-2711-2016-2-17-23
   Patle DS, 2019, VIRTUAL REAL-LONDON, V23, P293, DOI 10.1007/s10055-018-0354-3
   Pel AJ, 2012, TRANSPORTATION, V39, P97, DOI 10.1007/s11116-011-9320-6
   Plechatá A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01330
   Porcino T, 2020, SYMP VIRTUAL AUGMENT, P154, DOI 10.1109/SVR51698.2020.00035
   Rajanna V, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204541
   Razali N. M., 2011, J. Stat. Model. and Anal., V2, P21, DOI DOI 10.1515/BILE-2015-0008
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Rizzo A, 2017, NEUROPSYCHOLOGY, V31, P877, DOI 10.1037/neu0000405
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Sommer M, 2013, INT J EMERG MANAG, V9, P151, DOI 10.1504/IJEM.2013.055161
   Sorensen JL, 2013, TRIALS, V14, DOI 10.1186/1745-6215-14-220
   Tikhonova E, 2018, J LANG EDUC, V4, P4, DOI 10.17323/2411-7390-2018-4-4-4-7
   Tychsen L, 2020, AM J OPHTHALMOL, V209, P151, DOI 10.1016/j.ajo.2019.07.020
   Udeozor C, 2021, HIGH EDUC PEDAGOG, V6, P175, DOI 10.1080/23752696.2021.1951615
   Vosinakis S, 2018, VIRTUAL REAL-LONDON, V22, P47, DOI 10.1007/s10055-017-0313-4
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wenk N, 2023, VIRTUAL REAL-LONDON, V27, P307, DOI 10.1007/s10055-021-00565-8
   Wu CM, 2017, VIRTUAL REAL-LONDON, V21, P19, DOI 10.1007/s10055-016-0296-6
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Yildirim G., 2018, ASIAN J ED TRAINING, V4, P62, DOI [10.20448/journal.522.2018.42.62.69, DOI 10.20448/JOURNAL.522.2018.42.62.69, https://doi.org/10.20448/journal.522.2018.42.62.69]
NR 60
TC 4
Z9 4
U1 4
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 735
EP 759
DI 10.1007/s10055-022-00687-7
EA AUG 2022
PG 25
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000846111600001
PM 36061945
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Gulhan, D
   Durant, S
   Zanker, JM
AF Gulhan, Doga
   Durant, Szonya
   Zanker, Johannes M.
TI Aesthetic judgments of 3D arts in virtual reality and online settings
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality (VR); Empirical aesthetics; Art appreciation; Aesthetic
   judgment; Eye-tracking; Online experiment
ID APPRECIATION; EXPERIENCE; PREFERENCE; COMPLEXITY; CONTEXT; MUSEUMS;
   POWER
AB Empirical aesthetics is beginning to branch off from conventional laboratory-based studies, leading to in-situ, immersive, often more accessible experiments. Here, we explored different types of aesthetic judgments of three-dimensional artworks in two contexts: virtual reality (VR), aiming for an immersive experience, and online settings aiming for an accessible setup for a remote audience. Following the pilot experiment conducted to select a set of 3D artworks, in the first experiment, participants freely engaged with virtual artworks via an eye-tracking-enabled VR headset and provided evaluations based on subjective measures of aesthetic experience such as ratings on liking, novelty, complexity, perceived viewing duration; and the objective viewing duration was also recorded. Results showed positive, linear, and mostly moderate correlations between liking and the other perceived judgment attributes. Supplementary eye-tracking data showed a range of viewing strategies and variation in viewing durations between participants and artworks. Results of the second experiment, adapted as a short online follow-up, showed converging evidence on correlations between the different aspects contributing to aesthetic judgments and suggested similarity of judgment strategies across contexts. In both settings, participants provided further insights via exit questionnaires. We speculate that both VR and online settings offer ecologically valid experimental contexts, create immersive visual arts experience, and enhance accessibility to cultural heritage.
C1 [Gulhan, Doga; Durant, Szonya; Zanker, Johannes M.] Royal Holloway Univ London, Dept Psychol, Surrey, England.
C3 University of London; Royal Holloway University London
RP Gulhan, D (corresponding author), Royal Holloway Univ London, Dept Psychol, Surrey, England.
EM doga.gulhan@rhul.ac.uk
FU Royal Holloway University of London (RHUL)
FX The authors would like to thank Royal Holloway University of London
   (RHUL) for the doctoral scholarship of Doga Gulhan and access to the
   Psychology VR lab.
CR [Anonymous], 2016, ROLE MUSEUM ED YOUNG
   Arai S, 2016, ART PERCEPT, V4, P225, DOI 10.1163/22134913-00002052
   Augustin MD, 2012, ACTA PSYCHOL, V139, P187, DOI 10.1016/j.actpsy.2011.10.004
   Aumann A, 2014, J AESTHET ART CRITIC, V72, P117, DOI 10.1111/jaac.12073
   Belchev Z, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196246
   BERLYNE DE, 1958, J EXP PSYCHOL, V55, P289, DOI 10.1037/h0043555
   Brieber D, 2015, EMPIR STUD ARTS, V33, P95, DOI 10.1177/0276237415570000
   Carbon CC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517694184
   Chatterjee A., 2010, EMPIR STUD ARTS, V28, P207, DOI DOI 10.2190/EM.28.2.F
   Chen W., 2019, Proceedings of the Advances in Neural Information Processing Systems, P9609
   Chiquet S, 2021, VIRTUAL REAL-LONDON, V25, P655, DOI 10.1007/s10055-020-00478-y
   Cleeremans A, 2016, EMPIR STUD ARTS, V34, P126, DOI 10.1177/0276237415621197
   Clini P., 2018, INT ARCH PHOTOGRAMME, V4-7, P251, DOI DOI 10.5194/ISPRS-ARCHIVES-XLII-2-251-2018
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Consoli G, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01520
   Cooper J.M., 2009, Empir. Stud. Arts, V27, P109, DOI [10.2190/EM.27.1.f, DOI 10.2190/EM.27.1.F]
   Cova F, 2012, MONIST, V95, P241, DOI 10.5840/monist201295214
   Cupchik G.C., 1988, EMPIR STUD ARTS, V6, P1, DOI DOI 10.2190/5YN3-J3P8-FWHY-UDB3
   Faerber SJ, 2012, I-PERCEPTION, V3, P553, DOI 10.1068/i0506
   Fayn K, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01877
   Friedenberg J, 2016, ACTA PSYCHOL, V168, P41, DOI 10.1016/j.actpsy.2016.04.007
   Ginsborg H, 2006, INQUIRY, V49, P403, DOI 10.1080/00201740600937898
   Graf LKM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00015
   Grüner S, 2019, EMPIR STUD ARTS, V37, P138, DOI 10.1177/0276237418822896
   Güçlütürk Y, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00112
   Gulhan D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91904-x
   Hayn-Leichsenring GU, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01857
   Helbing J, 2020, COGNITION, V196, DOI 10.1016/j.cognition.2019.104147
   Hoang TN, 2017, PRESENCE-VIRTUAL AUG, V26, P402, DOI 10.1162/PRES_a_00307
   Isik AI, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223896
   Kim S, 2019, J VISION, V19, DOI 10.1167/19.12.19
   Koutsabasis P, 2018, VIRTUAL REAL-LONDON, V22, P103, DOI 10.1007/s10055-017-0325-0
   Landau MJ, 2006, J PERS SOC PSYCHOL, V90, P879, DOI 10.1037/0022-3514.90.6.879
   Leder H, 2006, ACTA PSYCHOL, V121, P176, DOI 10.1016/j.actpsy.2005.08.005
   Leder H, 2004, BRIT J PSYCHOL, V95, P489, DOI 10.1348/0007126042369811
   Liarokapis F, 2020, VISUAL COMPUTING CUL, DOI [10.1007/978-3-030-37191-3, DOI 10.1007/978-3-030-37191-3]
   Locher P., 1999, Empirical Studies of the Arts, V17, P121, DOI [/10.2190/R1WN-TAF2-376D-EFUH, DOI 10.2190/R1WN-TAF2-376D-EFUH, 10.2190/R1WN-TAF2-376D-EFUH]
   Locher P, 2011, I-PERCEPTION, V2, P697, DOI 10.1068/i0449aap
   Mallon B, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00161
   Markovic S, 2008, SPATIAL VISION, V21, P229, DOI 10.1163/156856808784532563
   Mildenhall B, 2020, ARXIV
   Moore KM, 2012, EMPIR STUD ARTS, V30, P23, DOI 10.2190/EM.30.1.d
   Muth C, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00365
   Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004
   Parker E, 2020, CONVERGENCE-US, V26, P1159, DOI 10.1177/1354856519897251
   Peer E, 2017, J EXP SOC PSYCHOL, V70, P153, DOI 10.1016/j.jesp.2017.01.006
   Pelowski M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01729
   Pelowski M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01006
   Petrelli Daniela, 2019, Digital Applications in Archaeology and Cultural Heritage, V15, P89, DOI 10.1016/j.daach.2019.e00123
   Pratt J, 2010, PSYCHOL SCI, V21, P1724, DOI 10.1177/0956797610387440
   Russell P.A., 1997, Empirical Studies of the Arts, V15, P61, DOI [10.2190/EHT3-HWVM-52CB-8QHJ, DOI 10.2190/EHT3-HWVM-52CB-8QHJ]
   Schepman A, 2015, J VISION, V15, DOI 10.1167/15.5.11
   Schöne B, 2021, VIRTUAL REAL-LONDON, V25, P209, DOI 10.1007/s10055-020-00450-w
   Seif El-Nasr M., 2006, P 2006 ACM SIGCHI IN, DOI DOI 10.1145/1178823.1178849
   Silvia PaulJ., 2007, PSYCHOL AESTHET CREA, V1, P100, DOI DOI 10.1037/1931-3896.1.2.100
   Skov M, 2020, PERSPECT PSYCHOL SCI, V15, P630, DOI 10.1177/1745691619897963
   Smith LF., 2006, EMPIR STUD ARTS, V24, P229, DOI [10.2190/DJM0-QBDW-03V7-BLRM, DOI 10.2190/DJM0-QBDW-03V7-BLRM, 10.2190/djm0-qbdw-03v7-blrm]
   Smith LF, 2017, PSYCHOL AESTHET CREA, V11, P77, DOI 10.1037/aca0000049
   Song J, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.694927
   Turpin MH, 2019, JUDGM DECIS MAK, V14, P658
   van Helvoort D, 2020, MEM COGNITION, V48, P691, DOI 10.3758/s13421-020-01024-6
   VITZ PC, 1966, BEHAV SCI, V11, P105, DOI 10.1002/bs.3830110204
   Wagner V, 2014, PSYCHOL AESTHET CREA, V8, P120, DOI 10.1037/a0036126
   Wassiliwizky E, 2021, TRENDS COGN SCI, V25, P437, DOI 10.1016/j.tics.2021.03.008
   Woods AT, 2015, PEERJ, V3, DOI 10.7717/peerj.1058
   Young J. O., 2017, Semantics of Aesthetic Judgements
   Zhao HT, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.191523
NR 67
TC 5
Z9 5
U1 12
U2 44
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 573
EP 589
DI 10.1007/s10055-022-00671-1
EA JUL 2022
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000830267400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Lahav, O
   Wolfson, A
AF Lahav, Orly
   Wolfson, Ana
TI Enhancing spatial skills of young children with special needs using the
   Osmo Tangram based on tangible technology versus a Tangram card game
SO VIRTUAL REALITY
LA English
DT Article
DE Young children; Special needs; Spatial ability; Tangible technology
ID PLAY
AB Looking at a group of kindergarteners and preschoolers, this study conducts a comparison of spatial ability performing identical spatial tasks during play with two different tangible interfaces: a Tangram card game versus an Osmo Tangram game. The main difference between the two interfaces is that the user receives computer feedback using the Osmo set and receives no feedback using the card set. Spatial perception development in young children indicates school readiness and predicts academic success in reading, arithmetic, science, and technology. The player is asked to place puzzle pieces in different positions in different orientations in relation to an entire pattern. Through the game the user learns spatial properties of different pieces in relation to their location and orientation and also gains cognitive rotation strategies. The Osmo tangible user interface integrates digital and physical objects. For students with special needs the tangible interface can assist in independent learning by using animation, acting, and auditory and visual feedback. Twenty young children participated in this research; they were divided into three experimental groups: children with a developmental disability, children with high-functioning autism, and children without special needs. All research participants showed improvement using the Osmo Tangram game compared to using the Tangram card game, with statistically significant results. The research results are likely to promote classroom integration of tangible technology games for learning spatial skills to the benefit of young children with and without special needs. Training in spatial tasks through tangible technologies has the potential to improve school readiness and academic success in reading, arithmetic, science, and technology.
C1 [Lahav, Orly; Wolfson, Ana] Tel Aviv Univ, Constantiner Sch Educ, Dept Math Sci & Technol Educ, IL-6997801 Tel Aviv, Israel.
C3 Tel Aviv University
RP Lahav, O (corresponding author), Tel Aviv Univ, Constantiner Sch Educ, Dept Math Sci & Technol Educ, IL-6997801 Tel Aviv, Israel.
EM lahavo@tauex.tau.ac.il
CR [Anonymous], 2016, OSMO TEACHERS GUIDE
   Baykal G. E., 2018, International Journal of Child-Computer Interaction, V16, P104, DOI 10.1016/j.ijcci.2018.01.003
   Bekele E, 2014, AUTISM, V18, P598, DOI 10.1177/1362361313479454
   Costa Costa S. S., 2013, ACHI 2013, VVolume 7 Volume 7, P117
   Dillenbourg P, 2010, NEW SCIENCE OF LEARNING: COGNITION, COMPUTERS AND COLLABORATION IN EDUCATION, P525, DOI 10.1007/978-1-4419-5716-0_26
   GARDNER H, 1995, PHI DELTA KAPPAN, V77, P200
   Gold ZS, 2021, EARLY EDUC DEV, V32, P49, DOI 10.1080/10409289.2019.1709382
   Hamidi F, 2012, CSE201202 DEP COMP S
   Horn MS, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P975
   Kim Hae-Young, 2013, Restor Dent Endod, V38, P52, DOI 10.5395/rde.2013.38.1.52
   Lepisto Auli, 2004, P 3 NORD C HUM COMP, P305
   Levine SC, 2012, DEV PSYCHOL, V48, P530, DOI 10.1037/a0025913
   Marco J, 2013, PERS UBIQUIT COMPUT, V17, P1577, DOI 10.1007/s00779-012-0522-5
   MARMOR GS, 1975, COGNITIVE PSYCHOL, V7, P548, DOI 10.1016/0010-0285(75)90022-5
   Marshall P., 2007, P 1 ST INT C TANGIBL, P163, DOI DOI 10.1145/1226969.1227004
   Newcombe NS, 2010, MIND BRAIN EDUC, V4, P102, DOI 10.1111/j.1751-228X.2010.01089.x
   Papert S., 1993, MINDSTORM CHILDREN C, V2
   Passolunghi MC, 2012, J LEARN DISABIL-US, V45, P341, DOI 10.1177/0022219411400746
   Piaget J., 1956, Childs Conception of Space
   Piaget J., 1951, Organization and pathology of thought: Selected sources, P154
   Piaget J., 1971, MENTAL IMAGERY CHILD
   Piaget Jean, 1967, On the Development of Memory and Identity, V19
   Scarlatos LL, 2006, INTERACT TECHNOL SMA, V3, P293, DOI 10.1108/17415650680000069
   Schroth S., 2019, J ED TECHNOL DEV EXC, DOI [10.18785/jetde.1101.01, DOI 10.18785/JETDE.1101.01]
   Sitdhisanguan K, 2012, PERS UBIQUIT COMPUT, V16, P143, DOI 10.1007/s00779-011-0382-4
   Soysa AI, 2019, LECT NOTES COMPUT SC, V11747, P135, DOI 10.1007/978-3-030-29384-0_8
   Uttal DH, 2013, PSYCHOL BULL, V139, P352, DOI 10.1037/a0028446
   VYGOTSKY LS, 1967, SOV PSYCHOL-USSR, V5, P6, DOI 10.2753/RPO1061-040505036
   Weng C, 2020, J COMPUT ASSIST LEAR, V36, P458, DOI 10.1111/jcal.12411
   Yang WP, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01938
NR 30
TC 1
Z9 1
U1 2
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 451
EP 463
DI 10.1007/s10055-022-00665-z
EA JUN 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000814472200001
DA 2024-07-18
ER

PT J
AU Glaser, N
   Schmidt, M
   Schmidt, C
AF Glaser, Noah
   Schmidt, Matthew
   Schmidt, Carla
TI Learner experience and evidence of cybersickness: design tensions in a
   virtual reality public transportation intervention for autistic adults
SO VIRTUAL REALITY
LA English
DT Article
DE Autism spectrum disorder; Cybersickness; Virtual reality; Oculus rift;
   Accessibility
ID TECHNOLOGY-BASED INTERVENTIONS; SPECTRUM DISORDER; SOCIAL-SKILLS;
   SIMULATOR SICKNESS; ASPERGER-SYNDROME; CHILDREN; QUESTIONNAIRE;
   ENVIRONMENTS; INDIVIDUALS; ADOLESCENTS
AB People with autism spectrum disorders (ASD) exhibit a range of socio-communicative and behavioral deficits which leads to difficulties holding meaningful relationships and vocational opportunities. Unfortunately, it is oftentimes difficult for this population to transfer learned skills from controlled intervention contexts into the real-world. As a result, interest in using virtual reality (VR) to create naturalistic training contexts has grown. Research has provided evidence to support the benefits of using VR-based training for people with ASD. However, the emergence of commercially available head-mounted displays (HMD), and their association with cybersickness, has led many to wonder if people with ASD would continue to find VR as being acceptable if they were to be immersed within these devices. Further, people with ASD often have sensory integration disorders making the continued use of VR a potential ethical concern. This research examined the extent that adults with ASD from a day program felt symptoms of cybersickness while undergoing sessions of a VR-training program. The nature of learner experiences while using HMD were also explored. Research questions were addressed through multi-method procedures that utilized quantitative and qualitative data. Despite the presence of some cybersickness symptoms, participants found the experiences to be positive and acceptable.
C1 [Glaser, Noah] Univ Missouri, Sch Informat Sci & Learning Technol, Columbia, MO USA.
   [Schmidt, Matthew; Schmidt, Carla] Univ Florida, Sch Teaching & Learning, Gainesville, FL USA.
C3 University of Missouri System; University of Missouri Columbia; State
   University System of Florida; University of Florida
RP Glaser, N (corresponding author), Univ Missouri, Sch Informat Sci & Learning Technol, Columbia, MO USA.
EM noah.glaser@missouri.edu
RI Glaser, Noah/HNR-3521-2023
OI Glaser, Noah/0000-0002-1966-2720; Schmidt, Matthew/0000-0002-8110-4367
CR Adjorlu A, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P294, DOI 10.1109/ISMAR-Adjunct.2017.93
   Ames SL, 2005, OPTOMETRY VISION SCI, V82, P168, DOI 10.1097/01.OPX.0000156307.95086.6
   [Anonymous], 2013, Diagnostic and statistical manual of mental disorders
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Bailenson J.N., 2008, Mediated interpersonal communication, P77, DOI 10.4324/9780203926864
   Baio J., 2018, Children Aged 8 Years - Autism and Developmental Disabilities Monitoring Network, V67, P11
   Bartoli L., 2014, IDC'14 Proceedings, P17, DOI DOI 10.1145/2593968.2593976
   Baxter AJ, 2015, PSYCHOL MED, V45, P601, DOI 10.1017/S003329171400172X
   Beaumont R, 2008, J CHILD PSYCHOL PSYC, V49, P743, DOI 10.1111/j.1469-7610.2008.01920.x
   Bellani M, 2011, EPIDEMIOL PSYCH SCI, V20, P235, DOI 10.1017/S2045796011000448
   Benaquisto L., 2008, The Sage Encyclopedia of Qualitative Research Methods, DOI [DOI 10.4135/9781412963909, 10.4135/9781412963909]
   Bian Dayi, 2013, Universal Access in Human-Computer Interaction. User and Context Diversity. 7th International Conference, UAHCI 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8010, P474, DOI 10.1007/978-3-642-39191-0_52
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bozgeyikli L, 2018, IEEE T LEARN TECHNOL, V11, P133, DOI 10.1109/TLT.2017.2739747
   Bozgeyikli L, 2017, ACM T ACCESS COMPUT, V10, DOI 10.1145/3046786
   Bradley R, 2018, J ENABLING TECHNOL, V12, P101, DOI 10.1108/JET-01-2018-0004
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Brown DJ, 2002, 4 INT C
   Bruck S, 2011, DISPLAYS, V32, P153, DOI 10.1016/j.displa.2011.07.002
   Carter A.S., 2005, Handbook of Autism and Pervasive Developmental Disorders, Diagnosis, Development, Neurobiology, and Behavior, V1
   Chan W, 2017, AUTISM RES, V10, P1663, DOI 10.1002/aur.1813
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chardonnet JR, 2017, INT J HUM-COMPUT INT, V33, P771, DOI 10.1080/10447318.2017.1286767
   Chen JY, 2019, COMPUT HUM BEHAV, V90, P204, DOI 10.1016/j.chb.2018.08.057
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Cooper J. O., 2019, Applied Behavior Analysis, V3rd
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Davignon MN, 2014, J DEV BEHAV PEDIATR, V35, P207, DOI 10.1097/DBP.0000000000000036
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Denzin N. K., 2018, SAGE HDB QUALITATIVE
   Durkin K, 2010, REV GEN PSYCHOL, V14, P122, DOI 10.1037/a0019438
   Eaves LC, 2008, J AUTISM DEV DISORD, V38, P739, DOI 10.1007/s10803-007-0441-x
   Frith U., 2003, Focus on Autism and Other Developmental Disabilities, V7, P13, DOI [DOI 10.1177/108835769200700302, 10.1177/108835769200700302]
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Geenen SJ, 2003, J ADOLESCENT HEALTH, V32, P225, DOI 10.1016/S1054-139X(02)00396-8
   Gianaros PJ, 2001, AVIAT SPACE ENVIR MD, V72, P115
   Gibson J. J., 2014, The ecological approach to visual perception, Vclassic
   Glaser N., 2021, Intersections Across Disciplines: Interdisciplinarity and Learning, P157, DOI [10.1007/978-3-030-53875-0_13, DOI 10.1007/978-3-030-53875-0_13]
   Glaser N.J., 2018, TECHNOL KNOWL LEARN, P1
   Glaser N, 2023, TECHNOL KNOWL LEARN, V28, P925, DOI 10.1007/s10758-022-09594-x
   Grynszpan O, 2014, AUTISM, V18, P346, DOI 10.1177/1362361313476767
   Hedley D, 2017, AUTISM, V21, P929, DOI 10.1177/1362361316661855
   Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687
   Jarrold W, 2013, AUTISM RES, V6, P393, DOI 10.1002/aur.1302
   Kanne SM, 2011, J AUTISM DEV DISORD, V41, P926, DOI 10.1007/s10803-010-1118-4
   Kennedy RS, 1993, INT J AVIAT PSYCHOL, V3
   Knight V, 2013, J AUTISM DEV DISORD, V43, P2628, DOI 10.1007/s10803-013-1814-y
   Kwok EYL, 2015, RES AUTISM SPECT DIS, V9, P202, DOI 10.1016/j.rasd.2014.10.008
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lee LC, 2007, RES AUTISM SPECT DIS, V1, P126, DOI 10.1016/j.rasd.2006.08.004
   Leung RC, 2016, CHILD NEUROPSYCHOL, V22, P336, DOI 10.1080/09297049.2015.1005066
   Lincoln Y. S., 1986, NEW DIRECTIONS PROGR, V1986, P73, DOI [10.1002/ev.1427, DOI 10.1002/EV.1427]
   LORD C, 1982, J AUTISM DEV DISORD, V12, P317, DOI 10.1007/BF01538320
   Maraj CS, 2017, ADV INTELL SYST, V498, P635, DOI 10.1007/978-3-319-42070-7_59
   Matson JL, 2009, RES AUTISM SPECT DIS, V3, P977, DOI 10.1016/j.rasd.2009.06.001
   Mazurek MO, 2013, COMPUT HUM BEHAV, V29, P1709, DOI 10.1016/j.chb.2013.02.004
   Miller HL, 2016, CYBERPSYCH BEH SOC N, V19, P246, DOI 10.1089/cyber.2014.0682
   Mitchell P, 2007, J AUTISM DEV DISORD, V37, P589, DOI 10.1007/s10803-006-0189-8
   Müller E, 2008, AUTISM, V12, P173, DOI 10.1177/1362361307086664
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Newbutt N, 2016, J AUTISM DEV DISORD, V46, P3166, DOI 10.1007/s10803-016-2830-5
   Parsons S, 2004, J AUTISM DEV DISORD, V34, P449, DOI 10.1023/B:JADD.0000037421.98517.8d
   Parsons S, 2016, EDUC RES REV-NETH, V19, P138, DOI 10.1016/j.edurev.2016.08.001
   Potter WJ, 1999, J APPL COMMUN RES, V27, P258, DOI 10.1080/00909889909365539
   Rao PA, 2008, J AUTISM DEV DISORD, V38, P353, DOI 10.1007/s10803-007-0402-4
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Rose D.H., 2006, PRACTICAL READER UNI
   Rump KM, 2009, CHILD DEV, V80, P1434, DOI 10.1111/j.1467-8624.2009.01343.x
   Schmidt M., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P3387, DOI 10.1109/HICSS.2012.639
   Schmidt M., 2021, FRONT VIRTUAL REAL, DOI 10.3389/frvir.2021.611740
   Schmidt M., 2019, Interactive Learning Environments, P1
   Schmidt M, 2021, ETR&D-EDUC TECH RES, V69, P1665, DOI 10.1007/s11423-021-10005-8
   Schmidt MM, 2021, J ENABLING TECHNOL, V15, P137, DOI 10.1108/JET-09-2020-0037
   Self T, 2007, TOP LANG DISORD, V27, P242, DOI 10.1097/01.TLD.0000285358.33545.79
   Simonoff E, 2008, J AM ACAD CHILD PSY, V47, P921, DOI 10.1097/CHI.0b013e318179964f
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P135
   Standen PJ, 2005, CYBERPSYCHOL BEHAV, V8, P272, DOI 10.1089/cpb.2005.8.272
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stokes TF, 2016, BEHAV THER, V47, P720, DOI 10.1016/j.beth.2016.08.012
   STRICKLAND D, 1997, VIRTUAL REALITY NEUR
   Thorson RT, 2012, RES AUTISM SPECT DIS, V6, P556, DOI 10.1016/j.rasd.2011.07.016
   Tuchman R, 2002, LANCET NEUROL, V1, P352, DOI 10.1016/S1474-4422(02)00160-6
   Wang M., 2014, Comprehensive guide to autism, P2125
   Wang M, 2011, NEUROEPIDEMIOLOGY, V36, P2, DOI 10.1159/000320847
   Wei Chen, 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2119
   Wong C, 2015, J AUTISM DEV DISORD, V45, P1951, DOI 10.1007/s10803-014-2351-z
   Zhang L, 2018, J AUTISM DEV DISORD, V48, P2779, DOI 10.1007/s10803-018-3544-7
NR 90
TC 8
Z9 8
U1 5
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1705
EP 1724
DI 10.1007/s10055-022-00661-3
EA JUN 2022
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000806688600001
DA 2024-07-18
ER

PT J
AU Stamm, O
   Dahms, R
   Reithinger, N
   Russ, A
   Müller-Werdan, U
AF Stamm, Oskar
   Dahms, Rebecca
   Reithinger, Norbert
   Russ, Aaron
   Mueller-Werdan, Ursula
TI Virtual reality exergame for supplementing multimodal pain therapy in
   older adults with chronic back pain: a randomized controlled pilot study
SO VIRTUAL REALITY
LA English
DT Article
DE Physical therapy; Psychotherapy; Virtual reality; Multimodal pain
   therapy; Serious gaming; Chronic back pain
ID EXERCISE PROGRAM; PSYCHOMETRIC PROPERTIES; PHYSICAL FUNCTION; TAMPA
   SCALE; WII FIT; AVOIDANCE; FEAR; ADHERENCE; RECOMMENDATIONS;
   REHABILITATION
AB Immersive Virtual Reality (VR) with head-mounted displays (HMD) can be a promising tool for increasing adherence to exercise in older adults. However, there is little known about the effectiveness of an interactive multimodal therapy in VR for older chronic back pain (CBP) patients. The aim of the exploratory randomized controlled trial was to examine the preliminary effectiveness of a VR multimodal therapy for older adults with CBP in a laboratory setting over a period of four weeks. The intervention group (IG; n = 11) received a multimodal pain therapy in VR (movement therapy and psychoeducation) and the control group (CG; n = 11) received a conventional multimodal pain therapy (chair-based group exercises and psychoeducation in a group setting). Although the VR therapy (IG) did not reach the pain intensity reduction of the CG (IG: MD = 0.64, p = .535; CG: MD = 1.64, p = .07), both groups showed a reduction in pain intensity on the Numeric Rating Scale. The functional capacity in the IG improved from Visit 1 (x) over bar = 73.11% to Visit 2, (x) over bar = 81.82% (MD = 8.71%; p =.026). In the changes of fear avoidance beliefs and general physical and mental health, no significance was achieved in either group. Although the IG did not reach a significant pain intensity reduction compared to the CG, the results of the present study showed that a pain intensity reduction can be achieved with the current VR application.
C1 [Stamm, Oskar; Dahms, Rebecca; Mueller-Werdan, Ursula] Charite Univ Med Berlin, Dept Geriatr & Med Gerontol, Working Grp Age & Technol, Reinickendorfer Str 61, D-13347 Berlin, Germany.
   [Stamm, Oskar; Dahms, Rebecca; Mueller-Werdan, Ursula] Free Univ Berlin, Reinickendorfer Str 61, D-13347 Berlin, Germany.
   [Stamm, Oskar; Dahms, Rebecca; Mueller-Werdan, Ursula] Humboldt Univ, Reinickendorfer Str 61, D-13347 Berlin, Germany.
   [Reithinger, Norbert; Russ, Aaron] Deutsch Forschungszentrum Kunstliche Intelligenz, DFKI, Alt Moabit 91c, D-10559 Berlin, Germany.
C3 Free University of Berlin; Humboldt University of Berlin; Charite
   Universitatsmedizin Berlin; Free University of Berlin; Humboldt
   University of Berlin; German Research Center for Artificial Intelligence
   (DFKI)
RP Stamm, O (corresponding author), Charite Univ Med Berlin, Dept Geriatr & Med Gerontol, Working Grp Age & Technol, Reinickendorfer Str 61, D-13347 Berlin, Germany.; Stamm, O (corresponding author), Free Univ Berlin, Reinickendorfer Str 61, D-13347 Berlin, Germany.; Stamm, O (corresponding author), Humboldt Univ, Reinickendorfer Str 61, D-13347 Berlin, Germany.
EM oskar.stamm@charite.de
RI Stamm, Oskar/ABE-6115-2021
OI Stamm, Oskar/0000-0003-1584-687X; Reithinger,
   Norbert/0000-0003-3696-2888; Muller-Werdan, Ursula/0000-0003-4440-8991
FU German Federal Ministry of Education and Research (BMBF) [16SV7952]
FX Open Access funding enabled and organized by Projekt DEAL. This work was
   supported by the German Federal Ministry of Education and Research
   (BMBF) under grant number 16SV7952. Responsibility for the contents of
   this publication lies with the authors. The aim of the project was to
   develop a VR application for patients with chronic back pain which had a
   physiotherapeutic and psychotherapeutic focus. This was a joint project
   that ended in March 2020. Open Access funding enabled and organized by
   Projekt DEAL.
CR Alemanno F, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216858
   Picorelli AMA, 2014, J PHYSIOTHER, V60, P151, DOI 10.1016/j.jphys.2014.06.012
   Baez S, 2018, ARCH PHYS MED REHAB, V99, P2287, DOI 10.1016/j.apmr.2017.11.003
   Brox E., 2011, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2011), P546, DOI 10.4108/icst.pervasivehealth.2011.246049
   Brox JI, 2008, SPINE J, V8, P948, DOI 10.1016/j.spinee.2007.07.389
   Cao LZ, 2021, VIRTUAL REAL-LONDON, V25, P597, DOI 10.1007/s10055-020-00477-z
   Darnall BD, 2020, JMIR FORM RES, V4, DOI 10.2196/17293
   Diers M, 2016, EUR J PAIN, V20, P581, DOI 10.1002/ejp.765
   Dionne CE, 2008, SPINE, V33, P95, DOI 10.1097/BRS.0b013e31815e7f94
   Farrar JT, 2001, PAIN, V94, P149, DOI 10.1016/S0304-3959(01)00349-9
   Fodor LA, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28113-6
   GBD 2016 Disease and Injury Incidence and Prevalence Collaborators, 2017, Lancet, V390, P1211, DOI 10.1016/S0140-6736(17)32154-2
   Graves LEF, 2010, J PHYS ACT HEALTH, V7, P393, DOI 10.1123/jpah.7.3.393
   Hapidou EG, 2012, PHYSIOTHER CAN, V64, P235, DOI 10.3138/ptc.2011-10
   Hilfiker R., 2008, PHYSIOPRAXIS, V6, P46, DOI DOI 10.1055/S-0032-1308158
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Jones T, 2016, J PAIN, V17, pS102, DOI 10.1016/j.jpain.2016.01.319
   Kamper SJ, 2014, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD000963.pub3
   Kent Michael., 2007, OXFORD DICT SPORTS S, DOI [10.1093/acref/9780198568506.001.0001, DOI 10.1093/ACREF/9780198568506.001.0001]
   Kim SS, 2014, J PHYS THER SCI, V26, P549, DOI 10.1589/jpts.26.549
   Kohlmann T, 1996, Rehabilitation (Stuttg), V35, pI
   Kothgassner O.D., 2012, TUI (Technology Usage Inventory) Manual
   Kruse L, 2021, SOCIETIES, V11, DOI 10.3390/soc11040134
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Leeuw M, 2007, J BEHAV MED, V30, P77, DOI 10.1007/s10865-006-9085-0
   Mallari B, 2019, J PAIN RES, V12, P2053, DOI 10.2147/JPR.S200498
   Mannion AF, 2009, EUR SPINE J, V18, P1881, DOI 10.1007/s00586-009-1093-7
   Maughan EF, 2010, EUR SPINE J, V19, P1484, DOI 10.1007/s00586-010-1353-6
   Meekes W, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6841
   Mehra S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01827
   Moher David, 2010, J Clin Epidemiol, V63, pe1, DOI [10.1016/j.ijsu.2011.10.001, 10.1136/bmj.c869, 10.1016/j.jclinepi.2010.03.004]
   Moore CG, 2011, CTS-CLIN TRANSL SCI, V4, P332, DOI 10.1111/j.1752-8062.2011.00347.x
   Nees TA, 2020, J CLIN MED, V9, DOI 10.3390/jcm9010145
   O'Sullivan P, 2012, BRIT J SPORT MED, V46, P224, DOI 10.1136/bjsm.2010.081638
   Palazzo C, 2016, ANN PHYS REHABIL MED, V59, P107, DOI 10.1016/j.rehab.2016.01.009
   Park JH, 2013, J PHYS THER SCI, V25, P985, DOI 10.1589/jpts.25.985
   Pfingsten M, 1997, PAIN, V73, P77, DOI 10.1016/S0304-3959(97)00083-3
   Reese C, 2013, INT J REHABIL RES, V36, P6, DOI 10.1097/MRR.0b013e32835acfec
   Rusu AC, 2014, BMC MUSCULOSKEL DIS, V15, DOI 10.1186/1471-2474-15-280
   SIUIJS EM, 1993, PHYS THER, V73, P771, DOI 10.1093/ptj/73.11.771
   Stamm O, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00753-8
   Thomas KS, 2002, BMJ-BRIT MED J, V325, P752, DOI 10.1136/bmj.325.7367.752
   van Gool CH, 2005, ARTHRIT RHEUM-ARTHR, V53, P24, DOI 10.1002/art.20902
   Villafaina S, 2019, GAMES HEALTH J, V8, P380, DOI 10.1089/g4h.2019.0023
   Von Der Lippe E, 2021, ERGEBNISSE KRANKHEIT, DOI [10.25646/7854, DOI 10.25646/7854]
   VONKORFF M, 1992, PAIN, V50, P133, DOI 10.1016/0304-3959(92)90154-4
   Waddell G., 2004, BACK PAIN REVOLUTION, V2nd
   Ware JE, 1996, MED CARE, V34, P220, DOI 10.1097/00005650-199603000-00003
   Woby SR, 2005, PAIN, V117, P137, DOI 10.1016/j.pain.2005.05.029
NR 49
TC 16
Z9 17
U1 5
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1291
EP 1305
DI 10.1007/s10055-022-00629-3
EA FEB 2022
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000754170900001
PM 35194374
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Kogler, W
   Wood, G
   Kober, SE
AF Kogler, Wolfgang
   Wood, Guilherme
   Kober, Silvia Erika
TI Effects of electrical brain stimulation on brain indices and presence
   experience in immersive, interactive virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Coherence; EEG; Transcranial direct current stimulation; Presence;
   Virtual reality
ID TRANSCRANIAL DC STIMULATION; MOTOR CORTEX; PREFRONTAL CORTEX; SPATIAL
   PRESENCE; EEG; ENVIRONMENTS; ALPHA; SYNCHRONIZATION; CORRELATE; THETA
AB The subjective presence experience in virtual reality (VR) is associated with distinct brain activation patterns. Particularly, the dorsolateral prefrontal cortex (DLPFC) seems to play a central role. We investigated the effects of electric brain stimulation (transcranial direct current, tDCS) on the presence experience as well as on brain activity and connectivity. Thirty-eight participants received either anodal (N = 18) or cathodal (N = 20) stimulation of the DLPFC before interacting in an immersive VR as well as sham stimulation. During VR interaction, EEG and heart rate were recorded. After VR interaction, participants rated their subjective presence experience using standardized questionnaires. Cathodal stimulation led to stronger brain connectivity than sham stimulation. Increased brain connectivity was associated with numerically lower levels of subjective presence. Anodal stimulation did not lead to changes in brain connectivity, and no differences in subjective presence ratings were found between the anodal and sham stimulation. These results indicate that cathodal tDCS over the DLPFC leads to a more synchronized brain state, which might hamper the activity in networks, which are generally associated with the evolvement of the subjective presence experience. Our results underline the importance of the DLPFC for the presence experience in VR.
C1 [Kogler, Wolfgang; Wood, Guilherme; Kober, Silvia Erika] Karl Franzens Univ Graz, Inst Psychol, Univ Pl 2, A-8010 Graz, Austria.
   [Kogler, Wolfgang; Wood, Guilherme; Kober, Silvia Erika] BioTechMed Graz, Graz, Austria.
C3 University of Graz
RP Kober, SE (corresponding author), Karl Franzens Univ Graz, Inst Psychol, Univ Pl 2, A-8010 Graz, Austria.; Kober, SE (corresponding author), BioTechMed Graz, Graz, Austria.
EM wkogler73@gmail.com; guilherme.wood@uni-graz.at;
   silvia.kober@uni-graz.at
RI Kogler, Wolfgang/GXG-4712-2022
OI Kogler, Wolfgang/0009-0002-2308-4633
FU University of Graz
FX Open access funding provided by University of Graz. The authors
   acknowledge the financial support by the University of Graz.
CR Ambrus GG, 2012, BRAIN STIMUL, V5, P499, DOI 10.1016/j.brs.2011.12.001
   [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053
   Antal A, 2004, J COGNITIVE NEUROSCI, V16, P521, DOI 10.1162/089892904323057263
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   Beeli G, 2008, BEHAV BRAIN FUNCT, V4, DOI 10.1186/1744-9081-4-33
   Brain Products GmbH, 2009, BRAINVISION ANAL 2 0
   Clemente M, 2014, INTERACT COMPUT, V26, P269, DOI 10.1093/iwc/iwt037
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cooper R, 2011, ORG MIND, DOI [10.1093/acprof:osobl/9780199579242.001.0001, DOI 10.1093/ACPROF:OSOBL/9780199579242.001.0001]
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dedoncker J, 2016, BRAIN STIMUL, V9, P501, DOI 10.1016/j.brs.2016.04.006
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Dosenbach NUF, 2007, P NATL ACAD SCI USA, V104, P11073, DOI 10.1073/pnas.0704320104
   Draganova R, 1999, PHYSIOL RES, V48, P157
   Freeman J, 1999, PRESENCE-TELEOP VIRT, V8, P1, DOI 10.1162/105474699566017
   Gandiga PC, 2006, CLIN NEUROPHYSIOL, V117, P845, DOI 10.1016/j.clinph.2005.12.003
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00349
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Herrera-Melendez AL, 2020, NEUROPSYCHOBIOLOGY, V79, P372, DOI 10.1159/000501227
   Horvath JC, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00002
   International Society for Presence Research, 2000, CONC PRES EXPL STAT
   Jäncke L, 2009, FRONT NEUROSCI-SWITZ, V3, P52, DOI 10.3389/neuro.01.006.2009
   Keeser D, 2011, NEUROIMAGE, V55, P644, DOI 10.1016/j.neuroimage.2010.12.004
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Klimesch W, 1999, BRAIN RES REV, V29, P169, DOI 10.1016/S0165-0173(98)00056-3
   Kober SE, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-17
   Kober SE, 2013, INT J HUM-COMPUT INT, V29, P13, DOI 10.1080/10447318.2012.668131
   Kober SE, 2012, INT J HUM-COMPUT ST, V70, P577, DOI 10.1016/j.ijhcs.2012.03.004
   Kober SE, 2012, INT J PSYCHOPHYSIOL, V83, P365, DOI 10.1016/j.ijpsycho.2011.12.003
   Lang N, 2005, EUR J NEUROSCI, V22, P495, DOI 10.1111/j.1460-9568.2005.04233.x
   Laufs H, 2003, NEUROIMAGE, V19, P1463, DOI 10.1016/S1053-8119(03)00286-6
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Nitsche MA, 2001, NEUROLOGY, V57, P1899, DOI 10.1212/WNL.57.10.1899
   Nitsche MA, 2000, J PHYSIOL-LONDON, V527, P633, DOI 10.1111/j.1469-7793.2000.t01-1-00633.x
   Nitsche MA, 2003, CLIN NEUROPHYSIOL, V114, P600, DOI 10.1016/S1388-2457(02)00412-1
   Notturno F, 2014, HUM BRAIN MAPP, V35, P2220, DOI 10.1002/hbm.22322
   Nunez PL, 1997, ELECTROEN CLIN NEURO, V103, P499, DOI 10.1016/S0013-4694(97)00066-7
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Polanía R, 2011, HUM BRAIN MAPP, V32, P1236, DOI 10.1002/hbm.21104
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Riva G, 2012, VIRTUAL REALITY IN PSYCHOLOGICAL, MEDICAL AND PEDAGOGICAL APPLICATIONS, P3, DOI 10.5772/46411
   Rogalewski A, 2004, EUR J NEUROSCI, V20, P313, DOI 10.1111/j.0953-816X.2004.03450.x
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sandro T., 2019, SUN TEMPLE VERSION 1
   Sauseng P, 2005, INT J PSYCHOPHYSIOL, V57, P97, DOI 10.1016/j.ijpsycho.2005.03.018
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Shafi MM, 2012, EUR J NEUROSCI, V35, P805, DOI 10.1111/j.1460-9568.2012.08035.x
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2009, ANU PSICOL, V40, P193
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Urban Life, 2017, 4K ULTR HD VID WILD
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Varela F, 2001, NAT REV NEUROSCI, V2, P229, DOI 10.1038/35067550
   Vorderer P., 2004, Mec spatial presence questionnaire
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 58
TC 3
Z9 3
U1 1
U2 39
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1019
EP 1029
DI 10.1007/s10055-021-00612-4
EA DEC 2021
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000734023300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Standen, B
   Anderson, J
   Sumich, A
   Heym, N
AF Standen, Bradley
   Anderson, John
   Sumich, Alexander
   Heym, Nadja
TI Effects of system- and media-driven immersive capabilities on presence
   and affective experience
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Virtual reality; Head-mounted display; Motivational salience
ID VIRTUAL-REALITY EXPOSURE; SPATIAL PRESENCE; EMOTION; ANXIETY;
   ENVIRONMENTS; MECHANISMS; ATTENTION; SENSE; MOTIVATION; CORRELATE
AB Virtual reality (VR) is receiving widespread attention as a delivery tool for exposure therapies. The advantage offered by VR over traditional technology is a greater sense of presence and immersion, which magnifies user effects and enhances the effectiveness of exposure-based interventions. The current study systematically examined the basic factors involved in generating presence in VR as compared to standard technology, namely (1) system-driven factors that are exclusive to VR devices while controlling general factors such as field of view and image quality; (2) media-driven factors of the virtual environment eliciting motivational salience through different levels of arousal and valence (relaxing, exciting and fear evoking stimuli); and (3) the effects of presence on magnifying affective response. Participants (N = 14) watched 3 different emotionally salient videos (1 x fear evoking, 1 x relaxing and 1 x exciting) in both viewing modes (VR and Projector). Subjective scores of user experience were collected as well as objective EEG markers of presence (frontal alpha power, theta/beta ratio). Subjective and objective presence was significantly greater in the VR condition. There was no difference in subjective or objective presence for stimulus type, suggesting presence is not moderated by arousal, but may be reliant on activation of motivational systems. Finally, presence did not magnify feelings of relaxation or excitement, but did significantly magnify users' experience of fear when viewing fear evoking stimuli. This is in line with previous literature showing strong links between presence and generation of fear, which is vital in the efficacy of exposure therapies.
C1 [Standen, Bradley; Anderson, John; Sumich, Alexander; Heym, Nadja] Nottingham Trent Univ, Dept Psychol, Nottingham, England.
C3 Nottingham Trent University
RP Standen, B (corresponding author), Nottingham Trent Univ, Dept Psychol, Nottingham, England.
EM brad.standen@ntu.ac.uk
RI Sumich, Alexander Luke/ABI-5354-2020
OI Sumich, Alexander Luke/0000-0003-4333-8442; Standen,
   Bradley/0000-0002-6615-063X
FU Nottingham Trent University; Alpha-Active Ltd.
FX This project was jointly funded by Nottingham Trent University and
   Alpha-Active Ltd.
CR Alsina-Jurnet I, 2011, COMPUT HUM BEHAV, V27, P504, DOI 10.1016/j.chb.2010.09.018
   Angelidis A, 2016, BIOL PSYCHOL, V121, P49, DOI 10.1016/j.biopsycho.2016.09.008
   [Anonymous], 2017, ALPHAACTIVE EEG
   [Anonymous], 2017, CURR NEUR SUIT 8
   [Anonymous], 2017, BRIST ONL SURV
   Backs RW, 2005, EXP AGING RES, V31, P421, DOI 10.1080/03610730500206808
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Baños RM, 2008, CYBERPSYCHOL BEHAV, V11, P1, DOI 10.1089/cpb.2007.9936
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   Benito KG, 2015, J OBSESS-COMPULS REL, V6, P147, DOI 10.1016/j.jocrd.2015.01.006
   Bouchard S, 2008, PRESENCE-VIRTUAL AUG, V17, P376, DOI 10.1162/pres.17.4.376
   Bouchard S, 2017, BRIT J PSYCHIAT, V210, P276, DOI 10.1192/bjp.bp.116.184234
   Bradley MM, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P581, DOI 10.1017/CBO9780511546396.025
   Bradley MM, 2001, EMOTION, V1, P300, DOI 10.1037//1528-3542.1.3.300
   Burriss L, 2007, COGNITION EMOTION, V21, P182, DOI 10.1080/02699930600562235
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Carretié L, 2014, COGN AFFECT BEHAV NE, V14, P1228, DOI 10.3758/s13415-014-0270-2
   Clark L.A., 1994, PANAS X MANUAL POSIT
   Clemente M, 2014, EXPERT SYST APPL, V41, P1584, DOI 10.1016/j.eswa.2013.08.055
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Davis M., 2001, COMPREHENSIVE HDB PS
   Davis M., 2000, The Amygdala, V2, P213
   De Paolis LT, 2020, VIRTUAL REAL-LONDON, V24, P483, DOI 10.1007/s10055-019-00409-6
   Deng WR, 2019, J AFFECT DISORDERS, V257, P698, DOI 10.1016/j.jad.2019.07.086
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Freeman J., 2005, PRESENCE, P213
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Howard CJ, 2019, PERCEPTION, V48, P346, DOI 10.1177/0301006619834251
   Howard CJ, 2017, BRAIN COGNITION, V117, P97, DOI 10.1016/j.bandc.2017.06.008
   Howard CJ, 2016, CEREB CORTEX, V26, P2952, DOI 10.1093/cercor/bhv101
   Kishimoto T, 2019, BEHAV COGN PSYCHOTH, V47, P726, DOI 10.1017/S1352465819000377
   Ko LW, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00388
   Kobayashi M, 2015, PRESENCE-TELEOP VIRT, V24, P163, DOI 10.1162/PRES_a_00226
   Kober SE, 2012, INT J PSYCHOPHYSIOL, V83, P365, DOI 10.1016/j.ijpsycho.2011.12.003
   Lang P. J., 1980, TECHNOLOGY MENTAL HL, P119, DOI DOI 10.1111/J.1469-8986.1993.TB03352.X
   Lang PJ, 1998, BIOL PSYCHIAT, V44, P1248, DOI 10.1016/S0006-3223(98)00275-3
   LeDoux J.E., 1990, Learning and Computational Neuroscience, P3
   LING Y, 2013, PLOS ONE, V8
   Ling Yun, 2014, PLoS One, V9, pe96144, DOI 10.1371/journal.pone.0096144
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Mansouri FA, 2017, TRENDS NEUROSCI, V40, P15, DOI 10.1016/j.tins.2016.11.001
   McNair DM, 1992, EDITS MANUAL PROFILE
   Miloff A, 2016, 46 EUR ASS BEH COGN, P753
   Öhman A, 2001, PSYCHOL REV, V108, P483, DOI 10.1037//0033-295X.108.3.483
   Owens ME, 2015, J PSYCHOPATHOL BEHAV, V37, P296, DOI 10.1007/s10862-014-9454-x
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   PFURTSCHELLER G, 1989, Brain Topography, V2, P3, DOI 10.1007/BF01128838
   Pitti CT, 2016, INT J PSYCHOL, V51, P146
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Price M, 2011, J ANXIETY DISORD, V25, P763, DOI 10.1016/j.janxdis.2011.03.004
   Putman P, 2010, BIOL PSYCHOL, V83, P73, DOI 10.1016/j.biopsycho.2009.10.008
   R Studio Team, 2015, RStudio: Integrated Development for R
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Scheufele PM, 2000, J BEHAV MED, V23, P207, DOI 10.1023/A:1005542121935
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Shomstein S, 2016, NEUROPSYCHOLOGIA, V92, P9, DOI 10.1016/j.neuropsychologia.2016.05.021
   van Son D, 2019, ANN NY ACAD SCI, V1452, P52, DOI 10.1111/nyas.14180
   van Son D, 2019, BIOL PSYCHOL, V140, P19, DOI 10.1016/j.biopsycho.2018.11.003
   Wechsler TF, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01758
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 67
TC 3
Z9 3
U1 2
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 371
EP 384
DI 10.1007/s10055-021-00579-2
EA OCT 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000705798400003
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Arquissandas, P
   Lamas, DR
   Oliveira, J
AF Arquissandas, Preyesse
   Lamas, David Ribeiro
   Oliveira, Jorge
TI Moving from VR into AR using bio-cybernetic loops and physiological
   sensory devices for intervention on anxiety disorders
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Adaptive systems; NyARToolkit; Unity 3D; Bitalino
ID AUGMENTED REALITY SYSTEM; VIRTUAL-REALITY; EXPOSURE THERAPY; IN-VIVO;
   EMOTION; PHOBIAS
AB Anxiety disorders comprise different clinical conditions that affect individuals in their personal, professional and social domains. The development of new intervention approaches for the treatment of anxiety disorders is crucial. As a step forward into promoting the well-being through adaptive physiological responses, we developed an augmented reality (AR)-based system using bio-cybernetic loops to create an adaptive system for exposure therapy in anxiety disorders. The system was built using open-source software (e.g., NyARToolkit and Unity 3D). AR technology uses computer-generated information to enrich the real world. It can be used with less intrusive devices to collect physiological data (e.g., Bitalino) describing human behavior in a cycle. In this context, our research project aims to study behavior during exposure to biologically relevant stimuli such as snakes. Phobia is described as an irrational fear to an object/stimulus. This fear triggers several physiological responses from sensors as increased heart rate (ECG) and skin conductance (EDA), which are responses from the autonomous nervous system. This approach can be used in several sessions, where the system through machine learning algorithms adapts the thresholds to the individual profile of each participant from historical data. Our study has been carried out in two stages: (1) The participants in a total of 35 students (30 males and 5 females with ages ranging from 19 to 29 years) were invited to fill a snake questionnaire (SNAQ). (2) A subsample was enrolled in an exposure session in AR using a virtual snake while collecting psychophysiological responses from sensors data. The results have shown increased physiological responses in two AR exposure sessions using snakes as stimuli. Therefore we conclude that the system was efficient to detect changes in physiological responses during the exposure sessions.
C1 [Arquissandas, Preyesse] Univ Lusofona, Copelabs, Av Campo Grande 388, P-1749024 Lisbon, Portugal.
   [Lamas, David Ribeiro] ULP Tallinn Univ, HCI, Tallinn, Estonia.
   [Oliveira, Jorge] Univ Lusofona, HEI Lab, Av Campo Grande 376, P-1749024 Lisbon, Portugal.
C3 Lusofona University; Lusofona University
RP Arquissandas, P (corresponding author), Univ Lusofona, Copelabs, Av Campo Grande 388, P-1749024 Lisbon, Portugal.
EM preyesse.arquissandas@alunos.ulusofona.pt; drl@tlu.ee;
   jorge.oliveira@ulusofona.pt
RI Oliveira, Jorge/KUH-2946-2024; Lamas, David/C-4161-2012
OI Lamas, David/0000-0003-0295-453X
FU FCT strategic project [COPELABS UID/04111/2020]
FX This work has also been (partially) funded by FCT strategic project
   COPELABS UID/04111/2020.
CR Agrafioti F, 2012, IEEE T AFFECT COMPUT, V3, P102, DOI 10.1109/T-AFFC.2011.28
   American Psychiatric Association APA, 2016, DIAGN STAT MAN MENT
   Aoto, 2011, T JPN SOC KANSEI ENG, V10, P109, DOI [10.5057/jjske.10.109, DOI 10.5057/JJSKE.10.109]
   Badia, 2017, MULTIMED TOOLS APPL, P1
   Baus O, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00112
   Bermudez, 2017, 4 INT C PHYS COMP SY
   Botella C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148237
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Juan MC, 2011, INT J HUM-COMPUT ST, V69, P440, DOI 10.1016/j.ijhcs.2011.03.002
   Juan MC, 2011, INT J HUM-COMPUT INT, V27, P436, DOI 10.1080/10447318.2011.552059
   Emmelkamp P.M. G., 1992, Anxiety disorders: A practitioner's guide
   Emmelkamp PMG, 2002, BEHAV RES THER, V40, P509, DOI 10.1016/S0005-7967(01)00023-7
   Frans, 2004, HOOPLOT MASTER THESI
   Gacek A, 2012, ECG SIGNAL PROCESSING, CLASSIFICATION AND INTERPRETATION: A COMPREHENSIVE FRAMEWORK OF COMPUTATIONAL INTELLIGENCE, P1, DOI 10.1007/978-0-85729-868-3
   Gamito P, 2011, VIRTUAL REALITY, P515
   Juan MC, 2010, COMPUT GRAPH-UK, V34, P756, DOI 10.1016/j.cag.2010.08.001
   Juan MC, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P256, DOI 10.1109/ISMAR.2004.14
   Kim KH, 2004, MED BIOL ENG COMPUT, V42, P419, DOI 10.1007/BF02344719
   KLORMAN R, 1974, BEHAV THER, V5, P401, DOI 10.1016/S0005-7894(74)80008-0
   Lochner, 2014, REACTIVE AUGMENTED R, DOI [10.4108/icst.pervasivehealth.2014.255341, DOI 10.4108/ICST.PERVASIVEHEALTH.2014.255341]
   Nakasone Arturo, 2005, P 5 INT WORKSH BIOS
   Ohkura, 2014, 5 INT C APPL HUM FAC, P6931
   Oliveira J, 2019, 2019 14 IBERIAN C IN, P1
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Rattanyu K, 2011, J ADV COMPUT INTELL, V15, P582, DOI 10.20965/jaciii.2011.p0582
   Riva G, 2002, IEEE T INF TECHNOL B, V6, P198, DOI 10.1109/TITB.2002.802370
   Suso-Ribera C, 2019, CYBERPSYCH BEH SOC N, V22, P31, DOI 10.1089/cyber.2017.0672
   van Rooij M., 2016, J. Anxiety Disord., P1989, DOI [10.1145/2851581.2892452, DOI 10.1145/2851581.2892452]
   Wiederhold M. D., 2012, CYBER THERAPY AUGMEN
   Wolitzky-Taylor KB, 2008, CLIN PSYCHOL REV, V28, P1021, DOI 10.1016/j.cpr.2008.02.007
   Wrzesien M, 2011, LECT NOTES COMPUT SC, V6946, P523, DOI 10.1007/978-3-642-23774-4_43
NR 32
TC 3
Z9 3
U1 2
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 233
EP 243
DI 10.1007/s10055-021-00549-8
EA JUL 2021
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000672319200001
OA Green Published
DA 2024-07-18
ER

PT J
AU Kim, W
   Sung, J
   Xiong, SP
AF Kim, Woojoo
   Sung, Jaeho
   Xiong, Shuping
TI Walking-in-place for omnidirectional VR locomotion using a single RGB
   camera
SO VIRTUAL REALITY
LA English
DT Article
DE Walking in place; VR locomotion; Navigation control; Virtual
   environment; OpenPose; Kinect
ID TREADMILL; TRAVEL
AB Locomotion is a fundamental interaction element allowing navigation inside the virtual environment, and the walking-in-place (WIP) techniques have been actively developed as a balanced compromise between naturalness and efficiency. One popular method to implement the WIP technique was to use a low-cost, easy to set up, and markerless Kinect, but required integration of multiple sensors or covered limited directions due to the poor tracking capability when facing non-frontal sides of the user. This study aimed to propose a WIP technique for omnidirectional VR locomotion based on a single RGB camera, utilizing an open-source 2D human pose estimation system called OpenPose. Three WIP techniques (existing Kinect-based technique, proposed Kinect-based technique, and proposed OpenPose-based technique) were compared in terms of variation of virtual walking speed and subjective evaluation through a user study with walking tasks in different directions. Experimental results showed that the proposed OpenPose-based technique performed comparably when the user faced the front of the camera, but it induced lower variation of virtual walking speed and higher subjective evaluation ratings at non-forward directions compared to other techniques. The proposed OpenPose-based WIP technique can be used in VR applications to provide a fully unobstructed VR locomotion experience. It can achieve stable WIP-based omnidirectional VR locomotion through a single low-cost easily accessible RGB camera, without the need for additional sensors, and at the same time, both hands are free for other interactions.
C1 [Kim, Woojoo; Xiong, Shuping] Korea Adv Inst Sci & Technol KAIST, Coll Engn, Dept Ind & Syst Engn, 291 Daehak Ro, Daejeon 34141, South Korea.
   [Sung, Jaeho] Korea Adv Inst Sci & Technol KAIST, Coll Engn, Dept Ind Design, 291 Daehak Ro, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST)
RP Xiong, SP (corresponding author), Korea Adv Inst Sci & Technol KAIST, Coll Engn, Dept Ind & Syst Engn, 291 Daehak Ro, Daejeon 34141, South Korea.
EM shupingx@kaist.ac.kr
RI Kim, Woojoo/HTL-8595-2023; Xiong, Shuping/G-3073-2016
OI Kim, Woojoo/0000-0001-6203-7309; Xiong, Shuping/0000-0003-1549-515X
FU Basic Science Research Program through the National Research Foundation
   of Korea - Ministry of Science, ICT and Future Planning
   [NRF-2020R1F1A1048510]
FX This work was supported by the Basic Science Research Program through
   the National Research Foundation of Korea funded by the Ministry of
   Science, ICT and Future Planning (NRF-2020R1F1A1048510).
CR Aitpayev K., 2012, Application of Information and Communication Technologies (AICT), 2012 6th International Conference on, P1
   Al Zayer Majed., 2018, IEEE transactions on visualization and computer graphics
   Alexander J., 2012, CHI 12 P SIGCHI C HU, P1229, DOI DOI 10.1145/2207676.2208575
   Ang YY, 2019, IEEE ACCESS, V7, P183985, DOI 10.1109/ACCESS.2019.2960409
   Bakker NH, 2003, HUM FACTORS, V45, P160, DOI 10.1518/hfes.45.1.160.27234
   Bhandari J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139133
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bohannon RW, 2011, PHYSIOTHERAPY, V97, P182, DOI 10.1016/j.physio.2010.12.004
   Bouguila L., 2004, P 6 INT C MULT INT, P77, DOI [10.1145/1027933.1027948, DOI 10.1145/1027933.1027948]
   Bowman D. A., 1998, Virtual Reality, V3, P120, DOI 10.1007/BF01417673
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bruno L, 2017, INT J HUM-COMPUT ST, V105, P1, DOI 10.1016/j.ijhcs.2017.03.006
   Bruno L, 2013, LECT NOTES COMPUT SC, V8119, P370
   Cakmak T, 2014, ACM SIGGRAPH 2014 EM
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Cohen J., 1988, STAT POWER ANAL BEHA
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Felberbaum Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173908
   Francese R, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P116, DOI 10.1145/2254556.2254580
   HA G, 2015, HCI INT 2015 POSTERS, V528
   Hale K.S., 2014, Handbook of virtual environments: Design, implementation, and applications
   Huang A, 2019, IEEE CONF IMAGING SY
   Humadi A, 2021, INT J IND ERGONOM, V84, DOI 10.1016/j.ergon.2021.103147
   Iwata H, 1999, IEEE COMPUT GRAPH, V19, P30, DOI 10.1109/38.799737
   Ke PNCA, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P438, DOI 10.1109/VR50410.2021.00067
   Ketoma VK, 2018, ADV INTELL SYST COMP, V722, P368, DOI 10.1007/978-3-319-73888-8_57
   Kim T, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P1219, DOI 10.1145/3196709.3196759
   Kim W, 2021, INT J IND ERGONOM, V84, DOI 10.1016/j.ergon.2021.103164
   Kim W, 2021, INT J HUM-COMPUT ST, V152, DOI 10.1016/j.ijhcs.2021.102648
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Lee J, 2019, 2019 IEEE INT C CONS, P1, DOI DOI 10.1109/ICCE.2019.8661906
   Lee J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092832
   McCullough M, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P107, DOI 10.1145/2804408.2804416
   MULLER F, 2019, P 2019 CHI C HUM FAC
   Nakano N, 2020, FRONT SPORTS ACT LIV, V2, DOI 10.3389/fspor.2020.00050
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   Nilsson NC, 2014, IEEE T VIS COMPUT GR, V20, P569, DOI 10.1109/TVCG.2014.21
   PAPAZOGLOU N, 1991, CLIN CARDIOL, V14, P913, DOI 10.1002/clc.4960141111
   Plantard P, 2015, SENSORS-BASEL, V15, P1785, DOI 10.3390/s150101785
   Pterneas V, 2020, LIGHTBUZZ
   Rogers Sol., 2019, FORBES
   Settgast V., 2014, J VIRTUAL REAL BROAD, DOI 10.20385/1860-2037/11.2014.4
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Teixeira L, 2013, LECT NOTES COMPUTER, V8014, DOI 10.1007/978-3-642-39238-2_46
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Viswakumar A, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P310, DOI 10.1109/ICIIP47207.2019.8985781
   von Willich J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376626
   Wang QF, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2015), P380, DOI 10.1109/ICHI.2015.54
   Wei Tao, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7411772
   Wendt JD, 2010, P IEEE VIRT REAL ANN, P51
   Williams B, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010329
   Williams Betsy., 2013, Proc. ACM Symp. on Applied Perception, P67
   Wilson PT, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P243, DOI 10.1145/3013971.3014010
   Wilson PrestonTunnell., 2014, P 13 ACM SIGGRAPH IN, P27, DOI DOI 10.1145/2670473.2670492
   Woojoo Kim, 2020, Advances in Physical, Social & Occupational Ergonomics. Proceedings of the AHFE 2020 Virtual Conferences on Physical Ergonomics and Human Factors, Social & Occupational Ergonomics and Cross-Cultural Decision Making. Advances in Intelligent Systems and Computing (AISC 1215), P3, DOI 10.1007/978-3-030-51549-2_1
   Xu WG, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300674
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Zhao T, 2020, GITHUB
   Zheng Ye., 2012, P ACM S APPL PERCEPT, P131
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
   Zielinski DJ, 2011, P IEEE VIRT REAL ANN, P167, DOI 10.1109/VR.2011.5759456
NR 68
TC 4
Z9 4
U1 1
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 173
EP 186
DI 10.1007/s10055-021-00551-0
EA JUN 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000663269400002
DA 2024-07-18
ER

PT J
AU Raees, M
   Ullah, S
AF Raees, Muhammad
   Ullah, Sehat
TI RUN: rational ubiquitous navigation, a model for automated navigation
   and searching in virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Machine learning in VR; Automated navigation; Object-based searching;
   Intelligent virtual reality systems
AB By now, the realm of virtual reality is abuzz with high-quality visuals, enough to simulate a real-world scene. The use of intelligence in virtual reality systems, however, is a milestone yet to be achieved to make possible seamless realism in a virtual environment. This paper presents a model, rational ubiquitous navigation to improve believability of a virtual environment. The model intends to augment maturity of a virtual agent by inculcating in it the human-like learning capability. A novel approach for automated navigation and searching is proposed by incorporating machine learning in virtual reality. An intelligent virtual agent learns objects of interest along with the paths followed for navigation. A mental map is molded dynamically as a user navigates in the environment. The map is followed by the agent during self-directed navigation to access any known object. After reaching at a location where an object of interest resides, the required object is selected on the basis of front-facet feature. The model is implemented in a case-study project learn objects on path (LOOP). Twelve users evaluated the model in the immersive maze-like environment of LOOP. Results of the evaluation assure applicability of the model in various cross-modality applications.
C1 [Raees, Muhammad; Ullah, Sehat] Univ Malakand, Dept Comp Sci & IT, Chakdara, Pakistan.
C3 University of Malakand
RP Raees, M (corresponding author), Univ Malakand, Dept Comp Sci & IT, Chakdara, Pakistan.
EM visitrais@yahoo.com; sehatullah@hotmail.com
RI ullah, sehat/HTT-4581-2023
OI ullah, sehat/0000-0002-1193-9350; Raees, Muhammad/0000-0001-6887-6883
CR [Anonymous], 2001, EUR C MANCH UK
   Ayas S, 2018, ADV ELECTR COMPUT EN, V18, P113, DOI 10.4316/AECE.2018.01014
   Badler B, 1996, PLANNING ANIMATION I, P235
   BATES J, 1994, COMMUN ACM, V37, P122, DOI 10.1145/176789.176803
   Caceres CA, 2014, THESIS
   Cai Y, 2010, NTCIR, P336
   Chang HW, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P279, DOI 10.1145/3126594.3126617
   Conde T, 2003, LECT NOTES ARTIF INT, V2792, P175
   Dobrzaski LA, 2016, ARCH MAT SCI ENG, V45, P69
   Downie RB, 2001, P GAM DEV C
   Dunagan Jake., 2004, J FUTURES STUDIES, V9, P1
   Elhassan I., 2005, FAST TEXTURE DOWNLOA
   Fränti P, 2006, IEEE T PATTERN ANAL, V28, P1875, DOI 10.1109/TPAMI.2006.227
   Gobbetti E., 1998, Virtual Reality: Past, Present
   Gonzalez R., 2002, DIGITAL IMAGE PROCES, P595
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   Hale K.S., 2014, Handbook of virtual environments: Design, implementation, and applications
   Hämäläinen P, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, PROCEEDINGS, P29
   Hu LY, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2941-7
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Luck M, 2000, APPL ARTIF INTELL, V14, P1, DOI 10.1080/088395100117133
   Lugrin JL, 2005, LECT NOTES COMPUT SC, V3814, P74, DOI 10.1007/11590323_8
   Matsas E, 2017, INT J ADV MANUF TECH, V92, P3903, DOI 10.1007/s00170-017-0428-5
   Mei G, 2015, ADV ELECTR COMPUT EN, V15, P35, DOI 10.4316/AECE.2015.02005
   Najadat Hassan M., 2019, 2019 10th International Conference on Information and Communication Systems (ICICS), P147, DOI 10.1109/IACS.2019.8809122
   Peterson, 2005, PACCALL J, V1, P29
   Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777
   Raees M, 2016, J ENG RES-KUWAIT, V4, P22
   Rivas E, 2015, ROBOTICS, V4, P120, DOI 10.3390/robotics4020120
   Roberts A, 2007, BIOINFORMATICS, V23, pI401, DOI 10.1093/bioinformatics/btm220
   Senger S, 2005, ST HEAL T, V111, P447
   Sheridan T.B., 2000, Proceedings of the ACM symposium on Virtual reality software and technology, P1, DOI DOI 10.1145/502390.502392
   Stork D., 2012, PATTERN CLASSIFICATI
   Tsai-Yen Li, 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P177, DOI 10.1109/VR.2000.840496
   Van LJ, 2001, P ACM SIGCHI C CHI, P117
NR 35
TC 1
Z9 1
U1 0
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 511
EP 521
DI 10.1007/s10055-020-00468-0
EA SEP 2020
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000571043500001
DA 2024-07-18
ER

PT J
AU Becher, A
   Angerer, J
   Grauschopf, T
AF Becher, Armin
   Angerer, Jens
   Grauschopf, Thomas
TI Negative effects of network latencies in immersive collaborative virtual
   environments
SO VIRTUAL REALITY
LA English
DT Article
DE Distributed virtual reality; Latency; Immersive collaborative virtual
   environment; Performance; Co-presence; Mutual understanding; Perceived
   workload
ID SIMULATOR SICKNESS; REALITY; TASK
AB The present work aims to investigate the negative effects of network latencies in immersive collaborative virtual environments. A user study was conducted to determine the impact of those delays on the performance of users. Participants of the study played a simple cooperative game designed for two players. The goal of the game was to correctly place bicolored cubes into their specific destinations. Since each player only saw the colors of the cubes of his or her partner, both players had to visually and verbally exchange information to complete the game. Each pair of participants played the game under four different latency conditions. The task performance was measured by the time needed to place one cube successfully. Besides, other subjectively observable variables were investigated. The results of the study show that a high end-to-end delay between two VR stations has an adverse effect on the users' task performance, the amount of mutual understanding and the perceived workload. For the co-presence metric, i.e., the perceived amount of togetherness inside the virtual environment, no significant correlation to the network delay could be determined.
C1 [Becher, Armin; Grauschopf, Thomas] TH Ingolstadt, Ingolstadt, Germany.
   [Angerer, Jens] AUDI AG, Ingolstadt, Germany.
C3 Volkswagen; Audi
RP Becher, A (corresponding author), TH Ingolstadt, Ingolstadt, Germany.
EM becherarmin@gmail.com; jens.angerer@audi.de; thomas.grauschopf@thi.de
OI Becher, Armin/0000-0002-8160-8637
CR Alahuhta P, 2016, PROGR IS, P103, DOI 10.1007/978-3-319-22041-3_4
   Basdogan C., 2000, ACM Transactions on Computer-Human Interaction, V7, P443, DOI 10.1145/365058.365082
   Becher A., 2018, NOVEL APPROACH MEASU
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Biocca F., 2001, 4 ANN INT WORKSH PRE, P1
   Buker TJ, 2012, HUM FACTORS, V54, P235, DOI 10.1177/0018720811428734
   Chen H, 2005, J COMPUT SCI TECH-CH, V20, P396, DOI 10.1007/s11390-005-0396-3
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Hagsand O, 1996, IEEE MULTIMEDIA, V3, P30, DOI 10.1109/93.486702
   HART S G, 1988, P139
   International Telecommunication Union, 2003, ITU T REC G 114 ON W
   KITAWAKI N, 1991, IEEE J SEL AREA COMM, V9, P586, DOI 10.1109/49.81952
   Lawson G, 2016, APPL ERGON, V53, P323, DOI 10.1016/j.apergo.2015.06.024
   Nam CS, 2008, COMPUT HUM BEHAV, V24, P1404, DOI 10.1016/j.chb.2007.07.014
   Nguyen TV, 2014, CLIN CASE DERMATOL, P1, DOI [10.1007/978-1-4471-4312-3, 10.1109/3DCVE.2014.7160928]
   Park KS, 1999, P IEEE VIRT REAL ANN, P104, DOI 10.1109/VR.1999.756940
   Pierre MES, 2015, DISPLAYS, V36, P1, DOI 10.1016/j.displa.2014.10.005
   Roberts D, 2003, PRESENCE-TELEOP VIRT, V12, P644, DOI 10.1162/105474603322955932
   Roberts D, 2009, IEEE ACM DIS SIM, P89, DOI 10.1109/DS-RT.2009.43
   Schreuder HWR, 2014, SCI WORLD J, DOI 10.1155/2014/507076
   Schroeder R, 2001, COMPUT GRAPH-UK, V25, P781, DOI 10.1016/S0097-8493(01)00120-0
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Steed A, 2005, P IEEE VIRT REAL ANN, P27
   Steed A, 1999, P IEEE VIRT REAL ANN, P112, DOI 10.1109/VR.1999.756941
   Steptoe W, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1039
   Su F, 2013, MULTISTAGE ACTING DI, P227
   Su F, 2014, ACSIS-ANN COMPUT SCI, V2, P719
   Wang CH, 2010, IEEE INT SYMP INFO, P2028, DOI 10.1109/ISIT.2010.5513368
   Yee N, 2007, CYBERPSYCHOL BEHAV, V10, P115, DOI 10.1089/cpb.2006.9984
NR 29
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 369
EP 383
DI 10.1007/s10055-019-00395-9
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000565033400002
DA 2024-07-18
ER

PT J
AU Lavoie, R
   Main, K
   King, C
   King, D
AF Lavoie, Raymond
   Main, Kelley
   King, Corey
   King, Danielle
TI Virtual experience, real consequences: the potential negative emotional
   consequences of virtual reality gameplay
SO VIRTUAL REALITY
LA English
DT Article
ID VIOLENT VIDEO GAMES; PHYSIOLOGICAL AROUSAL; AGGRESSIVE THOUGHTS; SELF;
   RESPONSES; EXPOSURE; ABSORPTION; BELIEFS; DESENSITIZATION; PERFORMANCE
AB As virtual reality (VR) technology enters mainstream markets, it is imperative that we understand its potential impacts on users, both positive and negative. In the present paper, we build on the extant literature's focus on the physical side effects of VR gameplay (e.g., cybersickness) by focusing on VR's potential to intensify users' experiences of negative emotions. We first conducted a preliminary survey to assess users' emotional responses during VR gameplay, with the results suggesting that certain VR situations can in fact produce intense negative emotional experiences. We then designed an interactive scenario intended to elicit low to moderate amounts of negative emotion, wherein participants played out the scenario in either VR (using the HTC Vive) or on a laptop computer. Compared to the participants who enacted the scenario on the laptop, those in the VR condition reported higher levels of absorption, which in turn increased the intensity of their negative emotional response to the scenario. A follow-up questionnaire administered several hours later revealed that the intensified negative emotions resulting from VR had a significant positive correlation with negative rumination (i.e., harmful self-related thoughts related to distress). These results show that VR gameplay has the potential to elicit strong negative emotional responses that could be harmful for users if not managed properly. We discuss the practical and policy implications of our findings.
C1 [Lavoie, Raymond; Main, Kelley; King, Corey; King, Danielle] Univ Manitoba, Winnipeg, MB, Canada.
C3 University of Manitoba
RP Lavoie, R (corresponding author), Univ Manitoba, Winnipeg, MB, Canada.
EM lavoier@merrimack.edu
CR Agarwal R, 2000, MIS QUART, V24, P665, DOI 10.2307/3250951
   Ahn H, 2016, MARKET LETT, V27, P223, DOI 10.1007/s11002-014-9342-x
   Aiken MP, 2015, VIRTUAL REAL-LONDON, V19, P95, DOI 10.1007/s10055-015-0260-x
   Akiduki H, 2003, NEUROSCI LETT, V340, P197, DOI 10.1016/S0304-3940(03)00098-3
   Anderson CA, 2000, J PERS SOC PSYCHOL, V78, P772, DOI 10.1037//0022-3514.78.4.772
   ANDERSON CA, 2004, ADV EXPT SOCIAL PSYC, V36
   Anderson CA, 2009, J EXP SOC PSYCHOL, V45, P731, DOI 10.1016/j.jesp.2009.04.019
   [Anonymous], 1992, J Pers, V60, P175
   Aquino K, 2002, J PERS SOC PSYCHOL, V83, P1423, DOI 10.1037//0022-3514.83.6.1423
   Arriaga P, 2008, AGGRESSIVE BEHAV, V34, P521, DOI 10.1002/ab.20272
   Banos R, 1999, Cyberpsychol Behav, V2, P143, DOI 10.1089/cpb.1999.2.143
   Barfield W., 1995, Virtual Reality: Research, Developments, Applications, V1, P3, DOI [10.1007/BF02009709, DOI 10.1007/BF02009709]
   Bartholow BD, 2005, PERS SOC PSYCHOL B, V31, P1573, DOI 10.1177/0146167205277205
   Bullinger AH, 2005, APPL PSYCHOPHYS BIOF, V30, P205, DOI 10.1007/s10484-005-6378-y
   Calvert S.L., 1994, J APPL DEV PSYCHOL, V15, P125, DOI DOI 10.1016/0193-3973(94)90009-4
   Cardos RAI, 2017, COMPUT HUM BEHAV, V72, P371, DOI 10.1016/j.chb.2017.03.007
   Carnagey NL, 2007, J EXP SOC PSYCHOL, V43, P489, DOI 10.1016/j.jesp.2006.05.003
   Carnagey NL, 2005, PSYCHOL SCI, V16, P882, DOI 10.1111/j.1467-9280.2005.01632.x
   Carroll A.B., 1979, ACAD MANAGE REV, V4, P497, DOI [10.5465/amr.1979.4498296, 10.5465/AMR.1979.4498296]
   CHANDRASIRI A, 2019, VIRTUAL REAL, P1
   Chirico A, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02351
   Chirico A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01242-0
   Chiu SI, 2004, CYBERPSYCHOL BEHAV, V7, P571, DOI 10.1089/cpb.2004.7.571
   Collier JE, 2008, J PUBLIC POLICY MARK, V27, P107, DOI 10.1509/jppm.27.1.107
   CSIKSZENTMIHALYI M, 1989, J PERS SOC PSYCHOL, V56, P815, DOI 10.1037/0022-3514.56.5.815
   De Gauquier L, 2019, VIRTUAL REAL-LONDON, V23, P235, DOI 10.1007/s10055-018-0344-5
   Dill KE, 1998, AGGRESS VIOLENT BEH, V3, P407, DOI 10.1016/S1359-1789(97)00001-3
   Dotsch R, 2008, J EXP SOC PSYCHOL, V44, P1194, DOI 10.1016/j.jesp.2008.03.003
   Drolet A, 2007, MARKET LETT, V18, P211, DOI 10.1007/s11002-007-9016-z
   Du GY, 2019, 2019 IEEE 6TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA), P1, DOI 10.1109/IEA.2019.8715127
   Eastin MS, 2006, COMMUN RES, V33, P448, DOI 10.1177/0093650206293249
   Engeser S, 2008, MOTIV EMOTION, V32, P158, DOI 10.1007/s11031-008-9102-4
   Ferguson CJ, 2007, AGGRESS VIOLENT BEH, V12, P470, DOI 10.1016/j.avb.2007.01.001
   Fleming MJ, 2001, J APPL SOC PSYCHOL, V31, P2047, DOI 10.1111/j.1559-1816.2001.tb00163.x
   FRIJDA NH, 1988, AM PSYCHOL, V43, P349, DOI 10.1037/0003-066X.43.5.349
   Funk JB, 2003, J APPL DEV PSYCHOL, V24, P413, DOI 10.1016/S0193-3973(03)00073-X
   Funk JB, 1996, J COMMUN, V46, P19, DOI 10.1111/j.1460-2466.1996.tb01472.x
   Hair JF, 2010, Multivariate data analysis
   Hayes A. F., 2013, Introduction to mediation, moderation, and conditional process analysis: a regression -based approach
   Ivory JD, 2007, J COMMUN, V57, P532, DOI 10.1111/j.1460-2466.2007.00356.x
   JONES H, 1996, VIRTUAL REAL, V2, P147, DOI DOI 10.1007/BF02534448
   Kaczmarek LD, 2014, CYBERPSYCH BEH SOC N, V17, P298, DOI 10.1089/cyber.2013.0595
   Keltner D, 2003, COGNITION EMOTION, V17, P297, DOI 10.1080/02699930302297
   Kennedy RS, 1996, INT J HUM-COMPUT INT, V8, P25, DOI 10.1080/10447319609526139
   KREJCI M, 2011, PSYCHOLOGY, V2, P674, DOI DOI 10.4236/psych.2011.27103
   LANIER J, 1992, J COMMUN, V42, P150, DOI 10.1111/j.1460-2466.1992.tb00816.x
   LAU KW, 2018, VIRTUAL REAL-LONDON, P1
   Lavoie R, 2019, PSYCHOL MARKET, V36, P1133, DOI 10.1002/mar.21262
   Lavoie R, 2020, CAN J ADM SCI, V37, P9, DOI 10.1002/cjas.1537
   Lavoie RV., 2019, J GAMBL ISSUES, V41
   Lemmens JS, 2009, MEDIA PSYCHOL, V12, P77, DOI 10.1080/15213260802669458
   Lindorff M, 2012, J BUS ETHICS, V110, P457, DOI 10.1007/s10551-012-1493-1
   Macedonio MF, 2007, CYBERPSYCHOL BEHAV, V10, P508, DOI 10.1089/cpb.2007.9997
   McCall C, 2009, SOC INFLUENCE, V4, P138, DOI 10.1080/15534510802517418
   Mentzoni RA, 2011, CYBERPSYCH BEH SOC N, V14, P591, DOI 10.1089/cyber.2010.0260
   Mittelstaedt JM, 2019, VIRTUAL REAL-LONDON, V23, P143, DOI 10.1007/s10055-018-0370-3
   Mor N, 2002, PSYCHOL BULL, V128, P638, DOI 10.1037//0033-2909.128.4.638
   Murray CD, 2007, COMPUT HUM BEHAV, V23, P1347, DOI 10.1016/j.chb.2004.12.010
   Nichols S, 2002, APPL ERGON, V33, P251, DOI 10.1016/S0003-6870(02)00020-0
   Nolen-Hoeksema S, 2000, J ABNORM PSYCHOL, V109, P504, DOI 10.1037/0021-843X.109.3.504
   Nolen-Hoeksema S, 2008, PERSPECT PSYCHOL SCI, V3, P400, DOI 10.1111/j.1745-6924.2008.00088.x
   NOLENHOEKSEMA S, 1991, J ABNORM PSYCHOL, V100, P569, DOI 10.1037/0021-843X.100.4.569
   Ortony A., 1988, COGNITIVE STRUCTURE
   Plante TG, 2003, COMPUT HUM BEHAV, V19, P495, DOI 10.1016/S0747-5632(02)00074-2
   Quesnel D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02158
   Regan C., 1995, VIRTUAL REAL-LONDON, V1, P17, DOI DOI 10.1007/BF02009710
   Rheinberg F., 2003, DIAGNOSTIK MOTIVATIO, P261, DOI DOI 10.1007/S11031-008-9102-4
   RIDGWAY N.M., 1990, Marketing Letters, V7, P139, DOI DOI 10.1007/BF00435297
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Schneider EF, 2004, HUM COMMUN RES, V30, P361, DOI 10.1111/j.1468-2958.2004.tb00736.x
   Sen S, 2001, J MARKETING RES, V38, P225, DOI 10.1509/jmkr.38.2.225.18838
   Serino S, 2014, VIRTUAL REAL-LONDON, V18, P73, DOI 10.1007/s10055-013-0237-6
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Sherman B., 1992, Glimpses of heaven, visions of hell: Virtual reality and its implications
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Smith SP, 2019, ARRAY-NY, V3-4, DOI 10.1016/j.array.2019.100010
   Smith SL, 2003, J BROADCAST ELECTRON, V47, P58, DOI 10.1207/s15506878jobem4701_4
   SONNEMANS J, 1995, COGNITION EMOTION, V9, P483, DOI 10.1080/02699939508408977
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stroud NJ, 2008, J CHILD MEDIA, V2, P1, DOI 10.1080/17482790701733153
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
   Taku K, 2009, ANXIETY STRESS COPIN, V22, P129, DOI 10.1080/10615800802317841
   Tamborini R, 2004, J BROADCAST ELECTRON, V48, P335
   TELLEGEN A, 1974, J ABNORM PSYCHOL, V83, P268, DOI 10.1037/h0036681
   Tracy JL, 2004, PSYCHOL INQ, V15, P103, DOI 10.1207/s15327965pli1502_01
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
   WIBIRAMA S, 2019, VIRTUAL REAL, P1
   Wiederhold Brenda, 2008, Virtual Reality, V12, P259, DOI 10.1007/s10055-008-0100-3
   Yehuda R, 2002, NEW ENGL J MED, V346, P108, DOI 10.1056/NEJMra012941
   Young IM, 2008, HANDBOOK OF RESEARCH ON GLOBAL CORPORATE CITIZENSHIP, P137
NR 92
TC 61
Z9 62
U1 5
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 69
EP 81
DI 10.1007/s10055-020-00440-y
EA APR 2020
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000523104600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Narayanan, S
   Polys, N
   Bukvic, II
AF Narayanan, Siddharth
   Polys, Nicholas
   Bukvic, Ivica Ico
TI Cinemacraft: exploring fidelity cues in collaborative virtual world
   interactions
SO VIRTUAL REALITY
LA English
DT Article
DE Information systems; Software engineering; Virtual worlds software;
   Computing methodologies; Motion capture
ID SOCIAL PRESENCE; BODY MOVEMENT; TELEPRESENCE; PERFORMANCE; ENVIRONMENT;
   COPRESENCE; AVATARS; MEDIA
AB The research presented in this paper explores the contribution of avatar fidelity to social interaction in virtual environments and how sensory fusion can improve these interactions. Specifically, we vary levels of interaction fidelity to investigate how responsiveness and behavioural realism affect people's experience of interacting with virtual humans. This is accomplished through the creation of Cinemacraft, a technology-mediated immersive platform for collaborative human-computer interaction. Cinemacraft leverages a voxel game engine similar to Minecraft to facilitate collaborative interaction in a virtual 3D world and incorporates sensory fusion to improve the fidelity of real-time collaboration. The primary hypothesis of the study is that embodied interactions result in a higher degree of presence, and that sensory fusion can improve the quality of presence and co-presence. We tested our hypothesis through a user-study of 24 participants. Based on suggestions from existing literature, we sidestep the uncanny valley effect through the use of low fidelity avatars (a la Minecraft) and identify cues that impact users ratings of presence, co-presence and successful collaboration. The findings and ensuing data in this research can be applied to produce a more compelling platform for live collaborative interactions, performances, and empathetic storytelling. This research contributes to the field of immersive, collaborative interaction by making transparent the platform, methodology, instruments and code accessible for team members with less technological expertise, as well as developers aspiring to use interactive 3D media to promote further experimentation and conceptual discussions.
C1 [Narayanan, Siddharth; Polys, Nicholas; Bukvic, Ivica Ico] Virginia Polytech Inst & State Univ, Blacksburg, VA 24061 USA.
C3 Virginia Polytechnic Institute & State University
RP Narayanan, S (corresponding author), Virginia Polytech Inst & State Univ, Blacksburg, VA 24061 USA.
EM nsiddh3@vt.edu
OI Polys, Nicholas/0000-0002-8503-970X; Narayanan,
   Siddharth/0000-0002-1879-9565
CR Ahmaniemi Teemu, 2010, NIME, P485
   Anderson A, 2017, J INF TECHNOL CONSTR, V22, P287
   Animesh A, 2011, MIS QUART, V35, P789
   [Anonymous], 1997, MARKET RES SOC J, DOI DOI 10.1177/147078539703900202
   [Anonymous], 2012, P INT SOC PRESENCE R
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Barnes B, 2016, CINEMACRAFT VIRTUAL, P11
   Bianchi-Berthouze N, 2007, LECT NOTES COMPUT SC, V4738, P102
   Bianchi-Berthouze N, 2013, HUM-COMPUT INTERACT, V28, P40, DOI 10.1080/07370024.2012.688468
   Biocca F., 2001, 4 ANN INT WORKSH PRE, P1
   Bowman D.A., 2009, Proceedings of Joint Virtual Reality Conference of EGVE - ICAT - EuroVR, Lyon, France, 7-9 December 2009, P121
   Bray David A., 2007, Data Base for Advances in Information Systems, V38, P17, DOI 10.1145/1314234.1314239
   Buecheler C, 2010, CHARACTER NEXT GREAT
   Bukvic I, 2012, LIN AUD C STANF CAL, P55
   Cahoon C, 2014, OPERACRAFT BLURRING, P6
   Carey B, 2016, ARXIV161103081, P4
   Carlson PJ, 1998, MIS QUART, V22, P335, DOI 10.2307/249669
   Choney S, 2016, MICROSOFT STORES OFF
   Collingwoode-Williams T, 2017, P IEEE VIRT REAL ANN, P253, DOI 10.1109/VR.2017.7892272
   Denisova A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P145, DOI 10.1145/2702123.2702256
   Duncan Sean C, 2011, Well Played J Video Games Value Mean, V1, P1
   Fritsch Tobias., 2005, NETGAMES 05, P1
   Garrelts N., 2014, Understanding Minecraft: Essays on play, community and possibilities
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   Huh Y., 2018, 2018 IEEE 20th International Conference on e-Health Networking, Applications and Services (Healthcom), P1
   Institute for Creativity A Technology, 2016, ICAT DAY 2016
   Kastelein R, 2013, RISE MACHINIMA ARTFO
   Katsyri J, 2018, UNCANNY SLOPE INSTEA, P4
   Kinect M, 2017, KINECT KINECT
   Kokkinara E, 2015, ACM T APPL PERCEPT, V13, DOI 10.1145/2818998
   Lay S, 2016, I-PERCEPTION, V7, DOI 10.1177/2041669516681309
   Lécuyer A, 2017, IEEE COMPUT GRAPH, V37, P20, DOI 10.1109/MCG.2017.14
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Makled E, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188573
   Mantymaki M., 2011, P PACIFIC ASIA C INF, P126
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Microsoft, 2016, IMP MIN ED ED MAK CL
   Microsoft, 2017, KIN 360
   Microsoft, 2017, WIND PRES FDN WPF IS
   Minetest, 2016, MEET MIN
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Nah FFH, 2011, MIS QUART, V35, P731
   Narang S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P9, DOI 10.1109/VR.2018.8446152
   Nash EB, 2000, INT J HUM-COMPUT INT, V12, P1, DOI 10.1207/S15327590IJHC1201_1
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Park N, 2010, INT J HUM-COMPUT ST, V68, P822, DOI 10.1016/j.ijhcs.2010.07.002
   Parker J. R., 2008, LOADING, V2, P2
   Polyak E, 2012, SIGGRAPH AS 2012 SA, P31, DOI 10.1145/2407156.2407191
   Polys NF, 2015, WEB3D 2015, P171, DOI 10.1145/2775292.2775317
   Ragan ED, 2010, PRESENCE-TELEOP VIRT, V19, P527, DOI 10.1162/pres_a_00016
   Ratcliffe J, 2014, P NEW INT MUS EXPR N, V2014, P136
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   Sacau A, 2008, COMPUT HUM BEHAV, V24, P2255, DOI 10.1016/j.chb.2007.11.001
   Saunders C, 2011, MIS QUART, V35, P1079
   Schroeder R, 2001, COMPUT GRAPH-UK, V25, P781, DOI 10.1016/S0097-8493(01)00120-0
   Schroeder Ralph, 2012, The social life of avatars: Presence and interaction in shared virtual environments
   Schultze U., 2011, P INT C INFORM SYSTE
   Schultze U, 2010, INFORM SYST RES, V21, P810, DOI 10.1287/isre.1100.0321
   Seymour M, 2017, HAW INT C SYST SCI
   Seymour M, 2018, J ASSOC INF SYST, V19, P953, DOI 10.17705/1jais.00515
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Sia CL, 2002, INFORM SYST RES, V13, P70, DOI 10.1287/isre.13.1.70.92
   Sims K., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P15, DOI 10.1145/192161.192167
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   SPANTE M, 2003, P PRES 2003 6 INT WO
   Swainston A, 2015, ASME 20 NAT C P AUST, P99
   Tech V, 2017, SCI MUSEUM W VIRGINI
   Tech V, 2016, S SW 2016
   Thon J.-N., 2008, EXTENDING EXPERIENCE, P29
   Tinwell A, 2011, COMPUT HUM BEHAV, V27, P741, DOI 10.1016/j.chb.2010.10.018
   Viniconis N, 2011, MINECRAFT KINECT BUI
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wright M., 2003, Conf. New Interfaces Music. Expr, P153, DOI DOI 10.1007/978-3-319-47214-0_9
   Yoo Y, 2001, MIS QUART, V25, P371, DOI 10.2307/3250922
   Zhu L, 2010, INFORM SYST RES, V21, P872, DOI 10.1287/isre.1080.0218
NR 79
TC 3
Z9 4
U1 3
U2 33
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 53
EP 73
DI 10.1007/s10055-019-00382-0
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800004
OA Green Published
DA 2024-07-18
ER

PT J
AU Daniela, L
   Lytras, MD
AF Daniela, Linda
   Lytras, Miltiadis D.
TI Editorial: themed issue on enhanced educational experience in virtual
   and augmented reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Augmented reality; Education; Learning process;
   Knowledge acquisition
AB VR and AR can bring changes not only to the everyday life of society, but also in humans' cognitive capacity to perceive and imagine, giving them the opportunity to experience what is not possible in the real world, and equipping them with the possibility to see objects, places and situations that cannot be seen in reality. Technologies change the field of education, the way people learn and the way they acquire knowledge; consequently, changes need to be made in the way students are taught and in how their knowledge is assessed when using these technologies. In the context of VR/AR educational experiences, significant transformations are needed; in particular, these experiences move away from local teaching to translocal teaching as the virtual world gives students the possibility to disconnect from their physical environment. VR/AR can be combined with haptic solutions and ideas of gamification to support learning and provide diverse experiences. Both the socialisation process and the environment are partly transformed, and virtual communities are created which, in turn, advance new challenges to the teaching and learning process.
C1 [Daniela, Linda] Univ Latvia, Riga, Latvia.
   [Lytras, Miltiadis D.] Amer Coll Greece, Athens, Greece.
C3 University of Latvia
RP Daniela, L (corresponding author), Univ Latvia, Riga, Latvia.
EM linda.daniela@lu.lv
RI Daniela, Linda/T-8987-2018; Lytras, Miltiadis/ABD-5607-2021; Lytras,
   Miltiadis D./P-8195-2016; Lytras, Miltiadis/GSM-7668-2022; Lytras,
   Miltiades Demetrios/ABD-5355-2021
OI Daniela, Linda/0000-0002-0712-2276; Lytras, Miltiadis
   D./0000-0002-7281-5458; Lytras, Miltiadis/0000-0002-7281-5458; 
CR [Anonymous], 2018, SUSTAINABILITY BASEL, DOI DOI 10.3390/su10092974
   Bloom B. S., 1956, TAXONOMY ED OBJECTIV
   Bloom B.S., 1971, HDB FORMATIVE SUMMAT
   Daniela L., 2019, Didactics of smart pedagogy: Smart pedagogy for technology enhanced learning, P3, DOI [DOI 10.1007/978-3-030-01551-03, 10.1007/978-3-030-01551-0_3, DOI 10.1007/978-3-030-01551-0_3]
   Fowler C, 2015, BRIT J EDUC TECHNOL, V46, P412, DOI 10.1111/bjet.12135
   Jonassen D.H., 2000, EDUC TECHNOL, V40, P21
NR 6
TC 20
Z9 20
U1 0
U2 67
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 325
EP 327
DI 10.1007/s10055-019-00383-z
PG 3
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300001
DA 2024-07-18
ER

PT J
AU Papanastasiou, G
   Drigas, A
   Skianis, C
   Lytras, M
   Papanastasiou, E
AF Papanastasiou, George
   Drigas, Athanasios
   Skianis, Charalabos
   Lytras, Miltiadis
   Papanastasiou, Effrosyni
TI Virtual and augmented reality effects on K-12, higher and tertiary
   education students' twenty-first century skills
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual and augmented reality; K-12; Higher education; Tertiary
   education; Twenty-first century skills
ID LEARNING OUTCOMES; ENVIRONMENTS; AUTISM; CHALLENGES; CHILDREN; SCIENCE;
   SYSTEMS; OPPORTUNITIES; INTERVENTION; TECHNOLOGY
AB The purpose of this review article is to present state-of-the-art approaches and examples of virtual reality/augmented reality (VR/AR) systems, applications and experiences which improve student learning and the generalization of skills to the real world. Thus, we provide a brief, representative and non-exhaustive review of the current research studies, in order to examine the effects, as well as the impact of VR/AR technologies on K-12, higher and tertiary education students' twenty-first century skills and their overall learning. According to the literature, there are promising results indicating that VR/AR environments improve learning outcomes and present numerous advantages of investing time and financial resources in K-12, higher and tertiary educational settings. Technological tools such as VR/AR improve digital-age literacy, creative thinking, communication, collaboration and problem solving ability, which constitute the so-called twenty-first century skills, necessary to transform information rather than just receive it. VR/AR enhances traditional curricula in order to enable diverse learning needs of students. Research and development relative to VR/AR technology is focused on a whole ecosystem around smart phones, including applications and educational content, games and social networks, creating immersive three-dimensional spatial experiences addressing new ways of human-computer interaction. Raising the level of engagement, promoting self-learning, enabling multi-sensory learning, enhancing spatial ability, confidence and enjoyment, promoting student-centered technology, combination of virtual and real objects in a real setting and decreasing cognitive load are some of the pedagogical advantages discussed. Additionally, implications of a growing VR/AR industry investment in educational sector are provided. It can be concluded that despite the fact that there are various barriers and challenges in front of the adoption of virtual reality on educational practices, VR/AR applications provide an effective tool to enhance learning and memory, as they provide immersed multimodal environments enriched by multiple sensory features.
C1 [Papanastasiou, George; Drigas, Athanasios] NCSR Demokritos, Gregoriou E & 27,Neapoleos Str, Aghia Paraskevi 15341, Greece.
   [Papanastasiou, George; Skianis, Charalabos] Univ Aegean, Karlovassi 83200, Samos, Greece.
   [Lytras, Miltiadis] Amer Coll Greece, 6 Gravias Str, Aghia Paraskevi 15342, Greece.
   [Lytras, Miltiadis] King Abdulaziz Univ, Jeddah, Saudi Arabia.
   [Papanastasiou, Effrosyni] Natl Tech Univ Athens, Zografou Campus 9,Iroon Polytechniou Str, Athens 15780, Greece.
C3 National Centre of Scientific Research "Demokritos"; University of
   Aegean; King Abdulaziz University; National Technical University of
   Athens
RP Papanastasiou, G (corresponding author), NCSR Demokritos, Gregoriou E & 27,Neapoleos Str, Aghia Paraskevi 15341, Greece.; Papanastasiou, G (corresponding author), Univ Aegean, Karlovassi 83200, Samos, Greece.
EM gpapanasta@aegean.gr
RI Lytras, Miltiades Demetrios/ABD-5355-2021; Lytras,
   Miltiadis/ABD-5607-2021; ARSLAN, Okan/AAA-3232-2020; Papanastasiou,
   George P./N-4934-2017; Lytras, Miltiadis/GSM-7668-2022; Lytras,
   Miltiadis D./P-8195-2016
OI Papanastasiou, George P./0000-0001-9964-0427; Lytras,
   Miltiadis/0000-0002-7281-5458; Lytras, Miltiadis D./0000-0002-7281-5458;
   DRIGAS, ATHANASIOS/0000-0001-5637-9601
CR González MMA, 2013, PROCEDIA COMPUT SCI, V25, P330, DOI 10.1016/j.procs.2013.11.039
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Anderson L., 2009, TAXONOMY LEARNING TE
   [Anonymous], 2013, ED LIFE WORK DEV TRA
   [Anonymous], DIGI CAPITAL
   [Anonymous], 2011, OECD Digital Economy Papers, V184, P1, DOI [DOI 10.1787/5KG9QGNPJMJG-EN, 10. 1787/5kg9qgnpjmjg-en]
   Ardila A., 2016, Psychology Neuroscience, V9, P215, DOI DOI 10.1037/PNE0000052
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Bellanca J., 2010, 21st Century skills: Rethinking how students learn
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Bower M, 2014, EDUC MEDIA INT, V51, P1, DOI 10.1080/09523987.2014.889400
   Cascales-Martínez A, 2017, EURASIA J MATH SCI T, V13, P355, DOI 10.12973/eurasia.2017.00621a
   Chau M, 2013, DECIS SUPPORT SYST, V56, P115, DOI 10.1016/j.dss.2013.05.009
   Chen CH, 2016, COMPUT HUM BEHAV, V55, P477, DOI 10.1016/j.chb.2015.09.033
   Chen Yu-Chien., 2008, Proceedings - ICCE 2008: 16th International Conference on Computers in Education, P291
   Chiang THC, 2014, EDUC TECHNOL SOC, V17, P352
   Chiang THC, 2014, COMPUT EDUC, V78, P97, DOI 10.1016/j.compedu.2014.05.006
   Chow A., 2007, P AM ED COMMUNICATIO, P75
   Christou C., 2010, Affective, interactive and cognitive methods for e-learning design: Creating an optimal education experience, P228
   López JMC, 2010, COMPUT EDUC, V55, P1336, DOI 10.1016/j.compedu.2010.05.028
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   De Lucia A, 2009, COMPUT EDUC, V52, P220, DOI 10.1016/j.compedu.2008.08.001
   Digi-Capital, 2017, DIGI CAPITAL
   Dunleavy M, 2009, J SCI EDUC TECHNOL, V18, P7, DOI 10.1007/s10956-008-9119-1
   Freitas R., 2008, Proceedings of the 22nd British HCI Group Annual Conference on People and Computers: Culture, Creativity, Interaction, VVolume 22, P27
   Furió D, 2013, COMPUT EDUC, V64, P24, DOI 10.1016/j.compedu.2012.12.015
   Gamito P., 2011, Int. J. Disabil. Hum. Dev, V10, P309, DOI DOI 10.1515/IJDHD.2011.049
   Gardner H., 1983, Frames of mind
   Hew KF, 2010, BRIT J EDUC TECHNOL, V41, P33, DOI 10.1111/j.1467-8535.2008.00900.x
   Huang TC, 2016, COMPUT EDUC, V96, P72, DOI 10.1016/j.compedu.2016.02.008
   Jackson R. L., 2000, CVE 2000. Proceedings of the Third International Conference on Collaborative Virtual Environments, P83, DOI 10.1145/351006.351018
   Jena RK, 2016, BEHAV INFORM TECHNOL, V35, P946, DOI 10.1080/0144929X.2016.1212930
   Karyotaki M, 2017, INT J EMERG TECHNOL, V12, P219, DOI 10.3991/ijet.v12i03.6587
   Kaufmann H, 2007, LECT NOTES COMPUT SC, V4563, P660
   Kerawalla L., 2006, Virtual Real, V10, P163, DOI [10.1007/s10055-006-0036-4, DOI 10.1007/S10055-006-0036-4]
   Kurilovas E, 2016, BEHAV INFORM TECHNOL, V35, P998, DOI 10.1080/0144929X.2016.1212929
   Kye B., 2008, International Journal for Education Media and Technology, V2, P4
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Ledward B.C., 2011, An overview of 21st century skills
   Lee EAL, 2010, COMPUT EDUC, V55, P1424, DOI 10.1016/j.compedu.2010.06.006
   Lee K, 2012, TECHTRENDS, V56, P13, DOI 10.1007/s11528-012-0559-3
   Legge ELG, 2012, ACTA PSYCHOL, V141, P380, DOI 10.1016/j.actpsy.2012.09.002
   Lorenzo G, 2016, COMPUT EDUC, V98, P192, DOI 10.1016/j.compedu.2016.03.018
   Lorenzo G, 2013, COMPUT EDUC, V62, P88, DOI 10.1016/j.compedu.2012.10.028
   Lytras MD, 2016, BEHAV INFORM TECHNOL, V35, P877, DOI 10.1080/0144929X.2016.1235815
   Lytras MD, 2015, COMPUT HUM BEHAV, V51, P557, DOI 10.1016/j.chb.2015.06.004
   Martín-Gutiérrez J, 2017, EURASIA J MATH SCI T, V13, P469, DOI 10.12973/eurasia.2017.00626a
   Martín-Gutiérrez J, 2015, COMPUT HUM BEHAV, V51, P752, DOI 10.1016/j.chb.2014.11.093
   Me FF, 2015, INTERNET HIGH EDUC, V26, P33, DOI 10.1016/j.iheduc.2015.04.003
   Mennecke BE, 2008, COMMUN ASSOC INF SYS, V22
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Michailidou A, 2002, P E LEARN 2002 WORLD, P690
   Mikropoulos T., 2006, P IADIS INT C E SOC, P122, DOI [10.4324/9780203852057, DOI 10.4324/9780203852057]
   Mikropoulos T. A., 1998, Education and Information Technologies, V3, P137, DOI 10.1023/A:1009687025419
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Muñoz-Cristóbal JA, 2015, IEEE T LEARN TECHNOL, V8, P83, DOI 10.1109/TLT.2014.2370634
   Muschio G, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS & INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION & STANDARDS DIGITAL HERITAGE PROJECTS & APPLICATIONS, P683, DOI 10.1109/DigitalHeritage.2015.7419598
   Novotny M, 2013, PROCEDIA COMPUT SCI, V25, P231, DOI 10.1016/j.procs.2013.11.028
   Orlosky J., 2017, J INF PROCESS SYST, V25, P133, DOI [DOI 10.2197/IPSJJIP.25.133, 10.2197/ipsjjip.25.133, DOI 10.2197/IPSJJIP.25, 10.2197/ipsjjip.25]
   Pantelidis V.S., 2010, THEMES SCI TECHNOLOG, V2, P59
   Parsons Sarah, 2015, International Journal of Child-Computer Interaction, V6, P28, DOI 10.1016/j.ijcci.2015.12.002
   Parsons S, 2016, EDUC RES REV-NETH, V19, P138, DOI 10.1016/j.edurev.2016.08.001
   Potkonjak V, 2016, COMPUT EDUC, V95, P309, DOI 10.1016/j.compedu.2016.02.002
   Radu I, 2012, INT SYM MIX AUGMENT, P313, DOI 10.1109/ISMAR.2012.6402590
   Roebers CM, 2017, DEV REV, V45, P31, DOI 10.1016/j.dr.2017.04.001
   Saltan F, 2017, EURASIA J MATH SCI T, V13, P503, DOI 10.12973/eurasia.2017.00628a
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Sanabria JC, 2017, EURASIA J MATH SCI T, V13, P487, DOI 10.12973/eurasia.2017.00627a
   Sárkány A, 2016, COMM COM INF SC, V604, P220, DOI 10.1007/978-3-319-32270-4_22
   Schmidt M, 2012, COMPUT HUM BEHAV, V28, P405, DOI 10.1016/j.chb.2011.10.011
   Sivan Y., 2008, J VIRTUAL WORLDS RES, V1, P1
   Sollervall H., 2012, Research and Practices in Technology Enhanced Learning, V7, P153
   Trilling B., 2012, 21st century skills: Learning for life in our times, DOI DOI 10.5860/CHOICE.47-5788
   Vitiello VE, 2017, J APPL DEV PSYCHOL, V53, P1, DOI 10.1016/j.appdev.2017.08.004
   Wallace S, 2010, AUTISM, V14, P199, DOI 10.1177/1362361310363283
   White SW, 2007, J AUTISM DEV DISORD, V37, P1858, DOI 10.1007/s10803-006-0320-x
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yilmaz RM, 2017, VIRTUAL REAL-LONDON, V21, P75, DOI 10.1007/s10055-016-0300-1
   Yu DG, 2010, VISUAL INFORMATION COMMUNICATION, P311, DOI 10.1007/978-1-4419-0312-9_21
   Yusof AM, 2014, INT J INCLUSIVE EDUC, V18, P1237, DOI 10.1080/13603116.2014.885595
   Zarzo E, 2015, PROCD SOC BEHV, V178, P222, DOI 10.1016/j.sbspro.2015.03.185
   Zygouris S, 2017, J ALZHEIMERS DIS, V56, P619, DOI 10.3233/JAD-160518
NR 82
TC 127
Z9 144
U1 22
U2 280
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2019
VL 23
IS 4
SI SI
BP 425
EP 436
DI 10.1007/s10055-018-0363-2
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA JB8RZ
UT WOS:000488844300009
DA 2024-07-18
ER

PT J
AU Al-Sada, M
   Jiang, KR
   Ranade, S
   Kalkattawi, M
   Nakajima, T
AF Al-Sada, Mohammed
   Jiang, Keren
   Ranade, Shubhankar
   Kalkattawi, Mohammed
   Nakajima, Tatsuo
TI HapticSnakes: multi-haptic feedback wearable robots for immersive
   virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Haptic; Multipurpose; Design; Wearable; Robot; Feeding; Airflow; Taps;
   Gestures; Torso
AB Haptic feedback plays a large role in enhancing immersion and presence in VR. However, previous research and commercial products have limitations in terms of variety and locations of delivered feedbacks. To address these challenges, we present HapticSnakes, which are snake-like waist-worn robots that can deliver multiple types of feedback in various body locations, including taps-, gestures-, airflow-, brushing- and gripper-based feedbacks. We developed two robots, one is lightweight and suitable for taps and gestures, while the other is capable of multiple types of feedback. We presented a design space based on our implementations and conducted two evaluations. Since taps are versatile, easy to deliver and largely unexplored, our first evaluation focused on distinguishability of tap strengths and locations on the front and back torso. Participants had highest accuracy in distinguishing feedback on the uppermost regions and had superior overall accuracy in distinguishing feedback strengths over locations. Our second user study investigated HapticSnakes' ability to deliver multiple feedback types within VR experiences, as well as users' impressions of wearing our robots and receiving novel feedback in VR. The results indicate that participants had distinct preferences for feedbacks and were in favor of using our robots throughout. Based on the results of our evaluations, we extract design considerations and discuss research challenges and opportunities for developing multi-haptic feedback robots.
C1 [Al-Sada, Mohammed; Jiang, Keren; Ranade, Shubhankar; Nakajima, Tatsuo] Waseda Univ, Tokyo, Japan.
   [Kalkattawi, Mohammed] Jeddah Univ, Jeddah, Saudi Arabia.
   [Al-Sada, Mohammed] Qatar Univ, Doha, Qatar.
C3 Waseda University; University of Jeddah; Qatar University
RP Al-Sada, M (corresponding author), Waseda Univ, Tokyo, Japan.; Al-Sada, M (corresponding author), Qatar Univ, Doha, Qatar.
EM Alsada@dcl.cs.waseda.ac.jp; Jiangkeren@dcl.cs.waseda.ac.jp;
   Shubhi@dcl.cs.waseda.ac.jp; Mhkalkattawi@uj.edu.sa;
   Tatsuo@dcl.cs.waseda.ac.jp
FU Qatar National Library; Program for Leading Graduate Schools, "Graduate
   Program for Embodiment Informatics" by Japan's Ministry of Education,
   Culture, Sports, Science and Technology
FX Open Access funding provided by the Qatar National Library. The
   presented work is supported in part through Program for Leading Graduate
   Schools, "Graduate Program for Embodiment Informatics" by Japan's
   Ministry of Education, Culture, Sports, Science and Technology. We would
   also like to thank Mr. Thomas Hoglund for his contribution to the
   mechanical design and control software of the HapticSnakes system.
CR Al Maimani A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2440, DOI 10.1145/3025453.3025835
   Al-Sada M, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188518
   Al-Sada M, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI [10.1145/3311823.3311850, 10.1109/ictcs.2019.8923046]
   [Anonymous], 2019, TACTSUIT FULL BODY H
   [Anonymous], 2019, WEBSOCKET PROTOCOL
   [Anonymous], 2018, TACTILE NAVIGATION T
   [Anonymous], 2018, ARAIG MULTISENSORY V
   [Anonymous], 1988, Proceedings of the SIGCHI conference on Human factors in computing systems-CHI, DOI DOI 10.1145/57167.57203
   [Anonymous], 2019, PHANTOMX PARALLEL AX
   [Anonymous], 2018, MOTION CAPTURE VIRTU
   [Anonymous], 2019, ALLEGRO HAND
   [Anonymous], 2019, UNITY3D GAME ENGINE
   [Anonymous], 2019, HTC Vive
   Arnold P, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P398, DOI 10.1145/3173225.3173238
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   Cholewiak RW, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P413
   Corley A-M, 2010, TACTILE GAMING VEST
   de Carvalho MR, 2017, BEHAV SCI-BASEL, V7, DOI 10.3390/bs7030043
   Delazio A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173894
   Dementyev A, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P111, DOI 10.1145/2984511.2984531
   Diener V, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (ISWC 17), P82, DOI 10.1145/3123021.3123047
   Ekman Inger, 2013, P 8 INT C FDN DIGITA, P142
   Ferrer-Garcia M, 2013, J CONTEMP PSYCHOTHER, V43, P207, DOI 10.1007/s10879-013-9240-1
   García-Valle G, 2018, IEEE ACCESS, V6, P7224, DOI 10.1109/ACCESS.2017.2782254
   García-Valle G, 2016, LECT NOTES COMPUT SC, V9775, P251, DOI 10.1007/978-3-319-42324-1_25
   Gil H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174232
   Harley D, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P386, DOI 10.1145/3173225.3173241
   Hoppe M, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P7, DOI 10.1145/3282894.3282898
   Ion A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2501, DOI 10.1145/2702123.2702459
   Je S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3106, DOI 10.1145/3025453.3025703
   Je S, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (ISWC 17), P98, DOI 10.1145/3123021.3123050
   Jones LA, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P82, DOI 10.1109/HAPTIC.2004.1287181
   Karrer T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1313
   Konishi Y, 2016, ACM SIGGRAPH 2016 VR VILLAGE (SIGGRAPH '16), DOI 10.1145/2945078.2945149
   Li HB, 2013, IEEE-ASME T MECH, V18, P74, DOI 10.1109/TMECH.2011.2163415
   Lindeman R.W., 2004, ACM Symposium on Virtual Reality Software and Technology, P146, DOI DOI 10.1145/1077534.1077562
   Luzhnica G, 2016, IEEE INT SYM WRBL CO, P148, DOI 10.1145/2971763.2971769
   McMahan A., 2003, The Video Game Reader, V67, P86
   Murakami T., 2017, ACM SIGGRAPH 2017 EM, DOI 10.1145/3084822.3084836
   Nakata Y, 2015, IEEE INT C INT ROBOT, P6238, DOI 10.1109/IROS.2015.7354267
   Okumura K, 2011, IEEE INT CONF ROBOT, DOI 10.1109/ICRA.2011.5980080
   Peiris RL, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5452, DOI 10.1145/3025453.3025824
   Ranasinghe N, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174151
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1731, DOI 10.1145/3025453.3025723
   Rasmussen M. K., 2012, P CHI 2012, P735, DOI DOI 10.1145/2207676.2207781
   Rietzler M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5669, DOI 10.1145/3025453.3026009
   Roudaut Anne., 2013, P SIGCHI C HUMAN FAC, P2547
   Schmitz A, 2011, IEEE T ROBOT, V27, P389, DOI 10.1109/TRO.2011.2132930
   Schneider OS, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P21, DOI 10.1145/2807442.2807470
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Shim YA, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173706
   Strasnick E, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3120, DOI 10.1145/3025453.3025759
   Tsetserukou D, 2010, INT C HUM HAPT SENS
   Tuanquin N.M. B., 2017, Proceedings of the 19th ACM International Conference on Multimodal Interaction, P618, DOI [DOI 10.1145/3136755, DOI 10.1145/3136755.3137029, 10.1145/3136755]
   Wagner Julie., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'13), P1299, DOI DOI 10.1145/2470654.2466170
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Wilson G, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1133, DOI 10.1145/2556288.2557033
   Wu SW, 2010, HAPT S 2010 IEEE WOO
   Yang U, 2002, INT C ART REAL TEL
NR 60
TC 29
Z9 30
U1 2
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 191
EP 209
DI 10.1007/s10055-019-00404-x
EA SEP 2019
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000488921100001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Brengman, M
   Willems, K
   Van Kerrebroeck, H
AF Brengman, Malaika
   Willems, Kim
   Van Kerrebroeck, Helena
TI Can't touch this: the impact of augmented reality versus touch and
   non-touch interfaces on perceived ownership
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Perceived ownership; Touch; Virtual product
   interaction; Mobile commerce
ID PSYCHOLOGICAL OWNERSHIP; PRODUCT EXPERIENCE; CONSUMER CHOICE; LOCAL
   PRESENCE; TACTILE INPUT; ONLINE; TECHNOLOGY; IMAGERY; RETAIL;
   INFORMATION
AB The rise of augmented reality (AR) technology presents e-retailers with new opportunities. According to previous research, it is a technology that can positively affect engagement, brand recall and purchase confidence. Mobile-enabled augmented reality differs from regular mobile phone use as the technology virtually overlays images or information to the real environment. As the use of a touch screen device (i.e. smartphone vs. laptop) has previously been found to positively affect feelings of perceived ownership, the current study examines whether the possibility to virtually manipulate a product on a mobile AR application would have an even stronger effect. This is examined for products with either material properties (i.e. products that require the examination of sensory information) or geometric properties (i.e. products that can be examined via written and/or visual information). The findings reveal that AR does indeed result in higher levels of perceived ownership, particularly in case of material products.
C1 [Brengman, Malaika; Willems, Kim; Van Kerrebroeck, Helena] Vrije Univ Brussel, Dept Business Mkt & Consumer Behav, Pl Laan 2 C2-12, B-1050 Brussels, Belgium.
   [Willems, Kim] Hasselt Univ, Dept Mkt & Strategy, Agoralaan Bldg D, B-3590 Diepenbeek, Belgium.
C3 Vrije Universiteit Brussel; Hasselt University
RP Brengman, M (corresponding author), Vrije Univ Brussel, Dept Business Mkt & Consumer Behav, Pl Laan 2 C2-12, B-1050 Brussels, Belgium.
EM malaika.brengman@vub.be; kim.willems@vub.be
CR Adhani NI., 2012, 1st International conference on future trends in computing and communication technologies, P89
   [Anonymous], 2016, GARTNERS 2016 HYPE C
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baier D., 2015, Successful Technological Integration for Competitive Advantage in Retail Settings, P168
   Balaji MS, 2011, ASIA PAC J MARKET LO, V23, P513, DOI 10.1108/13555851111165066
   Blázquez M, 2014, INT J ELECTRON COMM, V18, P97, DOI 10.2753/JEC1086-4415180404
   Brasel SA, 2014, J CONSUM PSYCHOL, V24, P226, DOI 10.1016/j.jcps.2013.10.003
   Brown StevenP., 1995, J ACAD MARKET SCI, V23, P170, DOI DOI 10.1177/0092070395233002
   Bulearca M., 2010, Global Business Management Research, V2, P237
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Citrin AV, 2003, J BUS RES, V56, P915, DOI 10.1016/S0148-2963(01)00278-8
   Coulter KS, 2016, PSYCHOL MARKET, V33, P135, DOI 10.1002/mar.20860
   Dacko SG, 2017, TECHNOL FORECAST SOC, V124, P243, DOI 10.1016/j.techfore.2016.09.032
   Daponte P, 2014, MEASUREMENT, V57, P53, DOI 10.1016/j.measurement.2014.07.009
   Degeratu AM, 2000, INT J RES MARK, V17, P55, DOI 10.1016/S0167-8116(00)00005-7
   Dhar R, 2000, J MARKETING RES, V37, P60, DOI 10.1509/jmkr.37.1.60.18718
   Feuchtl S, 2009, ADV CONSUM RES, V36, P995
   Field A., 2013, DISCOVERING STAT USI
   Fuchs C, 2010, J MARKETING, V74, P65, DOI 10.1509/jmkg.74.1.65
   Furby Lita, 1980, Political Psychology, V2, P30
   Gartner, 2016, WHY IT LEAD SHOULD P
   Gineikiene J, 2017, J BUS RES, V72, P93, DOI 10.1016/j.jbusres.2016.11.003
   Grohmann B, 2007, J RETAILING, V83, P237, DOI 10.1016/j.jretai.2006.09.001
   Gurtner S, 2014, TECHNOL FORECAST SOC, V88, P177, DOI 10.1016/j.techfore.2014.06.020
   Hoch SJ, 2002, J CONSUM RES, V29, P448, DOI 10.1086/344422
   HOMER PM, 1990, J MARKETING RES, V27, P78, DOI 10.2307/3172553
   Javornik A, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P871, DOI 10.1145/2901790.2901881
   Javornik A, 2016, J MARKET MANAG-UK, V32, P987, DOI 10.1080/0267257X.2016.1174726
   Javornik A, 2016, J RETAIL CONSUM SERV, V30, P252, DOI 10.1016/j.jretconser.2016.02.004
   Javornik A, 2014, INT SYM MIX AUGMENT, P67, DOI 10.1109/ISMAR-AMH.2014.6935441
   KAHNEMAN D, 1990, J POLIT ECON, V98, P1325, DOI 10.1086/261737
   Kamleitner B, 2015, J MARKET THEORY PRAC, V23, P208, DOI 10.1080/10696679.2015.1002337
   Kirk CP, 2015, J MARKET THEORY PRAC, V23, P166, DOI 10.1080/10696679.2015.1002335
   KLATZKY RL, 1993, J EXP PSYCHOL HUMAN, V19, P726
   Klatzky RL, 2012, IEEE T HAPTICS, V5, P139, DOI [10.1109/ToH.2011.54, 10.1109/TOH.2011.54]
   Krishna A, 2011, J CONSUM PSYCHOL, V21, P338, DOI 10.1016/j.jcps.2011.02.001
   Laroche M, 2005, J RETAILING, V81, P251, DOI 10.1016/j.jretai.2004.11.002
   LeBarr AN, 2017, CONSCIOUS COGN, V48, P190, DOI 10.1016/j.concog.2016.11.012
   Liao T, 2015, INFORM COMMUN SOC, V18, P310, DOI 10.1080/1369118X.2014.989252
   Mauroner O., 2016, World Academy of Science, Engineering and Technology, International Journal of Social, Behavioral, Educational, Economic, Business and Industrial Engineering, V10, P422
   McCabe DB, 2003, J CONSUM PSYCHOL, V13, P431, DOI 10.1207/S15327663JCP1304_10
   McKnight D. H., 2002, Information Systems Research, V13, P334, DOI 10.1287/isre.13.3.334.81
   Mekni M., 2014, APPL COMPUTATIONAL S, P205
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Overmars S, 2013, INT CONF AFFECT, P798, DOI 10.1109/ACII.2013.148
   Pantano E, 2014, INT J INFORM MANAGE, V34, P344, DOI 10.1016/j.ijinfomgt.2014.03.002
   Pantano E, 2012, J RETAIL CONSUM SERV, V19, P279, DOI 10.1016/j.jretconser.2012.02.002
   Pantano E, 2010, J RETAIL CONSUM SERV, V17, P200, DOI 10.1016/j.jretconser.2010.03.010
   Peck J, 2003, J MARKETING, V67, P35, DOI 10.1509/jmkg.67.2.35.18612
   Peck J, 2006, J BUS RES, V59, P765, DOI 10.1016/j.jbusres.2006.01.014
   Peck J, 2013, J CONSUM PSYCHOL, V23, P189, DOI 10.1016/j.jcps.2012.09.001
   Peck J, 2009, J CONSUM RES, V36, P434, DOI 10.1086/598614
   Pierce JL, 2003, REV GEN PSYCHOL, V7, P84, DOI 10.1037/1089-2680.7.1.84
   Pousttchi K., 2015, Introduction to the Special Issue on Mobile Commerce: Mobile Commerce Research Yesterday, Today, Tomorrow-What Remains to Be Done?
   Rese A, 2017, TECHNOL FORECAST SOC, V124, P306, DOI 10.1016/j.techfore.2016.10.010
   Rese A, 2014, J RETAIL CONSUM SERV, V21, P869, DOI 10.1016/j.jretconser.2014.02.011
   RUDMIN FW, 1987, PSYCHOL REC, V37, P257, DOI 10.1007/BF03394988
   Schlosser AE, 2003, J CONSUM RES, V30, P184, DOI 10.1086/376807
   Schlosser AE, 2006, J CONSUM RES, V33, P377, DOI 10.1086/508522
   Shen H, 2016, J MARKETING RES, V53, P745, DOI 10.1509/jmr.14.0563
   Song JH, 2008, J MARKETING, V72, P99, DOI 10.1509/jmkg.72.2.99
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Spreer P., 2014, SOP T MARKETING RES, V1, P20, DOI [10.15764/MR.2014.01002, DOI 10.15764/MR.2014.01002]
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Sundar SS, 2012, ROUTL COMMUN SER, P355
   Van Kerrebroeck H, 2017, INT J RETAIL DISTRIB, V45, P892, DOI 10.1108/IJRDM-09-2016-0156
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Varadarajan R, 2010, J INTERACT MARK, V24, P96, DOI 10.1016/j.intmar.2010.02.004
   Venkatesh V, 2012, MIS QUART, V36, P157
   Verhagen T, 2016, CYBERPSYCH BEH SOC N, V19, P460, DOI 10.1089/cyber.2015.0520
   Verhagen T, 2014, COMPUT HUM BEHAV, V39, P270, DOI 10.1016/j.chb.2014.07.036
   Vonkeman C, 2017, INFORM MANAGE-AMSTER, V54, P1038, DOI 10.1016/j.im.2017.02.008
NR 72
TC 29
Z9 29
U1 8
U2 66
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2019
VL 23
IS 3
SI SI
BP 269
EP 280
DI 10.1007/s10055-018-0335-6
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA IR5QR
UT WOS:000481490500006
DA 2024-07-18
ER

PT J
AU Patle, DS
   Manca, D
   Nazir, S
   Sharma, S
AF Patle, Dipesh S.
   Manca, Davide
   Nazir, Salman
   Sharma, Swapnil
TI Operator training simulators in virtual reality environment for process
   operators: a review
SO VIRTUAL REALITY
LA English
DT Review
DE Operator training simulators (OTS); Process simulators; Virtual reality;
   Training assessment
ID SITUATION AWARENESS; PERFORMANCE; IMPACT
AB Given the factors such as safety, profitability, and environmental concerns at stake, operator training is an everlasting and vital process in the process industry. An inevitable need for skilled operators in the chemical industry leads to search for novel and effective training methodologies. Consequently, dynamic simulation techniques have been considered as a tool to educate and train inexperienced personnel as expected by the industry. Traditional training methodologies are hardly sufficient to instruct the operators for seldom-occurring perilous situations. Conventional operator training simulators (OTS) are generally effective, but they lack to give operators the actual feel of the scenarios. Training effectiveness can be enhanced by providing operators with a sense of realism. Therefore, integration of OTS with virtual reality (VR-OTS) certainly comes out to be an alternative. VR-OTS can replicate emergency conditions, accidents, and investigate safety protocols. In this work, we discuss the need for virtual reality (VR) in OTS, merits of VR-OTS, and the role of training assessment methods. Contributions of OTS Authors' in process industry from year 2000 to mid-2017 are reviewed and discussed extensively. The review shows that VR-OTS provides tangible benefits over its conventional counterparts in terms of improved safety of plant, increased productivity, and environmental protection. Finally, this paper outlines future scopes that the current researcher may consider to focus for the increased and improved VR-OTS usage.
C1 [Patle, Dipesh S.; Sharma, Swapnil] Vellore Inst Technol, Sch Civil & Chem Engn, Dept Chem Engn, Vellore 632014, Tamil Nadu, India.
   [Patle, Dipesh S.; Manca, Davide] Politecn Milan, PSE Lab Proc Syst Engn Lab, CMIC Chem Engn Dept, Piazza Leonardo da Vinci 32, I-20133 Milan, Italy.
   [Nazir, Salman] Univ Coll Southeast Norway, Training & Assessment Res Grp TARG, Postboks 4, N-3199 Borre, Norway.
   [Patle, Dipesh S.] Motilal Nehru Natl Inst Technol Allahabad, Dept Chem Engn, Allahabad, Uttar Pradesh, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Polytechnic
   University of Milan; University College of Southeast Norway; National
   Institute of Technology (NIT System); Motilal Nehru National Institute
   of Technology
RP Patle, DS (corresponding author), Vellore Inst Technol, Sch Civil & Chem Engn, Dept Chem Engn, Vellore 632014, Tamil Nadu, India.; Patle, DS (corresponding author), Politecn Milan, PSE Lab Proc Syst Engn Lab, CMIC Chem Engn Dept, Piazza Leonardo da Vinci 32, I-20133 Milan, Italy.; Patle, DS (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Dept Chem Engn, Allahabad, Uttar Pradesh, India.
EM dipesh.patle@gmail.com
RI Nazir, Salman/KPA-0394-2024; Manca, Davide/G-6845-2013; Patle,
   Dipesh/I-1448-2013
OI Nazir, Salman/0000-0002-2058-6147; Patle, Dipesh/0000-0001-7592-5444;
   Sharma, Swapnil/0000-0001-8724-0987
FU Erasmus Mundus Intact for Postdoctoral research
FX We gratefully acknowledge the fellowship awarded to the author, Dipesh S
   Patle, from Erasmus Mundus Intact for Postdoctoral research.
CR Aggarwal R, 2006, EUR J VASC ENDOVASC, V31, P588, DOI 10.1016/j.ejvs.2005.11.009
   Ahmad Z, 2016, PROCESS SAF ENVIRON, V99, P55, DOI 10.1016/j.psep.2015.10.002
   Antonovsky A, 2014, HUM FACTORS, V56, P306, DOI 10.1177/0018720813491424
   Ayral T, 2016, HYDROCARB PROCESS, V92, P45
   Bell JT, 2004, P IEEE VIRT REAL ANN, P217, DOI 10.1109/VR.2004.1310077
   Bell JT, 1996, ANN ARBOR, V1001, P48109
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Brambilla S, 2011, J LOSS PREVENT PROC, V24, P344, DOI 10.1016/j.jlp.2011.01.009
   Brambilla S, 2009, CHEM PROD PROCESS MO, V4, DOI 10.2202/1934-2659.1295
   Chen Cheng-jun, 2010, Proceedings of the Third International Conference on Information and Computing Science (ICIC 2010), P133, DOI 10.1109/ICIC.2010.127
   Cibulka J, 2016, 2016 9 EUROSIM C MOD, P458
   Colombo S, 2013, P SPE EUR HSE C EXH, P405
   Colombo S, 2011, ASME 2011 WORLD C IN, P1
   Colombo Simone., 2014, SPE Econ. Manag, V6, P165, DOI [DOI 10.2118/164993-PA, 10.2118/164993-PA]
   Cox RK, 2006, COMPUT CHEM ENG, V30, P1542, DOI 10.1016/j.compchemeng.2006.05.020
   Cozens P., 2002, Conference Proceedings of the 18th ACROM Annual Conference, V2, P461
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Fiske T, 2010, 3D SIMULATION BRINGS
   Formosa NJ, 2018, AUST J PSYCHOL, V70, P57, DOI 10.1111/ajpy.12167
   Haller M, 1999, 20 ANN C EUR ASS CG
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Howarth PA, 1997, DISPLAYS, V18, P107, DOI 10.1016/S0141-9382(97)00011-5
   Kanawattanachai P, 2007, MIS QUART, V31, P783
   Kang S, 2018, CLUST COMPUT
   Kluge A., 2014, The Acquisition of Knowledge and Skills for Taskwork and Teamwork to Control Complex Technical Systems: A Cognitive and Macroergonomics Perspective
   Kluge A, 2009, THEOR ISS ERGON SCI, V10, P489, DOI 10.1080/14639220902982192
   Kozlak M., 2014, Szybkobiezne Pojazdy Gsienicowe, V2, P5
   Lee S, 2000, COMPUT CHEM ENG, V24, P1517, DOI 10.1016/S0098-1354(00)00557-3
   Li Z., 2002, Virtual Reality, V6, P96, DOI 10.1007/s100550200010
   Lily Q, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON IT IN MEDICINE AND EDUCATION, VOLS 1 AND 2, PROCEEDINGS, P491, DOI 10.1109/ITME.2008.4743913
   Luo N, 2015, COMPUT-AIDED CHEM EN, V37, P581
   Manca D, 2013, EUR HSE C EXH SOC PE
   Manca D, 2012, S COMP AID PROC ENG, V17, P20
   Manca D, 2017, TECHNICAL CONSIDERAT
   Manca D, 2016, CHEM ENGINEER TRANS, V53, P193, DOI 10.3303/CET1653033
   Manca D, 2014, CHEM ENGINEER TRANS, V36, P391, DOI 10.3303/CET1436066
   Manca D, 2012, CHEM ENGINEER TRANS, V26, P285, DOI 10.3303/CET1226048
   Manca D, 2013, ADV ENG SOFTW, V55, P1, DOI 10.1016/j.advengsoft.2012.09.002
   Manesh HF, 2011, INT J ADV MANUF TECH, V53, P385, DOI 10.1007/s00170-010-2822-0
   Mannan S, 2017, 100 LARGEST LOSSES
   Monferini A, 2010, EUR SAF REL C 2010 E, P1820
   Muravyev A, 2007, AICHE ANN M TEX C P
   Naderpour M, 2015, PROCESS SAF ENVIRON, V97, P13, DOI 10.1016/j.psep.2015.06.002
   Nazir S, 2014, P HUM FACT ERG SOC E, P251
   Nazir S., 2012, HUMAN FACTORS SYSTEM, P235
   Nazir S., 2013, AIDIC C SERIES, V11, P271
   Nazir S, 2015, PROCEDIA MANUF, V3, P1519, DOI 10.1016/j.promfg.2015.07.409
   Nazir S, 2015, PROCESS SAF PROG, V34, P237, DOI 10.1002/prs.11714
   Nazir S, 2015, SAFETY SCI, V73, P136, DOI 10.1016/j.ssci.2014.11.015
   Nazir S, 2013, COMPUT-AIDED CHEM EN, V32, P667
   Nazir S, 2012, COMPUT-AIDED CHEM EN, V30, P1397
   Nazir S, 2012, CHEM ENGINEER TRANS, V26, P303, DOI 10.3303/CET1226051
   Park J, 2004, RELIAB ENG SYST SAFE, V83, P179, DOI 10.1016/j.ress.2003.09.009
   Passos C, 2016, CHEM ENGINEER TRANS, V53, P217, DOI 10.3303/CET1653037
   Patle DS, 2014, REV CHEM ENG, V30, P199, DOI 10.1515/revce-2013-0027
   Reinach S, 2006, ACCIDENT ANAL PREV, V38, P396, DOI 10.1016/j.aap.2005.10.013
   Rose FD, 2005, CYBERPSYCHOL BEHAV, V8, P241, DOI 10.1089/cpb.2005.8.241
   Salmon PM, 2009, INT J IND ERGONOM, V39, P490, DOI 10.1016/j.ergon.2008.10.010
   Shang XL, 2009, COMPUT-AIDED CHEM EN, V26, P435
   Siminovich C, 2014, PROCEDIA ENGINEER, V83, P215, DOI 10.1016/j.proeng.2014.09.041
   Steptoe W, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P83, DOI 10.1109/VR.2009.4811003
   Tasng P.S., 2006, HDB HUMAN FACTORS ER, V3rd, P243, DOI [10.1002/9781118131350.ch8, DOI 10.1002/0470048204.CH9]
   Toro R., 2013, IFAC P, V46, P65
   Wasfy TM, 2001, ADV ENG SOFTW, V32, P717, DOI 10.1016/S0965-9978(01)00020-5
   Yang SH, 2001, PROCESS SAF ENVIRON, V79, P329, DOI 10.1205/095758201753373096
   Zou ZY, 2003, COMP AID CH, V15, P1447
NR 66
TC 54
Z9 55
U1 3
U2 45
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2019
VL 23
IS 3
SI SI
BP 293
EP 311
DI 10.1007/s10055-018-0354-3
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA IR5QR
UT WOS:000481490500008
DA 2024-07-18
ER

PT J
AU Chen, CJ
   Lau, SY
   Teh, CS
AF Chen, Chwen Jen
   Lau, Siew Yung
   Teh, Chee Siong
TI A feasible group testing framework for producing usable virtual reality
   learning applications
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Human-computer interface; Group usability testing;
   Interactive learning environments
ID USABILITY; ENVIRONMENTS
AB Designing a usable learning application is one of the key factors in ensuring effective learning. This article introduces modified group usability testing (MGUT) as a feasible framework for evaluating the usability of non-immersive virtual reality (VR) learning applications. Conventionally, usability testing of such learning applications often employs the one-to-one approach in which an evaluator conducts testing with several individual participants. As opposed to the one-to-one approach, the group approach involves several-to-many participants performing tasks simultaneously, with several evaluators observing and interacting with participants. This article describes the complete step-by-step procedure for conducting MGUT to uncover usability problems of a VR learning application that aims to educate its users on fire safety and prevention. It also proposes methods to analyze these usability problems. The effectiveness and efficiency of MGUT was then compared with DGUT, the original group testing technique and cooperative evaluation (CE), which is a typical one-to-one approach. Results indicate that all three techniques are able to reveal usability problems of different usability factors and show similar capability to discover the most critical and serious problems. MGUT is more effective than DGUT as it can collect additional usability problems of various factors and of different levels of severity. MGUT is as effective as CE as both techniques can identify usability problems which are more or less comparable in terms of quantity and quality. As for efficiency, MGUT and DGUT are more efficient than CE as these group testing approaches require lesser testing time, lesser effort in terms of the intensive interaction with participants although with slight more effort in the preparation of the physical setting. In addition, it is also obvious that MGUT and DGUT involve richer participation than CE. MGUT is also more feasible than DGUT as it allows some flexibility in the computer arrangement setting.
C1 [Chen, Chwen Jen; Lau, Siew Yung; Teh, Chee Siong] Univ Malaysia Sarawak, Fac Cognit Sci & Human Dev, Kota Samarahan 94300, Malaysia.
C3 University of Malaysia Sarawak
RP Chen, CJ (corresponding author), Univ Malaysia Sarawak, Fac Cognit Sci & Human Dev, Kota Samarahan 94300, Malaysia.
EM cjchen@fcs.unimas.my
OI TEH, Chee Siong/0000-0003-2474-5958
CR [Anonymous], 2002, COMPLEMENTARITY CONV, DOI DOI 10.1145/572020.572030
   Ardito C., 2006, Universal Access in the Information Society, V4, P270, DOI 10.1007/s10209-005-0008-6
   Bach C, 2010, INT J HUM-COMPUT INT, V26, P786, DOI 10.1080/10447318.2010.487195
   Barnum C.M., 2002, Usability testing and research
   Bowman DA, 2002, PRESENCE-TELEOP VIRT, V11, P404, DOI 10.1162/105474602760204309
   Bricken M., 1993, Virtual Reality: Applications and Explorations, P178
   Costalli F., 2001, P INT CULT HER INF M, P413
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Dearden A., 2004, Information and communication technologies in tourism 2004, the 11th ENTER International Conference in Cairo, Egypt, 2004, P172
   Deegan R., 2010, Journal of the Research Center for Education Technology (RCET), V6, P16
   Doubleday A., 1997, Symposium on Designing Interactive Systems: Processes, Practices, Methods and Techniques (ACM DIS), P101, DOI [10.1108/14678040810869422, DOI 10.1108/14678040810869422]
   Doubleday EG, 2011, ANAT SCI EDUC, V4, P318, DOI 10.1002/ase.252
   Downey LL., 2007, J USABILITY STUDIES, V2, P133
   Dumas J.F., 1993, A Practical Guide To Usability Testing
   Eklund T, 2008, P 19 AUSTR C INF SYS
   Faulkner L, 2003, BEHAV RES METH INS C, V35, P379, DOI 10.3758/BF03195514
   Ferk V, 2003, INT J SCI EDUC, V25, P1227, DOI 10.1080/0950069022000038231
   Forsslund Jonas, 2009, 2009 World Haptics Conference (WHC 2009), P391, DOI 10.1109/WHC.2009.4810916
   Freiberg C, 2005, P 2005 4 ASEE AAEE G
   GAGNE RM, 1990, ETR&D-EDUC TECH RES, V38, P23, DOI 10.1007/BF02298245
   Jeffries R., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P119, DOI 10.1145/108844.108862
   Kalawsky R., 1993, SCI VIRTUAL REALITY
   KONTIO J, 2004, P 2004 INT S EMP SOF
   Lim TY, 1999, P U SO MISS COMP SCI
   MARSH T, 1999, P WORKSH US CENTR DE, P99
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Monk A., 1993, IMPROVING YOUR HUMAN
   Morar S. S., 2004, Virtual Reality, V7, P129, DOI 10.1007/s10055-004-0135-z
   Nielsen J, 1997, IEEE SOFTWARE, V14, P94, DOI 10.1109/52.566434
   Nielsen J., 1995, SEVERITY RATINGS USA
   Ouyang X, 2004, COMPUT ENG, V2
   Rezazadeh IM., 2011, Dans Mixed Reality and Human-Robot Interaction, P95
   Rosli D.I., 2008, P 5 INT C INF TECHN
   Schwebel DC, 2013, VIRTUAL REALITY, V18, P1
   Seffah A, 2006, SOFTWARE QUAL J, V14, P159, DOI 10.1007/s11219-006-7600-8
   Smith S. P., 2007, P 4 INTUITION INT C, P102
   Smith SP, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P3, DOI 10.1109/TRIDUI.2006.1618263
   Squires D, 1999, INTERACT COMPUT, V11, P467, DOI 10.1016/S0953-5438(98)00063-0
   Stanney KM, 2003, INT J HUM-COMPUT ST, V58, P447, DOI 10.1016/S1071-5819(03)00015-6
   Stevens R., 1994, Computers for Handicapped Persons. 4th International Conference, ICCHP '94 Proceedings, P313
   Sutcliffe A, 2002, USER CTR REQUIREMENT
   Tang JC, 2006, P CSCW 06 BANFF ALB
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   Villanueva R., 2004, 16 ANN C SPAT INF RE
   Woolrych A., 2001, 15th Annual Conference of the Human-Computer Interaction Group of the British Computer Society. IHM-HCI 2001, P105
   Yoon SY, 2008, INT J HUM-COMPUT INT, V24, P288, DOI 10.1080/10447310801920516
   Youngblut C., 1998, IDAD2128
NR 47
TC 6
Z9 7
U1 0
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2015
VL 19
IS 2
BP 129
EP 144
DI 10.1007/s10055-015-0263-7
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA CJ9MO
UT WOS:000355826700006
OA Green Published
DA 2024-07-18
ER

PT J
AU Pilet, J
   Saito, H
AF Pilet, Julien
   Saito, Hideo
TI Dynamic learning, retrieval, and tracking to augment hundreds of
   photographs
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Multiple object tracking; Image retrieval
AB Tracking is a major issue of virtual and augmented reality applications. Single object tracking on monocular video streams is fairly well understood. However, when it comes to multiple objects, existing methods lack scalability and can recognize only a limited number of objects. Thanks to recent progress in feature matching, state-of-the-art image retrieval techniques can deal with millions of images. However, these methods do not focus on real-time video processing and cannot track retrieved objects. In this paper, we present a method that combines the speed and accuracy of tracking with the scalability of image retrieval. At the heart of our approach is a bi-layer clustering process that allows our system to index and retrieve objects based on tracks of features, thereby effectively summarizing the information available on multiple video frames. Dynamic learning of new viewpoints as the camera moves naturally yields the kind of robustness and reliability expected from an augmented reality engine. As a result, our system is able to track in real-time multiple objects, recognized with low delay from a database of more than 300 entries. We released the source code of our system in a package called Polyora.
C1 [Pilet, Julien; Saito, Hideo] Keio Univ, Kohoku Ku, Yokohama, Kanagawa 2238522, Japan.
C3 Keio University
RP Pilet, J (corresponding author), Keio Univ, Kohoku Ku, 3-14-1 Hiyoshi, Yokohama, Kanagawa 2238522, Japan.
EM julien.pilet@gmail.com; saito@hvrl.ics.keio.ac.jp
RI Saito, Hideo/D-6223-2014
OI Saito, Hideo/0000-0002-2421-9862
CR [Anonymous], 2006, P 9 EUR C COMP VIS 1
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2006, EUR C COMP VIS
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], C COMP VIS PATT REC
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   C Wu, 2008, GPU IMPLEMENTATION D
   Fiala M, 2005, PROC CVPR IEEE, P590
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Harris C. G., 1988, 4 ALV VIS C MANCH
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Nister D, 2006, EUR C COMP VIS GRAZ
   Obdrzalek S., 2005, BRIT MACH VIS C
   OZUYSAL M, 2006, EUR C COMP VIS GRAZ
   Park Y, 2008, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR.2008.4637336
   PHILBIN J, 2008, C COMP VIS PATT REC
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Uchiyama H, 2009, INT SYM MIX AUGMENT, P95, DOI 10.1109/ISMAR.2009.5336491
   Wagner D., 2008, INT S MIX AUGM REAL
   Wagner D., 2009, INT S MIX AUGM REAL
NR 26
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2014
VL 18
IS 2
BP 89
EP 100
DI 10.1007/s10055-013-0228-7
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AN5HV
UT WOS:000340622300001
DA 2024-07-18
ER

PT J
AU Okamoto, K
   Kume, N
   Tokunaga, T
   Tanaka, Y
   Terasawa, N
   Tsukasa, T
   Takemura, T
   Yoshihara, H
AF Okamoto, Kazuya
   Kume, Naoto
   Tokunaga, Tatsuya
   Tanaka, Yoko
   Terasawa, Noriaki
   Tsukasa, Takashi
   Takemura, Tadamasa
   Yoshihara, Hiroyuki
TI Augmented reality-based block piling game with superimposed collapse
   prediction
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Block collapse; Linear program; Overhang problem;
   Physical simulation
AB Understanding what cannot be seen is difficult. Physical behavior can be explained on the basis of physical theories even if the behavior cannot be observed. Explanation of what is physically happening in the real world would become easy, however, if annotations were superimposed on the real objects. Herein, the authors demonstrate how an understanding of a physical event can be facilitated by overlapping a real-world situation with a simulation that predicts a future state. This idea is demonstrated in a game application in which a player stacks blocks into a pile until it collapses. In general, it is easy to estimate whether a block on the edge of a table will fall or not. However, it is more difficult to predict whether a stack of many blocks will collapse, and in what manner the stack will collapse. Even though previous research has demonstrated that the problem of how two-dimensionally stacked blocks collapse can be reduced to solving a sequence of convex quadratic programs, algorithms for convex quadratic programs require massive computational resources. Hence, the authors developed a fast and new algorithm based on a linear program. The proposed algorithm realizes real-time simulation based on physics that superimposes predicted collapse. The block that is predicted to fall is superimposed on the real block with a lit background projection. The system was evaluated in an experiment, and superimposed augmented reality annotation was observed to be efficient. The system was also demonstrated in game contests and received positive feedback and comments.
C1 [Okamoto, Kazuya; Kume, Naoto; Takemura, Tadamasa; Yoshihara, Hiroyuki] Kyoto Univ Hosp, Dept Med Informat, Kyoto 606, Japan.
   [Okamoto, Kazuya; Kume, Naoto; Tokunaga, Tatsuya; Tanaka, Yoko; Terasawa, Noriaki; Tsukasa, Takashi; Takemura, Tadamasa; Yoshihara, Hiroyuki] Kyoto Univ, Grad Sch Informat, Kyoto, Japan.
C3 Kyoto University; Kyoto University
RP Okamoto, K (corresponding author), Kyoto Univ Hosp, Dept Med Informat, Kyoto 606, Japan.
EM kazuya@kuhp.kyoto-u.ac.jp; kume@kuhp.kyoto-u.ac.jp;
   tokunaga@kuhp.kyoto-u.ac.jp; tanaka@kuhp.kyoto-u.ac.jp;
   terasawa@kuhp.kyoto-u.ac.jp; ttsukasa@kuhp.kyoto-u.ac.jp;
   takemura@kuhp.kyoto-u.ac.jp; lob@kuhp.kyoto-u.ac.jp
FU Grants-in-Aid for Scientific Research [24700248] Funding Source: KAKEN
CR Ainley S, 1979, MATH GAZ, V63, P272, DOI DOI 10.2307/3618049
   Bender J, 2006, P 3 VIRT REAL INT PH
   Jebara T, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P138, DOI 10.1109/ISWC.1997.629930
   Kaufmann H., 2008, ACM SIGGRAPH ASIA 20, P1, DOI [DOI 10.1145/1507713.1507717, 10.1145/1507713.1507717]
   Matysczok C., 2004, 2004 ACM SIGCHI International Conference on Advances in Computer Entertainment Technology, P269
   MONTEIRO RDC, 1989, MATH PROGRAM, V44, P43, DOI 10.1007/BF01587076
   Okamoto K, 2009, P VRIC 09, P375
   Paterson M, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P231
   Paterson M, 2009, AM MATH MON, V116, P19, DOI 10.4169/193009709X469797
   Phear J.B., 1850, ELEMENTARY MECH
   ROSATO A, 1987, PHYS REV LETT, V58, P1038, DOI 10.1103/PhysRevLett.58.1038
   Rote G, 2011, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P603
   Shih C, 2009, OPT ENG, V48, DOI 10.1117/1.3083379
   Shinar Tamar., 2008, P 2008 ACM SIGGRAPH, P95
   Shinbrot T, 2004, NATURE, V429, P352, DOI 10.1038/429352b
   Walton W., 1855, COLLECTION PROBLEMS
NR 16
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2013
VL 17
IS 4
BP 279
EP 292
DI 10.1007/s10055-012-0219-0
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 239BT
UT WOS:000325997200003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lincoln, P
   Welch, G
   Nashel, A
   State, A
   Ilie, A
   Fuchs, H
AF Lincoln, Peter
   Welch, Greg
   Nashel, Andrew
   State, Andrei
   Ilie, Adrian
   Fuchs, Henry
TI Animatronic shader lamps avatars
SO VIRTUAL REALITY
LA English
DT Article
DE Telepresence; Avatar; Shader lamps; Teleconferencing; Conferencing;
   Animatronic
ID HEAD
AB Applications such as telepresence and training involve the display of real or synthetic humans to multiple viewers. When attempting to render the humans with conventional displays, non-verbal cues such as head pose, gaze direction, body posture, and facial expression are difficult to convey correctly to all viewers. In addition, a framed image of a human conveys only a limited physical sense of presence-primarily through the display's location. While progress continues on articulated robots that mimic humans, the focus has been on the motion and behavior of the robots rather than on their appearance. We introduce a new approach for robotic avatars of real people: the use of cameras and projectors to capture and map both the dynamic motion and the appearance of a real person onto a humanoid animatronic model. We call these devices animatronic Shader Lamps Avatars (SLA). We present a proof-of-concept prototype comprised of a camera, a tracking system, a digital projector, and a life-sized styrofoam head mounted on a pan-tilt unit. The system captures imagery of a moving, talking user and maps the appearance and motion onto the animatronic SLA, delivering a dynamic, real-time representation of the user to multiple viewers.
C1 [Lincoln, Peter; Welch, Greg; Nashel, Andrew; State, Andrei; Ilie, Adrian; Fuchs, Henry] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27515 USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Lincoln, P (corresponding author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27515 USA.
EM plincoln@cs.unc.edu; welch@cs.unc.edu; nashel@cs.unc.edu;
   andrei@cs.unc.edu; adyilie@cs.unc.edu; fuchs@cs.unc.edu
OI Welch, Gregory/0000-0002-8243-646X
FU Office of Naval Research [N00014-09-1-0813]
FX We thank Herman Towles for his insightful suggestions and technical help
   and advice. John Thomas provided mechanical and electronic engineering
   assistance. David Harrison set up our full-duplex audio subsystem.
   Dorothy Turner became our first non-author SLA user (Fig. 5, bottom half
   of image set). Tao Li helped set up the ISMAR demonstration. Donna Boggs
   modeled as the Avatar's interlocutor (Fig. 2). We thank Chris Macedonia,
   M. D. for inspiring us by expressing his desire to visit his patients in
   remote hospitals and other medical facilities with a greater
   effectiveness than is possible with current remote presence systems, and
   for offering the term "prosthetic presence." We are grateful to Brian
   Bradley for his appearance as a prosthetic physician at our ISMAR 2009
   booth, and we thank all ISMAR participants who visited our booth and
   engaged both the Avatar and the researchers with questions and
   suggestions. Partial funding for this work was provided by the Office of
   Naval Research (award N00014-09-1-0813, "3D Display and Capture of
   Humans for Live-Virtual Training," Dr. Roy Stripling, Program Manager).
CR Ahlberg J, 2003, INT J IMAG SYST TECH, V13, P8, DOI 10.1002/ima.10042
   AIST (National Institute of Advanced Industrial Science and Technology), 2009, SUCC DEV ROB APP PER
   [Anonymous], CHI 2004
   Argyle M., 1976, Gaze and Mutual Gaze
   Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Criminisi A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P191
   EPSTEIN R, 2006, SCI AM MIND      JUN, P68
   Hietanen JK, 1999, NEUROREPORT, V10, P3443, DOI 10.1097/00001756-199911080-00033
   *HOND MOT CO LTD, 2009, HOND WORLDW ASIMO
   Huang T.S., 2001, Proc. Picture Coding Symposium, P57
   ILIE A, 2009, CAMERA PROJECTOR CAL
   JONES A, 2009, SIGGRAPH 09, P1
   Jones A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276427
   KERSE D, 2005, P 2005 INT C AUGM TE, P240
   LINCOLN P, 2009, MULTIVIEW LENTICULAR
   *LOOXIS GMBH, 2009, FACEWORX
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]
   Nguyen D, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1465
   Paulos E, 2001, AUTON ROBOT, V11, P87, DOI 10.1023/A:1011264330469
   Raskar R., 1999, IWAR 99, P64
   RASKAR R, 2001, EUR WORKSH REND
   SCHREER O, 2008, CVMP 2008, P1
   *SEEING MACH, 2009, FACEAPI
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   STATE A, 2007, ICCV HCI, P138
   Tachi S., 2004, INT J HR, V1, P45
   *TAK LAB, 2009, VAR FAC SHAP EXPR RO
   *WIK, 2010, CISC TEL
   WOODWORTH C, 1993, GLOB TEL C 1993 INCL, V1, P399
   Yotsukura T, 2002, VISUAL COMPUT, V18, P111, DOI 10.1007/s003710100140
NR 30
TC 13
Z9 15
U1 0
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 225
EP 238
DI 10.1007/s10055-010-0175-5
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200012
DA 2024-07-18
ER

PT B
AU Basori, AH
   Bade, A
   Sunar, MS
   Daman, D
AF Basori, Ahmad Hoirul
   Bade, Abdullah
   Sunar, Mohd. Shahrizal
   Daman, Daut
BE Kim, JJ
TI Face-Touch: An Emotional Facial Expression Technique of Avatar Based on
   Tactile Vibration in Virtual Reality Game
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
C1 [Basori, Ahmad Hoirul; Bade, Abdullah; Sunar, Mohd. Shahrizal; Daman, Daut] Univ Malaysia Sabah, Univ Teknol Malaysia, Kota Kinabalu, Malaysia.
C3 Universiti Malaysia Sabah; Universiti Teknologi Malaysia
RP Basori, AH (corresponding author), Univ Malaysia Sabah, Univ Teknol Malaysia, Kota Kinabalu, Malaysia.
RI Basori, Ahmad Hoirul/F-5778-2011; Sunar, Mohd Shahrizal/AFQ-7366-2022
OI Basori, Ahmad Hoirul/0000-0001-9684-490X; Sunar, Mohd
   Shahrizal/0000-0002-0244-1622
CR ANDR E., 2009, P 13 INT C INT US IN
   [Anonymous], 2008, IEEE PAC VIS S 4 7 M
   [Anonymous], P 7 ACM SIGGRAPH INT
   Bailenson JN, 2007, HUM-COMPUT INTERACT, V22, P325
   BALCi K., 2007, MM 07 SEP 23 28 2007
   Bänziger T, 2005, SPEECH COMMUN, V46, P252, DOI 10.1016/j.specom.2005.02.016
   Camurri A, 2003, INT J HUM-COMPUT ST, V59, P213, DOI 10.1016/S1071-5819(03)00050-8
   DAI K., 2009, P 27 INT EXT ABSTR H
   Ekman P, 1982, EMOTION HUMAN FACE C
   FABRI M., 1999, P INT C GEST WORKSH
   FARBENLEHRE J. W. V. G. Z., 1808, SECHSTE ABTEILUNG SI
   Griffin MJ., 1990, Handbook of Human Vibration
   HASHIMOTO Y, 2008, ACM SIGGRAPH 2008 NE
   McCraty R., 1993, PROC 3 ANN C INTERNA
   MELO C., 2007, P 2 INT C AFF COMP I
   MELO C. M. D., 2009, INT C AFF COMP INT I
   Nasoz F., 2003, International Journal of Cognition, Technology, and Work, V6, P1, DOI [10.1007/s10111-003-0143-x, DOI 10.1007/S10111-003-0143-X]
   Nijdam N., 2006, MAPPING EMOTION COLO
   NIKOLAUS B., 2009, P 13 INT C INT US IN
   OBORNE DJ, 1974, ERGONOMICS, V17, P769, DOI 10.1080/00140137408931423
   OGRE, 2010, OP SOURC 3D GGRPH EN
   ROJAS A. G., 2006, P 4 INT C COMP GRAPH
   ROLLIN MCCRATY M. A., 1995, AM J CARDIOL, V76, P1089
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Shan MK, 2009, EXPERT SYST APPL, V36, P7666, DOI 10.1016/j.eswa.2008.09.042
   SUCONTPHUNT T., 2008, NOVEL VISUALIZATION
   THALMANN D., 2008, P 7 INT JOINT C AUT, V1
   WANG Z., 2005, CONSTRUCTION VIRTUAL
   Zagalo N, 2008, VISUAL COMPUT, V24, P981, DOI 10.1007/s00371-008-0272-6
NR 29
TC 2
Z9 2
U1 0
U2 2
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 107
EP 126
D2 10.5772/553
PG 20
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400007
DA 2024-07-18
ER

PT B
AU Zhou, KP
   Guo, MM
AF Zhou, Keping
   Guo, Mingming
BE Kim, JJ
TI Virtual Reality Simulation System for Underground Mining Project
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
C1 [Zhou, Keping; Guo, Mingming] Cent S Univ, Changsha, Peoples R China.
C3 Central South University
RP Zhou, KP (corresponding author), Cent S Univ, Changsha, Peoples R China.
CR Akenine-Moller Tomas, 2004, REAL TIME COMPUTER G
   [Anonymous], VIRTUAL REALITY ITS
   [Anonymous], 2005, VEG LYNX US GUID VER
   Burdea Grigore C., 2005, VIRTUAL REALITY TECH
   Cao ChuanFen, 2004, STUDY 3 DIMENSIONAL
   Chen Wei, 2007, NONFERROUS METALS, V59, P22
   Cullen ET, 2006, NIOSH INFORM CIRCULA, V9484, P14
   Fang Zhiheng, 2008, CHINA MOLYBDENUM IND, P136
   Foster PJ, 2006, T I MIN METALL A, V115, P85, DOI 10.1179/174328606X128714
   Foster P., 2004, J S AFR I MIN METALL, V3, P129
   FreeSouth, 2008, OPENSCENEGRAPH PROGR
   FU YM, 2004, MODERN SURVEYING MAP, V27, P11
   Gao Wenshu, 2008, LAND RESOURCE, V32, P28
   Gao Zhiwu, 2004, METAL MINE, V1, P287
   Gillies A.D.S, 2005, ARCH MINING SCI, V50
   Gu Desheng, 2006, MODERN METAL DEPOSIT
   Guan Wei, 2007, J SYSTEM SIMULATION, V19, P4164
   Guo MM, 2009, ICCSSE 2009: PROCEEDINGS OF 2009 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION, P1013, DOI 10.1109/ICCSE.2009.5228457
   HOLLAND R, 1999, GOLDEN COMPUTER APPL, P787
   Hou Xiang, 2006, RES VISUAL REALITY 3
   Hua Zhen, 2004, COAL SCI TECHNOLOGY, V32, P44
   Hua Zhen, 2003, METAL MINE, V325, P53
   Jia Huizhu, 2002, RES IMPLEMENTATION V, P22
   Jia Huizhu, 2002, RES REALIZATION 3 DI
   KIZIL M.S, 2001, P AUSTR I MIN MET YO, V2, P9
   Kizil M. S., 2003, VIRTUAL REALITY APPL
   Li Jian-zhong, 2007, Journal of System Simulation, V19, P4164
   Li JianZhong, 2002, COAL, V11, P33
   Li Lijun, 2006, COMPUTER ENG DESIGN, V27, P3604
   [李青 Li Qing], 2002, [中国矿业大学学报. 自然科学版, Journal of China University of Mining & Technology], V31, P27
   Li Qing Han, 2002, J CHINA U MINING TEC, V1, P27
   Liu Hongyu, 2005, APPL RES VIRTUAL REA
   Liu Huanming, 2005, RES TECHNOLOGY LEVEL
   Liu Xiaoming, 2007, RES APPL RELEVANCE T
   Liu Xiaoyan, 2003, VIRTUAL CITY CONSTRU
   Lu Hao, 2007, CHINA TUNGSTEN IND, V22, P22
   LUO Z, 2006, METAL MINE, V358, P33
   [毛善君 Mao Shanjun], 2005, [煤炭学报, Journal of China Coal Society], V30, P571
   Paul Martz, 2008, OPENSCENEGRAPH QUICK
   Rao Hongliang, 2004, STUDY IMPLEMENT OPEN
   Ruiling Wang, 2007, COMPUTER APPL SOFTWA, V24, P123
   Seng Dengwen, 2005, J ZHEJIANG WAT CONS, V19, P63
   [尚建嘎 Shang Jiange], 2003, [计算机工程, Computer Engineering], V29, P61
   [申闫春 SHEN Yanchun], 2007, [计算机仿真, Computer simulation], V24, P207
   SHERMAN WR, 2004, UNDERSTANDING VIRTUA
   Song Shucai, 2005, FU JIAN COMPUTER, V5, P39
   Squelch A.P., 2001, J S AFR I MIN METALL, V7, P209
   Tao Songlin, 1995, DRILLING BLASTING
   Wan Gang, 2001, J SYSTEM SIMULATION, V13, P73
   Wang Deyong, 2006, COAL MINE MACH, V27, P172
   Wang Ruiling, 2006, COMPUTER APPL SOFTWA, V18, P427
   Wang Yongtao, 2008, RESERCH REALIZATION
   Wang Yongtian, 2006, TECHNOL REV, V24, P36
   Wei Jing, 2008, RES VIRTUAL MINING S
   Wei Zeng, 2005, DELAUNAY TRIANGULATI
   Wen Zhuanping, 2009, COMPUTER TECHNOLOGY, V9, P217
   Wu Di, 2002, HYDROGRAPHIC SURVEYI, V22, P15
   [吴立新 Wu Lixin], 2002, [测绘学报, Acta Geodetica et Cartographica Sinica], V31, P28
   Wu Lixin, 2008, GEOMATICS WORLD, V10, P6
   WU Q, 2002, SYSTEM SIMULATION VI
   Xu Ling, 2008, RES IMPLEMENTATION R
   Xu M., 2003, RES MULTIRESOLUTION
   Yang Shixing, 2007, STEP OPENSCENEGRAPH
   Yu Yan, 2006, EXPRESS INFORM MININ, V442, P31
   Zeng Qintian, 2007, STUDY POLY METALLIC
   Zhang Ruixin, 1998, J CHINA U MINE TECHN, V27, P230
   ZHANG ZY, 2008, COMPUTER SIMULATION, V25, P252
   Zhao Fezhi, 2006, COMPUTER SYSTEM APPL, V11, P6
   [赵建忠 Zhao Jianzhong], 2003, [太原理工大学学报, Journal of taiyuan university of technology], V34, P39
   Zhao Jianzhong, 2006, J SYSTEM SIMULATION, V8, P274
   Zhao Jianzhong, 2007, J SYSTEM SIMULATION, V9, P4164
   [钟慧娟 ZHONG Huijuan], 2008, [计算机仿真, Computer Simulation], V25, P252
   Zhou Ke-ping, 2008, Journal of Central South University (Science and Technology), V39, P417
   Zhou Keping, 2008, COMPUTER SYSTEM APPL, V17, P6
   Zhou Zhi-yong, 2008, Journal of Central South University (Science and Technology), V39, P423
   Zhou Zhiyong, 2004, MINING ENG, V2, P31
NR 76
TC 0
Z9 0
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 615
EP 632
D2 10.5772/553
PG 18
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400031
DA 2024-07-18
ER

PT J
AU Wahlström, M
   Aittala, M
   Kotilainen, H
   Yli-Karhu, T
   Porkka, J
   Nykänen, E
AF Wahlstrom, Mikael
   Aittala, Miika
   Kotilainen, Helina
   Yli-Karhu, Tiina
   Porkka, Janne
   Nykanen, Esa
TI CAVE for collaborative patient room design: analysis with end-user
   opinion contrasting method
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; CAVE; Patient room design; End-user participation;
   Collaborative design
ID VIRTUAL ENVIRONMENT; EXPERIENCE
AB Several studies indicate that virtual reality (VR) systems are useful for end-user participation in an environmental design process. However, these systems can be costly and thus support for the decision whether to invest in a VR of some type is useful. This study presents a novel method for analysing the usefulness of a VR system for the purpose of end-user participation. We collected qualitative end-user opinion data in the real environment and then contrasted this data with the capabilities of a VR system. Additionally, to better understand the capabilities of the VR used, we examined how the end-users perceive the used virtual environment, which in this case was CAVE, an immersive VR system where projectors are directed to the walls of a room-sized cube. In this way, we analysed whether the same functions and elements identified by end-users on the actual wards could also be evaluated in the CAVE. Eleven nurses and 11 patients participated in the study by evaluating a bathroom and/or four patient rooms modelled by the CAVE and the actual hospital wards. The CAVE was convenient for evaluating most issues identified by the study participants in the actual hospital wards, i.e. aesthetics; correct location of equipment, supplies and materials; distraction by or the good companion of other patients as well as window position and size and living/workspace. However, it was not possible to evaluate with full certainty the possibilities for bracing against grab bars or other objects in the VR, and this was found to be relevant to the independent functioning of patients with limited mobility. Also, due to the relatively low luminance levels of projectors, evaluations regarding lighting were considered unreliable. Moreover, end-users were not always certain about the sizes and sufficiency of space in the CAVE. Solutions to overcome these limitations were proposed.
C1 [Yli-Karhu, Tiina] Seinajoki Cent Hosp, Seinajoki, Finland.
   [Aittala, Miika; Porkka, Janne; Nykanen, Esa] VTT Tech Res Ctr Finland, Espoo, Finland.
   [Wahlstrom, Mikael; Kotilainen, Helina] Natl Res & Dev Ctr Welf & Hlth STAKES, Helsinki, Finland.
C3 Seinajoki Central Hospital; VTT Technical Research Center Finland;
   Finland National Institute for Health & Welfare
RP Wahlström, M (corresponding author), Neljas Linja 16 17, Helsinki 00530, Finland.
EM mikael.wahlstrom@hiit.fi
OI Wahlstrom, Mikael/0000-0002-7753-2588; Porkka, Janne/0000-0003-3557-6010
FU hospital district of Southwest Finland; hospital district of South
   Ostrobothnia; Abloy Oy; Vaino Korpinen Ltd; Poyry CM Oy; STAKES
   (currently known as National Institute for Health and Welfare THL); VTT;
   Finnish Funding Agency for Technology and Innovation (Tekes)
FX This work was supported by the hospital districts of Southwest Finland
   and South Ostrobothnia, and by Abloy Oy, Vaino Korpinen Ltd, Poyry CM
   Oy, STAKES (currently known as National Institute for Health and Welfare
   THL), VTT and the Finn-Well programme of the Finnish Funding Agency for
   Technology and Innovation (Tekes). The CAVE (R) and CAVElibTM are
   registered trademarks of the Board of Trustees of the University of
   Illinois. Many thanks to Ulla Idanpaan-Heikkila for valuable comments
   and to Outi Raikkonen for extensively collecting relevant evidence-based
   design and nursing science literature and thus helping with the
   literature review that preceded planning and execution of this study.
   One of the authors, Janne Porkka, is doctoral candidate in Helsinki
   University of Technology.
CR Al-Kodmany K, 1999, LANDSCAPE URBAN PLAN, V45, P37, DOI 10.1016/S0169-2046(99)00024-9
   [Anonymous], 2006, Working Together for Health
   Benedetti F, 2007, NEUROSCIENCE, V147, P260, DOI 10.1016/j.neuroscience.2007.02.020
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   CRUZNEIRA C, 1993, 93 P 20 ANN C COMP G
   Douglas CH, 2005, HEALTH EXPECT, V8, P264, DOI 10.1111/j.1369-7625.2005.00336.x
   Douglas CH, 2004, HEALTH EXPECT, V7, P61, DOI 10.1046/j.1369-6513.2003.00251.x
   Drettakis G, 2007, PRESENCE-VIRTUAL AUG, V16, P318, DOI 10.1162/pres.16.3.318
   Dunston PS., 2007, 7 INT C CONSTR APPL
   FROST P, 2000, P INT C INF VIS
   Hakkinen J., 2006, P 8 C HUM COMP INT M
   Heldal Ilona, 2007, Virtual Reality, V11, P145, DOI 10.1007/s10055-006-0061-3
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Majumdar T., 2006, P JOINT INT C COMP D
   Mobach Mark P., 2008, Virtual Reality, V12, P163, DOI 10.1007/s10055-008-0081-2
   Seron F. J., 2004, Virtual Reality, V7, P82, DOI 10.1007/s10055-003-0117-6
   SPENCE G, 1995, P 22 ANN C COMP GRAP
   Ulrich R.S., 2004, CTR HLTH DESIGN
   WALL S, 2006, VIRTUAL REALITY, V9, P95
   Westerdahl B, 2006, AUTOMAT CONSTR, V15, P150, DOI 10.1016/j.autcon.2005.02.010
NR 20
TC 13
Z9 15
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2010
VL 14
IS 3
BP 197
EP 211
DI 10.1007/s10055-009-0138-x
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HW
UT WOS:000296279700003
DA 2024-07-18
ER

PT J
AU Martín, S
   Suárez, J
   Orea, R
   Rubio, R
   Gallego, R
AF Martin, S.
   Suarez, J.
   Orea, R.
   Rubio, R.
   Gallego, R.
TI GLSV: Graphics library stereo vision for OpenGL
SO VIRTUAL REALITY
LA English
DT Article
DE Software libraries; Display algorithms; Stereoscopic; Virtual reality
AB This work proposes the development of an auxiliary library for use with OpenGL, to facilitate the creation of graphic applications incorporating stereoscopic representation. This library, christened graphics library stereo vision (GLSV), is designed to remove all calculations involving knowledge of stereo vision theory from the task performed by the programmer without the latter having to change the way he/she has been working with the OpenGL library. The GLSV is distributed under the terms of the GNU Library General Public License agreement.
C1 [Martin, S.; Suarez, J.; Orea, R.; Rubio, R.; Gallego, R.] Univ Oviedo, Univ Sch Ind Tech Engn, Res Grp I3G, Oviedo, Spain.
C3 University of Oviedo
RP Martín, S (corresponding author), Univ Oviedo, Univ Sch Ind Tech Engn, Res Grp I3G, Oviedo, Spain.
EM martinsantiago@uniovi.es
RI Rubio-Garcia, Ramon/B-5283-2008; Gonzalez, Santiago Martin/C-4300-2008
OI Rubio-Garcia, Ramon/0000-0003-2033-529X; Gonzalez, Santiago
   Martin/0000-0002-5912-1400
FU Anade Recursos Naturales, S.L. company [CN-04-098, FUO-EM-090-05]
FX The work of the I<SUP>3</SUP>G group in the area of stereo graphics has
   been co-financed by the Anade Recursos Naturales, S.L. company, in the
   framework of University, Company projects (CN-04-098 and FUO-EM-090-05).
CR AKKA B, 1998, WRITING STEREOSCOPIC
   Bourke P., 1999, Calculating stereo pairs
   Carrozzo M, 1997, COMPUT GRAPH-UK, V21, P329, DOI 10.1016/S0097-8493(97)00010-1
   Foley JamesD., 1997, COMPUTER GRAPHICS PR
   Hodges LarryF., 1993, Presence: Teleoperators Virtual Environments, V2, P34, DOI 10.1162/pres.1993.2.1.34
   Lipton L., 1997, STEREOGRAPHICS DEV H
   Lipton L, 1997, STEREO VISION FORMAT
   *OPENGL ARCH REV B, 1997, OPENGL PROGR GUID V
   SOUTHARD DA, 1992, COMPUT GRAPH, V16, P401, DOI 10.1016/0097-8493(92)90027-S
   *STEREOGRAPHICS CO, 1999, HARDW DEV HDB
NR 10
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2009
VL 13
IS 1
BP 51
EP 57
DI 10.1007/s10055-008-0105-y
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XC
UT WOS:000208104100007
DA 2024-07-18
ER

PT J
AU Hussain, H
   Faisal, CMN
   Habib, MA
   Gonzalez-Rodriguez, M
   Fernandez-Lanvin, D
   De Andres, J
AF Hussain, Humael
   Faisal, C. M. Nadeem
   Habib, Muhammad Asif
   Gonzalez-Rodriguez, Martin
   Fernandez-Lanvin, Daniel
   De Andres, Javier
TI ARLexic game: an augmented reality-based serious game for training of
   dyslexic and dysgraphic children
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Dysgraphia; Dyslexia; Self-determination theory;
   Serious game
ID DESIGN
AB Over the years, researchers have discovered increased problems among children related to reading and writing. Dyslexia and Dysgraphia are the most common problems they try to solve with various paper-based activities and gaming interventions. But they either lack interactivity, and children get bored of the games after some time, or therapists and parents cannot learn about their children's performance. Augmented Reality is nowadays evolving technology in the field of education. Although some Augmented Reality applications have developed in the market, there is no feasible solution for children suffering from Dyslexia and Dysgraphia. In this paper, we developed an Augmented Reality-based Serious Game named ARLexic game to train children with Dyslexia and Dysgraphia. We performed an experiment with dyslexic and dysgraphic children aged from 7 to 14 years, along with their teachers, to evaluate their performance. Our study results show that ARLexic Game is an entertaining and easy-to-use game for children. Children also engage with the application for a longer time due to Augmented Reality.
C1 [Hussain, Humael; Faisal, C. M. Nadeem; Habib, Muhammad Asif] Natl Text Univ NTU, Dept Comp Sci, Faisalabad, Pakistan.
   [Gonzalez-Rodriguez, Martin; Fernandez-Lanvin, Daniel] Univ Oviedo, Dept Comp, Oviedo, Spain.
   [Habib, Muhammad Asif] Johannes Kepler Univ Linz, Inst Networks & Secur, A-4040 Linz, Austria.
   [De Andres, Javier] Univ Oviedo, Dept Accounting, Oviedo, Spain.
C3 University of Oviedo; Johannes Kepler University Linz; University of
   Oviedo
RP Hussain, H (corresponding author), Natl Text Univ NTU, Dept Comp Sci, Faisalabad, Pakistan.
EM humaelh888@gmail.com; nadeem.faisal@ntu.edu.pk; drasif@ntu.edu.pk;
   martin@uniovi.es; dflanvin@uniovi.es; jdandres@uniovi.es
RI Lanvin, Daniel Fernández/L-5470-2014; De Andrés, Javier/K-5387-2014;
   Gonzalez-Rodriguez, Martin/H-1768-2014
OI De Andrés, Javier/0000-0001-6887-4087; Faisal, Chaudhry Muhammad
   Nadeem/0000-0001-8781-4143; Gonzalez-Rodriguez,
   Martin/0000-0002-9695-3919; Hussain, Humael/0000-0003-0491-2544
FU This work was partially funded by the Department of Science, Innovation,
   and Universities (Spain) under the National Program for Research,
   Development, and Innovation (project RTI2018-099235-B-I00).
   [RTI2018-099235-B-I00]; Department of Science, Innovation, and
   Universities (Spain) under the National Program for Research,
   Development, and Innovation
FX This work was partially funded by the Department of Science, Innovation,
   and Universities (Spain) under the National Program for Research,
   Development, and Innovation (project RTI2018-099235-B-I00).
CR Abid M, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P544, DOI 10.1145/3311927.3325311
   Aborokbah Majed, 2021, International Journal of Cloud Computing, V10, P17, DOI 10.1504/IJCC.2021.113972
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   Aravena S, 2013, J EXP CHILD PSYCHOL, V115, P691, DOI 10.1016/j.jecp.2013.03.009
   Benmarrakchi F., 2019, INT J INF SCI TECHNO, V3, P4
   Bhatti Z, 2020, P 3 INT C COMP MATH, DOI [10.1109/iCoMET48670.2020.9073879, DOI 10.1109/ICOMET48670.2020.9073879]
   Clemens RG, 2016, IMPLEMENTING AUGMENT
   El Kah A, 2018, EDUC INF TECHNOL, V23, P2911, DOI 10.1007/s10639-018-9750-2
   Faisal CMN, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P656, DOI 10.1145/3167132.3167205
   Faisal CMN, 2020, INTERNET RES, V30, P1631, DOI 10.1108/INTR-05-2019-0217
   Fan M, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312756
   Avila-Pesantez DF, 2019, COMM COM INF SC, V895, P165, DOI 10.1007/978-3-030-05532-5_12
   Ferreira-Brito F, 2019, J BIOMED INFORM, V98, DOI 10.1016/j.jbi.2019.103287
   Franceschini S, 2019, NEUROPSYCHOLOGIA, V130, P100, DOI 10.1016/j.neuropsychologia.2018.10.023
   Franceschini S, 2013, CURR BIOL, V23, P462, DOI 10.1016/j.cub.2013.01.044
   Garzón J, 2019, VIRTUAL REAL-LONDON, V23, P447, DOI 10.1007/s10055-019-00379-9
   Garzón J, 2019, EDUC RES REV-NETH, V27, P244, DOI 10.1016/j.edurev.2019.04.001
   Guillen-Sanz H, 2022, LECT NOTES COMPUT SC, V13446, P34, DOI 10.1007/978-3-031-15553-6_3
   Gupta T, 2021, AUGMENTA11Y READING, P1, DOI [10.1145/3441852.3476530, DOI 10.1145/3441852.3476530]
   Gupta T, 2021, 23RD INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2021, DOI 10.1145/3441852.3476530
   Hashim HU, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14084831
   Holz H, 2017, LECT NOTES COMPUT SC, V10653, P73, DOI 10.1007/978-3-319-71940-5_7
   Jaramillo-Alcázar A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13052507
   Kashani-Vahid L, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL SERIOUS GAMES SYMPOSIUM (ISGS), P13, DOI 10.1109/ISGS49501.2019.9047004
   Kast M, 2011, ANN DYSLEXIA, V61, P177, DOI 10.1007/s11881-011-0052-2
   Kim JJ, 2021, ADV FUNCT MATER, V31, DOI 10.1002/adfm.202009602
   Köse H, 2021, EDUC INF TECHNOL, V26, P1921, DOI 10.1007/s10639-020-10326-w
   Lin CY, 2016, LECT NOTES COMPUT SC, V9739, P103, DOI 10.1007/978-3-319-40238-3_11
   Lovio R, 2012, BRAIN RES, V1448, P42, DOI 10.1016/j.brainres.2012.01.071
   Mokmin NAM, 2024, EDUC INF TECHNOL, V29, P1251, DOI 10.1007/s10639-022-11550-2
   Mombach J, 2020, REMOTE ASSESSING CHI, P1279, DOI [10.1109/COMPSAC48688.2020.00-80, DOI 10.1109/COMPSAC48688.2020.00-80]
   Ostiz-Blanco M, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P447, DOI 10.1145/3234695.3241028
   Papanastasiou G, 2019, VIRTUAL REAL-LONDON, V23, P425, DOI 10.1007/s10055-018-0363-2
   Peffers K, 2007, J MANAGE INFORM SYST, V24, P45, DOI 10.2753/MIS0742-1222240302
   Rapti D, 2023, EUR J SPEC NEEDS EDU, V38, P185, DOI 10.1080/08856257.2022.2045816
   Rauschenberger M, 2019, TECHNOLOGIES DYSLEXI, P603, DOI [10.1007/978-1-4471-7440-0_31, DOI 10.1007/978-1-4471-7440-0_31]
   Reis L, 2021, RES SOC ADMIN PHARM, DOI [10.1016/j.sapharm.2021.05.016, DOI 10.1016/J.SAPHARM.2021.05.016]
   Ryan RM, 2020, CONTEMP EDUC PSYCHOL, V61, DOI 10.1016/j.cedpsych.2020.101860
   Saeed A, 2022, INFORM KNOWLEDGE INT, P79, DOI [10.1007/978-3-030-75123-4_4/COVER, DOI 10.1007/978-3-030-75123-4_4/COVER]
   Science C, 2016, ENHANCING PHONOLOGIC, P1
   Tenemaza M, 2019, ADV INTELL SYST, V794, P925, DOI 10.1007/978-3-319-94947-5_91
   Tentori M, 2015, RELATED WORK SMART E
   Thomson JM, 2013, READ WRIT, V26, P139, DOI 10.1007/s11145-012-9359-6
   Tosto C, 2021, VIRTUAL REAL-LONDON, V25, P879, DOI 10.1007/s10055-020-00485-z
   van't Hof M, 2021, AUTISM, V25, P862, DOI 10.1177/1362361320971107
   Vasalou A, 2017, COMPUT EDUC, V114, P175, DOI 10.1016/j.compedu.2017.06.009
   Vecino S, 2021, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES (WEBIST), P167, DOI 10.5220/0010715800003058
   Yildirim O, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/25997
   Zare M, 2019, ROLE PERSIAN LANGUAG, DOI [10.1111/jcal.12400, DOI 10.1111/JCAL.12400]
   Zuo TJ, 2023, ENTERTAIN COMPUT, V46, DOI 10.1016/j.entcom.2023.100563
NR 50
TC 0
Z9 0
U1 12
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3649
EP 3663
DI 10.1007/s10055-023-00862-4
EA OCT 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001074559600001
DA 2024-07-18
ER

PT J
AU Dudley, J
   Yin, LL
   Garaj, V
   Kristensson, PO
AF Dudley, John
   Yin, Lulu
   Garaj, Vanja
   Kristensson, Per Ola
TI Inclusive Immersion: a review of efforts to improve accessibility in
   virtual reality, augmented reality and the metaverse
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality; Augmented Reality; Mixed Reality; The metaverse;
   Disability; Accessibility
ID SYSTEM; PAIN; REHABILITATION; DISABILITY; PEOPLE; METAANALYSIS;
   SUPERMARKET; CHILDREN; ADULTS
AB Virtual Reality (VR) and Augmented Reality (AR) afford new forms of work and leisure. While affordable and effective VR and AR headsets are now available, neither technology has achieved widespread user adoption. However, we predict continual technological advances and cost reductions are likely to lead to wider diffusion in society. Bridging the chasm from the early adopters to the early majority will require careful consideration of the needs of a more casual and diverse user population. In particular, it is desirable to minimise the exclusion of potential users based on their unique needs and maximise the inclusion of users in these novel immersive experiences. Ensuring equitable access to the emerging metaverse further reinforces the need to consider the diverse needs of users. We refer to this objective of maximising the accessibility and enjoyment potential of users of VR, AR and the metaverse as Inclusive Immersion. This paper reviews the research and commercial landscape seeking to address the accessibility needs of users in VR and AR. The survey provides the basis for a synthesis of the emerging strategies for maximising the inclusiveness of VR and AR applications. Finally, we identify several unaddressed accessibility challenges requiring further research attention. Our paper consolidates disparate efforts related to promoting accessible VR and AR and delivers directions for advancing research in this area.
C1 [Dudley, John; Kristensson, Per Ola] Univ Cambridge, Dept Engn, Cambridge, England.
   [Yin, Lulu; Garaj, Vanja] Brunel Univ London, Brunel Design Sch, Uxbridge, England.
C3 University of Cambridge; Brunel University
RP Dudley, J (corresponding author), Univ Cambridge, Dept Engn, Cambridge, England.
EM jjd50@cam.ac.uk
FU EPSRC [EP/S027432/1, EP/S027637/1]; EPSRC [EP/S027432/1, EP/S027637/1]
   Funding Source: UKRI
FX This work was funded by the EPSRC (Grants EP/S027432/1 and
   EP/S027637/1).
CR Achanccaray D, 2018, IEEE SYS MAN CYBERN, P1006, DOI 10.1109/SMC.2018.00179
   Agulló B, 2019, AI EDAM, V33, P416, DOI 10.1017/S0890060419000362
   Ahmetovic D, 2021, 18TH INTERNATIONAL WEB FOR ALL CONFERENCE (W4A '21), DOI 10.1145/3430263.3452441
   Albouys-Perrois J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174203
   Aljowaysir N, 2019, 2019 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), DOI 10.1109/gem.2019.8811558
   [Anonymous], 2010, P 23ND ANN ACM S USE
   Arafat IM, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P51, DOI 10.1145/2993369.2993383
   Ates H.C., 2015, P 9 INT C TANGIBLE E, P225, DOI [DOI 10.1145/2677199.2680551, 10.1145/2677199.2680551]
   Autismity, 2020, AUT THE AUT SIM
   Bailey B, 2022, REV J AUTISM DEV DIS, V9, P160, DOI 10.1007/s40489-020-00230-x
   Baker Steven, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445752
   Baker Steven, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359251
   Baker S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102105
   BBC R, 2020, 360 VID VIRT REAL
   Belo J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445349
   Benham S, 2019, OTJR-OCCUP PART HEAL, V39, P90, DOI 10.1177/1539449218817291
   Bertiz A, 2019, 5 VR GAMES CONSIDERA
   Bertram Craig, 2013, Biomimetic and Biohybrid Systems. Second International Conference, Living Machines 2013. Proceedings. LNCS 8064, P24, DOI 10.1007/978-3-642-39802-5_3
   Blaha J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P163, DOI 10.1109/VR.2014.6802102
   Boyd L, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P446, DOI 10.1145/3311927.3325315
   Boyd L, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313080
   Boyd LE, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173778
   Boyd LE, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4872, DOI 10.1145/2858036.2858215
   Bozgeyikli L, 2014, 2014 2ND WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P29, DOI 10.1109/VAAT.2014.6799466
   Brown A, 2017, DESIGNING SUBTITLES
   Brown A, 2018, EXPLORING SUBTITLE B
   Brulé E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376749
   Bryant L, 2020, DISABIL REHABIL-ASSI, V15, P365, DOI 10.1080/17483107.2018.1549276
   Cassidy B, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300289
   Chun-Chuan Chen, 2017, 2017 International Conference on Applied System Innovation (ICASI). Proceedings, P683, DOI 10.1109/ICASI.2017.7988517
   Ciccone BA, 2023, ERGON DES, V31, P24, DOI 10.1177/10648046211002578
   Clarkson J., 2007, INCLUSIVE DESIGN TOO
   Climent MM, 2021, IEEE ACCESS, V9, P2819, DOI 10.1109/ACCESS.2020.3047377
   Cook DM, 2019, PROCEEDINGS OF CHIUXID 2019: 5TH INTERNATIONAL ACM IN-COOPERATION HCI AND UX CONFERENCE, P147, DOI 10.1145/3328243.3328262
   Lecavalier NC, 2020, NEUROPSYCHOL REHABIL, V30, P462, DOI 10.1080/09602011.2018.1477684
   Coughlan JM, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P288, DOI 10.1109/ISMAR-Adjunct.2017.89
   D'Agnano F, 2015, INT ARCH PHOTOGRAMM, V40-5, P207, DOI 10.5194/isprsarchives-XL-5-W4-207-2015
   Davison SMC, 2018, ACTA NEUROPSYCHIATR, V30, P79, DOI 10.1017/neu.2017.14
   Devigne L, 2017, INT C REHAB ROBOT, P995, DOI 10.1109/ICORR.2017.8009379
   Di Luca M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445319
   Dick E., 2021, Principles and policies to unlock the potential of AR/VR for equity and inclusion
   Didehbani N, 2016, COMPUT HUM BEHAV, V62, P703, DOI 10.1016/j.chb.2016.04.033
   do Amaral WM, 2011, IMSCI'11: THE 5TH INTERNATIONAL MULTI-CONFERENCE ON SOCIETY, CYBERNETICS AND INFORMATICS, VOL I, P93
   do Amaral WM, 2010, INNOVATIONS IN COMPUTING SCIENCES AND SOFTWARE ENGINEERING, P85, DOI 10.1007/978-90-481-9112-3_15
   Dombrowski M, 2019, LECT NOTES COMPUT SC, V11574, P33, DOI 10.1007/978-3-030-21607-8_3
   Dzardanova E., 2018, ENCY COMPUTER GRAPHI, P1, DOI DOI 10.1007/978-3-319-08234-9_204-1
   Eisapour M, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3174362
   Epelde G, 2013, MULTIMED TOOLS APPL, V67, P497, DOI 10.1007/s11042-011-0949-0
   Ferdous SMS, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI 10.1109/VR.2018.8446488
   Ferdous SMS, 2017, P IEEE VIRT REAL ANN, P421, DOI 10.1109/VR.2017.7892356
   Ferdous SMS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P121, DOI 10.1109/3DUI.2016.7460041
   FERDOUS SMS, 2018, P 24 ACM S VIRT REAL, P1, DOI DOI 10.1109/VR.2018.8446488
   Fidyka A, 2021, TRANSL STUD, V14, P298, DOI 10.1080/14781700.2021.1888783
   Fidyka A, 2018, TRANSL SPACES, V7, P285, DOI 10.1075/ts.18018.fid
   Findlater L., 2010, Proceedings of ACM Symposium on User Interface Software and Technology (UIST). (New York, NY, P153, DOI [10.1145/1866029, DOI 10.1145/1866029]
   Findlater L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300276
   Flower A, 2007, REM SPEC EDUC, V28, P72, DOI 10.1177/07419325070280020601
   Fogli Daniela, 2018, Smart Objects and Technologies for Social Good. Third International Conference, GOODTECHS 2017. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 233), P364, DOI 10.1007/978-3-319-76111-4_36
   Foxman MH, 2018, THEIS COLUMBIA U, DOI [10.7916/D8M05NH3, DOI 10.7916/D8M05NH3]
   Franz RL, 2021, 23RD INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2021, DOI 10.1145/3441852.3471230
   Freeman Guo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432938
   Freeman G, 2021, PROCEEDINGS OF THE 2021 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2021, P84, DOI 10.1145/3452918.3458805
   Fuglerud KS, 2014, THESIS U OSLO, DOI [10.13140/2.1.4471.5844, DOI 10.13140/2.1.4471.5844]
   Ganapathi P, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P659, DOI 10.1109/VRW55335.2022.00185
   Gang P., 2019, Adv. Intell. Syst. Comput, V886, P612, DOI DOI 10.1007/978-3-030-03402-3_43
   Garaj V, 2019, 7 INT C UN DES UD201
   Garzotto F, 2018 3 DIGITAL HERIT, P427
   Garzotto F, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P478, DOI 10.1145/3078072.3084312
   Garzotto F, 2017, LECT NOTES COMPUT SC, V10360, P507, DOI 10.1007/978-3-319-60131-1_36
   Gerling K, 2014, P 1 ACM SIGCHI ANN S, P415, DOI [10.1145/2658537.2661303event-place, DOI 10.1145/2658537.2661303, 10.1145/2658537.2661303]
   Gerling K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445196
   Gerling K, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376265
   Gerling KM, 2015, ACM T ACCESS COMPUT, V6, DOI 10.1145/2724729
   Giaconi C, 2021, INT J INCL MUS, V14, P95, DOI 10.18848/1835-2014/CGP/v14i01/95-106
   Glaser N, 2022, VIRTUAL REAL-LONDON, V26, P1705, DOI 10.1007/s10055-022-00661-3
   Goldberg A, 2021, ACM SIGGRAPH 2021 PR, DOI [10.1145/3446368.3452125, DOI 10.1145/3446368.3452125]
   Guedes L, 2020, P INT C COMPUTERS HE, P157, DOI [10.1007/978-3-030-58796-3_20, DOI 10.1007/978-3-030-58796-3_20]
   Guerrero G, 2020, IBER CONF INF SYST, DOI 10.23919/cisti49556.2020.9140857
   Guitton P, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P443, DOI 10.1109/ISMAR-Adjunct.2019.00051
   Hansen J, 2019, P 2019 CHI C HUM FAC, DOI 10.1145//3290607.3299048
   Hedvall PO, 2009, LECT NOTES COMPUT SC, V5889, P264
   Herskovitz J, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3417006
   Hoffman HG, 2004, J CLIN PSYCHOL, V60, P189, DOI 10.1002/jclp.10244
   Hong S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10141652
   Hoppe AH, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3418009
   Hurd O, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P706, DOI 10.1145/3308561.3356110
   IrisVision, 2020, US
   Jaballah K, 2012, W4A 2012 INT CROSS D, DOI [10.1145/2207016.2207033, DOI 10.1145/2207016.2207033]
   Jain Dhruv, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P80, DOI 10.1145/3462244.3479946
   Jain D, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P160, DOI 10.1145/3461778.3462106
   Jain D, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P7, DOI 10.1145/3197391.3205404
   Jain D, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P81, DOI 10.1145/3234695.3236362
   Jimenez-Mixco V, 2009, LECT NOTES COMPUT SC, V5615, P75, DOI 10.1007/978-3-642-02710-9_9
   John NW, 2018, IEEE T VIS COMPUT GR, V24, P1867, DOI 10.1109/TVCG.2017.2700273
   Jones PR, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0242-6
   Kaminer C., 2014, Proceedings of the 16th International ACM SIGACCESS Conference on Computers Accessibility, P299, DOI [10.1145/2661334.2661340, DOI 10.1145/2661334.2661340]
   Kandalaft MR, 2013, J AUTISM DEV DISORD, V43, P34, DOI 10.1007/s10803-012-1544-6
   Kane S. K., 2013, P 2013 CHI C HUM FAC, P347, DOI DOI 10.1145/2470654.2470704
   Kartick P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P799, DOI [10.1109/VRW50115.2020.00250, 10.1109/VRW50115.2020.00-25]
   Kaul OB, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451611
   Keselj A, 2021, PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (CONTEL 2021), P49, DOI 10.23919/ConTEL52528.2021.9495975
   Kim A, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0225-2
   Kim JM, 2020, IEEE ACCESS, V8, P196151, DOI 10.1109/ACCESS.2020.3034363
   Kim W, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P123, DOI 10.1145/3210240.3210331
   Kizony R, 2003, J VISUAL COMP ANIMAT, V14, P261, DOI 10.1002/vis.323
   Kizony R, 2012, VIRTUAL REALITY
   Klinger E, 2004, CYBERPSYCHOL BEHAV, V7, P292
   Kreimeier Julian, 2020, PETRA '20: Proceedings of the 13th ACM International Conference on PErvasive Technologies Related to Assistive Environments, DOI 10.1145/3389189.3389194
   Kunze K, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P83, DOI 10.1145/2638728.2638747
   Lamash L, 2017, 2017 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION (ICVR)
   Lang F, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489873
   Levin MF, 2011, EXPERT REV NEUROTHER, V11, P153, DOI [10.1586/ern.10.201, 10.1586/ERN.10.201]
   Li LY, 2014, ACM-IEEE J CONF DIG, P299, DOI 10.1109/JCDL.2014.6970183
   Li NL, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376698
   Li X, 2018, AUTOMAT CONSTR, V86, P150, DOI 10.1016/j.autcon.2017.11.003
   Liu KH, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P122, DOI 10.1109/VRW55335.2022.00038
   Logitech, 2020, LOG G AD GAM KIT XBO
   Lowtek Games, 2021, DISL ASS STOR
   Lukava T, 2022, J ENABLING TECHNOL, V16, P75, DOI 10.1108/JET-03-2022-0025
   Mahmud MR, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P782, DOI 10.1109/VR51125.2022.00100
   Maidenbaum S, 2015, 2015 3RD IEEE VR INTERNATIONAL WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P15, DOI 10.1109/VAAT.2015.7155404
   Maidenbaum S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0072555
   Maloney D, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P271, DOI 10.1109/VRW52623.2021.00056
   Malu M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P221, DOI 10.1145/2702123.2702188
   Masood T, 2019, ROBOT CIM-INT MANUF, V58, P181, DOI 10.1016/j.rcim.2019.02.003
   Matamala A, 2021, SENDEBAR, P65, DOI 10.30827/sendebar.v32.16881
   McCloskey R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P857, DOI 10.1109/VRW55335.2022.00284
   McIntosh J, 2020, INT J ARCHIT COMPUT, V18, P284, DOI 10.1177/1478077120914020
   McLaughlin N, 2021, BMJ SIMUL TECHNOL EN, V7, P207, DOI 10.1136/bmjstel-2020-000683
   McNaney R, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2551, DOI 10.1145/2556288.2557092
   Meijer J, 2020, CEUR WORKSHOP PROC
   Mengoni M, 2015, LECT NOTES COMPUT SC, V9194, P311, DOI 10.1007/978-3-319-20913-5_29
   MetalPop Games, 2021, UI ACC PLUG UAP GUI
   Microsoft, 2020, SEEING AI APP MICR
   Microsoft, 2019, LAUNCH WIND SETT APP
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Miller KJ, 2014, AGE AGEING, V43, P188, DOI 10.1093/ageing/aft194
   Minakata K, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3317956.3318150
   Mirzaei M, 2020, IEEE T VIS COMPUT GR, V26, P2084, DOI 10.1109/TVCG.2020.2973441
   Misztal S, 2020, IEEE INT CONF SERIOU, DOI 10.1109/segah49190.2020.9201756
   Molloy D., 2020, BBC NEWS
   Montagud M., 2020, ITU J, V3, P8
   Montagud M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167472
   Montagud M, 2020, PROCEEDINGS OF THE 2020 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2020, P143, DOI [10.1145/3391614.3399390, 10.26807/cav.vi10.386]
   Montagud M, 2020, PERS UBIQUIT COMPUT, V24, P887, DOI 10.1007/s00779-019-01357-3
   Montagud M, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P245, DOI 10.1145/3210825.3213570
   Moranski M, 2014, VIRTUAL REALITY PEOP, P137
   Kohei M, 2020, 2020 59TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P421, DOI 10.23919/sice48898.2020.9240271
   Morris RG, 2000, VIRTUAL REAL-LONDON
   Mott M, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P451, DOI 10.1109/ISMAR-Adjunct.2019.00122
   Mott ME, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI [10.1145/3396956.3396969, 10.1145/3373625.3416998]
   Munteanu C, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P105, DOI 10.1145/2702123.2702481
   Murray CD, 2007, DISABIL REHABIL, V29, P1465, DOI 10.1080/09638280601107385
   Nabors L, 2020, ADV NEURODEV DISORD, V4, P344, DOI 10.1007/s41252-020-00177-4
   Oculus, 2021, QUEST VIRT REAL CHEC
   Ona Edwin Daniel, 2019, Stud Health Technol Inform, V266, P57, DOI 10.3233/SHTI190773
   Oncins E, 2020, MONTI, V12, P214, DOI 10.6035/MonTI.2020.12.07
   Paciulli GH, 2020, 2020 XV CONFERENCIA LATINOAMERICANA DE TECNOLOGIAS DE APRENDIZAJE (LACLO), DOI 10.1109/LACLO50806.2020.9381132
   Palaniappan SM, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P495, DOI 10.1145/3308561.3353810
   Palos XB, 2017, DAYDREAM LABS ACCESS
   Park SM, 2022, IEEE ACCESS, V10, P4209, DOI 10.1109/ACCESS.2021.3140175
   Paudyal P, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P522, DOI 10.1145/3325480.3326546
   PENG Y, 2018, POLYHEDRON, DOI DOI 10.1145/3173574.3173867
   Piovesan SD, 2013, 2013 12 INT C INF TE, P1, DOI [10.1109/ITHET.2013.6671021, DOI 10.1109/ITHET.2013.6671021]
   PlayStation, 2020, LAST US 2
   Powell W, 2020, CYBERPSYCH BEH SOC N, V23, P185, DOI 10.1089/cyber.2019.0409
   Poyade M, 2017, P 19 ACM INT C MULT, P504, DOI [10.1145/3136755.3143025, DOI 10.1145/3136755.3143025]
   Preiser W.F., 2011, UNIVERSAL DESIGN HDB, VSecond, p38.1
   Richard E, 2007, 2007 VIRTUAL REHABILITATION, P100
   Rizzo AS, 2002, DISABIL REHABIL, V24, P567, DOI 10.1080/09638280110111315
   Roberts JW, 2002, P SOC PHOTO-OPT INS, V4660, P422, DOI 10.1117/12.468059
   Rose FD, 2005, CYBERPSYCHOL BEHAV, V8, P241, DOI 10.1089/cpb.2005.8.241
   Salamon NZ, 2014, BRAZIL SYMP GAME DIG, P165, DOI 10.1109/SBGAMES.2014.12
   Salivia G., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P1213, DOI DOI 10.1145/2470654.2466157
   Samsung, 2017, SAMS REL
   Sánchez-Cabrero R, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01338
   Saposnik G, 2011, STROKE, V42, P1380, DOI 10.1161/STROKEAHA.110.605451
   Schneider O, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P877, DOI 10.1145/3242587.3242604
   Seaborn K, 2016, ACM T COMPUT-HUM INT, V23, DOI 10.1145/2893182
   Sears A., 2003, HUM FAC ER
   Seigneur JM, 2022, AUGMENTED HUMAN 2022: PROCEEDINGS OF THE 13TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE, AH2022, DOI 10.1145/3532525.3532534
   Shaker A, 2020, COMPUT SCI ENG, V22, P7, DOI 10.1109/MCSE.2019.2961352
   Shakespeare T., 2006, DISABILITY STUDIES R, P197, DOI DOI 10.2307/20141862
   Shao D, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12229345
   Sharar Sam R, 2008, Expert Rev Neurother, V8, P1667, DOI 10.1586/14737175.8.11.1667
   Sky, 2020, SKY IMM
   Smith K, 2012, UNIVERSAL ACCESS INF, V11, P387, DOI 10.1007/s10209-011-0254-8
   Standen P.J., 2006, VIRTUAL REAL-LONDON, V10, P241, DOI 10.1007/s10055-006-0042-6
   Stearns L, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P28, DOI 10.1145/3234695.3236361
   Sykownik P, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502008
   Teófilo M, 2018, LECT NOTES COMPUT SC, V10908, P132, DOI 10.1007/978-3-319-92052-8_11
   Teofilo M, 2018, IEEE ICCE, DOI 10.1109/ICCE.2018.8326167
   Teofilo M, 2016, P IEEE VIRT REAL ANN, P293, DOI 10.1109/VR.2016.7504769
   The University of Melbourne, 2019, ACC VIRT REAL ENV
   Thevin Dr-Ing Lauren, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3488550
   Thevin L, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P17, DOI 10.1145/3343055.3359711
   Thevin L, 2018, LECT NOTES COMPUT SC, V10897, P193, DOI 10.1007/978-3-319-94274-2_26
   Trost Z, 2014, J APPL BIOBEHAV RES, V19, P106, DOI 10.1111/jabr.12021
   Tsoupikova D, 2015, ANN BIOMED ENG, V43, P467, DOI 10.1007/s10439-014-1218-y
   Vedamurthy I, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0264
   Vinayagamoorthy V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300762
   Vivid Vision, 2020, VIV VIS LAZ EYE CROS
   Vona F, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399845
   Voss C, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1218, DOI 10.1145/2968219.2968310
   W3C, 2021, XR ACC US REQ
   W3C, 2018, Web content accessibility guidelines (WCAG) 2.1
   W3C, 2017, ACC VIRT REAL
   Waddingham P, 2006, 6 INT C DIS VIRT REA
   WalkinVR, 2020, WALKINVR VIRT REAL P
   Waller S, 2010, J INTEGR CARE, V18, P19, DOI 10.5042/jic.2010.0375
   Wang KJ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P161, DOI 10.1109/AIVR.2018.00034
   Wang X, 2023, INT J DEV DISABIL, V69, P524, DOI 10.1080/20473869.2021.1970938
   Wasserman B, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P755, DOI 10.1145/3341215.3356277
   Wedel M, 2020, INT J RES MARK, V37, P443, DOI 10.1016/j.ijresmar.2020.04.004
   Wedoff R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300371
   Weir K, 2020, JCDL, P393, DOI [10.1145/3383583.3398610, DOI 10.1145/3383583.3398610]
   Werner P, 2009, DEMENT GERIATR COGN, V27, P301, DOI 10.1159/000204915
   Williams K, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P231, DOI 10.1145/2702123.2702484
   Wobbrock J. O., 2011, ACM T ACCESS COMPUT, V3, P1, DOI [DOI 10.1145/1952383.1952384, 10.1145/1952383.1952384, https://doi.org/10.1145/1952383.1952384]
   Wong A, 2017, VR ACCESSIBILITY SUR
   World Health Organization, 2013, How to use the ICF: A practical manual for using the International Classification of Functioning, Disability and Health (ICF)
   Wu HY, 2021, MULTIMED TOOLS APPL, V80, P27259, DOI 10.1007/s11042-021-10899-9
   Xbox, 2020, XBOX AD CONTR
   XR Access, 2020, XR ACC
   XR Association, 2020, XR ASS DDEV GUID IND
   Xu JN, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3516399
   Yang D, 2022, Clinical eHealth, V5, P1, DOI [10.1016/j.ceh.2022.02.001, DOI 10.1016/J.CEH.2022.02.001]
   Yang TW, 2016, UKSIM EURO SYMP COMP, P143, DOI 10.1109/EMS.2016.32
   Yoon C, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P210, DOI 10.1145/3308561.3353788
   Yue K, 2022, 2022 13TH INTERNATIONAL CONFERENCE ON E-EDUCATION, E-BUSINESS, E-MANAGEMENT AND E-LEARNING, IC4E 2022, P40, DOI 10.1145/3514262.3514345
   ZHANG S, 2010, 2010 INT C NETWORKIN, P80, DOI DOI 10.1109/ICNSC.2010.5461539
   Zhao Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376516
   Zhao YH, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P387, DOI 10.1145/3332165.3347906
   Zhao YH, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300341
   Zhao Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173690
   Zhao YH, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4170, DOI 10.1145/3025453.3025949
   Zhu SZ, 2021, FRONT AGING NEUROSCI, V13, DOI 10.3389/fnagi.2021.586999
   Zolyomi A, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P220, DOI 10.1145/3132525.3132552
NR 238
TC 8
Z9 8
U1 7
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 2989
EP 3020
DI 10.1007/s10055-023-00850-8
EA SEP 2023
PG 32
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001065767500002
OA hybrid
DA 2024-07-18
ER

PT J
AU Moon, J
   Choi, GW
   Seo, JY
AF Moon, Jewoong
   Choi, Gi Woong
   Seo, Joo Young
TI Revisiting multimedia learning design principles in virtual
   reality-based learning environments for autistic individuals
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Autism; Cognitive load; Multimedia learning design
ID COGNITIVE LOAD THEORY; INSTRUCTIONAL-DESIGN; SPECTRUM DISORDER;
   CHILDREN; MODEL; COMMUNICATION; ARCHITECTURE; DISABILITY; COHERENCE;
   EDUCATION
AB Virtual reality (VR) offers promising opportunities for supporting autistic learners in developing social and cognitive skills. However, designing VR-based learning environments optimized for these learners requires a nuanced understanding that addresses their unique needs. This review article reconsiders the key theories of multimedia learning, including cognitive load theory and cognitive theory of multimedia learning, with the aim of illuminating how these theories can inform the development of effective VR-based learning environments for autistic learners. We propose four design goals for a VR-based learning environment optimized for autistic learners: (1) minimizing learners' extraneous load via attention guiding, (2) managing intrinsic cognitive load in problem-solving, (3) fostering germane processing through multiple representations, and (4) assessing cognitive load and implementing adaptive learning support design. In this exploration, we bring to demonstrate prevalent design challenges of existing VR-based learning environments for autistic individuals and offer prospective research trajectories for their enhancement. By incorporating a strengths-based approach, accommodating the diverse sensory needs, and recognizing the cognitive differences among autistic individuals, we aspire to advance a more inclusive VR design practice. This review presents crucial insights and direction for researchers and designers aiming to create effective, accessible, and inclusive VR-based learning environments for autistic learners and beyond.
C1 [Moon, Jewoong] Univ Alabama, Dept Educ Policy Leadership & Technol Studies, Tuscaloosa, AL 35487 USA.
   [Choi, Gi Woong] Univ Cincinnati, Cincinnati, OH USA.
   [Seo, Joo Young] Univ Illinois, Champaign, IL USA.
C3 University of Alabama System; University of Alabama Tuscaloosa;
   University System of Ohio; University of Cincinnati; University of
   Illinois System; University of Illinois Urbana-Champaign
RP Moon, J (corresponding author), Univ Alabama, Dept Educ Policy Leadership & Technol Studies, Tuscaloosa, AL 35487 USA.
EM jmoon19@ua.edu
OI Moon, Jewoong/0000-0001-6311-3019; Choi, Gi Woong/0000-0002-9631-3727;
   Seo, JooYoung/0000-0002-4064-6012
CR Adams NC, 2012, J AUTISM DEV DISORD, V42, P1052, DOI 10.1007/s10803-011-1345-3
   Alfalah SFM, 2018, EDUC INF TECHNOL, V23, P2633, DOI 10.1007/s10639-018-9734-2
   Atkinson RK, 2000, REV EDUC RES, V70, P181, DOI 10.2307/1170661
   Baron-Cohen S., 1995, ESSAY AUTISM THEORY
   Baron-Cohen S, 2009, ANN NY ACAD SCI, V1156, P68, DOI 10.1111/j.1749-6632.2009.04467.x
   Bogte H, 2009, AUTISM, V13, P229, DOI 10.1177/1362361309103793
   Chen F, 2016, HUM-COMPUT INT-SPRIN, P13, DOI 10.1007/978-3-319-31700-7_2
   Chen Li, 2021, International Journal of Innovation and Learning, V30, P317, DOI 10.1504/IJIL.2021.118194
   Choi HH, 2014, EDUC PSYCHOL REV, V26, P225, DOI 10.1007/s10648-014-9262-6
   Cobb S., 2005, The Cambridge handbook of multimedia learning, P525
   Conejero A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28831-x
   de Jong T, 2010, INSTR SCI, V38, P105, DOI 10.1007/s11251-009-9110-0
   Dechsling A, 2022, J AUTISM DEV DISORD, V52, P4692, DOI 10.1007/s10803-021-05338-5
   Herrero JF, 2020, EDUC INF TECHNOL, V25, P1689, DOI 10.1007/s10639-019-10050-0
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Geary D.C., 2005, Origins of the social mind: Evolutionary psychology and child development, P493
   Geary DC, 1998, EXP AGING RES, V24, P101
   Geurts HM, 2009, TRENDS COGN SCI, V13, P74, DOI 10.1016/j.tics.2008.11.006
   Glaser N, 2022, J FORMATIVE DES LEAR, V6, P63, DOI 10.1007/s41686-022-00072-2
   Glaser N, 2022, VIRTUAL REAL-LONDON, V26, P1705, DOI 10.1007/s10055-022-00661-3
   Glaser NJ, 2020, TECHNOL KNOWL LEARN, V25, P315, DOI 10.1007/s10758-018-9369-9
   Gomot M, 2008, BRAIN, V131, P2479, DOI 10.1093/brain/awn172
   Hill EL, 2004, TRENDS COGN SCI, V8, P26, DOI 10.1016/j.tics.2003.11.003
   Horvat N, 2022, VIRTUAL REAL-LONDON, V26, P1227, DOI 10.1007/s10055-022-00630-w
   Howard M, 2003, INTERACTIONIST PERSP
   Janssen J, 2020, ETR&D-EDUC TECH RES, V68, P783, DOI 10.1007/s11423-019-09729-5
   Janssen J, 2010, EDUC PSYCHOL REV, V22, P139, DOI 10.1007/s10648-010-9131-x
   Joseph RM, 2002, J CHILD PSYCHOL PSYC, V43, P807, DOI 10.1111/1469-7610.00092
   Kapp SK, 2020, AUTISTIC COMMUNITY AND THE NEURODIVERSITY MOVEMENT: STORIES FROM THE FRONTLINE, P1, DOI 10.1007/978-981-13-8437-0_1
   Kapp SK, 2013, DEV PSYCHOL, V49, P59, DOI 10.1037/a0028353
   Karami B, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.665326
   Ke FF, 2013, J EDUC RES, V106, P441, DOI 10.1080/00220671.2013.832999
   Khawaja MA, 2012, HUM FACTORS, V54, P518, DOI 10.1177/0018720811431258
   King-Sears ME, 2015, LEARN DISABILITY Q, V38, P84, DOI 10.1177/0731948714564575
   Kirschner Paul A, 2018, Int J Comput Support Collab Learn, V13, P213, DOI 10.1007/s11412-018-9277-y
   Kreijns K, 2013, EDUC PSYCHOL-US, V48, P229, DOI 10.1080/00461520.2012.750225
   Kuriakose S, 2017, IEEE T NEUR SYS REH, V25, P1180, DOI 10.1109/TNSRE.2016.2613879
   Lahiri U, 2013, IEEE T NEUR SYS REH, V21, P55, DOI 10.1109/TNSRE.2012.2218618
   Leadbitter K, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.635690
   Liu DJ, 2017, SMART COMPUT INTELL, P105, DOI 10.1007/978-981-10-5490-7_7
   Lorenzo G, 2019, EDUC INF TECHNOL, V24, P127, DOI 10.1007/s10639-018-9766-7
   Lorenzo GG, 2023, EDUC INF TECHNOL, V28, P9557, DOI 10.1007/s10639-022-11545-z
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   Mayer R, 2006, COPING COMPLEXITY MU, P129
   Mayer RE, 2002, PSYCHOL LEARN MOTIV, V41, P85, DOI 10.1016/S0079-7421(02)80005-6
   McCleery JP, 2020, AUTISM RES, V13, P1418, DOI 10.1002/aur.2352
   MISCHEL W, 1995, PSYCHOL REV, V102, P246, DOI 10.1037/0033-295X.102.2.246
   Moon J, 2023, J AUTISM DEV DISORD, DOI 10.1007/s10803-023-06021-7
   Moon J, 2019, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2019.1613665
   Munyofu M., 2007, LEARN MEDIA TECHNOL, V32, P407, DOI DOI 10.1080/17439880701690109
   Nyamse Victor, 2013, Virtual, Augmented and Mixed Reality. Systems and Applications. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings, Part II: LNCS 8022, P66, DOI 10.1007/978-3-642-39420-1_8
   Oliver M., 1997, COMMUNITY DEV J, V32, P244, DOI [10.1111/j.1467-954X.2006.00669, 10.1093/cdj/32.3.244]
   Paas F, 2003, EDUC PSYCHOL-US, V38, P63, DOI 10.1207/S15326985EP3801_8
   Parsloe SM, 2015, J APPL COMMUN RES, V43, P336, DOI 10.1080/00909882.2015.1052829
   Pellas N, 2020, IEEE T LEARN TECHNOL, V13, P748, DOI 10.1109/TLT.2020.3019405
   Pellicano E, 2006, DEV PSYCHOPATHOL, V18, P77, DOI 10.1017/S0954579406060056
   Reed P, 2012, J AUTISM DEV DISORD, V42, P947, DOI 10.1007/s10803-011-1324-8
   Rinehart Nicole J, 2002, Behav Cogn Neurosci Rev, V1, P164, DOI 10.1177/1534582302001002004
   Ringland KE, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P340, DOI 10.1145/3078072.3079749
   RITVO ER, 1984, PEDIATR ANN, V13, P298
   Roberts-Yates C, 2019, INT J SPEC EDUC, V34, P197
   Robertson CE, 2017, NAT REV NEUROSCI, V18, P671, DOI 10.1038/nrn.2017.112
   Rogers-Shaw C, 2018, ADULT LEARN, V29, P20, DOI 10.1177/1045159517735530
   ROUSSOU M, 2004, COMPUT ENTERTAIN, V2, DOI [10.1145/973801.973818, DOI 10.1145/973801.973818]
   Sani-Bozkurt S., 2017, Contemporary Educational Technology, V8, P1, DOI DOI 10.30935/CEDTECH/6184
   Schmidt M, 2021, ETR&D-EDUC TECH RES, V69, P1665, DOI 10.1007/s11423-021-10005-8
   Schnotz W, 2003, LEARN INSTR, V13, P141, DOI 10.1016/S0959-4752(02)00017-8
   Schnotz W, 1999, Z EXPT PSYCHOL, V46, P216
   Schuck RK, 2022, J AUTISM DEV DISORD, V52, P4625, DOI 10.1007/s10803-021-05316-x
   Schwamborn A, 2011, COMPUT HUM BEHAV, V27, P89, DOI 10.1016/j.chb.2010.05.028
   Seufert T, 2006, APPL COGNITIVE PSYCH, V20, P321, DOI 10.1002/acp.1248
   Shakespeare T., 2013, Disability rights and wrongs revisited
   Silberman S., 2015, Neurotribes: The legacy of autism and the future of neurodiversity
   Skulmowski A, 2022, EDUC PSYCHOL REV, V34, P171, DOI 10.1007/s10648-021-09624-7
   Strickland D, 1997, ST HEAL T, V44, P81
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   Sweller J, 2019, EDUC PSYCHOL REV, V31, P261, DOI 10.1007/s10648-019-09465-5
   Sweller J, 2010, EDUC PSYCHOL REV, V22, P123, DOI 10.1007/s10648-010-9128-5
   Taylor BA, 2012, BEHAV MODIF, V36, P341, DOI 10.1177/0145445512443981
   Tsai WT, 2021, UNIVERSAL ACCESS INF, V20, P375, DOI 10.1007/s10209-020-00724-9
   Van Gog T, 2011, APPL COGNITIVE PSYCH, V25, P584, DOI 10.1002/acp.1726
   Whalen C, 2003, J CHILD PSYCHOL PSYC, V44, P456, DOI 10.1111/1469-7610.00135
   White SW, 2018, CURR PSYCHIAT REP, V20, DOI 10.1007/s11920-018-0949-0
   Wong A, 2012, LEARN INSTR, V22, P449, DOI 10.1016/j.learninstruc.2012.05.004
   Woods R, 2017, DISABIL SOC, V32, P1090, DOI 10.1080/09687599.2017.1328157
   Zambrano J., 2019, Advances in cognitive load theory: Rethinking teaching, P30, DOI [10.4324/9780429283895-3, DOI 10.4324/9780429283895-3]
   Zhang L, 2015, INT CONF AFFECT, P532, DOI 10.1109/ACII.2015.7344621
   Zhang MY, 2022, BEHAV SCI-BASEL, V12, DOI 10.3390/bs12050138
   Zolyomi Annuska, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359236
NR 89
TC 1
Z9 1
U1 11
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3101
EP 3113
DI 10.1007/s10055-023-00856-2
EA SEP 2023
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001062310100001
DA 2024-07-18
ER

PT J
AU Ricci, M
   Evangelista, A
   Di Roma, A
   Fiorentino, M
AF Ricci, Marina
   Evangelista, Alessandro
   Di Roma, Annalisa
   Fiorentino, Michele
TI Immersive and desktop virtual reality in virtual fashion stores: a
   comparison between shopping experiences
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Retailing; Fashion industry; Shopping experience; User
   study
ID TECHNOLOGY ACCEPTANCE MODEL; CONSUMER; CONSEQUENCES; CONSTRUCTION;
   TELEPRESENCE; CONTEXT; DESIGN; SYSTEM; BRANDS; FLOW
AB With the high growth and prosperity of e-commerce, the retail industry needs to explore new technologies that improve digital shopping experiences. In the current technological scenario, Virtual Reality (VR) emerges as a tool and an opportunity for enhancing shopping activities, especially for the fashion industry. This study explores whether using Immersive Virtual Reality (IVR) technologies enhances the shopping experience in the fashion industry compared to Desktop Virtual Reality (DVR). A within-subject experiment was carried out involving a sample of 60 participants who completed a simulated shopping experience. In the first mode (DVR), a desktop computer setup was used to test the shopping experience using a mouse and keyboard for navigation. The second mode (IVR) exploited a Head-Mounted Display (HMD), and controllers, that allowed navigation while seated on a workstation to avoid sickness. Participants had to find a bag in the virtual shop and explore its features until they were ready to purchase it. Post-hoc measures of time duration of the shopping experience, hedonic and utilitarian values, user experience, and cognitive load were compared. Results showed that participants experienced higher hedonism and utilitarianism in the IVR shop compared to DVR. The cognitive load was comparable in both modes, while user experience was higher in IVR. In addition, the time duration of the shopping experience was higher in IVR, where users stayed immersed and enjoyed it for longer. This study has implications for fashion industry research, as the use of IVR can potentially lead to novel shopping patterns by enhancing the shopping experience.
C1 [Ricci, Marina; Evangelista, Alessandro; Fiorentino, Michele] Polytech Univ Bari, Dept Mech Math & Management, Via Orabona, 4, Bari, Italy.
   [Di Roma, Annalisa] Polytech Univ Bari, Dept Architecture Construction & Design, Via Orabona, 4, Bari, Italy.
C3 Politecnico di Bari; Politecnico di Bari
RP Ricci, M (corresponding author), Polytech Univ Bari, Dept Mech Math & Management, Via Orabona, 4, Bari, Italy.
EM marina.ricci@poliba.it
RI Ricci, Marina/KGL-8260-2024
OI Ricci, Marina/0000-0001-9355-8430
FU Politecnico di Bari within the CRUI-CARE Agreement; Italian Ministry of
   Education, University and Research [C-D94I18000260001]
FX Open access funding provided by Politecnico di Bari within the CRUI-CARE
   Agreement. This work was supported by the Italian Ministry of Education,
   University and Research under the Programmes "Department of Excellence",
   Legge 232/2016 (Grant No. C-D94I18000260001).
CR Albaum G, 1997, J MARKET RES SOC, V39, P331
   Alcañiz M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01530
   Altarteer S, 2016, P 21 INT C WEB3D TEC, P173, DOI [10.1145/2945292.2945317, DOI 10.1145/2945292.2945317]
   Altarteer S, 2019, IEEE ACCESS, V7, P64053, DOI 10.1109/ACCESS.2019.2916353
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Aurier P., 2009, MARKETING PRODUITS A
   AWS for Industries, 2021, IMM TECHN CHANG RET
   BABIN BJ, 1994, J CONSUM RES, V20, P644, DOI 10.1086/209376
   Bauer HH, 2013, J BUS RES, V66, P1035, DOI 10.1016/j.jbusres.2011.12.028
   Biocca Frank., 1992, Presence: Teleoperators Virtual Environments, V1, P334, DOI [DOI 10.1162/PRES.1992.1.3.334, 10.1162/pres.1992.1.3.334]
   Bloemer J., 1998, EUR J MARKETING, V32 Nos, P499, DOI DOI 10.1108/03090569810216118
   Bolton LE, 2010, J MARKETING RES, V47, P564, DOI 10.1509/jmkr.47.3.564
   Bonetti F, 2018, PROGR IS, P119, DOI 10.1007/978-3-319-64027-3_9
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bressoud E, 2013, J PROD BRAND MANAG, V22, P286, DOI 10.1108/JPBM-05-2012-0141
   Byers JC, 1989, ADV IND ERFONOMICS S
   CARROLL JM, 1987, COMMUN ACM, V30, P14, DOI 10.1145/7885.7886
   Childers TL, 2001, J RETAILING, V77, P511, DOI 10.1016/S0022-4359(01)00056-2
   CRONBACH LJ, 1951, PSYCHOMETRIKA, V16, P297, DOI [10.1007/BF02310555, DOI 10.1007/BF02310555]
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Diehl K, 2010, J MARKETING RES, V47, P312, DOI 10.1509/jmkr.47.2.312
   Donatiello L, 2018, 2018 IEEE 29TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P17, DOI 10.1109/PIMRC.2018.8581036
   Dzardanova E, 2017, IEEE SYMP COMP COMMU, P6, DOI 10.1109/ISCC.2017.8024496
   Filser M., 1994, Le comportement du consommateur
   Fiorentino M, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14120381
   Ghani J. A., 1991, Proceedings of the Twelfth International Conference on Information Systems, P229
   Goldsmith RE, 2005, INT J RETAIL DISTRIB, V33, P271, DOI 10.1108/09590550510593202
   Grand View Research, 2020, VIRT REAL MARK SIZ S
   Grewal D, 2018, J MARKET EDUC, V40, P85, DOI 10.1177/0273475318755838
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   HOLBROOK MB, 1982, J CONSUM RES, V9, P132, DOI 10.1086/208906
   Huang W, 2021, J COMPUT ASSIST LEAR, V37, P745, DOI 10.1111/jcal.12520
   Jang JY, 2019, FASH TEXT, V6, DOI 10.1186/s40691-018-0166-9
   Javornik A, 2016, J RETAIL CONSUM SERV, V30, P252, DOI 10.1016/j.jretconser.2016.02.004
   Jiang ZH, 2007, INFORM SYST RES, V18, P454, DOI 10.1287/isre.1070.0124
   Jones MA, 2006, J BUS RES, V59, P974, DOI 10.1016/j.jbusres.2006.03.006
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim T., 2006, J COMPUT-MEDIAT COMM, DOI [10.1111/J.1083-6101.1997.TB00073.X/4080405, DOI 10.1111/J.1083-6101.1997.TB00073.X/4080405]
   Klein LR, 2003, J INTERACT MARK, V17, P41, DOI 10.1002/dir.10046
   Koufaris M, 2002, INFORM SYST RES, V13, P205, DOI 10.1287/isre.13.2.205.83
   Lau K, 2014, ADV EC BUS, V2, P92, DOI [10.13189/aeb.2014.020205, DOI 10.13189/AEB.2014.020205]
   Lau KW, 2019, VIRTUAL REAL-LONDON, V23, P255, DOI 10.1007/s10055-018-0362-3
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lee SY, 2003, PROC SPIE, V4756, P38, DOI 10.1117/12.497665
   Lombart C, 2020, COMPUT HUM BEHAV, V110, DOI 10.1016/j.chb.2020.106374
   Lombart C, 2012, J RETAIL CONSUM SERV, V19, P644, DOI 10.1016/j.jretconser.2012.08.007
   McCormick H, 2014, TEXT PROG, V46, P227, DOI 10.1080/00405167.2014.973247
   McKinsey, 2020, COVID 19 DIG TRANSF
   Moes A, 2017, HELIYON, V3, DOI 10.1016/j.heliyon.2017.e00336
   MORONEY WF, 1992, PROC NAECON IEEE NAT, P734, DOI 10.1109/NAECON.1992.220513
   Morotti E, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P338, DOI [10.1109/VRW50115.2020.0-202, 10.1109/VRW50115.2020.00074]
   Nah FFH, 2011, MIS QUART, V35, P731
   Othman MK, 2022, UNIVERSAL ACCESS INF, V21, P995, DOI 10.1007/s10209-021-00820-4
   Pallavicini F, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P195, DOI 10.1145/3341215.3355736
   Park M, 2018, FASH TEXT, V5, DOI 10.1186/s40691-018-0149-x
   Peukert C, 2019, J MANAGE INFORM SYST, V36, P755, DOI 10.1080/07421222.2019.1628889
   Pizzi G, 2019, COMPUT HUM BEHAV, V96, P1, DOI 10.1016/j.chb.2019.02.008
   Ricci M, 2023, P INT JOINT C MECH D, DOI 10.1007/978-3-031-15928-2_123
   Ricci M, 2022, IEEE INT SYMP M AU R, P938, DOI 10.1109/ISMAR-Adjunct57072.2022.00210
   Rosedale P, 2017, IEEE CONSUM ELECTR M, V6, P48, DOI 10.1109/MCE.2016.2614416
   Scarpi D, 2006, J FASH MARK MANAG, V10, P7, DOI 10.1108/13612020610651097
   Schnack A, 2019, FOOD RES INT, V117, P40, DOI 10.1016/j.foodres.2018.01.028
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   Schrepp Martin., 2019, USER EXPERIENCE QUES
   Shankar V, 2021, J RETAILING, V97, P13, DOI 10.1016/j.jretai.2020.10.006
   Shen BQ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311087
   Sheridan Thomas B, 1992, TELEROBOTICS AUTOMAT
   Statista Market Forecast, 2022, FASHN WORLDW
   van Herpen E, 2016, APPETITE, V107, P196, DOI 10.1016/j.appet.2016.07.033
   Venkatesh V, 2017, MIS QUART, V41, P83, DOI 10.25300/MISQ/2017/41.1.05
   Vrechopoulos AP, 2004, J RETAILING, V80, P13, DOI 10.1016/j.jretai.2004.01.006
   Wahlers RG, 1986, ACR N AM ADV
   Wakefield KL, 1998, J RETAILING, V74, P515, DOI 10.1016/S0022-4359(99)80106-7
   Waterlander WE, 2011, BMC PUBLIC HEALTH, V11, DOI 10.1186/1471-2458-11-589
   Waterlander WE, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.3774
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu HY, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0204-7
   Xi NN, 2021, J BUS RES, V134, P37, DOI 10.1016/j.jbusres.2021.04.075
   Xu JJ, 2014, MIS QUART, V38, P379, DOI 10.25300/MISQ/2014/38.2.03
NR 81
TC 4
Z9 4
U1 15
U2 39
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2281
EP 2296
DI 10.1007/s10055-023-00806-y
EA MAY 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000988560400001
PM 37360805
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Pini, V
   Orso, V
   Pluchino, P
   Gamberini, L
AF Pini, Valentina
   Orso, Valeria
   Pluchino, Patrik
   Gamberini, Luciano
TI Augmented grocery shopping: fostering healthier food purchases through
   AR
SO VIRTUAL REALITY
LA English
DT Article
DE Nutritional label; Food choices; Food facts; Augmented reality;
   Human-computer interaction
ID NUTRITION INFORMATION; REALITY; CONSUMERS; CHOICES; LABELS;
   VISUALIZATION; PRODUCTS; DECISION; IMPACT; CLAIMS
AB Food choices are intimately related to individual health. Therefore, the food we buy should be carefully chosen. However, grocery shopping is typically done in noisy environments, and food products usually present cluttered labels with dense texts that make it hard to properly evaluate relevant nutritional data. Augmented reality (AR) allows a shopper to visualize digitally generated contents onto real objects and to interact with them. In this experiment, we investigated the effects of delivering nutritional information using AR technology on food choices. To this end, we ran a between-participants laboratory experiment in which participants were asked to choose among the products available. The experimental group received the food-related information via AR, while the control group had ordinary access to food packaging. We found that AR technology facilitated the choice of healthier food items. Additionally, participants in the experimental group reported that they based their decisions on nutritional information rather than on the appearance of the package. The present work highlights how AR can be exploited to bring to the foreground information that would otherwise be hard to spot, thereby increasing the consumer's awareness of the overall characteristics of the product.
C1 [Pini, Valentina; Orso, Valeria; Pluchino, Patrik; Gamberini, Luciano] Univ Padua, Dept Gen Psychol, Padua, Italy.
   [Pluchino, Patrik; Gamberini, Luciano] Univ Padua, Human Inspired Technol Res Ctr, Padua, Italy.
C3 University of Padua; University of Padua
RP Gamberini, L (corresponding author), Univ Padua, Dept Gen Psychol, Padua, Italy.; Gamberini, L (corresponding author), Univ Padua, Human Inspired Technol Res Ctr, Padua, Italy.
EM luciano.gamberini@unipd.it
RI Pluchino, Patrik/HJP-0747-2023; Orso, Valeria/KUD-5651-2024
OI Pluchino, Patrik/0000-0002-8562-0123; Orso, Valeria/0000-0003-2334-2882
CR Ahn J, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808207
   Ameen N, 2021, COMPUT HUM BEHAV, V120, DOI 10.1016/j.chb.2021.106761
   Azlina Mokmin Nur Azlina Mohamed, 2020, ICEEL 2020: 2020 The 4th International Conference on Education and E-Learning, P193, DOI 10.1145/3439147.3439162
   Azman N, 2014, PROCD SOC BEHV, V130, P490, DOI 10.1016/j.sbspro.2014.04.057
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   BABIN BJ, 1994, J CONSUM RES, V20, P644, DOI 10.1086/209376
   Bailey R, 2019, HEALTH COMMUN, V34, P735, DOI 10.1080/10410236.2018.1434734
   Barakat M A., 2019, Journal of Marketing Management, V7, P120, DOI DOI 10.15640/JMM.V7N1A10
   Bauer JM, 2019, J CONSUM POLICY, V42, P3, DOI 10.1007/s10603-018-9387-y
   Bayu MZ, 2013, PROC TECH, V11, P396, DOI 10.1016/j.protcy.2013.12.208
   Bialkova S, 2016, APPETITE, V96, P38, DOI 10.1016/j.appet.2015.08.030
   Bonetti F., 2019, Augmented Reality and Virtual Reality, P3, DOI [10.1007/978-3-030-06246-0_1, DOI 10.1007/978-3-030-06246-0_1]
   Brengman Malaika, 2019, Virtual Reality, V23, P269, DOI 10.1007/s10055-018-0335-6
   Campos S, 2011, PUBLIC HEALTH NUTR, V14, P1496, DOI 10.1017/S1368980010003290
   Cannoosamy K, 2016, PROG NUTR, V18, P195
   Chanlin LJ, 2018, LIBRI, V68, P137, DOI 10.1515/libri-2017-0024
   Chylinski M, 2014, P ANZM ANN C 2014 AG, P1092
   Dacko SG, 2017, TECHNOL FORECAST SOC, V124, P243, DOI 10.1016/j.techfore.2016.09.032
   Duarte P, 2013, BRIT FOOD J, V115, P1233, DOI 10.1108/BFJ-10-2011-0272
   Enax L., 2015, Journal of Agricultural & Food Industrial Organization, V13, P15, DOI 10.1515/jafio-2015-0015
   Finkelstein EA, 2018, AM J CLIN NUTR, V107, P647, DOI 10.1093/ajcn/nqy014
   Freedman MR, 2010, J AM DIET ASSOC, V110, P1222, DOI 10.1016/j.jada.2010.05.002
   Fuchs K, 2019, MADIMA'19: PROCEEDINGS OF THE 5TH INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P7, DOI 10.1145/3347448.3357167
   Gajadur Dwijesh, 2020, 2020 3rd International Conference on Emerging Trends in Electrical, Electronic and Communications Engineering (ELECOM), P40, DOI 10.1109/ELECOM49001.2020.9297013
   Gutiérrez F, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P1738
   Hamlin R, 2016, NUTRIENTS, V8, DOI 10.3390/nu8060327
   Inman J., 2015, J MARKETING RES, V52, P10, DOI [10.1509/jmr.13.0270, DOI 10.1509/JMR.13.0270]
   Isley SC, 2017, ENVIRON RES LETT, V12, DOI 10.1088/1748-9326/aa6def
   ivic B., 2017, RES WORLD EC, V8, P49, DOI [10.5430/rwe.v8n2p49, DOI 10.5430/RWE.V8N2P49]
   Jiang HT, 2018, IEEE CONSUM ELECTR M, V7, P21, DOI 10.1109/MCE.2018.2797740
   Koenigstorfer J, 2014, PUBLIC HEALTH NUTR, V17, P2115, DOI 10.1017/S136898001300219X
   Kozup JC, 2003, J MARKETING, V67, P19, DOI 10.1509/jmkg.67.2.19.18608
   Krystallis A, 2008, FOOD QUAL PREFER, V19, P525, DOI 10.1016/j.foodqual.2007.12.005
   Kumar N, 2017, BRIT FOOD J, V119, P218, DOI 10.1108/BFJ-06-2016-0249
   Lam MC, 2021, VIRTUAL REAL-LONDON, V25, P695, DOI 10.1007/s10055-020-00484-0
   Ludwig Thomas, 2020, MuC'20: Proceedings of the Conference on Mensch und Computer, P291, DOI 10.1145/3404983.3405526
   Luomala HT, 2018, J RETAIL CONSUM SERV, V41, P305, DOI 10.1016/j.jretconser.2017.05.001
   Maleki S., 2020, Journal of Marketing Communications, V26, P836, DOI [10.1080/13527266.2019.1590855, DOI 10.1080/13527266.2019.1590855]
   Márquez JOA, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P180, DOI 10.1145/3383313.3412266
   McLean G, 2019, COMPUT HUM BEHAV, V101, P210, DOI 10.1016/j.chb.2019.07.002
   Mitra A, 2019, J CONSUM AFF, V53, P1443, DOI 10.1111/joca.12237
   Overweight and Obesity-BMI Statistics, 2021, US
   Pantano E, 2017, J RETAIL CONSUM SERV, V38, P81, DOI 10.1016/j.jretconser.2017.05.011
   Parasuraman A., 2000, J SERV RES-US, V2, P307, DOI DOI 10.1177/109467050024001
   Poushneh A, 2017, J RETAIL CONSUM SERV, V34, P229, DOI 10.1016/j.jretconser.2016.10.005
   Priporas CV, 2017, COMPUT HUM BEHAV, V77, P374, DOI 10.1016/j.chb.2017.01.058
   Ranjbarian Bahrain, 2010, International Journal of Business Innovation and Research, V4, P376, DOI 10.1504/IJBIR.2010.033353
   Roddiger T, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P440, DOI 10.1145/3267305.3267631
   Silayoi P., 2004, British Food Journal, V106, P607, DOI 10.1108/00070700410553602
   Silayoi P, 2007, EUR J MARKETING, V41, P1495, DOI 10.1108/03090560710821279
   Spagnolli A, 2014, LECT NOTES COMPUT SC, V8820, P87, DOI 10.1007/978-3-319-13500-7_7
   STEPTOE A, 1995, APPETITE, V25, P267, DOI 10.1006/appe.1995.0061
   Sumarwan U., 2017, J CONSUM SCI, V2, P26, DOI [10.29244/jcs.2.2.26-40, DOI 10.29244/JCS.2.2.26-40]
   Walczuch R, 2007, INFORM MANAGE-AMSTER, V44, P206, DOI 10.1016/j.im.2006.12.005
   Waltner G, 2015, LECT NOTES COMPUT SC, V9281, P425, DOI 10.1007/978-3-319-23222-5_52
   Watson A, 2020, INT J RETAIL DISTRIB, V48, P433, DOI 10.1108/IJRDM-06-2017-0117
   Yardimci H, 2022, EAT WEIGHT DISORD-ST, P1
NR 57
TC 2
Z9 2
U1 11
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2117
EP 2128
DI 10.1007/s10055-023-00792-1
EA APR 2023
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:000968725900001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Yu, KY
   Wen, SY
   Xu, WE
   Caon, M
   Baghaei, N
   Liang, HN
AF Yu, Kangyou
   Wen, Shaoyue
   Xu, Wenge
   Caon, Maurizio
   Baghaei, Nilufar
   Liang, Hai-Ning
TI Cheer for me: effect of non-player character audience feedback on older
   adult users of virtual reality exergames
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Audience feedback; Non-player characters; Exergames;
   Elderly users
ID PHYSICAL-ACTIVITY; SELF-EFFICACY; SOCIAL FACILITATION; HEALTH-BENEFITS;
   PERFORMANCE; BEHAVIOR; HEART; GAME
AB The presence of an audience and its feedback could affect people's performance and experience during an event, especially related to sports such as tennis or boxing. Similarly, in videogames, players' gameplay could be affected if there is an audience and its feedback in response to players' performance in the environment. The inclusion of an audience with non-player characters (NPC) is common in videogames in general. However, there is a limited exploration of the use of an NPC audience in virtual reality (VR) exergames, especially focusing on elderly players. To fill this gap, this work examines the effect of an NPC audience and its associated feedback (with/without) on elderly users of VR exergames. In a user study, we used 120 NPC in a virtual audience. Results showed that the presence of the NPC audience with responsive feedback led to higher performance (with a higher success rate of performing gesture actions, more successful combinations of actions (or combos for short) performed, and more opponent's combos prevented) and better gameplay experience (with higher levels of competence, autonomy, relatedness, immersion, and intuitive controls) of elderly players. Our results can help frame the design and engineering of VR exergames that are targeted at elderly users to help them have an enhanced gameplay experience and improve their health.
C1 [Yu, Kangyou; Wen, Shaoyue; Liang, Hai-Ning] Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
   [Yu, Kangyou] Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA USA.
   [Xu, Wenge] Birmingham City Univ, DMT Lab, Birmingham, England.
   [Caon, Maurizio] Univ Appl Sci & Arts Western Switzerland HES SO, Sch Management Fribourg, Fribourg, Switzerland.
   [Baghaei, Nilufar] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.
C3 Xi'an Jiaotong-Liverpool University; University of California System;
   University of California Santa Barbara; Birmingham City University;
   University of Queensland
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
EM haining.liang@xjtlu.edu.cn
RI Xu, Wenge/AAX-7883-2021
OI Xu, Wenge/0000-0001-7227-7437; Wen, Shaoyue/0000-0002-2481-8531; Caon,
   Maurizio/0000-0003-4050-4214; Liang, Hai-Ning/0000-0003-3600-8955;
   Baghaei, Nilufar/0000-0003-1776-7075
CR Aiello JR, 2001, GROUP DYN-THEOR RES, V5, P163, DOI 10.1037//1089-2699.5.3.163
   [Anonymous], 2014, CHI 14 EXTENDED ABST, DOI [DOI 10.1145/2559206.2574827, 10.1145/2559206.2574827]
   Bandura A, 2001, MEDIA PSYCHOL, V3, P265, DOI 10.1207/S1532785XMEP0303_03
   BANDURA A, 1982, AM PSYCHOL, V37, P122, DOI 10.1037/0003-066X.37.2.122
   Bandura A., 1997, SELF EFFICACY EXERCI
   Bindarwish J, 2006, PSYCHOL SPORT EXERC, V7, P41, DOI 10.1016/j.psychsport.2005.04.001
   Bird ML, 2015, JMIR SERIOUS GAMES, V3, DOI 10.2196/games.4275
   Birk MV, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P157, DOI 10.1145/3116595.3116608
   BOND CF, 1983, PSYCHOL BULL, V94, P265, DOI 10.1037/0033-2909.94.2.265
   BORG GAV, 1982, MED SCI SPORT EXER, V14, P377, DOI 10.1249/00005768-198205000-00012
   Deci EL, 1999, PSYCHOL BULL, V125, P627, DOI 10.1037/0033-2909.125.6.627
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Ducheneaut N., 2006, P SIGCHI C HUM FACT, DOI DOI 10.1145/1124772.1124834
   Escartí A, 1999, J APPL SPORT PSYCHOL, V11, P83, DOI 10.1080/10413209908402952
   FITZSIMMONS PA, 1991, RES Q EXERCISE SPORT, V62, P424, DOI 10.1080/02701367.1991.10607544
   Gernigon C, 2003, SPORT PSYCHOL, V17, P55, DOI 10.1123/tsp.17.1.55
   Goldspink DF, 2005, ERGONOMICS, V48, P1334, DOI 10.1080/00140130500101247
   Guan W, 2020, NEW ENGL J MED, V382, P1708, DOI 10.1056/NEJMoa2002032
   Haller JC, 2019, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2019), DOI 10.1145/3290688.3290752
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   ILGEN DR, 1979, J APPL PSYCHOL, V64, P349, DOI 10.1037/0021-9010.64.4.349
   Ioannou C, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300388
   Kappen D. L., 2014, P 1 ACM SIGCHI ANN S, P151
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim J, 2018, J MEDIA PSYCHOL-GER, V30, P29, DOI 10.1027/1864-1105/a000175
   Kim SY, 2014, COMPUT HUM BEHAV, V36, P376, DOI 10.1016/j.chb.2014.03.067
   Konstantinidis EI, 2016, IEEE J BIOMED HEALTH, V20, P189, DOI 10.1109/JBHI.2014.2378814
   Lai CC, 2020, J MICROBIOL IMMUNOL, V53, P404, DOI 10.1016/j.jmii.2020.02.012
   Larsen LH, 2013, GAMES HEALTH J, V2, P205, DOI 10.1089/g4h.2013.0036
   Mellecker R, 2013, GAMES HEALTH J, V2, P142, DOI 10.1089/g4h.2013.0022
   Mikus CR, 2012, MED SCI SPORT EXER, V44, P225, DOI 10.1249/MSS.0b013e31822ac0c0
   Monteiro D., 2020, INT C COMP AN SOC AG, P62
   Monteiro D, 2024, UNIVERSAL ACCESS INF, V23, P23, DOI 10.1007/s10209-023-00985-0
   Moreira NB, 2021, REJUV RES, V24, P28, DOI 10.1089/rej.2020.2302
   Nes BM, 2013, SCAND J MED SCI SPOR, V23, P697, DOI 10.1111/j.1600-0838.2012.01445.x
   Peng HT, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01620
   Peng W, 2012, MEDIA PSYCHOL, V15, P175, DOI 10.1080/15213269.2012.673850
   Queiroz B. M. de, 2017, Journal of Physical Education and Sport, V17, P740
   Rendon AA, 2012, AGE AGEING, V41, P549, DOI 10.1093/ageing/afs053
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Sherry JL, 2006, LEA COMMUN SER, P213
   Spittle B, 2021, INT SYM MIX AUGMENT, P415, DOI 10.1109/ISMAR-Adjunct54149.2021.00094
   Strojny PM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01252
   Subramanian S, 2020, GAMES HEALTH J, V9, P24, DOI 10.1089/g4h.2019.0082
   Taylor AH, 2004, J SPORT SCI, V22, P703, DOI 10.1080/02640410410001712421
   THOMAS S, 1992, CAN J SPORT SCI, V17, P338
   United Nations Department of Economic and Social Affairs Population Division, 2022, DESAPOP2022TRNO3 UN
   Warburton DER, 2006, CAN MED ASSOC J, V174, P801, DOI 10.1503/cmaj.051351
   Wenge Xu, 2020, CHI PLAY '20: Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play, P98, DOI 10.1145/3383668.3419958
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Xu WG, 2023, INT J HUM-COMPUT INT, V39, P1134, DOI 10.1080/10447318.2022.2098559
   Xu WG, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/29330
   Xu WG, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/17972
   Xu WG, 2020, GAMES HEALTH J, V9, P389, DOI 10.1089/g4h.2019.0130
   Xu WG, 2020, GAMES HEALTH J, V9, P405, DOI 10.1089/g4h.2019.0102
   Xu WG, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300674
   Xu Wenge, P 2021 CHI C HUM FAC, DOI [10.1145/3411764.3445801, DOI 10.1145/3411764.3445801]
   YANG CM, 2020, MEDICINE, V99, DOI DOI 10.1097/MD.0000000000021228
   Yu TC, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17072565
NR 60
TC 5
Z9 5
U1 3
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1887
EP 1903
DI 10.1007/s10055-023-00780-5
EA MAR 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000948098300001
PM 37360816
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Lee, CG
   Kwon, O
AF Lee, Chang-Gyu
   Kwon, Ohung
TI Identification of the difference threshold for curvature gain of
   redirected walking
SO VIRTUAL REALITY
LA English
DT Article
DE Redirected walking; Curvature gain; Difference threshold
ID INTENSITY DISCRIMINATION
AB Redirected walking was developed for users to experience a relatively large virtual space while walking in a relatively small real space. Then, follow-up studies were conducted to find the detection threshold (DT) in order to prevent the user from recognizing the redirection. Thanks to these studies, by limiting the redirection magnitude to be smaller than the DT, it was possible to prevent user from perceiving the redirection. However, there have been reports in some papers that the users perceived redirections smaller than the DT. Rapid changes between two different curvature gains within the detection thresholds might be detectable because the research that produced the detection thresholds did not examine when changes to the curvature gains might be noticed. While there are such reports, an in-depth study on the difference threshold of curvature gain has not yet been conducted. Therefore, in this paper, two psychophysical studies were conducted to find the difference threshold of curvature gain. We found the difference threshold of curvature gain obtained by combining the results of the two experiments. The result is applicable for reference curvature gains between 1.5 and 3.5 (?)/m.
C1 [Lee, Chang-Gyu; Kwon, Ohung] Korea Inst Ind Technol, Digital Transformat R&D Dept, 143 Hanggaulro, Ansan 15588, Gyeonggi Do, South Korea.
C3 Korea Institute of Industrial Technology (KITECH)
RP Lee, CG (corresponding author), Korea Inst Ind Technol, Digital Transformat R&D Dept, 143 Hanggaulro, Ansan 15588, Gyeonggi Do, South Korea.
EM cglee@kitech.re.kr; ohung@kitech.re.kr
OI Lee, Chang-Gyu/0000-0002-7500-1150
CR Nguyen A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281515
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bölling L, 2019, IEEE T VIS COMPUT GR, V25, P2032, DOI 10.1109/TVCG.2019.2899228
   BRADLEY A, 1986, VISION RES, V26, P991, DOI 10.1016/0042-6989(86)90155-0
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Cao AT, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P137, DOI [10.1109/VR46266.2020.1581044610731, 10.1109/VR46266.2020.00-72]
   Chang YC, 2021, IEEE ACCESS, V9, P145083, DOI 10.1109/ACCESS.2021.3118056
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Cho YH, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P448, DOI 10.1109/VR50410.2021.00068
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.1581490806361, 10.1109/VR46266.2020.00-71]
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   Gao PZ, 2020, INT SYM MIX AUGMENT, P639, DOI 10.1109/ISMAR50242.2020.00092
   Grechkin T., 2016, P ACM S APPL PERC, P113
   HANNA TE, 1986, J ACOUST SOC AM, V80, P1335, DOI 10.1121/1.394385
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Klein SA, 2001, PERCEPT PSYCHOPHYS, V63, P1421, DOI 10.3758/BF03194552
   Langbehn E, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343125
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lawless H.T., 2010, SENSORY EVALUATION F, V2nd, P19, DOI [10.1007/978-1-4419-6488-5_2, DOI 10.1007/978-1-4419-6488-5_2]
   Lee C, 2023, PUBLIC MONEY MANAGE, V43, P340, DOI 10.1080/09540962.2021.1966197
   Lee CMS, 2023, VIRTUAL REAL-LONDON, V27, P1571, DOI 10.1007/s10055-022-00728-1
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li YJ, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P95, DOI [10.1109/VR50410.2021.00030, 10.1109/ISHC54333.2021.00026]
   Macmillan N. A., 2004, DETECTION THEORY USE, DOI [DOI 10.4324/9781410611147, 10.4324/9781410611147]
   Matsumoto K, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365705
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/VR.2019.8797818, 10.1109/vr.2019.8797818]
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   RAAB DH, 1963, J ACOUST SOC AM, V35, P1053, DOI 10.1121/1.1918653
   Razzaque S., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P123
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   SIMPSON WA, 1995, J OPT SOC AM A, V12, P2555, DOI 10.1364/JOSAA.12.002555
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Zhang R., 2014, Proc. Proceedings of the 2nd ACM Symposium on Spatial User Interaction, P62
   Zhang R., 2013, Proc. Proceedings of the ACM Symposium on Applied Perception (SAP), P71
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 45
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1635
EP 1645
DI 10.1007/s10055-023-00763-6
EA FEB 2023
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000927585800001
DA 2024-07-18
ER

PT J
AU Lancere, L
   Jürgen, M
   Gapeyeva, H
AF Lancere, L.
   Juergen, M.
   Gapeyeva, H.
TI Mixed reality and sensor real-time feedback to increase muscle
   engagement during deep core exercising
SO VIRTUAL REALITY
LA English
DT Article
DE Real-time feedback; Mixed reality; Surface electromyography; Transversus
   abdominis; Multifidus; Pursed lip breathing
ID LOWER-LIMB AMPUTATION; LOW-BACK-PAIN; VIRTUAL-REALITY; DISABILITY; EMG;
   RELIABILITY; MOBILITY; BALANCE
AB In lower extremity amputee rehabilitation programs, difficult-to-master targeted activation of deep core muscles and pursed-lip breathing training are prescribed to treat poor movement quality and to improve recovery after amputation. Non-invasive wireless sensors and mixed reality (MR) technologies are proposed as a solution. The main aim was to validate a novel rehabilitation technology by exploring whether a combined verbal and visual mixed reality feedback (VF + MR) will initiate a greater change in muscle electrical activation magnitude compared to verbal feedback only (VF) during exercising. The second objective was to evaluate the effectiveness of specific exercise program targeted to engage specifically deep core muscles. Pre-post-test cross-over study involved electromyographic activity (EMG) analysis from Transversus Abdominis (TA) and Multifidus (MF) muscles and self-reported questionnaires to evaluate the efficiency of MR feedback. Anthropometric data, state of health, subjective low back pain (Oswestry Disability Index), and physical activity level (IPAQ) estimation were analysed. The data from 13 patients following unilateral transtibial and transfemoral amputation showed a significant EMG increase in (VF + MR) for Chair Lean (p = 0.03) and Bent Leg Raise (p = 0.0005) exercises for TA muscle. Even though there was no significant difference in Back Bridge and Side Plank exercises, 6 to 10 participants depending on the exercise, had an increase of EMG in the range of 50-400% for both - TA and MF muscles. The proposed solution has a high potential for increasing motivation, self-awareness, and muscle engagement during exercises, based on EMG and self-reported questionnaire data.
C1 [Lancere, L.] Vidzeme Univ Appl Sci, Sociotech Syst Engn Inst SSII, Cesu St 4, LV-4201 Valmiera, Latvia.
   [Juergen, M.; Gapeyeva, H.] East Tallinn Cent Hosp, Clin Med Rehabil, Parnu St 104, EE-11312 Tallinn, Estonia.
C3 Vidzeme University of Applied Sciences
RP Lancere, L (corresponding author), Vidzeme Univ Appl Sci, Sociotech Syst Engn Inst SSII, Cesu St 4, LV-4201 Valmiera, Latvia.
EM linda.lancere@va.lv
OI Lancere, Linda/0000-0003-0524-5106
FU European Regional Development Fund; Engaged and Entrepreneurial
   University as Driver for European Smart and Sustainable Regions
   (E3UDRES2) [1.1.1.2/VIAA/2/18/357]; Erasmus+ Programme of the European
   Union [101004069]
FX This research has been supported by a grant from the European Regional
   Development Fund Project No. 1.1.1.2/VIAA/2/18/357 "Design research for
   user-friendly guidance of complex whole-body rehabilitation for lower
   extremity amputees by means of extended reality and advanced wearables
   data processing" within the Activity 1.1.1.2 "Post-doctoral Research
   Aid". Publishing supported by Engaged and Entrepreneurial University as
   Driver for European Smart and Sustainable Regions (E3UDRES2), Project
   No. 101004069. Co-funded by the Erasmus+ Programme of the European
   Union.
CR Abdelraouf O. R., 2020, Bulletin of Faculty of Physical Therapy, V25, P1, DOI 10.1186/s43161-020-00003-x
   Abiko T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122303
   Angelucci A, 2020, PULMONOLOGY, V26, P221, DOI 10.1016/j.pulmoe.2019.11.006
   [Anonymous], PLUXWIRELESSBIOSIGNA
   Applegate ME, 2018, JMIR SERIOUS GAMES, V20, P1
   Benady A, 2021, FRONT BIOENG BIOTECH, V09, DOI 10.3389/fbioe.2021.632594
   Berni A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9071064
   Bilal OR, 2020, ADV MATER TECHNOL-US, V5, DOI 10.1002/admt.202000181
   Birckhead B, 2021, BMJ OPEN, V11, DOI 10.1136/bmjopen-2021-050545
   Birckhead B, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/11973
   Blana D, 2016, J ELECTROMYOGR KINES, V29, P21, DOI 10.1016/j.jelekin.2015.06.010
   Bockenhauer SE, 2007, J AM OSTEOPATH ASSOC, V107, P191
   Cancelliero-Gaiad KM, 2014, BRAZ J PHYS THER, V18, P291, DOI 10.1590/bjpt-rbf.2014.0042
   Porras DC, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00836-0
   Chen M, 2017, CRITERION RELATED VA
   Craig CLC, 2003, MED SCI SPORTS EXERC, V35, P1, DOI DOI 10.1249/01.MSS.0000078924.61453.FB
   Crasto Carlos Filipe Barbosa, 2019, J Phys Ther Sci, V31, P755, DOI 10.1589/jpts.31.755
   Dadario NB, 2021, J CLIN NEUROSCI, V94, P41, DOI 10.1016/j.jocn.2021.09.037
   Darnall BD, 2020, JMIR FORM RES, V4, DOI 10.2196/17293
   Davidson M, 2002, PHYS THER, V82, P8, DOI 10.1093/ptj/82.1.8
   Debarba HG, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P537, DOI 10.1109/VR.2018.8446368
   Emami F, 2018, MED ENG PHYS, V60, P39, DOI 10.1016/j.medengphy.2018.07.006
   Esposito ER, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171786
   Fadem SZ, 2008, BODY MASS INDEX AMPU
   Feldwieser FM, 2012, EUR SPINE J, V21, pS171, DOI 10.1007/s00586-012-2254-7
   Friel K, 2005, J REHABIL RES DEV, V42, P155, DOI 10.1682/JRRD.2004.08.0090
   Gailey RS, 2002, ARCH PHYS MED REHAB, V83, P613, DOI 10.1053/ampr.2002.32309
   Garcia LM, 2021, J MED INTERNET RES, V23, DOI 10.2196/26292
   García-Bravo S, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17228472
   Gentil P, 2017, PHYSIOL BEHAV, V179, P148, DOI 10.1016/j.physbeh.2017.06.004
   Granacher U, 2013, SPORTS MED, V43, P627, DOI 10.1007/s40279-013-0041-1
   Hersh A, 2021, HSS J, V17, P351, DOI 10.1177/15563316211028595
   Hodges PW, 2005, J BIOMECH, V38, P1873, DOI 10.1016/j.jbiomech.2004.08.016
   Ives JC, 2003, CLIN BIOMECH, V18, P543, DOI 10.1016/S0268-0033(03)00089-5
   Kaptein S, 2018, DISABIL REHABIL, V40, P883, DOI 10.1080/09638288.2016.1277401
   Ko Min-Joo, 2018, J Phys Ther Sci, V30, P504, DOI 10.1589/jpts.30.504
   Kohler F, 2009, PROSTHET ORTHOT INT, V33, P117, DOI 10.1080/03093640802652029
   Kuo YL, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18094487
   Lancere L, 2021, P 13 INT C DISABILIT, P11
   Larivière C, 2005, J ELECTROMYOGR KINES, V15, P200, DOI 10.1016/j.jelekin.2004.08.009
   Li X, 2020, BMC MUSCULOSKEL DIS, V21, DOI 10.1186/s12891-020-03565-y
   Li ZC, 2021, NEURAL PLAST, V2021, DOI 10.1155/2021/9975862
   Lin S, 2019, J REHABIL ASSIST TER, V6, DOI 10.1177/2055668319831631
   Liu LZ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122142
   Ma CZH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010195
   Macedo LG, 2012, PHYS THER, V92, P363, DOI 10.2522/ptj.20110290
   Marinou EA, 2020, 2020 IEEE 25 INT WOR, V2017, P1
   Martin Sagayam K, 2020, ANN EMERG TECHNOL CO, V4, P39
   Massetti T, 2018, J CENT NERV SYST DIS, V10, DOI 10.1177/1179573518813541
   Matjacic Z, 2003, PROSTHET ORTHOT INT, V27, P214, DOI 10.1080/03093640308726684
   Mfolse N, 2014, ADV PHYSIOTHER, V3, P128
   Microsoft I, HOL 2 TECHN SPEC
   Mundell BF, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0400-0
   Ortegon-Sarmiento T, 2020, SYMP VIRTUAL AUGMENT, P169, DOI 10.1109/SVR51698.2020.00037
   Patel K, 2016, MEDICINE, V95, DOI 10.1097/MD.0000000000004149
   Penelle B, 2014, ACM INT C P SER
   Penko Amanda L, 2017, Int J Exerc Sci, V10, P76
   Riel H, 2018, MED SCI SPORT EXER, V50, P28, DOI 10.1249/MSS.0000000000001412
   Sakpal Tushar Vijay, 2010, Perspect Clin Res, V1, P67
   Seo KyoChul, 2017, J Phys Ther Sci, V29, P465, DOI 10.1589/jpts.29.465
   Sivapuratharasu B, 2019, ARCH REHAB RES CLIN, V1, DOI 10.1016/j.arrct.2019.100007
   Stamm O, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00753-8
   Tack C, 2021, DISABIL REHABIL-ASSI, V16, P637, DOI 10.1080/17483107.2019.1688399
   Tonosu J, 2012, EUR SPINE J, V21, P1596, DOI 10.1007/s00586-012-2173-7
   Trujillo MS, 2020, J PAIN RES, V13, P3131, DOI 10.2147/JPR.S275312
   Tsai YW, 2018, ANN PHYS REHABIL MED, V61, pe483, DOI [10.1016/j.rehab.2018.05.1128, DOI 10.1016/J.REHAB.2018.05.1128]
   Vestering MM, 2005, INT J REHABIL RES, V28, P237, DOI 10.1097/00004356-200509000-00006
   Wan JJ, 2017, EXP MOL MED, V49, DOI 10.1038/emm.2017.194
   Wasser JG, 2020, DISABIL REHABIL, V42, P3713, DOI 10.1080/09638288.2019.1610507
   Williams Rua M., 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P748, DOI 10.1177/1071181319631140
   Willigenburg NW, 2010, EXP BRAIN RES, V203, P39, DOI 10.1007/s00221-010-2207-5
   Yuvarani G, 2020, RES J PHARM TECHNOLO, V13, P2563, DOI DOI 10.5958/0974-360X.2020.00456.4
   Zhang SS, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24550-5
NR 73
TC 2
Z9 2
U1 4
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3435
EP 3449
DI 10.1007/s10055-022-00726-3
EA JAN 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000907778600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, XR
   Chen, HX
AF Chen, Xinrun
   Chen, Hengxin
TI Emotion recognition using facial expressions in an immersive virtual
   reality application
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Emotion recognition; Data synthesis; Machine learning
AB Facial expression recognition (FER) is an important method to study and distinguish human emotions. In the virtual reality (VR) context, people's emotions are instantly and naturally triggered and mobilized due to the high immersion and realism of VR. However, when people are wearing head mounted display (HMD) VR equipment, the eye regions will be covered. The FER accuracy will be reduced if the eye region information is discarded. Therefore, it is necessary to obtain the information of eye regions using other methods. The main difficulty in FER in an immersive VR context is that the conventional FER methods depend on public databases. The image facial information in the public databases is complete, so these methods are difficult to directly apply to the VR context. To solve this problem, this paper designs and implements a solution for FER in the VR context as follows. A real facial expression database collection scheme in the VR context is implemented by adding an infrared camera and infrared light source to the HMD. A virtual database construction method is presented for FER in the VR context, which can improve the generalization of models. A deep network named the multi-region facial expression recognition model is designed for FER in the VR context.
C1 [Chen, Xinrun; Chen, Hengxin] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Chen, HX (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM 201914021020@cqu.edu.cn; chenhengxin@cqu.edu.cn
CR Ansado J, 2021, NEUROSCI BIOBEHAV R, V120, P583, DOI 10.1016/j.neubiorev.2020.05.018
   Ashir AM, 2020, NEURAL COMPUT APPL, V32, P6295, DOI 10.1007/s00521-019-04138-4
   Chen JY, 2019, J PARALLEL DISTR COM, V131, P97, DOI 10.1016/j.jpdc.2019.04.017
   Chen YH, 2019, PROC CVPR IEEE, P1841, DOI 10.1109/CVPR.2019.00194
   Chen Y, 2021, PROC CVPR IEEE, P7226, DOI 10.1109/CVPR46437.2021.00715
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Han S., 2016, ADV NEURAL INF PROCE, P109
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   Heidari M, 2022, Arxiv, DOI arXiv:2207.08518
   Hickson S, 2019, IEEE WINT CONF APPL, P1626, DOI 10.1109/WACV.2019.00178
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hurl B, 2020, IEEE INT VEH SYM, P341, DOI 10.1109/IV47402.2020.9304695
   Hurl B, 2019, IEEE INT VEH SYM, P2522, DOI 10.1109/IVS.2019.8813809
   Jiang YY, 2019, IEEE T VIS COMPUT GR, V25, P2886, DOI 10.1109/TVCG.2018.2865945
   Küntzler T, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.627561
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Liu C, 2021, IEEE ACCESS, V9, P18876, DOI 10.1109/ACCESS.2021.3054332
   Liu Deyin, 2022, ACM Trans. Multimedia Comput., Commun., Appl., V1, P1, DOI 10.1145/3522714
   Liu Y, 2020, IEEE T COGN DEV SYST, V12, P311, DOI 10.1109/TCDS.2019.2917711
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mavridou I, 2017, P IEEE VIRT REAL ANN, P441, DOI 10.1109/VR.2017.7892369
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Murugappan Murugappan, 2010, Journal of Biomedical Science & Engineering, V3, P390, DOI 10.4236/jbise.2010.34054
   Naqvi RA, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030587
   Nekrasov V, 2019, IEEE INT CONF ROBOT, P7101, DOI [10.1109/icra.2019.8794220, 10.1109/ICRA.2019.8794220]
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Olagoke AS, 2020, IEEE ACCESS, V8, P172892, DOI 10.1109/ACCESS.2020.3024568
   Pal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165554
   Prachyabrued M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P671, DOI [10.1109/VR.2019.8797705, 10.1109/vr.2019.8797705]
   Rani P, 2003, IEEE SYS MAN CYBERN, P4896
   Roberts M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10892, DOI 10.1109/ICCV48922.2021.01073
   Samadiani N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081863
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Specker A, 2021, IEEE COMPUT SOC CONF, P4168, DOI 10.1109/CVPRW53098.2021.00471
   Suzuki K, 2017, P IEEE VIRT REAL ANN, P177, DOI 10.1109/VR.2017.7892245
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thenmozhi M, 2020, ADV INTELL SYST COMP, V1056, P133, DOI 10.1007/978-981-15-0199-9_12
   Vaswani A, 2017, P ADV NEURAL INFORM, P30
   Wu L., 2022, P 31 INT JOINT C ART, P1465, DOI [10.24963/ijcai.2022/204, DOI 10.24963/IJCAI.2022/204]
   Wu Y, 2021, IEEE T COGN DEV SYST, V13, P865, DOI 10.1109/TCDS.2020.3003674
   Yao T, 2022, LECT NOTES COMPUT SC, V13685, P328, DOI 10.1007/978-3-031-19806-9_19
   Yi JZ, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105540
   Yu MJ, 2020, PATTERN RECOGN LETT, V131, P166, DOI 10.1016/j.patrec.2020.01.016
   Zamir SW, 2020, PROC CVPR IEEE, P2693, DOI 10.1109/CVPR42600.2020.00277
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao JF, 2018, VISUAL COMPUT, V34, P1461, DOI 10.1007/s00371-018-1477-y
   Zhao XM, 2016, IETE TECH REV, V33, P505, DOI 10.1080/02564602.2015.1117403
   Zhong L, 2015, IEEE T CYBERNETICS, V45, P1499, DOI 10.1109/TCYB.2014.2354351
   Zhu Y, 2019, PROC CVPR IEEE, P8848, DOI 10.1109/CVPR.2019.00906
NR 53
TC 3
Z9 3
U1 4
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1717
EP 1732
DI 10.1007/s10055-022-00720-9
EA NOV 2022
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA P8LM8
UT WOS:000886888000001
DA 2024-07-18
ER

PT J
AU Radhakrishnan, U
   Chinello, F
   Koumaditis, K
AF Radhakrishnan, Unnikrishnan
   Chinello, Francesco
   Koumaditis, Konstantinos
TI Investigating the effectiveness of immersive VR skill training and its
   link to physiological arousal
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive virtual reality; Skill training; Physiological arousal;
   Electro-dermal activity; Heart rate variability
ID HEAD-MOUNTED DISPLAYS; VIRTUAL-REALITY; SELF-EFFICACY; EDUCATION;
   STRESS; ENVIRONMENTS; PERFORMANCE; VARIABILITY; RESPONSES; SIMULATOR
AB This paper details the motivations, design, and analysis of a study using a fine motor skill training task in both VR and physical conditions. The objective of this between-subjects study was to (a) investigate the effectiveness of immersive virtual reality for training participants in the 'buzz-wire' fine motor skill task compared to physical training and (b) investigate the link between participants' arousal with their improvements in task performance. Physiological arousal levels in the form of electro-dermal activity (EDA) and ECG (Electrocardiogram) data were collected from 87 participants, randomly distributed across the two conditions. Results indicated that VR training is as good as, or even slightly better than, training in physical training in improving task performance. Moreover, the participants in the VR condition reported an increase in self-efficacy and immersion, while marginally significant differences were observed in the presence and the temporal demand (retrieved from NASA-TLX measurements). Participants in the VR condition showed on average less arousal than those in the physical condition. Though correlation analyses between performance metrics and arousal levels did not depict any statistically significant results, a closer examination of EDA values revealed that participants with lower arousal levels during training, across conditions, demonstrated better improvements in performance than those with higher arousal. These findings demonstrate the effectiveness of VR in training and the potential of using arousal and training performance data for designing adaptive VR training systems. This paper also discusses implications for researchers who consider using biosensors and VR for motor skill experiments.
C1 [Radhakrishnan, Unnikrishnan; Chinello, Francesco; Koumaditis, Konstantinos] Aarhus Univ, Dept Business Dev & Technol, Birk Centerpk 15, DK-7400 Herning, Denmark.
C3 Aarhus University
RP Radhakrishnan, U (corresponding author), Aarhus Univ, Dept Business Dev & Technol, Birk Centerpk 15, DK-7400 Herning, Denmark.
EM unnik@btech.au.dk; chinello@btech.au.dk; kkoumaditis@btech.au.dk
RI Radhakrishnan, Unnikrishnan/AAG-9763-2020; Chinello,
   Francesco/J-1914-2018
OI Radhakrishnan, Unnikrishnan/0000-0002-1175-732X; Koumaditis,
   Konstantinos/0000-0003-3963-2358; Chinello,
   Francesco/0000-0001-8166-8835
CR Abich J IV, 2021, VIRTUAL REAL-LONDON, V25, P919, DOI 10.1007/s10055-020-00498-8
   Adhanom IB, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3448304
   Aggarwal R, 2004, BRIT J SURG, V91, P1549, DOI 10.1002/bjs.4816
   [Anonymous], 2016, IEEE, DOI DOI 10.1109/QOMEX.2016.7498964
   Ashiri M, 2020, ANN BIOMED ENG, V48, P1241, DOI 10.1007/s10439-019-02446-3
   BANDURA A, 1986, J SOC CLIN PSYCHOL, V4, P359, DOI 10.1521/jscp.1986.4.3.359
   Binsch O, 2021, MIL PSYCHOL, V33, P182, DOI 10.1080/08995605.2021.1897494
   BJORK RA, 1974, COGNITIVE PSYCHOL, V6, P173, DOI 10.1016/0010-0285(74)90009-7
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Budini F, 2014, ARCH PHYS MED REHAB, V95, P705, DOI 10.1016/j.apmr.2013.11.002
   Butt AL, 2018, CLIN SIMUL NURS, V16, P25, DOI 10.1016/j.ecns.2017.09.010
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Cacioppo JT, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P1, DOI 10.2277/ 0521844711
   Calderon DP, 2016, NEUROSCI BIOBEHAV R, V68, P167, DOI 10.1016/j.neubiorev.2016.05.014
   Carlson P, 2015, IEEE T VIS COMPUT GR, V21, P770, DOI 10.1109/TVCG.2015.2393871
   Cebeci B, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1893
   Champseix R., 2021, J OPEN RES STW, V9, pNA, DOI [DOI 10.5334/JORS.305, 10.5334/jors.305]
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chiviacowsky S, 2005, RES Q EXERCISE SPORT, V76, P42
   Christou C. G., 2018, P INT C ART REAL TEL, P149
   Coban M, 2022, EDUC RES REV-NETH, V36, DOI 10.1016/j.edurev.2022.100452
   Collet C, 2005, BIOL PSYCHOL, V69, P195, DOI 10.1016/j.biopsycho.2004.07.003
   Collins J, 2019, INT SYM MIX AUGMENT, P351, DOI 10.1109/ISMAR.2019.00033
   Cuervo E, 2018, HOTMOBILE'18: PROCEEDINGS OF THE 19TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS & APPLICATIONS, P7, DOI 10.1145/3177102.3177115
   Dawson ME., 2017, Handbook of Psychophysiology, V4, P217, DOI [DOI 10.1017/9781107415782, 10.1017/9781107415782.010]
   Dawson ME, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P159, DOI 10.1017/cbo9780511546396.007
   Demetriou C, 2019, ANZ J SURG, V89, P1567, DOI 10.1111/ans.15475
   Diemer J, 2016, J ANXIETY DISORD, V37, P30, DOI 10.1016/j.janxdis.2015.10.007
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Gilgen-Ammann R, 2019, EUR J APPL PHYSIOL, V119, P1525, DOI 10.1007/s00421-019-04142-5
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Harvey C, 2021, VISUAL COMPUT, V37, P3, DOI 10.1007/s00371-019-01702-w
   Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368
   Hebert EP, 2021, PERCEPT MOTOR SKILL, V128, P2381, DOI 10.1177/00315125211036413
   Hofmann SM, 2021, ELIFE, V10, DOI [10.7554/eLife.64812, 10.7554/eLife.64812.sa0, 10.7554/eLife.64812.sa1, 10.7554/eLife.64812.sa2]
   Högberg J, 2019, USER MODEL USER-ADAP, V29, P619, DOI 10.1007/s11257-019-09223-w
   Homer BD, 2019, COGNITIVE DEV, V49, P20, DOI 10.1016/j.cogdev.2018.11.005
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Huber T, 2018, INT J COMPUT ASS RAD, V13, P281, DOI 10.1007/s11548-017-1686-2
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jain S., 2020, SYSTEMS ENG, V10, P127, DOI [10.1080/24725579.2019.1692263, DOI 10.1080/24725579.2019.1692263]
   Janelle CM, 2002, J SPORT SCI, V20, P237, DOI 10.1080/026404102317284790
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Khalfa S, 2002, NEUROSCI LETT, V328, P145, DOI 10.1016/S0304-3940(02)00462-7
   Khan R, 2019, ENDOSCOPY, V51, P653, DOI 10.1055/a-0894-4400
   Kim T., 1997, Journal of Computer-Mediated Communication, V3, P2, DOI DOI 10.1111/J.1083-6101.1997.TB00073.X
   Koumaditis K, 2020, IEEE COMPUT GRAPH, V40, P41, DOI 10.1109/MCG.2020.3006330
   Kreimeier J, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P289, DOI 10.1145/3316782.3321536
   Krogmeier C, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1883
   Kuan G, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00014
   Lagos O, 2019, THINGIVERSE
   Larmuseau C, 2020, BRIT J EDUC TECHNOL, V51, P1548, DOI 10.1111/bjet.12958
   Lehikko A., 2021, Journal of Interactive Learning Research, V32, P125
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Liebold B, 2017, MEDIA PSYCHOL, V20, P477, DOI 10.1080/15213269.2016.1206829
   Luvizutto GJ, 2022, HUM MOV, V23, P138, DOI 10.5114/hm.2022.109072
   MACKAY C, 1978, BRIT J SOC CLIN PSYC, V17, P283, DOI 10.1111/j.2044-8260.1978.tb00280.x
   Magill R.A., 2016, MOTOR LEARNING CONTR, V11
   Makowski D, 2021, BEHAV RES METHODS, V53, P1689, DOI 10.3758/s13428-020-01516-y
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   Makransky G, 2019, J COMPUT ASSIST LEAR, V35, P691, DOI 10.1111/jcal.12375
   Makransky G, 2017, COMPUT HUM BEHAV, V72, P276, DOI 10.1016/j.chb.2017.02.066
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Matthews G., 1991, HUM PERFORM, V4, P107
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Moses ZB, 2007, P ANN INT IEEE EMBS, P644
   Movahedi A, 2007, J MOTOR BEHAV, V39, P457, DOI 10.3200/JMBR.39.6.457-462
   Mullen G, 2021, TIMING TIME PERCEPT, V9, P377, DOI 10.1163/22134468-bja10034
   Munoz J.E., 2019, LNCS, V0057, P218, DOI [10.1007/ 978- 3- 030-27950- 9_12, DOI 10.1007/978-3-030-27950-9_12]
   Murcia-López M, 2018, IEEE T VIS COMPUT GR, V24, P1574, DOI 10.1109/TVCG.2018.2793638
   Orsila R, 2008, INT J OCCUP SAF ERGO, V14, P275, DOI 10.1080/10803548.2008.11076767
   Owens ME, 2015, J PSYCHOPATHOL BEHAV, V37, P296, DOI 10.1007/s10862-014-9454-x
   Pakarinen T, 2019, IEEE ENG MED BIO, P2191, DOI [10.1109/EMBC.2019.8857621, 10.1109/embc.2019.8857621]
   Parong J, 2021, J COMPUT ASSIST LEAR, V37, P226, DOI 10.1111/jcal.12482
   Patle DS, 2019, VIRTUAL REAL-LONDON, V23, P293, DOI 10.1007/s10055-018-0354-3
   Pavlidis I, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38727-z
   Pijeira-Díaz HJ, 2018, J COMPUT ASSIST LEAR, V34, P397, DOI 10.1111/jcal.12271
   PINTRICH PR, 1993, EDUC PSYCHOL MEAS, V53, P801, DOI 10.1177/0013164493053003024
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Potter R. F., 2012, Psychophysiological measurement and meaning: Cognitive and emotional processing of media
   Prabhu A, 2010, SURGERY, V147, P640, DOI 10.1016/j.surg.2010.01.007
   Pulijala Y, 2018, J ORAL MAXIL SURG, V76, P1065, DOI 10.1016/j.joms.2017.10.002
   Quick JA, 2017, J SURG EDUC, V74, P674, DOI 10.1016/j.jsurg.2017.01.007
   Radhakrishnan U, 2021, BEHAV INFORM TECHNOL, V40, P1310, DOI 10.1080/0144929X.2021.1954693
   Radhakrishnan U, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P625, DOI 10.1109/VRW52623.2021.00195
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Rangarajan K, 2020, J SURG EDUC, V77, P337, DOI 10.1016/j.jsurg.2019.09.006
   Read JCA, 2013, I-PERCEPTION, V4, P101, DOI 10.1068/i0565
   Renganayagalu SK, 2021, TECHNOL KNOWL LEARN, V26, P999, DOI 10.1007/s10758-020-09489-9
   Rubin DC, 2009, MEMORY, V17, P802, DOI 10.1080/09658210903130764
   Sakowitz SM, 2020, VIRTUAL REAL-LONDON, V24, P399, DOI 10.1007/s10055-019-00413-w
   Schachinger H, 2008, HORM BEHAV, V54, P258, DOI 10.1016/j.yhbeh.2008.03.013
   Schwarz Stephanie, 2020, NordiCHI '20: Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society, DOI 10.1145/3419249.3420182
   Shaffer F, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00258
   Shafti A, 2016, IEEE ENG MED BIO, P1894, DOI 10.1109/EMBC.2016.7591091
   Shakur SF, 2015, OPER NEUROSURG, V11, P420, DOI 10.1227/NEU.0000000000000853
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Slater M, 2006, PRESENCE-VIRTUAL AUG, V15, P553, DOI 10.1162/pres.15.5.553
   Sternad D, 2018, CURR OPIN BEHAV SCI, V20, P183, DOI 10.1016/j.cobeha.2018.01.004
   Storbeck J, 2008, SOC PERSONAL PSYCHOL, V2, P1824, DOI 10.1111/j.1751-9004.2008.00138.x
   Syrjämäki AH, 2020, COMPUT HUM BEHAV, V112, DOI 10.1016/j.chb.2020.106454
   Tai KH, 2022, COMPUT EDUC, V182, DOI 10.1016/j.compedu.2022.104458
   Terkildsen T, 2019, INT J HUM-COMPUT ST, V126, P64, DOI 10.1016/j.ijhcs.2019.02.006
   Tian F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256211
   Ünal AB, 2013, TRANSPORT RES F-TRAF, V21, P52, DOI 10.1016/j.trf.2013.09.004
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vallat R, 2018, J. Open Source Softw, V3, P1026, DOI [10.21105/joss.01026, DOI 10.21105/JOSS.01026]
   van Dooren M, 2012, PHYSIOL BEHAV, V106, P298, DOI 10.1016/j.physbeh.2012.01.020
   van Merriënboer JJG, 2010, MED EDUC, V44, P85, DOI 10.1111/j.1365-2923.2009.03498.x
   Ventura S, 2022, VIRTUAL REAL-LONDON, V26, P323, DOI 10.1007/s10055-021-00567-6
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Vrchewal, 2020, MEAS
   Wang CA, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.01029
   Waskom M., 2021, Journal of Open Source Software, V6, P3021, DOI [DOI 10.21105/JOSS.03021, 10.21105/JOSS.03021]
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Winther F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P738, DOI [10.1109/VR46266.2020.1580939036664, 10.1109/VR46266.2020.000-7]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu DR, 2010, IEEE T AFFECT COMPUT, V1, P109, DOI 10.1109/T-AFFC.2010.12
   Wulf G, 2010, MED EDUC, V44, P75, DOI 10.1111/j.1365-2923.2009.03421.x
   Wulfert E, 2005, PSYCHOL ADDICT BEHAV, V19, P311, DOI 10.1037/0893-164X.19.3.311
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
   Yerkes RM, 1908, J COMP NEUROL PSYCHO, V18, P459, DOI 10.1002/cne.920180503
   Yin J, 2019, INDOOR AIR, V29, P1028, DOI 10.1111/ina.12593
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
NR 132
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1091
EP 1115
DI 10.1007/s10055-022-00699-3
EA NOV 2022
PG 25
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000884538300002
PM 36405878
OA Bronze, Green Accepted, Green Published
DA 2024-07-18
ER

PT J
AU Kossmann, C
   Straatmann, T
   Mueller, K
   Hamborg, KC
AF Kossmann, Cosima
   Straatmann, Tammo
   Mueller, Karsten
   Hamborg, Kai-Christoph
TI Effects of enactment in virtual reality: a comparative experiment on
   memory for action
SO VIRTUAL REALITY
LA English
DT Article
DE Learning medium; Enactment effect; Actions; Memory performance; Learning
   by enactment; Experimental design
ID ORDER INFORMATION; ENVIRONMENTS; SUBJECT; EDUCATION; RECALL; ITEM; TOOL
AB Virtual reality (VR) is thought of as a promising educational medium, especially for learning actions, as it enables learning by enactment. Learning by enactment is associated with the enactment effect which describes a superior memory for enacted actions compared to actions which have not been enacted. To date, however, little is known about whether the enactment effect across different conditions of action learning can be found in VR which sets the stage for our first research question. Additionally, as a second research question, this study explores the extent to which the memory performance of learning by enactment in VR corresponds to learning by enactment in physical reality. We conducted a VR between subjects experiment with four groups (N = 112) that differed in terms of condition or environment. Participants were asked to remember short action phrases for a subsequent memory test. The results indicate that learning by enactment in VR outperforms learning by reading in VR but does not exceed observational learning in VR. Furthermore, the results demonstrate that the memory performance of learning by enactment in VR is similar to that in physical reality. These findings are highly relevant as they demonstrate the potential of VR as a new educational medium supporting learning by enactment.
C1 [Kossmann, Cosima; Straatmann, Tammo; Mueller, Karsten; Hamborg, Kai-Christoph] Osnabrueck Univ, Dept Ind & Org Psychol, Seminarstr 20, D-49074 Osnabruck, Germany.
C3 University Osnabruck
RP Kossmann, C (corresponding author), Osnabrueck Univ, Dept Ind & Org Psychol, Seminarstr 20, D-49074 Osnabruck, Germany.
EM cosima.kossmann@uni-osnabrueck.de
OI Muller, Karsten/0000-0001-7389-8024; Hamborg,
   Kai-Christoph/0000-0002-5868-755X; Kossmann, Cosima/0000-0001-6615-5185
FU Projekt DEAL; "Graduiertenkolleg va-eva: Vertrauen und Akzeptanz in
   erweiterte und virtuelle Realitaten" at Osnabrueck University
FX Open Access funding enabled and organized by Projekt DEAL. This research
   is funded by the "Graduiertenkolleg va-eva: Vertrauen und Akzeptanz in
   erweiterte und virtuelle Realitaten" at Osnabrueck University.
CR Albus P, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104154
   Alfalah SFM, 2018, EDUC INF TECHNOL, V23, P2633, DOI 10.1007/s10639-018-9734-2
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Alqahtani AS, 2017, INT J ADV COMPUT SC, V8, P77
   Anderson JR., 2013, The architecture of cognition, DOI [10.4324/9781315799438, DOI 10.4324/9781315799438]
   Bakar AA., 2021, COLLABORATION INTEGR, P305, DOI [10.1007/978-3-030-48465-1_51, DOI 10.1007/978-3-030-48465-1_51]
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Clark JM, 1991, EDUC PSYCHOL REV, V3, P149, DOI 10.1007/BF01320076
   COHEN RL, 1983, MEM COGNITION, V11, P575, DOI 10.3758/BF03198282
   COHEN RL, 1983, INTELLIGENCE, V7, P287, DOI 10.1016/0160-2896(83)90019-3
   COHEN RL, 1987, MEM COGNITION, V15, P109, DOI 10.3758/BF03197022
   COHEN RL, 1981, SCAND J PSYCHOL, V22, P267, DOI 10.1111/j.1467-9450.1981.tb00402.x
   Donalek C, 2014, IEEE INT CONF BIG DA, P609, DOI 10.1109/BigData.2014.7004282
   ENGELKAMP J, 1980, Z EXP ANGEW PSYCHOL, V27, P511
   Engelkamp J, 1997, ACTA PSYCHOL, V96, P43, DOI 10.1016/S0001-6918(97)00005-X
   Engelkamp J, 2000, J EXP PSYCHOL LEARN, V26, P671, DOI 10.1037/0278-7393.26.3.671
   Engelkamp J, 2003, PSYCHOL RES-PSYCH FO, V67, P280, DOI 10.1007/s00426-002-0118-1
   ENGELKAMP J, 1991, PSYCHOL RES-PSYCH FO, V53, P175, DOI 10.1007/BF00941384
   Engelkamp J., 1998, Memory for actions
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gamberini L, 2000, CYBERPSYCHOL BEHAV, V3, P337, DOI 10.1089/10949310050078779
   Gorini A, 2010, ANN GEN PSYCHIATR, V9, DOI 10.1186/1744-859X-9-30
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Hamilton D, 2021, J COMPUT EDUC, V8, P1, DOI 10.1007/s40692-020-00169-2
   Hirt C, 2019, IEEE ICCE, P337, DOI [10.1109/ICCE-Berlin47944.2019.8966169, 10.1109/icce-berlin47944.2019.8966169]
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Kaminska D, 2019, INFORMATION, V10, DOI 10.3390/info10100318
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kisker J, 2021, CURR PSYCHOL, V40, P3190, DOI 10.1007/s12144-019-00257-2
   Kisker J, 2021, PSYCHOL RES-PSYCH FO, V85, P68, DOI 10.1007/s00426-019-01244-9
   Leder J, 2019, SAFETY SCI, V111, P271, DOI 10.1016/j.ssci.2018.07.021
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   Makransky G, 2021, J EDUC PSYCHOL, V113, P719, DOI 10.1037/edu0000473
   Makransky G, 2019, J COMPUT ASSIST LEAR, V35, P691, DOI 10.1111/jcal.12375
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   Martin F, 2020, ETR&D-EDUC TECH RES, V68, P1613, DOI 10.1007/s11423-020-09812-2
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Paivio A., 1990, Mental representations: A dual coding approach, DOI [10.1093/acprof:oso/9780195066661.001.0001, DOI 10.1093/ACPROF:OSO/9780195066661.001.0001]
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Riva G., 2008, J. Cyber Ther. Rehabil, V1, P7
   Riva G, 2009, BRIT J GUID COUNS, V37, P337, DOI 10.1080/03069880902957056
   SALTZ E, 1981, J VERB LEARN VERB BE, V20, P322, DOI 10.1016/S0022-5371(81)90472-2
   Sauzéon H, 2012, EXP PSYCHOL, V59, P99, DOI 10.1027/1618-3169/a000131
   Schultheis MT, 2002, J HEAD TRAUMA REHAB, V17, P378, DOI 10.1097/00001199-200210000-00002
   Smith SA, 2019, PSYCHON B REV, V26, P1213, DOI 10.3758/s13423-019-01605-w
   Soós R, 2019, EPJ NUCL SCI TECHNOL, V5, DOI 10.1051/epjn/2019053
   Stamenov MaximI., 2002, MIRROR NEURONS EVOLU
   Steffens MC, 2007, PSYCHON B REV, V14, P1194, DOI 10.3758/BF03193112
   Steffens MC, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01907
   Straatmann T, 2022, WORK, V72, P1765, DOI 10.3233/WOR-211260
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Sweller J, 2011, EXPLOR LEARN SCI, P3, DOI 10.1007/978-1-4419-8126-4
   van der Meijden OAJ, 2009, SURG ENDOSC, V23, P1180, DOI 10.1007/s00464-008-0298-x
   von Stulpnagel R, 2016, J ARTIC SUPPORT NULL, V12
   Webster R, 2016, THESIS U ALABAMA BIR
   Wilson PN., 2013, HDB SPATIAL RES PARA, P187
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
   Zhou Y, 2018, PROCEDIA COMPUT SCI, V130, P239, DOI 10.1016/j.procs.2018.04.035
   Zimmer H.D., 2001, MEMORY ACTION DISTIN, P3
NR 65
TC 1
Z9 1
U1 2
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1025
EP 1038
DI 10.1007/s10055-022-00701-y
EA OCT 2022
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000870592300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Maneuvrier, A
   Ceyte, H
   Renaud, P
   Morello, R
   Fleury, P
   Decker, LM
AF Maneuvrier, A.
   Ceyte, H.
   Renaud, P.
   Morello, R.
   Fleury, P.
   Decker, L. M.
TI Virtual reality and neuropsychological assessment: an analysis of human
   factors influencing performance and perceived mental effort
SO VIRTUAL REALITY
LA English
DT Article
DE Sense of presence; Cybersickness; Field dependence-independence; Video
   game experience; Executive control of attention
ID INDUCED MOTION SICKNESS; IMMERSIVE TECHNOLOGY; SENSE; SUSCEPTIBILITY;
   ENVIRONMENTS; EXPOSURE; GENDER; EXPERIENCE; DEPENDENCE; VERTIGO
AB This study aimed to compare a neuropsychological test tapping into executive control function, the Wisconsin Card Sorting Test (WCST), performed in either traditional paper-and-pencil (PP) or virtual reality (VR) modality, and to determine the role of human factors (i.e., sense of presence, cybersickness, field (in)dependence and video game experience) as contributors to performance and perceived mental effort. Indeed, if virtual assessment might bring the ecological dimension to controlled laboratory research, it is often suggested that human factors might bias performance. WCST performance and its associated perceived mental effort were compared between the two modalities (N = 107). In the VR modality (N = 52), a correlation matrix was conducted as well as a cluster analysis in order to build two experimental groups, or profiles, based on their subjective experience of VR. WCST performance and perceived mental effort were then compared between these two groups while controlling for age and education. Results outlined a similar WCST performance and perceived mental effort between the PP and VR modalities. However, when comparing the two VR groups, results suggest that an unfavorable profile for VR, i.e., less sense of presence, more cybersickness, more visual field dependence and less video game experience, is associated with greater perceived mental effort. These experimental findings enable outlining a new conceptual and methodological framework for the assessment of executive control task performance in VR. Results could help users to take human factors into consideration in order to fully exploit or predict the benefits of this tool.
C1 [Maneuvrier, A.; Fleury, P.; Decker, L. M.] Normandie Univ, CIREVE, UNICAEN, F-14000 Caen, France.
   [Ceyte, H.] Univ Lorraine, DevAH, F-54000 Nancy, France.
   [Renaud, P.] Univ Quebec Outaouais, Dept Psychol, Gatineau, PQ, Canada.
   [Renaud, P.] Inst Philippe Pinel, LIF, Montreal, PQ, Canada.
   [Morello, R.] CHU Caen, UBRC, F-14000 Caen, France.
   [Decker, L. M.] Normandie Univ, GIP CYCERON, COMETE, INSERM,UNICAEN, F-14000 Caen, France.
   [Ceyte, H.] Aix Marseille Univ, ISM, CNRS, Marseille, France.
C3 Universite de Caen Normandie; Universite de Lorraine; University of
   Quebec; University Quebec Outaouais; Universite de Montreal; CHU de Caen
   NORMANDIE; Universite de Caen Normandie; Institut National de la Sante
   et de la Recherche Medicale (Inserm); Universite de Caen Normandie;
   Centre National de la Recherche Scientifique (CNRS); Aix-Marseille
   Universite
RP Maneuvrier, A (corresponding author), Normandie Univ, CIREVE, UNICAEN, F-14000 Caen, France.
EM arthur.maneuvrier@protonmail.com; hadrien.ceyte@univ-lorraine.fr;
   patrice.renaud@uno.ca; remy.morello@unicaen.fr;
   philippe.fleury@unicaen.fr; leslie.decker@unicaen.fr
RI CEYTE, Hadrien/HGD-8921-2022; Decker, Leslie Marion/IWU-7992-2023;
   Maneuvrier, Arthur/IQW-0291-2023; Decker, Leslie Marion/N-8923-2015
OI CEYTE, Hadrien/0000-0003-1746-5026; Maneuvrier,
   Arthur/0000-0002-1897-8643; Decker, Leslie Marion/0000-0003-2929-0761
CR Alsina-Jurnet I, 2010, INT J HUM-COMPUT ST, V68, P788, DOI 10.1016/j.ijhcs.2010.07.001
   [Anonymous], 1975, Motion sickness
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Aymerich-Franch L, 2010, CYBERPSYCH BEH SOC N, V13, P649, DOI 10.1089/cyber.2009.0412
   Bagust J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0065321
   Barfield W., 1995, VIRTUAL ENV ADV INTE, P473, DOI [DOI 10.1093/OSO/9780195075557.001.0001, 10.1093/oso/9780195075557.001.0001]
   Berg EA, 1948, J GEN PSYCHOL, V39, P15, DOI 10.1080/00221309.1948.9918159
   Bian YL, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384529
   BLOOMBERG M, 1965, PERCEPT MOTOR SKILL, V20, P805, DOI 10.2466/pms.1965.20.3.805
   Boccia M, 2016, EXP BRAIN RES, V234, P2799, DOI 10.1007/s00221-016-4682-9
   Bohil CJ, 2011, NAT REV NEUROSCI, V12, P752, DOI 10.1038/nrn3122
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Canning CG, 2020, NAT REV NEUROL, V16, P409, DOI 10.1038/s41582-020-0370-2
   Chardonnet JR, 2017, INT J HUM-COMPUT INT, V33, P771, DOI 10.1080/10447318.2017.1286767
   Chen C.J., 2009, THEMES SCI TECHNOLOG, V2, P71
   Christou C., 2010, Affective, Interactive and Cognitive Methods for E-learning Design: Creating an Optimal Education Experience, P228, DOI [10.4018/978-1-60566-940-3.ch012, DOI 10.4018/978-1-60566-940-3, 10.4018/978-1-60566-940-3.ch012., DOI 10.4018/978-1-60566-940-3.CH012]
   Cian C, 2011, AVIAT SPACE ENVIR MD, V82, P959, DOI 10.3357/ASEM.3049.2011
   Clernes SA, 2005, J BIOL RHYTHM, V20, P71, DOI 10.1177/0748730404272567
   Coelho C, 2009, EMERG COMMUN-STUD NE, V9, P25
   Cogné M, 2017, ANN PHYS REHABIL MED, V60, P164, DOI 10.1016/j.rehab.2015.12.004
   Coleman B, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01851
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   de la Rosa S, 2018, BRIT J PSYCHOL, V109, P427, DOI 10.1111/bjop.12302
   De Leo G, 2014, SIMUL HEALTHC, V9, P1, DOI 10.1097/SIH.0b013e3182a99dd9
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Di Cesare CS, 2015, GAIT POSTURE, V41, P198, DOI 10.1016/j.gaitpost.2014.09.027
   Draper JV, 1998, HUM FACTORS, V40, P354, DOI 10.1518/001872098779591386
   Draper JV, 1996, IEEE INT CONF ROBOT, P1030, DOI 10.1109/ROBOT.1996.506844
   Felnhofer A., 2012, P INT SOC PRESENCE R
   Freeman D, 2017, PSYCHOL MED, V47, P2393, DOI 10.1017/S003329171700040X
   Fulvio JM, 2021, ENTERTAIN COMPUT, V38, DOI 10.1016/j.entcom.2021.100423
   Gamito P., 2008, Annual Review of CyberTherapy and Telemedicine: Changing the Face of Healthcare, P83
   Gamito P, 2010, STUD HEALTH TECHNOL, V154, P128, DOI 10.3233/978-1-60750-561-7-128
   Gregg L, 2007, SOC PSYCH PSYCH EPID, V42, P343, DOI 10.1007/s00127-007-0173-4
   Gresty MA, 2008, AVIAT SPACE ENVIR MD, V79, P105, DOI 10.3357/ASEM.2143.2008
   Gresty MA, 2009, ANN NY ACAD SCI, V1164, P263, DOI 10.1111/j.1749-6632.2008.03744.x
   Guerraz M, 2001, BRAIN, V124, P1646, DOI 10.1093/brain/124.8.1646
   Hakkinen J., 2002, IEEE International Conference on Systems, Man and Cybernetics, V4, P147, DOI [DOI 10.1109/ICSMC.2002.1167964, 10.1109/ICSMC.2002.1167964]
   HAYES RW, 1972, PSYCHON SCI, V28, P243
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hecht D, 2007, CYBERPSYCHOL BEHAV, V10, P243, DOI 10.1089/cpb.2006.9962
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Hutmacher F, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02246
   JungHa Park, 2020, The International Journal of Advanced Culture Technology, V8, P89
   Kaminska D, 2019, INFORMATION, V10, DOI 10.3390/info10100318
   KENNEDY RS, 1975, AVIAT SPACE ENVIR MD, V46, P1349
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517707768
   Knight M. M., 2006, ACM SIGGRAPH 2006 Res Posters, DOI [10.1145/1179622.1179846, DOI 10.1145/1179622.1179846]
   Kober SE, 2013, INT J HUM-COMPUT INT, V29, P13, DOI 10.1080/10447318.2012.668131
   Kopp B, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9060141
   Lachlan K, 2011, COMMUN RES REP, V28, P27, DOI 10.1080/08824096.2010.518924
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Lange F, 2018, NEUROSCI BIOBEHAV R, V93, P38, DOI 10.1016/j.neubiorev.2018.06.014
   Leung T, 2018, ARXIV
   Levine SC, 2016, WIRES COGN SCI, V7, P127, DOI 10.1002/wcs.1380
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Loup G, 2019, INT J HUM-COMPUT INT, V35, P1270, DOI 10.1080/10447318.2018.1519164
   MACLEOD CM, 1986, INTELLIGENCE, V10, P141, DOI 10.1016/0160-2896(86)90011-5
   Mahboobin A, 2005, EXP BRAIN RES, V167, P260, DOI 10.1007/s00221-005-0053-7
   Maneuvrier A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.706712
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   MILNER B, 1963, ARCH NEUROL-CHICAGO, V9, P90, DOI 10.1001/archneur.1963.00460070100010
   Minderer M, 2016, NATURE, V533, P324, DOI 10.1038/nature17899
   Nash EB, 2000, INT J HUM-COMPUT INT, V12, P1, DOI 10.1207/S15327590IJHC1201_1
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Nori R, 2023, CURR PSYCHOL, V42, P4567, DOI 10.1007/s12144-021-01788-3
   North Max M., 2016, Australasian Journal of Information Systems, V20, P1
   Paillard AC, 2013, J VESTIBUL RES-EQUIL, V23, P203, DOI 10.3233/VES-130501
   Palmisano S, 2018, EXP BRAIN RES, V236, P315, DOI 10.1007/s00221-017-5130-1
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Pantelidis VS., 2009, THEMES SCI TECHNOLOG, V2, P59
   Parsons TD, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7040042
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Persky S, 2009, CYBERPSYCHOL BEHAV, V12, P263, DOI 10.1089/cpb.2008.0262
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Riva G., 2003, PRESENCE CONNECT, V3
   Riva G, 2006, BEING IN THE WORLD W
   Riva G., 2015, Immersed in Media, P73, DOI DOI 10.1007/978-3-319-10190-3_5
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Riva G, 2011, NEW IDEAS PSYCHOL, V29, P24, DOI 10.1016/j.newideapsych.2009.11.002
   Robillard G., 2002, 25E CONGRES ANNUEL S
   Scozzari S, 2011, STUD COMPUT INTELL, V337, P63
   Sheppard AL, 2018, BMJ OPEN OPHTHALMOL, V3, DOI 10.1136/bmjophth-2018-000146
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Sheridan TB, 1996, PRESENCE-TELEOP VIRT, V5, P241, DOI 10.1162/pres.1996.5.2.241
   Sheridan TB, 2016, PRESENCE-TELEOP VIRT, V25, P75, DOI 10.1162/PRES_e_00247
   Singer MJ, 1995, ARITR1034
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Souchet AD, 2022, INT J HUM-COMPUT INT, V38, P801, DOI 10.1080/10447318.2021.1976509
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Stanney KM, 2002, HUM PERFORM, V15, P339, DOI 10.1207/S15327043HUP1504_03
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Strózak P, 2018, INT J AEROSP PSYCHOL, V28, P31, DOI 10.1080/24721840.2018.1486195
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Ukai K, 2008, DISPLAYS, V29, P106, DOI 10.1016/j.displa.2007.09.004
   Varmaghani S, 2022, VIRTUAL REAL-LONDON, V26, P659, DOI 10.1007/s10055-021-00535-0
   Weech S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.00010
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Welch RB, 1999, PRESENCE-TELEOP VIRT, V8, P574, DOI 10.1162/105474699566387
   Wirth W, 2012, MEDIA PSYCHOL, V15, P19, DOI 10.1080/15213269.2011.648536
   Witkin H.-A., 1962, Psychological differentiation: studies of development, P418
   Witkin H.A., 1954, PERSONALITY PERCEPTI
   WITKIN HA, 1949, J PERS, V18, P145, DOI 10.1111/j.1467-6494.1949.tb01237.x
   WITKIN HA, 1977, REV EDUC RES, V47, P1
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 117
TC 4
Z9 4
U1 5
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 849
EP 861
DI 10.1007/s10055-022-00698-4
EA SEP 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000856592600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shankhwar, K
   Smith, S
AF Shankhwar, Kalpana
   Smith, Shana
TI An interactive extended reality-based tutorial system for fundamental
   manual metal arc welding training
SO VIRTUAL REALITY
LA English
DT Article
DE Extended reality; Virtual reality; Mixed reality; Manual metal arc
   welding; Visual aids; Quantitative guidance
ID AUGMENTED REALITY; PROCESS PARAMETERS; VIRTUAL-REALITY; PENETRATION;
   BEAD
AB Extended reality (XR) technology has been proven an effective human-computer interaction tool to increase the perception of presence. The purpose of this study is to develop an interactive XR-based welding tutorial system to enhance the learning and hands-on skills of novice welders. This study is comprised of two parts: (1) fundamental manual metal arc welding (MMAW) science and technology tutoring in a virtual reality (VR)-based environment, and (2) hands-on welding training in a mixed reality (MR)-based environment. Using the developed tutorial system, complicated welding process and the effects of welding process parameters on weld bead geometry can be clearly observed and comprehended by using a 3D interactive user interface. Visual aids and quantitative guidance are displayed in real time to guide novice welders through the correct welding procedure and help them to maintain a proper welding position. A user study was conducted to evaluate the learnability, workload, and usability of the system. Results show that users obtained significantly better performance by using the XR-based welding tutorial system, compared to those who were trained using the conventional classroom training method.
C1 [Shankhwar, Kalpana; Smith, Shana] Natl Taiwan Univ, Dept Mech Engn, Taipei, Taiwan.
C3 National Taiwan University
RP Smith, S (corresponding author), Natl Taiwan Univ, Dept Mech Engn, Taipei, Taiwan.
EM ssmith@ntu.edu.tw
RI Shankhwar, Dr. Kalpana/HGA-6640-2022
FU Ministry of Science and Technology of Taiwan [MOST
   108-2221-E-002-161-MY2]
FX The authors would like to thank the Ministry of Science and Technology
   of Taiwan for financially supporting this research under contract MOST
   108-2221-E-002-161-MY2.
CR Ahmed AN, 2018, NEURAL COMPUT APPL, V29, P889, DOI 10.1007/s00521-016-2496-0
   Andrews Christopher, 2019, Curr Treat Options Cardiovasc Med, V21, P18, DOI 10.1007/s11936-019-0722-7
   Arvanitis TN, 2009, PERS UBIQUIT COMPUT, V13, P243, DOI 10.1007/s00779-007-0187-7
   Boob A.N., 2013, INT J M ENG RES, V3, P1493
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Byrd AP, 2015, WELD J, V94, p389S
   CLARK JN, 1985, MATER SCI TECH SER, V1, P1069, DOI 10.1179/mst.1985.1.12.1069
   Derisma, 2020, International Journal of Interactive Mobile Technologies, V14, P182, DOI 10.3991/ijim.v14i09.13123
   Di Natale AF, 2020, BRIT J EDUC TECHNOL, V51, P2006, DOI 10.1111/bjet.13030
   Doolani S, 2020, TECHNOLOGIES, V8, DOI 10.3390/technologies8040077
   Ejaz A, 2019, INT J ADV COMPUT SC, V10, P209
   Emuejevoke Omajene J, 2014, International Journal of Mechanical Engineering and Applications, V2, P128, DOI [10.11648/j.ijmea.20140206.17, DOI 10.11648/J.IJMEA.20140206.17]
   Eyres DJ, 2012, SHIP CONSTRUCTION, 7TH EDITION, P1
   Feier AI, 2021, ACTA TECH NAPOC SER-, V64, P117
   Gonzalez-Franco M, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00003
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Heirman J, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P266, DOI 10.1109/AIVR50618.2020.00055
   Hietanen A, 2020, ROBOT CIM-INT MANUF, V63, DOI 10.1016/j.rcim.2019.101891
   Huang TK, 2018, KAOHSIUNG J MED SCI, V34, P243, DOI 10.1016/j.kjms.2018.01.009
   Huerta O, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 3: IVAPP, P306, DOI 10.5220/0007566003060313
   Jeffus L., 2020, WELDING PRINCIPLES A
   Roldán JJ, 2019, ROBOT CIM-INT MANUF, V59, P305, DOI 10.1016/j.rcim.2019.05.004
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Karadeniz E, 2007, MATER DESIGN, V28, P649, DOI 10.1016/j.matdes.2005.07.014
   Kuo CY, 2021, COMPUT IND, V132, DOI 10.1016/j.compind.2021.103502
   Lavrentieva OO, 2019, CEUR WORKSHOP PROCEE, V2547, P201
   Lenin N., 2010, THAMMASAT INT J SCI, V15, P1
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Loureiro SandraMaria Correia., 2020, Spanish Journal of Marketing - ESIC, DOI [DOI 10.1108/SJME-01-2020-0013, 10.1108/sjme-01-2020-0013]
   Maas MJ, 2020, TECHNOL PEDAGOG EDUC, V29, P231, DOI 10.1080/1475939X.2020.1737210
   Macariu Camelia, 2020, Procedia Computer Science, V176, P2133, DOI 10.1016/j.procs.2020.09.250
   Mandal N.R., 2001, Aluminum Welding
   Mandal NR., 2009, WELDING TECHNIQUES D
   Matsas E, 2018, ROBOT CIM-INT MANUF, V50, P168, DOI 10.1016/j.rcim.2017.09.005
   Mavrikios D, 2006, INT J COMPUT INTEG M, V19, P294, DOI 10.1080/09511920500340916
   Milovanovic J., 2017, P 17 INT C CAAD FUT
   Nagesh DS, 2002, J MATER PROCESS TECH, V123, P303, DOI 10.1016/S0924-0136(02)00101-2
   Okimoto MLLR, 2015, PROCEDIA MANUF, V3, P6223, DOI 10.1016/j.promfg.2015.07.739
   Pomerantz J., 2019, Information and Technology Transforming Lives: Connection, Interaction, Innovation, P137
   Regazzoni D, 2018, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2018, VOL 1B
   Saha A, 2017, MEASUREMENT, V102, P80, DOI 10.1016/j.measurement.2017.01.048
   Taggart R., 1980, SHIP DESIGN CONSTRUC
   Tang YM, 2020, VIRTUAL REAL-LONDON, V24, P797, DOI 10.1007/s10055-020-00427-9
   Tewari S.P., 2010, International Journal of Engineering Science and Technology, V2, P512
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
NR 46
TC 3
Z9 3
U1 3
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1173
EP 1192
DI 10.1007/s10055-022-00626-6
EA JAN 2022
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000745411900001
DA 2024-07-18
ER

PT J
AU Oriti, D
   Manuri, F
   De Pace, F
   Sanna, A
AF Oriti, Damiano
   Manuri, Federico
   De Pace, Francesco
   Sanna, Andrea
TI Harmonize: a shared environment for extended immersive entertainment
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Collaborative environments; Immersive entertainment;
   Immersive environments; Shared environments; Virtual reality
ID VIRTUAL-REALITY; FRAMEWORK
AB Virtual reality (VR) and augmented reality (AR) applications are very diffuse nowadays. Moreover, recent technology innovations led to the diffusion of commercial head-mounted displays for immersive VR: users can enjoy entertainment activities that fill their visual fields, experiencing the sensation of physical presence in these virtual immersive environments. Even if AR and VR are mostly used separately, they can be effectively combined to provide a multi-user shared environment (SE), where two or more users perform some specific tasks in a cooperative or competitive way, providing a wider set of interactions and use cases compared to immersive VR alone. However, due to the differences between the two technologies, it is difficult to develop SEs offering a similar experience for both AR and VR users. This paper presents Harmonize, a novel framework to deploy applications based on SEs with a comparable experience for both AR and VR users. Moreover, the framework is hardware-independent, and it has been designed to be as much extendable to novel hardware as possible. An immersive game has been designed to test and to evaluate the validity of the proposed framework. The assessment of the system through the System Usability Scale questionnaire and the Game Experience Questionnaire shows a positive evaluation.
C1 [Oriti, Damiano; Manuri, Federico; De Pace, Francesco; Sanna, Andrea] Politecn Torino, Dipartimento Automat & Informat, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
C3 Polytechnic University of Turin
RP Oriti, D (corresponding author), Politecn Torino, Dipartimento Automat & Informat, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
EM damiano.oriti@polito.it
RI De Pace, Francesco/S-6346-2019; Sanna, Andrea/AAQ-4730-2020
OI De Pace, Francesco/0000-0001-8772-4105; SANNA,
   Andrea/0000-0001-7916-1699; MANURI, FEDERICO/0000-0002-6599-9949
FU Politecnico di Torino within the CRUI-CARE Agreement
FX Open access funding provided by Politecnico di Torino within the
   CRUI-CARE Agreement.
CR Anthes C, 2006, LECT NOTES COMPUT SC, V4208, P894
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Behr J, 2011, VIRTUAL REALITY & AUGMENTED REALITY IN INDUSTRY, P91
   Beznosyk, 2011, P 10 INT C VIRT REAL, DOI [10.1145/2087756.2087812, DOI 10.1145/2087756.2087812]
   Blonna R, 2018, 2018 IEEE REGION TEN SYMPOSIUM (TENSYMP), P118, DOI 10.1109/TENCONSpring.2018.8692018
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bozzelli Guido, 2019, Digital Applications in Archaeology and Cultural Heritage, V15, DOI 10.1016/j.daach.2019.e00124
   Broll W, 1997, P IEEE VIRT REAL ANN, P121, DOI 10.1109/VRAIS.1997.583053
   Casarin Julien, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274298
   Casarin J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139140
   Claypool M, 2003, IEEE IPCCC, P263
   Cohen J., 1988, STAT POWER ANAL BEHA
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Getchell K, 2010, IEEE T LEARN TECHNOL, V3, P281, DOI 10.1109/TLT.2010.25
   GrandViewResearch, 2020, VIRT REAL GAM MARK S
   IJsselsteijn WijnandA., 2013, GAME EXPERIENCE QUES, V46
   Izadi Shahram, 2011, KinectFusion: Real-time 3D Reconstruction and Interaction using a Moving Depth Camera, P559
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Kelso J, 2002, P IEEE VIRT REAL ANN, P183, DOI 10.1109/VR.2002.996521
   Langlotz T, 2011, COMPUT GRAPH-UK, V35, P831, DOI 10.1016/j.cag.2011.04.004
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mossel A., 2012, Int. J. Virtual Real, V11, P1, DOI [10.20870/IJVR.2012.11.3.2845, DOI 10.20870/IJVR.2012.11.3.2845]
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   North Max M., 2016, Australasian Journal of Information Systems, V20, P1
   Ohlenburg J, 2004, MORGAN FRAMEWORK ENA, P166, DOI [10.1145/1077534.1077568, DOI 10.1145/1077534.1077568]
   Pinz A, 2002, OGAI J, V21
   Ponder M, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P96
   Raaen K, 2015, LECT NOTES COMPUT SC, V9353, P457, DOI 10.1007/978-3-319-24589-8_40
   Ratti S, 2010, IEEE INTERNET COMPUT, V14, P60, DOI 10.1109/MIC.2010.57
   Rubio-Tamayo Jose Luis, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040021
   Schulze JP, 2013, PROC SPIE, V8649, DOI 10.1117/12.2005241
   Scott, 2017, FLUID INTERFACES
   Tomczak M., 2014, NEED REPORT EFFECT S, DOI DOI 10.1186/S13054-016-1208-6
   Zhang MH, 2019, ACM SIGGRAPH 2019 APPY HOUR (SIGGRAPH '19), P3, DOI 10.1145/3305365.3329732
NR 36
TC 9
Z9 9
U1 7
U2 33
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3259
EP 3272
DI 10.1007/s10055-021-00585-4
EA OCT 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000705798400001
PM 34642567
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Wenk, N
   Penalver-Andres, J
   Buetler, KA
   Nef, T
   Müri, RM
   Marchal-Crespo, L
AF Wenk, N.
   Penalver-Andres, J.
   Buetler, K. A.
   Nef, T.
   Muri, R. M.
   Marchal-Crespo, L.
TI Effect of immersive visualization technologies on cognitive load,
   motivation, usability, and embodiment
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive Virtual Reality; Augmented Reality; Cognitive Load;
   Motivation; Usability; Embodiment
ID VIRTUAL-REALITY; AUGMENTED REALITY; RUBBER HAND; PREMOTOR CORTEX; HAPTIC
   GUIDANCE; STROKE PATIENTS; REHABILITATION; PERFORMANCE; OWNERSHIP; TOUCH
AB Virtual reality (VR) is a promising tool to promote motor (re)learning in healthy users and brain-injured patients. However, in current VR-based motor training, movements of the users performed in a three-dimensional space are usually visualized on computer screens, televisions, or projection systems, which lack depth cues (2D screen), and thus, display information using only monocular depth cues. The reduced depth cues and the visuospatial transformation from the movements performed in a three-dimensional space to their two-dimensional indirect visualization on the 2D screen may add cognitive load, reducing VR usability, especially in users suffering from cognitive impairments. These 2D screens might further reduce the learning outcomes if they limit users' motivation and embodiment, factors previously associated with better motor performance. The goal of this study was to evaluate the potential benefits of more immersive technologies using head-mounted displays (HMDs). As a first step towards potential clinical implementation, we ran an experiment with 20 healthy participants who simultaneously performed a 3D motor reaching and a cognitive counting task using: (1) (immersive) VR (IVR) HMD, (2) augmented reality (AR) HMD, and (3) computer screen (2D screen). In a previous analysis, we reported improved movement quality when movements were visualized with IVR than with a 2D screen. Here, we present results from the analysis of questionnaires to evaluate whether the visualization technology impacted users' cognitive load, motivation, technology usability, and embodiment. Reports on cognitive load did not differ across visualization technologies. However, IVR was more motivating and usable than AR and the 2D screen. Both IVR and AR rea ched higher embodiment level than the 2D screen. Our results support our previous finding that IVR HMDs seem to be more suitable than the common 2D screens employed in VR-based therapy when training 3D movements. For AR, it is still unknown whether the absence of benefit over the 2D screen is due to the visualization technology per se or to technical limitations specific to the device.
C1 [Wenk, N.; Penalver-Andres, J.; Buetler, K. A.; Marchal-Crespo, L.] Univ Bern, ARTORG Ctr Biomed Engn Res, Motor Learning & Neurorehabil Lab, Bern, Switzerland.
   [Nef, T.; Muri, R. M.] Univ Bern, ARTORG Ctr Biomed Engn Res, Gerontechnol & Rehabil, Bern, Switzerland.
   [Muri, R. M.] Univ Bern, Univ Hosp Bern Inselspital, Univ Neurorehabil, Dept Neurol, Bern, Switzerland.
   [Marchal-Crespo, L.] Delft Univ Technol, Dept Cognit Robot, Delft, Netherlands.
C3 University of Bern; University of Bern; University of Bern; University
   Hospital of Bern; Delft University of Technology
RP Wenk, N (corresponding author), Univ Bern, ARTORG Ctr Biomed Engn Res, Motor Learning & Neurorehabil Lab, Bern, Switzerland.
EM nicolas.wenk@artorg.unibe.ch
RI Marchal-Crespo, Laura/AAA-1373-2019; Buetler, Karin/AAW-7001-2020;
   Penalver-Andres, Joaquin/HIZ-8827-2022; Mueri, Rene Martin/KHU-4328-2024
OI Marchal-Crespo, Laura/0000-0002-8008-5803; Buetler,
   Karin/0000-0002-4251-2149; Mueri, Rene Martin/0000-0001-6990-4188;
   Penalver-Andres, Joaquin/0000-0001-8181-7538
FU Universitat Bern; Swiss National Science Foundation [PP00P2 163800];
   Swiss National Center of Competence in Research (NCCR Robotics); Swiss
   National Science Foundation (SNF) [PP00P2_163800] Funding Source: Swiss
   National Science Foundation (SNF)
FX Open Access funding provided by Universitat Bern. This work was
   partially supported by the Swiss National Science Foundation through the
   grant PP00P2 163800, the Swiss National Center of Competence in Research
   (NCCR Robotics), and the B.Braun Foundation.
CR Ach N.K., 1935, Handbuch der Biologischen Arbeitsmethoden, Abt, V6, P460
   Alizadehsalehi S, 2023, SMART SUSTAIN BUILT, V12, P200, DOI 10.1108/SASBE-01-2021-0016
   Alizadehsalehi S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073225
   Alizadehsalehi S, 2020, AUTOMAT CONSTR, V116, DOI 10.1016/j.autcon.2020.103254
   Andrews Christopher, 2019, Curr Treat Options Cardiovasc Med, V21, P18, DOI 10.1007/s11936-019-0722-7
   [Anonymous], 2002, SOCIAL LIFE AVATARS, DOI DOI 10.1007/978-1-4471-0277-9_8
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Bailey JO, 2017, COGNITIVE DEVELOPMENT IN DIGITAL CONTEXTS, P181, DOI 10.1016/B978-0-12-809481-5.00009-2
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banerjee NT, 2021, VIRTUAL REAL-LONDON, V25, P399, DOI 10.1007/s10055-020-00462-6
   Basalp E, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00074
   Baumeister J, 2017, IEEE T VIS COMPUT GR, V23, P2378, DOI 10.1109/TVCG.2017.2735098
   Bernardoni F, 2019, INT C REHAB ROBOT, P760, DOI [10.7892/boris.131921, 10.1109/ICORR.2019.8779420]
   Blanke O, 2012, NAT REV NEUROSCI, V13, P556, DOI 10.1038/nrn3292
   Boeldt D, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00773
   Born F, 2019, INT CONF GAMES VIRTU, P25, DOI 10.1109/vs-games.2019.8864579
   Borrego A, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.01061
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Braun N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00535
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Cabeza R, 2001, SCAND J PSYCHOL, V42, P277, DOI 10.1111/1467-9450.00237
   Charles D., 2020, BIOMEDICAL VISUALISA
   Giglioli IAC, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02529
   Christou CG, 2018, VIRTUAL REALITY LOOP, P8
   Condino S, 2020, IEEE T BIO-MED ENG, V67, P411, DOI 10.1109/TBME.2019.2914517
   Crespo LM, 2008, J MOTOR BEHAV, V40, P545, DOI 10.3200/JMBR.40.6.545-557
   Cyr AA, 2009, J CLIN EXP NEUROPSYC, V31, P472, DOI 10.1080/13803390802255627
   Monteiro CBD, 2014, RES DEV DISABIL, V35, P2430, DOI 10.1016/j.ridd.2014.06.006
   Dias P, 2019, IEEE COMPUT GRAPH, V39, P64, DOI 10.1109/MCG.2018.2875630
   Dominguez-Tellez P, 2020, GAMES HEALTH J, V9, P1, DOI 10.1089/g4h.2019.0043
   dos Santos LF, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0289-4
   Ehrsson HH, 2005, J NEUROSCI, V25, P10564, DOI 10.1523/JNEUROSCI.0800-05.2005
   Ehrsson HH, 2004, SCIENCE, V305, P875, DOI 10.1126/science.1097011
   Elor A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2018), P219, DOI 10.1109/SMARTCOMP.2018.00094
   Fagard J, 2015, LATERALITY, V20, P543, DOI 10.1080/1357650X.2015.1009089
   Faria BM, 2013, ASSIST TECHNOL, V25, P88, DOI 10.1080/10400435.2012.723297
   Frokjaer E., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P345, DOI 10.1145/332040.332455
   Gamito P., 2014, Int. J. Disabil. Hum. Dev, V13, P337, DOI [10.1515/ijdhd-2014-0325, DOI 10.1515/IJDHD-2014-0325]
   Gamito P, 2017, DISABIL REHABIL, V39, P385, DOI 10.3109/09638288.2014.934925
   George C, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188686
   Gerber SM, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00287
   Gerber SM, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13153-1
   Gerig N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0189275
   Gobron SC, 2015, LECT NOTES COMPUT SC, V9254, P199, DOI 10.1007/978-3-319-22888-4_15
   Grechuta K, 2017, SCI REP-UK, V7, DOI [10.1038/s41598-017-15016-1, 10.1038/s41598-017-03488-0]
   Haans A, 2008, BODY IMAGE, V5, P389, DOI 10.1016/j.bodyim.2008.04.003
   Haggard P, 2009, CURR DIR PSYCHOL SCI, V18, P242, DOI 10.1111/j.1467-8721.2009.01644.x
   Harris PA, 2009, J BIOMED INFORM, V42, P377, DOI 10.1016/j.jbi.2008.08.010
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Hondori HM, 2016, NEUROREHAB NEURAL RE, V30, P258, DOI 10.1177/1545968315593805
   Hu Y., 2008, Motivation, usability and their interrelationships in a self-paced online learning environment
   Huygelier H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41200-6
   Juliano JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041204
   Jung J, 2012, J PHYS THER SCI, V24, P1133, DOI 10.1589/jpts.24.1133
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Keshner EA, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.641650
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Knobel SEJ, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00180
   Koumpouros Y, 2016, J HEALTHC ENG, V2016, DOI 10.1155/2016/1048964
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00342
   Krichenbauer M, 2018, IEEE T VIS COMPUT GR, V24, P1038, DOI 10.1109/TVCG.2017.2658570
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Lee CH, 2014, HONG KONG PHYSIOTHER, V32, P51, DOI 10.1016/j.hkpj.2014.04.002
   Lee JH, 2003, CYBERPSYCHOL BEHAV, V6, P383, DOI 10.1089/109493103322278763
   Lee SH, 2020, PM&R, V12, P257, DOI 10.1002/pmrj.12206
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Llorens R, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0029-1
   Longo L, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199661
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Longo UG, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073253
   Lungu AJ, 2021, EXPERT REV MED DEVIC, V18, P47, DOI 10.1080/17434440.2021.1860750
   Maclean N, 2000, SOC SCI MED, V50, P495
   Maclean N, 2000, BMJ-BRIT MED J, V321, P1051, DOI 10.1136/bmj.321.7268.1051
   Maier M, 2019, FRONT SYST NEUROSCI, V13, DOI 10.3389/fnsys.2019.00074
   Marchal-Crespo L, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00061
   Marchal-Crespo L, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00019
   Marchal-Crespo L, 2013, EXP BRAIN RES, V231, P277, DOI 10.1007/s00221-013-3690-2
   Matamala-Gomez M, 2021, J CLIN MED, V10, DOI 10.3390/jcm10010139
   Mekbib DB, 2020, BRAIN INJURY, V34, P456, DOI 10.1080/02699052.2020.1725126
   Meyer JT, 2019, INT C REHAB ROBOT, P1159, DOI [10.1109/ICORR.2019.8779527, 10.3929/ethz-b-000360416]
   Mondellini M, 2018, P 2018 IEEE 6 INT C, P1, DOI DOI 10.1109/SEGAH.2018.8401313
   Mutterlein J, 2017, P 25 EUR C INF SYST, P12
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Nijenhuis SM, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0080-y
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Odermatt IA, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.678909
   Özen Ö, 2020, P IEEE RAS-EMBS INT, P1223, DOI 10.1109/BioRob49111.2020.9224317
   Oing Theodore, 2018, JMIR Serious Games, V6, pe10965, DOI 10.2196/10965
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oshima K, 2016, P IEEE VIRT REAL ANN, P253, DOI 10.1109/VR.2016.7504749
   Otto M, 2019, PROC CIRP, V81, P785, DOI 10.1016/j.procir.2019.03.195
   PAAS FGWC, 1992, J EDUC PSYCHOL, V84, P429, DOI 10.1037/0022-0663.84.4.429
   Parger M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281529
   Park DC, 2009, ANNU REV PSYCHOL, V60, P173, DOI 10.1146/annurev.psych.59.103006.093656
   Patel B., 2015, Management of post-stroke complications, P277
   Pavani F, 2000, PSYCHOL SCI, V11, P353, DOI 10.1111/1467-9280.00270
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Perez-Marcos D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02120
   Perez-Marcos Daniel, 2012, Front Neurol, V3, P110, DOI 10.3389/fneur.2012.00110
   Bezerra IMP, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000009612
   Pourmand A, 2018, CURR PAIN HEADACHE R, V22, DOI 10.1007/s11916-018-0708-2
   Prabhakaran S, 2008, NEUROREHAB NEURAL RE, V22, P64, DOI 10.1177/1545968307305302
   Putrino D, 2017, GAMES HEALTH J, V6, P295, DOI 10.1089/g4h.2016.0108
   Radder Bob, 2016, J Rehabil Assist Technol Eng, V3, p2055668316670553, DOI 10.1177/2055668316670553
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Reynolds L., 2007, Handbook of Research on Electronic Surveys and Measurements, P170
   Riener R., 2012, Virtual Reality in Medicine, DOI [DOI 10.1007/978-1-4471-4011-5, 10.1007/978-1-4471-4011-5]
   Riva G, 2020, EXPERT REV MED DEVIC, V17, P1035, DOI 10.1080/17434440.2020.1825939
   Rivera-Flor H, 2019, PROCEDIA COMPUT SCI, V160, P641, DOI 10.1016/j.procs.2019.11.034
   Rizzo JR, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00227
   Robert MT, 2018, DEV MED CHILD NEUROL, V60, P382, DOI 10.1111/dmcn.13688
   Rocha R., 2016, NEW ADV INFORM SYSTE
   Rohrbach N, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0546-4
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Schultheis MT, 2001, REHABIL PSYCHOL, V46, P296, DOI 10.1037/0090-5550.46.3.296
   Schweighofer N, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0428-1
   Shibuya SS, 2018, NEUROPSYCHOLOGIA, V111, P77, DOI 10.1016/j.neuropsychologia.2018.01.023
   Sigrist R, 2013, PSYCHON B REV, V20, P21, DOI 10.3758/s13423-012-0333-8
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Sokolov AA, 2020, CURR OPIN NEUROL, V33, P239, DOI 10.1097/WCO.0000000000000791
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Subramanian SK, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-36
   Swanson LR, 2015, GAMES HEALTH J, V4, P253, DOI 10.1089/g4h.2014.0074
   Theingi S, 2022, J COGN ENHANCE, V6, P108, DOI 10.1007/s41465-021-00212-9
   Trempe M, 2012, J EXP PSYCHOL LEARN, V38, P52, DOI 10.1037/a0024883
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   Weber LM, 2019, AM J PHYS MED REHAB, V98, P783, DOI 10.1097/PHM.0000000000001190
   Wenk N., 2020, VIRTUAL REALITY HLTH
   Wenk N, 2019, INT C REHAB ROBOT, P1037, DOI [10.1109/ICORR.2019.8779366, 10.1109/icorr.2019.8779366]
   Widmer M., 2016, PROGR BRAIN RES MOTI
   WISE SP, 1985, ANNU REV NEUROSCI, V8, P1, DOI 10.1146/annurev.ne.08.030185.000245
   Wulf G, 2016, PSYCHON B REV, V23, P1382, DOI 10.3758/s13423-015-0999-9
   Zeller D, 2016, NEUROIMAGE, V138, P266, DOI 10.1016/j.neuroimage.2016.05.065
   Zhan T, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101397
NR 140
TC 31
Z9 32
U1 10
U2 61
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 307
EP 331
DI 10.1007/s10055-021-00565-8
EA AUG 2021
PG 25
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000685398400001
PM 36915633
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Chaudary, B
   Pohjolainen, S
   Aziz, S
   Arhippainen, L
   Pulli, P
AF Chaudary, Babar
   Pohjolainen, Sami
   Aziz, Saima
   Arhippainen, Leena
   Pulli, Petri
TI Teleguidance-based remote navigation assistance for visually impaired
   and blind people-usability and user experience
SO VIRTUAL REALITY
LA English
DT Article
DE Visual impairment; Navigation assistance; Remote assistance;
   Teleguidance; Haptic; Voice-based communication
ID TRAVEL AIDS; INSIGHT; SYSTEM; DESIGN
AB This paper reports the development of a specialized teleguidance-based navigation assistance system for the blind and the visually impaired. We present findings from a usability and user experience study conducted with 11 blind and visually impaired participants and a sighted caretaker. Participants sent live video feed of their field of view to the remote caretaker's terminal from a smartphone camera attached to their chest. The caretaker used this video feed to guide them through indoor and outdoor navigation scenarios using a combination of haptic and voice-based communication. Haptic feedback was provided through vibrating actuators installed in the grip of a Smart Cane. Two haptic methods for directional guidance were tested: (1) two vibrating actuators to guide left and right movement and (2) a single vibrating actuator with differentiating vibration patterns for the same purpose. Users feedback was collected using a meCUE 2.0 standardized questionnaire, interviews, and group discussions. Participants' perceptions toward the proposed navigation assistance system were positive. Blind participants preferred vibrational guidance with two actuators, while partially blind participants preferred the single actuator method. Familiarity with cane use and age were important factors in the choice of haptic methods by both blind and partially blind users. It was found that smartphone camera provided sufficient field of view for remote assistance; position and angle are nonetheless important considerations. Ultimately, more research is needed to confirm our preliminary findings. We also present an expanded evaluation model developed to carry out further research on assistive systems.
C1 [Chaudary, Babar; Pohjolainen, Sami; Pulli, Petri] Univ Oulu, Fac Informat Technol & Elect Engn, OASIS Res Unit, POB 3000, Oulu 90014, Finland.
   [Arhippainen, Leena] Univ Oulu, Fac Informat Technol & Elect Engn, INTERACT Res Unit, POB 8000, Oulu 90014, Finland.
C3 University of Oulu; University of Oulu
RP Chaudary, B (corresponding author), Univ Oulu, Fac Informat Technol & Elect Engn, OASIS Res Unit, POB 3000, Oulu 90014, Finland.
EM babar.chaudary@oulu.fi; sami.pohjolainen@oulu.fi;
   sci.choasaidan@punjab-zameen.gov.pk; leena.arhippainen@oulu.fi;
   petri.pulli@oulu.fi
OI Pohjolainen, Sami/0000-0002-4429-4245
FU University of Oulu; Oulu University Hospital; A UniOGS Travel grant
FX Open access funding provided by University of Oulu including Oulu
   University Hospital. This work was supported by the Scholarship Fund of
   the University of Oulu. A UniOGS Travel grant was awarded for the first
   author's PhD studies.
CR [Anonymous], 2021, APPL WATCH
   [Anonymous], 2009, 9241 210 2010 ERGONO, DOI DOI 10.3403/30388991
   Arhippainen, 2009, THESIS U OULU
   Avila M., 2016, ACM INT C P SER 29 J, P1, DOI DOI 10.1145/2910674.2935839
   Balata J, 2014, J MULTIMODAL USER IN, V8, P175, DOI 10.1007/s12193-013-0137-9
   Balata J, 2012, 3RD IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFOCOMMUNICATIONS (COGINFOCOM 2012), P769
   Baranski P, 2015, C HUM SYST INTERACT, P173, DOI 10.1109/HSI.2015.7170662
   Benjamin J M Jr, 1974, Bull Prosthet Res, P443
   Bevan N., 2009, P WORKSH UXEM CIT, V9, P1
   Bhatlawande S, 2014, IEEE T NEUR SYS REH, V22, P1148, DOI 10.1109/TNSRE.2014.2324974
   Bhowmick A, 2017, J MULTIMODAL USER IN, V11, P149, DOI 10.1007/s12193-016-0235-6
   Bourne RRA, 2017, LANCET GLOB HEALTH, V5, pE888, DOI 10.1016/S2214-109X(17)30293-0
   Bujacz M., 2008, 2008 Conference on Human System Interactions, P888, DOI 10.1109/HSI.2008.4581561
   Calder DJ, 2009, IEEE INTL CONF IND I, P149, DOI 10.1109/INDIN.2009.5195794
   Cardillo E, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111281
   Chaudary B, 2021, PROC CONF OPEN INNOV, P55, DOI 10.23919/FRUCT50888.2021.9347650
   Dell N., 2012, P SIGCHI C HUMAN FAC, P1321, DOI [DOI 10.1145/2207676.2208589, 10.1145/2207676.2208589]
   Diaz-Oreiro I., 2019, MULTIDISCIPLINARY DI, V31, P14, DOI DOI 10.3390/PROCEEDINGS2019031014
   Forlizzi J, 2008, INT J DES, V2, P11
   GARAJ V., 2003, British Journal of Visual Impairment, V21, P55
   Gori M, 2016, NEUROSCI BIOBEHAV R, V69, P79, DOI 10.1016/j.neubiorev.2016.06.043
   Guan WJ, 2020, EUR RESPIR J, V55, DOI [10.1183/13993003.00547-2020, 10.1183/13993003.00597-2020, 10.1371/journal.pone.0240308]
   Hassenzahl M., 2003, AttrakDiff: Ein FragebogenZur Messung Wahrgenommener Hedonischer Und Pragmatischer Qual-itat, P187, DOI [DOI 10.1007/978-3-322-80058-9_19, 10.1007/978-3-322-80058-9_19]
   Helal A, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P149, DOI 10.1109/ISWC.2001.962119
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Hevner R., 2007, Scandinavian Journal of Information Systems, V19, P4
   Humanware, TREKK 3 0 GPS OR SYS
   Islam MM, 2019, IEEE SENS J, V19, P2814, DOI 10.1109/JSEN.2018.2890423
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Kim SY, 2013, J INT J DES, V7
   Library of Congress, WHAT IS GPS DOES IT
   Loomis J.M., 2007, APPL SPATIAL COGNITI, P179
   Loomis JM, 2005, J VISUAL IMPAIR BLIN, V99, P219, DOI 10.1177/0145482x0509900404
   Lumsden J., 2008, HDB RES USER INTERFA, P982
   Majrashi K, 2015, P 5 INT C COMP SCI E, P43
   Marston JamesR., 2006, ACM T APPL PERCEPT, V3, P110, DOI [DOI 10.1145/1141897.1141900, 10.1145/1141897.1141900]
   Maude DR., 1983, J VISUAL IMPAIR BLIN, V77, P74
   Minge M., 2016, The meCUE Questionnaire: A Modular Tool for Measuring User Experience, V486, P115, DOI DOI 10.1007/978-3-319-41685-4_11
   Minge M, 2018, LECT NOTES COMPUT SC, V10918, P451, DOI 10.1007/978-3-319-91797-9_33
   Mostaghel R, 2016, J BUS RES, V69, P4896, DOI 10.1016/j.jbusres.2016.04.049
   National Research Council, 1986, EL TRAV AIDS NEW DIR, DOI [10.17226/1011, DOI 10.17226/1011]
   Nicolás JCO, 2011, INT CONF ENG DES, V7, P182
   Ojamo M, 2018, FINNISH REGISTER VIS
   Paajala IJ, 2015, INT SYM MED INFORM, P64, DOI 10.1109/ISMICT.2015.7107499
   Petrie H., 1997, J BR J VIS IMPAIR, V15, P63, DOI [10.1177/026461969701500205, DOI 10.1177/026461969701500205]
   Pohjolainen S, 2020, THESIS U OULU
   Pohjolainen S, 2020, 13 ICDVRAT ITAG SERP
   Ponchillia PE, 2007, J VISUAL IMPAIR BLIN, V101, P389, DOI 10.1177/0145482X0710100702
   Riemer-Reiss ML, 2000, J REHABIL, V66, P44
   Ripat J, 2011, DISABIL REHABIL-ASSI, V6, P87, DOI 10.3109/17483107.2010.507859
   Ripat JD, 2017, WORK, V57, P455, DOI 10.3233/WOR-172580
   Roentgen U.R., 2008, J. Vis. Impair. Blind, V102, P702, DOI [DOI 10.1177/0145482X0810201105, 10.1177/0145482X0810201105]
   Roentgen UR, 2012, ASSIST TECHNOL, V24, P110, DOI 10.1080/10400435.2012.659794
   Roto V., 2011, BRING CLAR CONC US E
   Sanyaolu Adekunle, 2020, SN Compr Clin Med, V2, P1069, DOI 10.1007/s42399-020-00363-4
   Schrepp M, 2019, RES REPORT
   Tet Kun Chung, 2015, International Journal of Computer Theory and Engineering, V7, P167, DOI 10.7763/IJCTE.2015.V7.950
   Vermeeren Arnold POS, 2010, P 6 NORD C HUM COMP, P521, DOI [DOI 10.1145/1868914.1868973, 10.1145/1868914, DOI 10.1145/1868914]
NR 58
TC 18
Z9 18
U1 6
U2 23
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 141
EP 158
DI 10.1007/s10055-021-00536-z
EA MAY 2021
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000653585300001
PM 34054327
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Magdin, M
   Balogh, Z
   Reichel, J
   Francisti, J
   Koprda, S
   György, M
AF Magdin, Martin
   Balogh, Zoltan
   Reichel, Jaroslav
   Francisti, Jan
   Koprda, Stefan
   Gyorgy, Molnar
TI Automatic detection and classification of emotional states in virtual
   reality and standard environments (LCD): comparing valence and arousal
   of induced emotions
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality (VR); Emotions; Classification; Valence; Arousal
ID IDENTIFICATION; SYSTEM
AB The following case study was carried out on a sample of one experimental and one control group. The participants of the experimental group watched the movie section from the standardized LATEMO-E database via virtual reality (VR) on Oculus Rift S and HTC Vive Pro devices. In the control group, the movie section was displayed on the LCD monitor. The movie section was categorized according to Ekman's and Russell's classification model of evoking an emotional state. The range of valence and arousal was determined in both observed groups. Valence and arousal were measured in each group using a Self-Assessment Manikin (SAM). The control group was captured by a camera and evaluated by Affdex software from Affectiva in order to compare valence values. The control group showed a very high correlation (0.92) between SAM and Affdex results. Having considered the Affdex results as a reference value, it can be concluded that SAM participants evaluated their emotions objectively. The results from both groups show that the movie section is supposed to evoke negative emotion. Negative emotion was perceived more intensely than its counterpart, positive emotion. Using virtual reality to evoke negative emotion (anger) has confirmed that VR triggers a significantly stronger intensity of emotion than LCD.
C1 [Magdin, Martin; Balogh, Zoltan; Reichel, Jaroslav; Francisti, Jan; Koprda, Stefan] Constantine Philosopher Univ Nitra, Fac Nat Sci, Dept Informat, Tr A Hlinku 1, Nitra 94974, Slovakia.
   [Gyorgy, Molnar] Budapest Univ Technol & Econ, Dept Tech Educ, Budapest, Hungary.
C3 Constantine the Philosopher University in Nitra; Budapest University of
   Technology & Economics
RP Balogh, Z (corresponding author), Constantine Philosopher Univ Nitra, Fac Nat Sci, Dept Informat, Tr A Hlinku 1, Nitra 94974, Slovakia.
EM mmagdin@ukf.sk; zbalogh@ukf.sk; jreichel@ukf.sk; jan.francisti@ukf.sk;
   skoprda@ukf.sk; molnar.gy@eik.bme.hu
RI Francisti, Jan/B-2662-2019; Molnar, Gyorgy/A-1941-2012; Balogh,
   Zoltán/D-9238-2013; Reichel, Jaroslav/D-2400-2019; Magdin,
   Martin/C-7889-2019; Koprda, Stefan/C-7496-2019; Magdin,
   Martin/P-9803-2019
OI Francisti, Jan/0000-0002-0601-2753; Balogh, Zoltán/0000-0002-8900-0693;
   Reichel, Jaroslav/0000-0003-3482-8108; Magdin,
   Martin/0000-0002-2331-9247; Koprda, Stefan/0000-0002-4176-1805; Magdin,
   Martin/0000-0002-2331-9247
FU project KEGA [036UKF-4/2019]
FX The authors received financial support for the research, authorship,
   and/or publication of this article. The financial support of the project
   was from project KEGA 036UKF-4/2019-"Adaptation of the learning process
   using sensor networks and the Internet of Things ".
CR Alberdi A, 2016, J BIOMED INFORM, V59, P49, DOI 10.1016/j.jbi.2015.11.007
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Baby Shalini T., 2013, INT J ENG TRENDS TEC, V4, P1337
   Bahreini K, 2016, INTERACT LEARN ENVIR, V24, P590, DOI 10.1080/10494820.2014.908927
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Chang SC, 2020, COMPUT EDUC, V146, DOI 10.1016/j.compedu.2019.103758
   Loureiro SMC, 2020, TOURISM MANAGE, V77, DOI 10.1016/j.tourman.2019.104028
   Loureiro SMC, 2019, J BUS RES, V100, P514, DOI 10.1016/j.jbusres.2018.10.055
   Cruz-Albarran IA, 2017, INFRARED PHYS TECHN, V81, P250, DOI 10.1016/j.infrared.2017.01.002
   Demitriadou E, 2020, EDUC INF TECHNOL, V25, P381, DOI 10.1007/s10639-019-09973-5
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Ding N, 2018, TELEMAT INFORM, V35, P1572, DOI 10.1016/j.tele.2018.04.003
   Ekman P, 1978, FACIAL ACTION CODING
   Ekman P., 2002, RESEARCHNEXUS
   Elias ZM, 2019, APPL ERGON, V81, DOI 10.1016/j.apergo.2019.102879
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Francisti Jan, 2019, Applied Physics, System Science and Computers III. 3rd International Conference on Applied Physics, System Science and Computers (APSAC2018). Proceedings: Lecture Notes in Electrical Engineering (LNEE 574), P59, DOI 10.1007/978-3-030-21507-1_9
   Francisti J, 2019, ADV INTELL SYST, V924, P687, DOI 10.1007/978-981-13-6861-5_58
   Garzotto F, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P189, DOI 10.1109/AIVR.2018.00042
   Gonçalves VP, 2017, SOFT COMPUT, V21, P5309, DOI 10.1007/s00500-016-2115-0
   Goshvarpour A, 2018, CHAOS SOLITON FRACT, V114, P400, DOI 10.1016/j.chaos.2018.07.035
   Gross T., 2015, FOREWORD LECT NOTES, DOI [10.1007/978-3-319-22701-6, DOI 10.1007/978-3-319-22701-6]
   Han K, 2009, COMPUT BIOL MED, V39, P173, DOI 10.1016/j.compbiomed.2008.12.002
   Hossain MS, 2019, INFORM SCIENCES, V504, P589, DOI 10.1016/j.ins.2019.07.040
   Imani M, 2019, J NETW COMPUT APPL, V147, DOI 10.1016/j.jnca.2019.102423
   Isomursu M, 2007, INT J HUM-COMPUT ST, V65, P404, DOI 10.1016/j.ijhcs.2006.11.007
   Jang Y, 2019, TELEMAT INFORM, V42, DOI 10.1016/j.tele.2019.101239
   Javaid M, 2020, CLIN EPIDEMIOL GLOB, V8, P600, DOI 10.1016/j.cegh.2019.12.010
   Kaklauskas A, 2011, ENG APPL ARTIF INTEL, V24, P928, DOI 10.1016/j.engappai.2011.04.006
   Kerkeni L, 2019, SPEECH COMMUN, V114, P22, DOI 10.1016/j.specom.2019.09.002
   Kowalczuk Z, 2019, IFAC PAPERSONLINE, V52, P200, DOI 10.1016/j.ifacol.2019.08.071
   Leukhin A, 2018, BIOL INSPIR COGN ARC, V26, P166, DOI 10.1016/j.bica.2018.10.007
   Lövheim H, 2012, MED HYPOTHESES, V78, P341, DOI 10.1016/j.mehy.2011.11.016
   Magdin Martin, 2019, Intelligent Computing Theories and Application. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11643), P400, DOI 10.1007/978-3-030-26763-6_39
   Magdin M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092140
   Mahlke S., 2006, P C HUM FACT COMP SY, DOI [DOI 10.1145/1125451.1125653, 10.1145/1125451.1125653]
   Makki I., 2019, PROCEDIA COMPUT SCI, V163, P164, DOI [10.1016/j.procs.2019.12.097, DOI 10.1016/J.PROCS.2019.12.097]
   Marchewka A, 2014, BEHAV RES METHODS, V46, P596, DOI 10.3758/s13428-013-0379-1
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   McDuff D., 2016, P CHI C HUM FACT COM, P3723
   Michelini Yanina, 2019, Trends Psychol., V27, P473
   Molnár G, 2018, ACTA POLYTECH HUNG, V15, P209
   Munk M, 2011, PROCEDIA COMPUT SCI, V4, P1640, DOI 10.1016/j.procs.2011.04.177
   NAM J, 2019, NEW TERRAIN HCI EMOT
   Niu YF, 2019, J IMAGING SCI TECHN, V63, DOI 10.2352/J.ImagingSci.Technol.2019.63.6.060413
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Picard RW, 2009, PHILOS T R SOC B, V364, P3575, DOI 10.1098/rstb.2009.0143
   Pizzi G, 2019, COMPUT HUM BEHAV, V96, P1, DOI 10.1016/j.chb.2019.02.008
   Plutchik R., 1980, GEN PSYCHOEVOLUTIONA, P3
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Quazi M. T., 2011, 2011 Fifth International Conference on Sensing Technology (ICST 2011), P464, DOI 10.1109/ICSensT.2011.6137022
   RUSSELL JA, 1979, J PERS SOC PSYCHOL, V37, P345, DOI 10.1037/0022-3514.37.3.345
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Sharma R, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101867
   Tonguç G, 2020, COMPUT EDUC, V148, DOI 10.1016/j.compedu.2019.103797
   Tsonos D., 2008, Tools in Artificial Intelligence IntechOpen
   Vanderlind WM, 2020, CLIN PSYCHOL REV, V76, DOI 10.1016/j.cpr.2020.101826
   Visch VT, 2010, COGNITION EMOTION, V24, P1439, DOI 10.1080/02699930903498186
   Vived E, 2005, ACM INT C P SER, V265, P338, DOI [10.1145/1178477.1178541, DOI 10.1145/1178477.1178541]
   Waller BM, 2020, NEUROSCI BIOBEHAV R, V113, P1, DOI 10.1016/j.neubiorev.2020.02.031
   Wang X, 2019, INT J HOSP MANAG, V77, P438, DOI 10.1016/j.ijhm.2018.08.007
   Yang XZ, 2019, COMPUT HUM BEHAV, V99, P345, DOI 10.1016/j.chb.2019.06.002
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
   Zinchenko YP, 2020, NEW IDEAS PSYCHOL, V59, DOI 10.1016/j.newideapsych.2020.100786
NR 65
TC 14
Z9 15
U1 4
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1029
EP 1041
DI 10.1007/s10055-021-00506-5
EA MAR 2021
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000626778700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Pietra, A
   Rull, MV
   Etzi, R
   Gallace, A
   Scurati, GW
   Ferrise, F
   Bordegoni, M
AF Pietra, Andrea
   Rull, Marina Vazquez
   Etzi, Roberta
   Gallace, Alberto
   Scurati, Giulia Wally
   Ferrise, Francesco
   Bordegoni, Monica
TI Promoting eco-driving behavior through multisensory stimulation: a
   preliminary study on the use of visual and haptic feedback in a virtual
   reality driving simulator
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Eco-driving; Haptics; Multisensory
AB This paper describes the design and preliminary test of a virtual reality driving simulator capable of conveying haptic and visual messages to promote eco-sustainable driving behavior. The driving simulator was implemented through the Unity game engine; a large street environment, including high-speed and urban sections, was created to examine different driving behaviors. The hardware setup included a gaming driving seat, equipped with a steering wheel and pedals; the virtual scenarios were displayed through an Oculus Rift headset to guarantee an immersive experience. Haptic stimulation (i.e., vibrations) was delivered to the driver through the accelerator pedal, while visual stimuli (i.e., icons and colors) were shown on a virtual head-up display. The sensory feedbacks were presented both alone and in combination, providing information about excessive acceleration and speed. Four different virtual scenarios, each one including a distracting element (i.e., navigator, rain, call, and traffic), were also created. Ten participants tested the simulator. Fuel consumption was evaluated by calculating a mean power index (MPI) in reference to the sensory feedback presentation; physiological reactions and responses to a usability survey were also collected. The results revealed that the haptic and visuo-haptic feedback were responsible for an MPI reduction, respectively, for 14% and 11% compared with a condition of no feedback presentation; while visual feedback alone resulted in an MPI increase of 11%. The efficacy of haptic feedback was also accompanied by a more relaxing physiological state of the users, compared with the visual stimulation. The system's usability was adequate, although haptic stimuli were rated slightly more intrusive than the visual ones. Overall, these preliminary results highlight how promising the use of the haptic channel can be in communicating and guiding the driver toward a more eco-sustainable behavior.
C1 [Pietra, Andrea; Rull, Marina Vazquez] Politecn Milan, Sch Ind & Informat Engn, Milan, Italy.
   [Etzi, Roberta; Scurati, Giulia Wally; Ferrise, Francesco; Bordegoni, Monica] Politecn Milan, Dept Mech Engn, Via Giuseppe La Masa 1, I-20156 Milan, Italy.
   [Gallace, Alberto] Univ Milano Bicocca, Mind & Behav Technol Ctr, MibTec, Milan, Italy.
   [Gallace, Alberto] Univ Milano Bicocca, Dept Psychol, Milan, Italy.
C3 Polytechnic University of Milan; Polytechnic University of Milan;
   University of Milano-Bicocca; University of Milano-Bicocca
RP Ferrise, F (corresponding author), Politecn Milan, Dept Mech Engn, Via Giuseppe La Masa 1, I-20156 Milan, Italy.
EM francesco.ferrise@polimi.it
RI Etzi, Roberta/AAK-7368-2020; Gallace, Alberto/L-7276-2015; Ferrise,
   Francesco/C-6502-2008
OI Etzi, Roberta/0000-0002-5530-6627; Ferrise,
   Francesco/0000-0001-8951-8807
FU Politecnico di Milano
FX Open Access funding provided by Politecnico di Milano.
CR [Anonymous], 2005, TRANSP RED
   Barkenbus JN, 2010, ENERG POLICY, V38, P762, DOI 10.1016/j.enpol.2009.10.021
   Birrell SA, 2013, ERGONOMICS, V56, P282, DOI 10.1080/00140139.2012.760750
   Bock O, 2019, VIRTUAL REAL-LONDON, V23, P61, DOI 10.1007/s10055-018-0342-7
   Caivano JL, 1998, COLOR RES APPL, V23, P390, DOI 10.1002/(SICI)1520-6378(199812)23:6<390::AID-COL7>3.0.CO;2-#
   Cao S, 2020, VIRTUAL REAL-LONDON, V24, P503, DOI 10.1007/s10055-019-00412-x
   Choi E, 2017, INT J SUSTAIN TRANSP, V11, P395, DOI 10.1080/15568318.2016.1262928
   Climate Change, 2014, MITIGATION CLIMATE C
   Cook J, 2016, ENVIRON RES LETT, V11, DOI 10.1088/1748-9326/11/4/048002
   Ericsson E, 2006, TRANSPORT RES C-EMER, V14, P369, DOI 10.1016/j.trc.2006.10.001
   EVANS L, 1979, HUM FACTORS, V21, P389, DOI 10.1177/001872087902100401
   Fonseca N, 2011, TRANSPORT RES D-TR E, V16, P194, DOI 10.1016/j.trd.2010.10.001
   Fraile-Ardanuy J, 2018, ENERG CONVERS MANAGE, V157, P59, DOI 10.1016/j.enconman.2017.11.070
   Gallace A., 2014, TOUCH FUTURE SENSE T, DOI [10.1093/acprof:oso/9780199644469.001.0001, DOI 10.1093/ACPROF:OSO/9780199644469.001.0001]
   Gallace A, 2007, PRESENCE-VIRTUAL AUG, V16, P655, DOI 10.1162/pres.16.6.655
   Gallace A, 2012, PSYCHOLOGIST, V25, P896
   Gallus J, 2017, TRANSPORT RES D-TR E, V52, P215, DOI 10.1016/j.trd.2017.03.011
   Gulliver, 2011, MULTIPLE SENSORIAL M
   Hennessy DA, 1999, AGGRESSIVE BEHAV, V25, P409, DOI 10.1002/(SICI)1098-2337(1999)25:6<409::AID-AB2>3.0.CO;2-0
   HOOKER JN, 1988, TRANSPORT RES A-POL, V22, P183, DOI 10.1016/0191-2607(88)90036-2
   Huang YH, 2018, RENEW SUST ENERG REV, V93, P596, DOI 10.1016/j.rser.2018.05.030
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Knowles M, 2012, INT J ELECTR HYBRID, V4, P228, DOI 10.1504/IJEHV.2012.050492
   Manning C., 2009, The psychology of sustainable behavior: Tips for empowering people to take environmentally positive action
   McIlroy RC, 2017, IEEE T HUM-MACH SYST, V47, P661, DOI 10.1109/THMS.2016.2608937
   McIlroy RC, 2017, TRANSPORT RES F-TRAF, V46, P34, DOI 10.1016/j.trf.2017.01.002
   McIlroy RC, 2015, IEEE T HUM-MACH SYST, V45, P145, DOI 10.1109/THMS.2014.2369372
   Merenda C, 2018, IEEE T VIS COMPUT GR, V24, P2875, DOI 10.1109/TVCG.2018.2868531
   Pravossoudovitch K, 2014, ERGONOMICS, V57, P503, DOI 10.1080/00140139.2014.889220
   Saerens B, 2013, TRANSPORT RES D-TR E, V24, P89, DOI 10.1016/j.trd.2013.05.004
   Sivak M, 2012, TRANSPORT POLICY, V22, P96, DOI 10.1016/j.tranpol.2012.05.010
   Spence C., 2017, MULTISENSORY DRIVER, DOI [10.1201/9781315555423, DOI 10.1201/9781315555423]
   Spence C., 2008, TOUCH MUSEUMS POLICY, P21, DOI DOI 10.1002/9781119170174.EPCN214
   Spence C, 2007, CAN J EXP PSYCHOL, V61, P196, DOI 10.1037/cjep2007021
   Spence C, 2008, THEOR ISS ERGON SCI, V9, P523, DOI 10.1080/14639220701816765
   Stanton, 2017, ECO DRIVING STRATEGI, DOI [10.1201/9780203731987, DOI 10.1201/9780203731987]
   Staubach M, 2014, TRANSPORT RES F-TRAF, V27, P11, DOI 10.1016/j.trf.2014.09.006
   Stein B. E., 2012, NEW HDB MULTISENSORY
   Thomas J, 2017, SAE INT J FUELS LUBR, V10, P672, DOI 10.4271/2017-01-9379
   Tulusan J., 2011, 2011 IEEE INT S WORL, P1, DOI [DOI 10.1109/W0WM0M.2011.5986187, 10.1109/WoWMoM.2011, DOI 10.1109/WOWMOM.2011]
   United Nations Environment Programme, 2018, EM GAP REP
   Wang HK, 2008, TRANSPORT RES D-TR E, V13, P479, DOI 10.1016/j.trd.2008.09.002
   Weidner F, 2017, P IEEE VIRT REAL ANN, P281, DOI 10.1109/VR.2017.7892286
   Xia HT, 2013, J INTELL TRANSPORT S, V17, P31, DOI 10.1080/15472450.2012.712494
   Zajonc RB, 2001, CURR DIR PSYCHOL SCI, V10, P224, DOI 10.1111/1467-8721.00154
   Zeng WL, 2016, TRANSPORT RES C-EMER, V68, P194, DOI 10.1016/j.trc.2016.04.007
NR 47
TC 11
Z9 12
U1 4
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 945
EP 959
DI 10.1007/s10055-021-00499-1
EA JAN 2021
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000607969200001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Farmani, Y
   Teather, RJ
AF Farmani, Yasin
   Teather, Robert J.
TI Evaluating discrete viewpoint control to reduce cybersickness in virtual
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Vection; Cybersickness; Visually induced motion
   sickness
ID MOTION SICKNESS; ENVIRONMENTS; NAVIGATION
AB Cybersickness in virtual reality (VR) is an ongoing problem, despite recent advances in head-mounted displays (HMDs). Discrete viewpoint control techniques have been recently used by some VR developers to combat cybersickness. Discrete viewpoint techniques rely on reducing optic flow via inconsistent displacement, to reduce cybersickness when using stationary HMD-based VR systems. However, reports of their effectiveness are mostly anecdotal. We experimentally evaluate two discrete movement techniques; we refer to as rotation snapping and translation snapping. We conducted two experiments measuring participant cybersickness levels via the widely used simulator sickness questionnaire (SSQ), as well as user-reported levels of nausea, presence, and objective error rates. Our results indicate that both rotation snapping and translation snapping significantly reduced SSQ by 40% for rotational viewpoint movement, and 50% for translational viewpoint movement. They also reduced participant nausea levels, especially with longer VR exposure. Presence levels, error rates, and performance were not significantly affected by either technique.
C1 [Farmani, Yasin] Carleton Univ, Sch Comp Sci, Ottawa, ON, Canada.
   [Teather, Robert J.] Carleton Univ, Sch Informat Technol, Ottawa, ON, Canada.
C3 Carleton University; Carleton University
RP Farmani, Y (corresponding author), Carleton Univ, Sch Comp Sci, Ottawa, ON, Canada.
EM yashin.nhl@gmail.com; rob.teather@carleton.ca
CR [Anonymous], 2017, ROTATION BLURRING US
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Chang CH, 2013, EXP BRAIN RES, V229, P235, DOI 10.1007/s00221-013-3609-y
   Chang E, 2013, INT WINT WORKSH BR, P62, DOI 10.1109/IWW-BCI.2013.6506631
   Chen DJ, 2014, FREQUENCY RESPONSES
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Davis Simon., 2015, 11th Australasian Conference on Interactive Entertainment (IE 2015), P27, DOI DOI 10.17973/MMSJ.2015
   Dorado JL, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P47, DOI 10.1109/3DUI.2014.6798841
   Farmani Y, 2018, P 44 GRAPH INT C, P168, DOI [DOI 10.20380/GI2018.23, 10.20380/GI2018.23, 10.20380/GI2018.21]
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Hecht J, 2016, OPT PHOTONICS NEWS, V27, P24
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hettinger L.J., 1992, Presence: Teleoperators & Virtual Environments, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Hu SQ, 1999, AVIAT SPACE ENVIR MD, V70, P759
   Kemeny A, 2017, NEW VR NAVIGATION TE
   Kennedy RS, 1996, J VESTIBUL RES-EQUIL, V6, P331, DOI 10.1016/0957-4271(96)00002-X
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Kolasinski EM, 1998, P HUM FACT ERG SOC A
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   LOOMIS JM, 1993, J EXP PSYCHOL GEN, V122, P73, DOI 10.1037/0096-3445.122.1.73
   Park G.R., 2006, Proceedings of the Human Factors and Ergonomics Society 50 Annual Meeting, P2702, DOI DOI 10.1177/154193120605002607
   Park GD, 2014, HUM FACTORS, V43, P47, DOI [10.1007/s00371-008-0277-1, DOI 10.1007/S00371-008-0277-1]
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Ryge AN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P675, DOI 10.1109/VR.2018.8446206
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Sarupuri B, 2017, IEEE SYMP 3D USER, P227, DOI 10.1109/3DUI.2017.7893354
   Seay A.F., 2002, CHI 02 EXTENDED ABST, P784, DOI DOI 10.1145/506443.506596
   Seno T, 2011, PERCEPTION, V40, P747, DOI 10.1068/p7018
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   Stanney KM, 1997, COMMUN ACM, V40, P66, DOI 10.1145/257874.257889
   Toet A, 2008, PROC SPIE, V6957, DOI 10.1117/12.771992
   Tschermak A, 1931, OPTISCHER RAUMSINN R, P834
   WeiBker Tim., 2018, Ieee Vr, P256
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yao R, 2016, OCULUS BEST PRACTICE
NR 44
TC 41
Z9 45
U1 0
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 645
EP 664
DI 10.1007/s10055-020-00425-x
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000579168100007
DA 2024-07-18
ER

PT J
AU Lee, JH
   Park, JH
AF Lee, Joong Ho
   Park, Ji-Hyung
TI Visuomotor adaptation to excessive visual displacement in video
   see-through HMDs
SO VIRTUAL REALITY
LA English
DT Article
DE Video see-through HMD; VSHMD; Visual displacement; Visuomotor;
   Adaptation; Aftereffect
ID PRISM ADAPTATION; MOTION SICKNESS; NEGLECT; REALITY
AB A video see-through head-mounted display (VSHMD) is a modified HMD having an additional small digital camera set (see-through camera set) attached in front of the HMD, which allows users to view the real scene along with virtual information in digitally mixed form. However, although VSHMD has potential utility in augmented reality applications, the visual displacement problem must be overcome. This problem is caused by the distance between the see-through camera and human eye and induces visuomotor performance deterioration. Previous studies have revealed that human adaptation improves the visuomotor performance over time, by rearranging the proprioception. In this study, we extend the visual displacement excessively to 300 mm and investigate the eye-hand and eye-foot visuomotor coordination in two experiments. In Experiment 1, the prism adaptation paradigm is used to compare task performance under various visual displacement conditions. In Experiment 2, the procedures of Experiment 1 are implemented on 3 consecutive days to evaluate the relatively long-term adaptation trend. The results reveal distinct adaptations under all conditions. When excessive visual displacement is unavoidable, sufficient training can improve task performance, similar to the previously discovered perceptual adaptation. However, with increased visual displacement, the task performance improvement decelerates significantly. This improvement attenuation increases as the task performance becomes close to that achieved under bare eye conditions. Although humans can adapt to a large amount of visual displacement, a serious usage problem arises because of this slow adaptation improvement trend.
C1 [Lee, Joong Ho] Youngsan Univ, Dept Intelligent Robot, 288 Junam Ro, Yangsan, Gyeongnam, South Korea.
   [Park, Ji-Hyung] KIST, Ctr Robot Res, 5,Hwarang Ro 14 Gil, Seoul, South Korea.
C3 Korea Institute of Science & Technology (KIST)
RP Lee, JH (corresponding author), Youngsan Univ, Dept Intelligent Robot, 288 Junam Ro, Yangsan, Gyeongnam, South Korea.
EM 3969@ysu.ac.kr; jhpark@kist.re.kr
FU Youngsan University
FX This work was supported by the Youngsan University Research Fund of
   2018.
CR Alexander MS, 2011, J NEUROPHYSIOL, V106, P860, DOI 10.1152/jn.01040.2010
   [Anonymous], 2000, THESIS UNC CHAPEL HI
   Bae Hyojoon., 2013, Visualization in Engineering, V1, P1, DOI DOI 10.1186/2213-7459-1-3
   Chintamani K, 2008, P 2008 IERC, P977
   Cobb SVG, 1999, APPL ERGON, V30, P47, DOI 10.1016/S0003-6870(98)00038-6
   Fernández-Ruiz J, 1999, LEARN MEMORY, V6, P47
   Fernández-Ruiz J, 2000, COGNITIVE BRAIN RES, V9, P223, DOI 10.1016/S0926-6410(99)00057-9
   Fernandez-Ruiz J, 2011, BEHAV BRAIN RES, V219, P8, DOI 10.1016/j.bbr.2010.11.060
   Frassinetti F, 2002, BRAIN, V125, P608, DOI 10.1093/brain/awf056
   Hakkinen J., 2002, IEEE International Conference on Systems, Man and Cybernetics, V4, P147, DOI [DOI 10.1109/ICSMC.2002.1167964, 10.1109/ICSMC.2002.1167964]
   HARRIS CS, 1963, SCIENCE, V140, P812, DOI 10.1126/science.140.3568.812
   HAY JC, 1966, J EXP PSYCHOL, V71, P150, DOI 10.1037/h0022611
   Hughes CE, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.139
   Kennedy R. S., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P35, DOI 10.1109/VRAIS.1995.512477
   Kennedy RS., 1994, Proceedings of "Virtual Reality and Medicine: The Cutting Edge.", P111
   Kim S.-Y., 2014, Proceedings of the 2014 ACM International Symposium on Wearable Computers - ISWC '14, P79, DOI [10.1145/2634317.2634339, DOI 10.1145/2634317.2634339]
   Kollenberg Tobit., 2010, P 2010 S EYE TRACKIN, P121, DOI [10.1145/1743666.1743696, DOI 10.1145/1743666.1743696]
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lang CE, 1999, J NEUROPHYSIOL, V82, P2108, DOI 10.1152/jn.1999.82.5.2108
   Lang CE, 2001, CLIN NEUROPHYSIOL, V112, P895, DOI 10.1016/S1388-2457(01)00518-1
   Lee Joong Ho, 2013, P SIGCHI C HUM FACT, P309
   Luaute J, 2009, J NEUROSCI, V29, P169, DOI 10.1523/JNEUROSCI.3054-08.2009
   Martin TA, 1996, BRAIN, V119, P1183, DOI 10.1093/brain/119.4.1183
   MCGONIGLE BO, 1978, NATURE, V272, P364, DOI 10.1038/272364a0
   Moss JD, 2011, DISPLAYS, V32, P159, DOI 10.1016/j.displa.2011.05.010
   Park M, 2008, ERGONOMICS OPEN J, V1, P46, DOI DOI 10.2174/1875934300801010046
   Pretlove J, 1998, IND ROBOT, V25, P401, DOI 10.1108/01439919810240225
   Reason J., 1974, Man in motion: The psychology of travel
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   REDDING GM, 1990, J MOTOR BEHAV, V22, P209
   Rolland J. P., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P56, DOI 10.1109/VRAIS.1995.512480
   ROLLAND JP, 1994, P SOC PHOTO-OPT INS, V2351, P293
   Savin DN, 2008, EXP BRAIN RES, V186, P175, DOI 10.1007/s00221-007-1220-9
   Serino A, 2007, NEUROPSYCHOL REHABIL, V17, P657, DOI 10.1080/09602010601052006
   Stanney K, 1998, INT J HUM-COMPUT INT, V10, P135, DOI 10.1207/s15327590ijhc1002_3
   Stanney KM, 1999, APPL ERGON, V30, P27, DOI 10.1016/S0003-6870(98)00039-8
   von Helmholtz HEF., 1909, Treatise on Physiological Optics
   Wurpts M, 2000, IMAGE 2000
NR 38
TC 4
Z9 5
U1 1
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 211
EP 221
DI 10.1007/s10055-019-00390-0
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800002
DA 2024-07-18
ER

PT J
AU Erfanian, A
   Hu, YP
AF Erfanian, Aida
   Hu, Yaoping
TI Verbal and vibrotactile cues on multiuser usability within collaborative
   virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Collaborative virtual environments; Dynamic priority model; Multiuser
   usability; Verbal cues; Vibrotactile cues
ID FRAMEWORK; PERCEPTION; REAL
AB Suitable cues for communication are crucial to multiuser usability of collaborative virtual environments (VEs). Although verbal cues are common among users, vibrotactile cues are nonverbal to facilitate conventionally interaction with objects. Few research efforts have examined the role of verbal and vibrotactile cues on multiuser usability of a collaborative VE. This paper hence presents assessments of verbal and vibrotactile cues, as well their combination, on affecting multiuser usability of the VE. The VE resolved conflicts of interactive commands issued by peer users through a dynamic priority (DP) model, which granted interaction to a user based on the recency of his/her gained interactions. As revealed in the existing work, the DP model yielded perceived equality in interaction (EII) among users to promote multiuser satisfaction. The assessments utilized metrics of multiuser usability, which we proposed for the components of both ISO/IEC 2050:2011 and 25022:2016 standards. The metrics considered collective outcomes of the users, differing from existing metrics of measuring individual experiences. We first conducted two baseline evaluations within the VE. One evaluation investigated how verbal cues affect EII and multiuser usability; another evaluation studied how vibrotactile cues influence the effect of the DP model. Based on the evaluations, we then undertook a study to assess the effect of combining verbal and vibrotactile cues on multiuser usability of the VE. We observed that both cues had no effect on the DP model to yield perceived EII. However, the combination of verbal cues in an affirmative mode and vibrotactile cues in a counteractive mode enhanced significantly the multiuser usability of the VE for the task of the study, compared to individual verbal and vibrotactile cues. These observations indicate a suitable combination of both cues to potentially foster multiuser usability of collaborative VEs.
C1 [Erfanian, Aida; Hu, Yaoping] Univ Calgary, Calgary, AB, Canada.
C3 University of Calgary
RP Hu, YP (corresponding author), Univ Calgary, Calgary, AB, Canada.
EM huy@ucalgary.ca
CR Albaum G, 1997, J MARKET RES SOC, V39, P331
   [Anonymous], 2011, ISO/IEC 25010:2011
   [Anonymous], 2016, 250222016 ISOIEC
   [Anonymous], FITB BLAZ SMART FITN
   [Anonymous], 2016, MATH MODEL ANAL
   [Anonymous], BEHAV INF TECHNOL
   [Anonymous], HIGHL SAMS GEAR S3 O
   [Anonymous], SENS GMBH
   Argelaguet F, 2017, IEEE SYMP 3D USER, P158, DOI 10.1109/3DUI.2017.7893333
   Oliveira VAD, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P91, DOI 10.1109/3DUI.2016.7460036
   Deng LJ, 2016, INFORM SCIENCES, V348, P107, DOI 10.1016/j.ins.2016.02.015
   Dodge Y., 2008, The concise encyclopedia of statistics
   Erfanian Aida, 2013, 9th IEEE International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom 2013), P363, DOI 10.4108/icst.collaboratecom.2013.254052
   Erfanian A, 2017, IEEE T HUM-MACH SYST, V47, P1052, DOI 10.1109/THMS.2017.2700431
   Erfanian A, 2017, IEEE SYMP 3D USER, P87, DOI 10.1109/3DUI.2017.7893322
   Erfanian A, 2014, 2014 INTERNATIONAL CONFERENCE ON COLLABORATIVE COMPUTING: NETWORKING, APPLICATIONS AND WORKSHARING (COLLABORATECOM), P187, DOI 10.4108/icst.collaboratecom.2014.257234
   Farinazzo Martins Valeria, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P222, DOI 10.1007/978-3-319-39907-2_21
   Gleeson B, 2015, J HUM-ROBOT INTERACT, V4, P95, DOI 10.5898/JHRI.4.1.Gleeson
   Gonzales-Gonzales C.S., 2016, Acta Scientiae, V18, P12
   Hargie O., 2010, Skilled interpersonal communication: research, theory and practice, DOI [10.4324/9780203833919, DOI 10.4324/9780203833919]
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Ho C, 2005, TRANSPORT RES F-TRAF, V8, P397, DOI 10.1016/j.trf.2005.05.002
   Hornbæk K, 2006, INT J HUM-COMPUT ST, V64, P79, DOI 10.1016/j.ijhcs.2005.06.002
   Law ELC, 2014, INT J HUM-COMPUT ST, V72, P523, DOI 10.1016/j.ijhcs.2014.03.003
   Madathil KC, 2017, APPL ERGON, V65, P501, DOI 10.1016/j.apergo.2017.02.011
   Meng FX, 2015, ERGONOMICS, V58, P411, DOI 10.1080/00140139.2014.976278
   Ortega FR, 2017, IEEE SYMP 3D USER, P144, DOI 10.1109/3DUI.2017.7893331
   Park J, 2017, IEEE T HAPTICS, V10, P54, DOI 10.1109/TOH.2016.2612202
   Patel H, 2012, APPL ERGON, V43, P1, DOI 10.1016/j.apergo.2011.04.009
   Pietroszek K, 2017, IEEE SYMP 3D USER, P172, DOI 10.1109/3DUI.2017.7893335
   Rogers Y, 2009, HUM-COMPUT INTERACT, V24, P79, DOI 10.1080/07370020902739379
   Salem M, 2015, ACMIEEE INT CONF HUM, P141, DOI 10.1145/2696454.2696497
   SANDOM C., 2004, HUMAN FACTORS ENG
   Schneider OS, 2014, IEEE HAPTICS SYM, P327, DOI 10.1109/HAPTICS.2014.6775476
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Soegaard Mads., 2012, The Encyclopedia of Human-Computer Interaction
   Tissenbaum M, 2017, INT J COMP-SUPP COLL, V12, P35, DOI 10.1007/s11412-017-9249-7
   Van Belle G, 2011, Statistical rules of thumb, V699
   Walker JM, 2015, IEEE T HAPTICS, V8, P454, DOI 10.1109/TOH.2015.2420096
   Whitaker TA, 2008, BRAIN RES, V1242, P59, DOI 10.1016/j.brainres.2008.05.037
   Wu S, 2017, IEEE SYMP 3D USER, P168, DOI 10.1109/3DUI.2017.7893334
   Yuill N, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2147783.2147784
NR 42
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 75
EP 91
DI 10.1007/s10055-018-0375-y
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800005
DA 2024-07-18
ER

PT J
AU Huang, FH
AF Huang, Fei-Hui
TI Adapting UTAUT2 to assess user acceptance of an e-scooter virtual
   reality service
SO VIRTUAL REALITY
LA English
DT Article
DE Technology acceptance model; UTAUT2; Virtual reality; Immersive
   experience; User experience
ID INFORMATION-TECHNOLOGY; SOCIAL-INFLUENCE; MODEL; PAIN
AB A virtual reality (VR) technology innovation experience service was designed to promote electric two-wheelers (E2Ws). An understanding of the factors that will have an impact on VR service adoption in experiencing an E2W ride is important. This study adapts the Unified Theory of Acceptance and Use of Technology (UTAUT2) to investigate the factors that may influence user acceptance of fully immersive VR as compared to desktop VR. A within-subjects design enabled 56 participants to evaluate both VR systems. The results indicate that the model constructs of performance expectancy, hedonic motivation, and facilitating conditions are useful predictors of the behavioral intention to use VR systems. Although these factors were significantly higher for fully immersive VR, both VR systems can yield a positive influence on behavioral intention. Based on these findings, several implications for developers and suggestions for future research are provided.
C1 [Huang, Fei-Hui] Oriental Inst Technol, New Taipei, Taiwan.
C3 Asia Eastern University of Science & Technology
RP Huang, FH (corresponding author), Oriental Inst Technol, New Taipei, Taiwan.
EM fn009@mail.oit.edu.tw
FU Oriental Institute of Technology [106-7-09-105]
FX The author would like to thank all the participants who took part in the
   study and wishes to express her gratitude to Oriental Institute of
   Technology for the funding (Grant No. 106-7-09-105).
CR Ajzen I., 1985, UNDERSTANDING ATTITU, P11, DOI 10.1007/978-3-642-69746-3_2
   [Anonymous], 2015, ADV ENVIRON BIOL
   [Anonymous], 2002, SPEAKING HLTH ASSESS
   Brown SA, 2005, MIS QUART, V29, P399
   Bugembe J, 2010, THESIS
   Burdea G. C., 2003, Virtual reality technology
   Colonius H, 2001, PERCEPT PSYCHOPHYS, V63, P126, DOI 10.3758/BF03200508
   Corneil BD, 2002, J NEUROPHYSIOL, V88, P438, DOI 10.1152/jn.2002.88.1.438
   Dahlquist LM, 2007, HEALTH PSYCHOL, V26, P794, DOI 10.1037/0278-6133.26.6.794
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Deci E.L., 1985, INTRINSIC MOTIVATION, DOI [10.1007/978-1-4899-2271-7, DOI 10.1007/978-1-4899-2271-7]
   Fonseca D., 2016, Proceedings of the 20th International Mindtrek Conference, P287, DOI [DOI 10.1145/2994310.2994334, 10.1145/2994310.2994334, 10.1145/2994310.2994334,96]
   Ghalandari K., 2012, MIDDLE EAST J SCI RE, V12, P801, DOI [10.5829/idosi.mejsr.2012.12.6.2536, DOI 10.5829/idosi.mejsr.2012.12.6.2536]
   Ghazizadeh M, 2012, COGN TECHNOL WORK, V14, P39, DOI 10.1007/s10111-011-0194-3
   Gutierrez MarioA., 2008, STEPPING VIRTUAL REA, DOI DOI 10.1007/978-1-84800-117-6
   Harrington LK, 1998, EXP BRAIN RES, V122, P247, DOI 10.1007/s002210050512
   Heim M., 2000, Virtual Realism
   HERTEL PT, 1982, J EXP PSYCHOL LEARN, V8, P513
   Hilfert Thomas, 2016, Visualization in Engineering, V4, DOI 10.1186/s40327-015-0031-5
   Huang Fei-Hui, 2016, ADV ERGONOMICS MODEL, P325
   John V., 1993, VIRTUAL REALITY SYST, P135, DOI DOI 10.1016/B978-0-12-227748-1.50018-4
   KELLER KL, 1993, J MARKETING, V57, P1, DOI 10.2307/1252054
   Kelman H.C., 1974, PERSPECTIVES SOCIAL, P125, DOI DOI 10.4324/9781315129693-6
   Khayati S., 2013, J KNOWLEDGE MANAGEME, V3, P68
   Kodama R, 2017, IEEE SYMP 3D USER, P130, DOI 10.1109/3DUI.2017.7893329
   Li HR, 2002, J ADVERTISING, V31, P43, DOI 10.1080/00913367.2002.10673675
   Maani CV, 2011, J TRAUMA, V71, pS125, DOI 10.1097/TA.0b013e31822192e2
   Madigan R, 2017, TRANSPORT RES F-TRAF, V50, P55, DOI 10.1016/j.trf.2017.07.007
   McArdle G, 2012, INTERACT LEARN ENVIR, V20, P57, DOI 10.1080/10494821003714749
   MILLER J, 1982, COGNITIVE PSYCHOL, V14, P247, DOI 10.1016/0010-0285(82)90010-X
   Ramalho Joao., 2013, Proceedings of the 2013 ACM international workshop on Immersive media experiences, P35, DOI [DOI 10.1145/2512142.2512144, 10.1145/2512142.2512144]
   Ray M, 2016, VIRTUAL REALITY
   Sawai F, 2014, J ORAL MAXILLOFAC SU, V72, pe204, DOI [10.1016/j.joms.2014.06.366, DOI 10.1016/J.JOMS.2014.06.366]
   Schlosser AE, 2006, J CONSUM RES, V33, P377, DOI 10.1086/508522
   Scott S, 2019, BEST VR HEADSETS 201
   Tossy T., 2014, International Journal of Information Technology and Business Management, V27, P1
   Van den Broeck M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P762, DOI 10.1145/3123266.3123347
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2012, MIS QUART, V36, P157
   Villa C, 2013, LIGHTING RES TECHNOL, V45, P401, DOI 10.1177/1477153512450452
   Weidner F, 2017, P IEEE VIRT REAL ANN, P281, DOI 10.1109/VR.2017.7892286
   Wender Regina, 2009, J Cyber Ther Rehabil, V2, P27
   Wu M.-Y., 2012, Asia Pacific Management Review, V17, P91, DOI [DOI 10.6126/APMR.2012.17.1.06, 10.6126/APMR.2012.17.1.06]
   Xinxiong Liu, 2018, IOP Conference Series: Earth and Environmental Science, V170, DOI 10.1088/1755-1315/170/3/032155
   Zhou T, 2011, INTERNET RES, V21, P67, DOI 10.1108/10662241111104884
NR 45
TC 17
Z9 18
U1 5
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 635
EP 643
DI 10.1007/s10055-019-00424-7
EA JAN 2020
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000574061400001
DA 2024-07-18
ER

PT J
AU De Paolis, LT
   De Luca, V
AF De Paolis, Lucio Tommaso
   De Luca, Valerio
TI The impact of the input interface in a virtual environment: the Vive
   controller and the Myo armband
SO VIRTUAL REALITY
LA English
DT Article
DE Touchless interaction; Gesture; User experience; Usability; Presence;
   Virtual environment
ID USER EXPERIENCE; REALITY; TECHNOLOGIES; IMMERSION; OPERATION; MOTION;
   HAND
AB Gesture-based touchless devices are becoming a widespread alternative to traditional gaming devices such as joysticks or gamepads. However, the impact of such devices on the user experience has to be evaluated, especially if we consider that most users are more familiar with classical handheld gaming controllers. In virtual reality applications, they influence not only the traditional usability, but also the user perception related to some peculiarities of immersive environments. In this paper, we evaluate both these aspects by comparing the user experience with the Myo armband touchless interface and the Vive controller distributed with the HTC Vive headset. We focused on a virtual navigator we developed for HTC Vive to allow users exploring the organs of the human body and navigating inside them. We recruited 78 subjects to test the virtual environment and asked them to fill in a questionnaire: we combined two generic purpose questionnaires focusing on the system usability (UMUX and SUS) and a presence questionnaire, which was specifically designed for virtual environments. We conducted a statistical analysis to study the effects of a touchless interaction on the user experience. The results revealed a better usability of the Myo armband, even though the effort to learn how to use the two devices is similar. In particular, difficulties in using Myo have a significant impact on immersion and adaptation in the virtual environment.
C1 [De Paolis, Lucio Tommaso; De Luca, Valerio] Univ Salento, Dept Engn Innovat, Lecce, Italy.
C3 University of Salento
RP De Luca, V (corresponding author), Univ Salento, Dept Engn Innovat, Lecce, Italy.
EM lucio.depaolis@unisalento.it; valerio.deluca@unisalento.it
RI De Luca, Valerio/HGJ-6239-2022; De Luca, Valerio/JBJ-2116-2023
OI De Luca, Valerio/0000-0003-3018-7251
CR [Anonymous], 2013, MEASURING USER EXPER
   [Anonymous], 2019, MICROSOFT HOLOLENS
   Anwar Shamama, 2018, NANOELECTRONICS CIRC, P365
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Assila A., 2016, Electronic Journal of Computer Science and Information Technology, V6, DOI DOI 10.1016/B978-0-12-384968-7.00008-4
   Bachmann D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072194
   Bailey Shannon KT, 2018, C INT ERG ASS, P663
   Bartlett MS, 1937, PROC R SOC LON SER-A, V160, P0268, DOI 10.1098/rspa.1937.0109
   Bhattacharyya A, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2127, DOI 10.1109/ICACCI.2018.8554686
   Borges M, 2018, IEEE INT C INT ROBOT, P2610, DOI 10.1109/IROS.2018.8593707
   Borrego A, 2018, GAMES HEALTH J, V7, P151, DOI 10.1089/g4h.2017.0114
   Borsci S, 2009, COGN PROCESS, V10, P193, DOI 10.1007/s10339-009-0268-9
   Bowman DA, 2008, IEEE COMPUT GRAPH, V28, P20, DOI 10.1109/MCG.2008.109
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI DOI 10.1201/9781498710411
   Caggianese G., 2018, INT C INT INT MULT S, P24, DOI [10.1007/978-3-319-92231-7_3, DOI 10.1007/978-3-319-92231-73]
   Cain B, 2004, RTOTRHFM121 NATO 2
   Caputo D, 2015, 2015 INTERNATIONAL CONFERENCE ON BIOPHOTONICS (BIOPHOTONICS), P74
   Chen MY, 2015, USER DEFINED GAME IN
   Cook HE, 2015, NEW CONCEPTS AND DISCOVERIES, VOLS. I AND II, P1
   Csapo AB, 2017, 7 IEEE INT C COGN IN
   Curtis P, 2009, CHILDREN, FOOD AND IDENTITY IN EVERYDAY LIFE, P94
   De Paolis Lucio Tommaso, 2018, Bioinformatics and Biomedical Engineering. 6th International Work-Conference, IWBBIO 2018. Proceedings: LNB 10814, P118, DOI 10.1007/978-3-319-78759-6_12
   De Paolis Lucio T., 2010, Journal of Computing and Information Technology - CIT, V18, P385, DOI 10.2498/cit.1001878
   De Paolis LT, 2016, 14 MED C MED BIOL EN, V57, P880
   De Paolis LT, 2009, STUD HEALTH TECHNOL, V150, P811, DOI 10.3233/978-1-60750-044-5-811
   De Paolis LT, 2019, LECT NOTES COMPUT SC, V11614, P348, DOI 10.1007/978-3-030-25999-0_30
   De Paolis LT, 2019, MED BIOL ENG COMPUT, V57, P995, DOI 10.1007/s11517-018-1929-6
   Dong H, 2016, ELICITATION STUDY GE
   Duvinage M, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-56
   Emotiv, 2019, EM EPOC
   Figueiredo L, 2018, COMPUT GRAPH-UK, V77, P108, DOI 10.1016/j.cag.2018.10.006
   Finstad K, 2010, INTERACT COMPUT, V22, P323, DOI 10.1016/j.intcom.2010.04.004
   Frankenstein J, 2012, COGN PROCESS, V13, pS165, DOI 10.1007/s10339-012-0482-8
   GABRIEL KR, 1971, BIOMETRIKA, V58, P453, DOI 10.1093/biomet/58.3.453
   Gamer PC, 2019, VALVE INDEX REV
   Garber L, 2013, COMPUTER, V46, P22, DOI 10.1109/MC.2013.352
   Grandhi SA, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P821
   Gusai E, 2017, LECT NOTES COMPUT SC, V10590, P290, DOI 10.1007/978-3-319-70742-6_27
   Guzsvinecz T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051072
   Hauser N, 2018, IEEE ENG MED BIO, P3264, DOI 10.1109/EMBC.2018.8512937
   Hilliges O., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '12, P2421
   HTC, 2019, HTC VIV CONTR
   HTC, 2019, VIVE WIR AD
   HTC, 2019, VIV VR PROD
   Hudson S, 2019, J BUS RES, V100, P459, DOI 10.1016/j.jbusres.2018.10.062
   Indraccolo C, 2017, LECT NOTES COMPUT SC, V10325, P63, DOI 10.1007/978-3-319-60928-7_6
   Invitto S, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030394
   Invitto S, 2015, PROCEEDINGS OF THE 2015 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNOLOGIES FOR INTERACTIVE ENTERTAINMENT, P88, DOI 10.4108/icst.intetain.2015.259537
   Rechy-Ramirez EJ, 2018, J AMB INTEL HUM COMP, V9, P1479, DOI 10.1007/s12652-017-0568-3
   KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Lachat E, 2015, REMOTE SENS-BASEL, V7, P13070, DOI 10.3390/rs71013070
   Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P1148, DOI 10.1080/10447318.2017.1418805
   Lewis JR, 2015, LECT NOTES COMPUT SC, V9186, P204, DOI 10.1007/978-3-319-20886-2_20
   Livatino S, 2015, IEEE T IND ELECTRON, V62, P525, DOI 10.1109/TIE.2014.2334675
   Lucas JF., 2005, PROC HUMAN FACTORS C, P1601, DOI DOI 10.1145/1056808.1056976
   Lund B. A. M., 2001, STC USABILITY SIG NE
   McMahan RP, 2007, P ACM S VIRT REAL SO, P108
   Méndez R, 2019, UNIVERSAL ACCESS INF, V18, P17, DOI 10.1007/s10209-017-0586-0
   Microsoft, 2019, Azure kinect dk
   Moustafa K., 2017, INT S HUM MENT WORKL, P30, DOI [10. 1007/978-3-319-61061-0_3, DOI 10.1007/978-3-319-61061-0_3]
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Nintendo, 2019, WII REM
   Oculus VR, 2019, OC TOUCH
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Polygon, 2019, OC GO REV
   Ruddle R, 2006, PRESENCE TELEOPERATO
   Samsung, 2019, SAMS GEAR VR
   Santos M. E. C., 2014, P 20 ACM S VIRT REAL, P167, DOI DOI 10.1145/2671015.2671019
   Santos MEC, 2015, IEEE COMPUT GRAPH, V35, P66, DOI 10.1109/MCG.2015.94
   Santoyo-González A, 2018, 2018 IEEE CONFERENCE ON STANDARDS FOR COMMUNICATIONS AND NETWORKING (IEEE CSCN)
   Sarbolandi H, 2015, COMPUT VIS IMAGE UND, V139, P1, DOI 10.1016/j.cviu.2015.05.006
   Sayin FS, 2018, SIG P ALGO ARCH ARR, P27, DOI 10.23919/SPA.2018.8563394
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Somrak A, 2019, FUTURE GENER COMP SY, V94, P302, DOI 10.1016/j.future.2018.11.041
   Spitzley KA, 2019, J BIOMECH, V87, P172, DOI 10.1016/j.jbiomech.2019.02.015
   Stanney KM, 2003, INT J HUM-COMPUT ST, V58, P447, DOI 10.1016/S1071-5819(03)00015-6
   Sun CY, 2019, J COMPUT DES ENG, V6, P189, DOI 10.1016/j.jcde.2018.05.006
   Sun R, 2019, VIRTUAL REAL-LONDON, V23, P385, DOI 10.1007/s10055-018-0355-2
   Tcha-Tokey K., 2017, EFFECTS USER EXPERIE
   Thalmic Labs, 2019, MYO ARMB
   Ullmer B, 2000, IBM SYST J, V39, P915, DOI 10.1147/sj.393.0915
   Uloziene I, 2017, MEDICINA-LITHUANIA, V53, P394, DOI 10.1016/j.medici.2018.02.002
   UploadVR, 2019, OC QUEST REV
   UploadVR, 2019, OC6 OC QUEST IS GETT
   Vosinakis S, 2018, VIRTUAL REAL-LONDON, V22, P47, DOI 10.1007/s10055-017-0313-4
   Vrellis I, 2014, IEEE INT CONF ADV LE, P678, DOI 10.1109/ICALT.2014.199
   Webster Rustin, 2017, 2017 ASEE ANN C EXP
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wobbrock JacobO., 2005, CHI'05 Extended Abstracts on Human Factors in Computing Systems. CHI EA'05, P1869, DOI DOI 10.1145/1056808.1057043
   Yu ML, 2019, APPL ERGON, V74, P206, DOI 10.1016/j.apergo.2018.08.012
NR 94
TC 14
Z9 13
U1 0
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 483
EP 502
DI 10.1007/s10055-019-00409-6
EA NOV 2019
PG 20
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000498619700001
DA 2024-07-18
ER

PT J
AU Lau, KW
   Lee, PY
AF Lau, Kung Wong
   Lee, Pui Yuen
TI Shopping in virtual reality: a study on consumers' shopping experience
   in a stereoscopic virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Stereoscopic displays; Consumer research; Retailing;
   Shopping experiences
ID HEDONIC CONSUMPTION; MOTIVATION; INTERNET; PRODUCTS; STORES; FLOW
AB The popularity of home-based stereoscopic television provides researchers and practitioners with possibilities of bringing stereoscopic virtual reality (StereoVR) at consumers' home. To further the investigation on the potential development of applying StereoVR in retailing, this research focuses on understanding consumers' shopping experiences in this new platform. The research team believes that the use of StereoVR has potentials to become a new arena for interactive business. To explore these potential uses of technology in retailing, the team designed and built a StereoVR, called "FutureShop," for implementing a virtual fashion retailing practices as well as collecting consumers' responses for further development. Participants are asked to complete a shopping process from product selection to purchase in FutureShop. The factors examined in this research included the consumers' purchase intention, interactive shopping and hedonic shopping experience. The findings and implications suggest that the StereoVR can make a significant contribution in creating more interactive experiences for apparel retailing by enhancing consumers' hedonic shopping experiences in the StereoVR.
C1 [Lau, Kung Wong] Hong Kong Polytech Univ, Inst Text & Clothing, Hung Hom, Kowloon, Hong Kong, Peoples R China.
   [Lee, Pui Yuen] Hong Kong Polytech Univ, Sch Design, Hung Hom, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; Hong Kong Polytechnic University
RP Lau, KW (corresponding author), Hong Kong Polytech Univ, Inst Text & Clothing, Hung Hom, Kowloon, Hong Kong, Peoples R China.
EM tcrobert@polyu.edu.hk; py.lee@polyu.edu.hk
RI LAU, Kung Wong/G-3653-2010
OI LAU, Kung Wong/0000-0003-4896-264X; Lee, Pui Yuen/0000-0001-6081-2893
CR BABIN BJ, 1994, J CONSUM RES, V20, P644, DOI 10.1086/209376
   Ben-Ur J, 2015, J INTERNET COMMER, V14, P406, DOI 10.1080/15332861.2015.1081792
   Blackwell RD, 2001, CONSUMER BEHAV, P219
   Bradford TW, 2017, J INTERACT MARK, V40, P9, DOI 10.1016/j.intmar.2017.06.002
   Brown R, 2012, WONMENS WEAR DA 0321
   Bystrom KE, 1999, PRESENCE-TELEOP VIRT, V8, P241, DOI 10.1162/105474699566107
   Childers TL, 2001, J RETAILING, V77, P511, DOI 10.1016/S0022-4359(01)00056-2
   Chittaro L, 2000, P CHI2000 WORKSH DES
   Coxon M, 2016, VIRTUAL REAL-LONDON, V20, P203, DOI 10.1007/s10055-016-0292-x
   Dahan E, 2000, J PROD INNOVAT MANAG, V17, P99, DOI 10.1016/S0737-6782(99)00029-6
   Diep VCS, 2008, J RETAIL CONSUM SERV, V15, P399, DOI 10.1016/j.jretconser.2007.10.002
   Drake-Bridges Erin., 2011, Marketing Education Review, V21, P125
   Elgan M, 2017, CIO, P1
   Goel L, 2011, MIS QUART, V35, P749
   Goldsmith RE, 2005, INT J RETAIL DISTRIB, V33, P271, DOI 10.1108/09590550510593202
   Grewal D, 2017, J RETAILING, V93, P1, DOI 10.1016/j.jretai.2016.12.008
   Ha Y, 2007, J FASH MARK MANAG, V11, P477, DOI 10.1108/13612020710824553
   HIRSCHMAN EC, 1982, J MARKETING, V46, P92, DOI 10.2307/1251707
   Hoffman DL, 2009, J INTERACT MARK, V23, P23, DOI 10.1016/j.intmar.2008.10.003
   Hoffman K.D., 1997, Essentials of services marketing
   Huang E., 2013, INT J ELECT COMMERCE, V4, P305, DOI [DOI 10.7903/IJECS.1123, 10.7903/ijecs.1123]
   Jin SAA, 2009, J INTERACT MARK, V23, P234, DOI 10.1016/j.intmar.2009.04.005
   Jones M.A., 1999, Journal of Retailing and Consumer Services, V6, P129
   Kaewrat C., 2017, WALAILAK J SCI TECHN, V14, P759
   Kenkare N, 2008, J TEXT I, V99, P211, DOI 10.1080/00405000701489222
   Khakimdjanova L, 2005, J RETAIL CONSUM SERV, V12, P307, DOI 10.1016/j.jretconser.2004.10.005
   Kim J, 2008, J INTERACT MARK, V22, P45, DOI 10.1002/dir.20113
   Kim M., 2006, Managing Service Quality, V16, P51, DOI DOI 10.1108/09604520610639964
   Kimiloglu Hande., 2004, ACAD MARKETING SCI R, V6, P1
   Klein LR, 2003, J INTERACT MARK, V17, P41, DOI 10.1002/dir.10046
   Kort PM, 2006, AUTOMATICA, V42, P1363, DOI 10.1016/j.automatica.2005.10.002
   Kugler L, 2017, COMMUN ACM, V60, P15, DOI 10.1145/3105444
   Lee KC, 2008, COMPUT HUM BEHAV, V24, P88, DOI 10.1016/j.chb.2007.01.018
   Magnenat-Thalmann N, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P2, DOI 10.1109/MMMC.2005.24
   Mathwick C, 2001, J RETAILING, V77, P39, DOI 10.1016/S0022-4359(00)00045-2
   McGoldrick P., 2002, RETAIL MARKETING, V2nd
   McKone D, 2016, HARVARD BUSINES 0909, V9, P2
   Muller-Lankenau C, 2005, P EUR AC MAN C EURAM
   Nah FFH, 2011, MIS QUART, V35, P731
   Newsom MK, 2009, BUS HORIZONS, V52, P167, DOI 10.1016/j.bushor.2008.10.005
   Nwankwo S, 2014, J RETAIL CONSUM SERV, V21, P735, DOI 10.1016/j.jretconser.2014.05.003
   Pantano Eleonora, 2012, Journal of Technology Management & Innovation, V7, P198, DOI 10.4067/S0718-27242012000300016
   PARK CHANG HEE, 2017, Journal of Marketing Thought, V4, P25
   Park J, 2003, P ANN M INT TEXT APP
   PARK J.H., 2002, J FASHION MARKETING, V6, P158
   Park M, 2009, J FASH MARK MANAG, V13, P149, DOI 10.1108/13612020910957680
   Pegler M., 2001, VISUAL MERCHANDISING
   Pine BJ, 1998, HARVARD BUS REV, V76, P97
   Puccinelli NM, 2009, J RETAILING, V85, P15, DOI 10.1016/j.jretai.2008.11.003
   Ragusa JM, 2001, COMMUN ACM, V44, P40, DOI 10.1145/501317.501339
   Sanna A, 2004, INT J HUM-COMPUT ST, V60, P701, DOI 10.1016/j.ijhcs.2003.12.004
   Saren M, 2013, J MARKET MANAG-UK, V29, P1435, DOI 10.1080/0267257X.2013.833776
   Satam D, 2011, J TEXT I, V102, P353, DOI 10.1080/00405000.2010.482351
   Schlosser AE, 2003, J CONSUM RES, V30, P184, DOI 10.1086/376807
   Sherman WilliamR., 2003, UNDERSTANDING VIRTUA
   SHERRY JF, 1993, J BUS RES, V28, P225, DOI 10.1016/0148-2963(93)90049-U
   Smolentsev A, 2017, VIRTUAL REAL-LONDON, V21, P153, DOI 10.1007/s10055-017-0305-4
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Tae HB, 2015, AM ACAD ADVERT C P, V2015, P102
   Ullah Sehat, 2009, International Journal of Virtual Reality, V8, P25
   Varajao J, 2012, J TEXT I, V103, P960, DOI 10.1080/00405000.2011.639513
   Wagner T, 2007, INT J RETAIL DISTRIB, V35, P569, DOI 10.1108/09590550710755949
   Widyarini L.A., 2017, Int J Emerg Res Manag Technol, V6, P7
NR 63
TC 38
Z9 39
U1 4
U2 105
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2019
VL 23
IS 3
SI SI
BP 255
EP 268
DI 10.1007/s10055-018-0362-3
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA IR5QR
UT WOS:000481490500005
DA 2024-07-18
ER

PT J
AU Wu, YC
   Chen, SC
   Lin, IC
AF Wu, Yenchun
   Chen, Shih-Chih
   Lin, I-Cheng
TI Elucidating the impact of critical determinants on purchase decision in
   virtual reality products by Analytic Hierarchy Process approach
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality (VR); VR device; Purchase intention; Analytic hierarchy
   process (AHP)
ID DESK-TOP; CONTINUANCE; EDUCATION; DISPLAY
AB Virtual Reality (VR) is a technology that uses a specialized user interface to connect people to the virtual world, where they can enjoy a multitude of visual, auditory, olfactory, and tactile experiences. In this study, the analytic hierarchy process method is used to analyze the following four factors that affect consumers' purchase decisions with respect to VR products: VR system requirements, purchase-oriented marketing of VR products, VR application types, and user-friendliness of VR products. Additionally, this study also examines consumer preferences for various VR products. Despite the interviewees' concerns regarding computing power, product pricing, after-sales services, knowledge learning, and user-friendliness, the results of this study reveal that what they need most are VR products that can be used on the go. Therefore, portable VR is expected to be the trend as people are hoping to use VR applications whenever and wherever they wish to use them. This research provides the theoretical and managerial implications for understanding the potential trends for VR products and thus develops the appropriate marketing strategies for them.
C1 [Wu, Yenchun; Lin, I-Cheng] Natl Taiwan Normal Univ, Grad Inst Global Business & Strategy, 31 Shida Rd, Taipei 10645, Taiwan.
   [Chen, Shih-Chih] Natl Kaohsiung Univ Sci & Technol, Dept Informat Management, 1 Univ Rd, Kaohsiung 824, Taiwan.
C3 National Taiwan Normal University; National Kaohsiung University of
   Science & Technology
RP Chen, SC (corresponding author), Natl Kaohsiung Univ Sci & Technol, Dept Informat Management, 1 Univ Rd, Kaohsiung 824, Taiwan.
EM wuyenchun@gmail.com; scchen@nkust.edu.tw; judy.thelittlegirl@gmail.com
RI 吳, 書平/GXG-9770-2022; Chen, Shih-Chih/ABC-7705-2020
OI Chen, Shih-Chih/0000-0002-0039-421X; Wu, Yenchun/0000-0001-5479-2873
FU Ministry of Science and Technology, Taiwan [MOST 106-2511-S-003-029-MY3,
   107-2410-H-992-011]
FX The authors would like to thank the Ministry of Science and Technology,
   Taiwan, for financially supporting this research (Contract Number: MOST
   106-2511-S-003-029-MY3 and 107-2410-H-992-011).
CR Abry P, 2013, SIGNAL PROCESS, V93, P554, DOI 10.1016/j.sigpro.2012.01.016
   Alto P, 2017, MEDIA ALERT VIRTUAL
   [Anonymous], 2013, Human Technology: An Interdisciplinary Journal on Humans in ICT Environments, DOI DOI 10.17011/HT/URN.201305211721
   Barnes SJ, 2011, INFORM MANAGE-AMSTER, V48, P313, DOI 10.1016/j.im.2011.08.004
   Brown A, 2016, TECHTRENDS, V60, P517, DOI 10.1007/s11528-016-0102-z
   Cheng LK, 2014, VIRTUAL REAL-LONDON, V18, P173, DOI 10.1007/s10055-014-0244-2
   Cochrane T, 2016, INT J MOB BLENDED LE, V8, P44, DOI 10.4018/IJMBL.2016100104
   Computer Hope, 2017, COMP VS SMARTPH
   Cox DJ, 2010, MIL MED, V175, P411, DOI 10.7205/MILMED-D-09-00081
   Freeman D, 2014, PSYCHIAT RES, V218, P348, DOI 10.1016/j.psychres.2013.12.014
   Goel L, 2011, MIS QUART, V35, P749
   Grabowski A, 2015, SAFETY SCI, V72, P310, DOI 10.1016/j.ssci.2014.09.017
   Huang HM, 2016, INTERACT LEARN ENVIR, V24, P3, DOI 10.1080/10494820.2013.817436
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Huang IB, 2011, SCI TOTAL ENVIRON, V409, P3578, DOI 10.1016/j.scitotenv.2011.06.022
   Jones MG, 2016, INT J EDUC INF TECH, V10, P73
   Jung Y, 2011, J COMPUT-MEDIAT COMM, V16, P492, DOI 10.1111/j.1083-6101.2011.01540.x
   Kenney PA, 2009, UROLOGY, V73, P1288, DOI 10.1016/j.urology.2008.12.044
   Kober SE, 2012, INT J PSYCHOPHYSIOL, V83, P365, DOI 10.1016/j.ijpsycho.2011.12.003
   Kuo Y, 2008, COMPUT IND ENG, V55, P80, DOI 10.1016/j.cie.2007.12.002
   Lee EAL, 2014, COMPUT EDUC, V79, P49, DOI 10.1016/j.compedu.2014.07.010
   Lytras MD, 2017, INT J SEMANT WEB INF, V13, P1, DOI 10.4018/IJSWIS.2017010101
   Mäntymäki M, 2014, BEHAV INFORM TECHNOL, V33, P536, DOI 10.1080/0144929X.2013.872190
   Merchant Z, 2012, COMPUT EDUC, V59, P551, DOI 10.1016/j.compedu.2012.02.004
   Saaty T. L., 2008, INT J SERV SCI, V1, P83, DOI [10.1504/IJSSCI.2008.017590, DOI 10.1504/IJSSCI.2008.017590]
   SAATY TL, 1990, EUR J OPER RES, V48, P9, DOI 10.1016/0377-2217(90)90057-I
   Santos BS, 2011, IEEE COMPUT GRAPH, V31, P14, DOI 10.1109/MCG.2011.78
   Shobeiri S, 2013, J RETAIL CONSUM SERV, V20, P102, DOI 10.1016/j.jretconser.2012.10.011
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Sun R, 2018, VIRTUAL REAL
   Tromp J., 2018, SOCIAL NETWORKS SCI, P131, DOI [10.1007/978-3-319-90059-9_7, DOI 10.1007/978-3-319-90059-9_7]
   Velasquez M., 2013, INT J OPERATIONS RES, V10, P56
   Verhulst A, 2017, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2017.7892231
   Wu YCJ, 2015, COMPUT HUM BEHAV, V51, P1395, DOI 10.1016/j.chb.2014.10.001
NR 35
TC 4
Z9 4
U1 3
U2 39
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2019
VL 23
IS 2
BP 187
EP 195
DI 10.1007/s10055-018-0373-0
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA HZ5RO
UT WOS:000468910500007
DA 2024-07-18
ER

PT J
AU Kwon, C
AF Kwon, Chongsan
TI Verification of the possibility and effectiveness of experiential
   learning using HMD-based immersive VR technologies
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Authentic virtual reality; Presence; Experiential
   learning; Tactile interactivity; Locomotive interactivity
ID VIRTUAL-REALITY; SIMULATOR SICKNESS; ENVIRONMENTS; LOCOMOTION; TRAVEL;
   SCALE; FLOW
AB This paper examines the possibility of experiential learning in a virtual space using head-mounted-display-based immersive virtual reality (VR) technologies. Experiential learning refers to learning through direct experiences in the context of learning. Realistically, experiential learning is impossible in most cases, but VR technologies allowing direct interaction with virtual environments and objects are being developed and commercialized. These technologies are predicted to enhance vividness, interactivity, presence, flow, and experientiality, and increase the expectations of the possibility of experiential learning using VR. Thus, in this study, an experiment was conducted to verify such possibility. The analysis of the experiment results showed that the tactile interactivity and presence improved with the use of enhanced interaction technologies in VR, and in terms of experientiality, the experiment participants became highly aware of the exploratory stage, referring to the level of experience of being exposed to an interesting site and directly touching an object in the currently enhanced VR in providing direct tactile and locomotive interactivity. Furthermore, the fact that the learning effect is also partially enhanced was discovered. Accordingly, it was determined that experiential learning using VR is possible based on the experiment results, which showed that the enhanced vividness and interactivity of VR technologies allow the users to closely recognize virtual experiences as direct experiences, and that the learning effect is enhanced. It was also determined that experiential learning in a virtual environment that is identical to an experience in reality would be made possible in the near future based on continued technological development.
C1 [Kwon, Chongsan] Seoul Natl Univ, Grad Sch Convergence Sci & Technol, Dept Transdisciplinary Studies, Suwon, Gyeonggi Do, South Korea.
C3 Seoul National University (SNU)
RP Kwon, C (corresponding author), Seoul Natl Univ, Grad Sch Convergence Sci & Technol, Dept Transdisciplinary Studies, Suwon, Gyeonggi Do, South Korea.
EM jazzhana@snu.ac.kr
RI Kwon, Chongsan/ABA-1931-2020
OI Kwon, Chongsan/0000-0002-0736-8786
CR Anderson L., 2009, TAXONOMY LEARNING TE
   [Anonymous], 2000, BOREDOM ANXIETY
   [Anonymous], 2007, Journal of Science Education and Technology, DOI [DOI 10.1007/S10956-006-9037-Z, 10.1007/s10956-006-9037-z]
   [Anonymous], 1988, OPTIMAL EXPERIENCE
   [Anonymous], 2004, DEMOCRACY ED
   [Anonymous], INF SYST DIV INT COM
   [Anonymous], 1998, P 25 ANN C COMP GRAP
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Barfield W., 1995, J VIRTUAL REALITY SO, V1, P3, DOI DOI 10.1007/BF02009709
   Blake J, 2009, IEEE-ASME T MECH, V14, P606, DOI 10.1109/TMECH.2008.2010934
   BOCKER M, 1993, DESIGNING FOR DIVERSITY, VOLS 1 AND 2, P249
   Bouzit M, 2002, IEEE-ASME T MECH, V7, P256, DOI 10.1109/TMECH.2002.1011262
   Bracken C.C., 2010, Immersed in Media: Telepresence in Everyday Life
   Brennan D, 2017, ROAD TO VR
   Burdea G, 2000, IEEE T REHABIL ENG, V8, P430, DOI 10.1109/86.867886
   Cakmak T., 2014, ACM SIGGRAPH 2014 Emerging Technologies, P1, DOI DOI 10.1145/2614066.2614105
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Connelly L, 2010, IEEE T NEUR SYS REH, V18, P551, DOI 10.1109/TNSRE.2010.2047588
   Csikszentmihalyi M., 2008, FLOW PSYCHOL OPTIMAL
   Csikszentmihalyi M., 1986, BEING ADOLESCENT CON
   Csikszentmihalyi M., 1997, Talented teenagers: The roots of success and failure
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Dewey J., 1959, The child and the curriculum
   Draper MH, 2001, HUM FACTORS, V43, P129, DOI 10.1518/001872001775992552
   Dunleavy M, 2014, TECHTRENDS, V58, P28, DOI 10.1007/s11528-013-0717-2
   e Silva A.de Souza., 2006, Games and Culture, V1, P231, DOI DOI 10.1177/1555412006290443
   Elias G. S., 2012, CHARACTERISTICS GAME
   EyeSight Mobile Technologies Ltd, 2016, EYESIGHT GEST CONTR
   Gibbons M., 1980, J EXPERIENT EDUC, V3, P32, DOI [10.1177/105382598000300107, DOI 10.1177/105382598000300107]
   Izard SG, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0723-6
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hoffman DL, 1996, J MARKETING, V60, P50, DOI 10.2307/1251841
   Hou JH, 2012, COMPUT HUM BEHAV, V28, P617, DOI 10.1016/j.chb.2011.11.007
   Iwata H, 1996, P IEEE VIRT REAL ANN, P60, DOI 10.1109/VRAIS.1996.490511
   Iwata H, 1999, PRESENCE-TELEOP VIRT, V8, P587, DOI 10.1162/105474699566503
   Jackson SA, 1996, J SPORT EXERCISE PSY, V18, P17, DOI 10.1123/jsep.18.1.17
   Kamarainen AM, 2013, COMPUT EDUC, V68, P545, DOI 10.1016/j.compedu.2013.02.018
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim JH, 2009, WRITING PAPER STRUCT
   Klopfer E, 2002, IEEE INTERNATIONAL WORKSHOP ON WIRELESS AND MOBILE TECHNOLOGIES IN EDUCATION, PROCEEDINGS, P95, DOI 10.1109/WMTE.2002.1039227
   Klopfer Eric, 2010, New Dir Youth Dev, V2010, P85, DOI 10.1002/yd.378
   Kolb D.A., 2000, EXPERIENTIAL LEARNIN
   Kwon C, 2016, GAMES CULT, V11, P390, DOI 10.1177/1555412014568789
   Lang B, 2016, ROAD TO VR
   Lave J., 1991, SITUATED LEARNING LE, DOI DOI 10.1017/CBO9780511815355
   Lombard M., 1997, J COMPUT MEDIATED CO
   Maraj CS, 2017, ADV INTELL SYST, V498, P635, DOI 10.1007/978-3-319-42070-7_59
   Microsoft Inc, 2014, HANDP FULL ART HAND
   Munnerley D, 2012, RES LEARN TECHNOL, V20, P39, DOI 10.3402/rlt.v20i0.19189
   Neuman W. R., 1990, HDTV EXPLORING SUBJE
   Nichols S, 2000, INT J HUM-COMPUT ST, V52, P471, DOI 10.1006/ijhc.1999.0343
   Novak TP, 2000, MARKET SCI, V19, P22, DOI 10.1287/mksc.19.1.22.15184
   Perry B, 2014, P SOC BEHAV SCI, V174, P2308
   PilotBit Inc, 2018, FULL HAND SKEL TRACK
   Prensky M., 1998, TWITCH SPEED KEEPING
   Priest S., 2005, Effective leadership in adventure programming, V2nd
   Robertson A, 2015, THE VERGE
   Salen Katie, 2004, RULES PLAY GAME DESI
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert T. W., 1999, 2 INT WORKSH PRES
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Seibert J., 2017, VIRTUAL REALITY, P1
   Shafer DM, 2011, PRESENCE-TELEOP VIRT, V20, P591, DOI 10.1162/PRES_a_00084
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Shin J, 2016, MULTIMED TOOLS APPL, V75, P12331, DOI 10.1007/s11042-016-3520-1
   Skalski P, 2011, NEW MEDIA SOC, V13, P224, DOI 10.1177/1461444810370949
   Slater M., 1993, Presence, V2, P221, DOI [DOI 10.1162/PRES.1993.2.3.221, 10.1162/pres.1993.2.3.221]
   Squire K, 2007, J LEARN SCI, V16, P371, DOI 10.1080/10508400701413435
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   SUMA E., 2007, IEEE S 3D US INT, P149
   Treleaven J, 2015, VIRTUAL REAL-LONDON, V19, P267, DOI 10.1007/s10055-015-0266-4
   Villard Caroline, 2005, Computer Methods in Biomechanics and Biomedical Engineering, V8, P215, DOI 10.1080/10255840500289988
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yuyama I, 1982, HNK TECH MONOGR, V32, P14
   Zaman M, 2010, COMPUT HUM BEHAV, V26, P1009, DOI 10.1016/j.chb.2010.03.001
   Zanbaka CA, 2005, IEEE T VIS COMPUT GR, V11, P694, DOI 10.1109/TVCG.2005.92
   Zeltzer D., 1992, Presence: Teleoperators Virtual Environments, V1, P127, DOI [DOI 10.1162/PRES.1992.1.1.127, 10.1162/pres.1992.1.1.127]
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 78
TC 85
Z9 95
U1 13
U2 69
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2019
VL 23
IS 1
BP 101
EP 118
DI 10.1007/s10055-018-0364-1
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA HN8ZN
UT WOS:000460487500009
OA hybrid
DA 2024-07-18
ER

PT J
AU Lee, H
AF Lee, Hyunsoo
TI Real-time manufacturing modeling and simulation framework using
   augmented reality and stochastic network analysis
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual manufacturing; Augmented reality; Stochastic network; Petri net;
   Manufacturing layout design; Manufacturing simulation
ID LAYOUT
AB While the development of augmented reality (AR) technologies has made it possible to assign real-time features to many systems and applications, these trends are rare in manufacturing modeling and simulation. This research study proposes a real-time manufacturing layout modeler and material flow simulator. The manufacturing devices of interest are positioned using AR labels, and the generated layout is converted into a stochastic Petri net model, where the validity of material flow and other criteria are checked. In order to overcome the limitations of the Petri net model and enhance analytical functionalities, stochastic network analyses are embedded into the framework. The layout model with greater uncertainty is analyzed, and manufacturing performance indicators such as cycle time, throughput, and work-in process are estimated. The proposed framework is not simply an integration of AR techniques and manufacturing simulations, but provides an efficient AR labeling architecture for large-scale manufacturing environments, and is suitable for a fast, real-time rendering. In order to verify the effectiveness of the proposed framework, real-time modeling and simulation examples were used as case studies. The results showed that the proposed system contributes to more accurate layout design and simulation analysis by using the embedded AR techniques and queuing network methods.
C1 [Lee, Hyunsoo] Kumoh Natl Inst Technol, Sch Ind Engn, Gumi 730701, South Korea.
C3 Kumoh National University Technology
RP Lee, H (corresponding author), Kumoh Natl Inst Technol, Sch Ind Engn, Gumi 730701, South Korea.
EM hsl@kumoh.ac.kr
OI Lee, Hyunsoo/0000-0001-5512-2986
CR Abadi A, 2010, J IND ENG, V5, P43
   [Anonymous], STOCHASTIC MODELS MA
   Banerjee Prashant., 2001, VIRTUAL MANUFACTURIN
   Bause F., 2002, Stochastic Petri Nets: An Introduction to the Theory
   Curry GL, 2011, MANUFACTURING SYSTEMS MODELING AND ANALYSIS, SECOND EDITION, P1, DOI 10.1007/978-3-642-16618-1
   Ding JH, 2010, INFORMATION TECHNOLOGY FOR MANUFACTURING SYSTEMS, PTS 1 AND 2, P421, DOI 10.4028/www.scientific.net/AMM.20-23.421
   Dongwoo S., 2014, Adv. Sci. Technol. Lett., V64, P26, DOI [10.14257/astl.2014.64.07, DOI 10.14257/ASTL.2014.64.07]
   Dror M., 2002, MODELING UNCERTAINTY
   Haas P. J., 2002, SPRING S OPERAT RES
   Hyunsoo Lee，, 2017, [Journal of Korean Institute of Intelligent Systems, 한국지능시스템학회 논문지], V27, P459
   Jiang S, 2013, CIRP ANN-MANUF TECHN, V62, P483, DOI 10.1016/j.cirp.2013.03.133
   Joshi SB, 2012, COMPUTER CONTROL FLE
   Kim T, 2013, INT J LOGIST SCM SYS, V7, P39
   Kusiak A, 2018, INT J PROD RES, V56, P508, DOI 10.1080/00207543.2017.1351644
   Lachenmaier JF, 2017, PROC CIRP, V62, P577, DOI 10.1016/j.procir.2016.06.074
   Lee H, 2007, PROCEEDINGS OF THE 2007 WINTER SIMULATION CONFERENCE, VOLS 1-5, P1042
   Lee H, 2017, J MANUF SYST, V43, P257, DOI 10.1016/j.jmsy.2017.02.007
   Lee H, 2009, WINT SIMUL C PROC, P2191
   Lee H, 2011, VIRTUAL REAL-LONDON, V15, P21, DOI 10.1007/s10055-009-0151-0
   Lee H, 2008, J MANUF SYST, V27, P166, DOI 10.1016/j.jmsy.2009.02.001
   Lee Jay, 2015, Manufacturing Letters, V3, P18, DOI 10.1016/j.mfglet.2014.12.001
   Lee SD, 2001, INT J PROD RES, V39, P1183, DOI 10.1080/00207540010011036
   Novak-Marcincin J, 2012, ANN DAAAM, V23, P65
   Qi JY, 2010, CHIN CONTR CONF, P5224
   Qu T., 2016, International Journal of Advanced Manufacturing Technology, V84, P147, DOI 10.1007/s00170-015-7220-1
   Recalde L, 2004, LECT CONCURRENCY PET
   Saaski J, 2008, P NORDDESIGN 2008, V2008, P1
   Xiangyu Wang, 2007, International Journal of Advanced Robotic Systems, V4, P501
   Yang X., 2013, INT J COMPUT INTEG M, V8, P25
   Zhang YF, 2015, INT J COMPUT INTEG M, V28, P811, DOI 10.1080/0951192X.2014.900874
   Zhou M, 2015, CONTEMPORARY ISSUES IN SYSTEMS SCIENCE AND ENGINEERING, P1, DOI 10.1002/9781119036821
   Zhou M. C., 2012, Petri Net Synthesis for Discrete Event Control of Manufacturing Systems
NR 32
TC 13
Z9 14
U1 1
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2019
VL 23
IS 1
BP 85
EP 99
DI 10.1007/s10055-018-0343-6
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA HN8ZN
UT WOS:000460487500008
DA 2024-07-18
ER

PT J
AU Van Kerrebroeck, H
   Brengman, M
   Willems, K
AF Van Kerrebroeck, Helena
   Brengman, Malaika
   Willems, Kim
TI When brands come to life: experimental research on the vividness effect
   of Virtual Reality in transformational marketing communications
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual Reality; Vividness; Marketing communications; Presence; Brand
   attitudes
ID MEDIATING ROLE; TELEPRESENCE; IMPACT; INTERNET; ATTITUDE; WORLDS; STORE;
   INTERACTIVITY; INVOLVEMENT; ENVIRONMENT
AB Mobile Virtual Reality provides a gateway for marketers to innovatively reach consumers. This study examines the impact of Virtual Reality in the context of transformational brand experience appeals, focussing specifically on the determining role of vividness. A three-dimensional conceptual framework is presented, offering a systematic review of the literature on vividness effects in marketing communications, revealing the major gap that most available studies only focus on informational messages. We conducted an experiment to address this gap and demonstrate in the context of a transformational ad that Virtual Reality generates higher perceptions of vividness and presence than a regular two-dimensional video, with vividness positively affecting attitude toward the ad, both directly and indirectly via presence. Our study also reveals that vividness in turn elicits a positive effect on brand attitudes which stimulates consumers' purchase intentions. As such, the strategic potential of Virtual Reality for marketing communications is highlighted.
C1 [Van Kerrebroeck, Helena; Brengman, Malaika; Willems, Kim] Vrije Univ Brussel, Dept Business Mkt & Consumer Behav, Pl Laan 2 C2-12, B-1050 Brussels, Belgium.
   [Willems, Kim] Hasselt Univ, Dept Mkt & Strategy, Agoralaan Bldg D, B-3590 Diepenbeek, Belgium.
C3 Vrije Universiteit Brussel; Hasselt University
RP Van Kerrebroeck, H (corresponding author), Vrije Univ Brussel, Dept Business Mkt & Consumer Behav, Pl Laan 2 C2-12, B-1050 Brussels, Belgium.
EM helena.van.kerrebroeck@vub.ac.be; malaika.brengman@vub.ac.be;
   kim.willems@vub.ac.be
OI Willems, Kim/0000-0002-0941-8599; Brengman, Malaika/0000-0001-9860-7107
CR Adams R.L., 2016, 5 WAYS VIRTUAL REALI
   Alvares E., 2016, INSIDE ADIDAS NEW TE
   [Anonymous], 2006, MULTIVARIATE DATA AN
   [Anonymous], COMPANIES ARE MARKET
   [Anonymous], 2016, GARTNERS 2016 HYPE C
   [Anonymous], VIRT REAL SHOWC 228
   Bainbridge WS, 2007, SCIENCE, V317, P472, DOI 10.1126/science.1146930
   Barfield W, 2005, UCLA ENTERTAIN LAW R, V13, P153
   Baus O, 2017, VIRTUAL REAL-LONDON, V21, P59, DOI 10.1007/s10055-016-0299-3
   BIOCCA F, 1992, J COMMUN, V42, P5, DOI 10.1111/j.1460-2466.1992.tb00810.x
   Borsci S, 2016, VIRTUAL REAL-LONDON, V20, P41, DOI 10.1007/s10055-015-0281-5
   Chang L., 2016, DIGITAL TRENDS
   Cheng LK, 2014, VIRTUAL REAL-LONDON, V18, P173, DOI 10.1007/s10055-014-0244-2
   Choi YK, 2014, J BUS RES, V67, P2164, DOI 10.1016/j.jbusres.2014.04.026
   Coyle JR, 2001, J ADVERTISING, V30, P65, DOI 10.1080/00913367.2001.10673646
   Dahan E, 2000, J PROD INNOVAT MANAG, V17, P99, DOI 10.1016/S0737-6782(99)00029-6
   Debbabi S, 2010, J MARKET MANAG, V26, P967, DOI 10.1080/02672570903498819
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Dolbec PY, 2013, J RETAILING, V89, P460, DOI 10.1016/j.jretai.2013.06.003
   Domina T, 2012, J RETAIL CONSUM SERV, V19, P613, DOI 10.1016/j.jretconser.2012.08.001
   Fennis BM, 2012, J BUS RES, V65, P861, DOI 10.1016/j.jbusres.2011.01.008
   Fortin DR, 2005, J BUS RES, V58, P387, DOI 10.1016/S0148-2963(03)00106-1
   Goldsmith R.E., 1991, Journal of the Academy of Marketing Science, V19, P209, DOI [DOI 10.1007/BF02726497, 10.1007/bf02726497, 10.1007/BF02726497]
   Hair J. F., 2017, PRIMER PARTIAL LEAST, DOI [https://doi.org/10.1108/EBR-10-2013-0128, DOI 10.1007/978-3-030-80519-7]
   Hassouneh D, 2015, J ELECTRON COMMER RE, V16, P218
   Hassouneh D, 2014, COMPUT HUM BEHAV, V33, P330, DOI 10.1016/j.chb.2013.08.012
   Hassouneh D, 2011, J BRAND MANAG, V19, P72, DOI 10.1057/bm.2011.24
   Hernoux F, 2015, VIRTUAL REAL-LONDON, V19, P1, DOI 10.1007/s10055-014-0255-z
   HOMER PM, 1990, J MARKETING RES, V27, P78, DOI 10.2307/3172553
   Houliez C, 2013, VIRTUAL REAL-LONDON, V17, P263, DOI 10.1007/s10055-012-0218-1
   Jaunt, 2015, N FAC CLIMB
   Jin SAA, 2011, PSYCHOL MARKET, V28, P240, DOI 10.1002/mar.20390
   Jin SAA, 2009, J INTERACT MARK, V23, P234, DOI 10.1016/j.intmar.2009.04.005
   Jones P, 2010, MARK INTELL PLAN, V28, P241, DOI 10.1108/02634501011041408
   Karlis D, 2003, COMMUN STAT-THEOR M, V32, P643, DOI 10.1081/STA-120018556
   Keller PA, 1997, J CONSUM RES, V24, P295, DOI 10.1086/209511
   Keng CJ, 2006, CYBERPSYCHOL BEHAV, V9, P82, DOI 10.1089/cpb.2006.9.82
   Klein LR, 2003, J INTERACT MARK, V17, P41, DOI 10.1002/dir.10046
   Li HR, 2002, J ADVERTISING, V31, P43, DOI 10.1080/00913367.2002.10673675
   Lombard M., 2015, Immersed in media, P13, DOI [DOI 10.1007/978-3-319-10190-3, https://doi.org/10.1007/978-3-319-10190-32, DOI 10.1007/978-3-319-10190-32, 10.1007/978-3-319-10190-3_2, DOI 10.1007/978-3-319-10190-3_2]
   Manganari EE, 2009, EUR J MARKETING, V43, P1140, DOI 10.1108/03090560910976401
   Menzies RJ, 2016, VIRTUAL REAL-LONDON, V20, P173, DOI 10.1007/s10055-016-0288-6
   Metz R., 2016, OCULUS PROJECT LETS
   Muzellec L, 2012, EUR J MARKETING, V46, P811, DOI 10.1108/03090561211214618
   N. a, 2014, 360 VIRT EXP TOPSH U
   Newhouse D, 2013, LANCOME LAUNCHES 3D
   Newman SD, 2005, COGNITIVE BRAIN RES, V23, P235, DOI 10.1016/j.cogbrainres.2004.10.020
   Overmars S, 2015, INT REV RETAIL DISTR, V25, P236, DOI 10.1080/09593969.2014.988279
   PUTO CP, 1984, ADV CONSUM RES, V11, P638
   Rubin P, 2014, FUTURE TRAVEL HAS AR
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   SHIH C.F., 1998, EUR J MARKETING, V32, P655
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stott J., 2016, Virtual reality: Content marketing's next big trend
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Wallach HS, 2010, VIRTUAL REAL-LONDON, V14, P3, DOI 10.1007/s10055-009-0124-3
   Zeltzer D., 1992, Presence: Teleoperators Virtual Environments, V1, P127, DOI [DOI 10.1162/PRES.1992.1.1.127, 10.1162/pres.1992.1.1.127]
   Zheng L, 2016, CHINA DAILY
NR 58
TC 135
Z9 148
U1 12
U2 246
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2017
VL 21
IS 4
BP 177
EP 191
DI 10.1007/s10055-017-0306-3
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA FG6HN
UT WOS:000410473200002
DA 2024-07-18
ER

PT J
AU Lara, G
   De Antonio, A
   Peña, A
AF Lara, Graciela
   De Antonio, Angelica
   Pena, Adriana
TI Computerized spatial language generation for object location
SO VIRTUAL REALITY
LA English
DT Article
DE Spatial language; Spatial reference frames; Computer systems; Virtual
   environment; Objects location and perceptual salience
ID VISUAL SCENES; SALIENCE; SYSTEMS; FRAMES
AB Spatial language is the syntax used for object or place locations. Because an object location is inherently relative, it implies a frame of reference, which in turn may be aided by a reference object, other than the one to be located. This reference object is commonly selected based on its perceptual salience, that is, its more prominent features. Computer systems linked to various research areas have been developed to facilitate the communication and/or interpretation of spatial language for localization tasks. In this paper is presented a literature review of computer systems that adopt spatial language and perceptual salience for object location.
C1 [Lara, Graciela; Pena, Adriana] Univ Guadalajara, CUCEI, Ave Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
   [De Antonio, Angelica] Univ Politecn Madrid, Escuela Tecn Super Ingenieros Informat, Campus Montegancedo, Boadilla Del Monte, Spain.
C3 Universidad de Guadalajara; Universidad Politecnica de Madrid
RP Lara, G (corresponding author), Univ Guadalajara, CUCEI, Ave Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
EM graciela.lara@red.cucei.udg.mx
RI de Antonio, Angélica/B-2584-2009; Peña Pérez Negrón,
   Adriana/AFK-8243-2022
OI de Antonio, Angélica/0000-0002-8936-9095; Peña Pérez Negrón,
   Adriana/0000-0001-6823-2367
FU Universidad de Guadalajara, Mexico [UDG-685]; PROMEP scholarship
FX Graciela Lara holds a PROMEP scholarship in partnership with the
   Universidad de Guadalajara (UDG-685), Mexico.
CR Abella A., 1999, Proceedings Integration of Speech and Image Understanding, P117, DOI 10.1109/ISIU.1999.824875
   Andre E., 1988, ECAI 88. Proceedings of the 8th European Conference on Artificial Intelligence, P449
   Andre E, 1989, P 1 WORKSH LOG SEM T, P1
   Andre E, 1986, CHARACTERIZING TRAJE, P1
   Andre E, 1987, COPING INTRINSIC DEI, P375
   Barclay M., 2010, THESIS
   Byron Donna, 2007, THESIS
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Gapp K-P, 1995, OBJECT LOCALIZATION, P1
   Gapp K-P, 1996, SELECTION BEST REFER, P1
   Gorniak P, 2004, J ARTIF INTELL RES, V21, P429, DOI 10.1613/jair.1327
   Hall Daniela., 2002, British Machine Vision Conference, P646
   HAYWARD WG, 1995, COGNITION, V55, P39, DOI 10.1016/0010-0277(94)00643-Y
   Herzog G, 1995, P AAAI FALL S COMP M, P1
   Herzog G, 1992, VISUALIZATION METHOD, P1
   Huang LQ, 2005, VISION RES, V45, P1909, DOI 10.1016/j.visres.2005.01.013
   Kelleher J., 2003, THESIS
   Kelleher JD, 2009, COMPUT LINGUIST, V35, P271, DOI 10.1162/coli.06-78-prep14
   Lahera G, 2013, REV PSIQUIATR SALUD, V6, P45, DOI 10.1016/j.rpsm.2012.05.003
   LANDAU B, 1993, BEHAV BRAIN SCI, V16, P255, DOI 10.1017/S0140525X00029927
   Levinson S. C, 2003, Space in language and cognition: Explorations in cognitive diversity, V5
   Lockwood K, 2005, P 27 ANN C COGN SCI
   Lockwood K., 2006, P 28 ANN C COGN SCI
   Ma YY, 2012, NEUROSCI BIOBEHAV R, V36, P26, DOI 10.1016/j.neubiorev.2011.03.011
   MCMULLEN PA, 1990, MEM COGNITION, V18, P99, DOI 10.3758/BF03202650
   Moratz R, 2003, LECT NOTES ARTIF INT, V2685, P263
   Moratz R., 2006, Spatial Cogn. Compn, V6, P63, DOI DOI 10.1207/S15427633SCC0601_
   Mou WM, 2002, J EXP PSYCHOL LEARN, V28, P162, DOI 10.1037//0278-7393.28.1.162
   Mukerjee A, 2000, IMAGE VISION COMPUT, V18, P173, DOI 10.1016/S0262-8856(99)00022-0
   O'Meara C, 2011, LANG SCI, V33, P837, DOI 10.1016/j.langsci.2011.06.013
   Pederson E, 1998, LANGUAGE, V74, P557, DOI 10.2307/417793
   PINKER S, 1990, BEHAV BRAIN SCI, V13, P707, DOI 10.1017/S0140525X00081061
   Raubal M., 2002, Geographic Information Science. Second International Conference, GIScience 2002. Proceedings (Lecture Notes in Computer Science Vol.2478), P243
   Regier T, 2001, J EXP PSYCHOL GEN, V130, P273, DOI 10.1037//0096-3445.130.2.273
   Regier T, 1996, COMPUT LINGUIST, V23, P483
   Rickheit G, 2006, TRENDS LINGUIST-STUD, V166, P7
   Roser F., 2013, Experimental Psychology and Cognitive Science, P3315
   Roy DK, 2002, COMPUT SPEECH LANG, V16, P353, DOI 10.1016/S0885-2308(02)00024-4
   Shelton AL, 2001, COGNITIVE PSYCHOL, V43, P274, DOI 10.1006/cogp.2001.0758
   Skubic M, 2002, IEEE T SMC C, P1
   Spotorno S, 2013, ACTA PSYCHOL, V142, P168, DOI 10.1016/j.actpsy.2012.12.009
   Tenbrink T., 2012, LECT NOTES ARTIF INT, V7463, P279
   Titchener E.B., 1908, LECT ELEMENTARY PSYC
   Trinh TN, 2013, THESIS
   Vargas ML, 2011, ACTAS ESP PSIQUIATRI, P271
   Williams P, 2006, P 28 ANN C COGN SCI
   Winograd Terry, 1971, THESIS
   Wraga M, 1998, ELSEVIER ACTA PSYCHO, V102, P247
NR 48
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2016
VL 20
IS 3
BP 183
EP 192
DI 10.1007/s10055-016-0289-5
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DV0XZ
UT WOS:000382645300004
DA 2024-07-18
ER

PT J
AU Chin, S
   Lee, CY
   Lee, J
AF Chin, Seongah
   Lee, Chung Yeon
   Lee, Jaedong
TI An automatic method for motion capture-based exaggeration of facial
   expressions with personality types
SO VIRTUAL REALITY
LA English
DT Article
DE Facial expressions; Exaggeration; Facial motion capture; Facial motion
   cloning; Personality; MBTI; Nonnegative matrix factorization
ID MATRIX FACTORIZATION; DEFORMATION; RECOGNITION; INTENSITY; SEQUENCES;
   MANAGERS; EMOTION
AB Facial expressions have always attracted considerable attention as a form of nonverbal communication. In visual applications such as movies, games, and animations, people tend to be interested in exaggerated expressions rather than regular expressions since the exaggerated ones deliver more vivid emotions. In this paper, we propose an automatic method for exaggeration of facial expressions from motion-captured data with a certain personality type. The exaggerated facial expressions are generated by using the exaggeration mapping (EM) that transforms facial motions into exaggerated motions. As all individuals do not have identical personalities, a conceptual mapping of the individual's personality type for exaggerating facial expressions needs to be considered. The Myers-Briggs type indicator, which is a popular method for classifying personality types, is employed to define the personality-type-based EM. Further, we have experimentally validated the EM and simulations of facial expressions.
C1 [Chin, Seongah] Sungkyul Univ, Coll Engn, Div Multimedia, Anyang, South Korea.
   [Lee, Chung Yeon] Seoul Natl Univ, Biointelligence Lab, Sch Comp Sci & Engn, Seoul, South Korea.
   [Lee, Jaedong] Korea Univ, Coll Engn, Dept Comp Sci, DXP Lab, Seoul, South Korea.
C3 Sungkyul University; Seoul National University (SNU); Korea University
RP Chin, S (corresponding author), Sungkyul Univ, Coll Engn, Div Multimedia, Anyang, South Korea.
EM solideochin@gmail.com; jamixlee@gmail.com; eyewater3199@gmail.com
FU Korea Research Foundation [KRF-521-D00398]
FX This research was partially supported by the Korea Research Foundation
   Grant fund (KRF-521-D00398).
CR Ahn S, 2004, IEEE SYS MAN CYBERN, P660
   [Anonymous], 2002, P 2 INT S SMART GRAP
   [Anonymous], 2003, UNMASKING FACE GUIDE
   [Anonymous], 2008, Computer Facial Animation
   [Anonymous], VEH TECHN C VTC FALL
   [Anonymous], 1990, Imagination, Cognition, and Personality, DOI DOI 10.2190/DUGG-P24E-52WK-6CDG
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Calder AJ, 1997, P ROY SOC B-BIOL SCI, V264, P919, DOI 10.1098/rspb.1997.0127
   Calder AJ, 2000, COGNITION, V76, P105, DOI 10.1016/S0010-0277(00)00074-3
   Cao Y., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P225
   Chai J., 2003, EUR SIGGRAPH S COMP
   Chen Hong., 2004, P 3 INT S NONPHOTORE, P95, DOI DOI 10.1145/987
   Chin S, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/55665
   Chin S, 2010, CHIN OPT LETT, V8, P29, DOI 10.3788/COL20100801.0029
   Chin S, 2009, IEEE T SYST MAN CY C, V39, P315, DOI 10.1109/TSMCC.2008.2011283
   CHUANG ES, 2004, THESIS STANFORD U PA
   Clarke L, 2011, IEEE T VIS COMPUT GR, V17, P808, DOI 10.1109/TVCG.2010.76
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Deng Z., 2006, Proc. of ACM SIGGGRAPH/Eurographics Symposium on Computer Animation, P251
   Ekman P., 1971, Nebraska symposium on motivation, V19, P207
   Gardner WL, 1996, J MANAGE, V22, P45, DOI 10.1016/S0149-2063(96)90012-4
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Keltner D, 2004, J RES PERS, V38, P37, DOI 10.1016/j.jrp.2003.09.006
   Keltner D, 1996, COGNITION EMOTION, V10, P323, DOI 10.1080/026999396380277
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lewiner T, 2011, COMPUT GRAPH-UK, V35, P586, DOI 10.1016/j.cag.2011.03.005
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Liang L, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P386, DOI 10.1109/PCCGA.2002.1167882
   Ma Xiaohan., 2009, Proceedings of SCA 2009, P123
   Martin RA, 1996, J RES PERS, V30, P290, DOI 10.1006/jrpe.1996.0019
   Miranda JC, 2012, COMPUT GRAPH-UK, V36, P585, DOI 10.1016/j.cag.2012.03.002
   Mo Z., 2004, ACM SIGGRAPH 2004 SK, P57
   Morand DA, 2001, J BUS PSYCHOL, V16, P21, DOI 10.1023/A:1007831603825
   Myers Isabel Briggs, 1998, MBTI Manual: A Guide to the Development and Use of the Myers-Briggs Type Indicator
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   Pighin F, 1995, P SIGGRAPH 1998 INT, P75
   Platt S., 1981, Computer graphics, V15, P245
   Ratner P, 2003, 3 D HUMAN MODELING A
   Redman L., 1984, DRAW CARICATURES
   Rhodes G, 1997, SUPERPORTRAITS
   Scherer K.R., 1979, Emotions in personality and psychopathology, P493, DOI DOI 10.1007/978-1-4613-2892-6_18
   Seongah Chin, 2009, Proceedings of the 2009 International Conference on Computer Graphics & Virtual Reality. CGVR 2009, P91
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   Soon A, 2006, VISUAL COMPUT, V22, P478, DOI 10.1007/s00371-006-0023-5
   Tarantili VV, 2005, AM J ORTHOD DENTOFAC, V128, P8, DOI 10.1016/j.ajodo.2004.03.042
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Wang SF, 2010, COMPUT GRAPH FORUM, V29, P2161, DOI 10.1111/j.1467-8659.2010.01804.x
   Wang Y, 2004, COMPUT GRAPH FORUM, V23, P677, DOI 10.1111/j.1467-8659.2004.00800.x
   Waters K., 1987, COMPUTER GRAPHICS, V22, P17
   Zhang QS, 2006, IEEE T VIS COMPUT GR, V12, P48, DOI 10.1109/TVCG.2006.9
NR 55
TC 6
Z9 7
U1 0
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2013
VL 17
IS 3
BP 219
EP 237
DI 10.1007/s10055-013-0227-8
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 214EM
UT WOS:000324113800005
DA 2024-07-18
ER

PT J
AU Ventura, J
   Höllerer, T
AF Ventura, Jonathan
   Hoellerer, Tobias
TI Structure and motion in urban environments using upright panoramas
SO VIRTUAL REALITY
LA English
DT Article
DE Structure and motion; Urban environments; Panoramas
AB Image-based modeling of urban environments is a key component of enabling outdoor, vision-based augmented reality applications. The images used for modeling may come from off-line efforts, or online user contributions. Panoramas have been used extensively in mapping cities and can be captured quickly by an end-user with a mobile phone. In this paper, we describe and evaluate a reconstruction pipeline for upright panoramas taken in an urban environment. We first describe how panoramas can be aligned to a common vertical orientation using vertical vanishing point detection, which we show to be robust for a range of inputs. The orientation sensors in modern cameras can also be used to correct the vertical orientation. Secondly, we introduce a pose estimation algorithm, which uses knowledge of a common vertical orientation as a simplifying constraint. This procedure is shown to reduce pose estimation error in comparison with the state of the art. Finally, we evaluate our reconstruction pipeline with several real-world examples.
C1 [Ventura, Jonathan; Hoellerer, Tobias] Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
C3 University of California System; University of California Santa Barbara
RP Ventura, J (corresponding author), Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
EM jventura@cs.ucsb.edu
FU NSF CAREER grant [IIS-0747520]; Direct For Computer & Info Scie & Enginr
   [0747520] Funding Source: National Science Foundation; Div Of
   Information & Intelligent Systems [0747520] Funding Source: National
   Science Foundation
FX Thanks to Chris Coffin and Sehwan Kim for preparing the tripod panorama
   datasets, and to Google, Inc. for providing the Street View datasets.
   This work was partially supported by NSF CAREER grant IIS-0747520.
CR [Anonymous], COMP VIS WORKSH ICCV
   Antone M, 2002, INT J COMPUT VISION, V49, P143, DOI 10.1023/A:1020141505696
   Baatz G, 2010, LECT NOTES COMPUT SC, V6316, P266, DOI 10.1007/978-3-642-15567-3_20
   Fraundorfer F, 2010, LECT NOTES COMPUT SC, V6314, P269, DOI 10.1007/978-3-642-15561-1_20
   Gallagher AC, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P460, DOI 10.1109/CRV.2005.84
   HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352
   Hartley R.I., 2004, MULTIPLE VIEW GEOMET, V2nd, P238
   HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127
   Kosecká J, 2002, LECT NOTES COMPUT SC, V2353, P476
   Kukelova Z, 2011, LECT NOTES COMPUT SC, V6493, P216
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Micusik Branislav, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2906, DOI 10.1109/CVPRW.2009.5206535
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4
   Robertson D., 2004, BRITICH MACHINE VISI, P819
   Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Tardif JP, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2531, DOI 10.1109/IROS.2008.4651205
   Werner T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P548, DOI 10.1109/ICCV.2001.937564
NR 20
TC 7
Z9 8
U1 0
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2013
VL 17
IS 2
SI SI
BP 147
EP 156
DI 10.1007/s10055-012-0208-3
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 139IH
UT WOS:000318575200005
DA 2024-07-18
ER

PT J
AU Ragan, ED
   Bowman, DA
   Huber, KJ
AF Ragan, Eric D.
   Bowman, Doug A.
   Huber, Karl J.
TI Supporting cognitive processing with spatial information presentations
   in virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual environments; Memory; Cognition; Learning; Space
ID FIELD-OF-VIEW; WORKING-MEMORY; PERFORMANCE; LOCATION; REALITY; TRAVEL;
   SPACE
AB While it has been suggested that immersive virtual environments could provide benefits for educational applications, few studies have formally evaluated how the enhanced perceptual displays of such systems might improve learning. Using simplified memorization and problem-solving tasks as representative approximations of more advanced types of learning, we are investigating the effects of providing supplemental spatial information on the performance of learning-based activities within virtual environments. We performed two experiments to investigate whether users can take advantage of a spatial information presentation to improve performance on cognitive processing activities. In both experiments, information was presented either directly in front of the participant, at a single location, or wrapped around the participant along the walls of a surround display. In our first experiment, we measured memory scores and analyzed participant strategies for a memorization and recall task. In addition to comparing spatial and non-spatial presentations, we also varied field of view and background imagery. The results showed that the spatial presentation caused significantly better memory scores. Additionally, a significant interaction between background landmarks and presentation style showed that participants used more visualization strategies during the memorization task when background landmarks were shown with spatial presentations. To investigate whether the advantages of spatial information presentation extend beyond memorization to higher level cognitive activities, our second experiment employed a puzzle-like task that required critical thinking using the presented information. Focusing only on the effects of spatial presentations, this experiment measured task performance and mental workload. The results indicate that no performance improvements or mental workload reductions were gained from the spatial presentation method compared with a non-spatial layout for our problem-solving task. The results of these two experiments suggest that supplemental spatial information can affect mental strategies and support performance improvements for cognitive processing and learning-based activities. However, the effectiveness of spatial presentations is dependent on the nature of the task and a meaningful use of space and may require practice with spatial strategies.
C1 [Ragan, Eric D.; Bowman, Doug A.; Huber, Karl J.] Virginia Tech, Blacksburg, VA 24060 USA.
C3 Virginia Polytechnic Institute & State University
RP Ragan, ED (corresponding author), Virginia Tech, 2202 Kraft Dr, Blacksburg, VA 24060 USA.
EM eragan@vt.edu; dbowman@vt.edu; huberkj@vt.edu
OI Bowman, Doug/0000-0003-0491-5067
CR [Anonymous], 2003, PRESENCE CONNECT
   Baddeley A, 1998, CR ACAD SCI III-VIE, V321, P167, DOI 10.1016/S0764-4469(97)89817-4
   Bloom B, 1956, TAXONOMY ED OBJECTIV
   Boulos MNK, 2007, HEALTH INFO LIBR J, V24, P233, DOI 10.1111/J.1471-1842.2007.00733.x
   Bowman DA, 1999, PRESENCE-TELEOP VIRT, V8, P317, DOI 10.1162/105474699566251
   Bowman DA, 2003, P ACM S VIRT REAL SO
   Bowman DA, 2009, P JOINT VIRT REAL C
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Dalgarno B., 2002, E J INSTR SCI TECHNO, V5
   Dede C, 1999, MODEL DYN SYST, P282
   Duff SC, 2001, Q J EXP PSYCHOL-A, V54, P31, DOI 10.1080/02724980042000011
   Hart S. G., 1988, HUMAN MENTAL WORKLOA
   Hess SM, 1999, HUM FACTORS, V41, P257, DOI 10.1518/001872099779591187
   Johnson A, 1998, P IEEE VIRT REAL ANN, P176, DOI 10.1109/VRAIS.1998.658487
   JONES WP, 1986, ACM T INFORM SYST, V4, P42, DOI 10.1145/5401.5405
   Kennedy MM, 1999, EDUC EVAL POLICY AN, V21, P345, DOI 10.3102/01623737021004345
   Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   MANDLER JM, 1977, MEM COGNITION, V5, P10, DOI 10.3758/BF03209185
   McCreary FA, 1998, HUM FAC ERG SOC P, P1491
   Norman DA, 1991, CAMBRIDGE SERIES HUM, V4, P17
   PYLYSHYN Z, 1989, COGNITION, V32, P65, DOI 10.1016/0010-0277(89)90014-0
   Quarles J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P11
   Richardson DC, 2000, COGNITION, V76, P269, DOI 10.1016/S0010-0277(00)00084-6
   Roussou M., 2006, Virt Real, V10, P227, DOI 10.1007/s10055-006-0035-5
   Rymaszewski M., 2007, Second Life: The Official Guide
   Schuchardt P, 2007, P 2007 ACM S VIRT RE
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Sowndararajan A., 2008, P 2008 WORKSH IMM PR, P1
   Stasz C, 2001, OXFORD ECON PAP, V53, P385, DOI 10.1093/oep/53.3.385
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   Waller D, 1998, PRESENCE-TELEOP VIRT, V7, P129, DOI 10.1162/105474698565631
   Ware C., 2005, P 2 S APPL PERC GRAP
   WICKENS CD, 1988, HUM FACTORS, V30, P599, DOI 10.1177/001872088803000505
   Wickens CD, 2003, HUM FACTORS, V45, P360, DOI 10.1518/hfes.45.3.360.27250
   Wickens CD, 1992, IEEE INT C SYST MAN
   Winn W., 1999, Educational Technology, V39, P5
   Yates FrancesA., 1974, ART MEMORY
   Zanbaka C, 2004, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2004.1310068
NR 40
TC 35
Z9 40
U1 0
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2012
VL 16
IS 4
BP 301
EP 314
DI 10.1007/s10055-012-0211-8
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 025YG
UT WOS:000310233000004
DA 2024-07-18
ER

PT J
AU Dorozhkin, DV
   Vance, JM
   Rehn, GD
   Lemessi, M
AF Dorozhkin, Denis V.
   Vance, Judy M.
   Rehn, Gordon D.
   Lemessi, Marco
TI Coupling of interactive manufacturing operations simulation and
   immersive virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Concurrent operations simulation; Virtual reality
AB This paper presents a novel general-purpose simulation analysis application that combines concurrent operations simulation with the advanced data interrogation and user interaction capabilities of immersive virtual reality systems. The application allows for interactive modification of the simulation parameters, while providing the users with the available simulation information by effectively placing the operator in the midst of the environment being simulated. The major contribution of this research is the total integration of the immersive virtual reality environment with the simulation, allowing users in the environment to interactively change the inputs to the simulation as it is running. Implementation and functionality details of the developed application are presented. The experience of using the application to analyze a manufacturing operation in a collaborative scenario is also discussed.
C1 [Dorozhkin, Denis V.; Vance, Judy M.] Iowa State Univ, Dept Mech Engn, Virtual Real Applicat Ctr, Ames, IA 50011 USA.
   [Rehn, Gordon D.; Lemessi, Marco] Deere & Co, Simulat Grp, Ind Engn, Moline, IL 61265 USA.
C3 Iowa State University; Deere & Company
RP Dorozhkin, DV (corresponding author), Iowa State Univ, Dept Mech Engn, Virtual Real Applicat Ctr, Ames, IA 50011 USA.
EM dorodv@iastate.edu
OI Vance, Judy/0000-0001-9801-191X
FU Deere Company
FX The authors gratefully acknowledge the support provided by Deere &
   Company. The authors would like to thank the Institute of Electrical and
   Electronics Engineers (IEEE) for granting the permission to reuse
   portions of the article "Integrating Operations Simulation Results with
   an Immersive Virtual Reality Environment", by Gordon D. Rehn, Marco
   Lemessi, Judy M. Vance and Denis Dorozhkin, published in the Proceedings
   of the 2004 Winter Simulation Conference.
CR [Anonymous], 1999, OpenGL programming guide: the official guide to learning OpenGL
   Barfield W, 1995, VIRTUAL ENV ADV INT
   Bierbaum A, 2001, IEEE VIRT REAL 2001
   Dessouky MM, 2001, IIE TRANS, V33, P167, DOI 10.1080/07408170108936820
   Henriksen JO, 2000, WINT SIM C
   Kelsick J, 2003, J MECH DESIGN, V125, P428, DOI 10.1115/1.1587745
   Kesavadas T, 1999, ASME S VIRT REAL ENV
   Kibria D, 2002, WINT SIM C
   PRITSKER AAB, 1999, SIMULATION VISUAL SL
   Pulugurtha S., 2002, 7 INT C APPL ADV TEC
   Schriber TJ, 1997, WINT SIM C
   Strassburger S, 2005, WINT SIM C ORL FL
   Stuart R., 2001, The Design of Virtual Environments
   Whitman L, 2002, IND ENG RES C
NR 14
TC 20
Z9 25
U1 18
U2 103
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2012
VL 16
IS 1
SI SI
BP 15
EP 23
DI 10.1007/s10055-010-0165-7
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 897NL
UT WOS:000300657600003
DA 2024-07-18
ER

PT J
AU Ascone, L
   Wirtz, J
   Mellentin, AI
   Kugler, D
   Bremer, T
   Schadow, F
   Hoppe, S
   Jebens, C
   Kühn, S
AF Ascone, Leonie
   Wirtz, Janina
   Mellentin, Angelina Isabella
   Kugler, Dimitrij
   Bremer, Thomas
   Schadow, Friedrich
   Hoppe, Stine
   Jebens, Charlotte
   Kuehn, Simone
TI Transferring the approach avoidance task into virtual reality: a study
   in patients with alcohol use disorder versus healthy controls
SO VIRTUAL REALITY
LA English
DT Article
DE Approach bias; AAT; Alcohol use disorder; Virtual reality; Validation
ID AUTOMATIC ACTION-TENDENCIES; APPROACH BIAS; MECHANISMS; ADDICTION
AB Study aims were to (I) transfer the measurement of the approach bias (Apb) related to alcoholic stimuli via the Approach Avoidance Task (AAT) into Virtual Reality (VR), (II) check whether measuring Apb in VR leads to similar or different results compared to the classical PC-based version, (III) check the validity of VR versus PC-based bias scores in terms of relatedness to clinical variables. Different 'grasping-conditions' were tested and contrasted in VR concerning (Ia) feasibility (performance): (1) never grasp, (2) always grasp, (3) grasp when PULLing stimuli towards oneself. (Ib) Differences in the bias scores between patients with alcohol use disorder (AUD) and healthy controls (HC) were examined for each grasping-condition. (II) PC-based bias scores were computed and contrasted for AUD versus HC. (III) Correlations of the different VR- versus PC-based bias scores with AUD symptom severity and impulsivity were checked to evaluate validity. (Ia) Grasping-condition 1, followed by 3, showed acceptable (> 50%) and good (> 80%) rates of correct performances allowing for robust median estimation. (Ib) Significant differences in the resulting bias scores emerged between AUD and HC only for grasping-condition 1 (p = 0.034) and 3 at trend-level (p = 0.093). For grasping-condition 1 the Apb Median for AUD was different from zero at a non-significant trend-level (p = 0.064). (II) The PC-based bias scores did not discriminate between AUD versus HC groups. (III) Grasping-condition 1 and 3 VR-based bias scores correlated significantly with impulsivity. In sum, transferring the AAT into VR is feasible, valid, and best implemented without an additional grasping-component when using the VR-controller. This way of Apb assessment represents a viable, perhaps even superior, alternative to PC-based assessments.Trial registration The trial was pre-registered at AsPredicted #76854: 'Transferring the approach avoidance task into virtual reality', 10/13/2021; prior to any analyses being undertaken.
C1 [Ascone, Leonie; Wirtz, Janina; Kugler, Dimitrij; Kuehn, Simone] Univ Med Ctr Hamburg Eppendorf, Dept Psychiat & Psychotherapy, Neuronal Plast Working Grp, Martinistr 52, D-20246 Hamburg, Germany.
   [Kuehn, Simone] Max Planck Inst Human Dev, Lise Meitner Grp Environm Neurosci, Lentzeallee 94, D-14195 Berlin, Germany.
   [Mellentin, Angelina Isabella] Univ Southern Denmark, Dept Clin Res, Unit Clin Alcohol Res, Unit Psychiat Res, J B Winslowvej 18, DK-5000 Odense C, Denmark.
   [Mellentin, Angelina Isabella] Univ Southern Denmark, Dept Clin Res, Brain Res Interdisciplinary Guided Excellence BRID, DK-5000 Odense C, Denmark.
   [Mellentin, Angelina Isabella] Ctr Digital Psychiat CEDIP, Heden 11, DK-5000 Odense C, Denmark.
   [Bremer, Thomas; Schadow, Friedrich] Univ Appl Sci, Treskowallee 8, D-10318 Berlin, Germany.
   [Hoppe, Stine; Jebens, Charlotte] Christian Albrechts Univ Kiel, Dept Clin Psychol & Psychotherapy, Christian Albrechts Pl 4, D-24118 Kiel, Germany.
   [Kuehn, Simone] Max Planck Inst Human Dev, Max Planck UCL Ctr Computat Psychiat & Ageing Res, Lentzeallee 94, D-14195 Berlin, Germany.
C3 University of Hamburg; University Medical Center Hamburg-Eppendorf; Max
   Planck Society; University of Southern Denmark; University of Southern
   Denmark; University of Kiel; Max Planck Society
RP Ascone, L (corresponding author), Univ Med Ctr Hamburg Eppendorf, Dept Psychiat & Psychotherapy, Neuronal Plast Working Grp, Martinistr 52, D-20246 Hamburg, Germany.
EM l.ascone-michelis@uke.de
RI Ascone, Leonie/AAR-1811-2021
OI Ascone, Leonie/0000-0002-9059-9277
FU Projekt DEAL; European Union [ERC-2016-StG-Self-Control-677804]; Max
   Planck Society and the German Science Foundation [TRR 169/C8, SFB
   936/C7]
FX Open Access funding enabled and organized by Projekt DEAL. S.K. received
   research grants from the European Union
   (ERC-2016-StG-Self-Control-677804, Interreg: Baltic Game Industry), the
   Max Planck Society and the German Science Foundation (TRR 169/C8, SFB
   936/C7) S.K. developed the imaginal retraining technique & nbsp;together
   with S.M. The study was funded by the European Union
   (ERC-2016-StG-Self-Control-677804, Interreg: Baltic Game Industry) as
   well as overhead sources.
CR Babor T.F., 2001, The Alcohol Use Disorders Identification Test. Guidelines for Use in Primary Care
   Barkby H, 2012, ALCOHOL CLIN EXP RES, V36, P361, DOI 10.1111/j.1530-0277.2011.01620.x
   Castillo-Carniglia A, 2019, LANCET PSYCHIAT, V6, P1068, DOI 10.1016/S2215-0366(19)30222-6
   Dijksterhuis A, 2001, ADV EXP SOC PSYCHOL, V33, P1, DOI 10.1016/S0065-2601(01)80003-4
   Dijkstra K, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01525
   Fridland E, 2018, PHENOMENOL COGN SCI, V17, P15, DOI 10.1007/s11097-017-9508-0
   Kakoschke N, 2017, ADDICT BEHAV, V64, P21, DOI 10.1016/j.addbeh.2016.08.007
   Kim DY, 2019, CYBERPSYCH BEH SOC N, V22, P794, DOI 10.1089/cyber.2019.0121
   Kim DY, 2015, CYBERPSYCH BEH SOC N, V18, P763, DOI 10.1089/cyber.2014.0490
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Lender A, 2018, APPETITE, V125, P42, DOI 10.1016/j.appet.2018.01.032
   Litten RZ, 2015, ALCOHOL CLIN EXP RES, V39, P579, DOI 10.1111/acer.12669
   Patton JH, 1995, J CLIN PSYCHOL, V51, P768, DOI 10.1002/1097-4679(199511)51:6<768::AID-JCLP2270510607>3.0.CO;2-1
   Rinck M, 2007, J BEHAV THER EXP PSY, V38, P105, DOI 10.1016/j.jbtep.2006.10.001
   Sheehan DV, 1998, J CLIN PSYCHIAT, V59, P22, DOI 10.4088/JCP.09m05305whi
   Skinner H.A., 1984, ALCOHOL DEPENDENCE S
   Spruyt A, 2013, DRUG ALCOHOL DEPEN, V127, P81, DOI 10.1016/j.drugalcdep.2012.06.019
   SULLIVAN JT, 1989, BRIT J ADDICT, V84, P1353
   Watson P, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00440
   Wiers CE, 2013, PSYCHOPHARMACOLOGY, V229, P187, DOI 10.1007/s00213-013-3098-5
   Wiers RW, 2009, GENES BRAIN BEHAV, V8, P101, DOI 10.1111/j.1601-183X.2008.00454.x
   Wiers RW, 2013, CLIN PSYCHOL SCI, V1, P192, DOI 10.1177/2167702612466547
   Wiers RW, 2011, PSYCHOL SCI, V22, P490, DOI 10.1177/0956797611400615
   Wiers RW, 2010, ADDICTION, V105, P279, DOI 10.1111/j.1360-0443.2009.02775.x
   World Health Organization, 2018, Global status report on alcohol and health 2018
NR 25
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2711
EP 2722
DI 10.1007/s10055-023-00835-7
EA AUG 2023
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001042081700003
PM 37614715
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Bassano, C
   Chessa, M
   Solari, F
AF Bassano, Chiara
   Chessa, Manuela
   Solari, Fabio
TI Visual working memory in immersive visualization: a change detection
   experiment and an image-computable model
SO VIRTUAL REALITY
LA English
DT Article
DE Change blindness; Immersive virtual reality; Depth; Visual angle; 3D
   spatial arrangement; Saliency
ID SALIENCY; CAPACITY; ATTENTION; REPRESENTATIONS; CONSCIOUSNESS; STORAGE;
   PEOPLE
AB Visual working memory (VWM) is a cognitive mechanism essential for interacting with the environment and accomplishing ongoing tasks, as it allows fast processing of visual inputs at the expense of the amount of information that can be stored. A better understanding of its functioning would be beneficial to research fields such as simulation and training in immersive Virtual Reality or information visualization and computer graphics. The current work focuses on the design and implementation of a paradigm for evaluating VWM in immersive visualization and of a novel image-based computational model for mimicking the human behavioral data of VWM. We evaluated the VWM at the variation of four conditions: set size, spatial layout, visual angle (VA) subtending stimuli presentation space, and observation time. We adopted a full factorial design and analysed participants' performances in the change detection experiment. The analysis of hit rates and false alarm rates confirms the existence of a limit of VWM capacity of around 7 & PLUSMN; 2 items, as found in the literature based on the use of 2D videos and images. Only VA and observation time influence performances (p<0.0001). Indeed, with VA enlargement, participants need more time to have a complete overview of the presented stimuli. Moreover, we show that our model has a high level of agreement with the human data, r>0.88 (p<0.05).
C1 [Bassano, Chiara; Chessa, Manuela; Solari, Fabio] Univ Genoa, Dept Informat Bioengn Robot & Syst Engn, Via Dodecaneso 35, I-16146 Genoa, Italy.
C3 University of Genoa
RP Chessa, M; Solari, F (corresponding author), Univ Genoa, Dept Informat Bioengn Robot & Syst Engn, Via Dodecaneso 35, I-16146 Genoa, Italy.
EM chiara.bassano@dibris.unige.it; manuela.chessa@unige.it;
   fabio.solari@unige.it
RI Chessa, Manuela/O-4628-2016; Solari, Fabio/O-4729-2016
OI Solari, Fabio/0000-0002-8111-0409
CR Alvarez GA, 2011, TRENDS COGN SCI, V15, P122, DOI 10.1016/j.tics.2011.01.003
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   [Anonymous], 2009, ADV NEURAL INFORM PR
   BALLARD DH, 1995, J COGNITIVE NEUROSCI, V7, P66, DOI 10.1162/jocn.1995.7.1.66
   Bays PM, 2008, SCIENCE, V321, P851, DOI 10.1126/science.1158023
   Block N, 2011, TRENDS COGN SCI, V15, P567, DOI 10.1016/j.tics.2011.11.001
   Brady TF, 2022, J EXP PSYCHOL LEARN, V48, P942, DOI 10.1037/xlm0001014
   Brady TF, 2013, PSYCHOL REV, V120, P85, DOI 10.1037/a0030779
   Brockmole JR, 2005, PSYCHON B REV, V12, P1061, DOI 10.3758/BF03206444
   Brunel N, 2001, J COMPUT NEUROSCI, V11, P63, DOI 10.1023/A:1011204814320
   Capasso I, 2022, LECT NOTES COMPUT SC, V13445, P130, DOI 10.1007/978-3-031-15546-8_11
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Cohen MA, 2016, TRENDS COGN SCI, V20, P324, DOI 10.1016/j.tics.2016.03.006
   Compte A, 2000, CEREB CORTEX, V10, P910, DOI 10.1093/cercor/10.9.910
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Cowan N, 2005, COGNITIVE PSYCHOL, V51, P42, DOI 10.1016/j.cogpsych.2004.12.001
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Dempere-Marco L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042719
   Draschkow D, 2021, CURR BIOL, V31, P869, DOI 10.1016/j.cub.2020.11.013
   Endress AD, 2014, J EXP PSYCHOL GEN, V143, P548, DOI 10.1037/a0033934
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fang S, 2017, IEEE T NEUR NET LEAR, V28, P1095, DOI 10.1109/TNNLS.2016.2522440
   Fine MS, 2009, J NEUROSCI, V29, P8016, DOI 10.1523/JNEUROSCI.5503-08.2009
   Fougnie D, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms2237
   Foulsham T, 2007, PERCEPTION, V36, P1123, DOI 10.1068/p5659
   Foulsham T, 2008, J VISION, V8, DOI 10.1167/8.2.6
   Franconeri SL, 2007, J EXP PSYCHOL HUMAN, V33, P1003, DOI 10.1037/0096-1523.33.5.1003
   Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gras D, 2013, J COGN PSYCHOL, V25, P38, DOI 10.1080/20445911.2012.739154
   Guo ZY, 2020, J MANUF SYST, V56, P525, DOI 10.1016/j.jmsy.2020.07.007
   Gusev AN, 2014, PSYCHOL RUSS, V7, P122, DOI 10.11621/pir.2014.0112
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jaiswal N, 2010, BRAIN RES, V1347, P80, DOI 10.1016/j.brainres.2010.05.086
   Karacan H, 2010, COMPUT HUM BEHAV, V26, P1305, DOI 10.1016/j.chb.2010.04.002
   Keshvari S, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002927
   Kouider S, 2010, TRENDS COGN SCI, V14, P301, DOI 10.1016/j.tics.2010.04.006
   Kristjánsson A, 2021, ATTEN PERCEPT PSYCHO, V83, P1375, DOI 10.3758/s13414-021-02256-7
   Kummerer M, 2018, MIT TUBINGEN SALIENC
   La Corte V, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00173
   Lau H, 2011, TRENDS COGN SCI, V15, P365, DOI 10.1016/j.tics.2011.05.009
   Li C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21963-0
   Li XD, 2021, VIRTUAL REAL-LONDON, V25, P1123, DOI 10.1007/s10055-021-00512-7
   Lochner MJ, 2014, ATTEN PERCEPT PSYCHO, V76, P2326, DOI 10.3758/s13414-014-0694-3
   Luck SJ, 1997, NATURE, V390, P279, DOI 10.1038/36846
   Luck SJ, 2013, TRENDS COGN SCI, V17, P391, DOI 10.1016/j.tics.2013.06.006
   Ma LQ, 2013, IEEE T VIS COMPUT GR, V19, P1808, DOI 10.1109/TVCG.2013.99
   Ma WJ, 2014, NAT NEUROSCI, V17, P347, DOI 10.1038/nn.3655
   Maiello G, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1007699
   Marwecki S, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P777, DOI 10.1145/3332165.3347919
   Matzen LE, 2018, IEEE T VIS COMPUT GR, V24, P563, DOI 10.1109/TVCG.2017.2743939
   Meilinger T, 2008, COGNITIVE SCI, V32, P755, DOI 10.1080/03640210802067004
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Pedale T, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00060
   PHILLIPS WA, 1974, PERCEPT PSYCHOPHYS, V16, P283, DOI 10.3758/BF03203943
   Polatsek P, 2018, COMPUT GRAPH-UK, V72, P26, DOI 10.1016/j.cag.2018.01.010
   Posner M.I., 1978, Modes of perceiving and processing information, V137, P2
   PYLYSHYN Z W, 1988, Spatial Vision, V3, P179, DOI 10.1163/156856888X00122
   Read T, 2023, VIRTUAL REAL-LONDON, V27, P1265, DOI 10.1007/s10055-022-00723-6
   Rensink RA, 1997, PSYCHOL SCI, V8, P368, DOI 10.1111/j.1467-9280.1997.tb00427.x
   Rensink Ronald A., 2005, P76, DOI 10.1016/B978-012375731-9/50017-3
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   Robinson MM, 2020, COGNITIVE PSYCHOL, V121, DOI 10.1016/j.cogpsych.2020.101305
   Rouder JN, 2011, PSYCHON B REV, V18, P682, DOI 10.3758/s13423-011-0088-7
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Schneegans S, 2020, P NATL ACAD SCI USA, V117, P20959, DOI 10.1073/pnas.2004306117
   Seinfeld S, 2022, IEEE T VIS COMPUT GR, V28, P1545, DOI 10.1109/TVCG.2020.3021342
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Simons DJ, 1998, PSYCHON B REV, V5, P644, DOI 10.3758/BF03208840
   Simons DJ, 2000, PERCEPTION, V29, P1143, DOI 10.1068/p3104
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Steinicke F, 2011, IEEE T VIS COMPUT GR, V17, P1223, DOI 10.1109/TVCG.2011.41
   Stirk JA, 2007, J VISION, V7, DOI 10.1167/7.10.3
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   SVENSON O, 1983, J GENET PSYCHOL, V142, P203, DOI 10.1080/00221325.1983.10533512
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Thornton IM, 2022, Q J EXP PSYCHOL, V75, P297, DOI 10.1177/1747021820961640
   Underwood G, 2006, Q J EXP PSYCHOL, V59, P1931, DOI 10.1080/17470210500416342
   van den Berg R, 2018, ELIFE, V7, DOI 10.7554/eLife.34963
   van den Berg R, 2017, PSYCHOL REV, V124, P197, DOI 10.1037/rev0000060
   Varakin DA, 2007, PERCEPTION, V36, P737, DOI 10.1068/p5572
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417
   Wilken P, 2004, J VISION, V4, P1120, DOI 10.1167/4.12.11
   Williams JR, 2022, J EXP PSYCHOL HUMAN, V48, P1390, DOI 10.1037/xhp0001055
   Wloka C, 2018, ARXIV
   Wolfe JM, 2013, J VISION, V13, DOI 10.1167/13.3.10
   Wolfe JM, 2012, PSYCHOL SCI, V23, P698, DOI 10.1177/0956797612443968
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang WW, 2008, NATURE, V453, P233, DOI 10.1038/nature06860
NR 92
TC 1
Z9 1
U1 5
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2493
EP 2507
DI 10.1007/s10055-023-00822-y
EA JUN 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001015438600001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Onderdijk, KE
   Bouckaert, L
   Van Dyck, E
   Maes, PJ
AF Onderdijk, Kelsey E.
   Bouckaert, Lies
   Van Dyck, Edith
   Maes, Pieter-Jan
TI Concert experiences in virtual reality environments
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Music concerts; Livestream; Social connection;
   Presence; Uniqueness
ID SOCIAL PRESENCE; E-MAIL; MUSIC; ENGAGEMENT; CONSUMPTION; ONLINE
AB Spurred by recent advances in digital technologies, virtual concerts have become established modes for event attendance and represent a rapidly growing segment of the music industry. Yet, up to now, general experience of virtual concert attendees remains largely underexplored. Here, we focus on a subcategory in this domain: music concerts in virtual reality (VR). Our approach is situated within the theoretical framework of embodied music cognition and entailed investigation through a survey study. Responses of seventy-four VR concert attendees were collected, consisting of demographics, motivations, experiences, and future perspectives. In contrast to previous research, which generally identified social connectedness as a main motivator for concert attendance, our sample regarded it as one of the least important incentives. On the other hand, in line with previous studies, 'seeing specific artists perform' and 'uniqueness of the experience', were pivotal. The latter was mostly fueled by the possibility to experience/interact with visuals and environments considered as unconceivable in the real world. Furthermore, 70% of our sample regarded VR concerts as 'the future of the music industry', mainly relating to the accessibility of such events. Positive evaluations of VR concert experiences, as well as future perspectives regarding the medium, were significantly influenced by the level of experienced immersivity. To our knowledge, this is the first study to provide such an account.
C1 [Onderdijk, Kelsey E.; Bouckaert, Lies; Van Dyck, Edith; Maes, Pieter-Jan] Univ Ghent, Dept Arts Mus & Theatre Sci, IPEM, Ghent, Belgium.
C3 Ghent University
RP Van Dyck, E (corresponding author), Univ Ghent, Dept Arts Mus & Theatre Sci, IPEM, Ghent, Belgium.
EM edith.vandyck@ugent.be
RI Van Dyck, Edith/ITU-6709-2023
OI Van Dyck, Edith/0000-0001-7239-1918; Maes,
   Pieter-Jan/0000-0002-9237-3298; Onderdijk, Kelsey E./0000-0001-9992-7620
CR Aguiar L, 2018, INT J IND ORGAN, V57, P278, DOI 10.1016/j.ijindorg.2017.06.004
   Allmendinger K, 2010, EDUC PSYCHOL REV, V22, P41, DOI 10.1007/s10648-010-9117-8
   Auslander P., 2008, Liveness: Performance in a mediatized culture, V2nd, DOI DOI 10.4324/9780203938133
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Beaufils K., 2022, Hybrid, P1, DOI DOI 10.4000/HYBRID.2664
   Belfi AM, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.618025
   Black GC, 2007, POP MUSIC SOC, V30, P149, DOI 10.1080/03007760701267698
   Bonett DG, 2015, J ORGAN BEHAV, V36, P3, DOI 10.1002/job.1960
   Brandtzæg PB, 2009, LECT NOTES COMPUT SC, V5621, P143, DOI 10.1007/978-3-642-02774-1_16
   Breese JL., 2020, Issues in Information Systems, V21, P179, DOI [DOI 10.48009/3_IIS_2020_179-188, 10.48009/3_iis_2020_179-188]
   Brown SC, 2017, MUSIC SCI, V21, P233, DOI 10.1177/1029864916650719
   Caldas OI, 2022, VIRTUAL REAL-LONDON, V26, P1507, DOI 10.1007/s10055-022-00645-3
   Cayari C, 2011, INT J EDUC ARTS, V12, P1
   Charron JP, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00800
   Cortese J, 2012, COMMUN RES REP, V29, P44, DOI 10.1080/08824096.2011.639913
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Datta H, 2018, MARKET SCI, V37, P5, DOI 10.1287/mksc.2017.1051
   de Kort YAW, 2007, P 10 ANN INT WORKSHO, P195
   Dey A. K., 2006, Conference on Human Factors in Computing Systems. CHI2006, P899
   Durlach N, 2000, PRESENCE-TELEOP VIRT, V9, P214, DOI 10.1162/105474600566736
   Earl PE, 2001, J ECON PSYCHOL, V22, P335, DOI 10.1016/S0167-4870(01)00037-X
   Feldmeier M, 2007, COMPUT MUSIC J, V31, P50, DOI 10.1162/comj.2007.31.1.50
   Felnhofer A., 2012, P INT SOC PRESENCE R
   Fox J., 2019, An R Companion to Applied Regression, VThird
   Friedlander Mathilde B., 2017, Journal of Information Management, V5, P65
   Godbey G, 2010, J LEISURE RES, V42, P111, DOI 10.1080/00222216.2010.11950197
   Gotting M.C., 2022, STATISTA
   Gotting MC, 2021, STATISTA
   Hamilton WA, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1315, DOI 10.1145/2556288.2557048
   Hammick JK, 2014, COMPUT HUM BEHAV, V33, P302, DOI 10.1016/j.chb.2013.01.046
   Hertel G, 2008, SOC PSYCHOL-GERMANY, V39, P231, DOI 10.1027/1864-9335.39.4.231
   Hilvert-Bruce Z, 2018, COMPUT HUM BEHAV, V84, P58, DOI 10.1016/j.chb.2018.02.013
   Holt F, 2010, EUR J CULT STUD, V13, P243, DOI 10.1177/1367549409352277
   Ijsselsteijn W., 2003, P INT C HUMAN COMPUT, P924
   Joinson AN, 2004, CYBERPSYCHOL BEHAV, V7, P472, DOI 10.1089/cpb.2004.7.472
   Kang SH, 2014, COMPUT HUM BEHAV, V34, P120, DOI 10.1016/j.chb.2014.01.006
   Kennedy M, 2020, EUR J CULT STUD, V23, P1069, DOI 10.1177/1367549420945341
   Khalid A, 2020, QUARTZ
   Khan ML, 2017, COMPUT HUM BEHAV, V66, P236, DOI 10.1016/j.chb.2016.09.024
   Krause A. E., 2020, Music & Science, V3, P1, DOI [10.1177/2059204320941320, DOI 10.1177/2059204320941320]
   Lamont A, 2011, MUSIC SCI, V15, P229, DOI 10.1177/1029864911403368
   Lee D., 2020, Coronavirus, the cultural catalyst
   Leman M., 2008, Embodied Music Cognition and Mediation Technology, DOI [DOI 10.7551/MITPRESS/7476.001.0001, 0.7551/mitpress/7476.001.0001, 10.7551/mitpress/7476.001.0001]
   Lesaffre M, 2017, ROUTLEDGE COMPANION TO EMBODIED MUSIC INTERACTION, P1
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Nguyen H.T. T., 2018, Audiences' engagement with Twitter and Facebook Live during classical music performances: Community and connectivity through live listening experiences, DOI DOI 10.17077/ETD.IPOK-YUOJ
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Onderdijk KE, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.647929
   Pallavicini F, 2019, SIMULAT GAMING, V50, P136, DOI 10.1177/1046878119831420
   Park SM, 2022, IEEE ACCESS, V10, P4209, DOI 10.1109/ACCESS.2021.3140175
   Phelan Peggy., 1993, Unmarked: The Politics of Performance
   Pitts S, 2014, SEMPRE STUD PSYCHOL, P21
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Radbourne J, 2014, SEMPRE STUD PSYCHOL, P55
   Radoff J, 2022, MEDIUM
   Ren Y, 2020, TELEGRAPH
   Rettie R., 2003, Proceeding of 6th Annual International Workshop Presence, P1
   Rizopoulos D, 2006, J STAT SOFTW, V17
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Shoda H, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154322
   Shoda H, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01564
   Skjuve M, 2019, INTERACT COMPUT, V31, P589, DOI 10.1093/iwc/iwz038
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2023, VIRTUAL REAL-LONDON, V27, P651, DOI 10.1007/s10055-022-00685-9
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smolentsev A, 2017, VIRTUAL REAL-LONDON, V21, P153, DOI 10.1007/s10055-017-0305-4
   Swarbrick D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.648448
   Swarbrick D, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02682
   Tamborini R., 2010, IMMERSED IN MEDIA, P87
   Tarumi H, 2017, LECT NOTES COMPUT SC, V10397, P14, DOI 10.1007/978-3-319-63088-5_2
   Van Kerrebroeck B, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.663725
   Vandenberg F, 2021, EUR SOC, V23, pS141, DOI 10.1080/14616696.2020.1818271
   Vergauwen R, 2021, REKTOVERSO
   Wang Q, 2008, COMMUN Q, V56, P87, DOI 10.1080/01463370701839057
   Wang T, 2021, HEART FIRE SMART WAT, DOI [10.36227/techrxiv.17126768.v1, DOI 10.36227/TECHRXIV.17126768.V1]
   Weaver Caity., 2020, The New York Times
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yang J, 2017, AER ADV ENG RES, V141, P596
NR 78
TC 4
Z9 4
U1 16
U2 33
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2383
EP 2396
DI 10.1007/s10055-023-00814-y
EA JUN 2023
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000999000800001
PM 37360813
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Jeong, D
   Paik, S
   Noh, Y
   Han, K
AF Jeong, Dayoung
   Paik, Seungwon
   Noh, YoungTae
   Han, Kyungsik
TI MAC: multimodal, attention-based cybersickness prediction modeling in
   virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Cybersickness; Deep learning; User characteristics
ID MOTION SICKNESS; SUSCEPTIBILITY; HABITUATION; SYMPTOMS; VIDEOS; HMD
AB Cybersickness is one of the greatest barriers to the adoption of virtual reality. A growing body of research has focused on identifying the characteristics of cybersickness and finding ways to mitigate it through the utilization of data from VR content, physiological signals, and body movement, along with artificial intelligence techniques. In this work, we extend prior research on cybersickness prediction by considering the role of different data modalities. We propose a novel deep learning model named multimodal, attention-based cybersickness (MAC), which learns temporal sequences and characteristics of video flows, eye movement, head movement, and electrodermal activity. Based on data collected from 27 participants, we demonstrate the effectiveness of MAC, showing an F1-score of 0.87. Our experimental results further show not only the influences of gender and prior VR experience but also the effectiveness of the attention mechanism on model performance, emphasizing the importance of considering the characteristics of data types and users in cybersickness modeling.
C1 [Jeong, Dayoung] Hanyang Univ, Dept Artificial Intelligence, Seoul, South Korea.
   [Paik, Seungwon] LG Elect, Seoul, South Korea.
   [Noh, YoungTae] Korea Inst Energy Technol, Sch Energy Engn, Naju, South Korea.
   [Han, Kyungsik] Hanyang Univ, Dept Data Sci, Seoul, South Korea.
C3 Hanyang University; LG Electronics; Hanyang University
RP Noh, Y (corresponding author), Korea Inst Energy Technol, Sch Energy Engn, Naju, South Korea.; Han, K (corresponding author), Hanyang Univ, Dept Data Sci, Seoul, South Korea.
EM dayoungjeong@hanyang.ac.kr; seungwon.paik@lge.com; ytnoh@kentech.ac.kr;
   kyungsikhan@hanyang.ac.kr
RI Han, Kyungsik/D-3010-2017; Noh, Youngtae/H-1943-2013
OI Han, Kyungsik/0000-0001-5535-0081; Jeong, Dayoung/0000-0002-8347-4986;
   Noh, Youngtae/0000-0002-9173-1575
FU National Research Foundation [2021M3A9E4080780]; Institute for
   Information & Communication Technology Planning Evaluation
   [IITP-2020-0-01373, IITP-2023-2018-0-01431]
FX This research was supported by the National Research Foundation
   (2021M3A9E4080780) and Institute for Information & Communication
   Technology Planning & Evaluation (IITP-2020-0-01373,
   IITP-2023-2018-0-01431)
CR Alsheikh MA, 2016, WORKSH AAAI C ART IN
   [Anonymous], 1975, Motion sickness
   Anwar MS, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091530
   Anwar MS, 2020, IEEE ACCESS, V8, P148084, DOI 10.1109/ACCESS.2020.3015556
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bala P, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P244, DOI 10.1109/ISMAR-Adjunct.2018.00077
   Balasubramanian S, 2019, INT SYM MIX AUGMENT, P169, DOI [10.1109/ISMAR.2019.00-7, 10.1109/ISMAR.2019.000-7]
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bosser G, 2006, BRAIN RES BULL, V68, P217, DOI 10.1016/j.brainresbull.2005.05.031
   Cai K, 2017, NEUROCOMPUTING, V220, P138, DOI 10.1016/j.neucom.2016.03.106
   Chang E, 2021, J COMPUT DES ENG, V8, P728, DOI 10.1093/jcde/qwab010
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   David-Grignot Stephane, 2014, Proceedings 2014 IEEE International Test Conference (ITC), DOI 10.1109/TEST.2014.7035301
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Draper MH, 2001, HUM FACTORS, V43, P129, DOI 10.1518/001872001775992552
   Ebenholtz S.M., 1992, Teleoperators and Virtual Environments, V1, P302, DOI DOI 10.1162/PRES.1992.1.3.302
   EBENHOLTZ SM, 1994, AVIAT SPACE ENVIR MD, V65, P1032
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Groth C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P169, DOI 10.1109/VRW52623.2021.00039
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Howarth PA, 2008, DISPLAYS, V29, P117, DOI 10.1016/j.displa.2007.09.009
   Huang Z., 2015, ARXIV
   Islam R, 2021, INT SYM MIX AUGMENT, P31, DOI 10.1109/ISMAR52148.2021.00017
   Islam R, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P148, DOI 10.1109/VRW52623.2021.00035
   Islam R, 2020, INT SYM MIX AUGMENT, P400, DOI 10.1109/ISMAR50242.2020.00066
   Jahangiri A, 2015, IEEE T INTELL TRANSP, V16, P2406, DOI 10.1109/TITS.2015.2405759
   Jeong D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P827, DOI [10.1109/VR.2019.8798334, 10.1109/vr.2019.8798334]
   Jeong H, 2017, IEEE IMAGE PROC, P715, DOI 10.1109/ICIP.2017.8296374
   Jeong JH, 2020, IEEE T NEUR SYS REH, V28, P1226, DOI 10.1109/TNSRE.2020.2981659
   Jin WN, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P382, DOI 10.1109/GEM.2018.8516469
   Jokerst M, 1999, AVIAT SPACE ENVIR MD
   Jung S, 2021, IEEE T VIS COMPUT GR, V27, P2669, DOI 10.1109/TVCG.2021.3067773
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim HG, 2019, IEEE T IMAGE PROCESS, V28, P1646, DOI 10.1109/TIP.2018.2880509
   Kim H, 2017, 2017 SIXTH INTERNATIONAL CONFERENCE ON FUTURE GENERATION COMMUNICATION TECHNOLOGIES (FGCT), P1
   Kim J, 2022, IEEE T NEUR NET LEAR, V33, P554, DOI 10.1109/TNNLS.2020.3028080
   Kim J, 2019, IEEE I CONF COMP VIS, P10579, DOI 10.1109/ICCV.2019.01068
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kundu R.K, 2022, ARXIV
   Lee S, 2019, IEEE IMAGE PROC, P440, DOI [10.1109/icip.2019.8802983, 10.1109/ICIP.2019.8802983]
   Lee S, 2009, IEEE T VIS COMPUT GR, V15, P453, DOI 10.1109/TVCG.2008.106
   Lee TM, 2019, IEEE T VIS COMPUT GR, V25, P1919, DOI 10.1109/TVCG.2019.2899186
   Lindsay GW, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.00029
   Litleskare S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02436
   Lopes P., 2020, MOTION INTERACTION G, P1
   MacArthur Cayley, 2021, P 2021 CHI C HUMAN F, P1, DOI DOI 10.1145/3411764.3445701PAGES#5
   Magaki T., 2020, Int. J. Virtual Augment. Real. (IJVAR), V4, P1, DOI [10.4018/IJVAR.2020010101, DOI 10.4018/IJVAR.2020010101]
   Martin N, 2020, INT SYM MIX AUGMENT, P387, DOI 10.1109/ISMAR50242.2020.00065
   McHugh N, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364259
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nalivaiko Eugene, 2014, Temperature (Austin), V1, P164, DOI 10.4161/23328940.2014.982047
   Oh S, 2021, CYBERPSYCH BEH SOC N, V24, P729, DOI 10.1089/cyber.2020.0613
   Oman C M, 1982, Acta Otolaryngol Suppl, V392, P1
   Padmanaban N, 2018, IEEE T VIS COMPUT GR, V24, P1594, DOI 10.1109/TVCG.2018.2793560
   Palmisano S, 2023, VIRTUAL REAL-LONDON, V27, P1293, DOI 10.1007/s10055-022-00732-5
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qu CX, 2022, CCF T PERVAS COMPUT, V4, P268, DOI 10.1007/s42486-022-00103-8
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Uddin MZ, 2019, IEEE SENS J, V19, P8413, DOI 10.1109/JSEN.2018.2871203
   Um TT, 2017, IEEE INT C INT ROBOT, P2385, DOI 10.1109/IROS.2017.8206051
   Wang YY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1874, DOI [10.1109/VR.2019.8798213, 10.1109/vr.2019.8798213]
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
NR 78
TC 3
Z9 3
U1 4
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2315
EP 2330
DI 10.1007/s10055-023-00804-0
EA MAY 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000993337300001
DA 2024-07-18
ER

PT J
AU Pamparau, C
   Schipor, OA
   Dancu, A
   Vatavu, RD
AF Pamparau, Cristian
   Schipor, Ovidiu-Andrei
   Dancu, Alexandru
   Vatavu, Radu-Daniel
TI SAPIENS in XR: operationalizing interaction-attention in extended
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Extended reality; Peripheral interaction; Conceptual space; Event-based
   software architecture; Head-mounted displays
ID PERIPHERAL INTERACTION; AUGMENTED REALITY; SMART; ENVIRONMENTS;
   ARCHITECTURE; DISPLAYS
AB We examine peripheral interactions in XR environments, for which we propose a conceptual space with two specialized dimensions, interaction-attention and reality-virtuality. We also formalize the notion of an "XR display" to expand the application range of ambient displays from physical environments to XR. To operationalize these conceptual contributions for researchers and practitioners, we capitalize on Sapiens, an open-source event-based software architecture for peripheral interactions in smart environments, to propose Sapiens-in-XR, an extended architecture that also covers XR displays. In a simulation study based on a Poisson probabilistic model of notification delivery, we demonstrate the efficiency of the event processing pipeline of Sapiens-in-XR with an average processing time of just 18ms from event creation to delivery. We present simulations of peripheral interaction scenarios enabled by our conceptual space and Sapiens-in-XR, and report empirical results from a controlled experiment implementing one scenario, where users were asked to maintain their focus of attention in the central field of view while notifications were displayed at the attention periphery. Our results show similar user perception and the same level of user performance for understanding and recalling content of notifications in either the virtual and physical environments. Our conceptual space, software architecture, and simulator constitute tools meant to assist researchers and practitioners to explore, design, and implement peripheral interactions in XR.
C1 [Pamparau, Cristian; Schipor, Ovidiu-Andrei; Dancu, Alexandru; Vatavu, Radu-Daniel] Stefan Cel Mare Univ Suceava, MintViz Lab, 13 Univ, Suceava 720229, Romania.
C3 Stefan cel Mare University of Suceava
RP Vatavu, RD (corresponding author), Stefan Cel Mare Univ Suceava, MintViz Lab, 13 Univ, Suceava 720229, Romania.
EM cristian.pamparau@usm.ro; ovidiu.schipor@usm.ro;
   lexandru.dancu@gmail.com; radu.vatavu@usm.ro
RI Vatavu, Radu-Daniel/AAA-3282-2022; Pamparau, Cristian/AAB-5215-2021;
   Schipor, Ovidiu-Andrei/ABD-1755-2020
FU Ministry of Research, Innovation and Digitization; CNCS/CCCDI-UEFISCDI ,
   within PNCDI III [PN-III-P4-ID-PCE-2020-0434 (PCE29/2021)]
FX This work was supported by a grant of the Ministry of Research,
   Innovation and Digitization, CNCS/CCCDI-UEFISCDI, project number
   PN-III-P4-ID-PCE-2020-0434 (PCE29/2021), within PNCDI III. The authors
   acknowledge support from OSF Global Services, the Mobile Division,
   Suceava, which kindly provided the HoloLens HMD used for the experiment
   reported in this work.
CR Alavi HS, 2012, IEEE T LEARN TECHNOL, V5, P264, DOI 10.1109/TLT.2012.7
   [Anonymous], 1997, The coming age of calm technolgy. pages, DOI DOI 10.1007/978-1-4612-0685-9_6
   Ardito C, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682623
   Bakker S, 2013, P 7 INT C TANG EMB E, P57, DOI [10.1145/2460625.2460634, DOI 10.1145/2460625.2460634]
   Bakker S, 2012, P 6 INT C TANG EMB E, P245, DOI [10.1145/2148131.2148184, DOI 10.1145/2148131.2148184]
   Bakker S, 2013, THESIS EINDHOVEN U T, DOI [10.6100/IR754544, DOI 10.6100/IR754544]
   Bakker S, 2016, INT J DES, V10, P1
   Bakker S, 2015, PERS UBIQUIT COMPUT, V19, P239, DOI 10.1007/s00779-014-0775-2
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Billinghurst M, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3445002
   Biocca F., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1115
   Biocca F, 2007, J MANAGE INFORM SYST, V23, P163, DOI 10.2753/MIS0742-1222230408
   Bonanni Leonardo., 2005, CHI '05 Extended Abstracts on Human Factors in Computing Systems. CHIEA '05, P1228, DOI DOI 10.1145/1056808.1056883
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cook DJ, 2007, PERVASIVE MOB COMPUT, V3, P53, DOI 10.1016/j.pmcj.2006.12.001
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Dunne R, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447242
   Endo Isamu, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P100, DOI 10.1145/3472749.3474738
   Fender A, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P303, DOI 10.1145/3343055.3359715
   Fernández-Caballero A, 2016, J BIOMED INFORM, V64, P55, DOI 10.1016/j.jbi.2016.09.015
   Fischer R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01366
   Grier R.A., 2015, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P1727, DOI DOI 10.1177/1541931215591373
   Grübel J, 2021, PROCEEDINGS OF THE 5TH MEDIA ARCHITECTURE BIENNALE CONFERENCE, MAB20, P215, DOI 10.1145/3469410.3469435
   HART S G, 1988, P139
   Heller F, 2021, PROCEEDINGS OF 23RD ACM INTERNATIONAL CONFERENCE ON MOBILE HUMAN-COMPUTER INTERACTION (MOBILEHCI 2021): MOBILE APART, MOBILE TOGETHER, DOI 10.1145/3447526.3472034
   Hsieh CY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376228
   Ishii H., 1998, P CHI 98 C SUMMARY H, P173, DOI DOI 10.1145/286498.286652
   Itoh Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453157
   Katti SK., 1968, TECHNO METRICS, V10, P412, DOI [DOI 10.1080/00401706.1968.10490580, 10.1080/00401706.1968.10490580]
   Ku PS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P630, DOI [10.1109/vr.2019.8798065, 10.1109/VR.2019.8798065]
   Lantz Ed, 2007, P 2007 WORKSH EM DIS, DOI [10.1145/1278240.1278241, DOI 10.1145/1278240.1278241]
   Lu WQ, 2012, INT SYM MIX AUGMENT, P161, DOI 10.1109/ISMAR.2012.6402553
   Mackworth N.H., 1965, PSYCHON SCI, V3, P67, DOI DOI 10.3758/BF03343023
   MACKWORTH NH, 1976, EYE MOVEMENTS PSYCHO, P307
   Marquardt Nicolai, 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology-UIST'11, P315, DOI 10.1145/2047196.2047238
   Marr B, 2019, FORBES
   Maselli Gaia, 2020, CRYBLOCK 2020. Proceedings of the 3rd Workshop on Cryptocurrencies and Blockchains for Distributed Systems, P23, DOI 10.1145/3410699.3413793
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Nebeling M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445323
   Pamparau C, 2022, PROCEEDINGS OF THE 2022 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2022, P161, DOI 10.1145/3505284.3529969
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P399, DOI 10.1007/s11042-011-0917-8
   Pohl H., 2020, 26 ACM S VIRTUAL REA, DOI [10.1145/3385956.3418946, DOI 10.1145/3385956.3418946]
   Preuveneers D, 2012, J AMB INTEL SMART EN, V4, P149, DOI 10.3233/AIS-2012-0150
   Renner P, 2017, IEEE SYMP 3D USER, P186, DOI 10.1109/3DUI.2017.7893338
   Richards K, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357585
   Rigby JM, 2019, TVX 2019: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P35, DOI 10.1145/3317697.3323361
   Rompapas D, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451535
   Schipor Ovidiu-Andrei, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3331153
   Schipor OA, 2021, INTERACT COMPUT, V33, P3, DOI 10.1093/iwcomp/iwaa025
   Schipor OA, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P358, DOI 10.1109/ISMAR-Adjunct.2019.00-12
   Schipor OA, 2019, INFORM SOFTWARE TECH, V109, P43, DOI 10.1016/j.infsof.2019.01.006
   Schmidt A, 1999, LECT NOTES COMPUT SC, V1670, P140
   Seraj M, 2018, NORDICHI'18: PROCEEDINGS OF THE 10TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION, P886, DOI 10.1145/3240167.3240239
   Speicher Maximilian, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3461727
   Tolmie P., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P399, DOI 10.1145/503376.503448
   Vatavu R-D, 2015, P ACM INT C INT EXP, P13, DOI [10.1145/2745197.2745207, DOI 10.1145/2745197.2745207]
   Vatavu RD, 2020, PROCEEDINGS OF THE 2020 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2020, P1, DOI 10.1145/3391614.3393660
   Veas E, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1471
   Vermeulen J, 2016, HUM-COMPUT INT-SPRIN, P137, DOI 10.1007/978-3-319-29523-7_7
   Wisneski C, 1998, LECT NOTES COMPUT SC, V1370, P22
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xu JN, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3516399
NR 62
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1765
EP 1781
DI 10.1007/s10055-023-00776-1
EA FEB 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000937114600002
DA 2024-07-18
ER

PT J
AU Erdogan, K
   Ceylan, R
   Gezer, I
AF Erdogan, Kemal
   Ceylan, Rahime
   Gezer, IlknurAlbayrak
TI The use of augmented reality in the teaching and training of basic
   exercises involved in the non-surgical treatment of neck pain
SO VIRTUAL REALITY
LA English
DT Article
DE AR; Augmented reality; Medical training system; Mixed reality; Neck
   pain; Virtual rehabilitation
ID POSTURAL CONTROL; REHABILITATION
AB In this study, a new holographic supervision method was developed that enables patients to correctly apply the exercise movements associated with the non-surgical treatment of neck pain. The proposed method uses augmented reality technology to teach patients the correct exercise movements and supervise them, ensuring that they perform these exercises correctly. Previous studies have shown that patients generally do not adhere to prescribed treatments or may not perform the required exercises correctly. Thus, this system was developed to ease the workload of physical therapists and medical doctors. It uses a head-mounted device named HoloLens as well as some markers. Exercise movements are first taught to patients using holographic videos, guiding holograms, and sounds. The movements of the patients are subsequently observed using the sensors available on the HoloLens as well as markers placed around the patient to ensure that patients maintain the correct angle, duration, and the number of repetitions during the exercises. A methodology that employed finite-state machines was used to develop this software. To quantify the benefits of this system, tests were conducted on a total of 30 participants that were split equally into a control group and an experimental group. The duration, repetition, and angle error rates in the control group (who did not use the device) were 36.4%, 8%, and 27.3%, respectively; the corresponding error rates in the experiment group (who were provided with the device) were 0%, 0%, and 9.1%. Thus, a system has been developed that can address the issue of patients who do not adhere to treatment programs or apply them incorrectly. This study represents the first time that the exercises for the treatment of neck pain were taught and supervised with holograms instead of physical therapists.
C1 [Erdogan, Kemal; Ceylan, Rahime] Konya Tech Univ, Fac Engn & Nat Sci, Dept Elect & Elect Engn, Konya, Turkey.
   [Gezer, IlknurAlbayrak] Selcuk Univ, Fac Med, Dept Phys Med & Rehabil, Konya, Turkey.
C3 Konya Technical University; Selcuk University
RP Erdogan, K (corresponding author), Konya Tech Univ, Fac Engn & Nat Sci, Dept Elect & Elect Engn, Konya, Turkey.
EM kerdogan@ktun.edu.tr; rceylan@ktun.edu.tr; ilknur.ftr@gmail.com
RI Erdogan, Kemal/AAD-5691-2021
OI Erdogan, Kemal/0000-0001-7433-2516
FU Selcuk University BAP Office [16101010]; TUBITAK [1059B141600796]; Konya
   Technical University
FX Authors would like to thank Selcuk University BAP Office for their
   support to the project which is numbered as 16101010 and TUBITAK for
   their support to the 2214-A project which is numbered as 1059B141600796.
   Also, authors would like to thank to MD Ilyas KAYA, MD Serkan SEVINDIK
   and Konya Technical University for their supports.
CR Al-Issa H, 2012, PHYS THER REV, V17, P16, DOI 10.1179/1743288X11Y.0000000051
   Bozgeyikli L, 2017, ACM T ACCESS COMPUT, V10, DOI 10.1145/3046786
   Capecci M, 2016, IEEE ENG MED BIO, P5409, DOI 10.1109/EMBC.2016.7591950
   Carpenter M.B., 1991, Core text of neuroanatomy, V4th
   Cohen SP, 2017, BMJ-BRIT MED J, V358, DOI 10.1136/bmj.j3221
   Condino S, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8101178
   Doc-Ok.org, 2019, HOLOLENS FIELD VIEW
   Dusunceli Y, 2009, J REHABIL MED, V41, P626, DOI 10.2340/16501977-0392
   Erdogan K, 2019, ED PURPOSED HUMAN MA
   Da Gama AEF, 2016, COMPUT METH PROG BIO, V135, P105, DOI 10.1016/j.cmpb.2016.07.014
   Huber ME, 2015, PHYSIOTHERAPY, V101, P389, DOI 10.1016/j.physio.2015.02.002
   Jack K, 2010, MANUAL THER, V15, P220, DOI 10.1016/j.math.2009.12.004
   Kouris I, 2018, IEEE ENG MED BIO, P4233, DOI 10.1109/EMBC.2018.8513357
   Lee CH, 2014, HONG KONG PHYSIOTHER, V32, P51, DOI 10.1016/j.hkpj.2014.04.002
   Martin Leslie R, 2005, Ther Clin Risk Manag, V1, P189
   Merians AS, 2002, PHYS THER, V82, P898, DOI 10.1093/ptj/82.9.898
   Mostajeran F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1465, DOI [10.1109/vr.2019.8797813, 10.1109/VR.2019.8797813]
   Mousavi Hondori Hossein, 2014, J Med Eng, V2014, P846514, DOI 10.1155/2014/846514
   Ortiz-Gutiérrez R, 2013, INT J ENV RES PUB HE, V10, P5697, DOI 10.3390/ijerph10115697
   Paolis, 2020, 2020 IEEE INT S MEDI
   PTC, 2019, VUF ENG
   Röijezon U, 2008, J NEUROENG REHABIL, V5, DOI 10.1186/1743-0003-5-36
   Schlagenhauf F, 2018, IEEE INT CONF CON AU, P674, DOI 10.1109/ICCA.2018.8444349
   Taza-Aquino Y, 2022, 2022 IEEE INT IOT EL
   Vovk A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313007
   Zulkarnain RF, 2017, DIGITAL DATA ACQUISI, P1532
NR 26
TC 1
Z9 1
U1 8
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 481
EP 492
DI 10.1007/s10055-022-00739-y
EA DEC 2022
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000906176600001
DA 2024-07-18
ER

PT J
AU Sanchez-Rocamora, A
   Martinez-Martin, E
   Costa, A
AF Sanchez-Rocamora, Alvaro
   Martinez-Martin, Ester
   Costa, Angelo
TI A low-cost AR application to control arm prosthesis
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Deep learning; Electromyography signal processing;
   Virtual rehabilitation
AB This paper presents an augmented reality application to assist with myoelectric prostheses control for people with limb amputations. For that, we use the low-cost Myo armband coupled with low-level signal processing methods specifically built to control filters' levels and processing chain. In particular, we use deep learning techniques to process the signals and to accurately identify seven different hand gestures. From that, we have built an augmented reality projection of a hand based on AprilTag markers that displays the gesture identified by the deep learning techniques. With the aim to properly train the gesture recognition system, we have built our own dataset with nine subjects. This dataset was combined with one publicly available to work with the data of 24 subjects in total. Finally, three different deep learning architectures have been comparatively studied, achieving high accuracy values (being 95.56% the best one). This validates our hypothesis that it is possible to have an adaptive platform able to fast learn personalized hand/arm gestures while projecting a virtual hand in real-time. This can reduce the adaptation time to myoelectric prostheses and improve the acceptance levels.
C1 [Sanchez-Rocamora, Alvaro; Martinez-Martin, Ester; Costa, Angelo] Univ Alicante, Dept Comp Sci & Artificial Intelligence, Carretera San Vicente Raspeig s-n, San Vicente Ras, Alicante 03690, Spain.
C3 Universitat d'Alacant
RP Martinez-Martin, E (corresponding author), Univ Alicante, Dept Comp Sci & Artificial Intelligence, Carretera San Vicente Raspeig s-n, San Vicente Ras, Alicante 03690, Spain.
EM alvarosanchezroc@gmail.com; ester@ua.es; angelogoncalo.costa@ua.es
RI Costa, Angelo/P-5651-2014; Martinez-Martin, Ester/M-7374-2016
OI Costa, Angelo/0000-0002-6170-4912; Martinez-Martin,
   Ester/0000-0003-4495-6912
FU MCIN/AEI [PID2019-104818RB-I00]; ERDF A way of making Europe;
   Generalitat Valenciana [CIGE/2021/136]
FX This work has been partly supported by Grant PID2019-104818RB-I00 funded
   by MCIN/AEI/10.13039/501100011033 and by "ERDF A way of making Europe";
   and by Generalitat Valenciana (CIGE/2021/136)
CR adafruit, 2016, INS MYO
   Ambron E, 2021, NEUROREHAB NEURAL RE, V35, P1100, DOI 10.1177/15459683211054164
   Ambron E, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00067
   Biddiss EA, 2007, PROSTHET ORTHOT INT, V31, P236, DOI 10.1080/03093640600994581
   Braza DW., 2020, Essentials of Physical Medicine and Rehabilitation, VFourth, P651, DOI DOI 10.1016/B978-0-323-54947-9.00119-X
   Buongiorno Domenico, 2019, Intelligent Computing Methodologies. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11645), P751, DOI 10.1007/978-3-030-26766-7_68
   Chau Brian, 2017, Innov Clin Neurosci, V14, P3
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Côté-Allard U, 2019, IEEE T NEUR SYS REH, V27, P760, DOI 10.1109/TNSRE.2019.2896269
   Du Y, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030458
   Dunn J, 2017, NEUROREHABILITATION, V40, P595, DOI 10.3233/NRE-171447
   Franzke AW, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0220899
   Garrido-Jurado S, 2016, PATTERN RECOGN, V51, P481, DOI 10.1016/j.patcog.2015.09.023
   Heerschop A, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00878-4
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Koskimäki H, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P537, DOI 10.1145/3123024.3124400
   McDonald CL, 2021, PROSTHET ORTHOT INT, V45, P105, DOI 10.1177/0309364620972258
   Nasri N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226451
   Olson E, 2011, IEEE INT CONF ROBOT
   Phelan I, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3443454
   Pizzolato S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0186132
   Rim B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20040969
   Romero-Ramirez FJ, 2018, IMAGE VISION COMPUT, V76, P38, DOI 10.1016/j.imavis.2018.05.004
   Rutledge T, 2019, PAIN MED, V20, P2051, DOI 10.1093/pm/pnz121
   Salminger S, 2022, DISABIL REHABIL, V44, P3708, DOI 10.1080/09638288.2020.1866684
   Semmlow J. L., 2014, Biosignal and Medical Image Processing, DOI DOI 10.1201/B16584
   Tong X, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00876
   Wang J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4193, DOI 10.1109/IROS.2016.7759617
   Xiong DZ, 2021, IEEE-CAA J AUTOMATIC, V8, P512, DOI 10.1109/JAS.2021.1003865
   Yigiter K, 2002, PROSTHET ORTHOT INT, V26, P213, DOI 10.1080/03093640208726650
NR 30
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3469
EP 3483
DI 10.1007/s10055-022-00741-4
EA DEC 2022
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000904044400001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Lin, Y
   Lan, YF
   Wang, SB
AF Lin, Yi
   Lan, Yangfan
   Wang, Shunbo
TI A method for evaluating the learning concentration in head-mounted
   virtual reality interaction
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality education; Learning concentration; Head-mounted virtual
   reality interaction; Weight configuration
ID COGNITIVE ENGAGEMENT; ATTENTION; STATES
AB In education, learning concentration is closely related to the quality of learning, and teachers can adjust their teaching methods accordingly to improve the learning outcomes of students. Particularly in head-mounted virtual reality interactions, current methods for assessing learning concentration cannot be fully applied to new interactive environments because immersion shaping and cognitive formation differ from the conventional education. Therefore, in this study, a learning concentration assessment method is proposed to measure the learning concentration of students in head-mounted virtual interaction, using the expression score, visual focus rate, and task mastery as evaluation indicators. In addition, the weights of the evaluation indicators can be configured to be included in the calculation of learning concentration depending on the characteristics of different types of courses. The results of a usability evaluation indicate that the learning concentration of students can be effectively evaluated using the proposed method. By developing and implementing strategies for optimizing learning effects, the learning concentration and assessment scores of students increased by 18% and 15.39%, respectively.
C1 [Lin, Yi; Lan, Yangfan; Wang, Shunbo] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350018, Peoples R China.
C3 Fuzhou University
RP Lan, YF (corresponding author), Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350018, Peoples R China.
EM lanyangfan_123@163.com
OI lan, yang fan/0000-0001-9388-9264; Lin, Yi/0000-0003-3239-3446
FU Program of Study Abroad for Young Scholar - CSC [201806655029];
   Educational Research Project for Young Teachers of The Education
   Department of Fujian Province, China [JAT200029]
FX This work is funded by Program of Study Abroad for Young Scholar
   sponsored by CSC (201806655029) and Educational Research Project for
   Young Teachers of The Education Department of Fujian Province, China
   (JAT200029).
CR Abdullah J, 2019, VIRTUAL REAL-LONDON, V23, P461, DOI 10.1007/s10055-019-00381-1
   Ainley M, 2012, HANDBOOK OF RESEARCH ON STUDENT ENGAGEMENT, P283, DOI 10.1007/978-1-4614-2018-7_13
   Alemdag E, 2018, COMPUT EDUC, V125, P413, DOI 10.1016/j.compedu.2018.06.023
   Arana-Llanes JY, 2018, J INTELL FUZZY SYST, V34, P3359, DOI 10.3233/JIFS-169517
   Arya R, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100399
   Ba lan O., 2019, Symmetry, V12, P21
   Bostan Sarioglan A., 2020, Cypriot Journal of Educational Sciences, V15, P674, DOI [10.18844/cjes.v15i4.5050, DOI 10.18844/CJES.V15I4.5050]
   Boutefara T, 2020, 2020 INT C ADV ASPEC
   Castelló A, 2020, MULTIMED TOOLS APPL, V79, P24969, DOI 10.1007/s11042-020-09170-4
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chi MTH, 2014, EDUC PSYCHOL-US, V49, P219, DOI 10.1080/00461520.2014.965823
   Chicco D, 2021, BIODATA MIN, V14, DOI 10.1186/s13040-021-00244-z
   Christenson SL., 2012, HDB RES STUDENT ENGA, DOI [DOI 10.1007/978-1-4614-2018-7, 10.1007/978-1-4614-2018-7]
   D'Mello S., 2017, Handbook of Learning Analytics, P115
   D'Mello S, 2012, LEARN INSTR, V22, P145, DOI 10.1016/j.learninstruc.2011.10.001
   Fredricks JA, 2004, REV EDUC RES, V74, P59, DOI 10.3102/00346543074001059
   Fredricks JA, 2012, HANDBOOK OF RESEARCH ON STUDENT ENGAGEMENT, P763, DOI 10.1007/978-1-4614-2018-7_37
   Greene BA, 2015, EDUC PSYCHOL-US, V50, P14, DOI 10.1080/00461520.2014.989230
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Guo X., 2018, International Journal of Performability Engineering, V14, P2877, DOI [https://doi.org/10.23940/ijpe.18.11.p33.28772885, DOI 10.23940/IJPE.18.11.P33.28772885]
   Gupta A, 2018, PHYS REV PHYS EDUC R, V14, DOI 10.1103/PhysRevPhysEducRes.14.010129
   Guthrie JT, 2004, J EDUC PSYCHOL, V96, P403, DOI 10.1037/0022-0663.96.3.403
   Jiao PF, 2022, IEEE T NEUR NET LEAR, V33, P7400, DOI 10.1109/TNNLS.2021.3084957
   Käser DP, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085094
   Kht A, 2022, VIRTUAL REALITY CAR
   Kim J, 2020, INT J HUM-COMPUT INT, V36, P1902, DOI 10.1080/10447318.2020.1801227
   Kim YSG, 2017, J EDUC PSYCHOL, V109, P35, DOI 10.1037/edu0000129
   Krejtz K, 2016, J EYE MOVEMENT RES, V9
   Kruger JL, 2016, AUSTRALAS J EDUC TEC, V32, P19, DOI 10.14742/ajet.3084
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liong ST, 2020, J SIGNAL PROCESS SYS, V92, P705, DOI 10.1007/s11265-020-01523-4
   Liu, 2017, EMPIRICAL STUDY BEHA, DOI [10.15881/j.cnki.cn33-1304/g4.2017.01.008, DOI 10.15881/J.CNKI.CN33-1304/G4.2017.01.008]
   Liu HC, 2011, INTERACT LEARN ENVIR, V19, P503, DOI 10.1080/10494820903520123
   Mahmoudi MA, 2020, PATTERN RECOGN LETT, V138, P644, DOI 10.1016/j.patrec.2020.09.001
   Maraza-Quispe B, 2020, INT J ADV COMPUT SC, V11, P146
   MEECE JL, 1988, J EDUC PSYCHOL, V80, P514, DOI 10.1037/0022-0663.80.4.514
   MILLER KA, 1988, CONTEMP SOCIOL, V17, P253, DOI 10.2307/2070638
   Mohammed BA, 2020, MATH BIOSCI ENG, V18, P851, DOI 10.3934/mbe.2021045
   Parong J, 2021, J COMPUT ASSIST LEAR, V37, P226, DOI 10.1111/jcal.12482
   Pedram S, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103891
   Pekrun R., 2012, ACAD EMOTIONS STUDEN, P259
   Pekrun R, 2014, EDUC PSYCHOL HANDB, P120
   Qi MS, 2020, IEEE T CIRC SYST VID, V30, P549, DOI 10.1109/TCSVT.2019.2894161
   Rajan S, 2019, IET IMAGE PROCESS, V13, P1031, DOI 10.1049/iet-ipr.2018.6647
   Renninger K. A., 2015, The power of interest for motivation and engagement, DOI DOI 10.4324/9781315771045
   Russell JA, 1999, J PERS SOC PSYCHOL, V76, P805, DOI 10.1037/0022-3514.76.5.805
   Shen CW, 2019, VIRTUAL REAL-LONDON, V23, P313, DOI 10.1007/s10055-018-0348-1
   Shete PC, 2020, SUSTAIN PROD CONSUMP, V23, P77, DOI 10.1016/j.spc.2020.05.001
   Shi GF, 2019, NONLINEAR DYNAM, V95, P2717, DOI 10.1007/s11071-018-4718-8
   Shi Y, 2020, DISSERTATION
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinatra GM, 2015, EDUC PSYCHOL-US, V50, P1, DOI 10.1080/00461520.2014.1002924
   Skinner E, 2008, J EDUC PSYCHOL, V100, P765, DOI 10.1037/a0012840
   Skinner EA, 2016, EDUC PSYCHOL HANDB, P145
   Soroush MZ, 2018, BEHAV BRAIN FUNCT, V14, DOI 10.1186/s12993-018-0149-4
   Suhaimi N. S., 2020, INT J ADV SCI TECHNO, V29, P1483
   Sutjarittham T, 2019, IEEE INTERNET THINGS, V6, P7595, DOI 10.1109/JIOT.2019.2902410
   Teng T, 2017, DISSERTATION
   Thomas AW, 2019, NAT HUM BEHAV, V3, P625, DOI 10.1038/s41562-019-0584-8
   Tsai CW, 2020, UNIVERSAL ACCESS INF, V19, P1, DOI 10.1007/s10209-018-0614-8
   Wong YK, 2018, READ WRIT, V31, P945, DOI 10.1007/s11145-018-9820-2
   Wu T, 2019, DISSERTATION
   Yeh SC, 2020, IEEE T NEUR SYS REH, V28, P1899, DOI 10.1109/TNSRE.2020.3004545
   You MY, 2020, NEUROCOMPUTING, V388, P144, DOI 10.1016/j.neucom.2020.01.023
   Zhang FF., 2019, CHIN J COMP, V42, P1
NR 66
TC 6
Z9 6
U1 7
U2 47
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 863
EP 885
DI 10.1007/s10055-022-00689-5
EA SEP 2022
PG 23
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000860375700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Lu, YJ
   Gao, BY
   Tu, HW
   Wu, HY
   Xin, WQ
   Cui, H
   Luo, WQ
   Duh, HBL
AF Lu, Yujun
   Gao, BoYu
   Tu, Huawei
   Wu, Huiyue
   Xin, Weiqiang
   Cui, Hui
   Luo, Weiqi
   Duh, Henry Been-Lirn
TI Effects of physical walking on eyes-engaged target selection with
   ray-casting pointing in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Target selection; Physical walking; Ray-casting
   selection; Eyes-engaged interaction
ID OBJECT SELECTION; ENVIRONMENTS; PERCEPTION; TREADMILL; SPEED
AB Target selection in virtual reality (VR) is usually carried out with the need of visual attention. While target selection in VR has been extensively investigated in non-walking activities (e.g., sitting or standing), there have been few studies about eyes-engaged target selection during walking in virtual environments. Therefore, we conducted a comprehensive study to explore the effects of physical walking (as an independent variable with low, medium and high speeds) on eyes-engaged selection tasks with targets (three target sizes and three target depths) in two experiments: targets fixed in the virtual environment (Experiment One) and targets fixed to the virtual body (Experiment Two), respectively. Results showed that for Experiment One, the low walking speed led to the significantly longest task completion time, while the medium and high speeds had similar task completion time. For Experiment Two, higher walking speed led to longer task completion time. In both tasks, error rate significantly increased as walking speed increased. The effects of walking speed also varied across target size and target depth. We conclude our study with a set of design implications for target selection tasks when walking in VR environments.
C1 [Lu, Yujun; Tu, Huawei; Cui, Hui; Duh, Henry Been-Lirn] La Trobe Univ, Dept Comp Sci & Informat Technol, Plenty Rd & Kingsbury Dr, Melbourne, Vic 3086, Australia.
   [Gao, BoYu; Xin, Weiqiang; Luo, Weiqi] Jinan Univ, Guangdong Inst Smart Educ, Coll Informat Sci & Technol Cyber Secur, 601 West Huangpu Ave, Guangzhou 510632, Guangdong, Peoples R China.
   [Wu, Huiyue] Sun Yat Sen Univ, Sch Commun & Design, 132,Waihuan Donglu, Guangzhou 510006, Guangdong, Peoples R China.
C3 La Trobe University; Jinan University; Sun Yat Sen University
RP Tu, HW (corresponding author), La Trobe Univ, Dept Comp Sci & Informat Technol, Plenty Rd & Kingsbury Dr, Melbourne, Vic 3086, Australia.; Gao, BY (corresponding author), Jinan Univ, Guangdong Inst Smart Educ, Coll Informat Sci & Technol Cyber Secur, 601 West Huangpu Ave, Guangzhou 510632, Guangdong, Peoples R China.
EM yujunlug@gmail.com; bygao@jnu.edu.cn; h.tu@latrobe.edu.au;
   wuhuiyue@mail.sysu.edu.cn; waikeung@stu2017.jnu.edu.cn;
   l.cui@latrobe.edu.au; lwq@jnu.edu.cn; b.duh@latrobe.edu.au
RI Gao, Boyu/JNE-3525-2023
OI Lu, yujun/0000-0001-8564-4398; Duh, Henry/0000-0003-4808-6109
FU National Science Foundation of China [61902147]; Natural Science
   Foundation of Guangdong Province [2021A1515012629]; Guangzhou Basic and
   Applied Basic Foundation [202102021131]
FX This work was supported by the National Science Foundation of China
   (61902147), Natural Science Foundation of Guangdong Province
   (2021A1515012629), and Guangzhou Basic and Applied Basic Foundation
   (202102021131).
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   Banton T, 2005, PRESENCE-TELEOP VIRT, V14, P394, DOI 10.1162/105474605774785262
   Batmaz AU, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P85, DOI 10.1109/VR50410.2021.00029
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P23, DOI [10.1109/VRW50115.2020.00012, 10.1109/VRW50115.2020.0-264]
   Bergstrom Joanna, 2021, P 2021 CHI C HUM FAC, P1
   Bergstrom-Lehtovirta J., 2011, 13th International Conference on Human Computer Interaction with Mobile Devices and Services, P143, DOI DOI 10.1145/2037373.2037396
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P75, DOI 10.1162/105474601750182333
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Cashion J, 2012, IEEE T VIS COMPUT GR, V18, P634, DOI 10.1109/TVCG.2012.40
   Cherni H., 2020, International Journal of Virtual Reality, V20, P1, DOI [DOI 10.20870/IJVR.2020.20.1.3183, 10.20870/ijvr.2020.20.1, DOI 10.20870/IJVR.2020.20.1]
   Chiovetto E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079555
   Choi JS, 2015, J BIOMECH, V48, P1336, DOI 10.1016/j.jbiomech.2015.02.047
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Feasel J, 2011, IEEE T NEUR SYS REH, V19, P290, DOI 10.1109/TNSRE.2011.2120623
   Fung J, 2006, CYBERPSYCHOL BEHAV, V9, P157, DOI 10.1089/cpb.2006.9.157
   Gao BY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P493, DOI 10.1109/VR50410.2021.00073
   Gao BY, 2019, LECT NOTES COMPUT SC, V11574, P44, DOI 10.1007/978-3-030-21607-8_4
   Gao B, 2019, INT J HUM-COMPUT INT, V35, P831, DOI 10.1080/10447318.2018.1498654
   Grossman T., 2006, P UIST 2006, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Hanson S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P367, DOI [10.1109/vr.2019.8797751, 10.1109/VR.2019.8797751]
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Iwata H, 2005, IEEE COMPUT GRAPH, V25, P64, DOI 10.1109/MCG.2005.5
   Iwata H, 1999, P IEEE VIRT REAL ANN, P286, DOI 10.1109/VR.1999.756964
   Janeh O, 2017, P IEEE VIRT REAL ANN, P217, DOI 10.1109/VR.2017.7892254
   Janeh O, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3022731
   Kane Shaun K., 2008, P 10 INT C HUMAN COM, P109, DOI [DOI 10.1145/1409240.1409253, 10.1145/1409240.1409253]
   Kannape OA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085560
   Kassler L., 2010, P 7 S APPL PERC GRAP, P161, DOI [10.1145/1836248.1836283, DOI 10.1145/1836248.1836283]
   Keung CCW, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156881
   Khanwalkar S, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P596, DOI 10.1145/2964284.2967291
   Lin CJ, 2017, APPL ERGON, V64, P66, DOI 10.1016/j.apergo.2017.05.007
   Lin M, 2007, INT J HUM-COMPUT ST, V65, P759, DOI 10.1016/j.ijhcs.2007.04.001
   Liu JZ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P588, DOI [10.1109/VR46266.2020.00-23, 10.1109/VR46266.2020.1581122519414]
   Lu YQ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P35, DOI [10.1109/VR46266.2020.1581165829725, 10.1109/VR46266.2020.00-83]
   Lubos P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P11, DOI 10.1109/3DUI.2014.6798834
   Machuca MDB, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188540
   Machuca MDB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300437
   Medina Eliana, 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P2102, DOI 10.1518/107118108X352490
   Mine M.R., 1995, Virtual Environment Interaction Techniques
   Ng Alexander., 2013, CHI'13 Extended Abstracts on Human Factors in Computing Systems, CHI EA'13, P1359, DOI DOI 10.1145/2468356.2468599
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nilsson NC, 2015, P IEEE VIRT REAL ANN, P81, DOI 10.1109/VR.2015.7223328
   Nilsson NC, 2014, IEEE T VIS COMPUT GR, V20, P569, DOI 10.1109/TVCG.2014.21
   Nilsson NielsChristian., 2014, Proc. ACM Symp. on Virtual Reality Software and Technology, P187
   Polechonski J, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17218051
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Powell W., 2011, 3 IEEE VR 2011 WORKS
   Sayyad E, 2020, INT SYM MIX AUGMENT, P608, DOI 10.1109/ISMAR50242.2020.00088
   Schildbach B., 2010, Proceedings of the 12th international conference on Human computer interaction with mobile devices and services, P93, DOI DOI 10.1145/1851600.1851619
   Schneider S, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2018), P22, DOI 10.1145/3192975.3193022
   Serrar Z, 2014, P 15 INT C HUMAN COM, P1
   Sloot LH, 2014, GAIT POSTURE, V39, P939, DOI 10.1016/j.gaitpost.2013.12.005
   Steinicke F, 2006, COMPUT IMAGING VIS, V32, P320, DOI 10.1007/1-4020-4179-9_46
   Suma EA, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P147
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Takashina T, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P534, DOI 10.1109/VRW52623.2021.00149
   Teather R. J., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P87, DOI 10.1109/3DUI.2011.5759222
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   Tu HW, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300848
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vanacken L, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P115
   Wehden LO, 2021, MEDIA COMMUN-LISBON, V9, P5, DOI 10.17645/mac.v9i1.3170
   Wendt JD, 2010, P IEEE VIRT REAL ANN, P51
   Wobbrock JO, 2016, HUM-COMPUT INT-SPRIN, P135, DOI 10.1007/978-3-319-26633-6_7
   Wu HY, 2021, APPL ERGON, V94, DOI 10.1016/j.apergo.2021.103400
   Yan YK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173616
   Yao Richard., 2014, Oculus VR, V4, P27
   Yatani K, 2009, PERVASIVE MOB COMPUT, V5, P496, DOI 10.1016/j.pmcj.2009.04.002
   Yu DF, 2020, IEEE T VIS COMPUT GR, V26, P3402, DOI [10.1109/TVCG.2020.3023606, 10.1109/TCVG.2020.3023606]
   Zhou QS, 2020, IEEE T VIS COMPUT GR, V26, P3423, DOI [10.1109/TVCG.2020.3023570, 10.1109/TVCG.2020.3023.570]
NR 77
TC 1
Z9 1
U1 2
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 603
EP 625
DI 10.1007/s10055-022-00677-9
EA AUG 2022
PG 23
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000834700700001
DA 2024-07-18
ER

PT J
AU Gamito, P
   Souto, T
   Conde, AR
   Salvador, A
   Ferreira, MJ
   de Sousa, JA
   Ferreira, M
   Dias, F
   Atul, S
   Pereira, R
   Távora, E
   Maia, I
   Oliveira, J
AF Gamito, Pedro
   Souto, Teresa
   Conde, Ana Rita
   Salvador, Agata
   Ferreira, Maria Jose
   de Sousa, Joao Alves
   Ferreira, Marco
   Dias, Fabio
   Atul, Shivani
   Pereira, Rita
   Tavora, Edna
   Maia, Ines
   Oliveira, Jorge
TI Relaxing in virtual reality: one synthetic agent relaxes all
SO VIRTUAL REALITY
LA English
DT Article
DE Relaxing; Synthetic agents; Virtual environments
ID RELAXATION; ANXIETY; ENVIRONMENTS; DISORDER; CHILDREN
AB Virtual reality-based interventions have gained attention as innovative approaches in clinical settings. However, the use of virtual-based relaxation in reducing psychological distress and physiological activation, a common strategy in traditional interventions, is not well documented. This study aims at exploring the role of a non-familiar synthetic agent (SyA) as a resource to promote relaxation in a virtual environment (VE). Sixty-nine healthy participants were randomly assigned to three conditions: relaxing in VE while listening to relaxing instructions delivered by a SyA (n = 23), relaxing in the same VE while listening to the same instructions but aired by a radio set (n = 23; 'active' control group) and waiting to the end of the experience without relaxing instructions (n = 23; 'passive' control group). The instruction was preceded by an activation task (i.e., a matching game within a limited time). Our hypothesis claims that the presence of a humanoid-like figure that is strange to the participant (SyA) hinders the relaxing process. Data from several self-reports (Presence, Immersion, Cybersickness and emotional response) and from psychophysiology (respiratory rate-RR) revealed that no differences were found between the two groups that listened to the relaxing instructions (SyA and radio). Additionally, a significant decrease in RR recordings was only significant for these two relaxation conditions (SyA and radio), but not for the 'passive' control group. Results suggest that the presence of a non-familiar humanoid character was not perceived as a dissonant element in the VE setting and did not negatively influence the relaxation outcome. This study sets the ground for future studies that may provide an insight into the optimal characteristics of a SyA, contributing to the development of accessible and beneficial digital applications to a wide range of individuals in clinical and non-clinical contexts.
C1 [Gamito, Pedro; Souto, Teresa; Conde, Ana Rita; Salvador, Agata; Ferreira, Maria Jose; de Sousa, Joao Alves; Dias, Fabio; Atul, Shivani; Pereira, Rita; Tavora, Edna; Maia, Ines; Oliveira, Jorge] Lusofona Univ, HEI Lab, Digital Human Environm Interact Labs, P-1749024 Lisbon, Portugal.
   [Gamito, Pedro; Salvador, Agata; Dias, Fabio; Atul, Shivani; Pereira, Rita; Tavora, Edna; Maia, Ines; Oliveira, Jorge] Lusofona Univ, Sch Psychol & Life Sci, Lisbon, Portugal.
   [Souto, Teresa; Conde, Ana Rita; Ferreira, Maria Jose; de Sousa, Joao Alves] Univ Lusofona Porto, Sch Psychol Educ & Sports, Lisbon, Portugal.
   [Ferreira, Marco] Univ Lusofona Porto, Fac Commun Architecture Art & Informat Technol, Lisbon, Portugal.
C3 Lusofona University; Lusofona University; Lusofona University; Lusofona
   University
RP Gamito, P (corresponding author), Lusofona Univ, HEI Lab, Digital Human Environm Interact Labs, P-1749024 Lisbon, Portugal.; Gamito, P (corresponding author), Lusofona Univ, Sch Psychol & Life Sci, Lisbon, Portugal.
EM pedro.gamito@ulusofona.pt
RI Oliveira, Jorge/KUH-2946-2024; Ferreira, Maria José/AAC-1389-2022;
   gamito, pedro/G-4353-2013
OI Ferreira, Maria José/0000-0003-0045-200X; gamito,
   pedro/0000-0003-0585-8447; Soares Souto, Maria
   Teresa/0000-0001-7268-1747; Mansuklal, Shivani Atul/0000-0002-5626-4369;
   Conde, Rita/0000-0003-4493-5388
FU Foundation for Science and Technology-FCT (Portuguese Ministry of
   Science, Technology and Higher Education) [UIDB/05380/2020]; Fundação
   para a Ciência e a Tecnologia [UIDB/05380/2020] Funding Source: FCT
FX This study was funded by the Foundation for Science and Technology-FCT
   (Portuguese Ministry of Science, Technology and Higher Education), under
   the grant UIDB/05380/2020.
CR Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   Bickmore T, 2010, HARVARD REV PSYCHIAT, V18, P119, DOI 10.3109/10673221003707538
   Bouchard S, 2007, ANN REV CYBERTHERAPY, V5, P128
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Chandrasiri A, 2020, VIRTUAL REAL-LONDON, V24, P143, DOI 10.1007/s10055-019-00380-2
   Chang RB, 2015, CELL, V161, P622, DOI 10.1016/j.cell.2015.03.022
   Charalambous A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156911
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   Diemer J, 2014, WORLD J BIOL PSYCHIA, V15, P427, DOI 10.3109/15622975.2014.892632
   Freedman G, 2017, SOC PERSONAL PSYCHOL, V11, DOI 10.1111/spc3.12368
   Geraets CNW, 2019, BEHAV COGN PSYCHOTH, V47, P745, DOI 10.1017/S1352465819000225
   Gerritsen RJS, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00397
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00349
   Herbelin B, 2002, 1 INT WORKSH VIRT RE
   Hoch DB, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033843
   Kazzi C, 2018, 2018 40 ANN INT C IE
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kothgassner OD, 2019, EUR J PSYCHOTRAUMATO, V10, DOI 10.1080/20008198.2019.1654782
   Lisetti CL, 2004, EURASIP J APPL SIG P, V2004, P1672, DOI 10.1155/S1110865704406192
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Matsangidou M., 2017, Brit J Neurosci Nurs, V13, P133, DOI [10.12968/bjnn.2017.13.3.133, DOI 10.12968/BJNN.2017.13.3.133]
   McArthur V, 2019, BEHAV INFORM TECHNOL, V38, P230, DOI 10.1080/0144929X.2018.1526969
   McArthur V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5029, DOI 10.1145/3025453.3026020
   Merakou K, 2019, EXPLORE-NY, V15, P38, DOI 10.1016/j.explore.2018.08.001
   Mesa-Gresa P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082486
   Migoya-Borja M, 2020, CYBERPSYCH BEH SOC N, V23, P246, DOI 10.1089/cyber.2019.0497
   Mikolasek M, 2018, INT J BEHAV MED, V25, P1, DOI 10.1007/s12529-017-9679-7
   Newton J, 2019, LOWERING HEART RATES, V1, P19
   Photiadis T., 2015, J VIRTUAL WORLDS RES, V8, P1, DOI [10.4101/jvwr.v8i1.7092, DOI 10.4101/JVWR.V8I1.7092]
   Pizzoli SFM, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00479
   Premkumar P, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.694610
   Rehm IC, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00186
   Robillard G., 2002, SOC QUEB RECH PSYCH
   Tsitsi T, 2017, EUR J ONCOL NURS, V26, P9, DOI 10.1016/j.ejon.2016.10.007
   URMC, 2020, VIT SIGNS BOD TEMP P
   Weiss P.L., 2006, Textbook of neural repair and rehabilitation, VII, P182, DOI [DOI 10.1017/CBO9780511545078.015, 10.1017/CBO9780511545078.015.]
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yuen EK, 2013, BEHAV THER, V44, P51, DOI 10.1016/j.beth.2012.06.001
NR 40
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 439
EP 449
DI 10.1007/s10055-022-00650-6
EA MAY 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000790621700001
DA 2024-07-18
ER

PT J
AU Garrido, LE
   Frías-Hiciano, M
   Moreno-Jiménez, M
   Cruz, GN
   García-Batista, ZE
   Guerra-Peña, K
   Medrano, LA
AF Garrido, Luis Eduardo
   Frias-Hiciano, Maite
   Moreno-Jimenez, Mariano
   Cruz, Gabriella Nicole
   Garcia-Batista, Zoilo Emilio
   Guerra-Pena, Kiero
   Medrano, Leonardo Adrian
TI Focusing on cybersickness: pervasiveness, latent trajectories,
   susceptibility, and effects on the virtual reality experience
SO VIRTUAL REALITY
LA English
DT Article
DE Cybersickness; Virtual reality; Virtual presence; Motion sickness;
   Technology acceptance; Head-mounted displays
ID STATISTICAL POWER; INDIVIDUAL-DIFFERENCES; IMMERSIVE TECHNOLOGY;
   SIMULATOR SICKNESS; ENJOYMENT; QUESTIONNAIRE; ENVIRONMENTS; ACCEPTANCE;
   UNDERMINES; SELECTION
AB Although virtual reality (VR) usage has become widespread in the last decade, its adoption has been hampered by experiences of user discomfort known as cybersickness. The present study, in line with the "2020 cybersickness R&D agenda", sought to provide a broad examination of the cybersickness phenomenon, assessing its pervasiveness, latent trajectories, impacts on the VR experience, and predictor variables. The study was composed of 92 participants living in the Dominican Republic with ages ranging from 18 to 52 years (M = 26.22), who experienced a 10-min VR immersion in two environments designed for psychotherapy. The results indicated that cybersickness was pervasive, with 65.2% of the participants experiencing it, and 23.9% severely. Additionally, the latent trajectories of cybersickness were positive and curvilinear, with large heterogeneity across individuals. Cybersickness also had a substantive negative impact on the user experience and the intentions to adopt the VR technology. Finally, motion sickness susceptibility, cognitive stress, and recent headaches uniquely predicted greater severity of cybersickness, while age was negatively related. These combined results highlight the critical role that cybersickness plays on the VR experience and underscore the importance of finding solutions to the problems, such as technological advancements or special usage protocols for the more susceptible individuals.
C1 [Garrido, Luis Eduardo; Frias-Hiciano, Maite; Moreno-Jimenez, Mariano; Cruz, Gabriella Nicole; Garcia-Batista, Zoilo Emilio; Guerra-Pena, Kiero; Medrano, Leonardo Adrian] Pontificia Univ Catolica Madre & Maestra, Dept Psychol, Santiago De Los Caballer, Dominican Rep.
C3 Pontificia Universidad Catolica Madre y Maestra
RP Garrido, LE (corresponding author), Pontificia Univ Catolica Madre & Maestra, Dept Psychol, Santiago De Los Caballer, Dominican Rep.
EM luisgarrido@pucmm.edu.do
RI Guerra-Peña, Kiero/AAC-3132-2020; Garcia-Batista, Zoilo
   Emilio/IUM-7697-2023; Garrido, Luis Eduardo/K-6234-2017
OI Garcia-Batista, Zoilo Emilio/0000-0002-0353-4804; Garrido, Luis
   Eduardo/0000-0001-8932-6063; Guerra-Pena, Kiero/0000-0003-3315-9459
FU National Fund for Innovation and Scientific and Technological
   Development of the Dominican Republic [FONDOCYT 009-2014]
FX This research was supported by the National Fund for Innovation and
   Scientific and Technological Development (FONDOCYT 009-2014) of the
   Dominican Republic.
CR Asparouhov T., 2010, MULTIPLE IMPUTATION
   Balog A, 2010, STUD INFORM CONTROL, V19, P319
   Behling O., 2000, Translating Questionnaires and Other Research Instruments: Problems and solutions, DOI DOI 10.4135/9781412986373
   Bishara AJ, 2017, BEHAV RES METHODS, V49, P294, DOI 10.3758/s13428-016-0702-8
   Bishara AJ, 2015, EDUC PSYCHOL MEAS, V75, P785, DOI 10.1177/0013164414557639
   Bockelman P, 2017, CCIS, P3, DOI DOI 10.1007/978-3-319-58753-0_1
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Bouchard S., 2009, Journal of CyberTherapy Rehabilitation, V2, P127, DOI DOI 10.3233/SHTI210961
   Bradley R, 2018, J ENABLING TECHNOL, V12, P101, DOI 10.1108/JET-01-2018-0004
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Burr H, 2019, SAF HEALTH WORK-KR, V10, P482, DOI 10.1016/j.shaw.2019.10.002
   Button KS, 2013, NAT REV NEUROSCI, V14, P365, DOI 10.1038/nrn3475
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   Chan JJI, 2020, BMC ANESTHESIOL, V20, DOI 10.1186/s12871-020-01177-6
   Chasson GS, 2020, J OBSESS-COMPULS REL, V25, DOI 10.1016/j.jocrd.2020.100519
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Loureiro SMC, 2020, TOURISM MANAGE, V77, DOI 10.1016/j.tourman.2019.104028
   Culbertson Christopher S, 2012, J Cyber Ther Rehabil, V5, P57
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Curran PJ, 2010, J COGN DEV, V11, P121, DOI 10.1080/15248371003699969
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Davis S, 2015, P 11 AUSTR C INT ENT, V27, P30
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dennison MS, 2017, APPL ERGON, V58, P215, DOI 10.1016/j.apergo.2016.06.014
   Desimone JA, 2015, J ORGAN BEHAV, V36, P171, DOI 10.1002/job.1962
   Di Stefano J, 2003, FUNCT ECOL, V17, P707, DOI 10.1046/j.1365-2435.2003.00782.x
   DOYEON LEE, 2020, [Journal of Internet Computing and Services, 인터넷정보학회논문지], V21, P81, DOI 10.7472/jksii.2020.21.6.81
   Eekhout I, 2014, J CLIN EPIDEMIOL, V67, P335, DOI 10.1016/j.jclinepi.2013.09.009
   García-Batista ZE, 2020, COMPUT HUM BEHAV, V102, P97, DOI 10.1016/j.chb.2019.08.015
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Ferguson CJ, 2012, PERSPECT PSYCHOL SCI, V7, P555, DOI 10.1177/1745691612459059
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Friese M, 2020, PSYCHOL METHODS, V25, P456, DOI 10.1037/met0000246
   Funder DC., 2019, PRACT PSYCHOL SCI, V2, P68, DOI [10.1177/2515245919847202, DOI 10.1177/2515245919847202]
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Gianaros PJ, 2001, AVIAT SPACE ENVIR MD, V72, P115
   Gignac GE, 2016, PERS INDIV DIFFER, V102, P74, DOI 10.1016/j.paid.2016.06.069
   Glaser N, 2022, INT J HUM-COMPUT INT, V38, P753, DOI 10.1080/10447318.2021.1970433
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Golding JF, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.576871
   Gottschall AC, 2012, MULTIVAR BEHAV RES, V47, P1, DOI 10.1080/00273171.2012.640589
   Graham JW, 2007, PREV SCI, V8, P206, DOI 10.1007/s11121-007-0070-9
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00349
   Hair F., 2005, Multivariate Data Analysis, V6th
   Hayes AF, 2020, COMMUN METHODS MEAS, V14, P1, DOI 10.1080/19312458.2020.1718629
   Hildebrandt J, 2018, LECT NOTES COMPUT SC, V10909, P82, DOI 10.1007/978-3-319-91581-4_7
   Howard MC, 2021, VIRTUAL REAL-LONDON, V25, P1221, DOI 10.1007/s10055-021-00524-3
   Hutton C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P579, DOI 10.1109/VR.2018.8446382
   igroup, IGR PRES QUEST IPQ F
   Inozu M, 2020, J OBSESS-COMPULS REL, V25, DOI 10.1016/j.jocrd.2020.100518
   Karjaluoto Heikki, 2013, J. theor. appl. electron. commer. res., V8, P1, DOI 10.4067/S0718-18762013000100002
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim J, 2022, VIRTUAL REAL-LONDON, V26, P425, DOI 10.1007/s10055-021-00570-x
   Kim J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106484
   Kober SE, 2013, INT J HUM-COMPUT INT, V29, P13, DOI 10.1080/10447318.2012.668131
   Kousoulis P, 2016, AEROSP MED HUM PERF, V87, P954, DOI 10.3357/AMHP.4540.2016
   Kung FYH, 2018, APPL PSYCHOL-INT REV, V67, P264, DOI 10.1111/apps.12108
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   de Araújo AVL, 2019, BIOMED RES INT-UK, V2019, DOI 10.1155/2019/7106951
   Laforest M., 2016, Frontiers in ICT, V3, DOI DOI 10.3389/FICT.2016.00018
   Lang KM, 2018, PREV SCI, V19, P284, DOI 10.1007/s11121-016-0644-5
   Lanier M, 2019, COMPUT HUM BEHAV, V100, P70, DOI 10.1016/j.chb.2019.06.015
   Leite WL, 2011, J EXP EDUC, V79, P361, DOI 10.1080/00220973.2010.509369
   Li L, 2017, AM J TRANSL RES, V9, P3867
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Lumley T, 2002, ANNU REV PUBL HEALTH, V23, P151, DOI 10.1146/annurev.publhealth.23.100901.140546
   Makransky G, 2017, COMPUT HUM BEHAV, V72, P276, DOI 10.1016/j.chb.2017.02.066
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   McDonald RP, 1999, TEST THEORY UNIFIED
   McHugh N., 2019, Master's Thesis, DOI [10.26021/1316, DOI 10.26021/1316]
   McNeish D, 2018, PSYCHOL METHODS, V23, P412, DOI 10.1037/met0000144
   Melo M, 2018, COMPUT GRAPH-UK, V71, P159, DOI 10.1016/j.cag.2017.11.007
   Moncada i LluYs SM., 2021, REV ESP SALUD PUBLIC, V95, P1
   Mousavi M, 2013, ADV ENG FORUM, V10, P34, DOI 10.4028/www.scientific.net/AEF.10.34
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Newbutt N, 2016, J AUTISM DEV DISORD, V46, P3166, DOI 10.1007/s10803-016-2830-5
   Owens ME, 2015, J PSYCHOPATHOL BEHAV, V37, P296, DOI 10.1007/s10862-014-9454-x
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Park G.R., 2006, Proceedings of the Human Factors and Ergonomics Society 50 Annual Meeting, P2702, DOI DOI 10.1177/154193120605002607
   Pot-Kolder R, 2018, CYBERPSYCH BEH SOC N, V21, P187, DOI 10.1089/cyber.2017.0082
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Riva G, 2019, CYBERPSYCH BEH SOC N, V22, P82, DOI 10.1089/cyber.2017.29099.gri
   Riva G, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00164
   Sagnier C, 2020, INT J HUM-COMPUT INT, V36, P993, DOI 10.1080/10447318.2019.1708612
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Satorra A, 2010, PSYCHOMETRIKA, V75, P243, DOI 10.1007/S11336-009-9135-Y
   Sauerbrei W, 2007, STAT MED, V26, P5512, DOI 10.1002/sim.3148
   Schmidt M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.611740
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Servotte JC, 2020, CLIN SIMUL NURS, V38, P35, DOI 10.1016/j.ecns.2019.09.006
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Sheeran P., 2002, EUR REV SOC PSYCHOL, V12, P1, DOI [10.1080/14792772143000003, DOI 10.1080/14792772143000003]
   Shen J, 2009, J ELECTRON COMMER RE, V10, P94
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Suki Norazah Mohd, 2011, Journal of Information Technology Management, V22, P1
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   Teixeira J, 2021, VIRTUAL REAL-LONDON, V25, P433, DOI 10.1007/s10055-020-00466-2
   Tussyadiah IP, 2018, TOURISM MANAGE, V66, P140, DOI 10.1016/j.tourman.2017.12.003
   Venkatesh V, 2008, DECISION SCI, V39, P273, DOI 10.1111/j.1540-5915.2008.00192.x
   Vrieze SI, 2012, PSYCHOL METHODS, V17, P228, DOI 10.1037/a0027127
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   WARSHAW PR, 1985, J EXP SOC PSYCHOL, V21, P213, DOI 10.1016/0022-1031(85)90017-4
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wu J., 2007, Journal of Electronic Commerce Research, V8, P128, DOI DOI 10.4018/JEBR.2012070103
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Yildirim C, 2019, DISPLAYS, V59, P35, DOI 10.1016/j.displa.2019.07.002
NR 112
TC 15
Z9 17
U1 1
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1347
EP 1371
DI 10.1007/s10055-022-00636-4
EA MAR 2022
PG 25
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000762882100001
PM 35250349
OA Green Submitted, Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Shakeri, M
   Sadeghi-Niaraki, A
   Choi, SM
AF Shakeri, Maryam
   Sadeghi-Niaraki, Abolghasem
   Choi, Soo-Mi
TI Augmented reality-based border management
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Border management; Information integration;
   Experimental study
ID EXPERIENCE; CONTEXT; GIS
AB A proficient border management has typically been tied to its capability to support information structuring and to make exchanges from the distributed sources. The lack of a proper access interface to information at the right time and the right place to conduct various activities. Augmented reality (AR) has been proposed as an efficient interface in order to improve the efficiency and the effectiveness of activities in the real world. There has only been a limited amount of research that has evaluated the effectiveness and usability of AR in the border management domain. This research aims to evaluate the effectiveness of border management and AR system integration to enhance the activities' efficiency through improving the information retrieval process. The system development steps were adopted to design, develop, and evaluate the border management AR (BM AR) system. The system contains three AR services that include pointing to border objects, showing the borderline, and locating border objects. The system also integrates the information from different resources in an interoperable way using GIS web services. The results revealed the effectiveness of using AR for border activities, which can reduce the operating costs and effectively, access the required information for doing different activities in the border field.
C1 [Shakeri, Maryam] KN Toosi Univ Technol, Fac Geodesy & Geomat Engn, Geoinformat Technol Ctr Excellence, Tehran, Iran.
   [Sadeghi-Niaraki, Abolghasem; Choi, Soo-Mi] Sejong Univ, Dept Comp Sci & Engn & Convergence Engn Intellige, Seoul, South Korea.
C3 K. N. Toosi University of Technology; Sejong University
RP Choi, SM (corresponding author), Sejong Univ, Dept Comp Sci & Engn & Convergence Engn Intellige, Seoul, South Korea.
EM a.sadeghi@sejong.ac.kr; smchoi@sejong.ac.kr
RI Sadeghi-Niaraki, Abolghasem/AAS-8441-2020
OI Sadeghi-Niaraki, Abolghasem/0000-0002-0048-8216
FU MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) support program [IITP-2021-2016-0-00312]
FX This research was supported by the MSIT (Ministry of Science and ICT),
   Korea, under the ITRC (Information Technology Research Center) support
   program (IITP-2021-2016-0-00312) supervised by the IITP (Institute for
   Information & communications Technology Planning & Evaluation).
CR Ahmed TT, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2426, DOI 10.1109/ICACCI.2018.8554868
   Ahn J, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-18
   Amin Dhiraj, 2015, International Journal on Computational Science & Applications, V5, P11, DOI DOI 10.5121/IJCSA.2015.5102
   Ananda F., 2016, INT J SOFTW ENG APPL, V7, P1
   Anderson J, 1999, REG STUD, V33, P593, DOI 10.1080/00343409950078648
   [Anonymous], 2008, State/space: a reader
   [Anonymous], 2018, INT RES J ENG TECHNO
   Auchter J., 2020, PUBLIC MEMORY CONTEX, P267
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baral T. N., 2018, J APF COMMAND STAFF, V1, P28, DOI DOI 10.3126/JAPFCSC.V1I1.26710
   Bertino Elisa, 2008, SPRINGL, P6, DOI DOI 10.1145/1503402.1503406
   Bharosa N, 2012, SECUR INFORM, V1, DOI 10.1186/2190-8532-1-15
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Blanco-Pons S, 2019, MULTIMED TOOLS APPL, V78, P10265, DOI 10.1007/s11042-018-6609-x
   Bower M, 2014, EDUC MEDIA INT, V51, P1, DOI 10.1080/09523987.2014.889400
   Brioso SAP, 2020, THESIS
   Cao L., 2007, Geocarto International, V22, P107, DOI [10.1080/10106040701204073, DOI 10.1080/10106040701204073]
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Carozza L, 2014, COMPUT-AIDED CIV INF, V29, P2, DOI 10.1111/j.1467-8667.2012.00798.x
   Carpenter N, 2018, U.S. Patent Application, Patent No. [15/897,115, 15897115]
   Champney R, 2015, LECT NOTES COMPUT SC, V9179, P251, DOI 10.1007/978-3-319-21067-4_26
   Charisi K, 2021, INT SCI C STRAT 21, P247
   Chen J, 2013, INT ARCH PHOTOGRAMM, V40-4-W3, P15, DOI 10.5194/isprsarchives-XL-4-W3-15-2013
   Chu M, 2018, AUTOMAT CONSTR, V85, P305, DOI 10.1016/j.autcon.2017.10.032
   Donaubauer A., 2006, P 23 INT FIG C MUN G, P8
   Dünser A, 2011, HANDBOOK OF AUGMENTED REALITY, P289, DOI 10.1007/978-1-4614-0064-6_13
   Duguleana M, 2018, COMM COM INF SC, V852, P184, DOI 10.1007/978-3-319-92285-0_26
   Geihs K, 2012, 2012 IEEE/IPSJ 12TH INTERNATIONAL SYMPOSIUM ON APPLICATIONS AND THE INTERNET (SAINT), P405, DOI 10.1109/SAINT.2012.73
   Guo Rongxing., 2015, Cross-Border Management: Theory, Method and Application
   Hartmann J, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188535
   Haynes P, 2018, ENVIRON MODELL SOFTW, V109, P380, DOI 10.1016/j.envsoft.2018.05.012
   Heimo OI, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON ETHICS IN SCIENCE, TECHNOLOGY AND ENGINEERING
   Hoffman AJ, 2013, AFRICON, P654
   Hong SK, 2008, ISO WORKSH ADDR STAN
   Huang HS, 2012, CARTOGR GEOGR INF SC, V39, P107, DOI 10.1559/15230406392107
   Hugues O, 2011, HANDBOOK OF AUGMENTED REALITY, P721, DOI 10.1007/978-1-4614-0064-6_33
   Javornik A, 2019, BEHAV INFORM TECHNOL, V38, P9, DOI 10.1080/0144929X.2018.1505950
   Jelokhani-Niaraki M, 2018, ENVIRON MODELL SOFTW, V100, P104, DOI 10.1016/j.envsoft.2017.11.011
   Jones SB, 1943, ANN ASSOC AM GEOGR, V33, P99, DOI 10.2307/2561003
   Jooste D, 2015, FREE OPEN SOURCE SOF, V15, P37
   Kagawa A, 2013, INT ARCH PHOTOGRAMM, V40-4-W3, P149, DOI 10.5194/isprsarchives-XL-4-W3-149-2013
   Kansakar VBS, 2012, NEPAL INDIA OPEN BOR
   Kim J, 2008, IEEE T CONSUM ELECTR, V54, P954, DOI 10.1109/TCE.2008.4637573
   Kim TJ, 2012, SPRINGER HANDBOOK OF GEOGRAPHIC INFORMATION, P643
   Knörchen A, 2015, COMPUT GEOSCI-UK, V74, P13, DOI 10.1016/j.cageo.2014.10.003
   Kumar JA, 2018, INFORM SCIENCES, V460, P23, DOI 10.1016/j.ins.2018.05.003
   Latre MA, 2005, P 11 EC GI GIS WORKS, V29, P12
   Lee S, 2015, COMPUT GEOSCI-UK, V76, P41, DOI 10.1016/j.cageo.2014.12.005
   Levitt JP, 2019, GEOSCI FRONT, V10, P1669, DOI 10.1016/j.gsf.2019.01.002
   LEWIS JR, 1992, PROCEEDINGS OF THE HUMAN FACTORS SOCIETY, 36TH ANNUAL MEETING, VOLS 1 AND 2, P1259, DOI 10.1177/154193129203601617
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Litvak E, 2020, PERS UBIQUIT COMPUT, V24, P873, DOI 10.1007/s00779-020-01366-7
   Lovelock B., 2006, N TOUR GEOGR, V8, P143
   Masoumi Z, 2021, GEOCARTO INT, V36, P137, DOI 10.1080/10106049.2019.1595176
   MD, 2013, MACMILLAN DICT
   Meha M., 2010, CHALLENGES BORDER DE
   Meza S, 2015, ADV ENG SOFTW, V90, P1, DOI 10.1016/j.advengsoft.2015.06.005
   Milosavljevic A, 2010, INT J GEOGR INF SCI, V24, P1415, DOI 10.1080/13658811003792213
   Mirauda D, 2017, WATER-SUI, V9, DOI 10.3390/w9090699
   Moreno-Sanchez R, 2007, INT J GEOGR INF SCI, V21, P1135, DOI 10.1080/13658810701300113
   Nunes MDC, 2015, P INT FED SURV FIG W, P16
   Olsson T, 2013, PERS UBIQUIT COMPUT, V17, P287, DOI 10.1007/s00779-011-0494-x
   Park NY, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P484, DOI 10.1109/SITIS.2016.81
   Pierdicca R, 2016, COMPUT GEOSCI-UK, V95, P67, DOI 10.1016/j.cageo.2016.06.018
   Plopski A, 2018, LECT NOTES COMPUT SC, V10927, P113, DOI 10.1007/978-3-319-92037-5_10
   Pombo L, 2019, INT J MOB BLENDED LE, V11, P59, DOI 10.4018/IJMBL.2019100105
   Portman ME, 2007, OCEAN COAST MANAGE, V50, P499, DOI 10.1016/j.ocecoaman.2007.02.008
   Ramtohul Arvind, 2019, Information Systems Design and Intelligent Applications. Proceedings of Fifth International Conference INDIA 2018. Advances in Intelligent Systems and Computing (AISC 863), P175, DOI 10.1007/978-981-13-3338-5_17
   Reuter A, 2008, BLACKW COMPANION GEO, P609
   RIECKEN J, 2003, 9 EC GI GIS WORKSH E
   Sabry D, 2014, J ADV RES, V5, P595, DOI 10.1016/j.jare.2013.08.003
   Schober P, 2018, ANESTH ANALG, V126, P1763, DOI 10.1213/ANE.0000000000002864
   Sharif M, 2017, J NETW COMPUT APPL, V93, P150, DOI 10.1016/j.jnca.2017.05.009
   Uchida N, 2017, IEEE INTEL TRANSP SY, V9, P35, DOI 10.1109/MITS.2016.2601943
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Winzer P, 2017, LECT NOTES COMPUT SC, V10653, P173, DOI 10.1007/978-3-319-71940-5_16
   Zhang GY, 2020, INT J DIGIT EARTH, V13, P1302, DOI 10.1080/17538947.2019.1711210
   Zsila A, 2018, PERS INDIV DIFFER, V133, P56, DOI 10.1016/j.paid.2017.06.024
NR 78
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1123
EP 1143
DI 10.1007/s10055-021-00611-5
EA JAN 2022
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000743830800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Fialho, L
   Oliveira, J
   Filipe, A
   Luz, F
AF Fialho, L.
   Oliveira, J.
   Filipe, A.
   Luz, F.
TI Soundspace VR: spatial navigation using sound in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Spatial memory; Spatial navigation; Sound cues
ID MONTREAL COGNITIVE ASSESSMENT; CONGENITALLY BLIND; MEMORY; INFORMATION;
   HIPPOCAMPUS; CORTEX; MOCA
AB Prior research reveals that spatial navigation skills rely mostly in visual sensory abilities, but the study of how spatial processing operates in the absence of visual information is still incomplete. Therefore, a spatial navigation task in virtual reality using auditory cues was developed to study navigational strategies in blindfolded sighted individuals. Twenty healthy adult participants were recruited. The task consisted of a VR scene, in which participants were asked to localize a sound source and move to the target without visual information throughout the entire task. Task difficulty was manipulated by route length and complexity in three different difficulty levels repeated in two different trials. The first trial (learning) consisted of moving to the sound source and then returning to the starting point. The second trial (retrieval) consisted of the same task without the sound source but with auditory cues from obstacles to test spatial learning. Performance was assessed from behavioral measures of execution time, obstacle collisions, and prompts during the task execution. These variables were compared to established neuropsychological instruments for global cognition (Montreal Cognitive Assessment) and memory abilities (Wechsler Memory Scale-R). The results suggested that difficulty level affected navigation performance in both trials. Navigation performance was better in the retrieval trial, but both learning and retrieval trials were explained by global cognitive functioning. These data suggested the Soundspace VR as being effective to study spatial navigation in the absence of visual information and highlight the importance of auditory information from spatial sound cues for spatial navigation and spatial learning.
C1 [Fialho, L.; Oliveira, J.; Filipe, A.; Luz, F.] Lusofona Univ, Campo Grande 376, P-1749024 Lisbon, Portugal.
   [Oliveira, J.; Luz, F.] HEI Lab, Lisbon, Portugal.
C3 Lusofona University
RP Oliveira, J (corresponding author), Lusofona Univ, Campo Grande 376, P-1749024 Lisbon, Portugal.; Oliveira, J (corresponding author), HEI Lab, Lisbon, Portugal.
EM jorge.oliveira@ulusofona.pt
RI Oliveira, J/F-4476-2015
OI Oliveira, J/0000-0002-3467-4981; Luz, Filipe/0000-0002-3608-8417
CR Allen G. L., 1999, SPAT COGN COMPUT, V1, P413
   Allison SL, 2016, J ALZHEIMERS DIS, V52, P77, DOI 10.3233/JAD-150855
   [Anonymous], 2011, INT J DISABIL HUM DE, DOI DOI 10.1515/IJDHD.2011.050
   Burton H, 2003, J NEUROSCI, V23, P4005
   CLEAVES WT, 1979, J VISUAL IMPAIR BLIN, V73, P13
   Cushman LA, 2008, NEUROLOGY, V71, P888, DOI 10.1212/01.wnl.0000326262.67613.fe
   Dolins FL, 2014, AM J PRIMATOL, V76, P496, DOI 10.1002/ajp.22252
   Dumas C, 1998, BEHAV PROCESS, V42, P101, DOI 10.1016/S0376-6357(97)00071-5
   Eichenbaum H, 2017, J NEUROPHYSIOL, V117, P1785, DOI 10.1152/jn.00005.2017
   Franz MO, 2000, ROBOT AUTON SYST, V30, P133, DOI 10.1016/S0921-8890(99)00069-X
   Freitas S, 2011, J CLIN EXP NEUROPSYC, V33, P989, DOI 10.1080/13803395.2011.589374
   Haun DBM, 2006, CURR BIOL, V16, P1736, DOI 10.1016/j.cub.2006.07.049
   Healy S.D., 2010, Encyclopedia of Animal Behavior, P304
   Jost TA, 2021, DISABIL REHABIL-ASSI, V16, P632, DOI 10.1080/17483107.2019.1688398
   Lages W. S., 2018, Frontiers in ICT, V5, P1, DOI [DOI 10.3389/FICT.2018.00015, 10.3389/fict.2018.00015]
   Leo F, 2018, SAGE OPEN MED, V6, DOI 10.1177/2050312118820028
   Lubetzky AV, 2019, J BIOMECH, V86, P175, DOI 10.1016/j.jbiomech.2019.02.004
   Massiceti D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199389
   McCabe DP, 2010, NEUROPSYCHOLOGY, V24, P222, DOI 10.1037/a0017619
   Montana JI, 2019, J CLIN MED, V8, DOI 10.3390/jcm8101516
   MORRIS RGM, 1986, Q J EXP PSYCHOL-B, V38, P365
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   PASSINGHAM RE, 1985, BEHAV NEUROSCI, V99, P3, DOI 10.1037/0735-7044.99.1.3
   Schinazi VR, 2016, WIRES COGN SCI, V7, P37, DOI 10.1002/wcs.1375
   Spillers F, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P158, DOI 10.1145/3131277.3134921
   Vargas JP, 2005, J COMP PSYCHOL, V119, P458, DOI 10.1037/0735-7036.119.4.458
   Wechsler D, 1987, WMS-R: Wechsler Memory Scale-Revised: Manual
   Wolbers T, 2007, J NEUROSCI, V27, P9408, DOI 10.1523/JNEUROSCI.2146-07.2007
   Yang CL, 2014, J NEUROIMAGING, V24, P68, DOI 10.1111/j.1552-6569.2011.00686.x
NR 30
TC 3
Z9 3
U1 5
U2 32
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 397
EP 405
DI 10.1007/s10055-021-00597-0
EA NOV 2021
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000722492300001
DA 2024-07-18
ER

PT J
AU Kim, H
   Remaggi, L
   Dourado, A
   de Campos, T
   Jackson, PJB
   Hilton, A
AF Kim, Hansung
   Remaggi, Luca
   Dourado, Aloisio
   de Campos, Teofilo
   Jackson, Philip J. B.
   Hilton, Adrian
TI Immersive audio-visual scene reproduction using semantic scene
   reconstruction from 360 cameras
SO VIRTUAL REALITY
LA English
DT Article
DE Audio-visual scene reproduction; Scene understanding; 3D reconstruction
   and completion; Spatial audio
ID VIRTUAL-REALITY; IMPLEMENTATION; PERCEPTION; FUTURE
AB As personalised immersive display systems have been intensely explored in virtual reality (VR), plausible 3D audio corresponding to the visual content is required to provide more realistic experiences to users. It is well known that spatial audio synchronised with visual information improves a sense of immersion but limited research progress has been achieved in immersive audio-visual content production and reproduction. In this paper, we propose an end-to-end pipeline to simultaneously reconstruct 3D geometry and acoustic properties of the environment from a pair of omnidirectional panoramic images. A semantic scene reconstruction and completion method using a deep convolutional neural network is proposed to estimate the complete semantic scene geometry in order to adapt spatial audio reproduction to the scene. Experiments provide objective and subjective evaluations of the proposed pipeline for plausible audio-visual VR reproduction of real scenes.
C1 [Kim, Hansung] Univ Southampton, ECS, Southampton, Hants, England.
   [Remaggi, Luca] Creat Labs UK, London, England.
   [Dourado, Aloisio; de Campos, Teofilo] Univ Brasilia, Brasilia, DF, Brazil.
   [Jackson, Philip J. B.; Hilton, Adrian] Univ Surrey, CVSSP, Guildford, Surrey, England.
C3 University of Southampton; Universidade de Brasilia; University of
   Surrey
RP Kim, H (corresponding author), Univ Southampton, ECS, Southampton, Hants, England.
EM h.kim@soton.ac.uk; luca_remaggi@cle.creative.com;
   aloisio.dourado.bh@gmail.com; t.decampos@oxfordalumni.org;
   p.jackson@surrey.ac.uk; a.hilton@surrey.ac.uk
RI Jackson, Philip J B/E-8422-2013; Hilton, Adrian/N-3736-2014
OI Jackson, Philip J B/0000-0001-7933-5935; Hilton,
   Adrian/0000-0003-4223-238X; Kim, Hansung/0000-0003-4907-0491
FU UKRI EPSRC [EP/L000539/1, EP/V038087/1, EP/P022529/1]; EPSRC
   [EP/P022529/1, EP/L000539/1] Funding Source: UKRI
FX This work was supported by the UKRI EPSRC Programme Grant S3A: Future
   Spatial Audio for an Immersive Listener Experience at Home
   (EP/L000539/1) and Prosperity Partnership AI4ME: AI for Personalised
   Media Experiences EP/V038087/1, the BBC as part of the BBC Audio
   Research Partnership, and Audio-Visual Media Research Platform
   (EP/P022529/1). Details about the data underlying this work are
   available from: http://dx.doi.org/10.15126/surreydata.00812228.
CR [Anonymous], 1908, BIOMETRIKA, V6, P1
   [Anonymous], 2019, INSTA360 INSTA360 ON
   [Anonymous], 2016, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI [DOI 10.1109/CVPR.2016.170, 10.1109/CVPR.2016.170]
   [Anonymous], 1989, Simulated annealing and Boltzmann machines: A stochastic approach to combinatorial optimization and neural computing
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bailey W., 2017, J ACOUST SOC AM, V141, P3510, DOI DOI 10.1121/1.4987362
   Bailey W, 2018, P 144 AES CONV MIL I
   Barazzetti L., 2018, Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci, VXLII-2, P69, DOI [10.5194/isprs-archives-XLII-2-69-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-69-2018]
   BARRON M, 1995, ACUSTICA, V81, P320
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Bianco S, 2018, J IMAGING, V4, DOI 10.3390/jimaging4080098
   Blauert J, 2005, COMMUNICATION ACOUSTICS, P1, DOI 10.1007/3-540-27437-5_1
   Bleyer M, 2013, ADV COMPUT VIS PATT, P143, DOI 10.1007/978-1-4471-5520-1_6
   Bradley JS, 2011, APPL ACOUST, V72, P713, DOI 10.1016/j.apacoust.2011.04.004
   Brown K, 2017, AUDIO ENG SOC CONVEN, P142
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Corporation V, 2021, STEAM AUD
   Cosker D, 2013, IEEE MULTIMEDIA, V20, P18, DOI 10.1109/MMUL.2012.61
   Cox T, 2013, GUN SHOT ANECHOIC CH
   Dourado A, 2021, P ICPR
   Farina Angelo, 2000, 108 AES CONVENTION
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Furukawa Y., 2015, COMPUT GR VIS, V9
   Garofolo J. S., 1993, DARPA TIMIT acoustic-phonetic continuous speech corpus CD-ROM TIMIT
   Gaudio, 2021, GAUD VR AUD
   Gonzalez R., 2017, DIGITAL IMAGE PROCES
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   Google, 2021, GOOGL RES AUD
   GoPro, 2019, GOPR FUS
   Gorzel M, 2019, 2019 AES INTERNATIONAL CONFERENCE ON IMMERSIVE AND INTERACTIVE AUDIO
   Guo R., 2015, ARXIV150402437
   Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13
   Handa A., 2015, Scenenet: Understanding real world indoor scenes with synthetic data. arXiv
   Hicks M., 2004, Virtual Reality, V7, P148, DOI 10.1007/s10055-004-0126-0
   Hoeg W, 1997, SUBJECTIVE ASSESSMEN
   HTC, 2018, VIV PRO
   Hulusic V, 2012, COMPUT GRAPH FORUM, V31, P102, DOI 10.1111/j.1467-8659.2011.02086.x
   Im S, 2016, LECT NOTES COMPUT SC, V9907, P156, DOI 10.1007/978-3-319-46487-9_10
   Kim H, 2017, P 142 AES CONV
   Kim HG, 2020, IEEE T CIRC SYST VID, V30, P917, DOI 10.1109/TCSVT.2019.2898732
   Kim H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P120, DOI 10.1109/VR.2019.8798247
   Kim H, 2013, INT J COMPUT VISION, V104, P94, DOI 10.1007/s11263-013-0616-1
   Kim H, 2012, IEEE T CIRC SYST VID, V22, P1611, DOI 10.1109/TCSVT.2012.2202185
   Kim UH, 2020, IEEE T CYBERNETICS, V50, P4921, DOI 10.1109/TCYB.2019.2931042
   Kinetic A, 2021, WWISE SPATIAL AUDIO
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kon H, 2018, P 144 AES CONV MIL I
   Larsson P, 2010, HUM-COMPUT INT-SPRIN, P143, DOI 10.1007/978-1-84882-733-2_8
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Li D, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201391
   Lindau A, 2012, ACTA ACUST UNITED AC, V98, P804, DOI 10.3813/AAA.918562
   Liu SC, 2018, ADV NEUR IN, V31
   Mekuria R, 2017, IEEE T CIRC SYST VID, V27, P828, DOI 10.1109/TCSVT.2016.2543039
   Meng ZH, 2006, 2006 INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES,VOLS 1-3, P468
   Menzies RJ, 2016, VIRTUAL REAL-LONDON, V20, P173, DOI 10.1007/s10055-016-0288-6
   Morgado Pedro, 2018, Advances in Neural Information Processing Systems
   Narayanan S, 2020, VIRTUAL REAL-LONDON, V24, P53, DOI 10.1007/s10055-019-00382-0
   Neidhardt Annika, 2018, 144 INT AES CONV MIL, P1
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Peng XM, 2015, IEEE T CIRC SYST VID, V25, P225, DOI 10.1109/TCSVT.2014.2335832
   Politis A, 2018, P 144 AES CONV
   Pollard KA, 2020, VIRTUAL REAL-LONDON, V24, P783, DOI 10.1007/s10055-019-00411-y
   Postma BNJ, 2015, VIRTUAL REAL-LONDON, V19, P161, DOI 10.1007/s10055-015-0275-3
   Remaggi L, 2015, P 138 AES CONV
   Remaggi L., 2019, P ICA
   Ricoh, 2019, RIC THET V
   Robotham T, 2018, P 145 AES CONV NEW Y
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rossing T., 2014, Springer handbook of acoustics
   Rossiter D., 1995, VIRT REAL, V1, P117, DOI [10.1007/BF02009728, DOI 10.1007/BF02009728]
   Rothman K J, 1990, Epidemiology, V1, P43, DOI 10.1097/00001648-199001000-00010
   Ruminski D, 2015, VIRTUAL REAL-LONDON, V19, P223, DOI 10.1007/s10055-015-0274-4
   Bhama PRKS, 2020, VIRTUAL REAL-LONDON, V24, P163, DOI 10.1007/s10055-017-0321-4
   Schissler C, 2018, IEEE T VIS COMPUT GR, V24, P1246, DOI 10.1109/TVCG.2017.2666150
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Smith L. N., 2018, A disciplined approach to neural network hyper-parameters: Part 1 learning rate, batch size, momentum, and weight decay
   Song M., 2018, Int. Conf. Wireless Commun. Signal Processing, P1, DOI 10.1109/wcsp.2018.8555927
   Song SR, 2018, PROC CVPR IEEE, P3847, DOI 10.1109/CVPR.2018.00405
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   STAHLE L, 1989, CHEMOMETR INTELL LAB, V6, P259, DOI 10.1016/0169-7439(89)80095-4
   Stan GB, 2002, J AUDIO ENG SOC, V50, P249
   Tervo S, 2013, J AUDIO ENG SOC, V61, P17
   Turk M, 2014, PATTERN RECOGN LETT, V36, P189, DOI 10.1016/j.patrec.2013.07.003
   Välimäki V, 2012, IEEE T AUDIO SPEECH, V20, P1421, DOI 10.1109/TASL.2012.2189567
   VORLANDER M, 1995, ICA 95 - PROCEEDINGS OF THE 15TH INTERNATIONAL CONGRESS ON ACOUSTICS, VOL II, P689
   Zhang JH, 2018, LECT NOTES COMPUT SC, V11216, P749, DOI 10.1007/978-3-030-01258-8_45
NR 87
TC 5
Z9 5
U1 2
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 823
EP 838
DI 10.1007/s10055-021-00594-3
EA OCT 2021
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000712929600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Yan, W
AF Yan, Wei
TI Augmented reality instructions for construction toys enabled by accurate
   model registration and realistic object/hand occlusions
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Assembly; Instruction; Occlusion; Accuracy
ID SIMULTANEOUS LOCALIZATION
AB BRICKxAR is a novel augmented reality (AR) instruction method for construction toys such as LEGO (R). With BRICKxAR, physical LEGO construction is guided by virtual bricks. Compared with the state of the art, accuracy of the virtual-physical model alignment is significantly improved through a new design of marker-based registration, which can achieve an average error less than 1 mm throughout the model. Realistic object occlusion is accomplished to reveal the true spatial relationship between physical and virtual bricks. LEGO players' hand detection and occlusion are realized to visualize the correct spatial relationship between real hands and virtual bricks, and allow virtual bricks to be "grasped" by real hands. The major finding of the research is that the integration of these features makes AR instructions possible for small parts assembly, validated through a working AR prototype for constructing LEGO Arc de Triomphe and quantitative measures of the accuracies of registration and occlusions. In addition, a heuristic evaluation of BRICKxAR's features has led to findings that the present method could advance AR instructions in terms of enhancing part visibility, match between mental models and visualization, alignment of physical and virtual parts in perspective views and spatial transformations, tangible user interface, consolidated structural diagrams, virtual cutaway views, among other benefits for guiding construction.
C1 [Yan, Wei] Texas A&M Univ, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station
RP Yan, W (corresponding author), Texas A&M Univ, College Stn, TX 77843 USA.
EM wyan@tamu.edu
CR Abate Andrea F., 2014, Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8525, P319, DOI 10.1007/978-3-319-07458-0_30
   Abe UI, 2017, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON COMPUTER-AIDED ARCHITECTURAL DESIGN RESEARCH IN ASIA (CAADRIA 2017), P75
   Agrawala M, 2003, ACM T GRAPHIC, V22, P828, DOI 10.1145/882262.882352
   AlNajdi SM, 2020, INTERACT LEARN ENVIR, V28, P964, DOI 10.1080/10494820.2018.1552873
   Alonso L., 2018, Unifying Themes in Complex Systems IX: Proceedings of the Ninth International Conference on Complex Systems 9, V9, P253, DOI [10.1007/978-3-319-96661-8 27, DOI 10.1007/978-3-319-96661-8_27, DOI 10.1007/978-3-319-96661-827]
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144
   Bottani E, 2019, IISE TRANS, V51, P284, DOI 10.1080/24725854.2018.1493244
   Büttner S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376720
   Cao YZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376688
   Chen ZR., 2018, P CAADRIA, V2018, P349
   Christensen AL, 2018, P 36 EUR C COGN ERG, P5
   Du C, 2016, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR.2016.17
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Eisenberg, 1998, DESIGN CHILDRENS TEC, P244
   Endsley Tristan C., 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P2100, DOI 10.1177/1541931213602007
   Funk M, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P253, DOI 10.1145/2836041.2836067
   Hahm S, 2019, INTELLIGENT INFORM P, V1, P553
   Heiser J., 2004, P WORK C ADV VIS INT, P311, DOI DOI 10.1145/989863.989917
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Hoover M, 2020, J COMPUT INF SCI ENG, V20, DOI 10.1115/1.4046006
   Ibáñez MB, 2018, COMPUT EDUC, V123, P109, DOI 10.1016/j.compedu.2018.05.002
   Jahn G., 2018, Proceedings of the 38th Annual Conference of the Association for Computer Aided Design in Architecture, P88, DOI [10.52842/conf.acadia.2018.088, DOI 10.52842/CONF.ACADIA.2018.088]
   Jirout JJ, 2015, PSYCHOL SCI, V26, P302, DOI 10.1177/0956797614563338
   KASPERI J, 2017, P 23 ACM S VIRTUAL R, P1
   Kobie N, 2017, WIRED UK        1201
   Legolizer, 2018, 21036 LEGO
   Lindstrom M., 2016, Small data: the tiny clues that uncover huge trends
   MacAllister A., 2017, I/ITSEC 2017, P1
   Martin C.V., 2007, Proceedings of the Human Factors and Ergonomics Society 51st Annual Meeting, P1025
   Martin CV, 2008, HUM FACTORS, V50, P652, DOI 10.1518/001872008X288592
   Martin CV, 2007, THESIS VIRGINIA POLY
   Nielsen J, 1990, Proceedings ACM CHI'90 Conf, DOI [DOI 10.1145/97243.97281, 10.1145/97243.97281]
   Olson E, 2011, IEEE INT CONF ROBOT
   Qian, 2019, INTELLIGENT INFORM P, P495
   Richardson T., 2014, I/ITSEC, P1
   Schwald B, 2003, WSCG'2003, VOL 11, NO 3, CONFERENCE PROCEEDINGS, P425
   Shaik KB, 2015, PROCEDIA COMPUT SCI, V57, P41, DOI 10.1016/j.procs.2015.07.362
   Smith TP., 2003, DEV CONSUMER PRODUCT
   Son K, 2020, 2020 IEEE MTT-S INTERNATIONAL CONFERENCE ON NUMERICAL ELECTROMAGNETIC AND MULTIPHYSICS MODELING AND OPTIMIZATION (NEMO 2020), DOI 10.1109/NEMO49486.2020.9343473
   Tang A., 2003, P SIGCHI C HUM FACT, P73, DOI [10.1145/642611.642626, DOI 10.1145/642611.642626]
   Tatic D, 2017, COMPUT IND, V85, P1, DOI 10.1016/j.compind.2016.11.004
   TRACY DM, 1987, SEX ROLES, V17, P115, DOI 10.1007/BF00287620
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Westerfield Giles, 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P542, DOI 10.1007/978-3-642-39112-5_55
   Wood H, 2010, TG62 SPEC TRACK 18 C
NR 46
TC 12
Z9 13
U1 2
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 465
EP 478
DI 10.1007/s10055-021-00582-7
EA OCT 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000704964900001
PM 34658653
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Dzardanova, E
   Kasapakis, V
   Gavalas, D
   Sylaiou, S
AF Dzardanova, Elena
   Kasapakis, Vlasios
   Gavalas, Damianos
   Sylaiou, Stella
TI Virtual reality as a communication medium: a comparative study of forced
   compliance in virtual reality versus physical world
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; VR-mediated communication; Computer-mediated
   communication; Face-to-face communication; Forced compliance; Cognitive
   dissonance
ID COGNITIVE-DISSONANCE; INDIVIDUAL-DIFFERENCES; BODY OWNERSHIP; SPEAKING
AB There are reasons to consider virtual reality (VR) as a newly arrived communication medium that ought to be differentiated from all other forms of mediated communication, since it is the first and only medium with the potential to enable incorporation of the full spectrum of both verbal and non-verbal cues. The present paper is part of a broader scheme in investigating potential differentiations in interpersonal communication between the physical world and VR. Our experimental design builds upon the existing knowledge base of forced compliance experiments; the set-up involved a comparative study of two groups (N = 46) performing tasks under the authoritative influence of a researcher who applied persuasion techniques. Results indicate that VR-mediated communication is as intricate as face to face, since subjects were equally or more compliant, with the nature of information exchanged (e.g. fact-based, morality-based, etc.) being a contributing factor, whilst exemplifying under-development and future applications of VR collaborative environments.
C1 [Dzardanova, Elena; Gavalas, Damianos; Sylaiou, Stella] Univ Aegean, Dept Prod & Syst Design Engn, Syros, Greece.
   [Kasapakis, Vlasios] Univ Aegean, Dept Cultural Technol & Commun, Lesvos, Greece.
C3 University of Aegean; University of Aegean
RP Kasapakis, V (corresponding author), Univ Aegean, Dept Cultural Technol & Commun, Lesvos, Greece.
EM v.kasapakis@aegean.gr
RI Dzardanova, Elena/GSN-6241-2022; Sylaiou, Stella/E-9605-2013; Vlasis,
   Kasapakis/AAS-8169-2020
OI Sylaiou, Stella/0000-0001-5879-5908; Kasapakis,
   Vlasios/0000-0002-4048-6047
FU Hellenic Foundation for Research and Innovation (H.F.R.I.) under the
   "First Call for H.F. R.I. Research Projects to support Faculty members
   and Researchers and the procurement of high-cost research equipment
   grant" [HFRI-FM17-1168]
FX The research work has been supported by the Hellenic Foundation for
   Research and Innovation (H.F.R.I.) under the "First Call for H.F. R.I.
   Research Projects to support Faculty members and Researchers and the
   procurement of high-cost research equipment grant" (Project Number:
   HFRI-FM17-1168).
CR [Anonymous], 2007, COGNITIVE DISSONANCE, DOI DOI 10.4135/9781446214282
   [Anonymous], 1978, OBEDIENCE AUTHORITY
   ARGYLE M, 1973, LINGUISTICS, P71
   Arthur EJ, 1997, ERGONOMICS, V40, P69, DOI 10.1080/001401397188387
   Asch S. E, 1951, GROUPS LEADERSHIP ME, P177
   Avdiu B, 2020, ECON LETT, V197, DOI 10.1016/j.econlet.2020.109648
   Baka E, 2018, P COMPUTER GRAPHICS, P107, DOI DOI 10.1145/3208159.3208179
   Banakou D, 2014, P NATL ACAD SCI USA, V111, P17678, DOI 10.1073/pnas.1414936111
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Basdogan C, 2007, IEEE COMPUT GRAPH, V27, P54, DOI 10.1109/MCG.2007.51
   BIOCCA F, 1992, J COMMUN, V42, P5, DOI 10.1111/j.1460-2466.1992.tb00810.x
   Biocca F., 1995, COMMUNICATION AGE VI
   Biocca Frank., 1995, Communication in the Age of Virtual Reality, P15
   Birdwhistell R.L., 1970, Kinesics and Context
   Carrillo C, 2020, EUR J TEACH EDUC, V43, P466, DOI 10.1080/02619768.2020.1821184
   Cialdini R.B., 2009, Influence: Science and Practice, V4
   Cialdini RB, 2004, ANNU REV PSYCHOL, V55, P591, DOI 10.1146/annurev.psych.55.090902.142015
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   de Kort YAW, 2003, PRESENCE-TELEOP VIRT, V12, P360, DOI 10.1162/105474603322391604
   Dzardanova E., 2018, ENCY COMPUTER GRAPHI, P1, DOI DOI 10.1007/978-3-319-08234-9_204-1
   Dzardanova E, 2018, IEEE CONSUM ELECTR M, V7, P44, DOI 10.1109/MCE.2018.2816204
   Dzardanova E, 2017, IEEE SYMP COMP COMMU, P6, DOI 10.1109/ISCC.2017.8024496
   Ellis S. R., 1991, Computing Systems in Engineering, V2, P321, DOI 10.1016/0956-0521(91)90001-L
   ELLIS SR, 1994, IEEE COMPUT GRAPH, V14, P17, DOI 10.1109/38.250914
   Feldman RS, 1991, FUNDAMENTALS NONVERB
   FESTINGER L, 1962, SCI AM, V207, P93, DOI 10.1038/scientificamerican1062-93
   Fiske S.T., 1991, SOCIAL COGNITION
   Girandola F, 1997, J SOC PSYCHOL, V137, P594, DOI 10.1080/00224549709595481
   Grechkin TY, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823744
   Haans A, 2014, J NONVERBAL BEHAV, V38, P301, DOI 10.1007/s10919-014-0184-2
   Hargie O., 1997, HDB COMMUNICATION SK
   Harjunen VJ, 2018, COMPUT HUM BEHAV, V87, P384, DOI 10.1016/j.chb.2018.06.012
   HOFLING CK, 1966, J NERV MENT DIS, V143, P171, DOI 10.1097/00005053-196608000-00008
   Janeh O., 2019, P 2019 ACM S APPL PE, P9, DOI DOI 10.1145/3343036.3343119
   Jonas M, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P437, DOI 10.1145/3341215.3356271
   JOULE RV, 1991, J SOC PSYCHOL, V131, P839, DOI 10.1080/00224545.1991.9924671
   Kasapakis V., 2018, ENCY COMPUTER GRAPHI, P1
   Kasapakis V, 2018, PROCEEDINGS OF THE 10TH ACM WORKSHOP ON IMMERSIVE MIXED AND VIRTUAL ENVIRONMENT SYSTEMS (MMVE'18), P13, DOI 10.1145/3210438.3210441
   Kasapakis V, 2018, LECT NOTES COMPUT SC, V10851, P668, DOI 10.1007/978-3-319-95282-6_47
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Knapp M.L., 2013, Cengage Learning
   Kuliga SF, 2015, COMPUT ENVIRON URBAN, V54, P363, DOI 10.1016/j.compenvurbsys.2015.09.006
   Kyrlitsias C, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1804
   Larsen CR., 2009, Bmj, V338, pb1802, DOI DOI 10.1136/BMJ.B1802
   Lee A.T., 2017, FLIGHT SIMULATION VI
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Mantovani E, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00926
   Matsumoto D., 2012, Nonverbal communication: Science and applications
   Mehrabian A., 1972, Nonverbal communication
   Milgram S., 1974, SCIENCE, V184, P667, DOI [10.1126/science.184.4137.667, DOI 10.1126/SCIENCE.184.4137.667]
   MILLS AW, 1960, J ACOUST SOC AM, V32, P132, DOI 10.1121/1.1907864
   Mussel P, 2013, JUDGM DECIS MAK, V8, P381
   Nahai N., 2012, Webs of influence: the psychology of online persuasion. Gra-
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Patterson ML, 1991, FUNCTIONAL APPROACH
   PAULHUS D, 1982, J PERS SOC PSYCHOL, V43, P838, DOI 10.1037/0022-3514.43.4.838
   Pertaub DP, 2001, STUD HEALTH TECHNOL, V81, P372
   Pfeiffer t, 2015, P 21 S VIRT REAL SOF, P134
   Renard E, 2007, REV INT PSYCHOL SOC, V20, P79
   Riva G, 2020, CYBERPSYCH BEH SOC N, V23, P581, DOI 10.1089/cyber.2020.29194.gri
   Roth Daniel, 2015, i-com: A Journal of Interactive and Cooperative Media, V14, P107, DOI 10.1515/icom-2015-0030
   Roth D, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364269
   Roth D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P215, DOI 10.1109/VR.2018.8447550
   Roth D, 2017, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2017.7892275
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   Roth D, 2016, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2016.7504760
   Slater M, 2006, PLOS ONE, V1, DOI 10.1371/journal.pone.0000039
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   SPEARS R, 1994, COMMUN RES, V21, P427, DOI 10.1177/009365094021004001
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Tanenbaum TJ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376606
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Witmer BG, 1998, HUM FACTORS, V40, P478, DOI 10.1518/001872098779591340
   Wu JJ, 2019, FRONT COMPUT SCI-CHI, V13, P4, DOI 10.1007/s11704-016-6213-z
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
   Zhao Q, 2009, SCI CHINA SER F, V52, P348, DOI 10.1007/s11432-009-0066-0
NR 79
TC 13
Z9 13
U1 4
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 737
EP 757
DI 10.1007/s10055-021-00564-9
EA AUG 2021
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000687002200002
PM 34456607
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU VanHorn, K
   Çobanoglu, MC
AF VanHorn, Kevin
   Cobanoglu, Murat Can
TI Democratizing AI in biomedical image classification using virtual
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Deep learning; Machine learning; Neural nets; Virtual reality;
   Visualization
AB Artificial intelligence models can produce powerful predictive computer vision tools for healthcare. However, their development simultaneously requires computational skill as well as biomedical expertise. This barrier often impedes the wider utilization of AI in professional environments since biomedical experts often lack software development skills. We present the first development environment where a user with no prior training can build near-expert level convolutional neural network classifiers on real-world datasets. Our key contribution is a simplified environment in virtual reality where the user can build, compute, and critique a model. Through a controlled user study, we show that our software enables biomedical researchers and healthcare professionals with no AI development experience to build AI models with near-expert performance. We conclude that the potential role for AI in the biomedical domain can be realized more effectively by making its development more intuitive for non-technical domain experts using novel modes of interaction.
C1 [VanHorn, Kevin; Cobanoglu, Murat Can] Univ Texas Southwestern Med Ctr Dallas, 5323 Harry Hines Blvd, Dallas, TX 75390 USA.
C3 University of Texas System; University of Texas Southwestern Medical
   Center Dallas
RP VanHorn, K (corresponding author), Univ Texas Southwestern Med Ctr Dallas, 5323 Harry Hines Blvd, Dallas, TX 75390 USA.
EM Kevin.VanHorn@utsouthwestern.edu; MuratCan.Cobanoglu@utsouthwestern.edu
OI VanHorn, Kevin/0000-0002-3629-3875
FU Lyda Hill Department of Bioinformatics startup funds
FX Lyda Hill Department of Bioinformatics startup funds awarded to M.C.C.
CR Ameet T, 2018, NOVEL BANDIT BASED A, P52
   [Anonymous], 2015, NVIDIA DIGITS
   [Anonymous], 2019, HCI International 2019-Posters, DOI DOI 10.1007/978-3-030-23528-4_29
   [Anonymous], 2019, Keras
   [Anonymous], 2017, DEEP COGNITION
   [Anonymous], 2020, MAT DESIGN
   [Anonymous], 2020, NEURAL NETWORK CONSO
   Azure Machine Learning, 2019, MICROSOFT AZURE
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Blei DM, 2014, ANNU REV STAT APPL, V1, P203, DOI 10.1146/annurev-statistics-022513-115657
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   BOX GEP, 1976, J AM STAT ASSOC, V71, P791, DOI 10.2307/2286841
   Carter, 2016, TENSORFLOW NEURAL NE
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   ConvNetJS, 2016, DEEP LEARN YOUR BROW
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dietz S, 2014, COMPUT HUM BEHAV, V36, P163, DOI 10.1016/j.chb.2014.03.045
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Everett NM., 2018, INTUITIVE DESIGN 8 S
   Ghadai S, 2018, COMPUT AIDED GEOM D, V62, P263, DOI 10.1016/j.cagd.2018.03.024
   Harley AW, 2015, LECT NOTES COMPUT SC, V9474, P867, DOI 10.1007/978-3-319-27857-5_77
   Hernik J, 2018, INTED PROC, P508
   HIPS/Spearmint, 2020, HARV INT PROB SYST G
   Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266
   Kearnes S, 2016, J COMPUT AID MOL DES, V30, P595, DOI 10.1007/s10822-016-9938-8
   Keras.js, 2018, RUN KERAS MODELS BRO
   Kim YM, 2020, INT J HUM-COMPUT INT, V36, P893, DOI 10.1080/10447318.2019.1699746
   Kindermans P.-J., 2017, ARXIV170505598CSSTAT
   Kingma D. P., 2014, arXiv
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu Y, 2019, ARCH PATHOL LAB MED, V143, P859, DOI 10.5858/arpa.2018-0147-OA
   Lobe, 2019, DEEP LEARNING MADE S
   Ma B, 2017, MATH VIS, P185, DOI 10.1007/978-3-319-47024-5_11
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Meissler N, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P152, DOI 10.1109/AIVR46125.2019.00031
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Naumann A, 2007, LECT NOTES ARTIF INT, V4562, P128
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Neural network modeler, 2019, IBM WATS
   Obuchowski NA, 2004, ACAD RADIOL, V11, P980, DOI 10.1016/j.arca.2004.04.014
   Ounkomol C, 2018, NAT METHODS, V15, P917, DOI 10.1038/s41592-018-0111-2
   Reddy ND, 2019, PROC CVPR IEEE, P7318, DOI 10.1109/CVPR.2019.00750
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Springenberg J. T., 2015, ARXIV PREPRINT ARXIV
   Srensen T., 1948, K DANSKE VIDENSK SEL, V5, P1, DOI DOI 10.1234/12345678
   Um E, 2012, J EDUC PSYCHOL, V104, P485, DOI 10.1037/a0026609
   Vardhana M, 2018, COGN SYST RES, V50, P10, DOI 10.1016/j.cogsys.2018.03.005
   Veeling B., 2019, The patchcamelyon (PCam) deep learning classification benchmark
   Welling M, 2018, ARXIV180603962CSSTAT
   Xiao H., 2017, ARXIV170807747
   Yang Chengliang, 2018, AMIA Annu Symp Proc, V2018, P1571
   Zureick AH, 2018, ANAT SCI EDUC, V11, P366, DOI 10.1002/ase.1754
NR 54
TC 5
Z9 5
U1 2
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 159
EP 171
DI 10.1007/s10055-021-00550-1
EA JUN 2021
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000663269400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Joy, T
   Ugur, E
   Ayhan, I
AF Joy, Tugce
   Ugur, Emre
   Ayhan, Inci
TI Trick the body trick the mind: avatar representation affects the
   perception of available action possibilities in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Avatars; Affordance; Virtual hands
AB In immersive Virtual Reality (VR), your brain can trick you into believing that your virtual hands are your real hands. Manipulating the representation of the body, namely the avatar, is a potentially powerful tool for the design of innovative interactive systems in VR. In this study, we investigated interactive behavior in VR by using the methods of experimental psychology. Objects with handles are known to potentiate the afforded action. Participants tend to respond faster when the handle is on the same side as the responding hand in bi-manual speed response tasks. In the first experiment, we successfully replicated this affordance effect in a Virtual Reality (VR) setting. In the second experiment, we showed that the affordance effect was influenced by the avatar, which was manipulated by two different hand types: (1) hand models with full finger tracking that are able to grasp objects, and (2) capsule-shaped-fingerless-hand models that are not able to grasp objects. We found that less than 5 mins of adaptation to an avatar, significantly altered the affordance perception. Counter intuitively, action planning was significantly shorter with the hand model that is not able to grasp. Possibly, fewer action possibilities provided an advantage in processing time. The presence of a handle speeded up the initiation of the hand movement but slowed down the action completion because of ongoing action planning. The results were examined from a multidisciplinary perspective and the design implications for VR applications were discussed.
C1 [Joy, Tugce] Bogazici Univ, Cognit Sci MA Program, Istanbul, Turkey.
   [Ugur, Emre] Bogazici Univ, Comp Engn Dept, Istanbul, Turkey.
   [Ayhan, Inci] Bogazici Univ, Psychol Dept, Istanbul, Turkey.
C3 Bogazici University; Bogazici University; Bogazici University
RP Ayhan, I (corresponding author), Bogazici Univ, Psychol Dept, Istanbul, Turkey.
EM joytugce@gmail.com; inci.ayhan@boun.edu.tr
RI Ugur, Emre/A-6011-2017
OI Ugur, Emre/0000-0001-9597-2731
FU Teleporter Realities Inc.
FX We provide our thanks to Albert Ali Salah, Erhan Oztop and Esra Mungan
   for reading and providing comments to an earlier version of this
   manuscript. Also, we are grateful for the support of Teleporter
   Realities Inc. which provided the devices used in this study.
CR Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Aldhous J., 2017, P 31 INT BCS HUM COM, P1
   Ambrosecchia M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00283
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Berti A, 2000, J COGNITIVE NEUROSCI, V12, P415, DOI 10.1162/089892900562237
   Bhalla M, 1999, J EXP PSYCHOL HUMAN, V25, P1076, DOI 10.1037/0096-1523.25.4.1076
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bub DN, 2012, J EXP PSYCHOL GEN, V141, P502, DOI 10.1037/a0026748
   Canzoneri E, 2013, EXP BRAIN RES, V228, P25, DOI 10.1007/s00221-013-3532-2
   Cho D, 2010, J EXP PSYCHOL HUMAN, V36, P853, DOI 10.1037/a0019328
   Cisek P, 2001, BEHAV BRAIN SCI, V24, P36, DOI 10.1017/S0140525X0124391X
   Cisek P, 2005, NEURON, V45, P801, DOI 10.1016/j.neuron.2005.01.027
   Cisek P, 2007, PHILOS T R SOC B, V362, P1585, DOI 10.1098/rstb.2007.2054
   Costantini M, 2011, PSYCHON B REV, V18, P302, DOI 10.3758/s13423-011-0054-4
   Costantini M, 2010, EXP BRAIN RES, V207, P95, DOI 10.1007/s00221-010-2435-8
   Day B, 2019, J EXP PSYCHOL-APPL, V25, P1, DOI 10.1037/xap0000192
   Debarba HG, 2018, COMPUT GRAPH-UK, V76, P142, DOI 10.1016/j.cag.2018.09.001
   Ellis R, 2000, BRIT J PSYCHOL, V91, P451, DOI 10.1348/000712600161934
   Eves FF, 2014, PSYCHON B REV, V21, P71, DOI 10.3758/s13423-013-0463-7
   Farnè A, 2005, NEUROPSYCHOLOGIA, V43, P238, DOI 10.1016/j.neuropsychologia.2004.11.010
   Ferri F, 2011, NEUROPSYCHOLOGIA, V49, P3519, DOI 10.1016/j.neuropsychologia.2011.09.001
   FITTS PM, 1953, J EXP PSYCHOL, V46, P199, DOI 10.1037/h0062827
   Fizek S., 2011, 4 EMBODIMENT GENDER, P75
   Fleming J, 2002, VIS COGN, V9, P502, DOI 10.1080/13506280143000557
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Grefkes C, 2005, J ANAT, V207, P3, DOI 10.1111/j.1469-7580.2005.00426.x
   Handy TC, 2003, NAT NEUROSCI, V6, P421, DOI 10.1038/nn1031
   Harris LR, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00819
   Jamone L, 2018, IEEE T COGN DEV SYST, V10, P4, DOI 10.1109/TCDS.2016.2594134
   JEANNEROD M, 1995, TRENDS NEUROSCI, V18, P314, DOI 10.1016/0166-2236(95)93921-J
   KALASKA JF, 1995, CEREB CORTEX, V5, P410, DOI 10.1093/cercor/5.5.410
   Kalaska JF, 1996, CAN J PHYSIOL PHARM, V74, P483, DOI 10.1139/cjpp-74-4-483
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   KOSTOV K, 2017, THESIS, P18823
   Kostov K, 2015, COGN PROCESS, V16, pS287, DOI 10.1007/s10339-015-0708-7
   Lanier J., 2006, Homuncular flexibility
   Le Chénéchal M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P277
   Lee P.-W., 2015, Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, P73
   Lessard DA, 2009, PERCEPTION, V38, P1863, DOI 10.1068/p6509
   MARK LS, 1987, J MOTOR BEHAV, V19, P367
   Miura, 2016, P 8 INT C ADV MULT
   NOE Alva, 2006, Action in Perception
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Ren SG, 2013, 2013 IEEE WORKSHOP ON ROBOT VISION (WORV), P1, DOI 10.1109/WORV.2013.6521912
   Rizzolatti G, 1998, ELECTROEN CLIN NEURO, V106, P283, DOI 10.1016/S0013-4694(98)00022-4
   ROSENBAUM DA, 1980, J EXP PSYCHOL GEN, V109, P444, DOI 10.1037/0096-3445.109.4.444
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   Salmanowitz N, 2018, J LAW BIOSCI, V5, P174, DOI 10.1093/jlb/lsy005
   Serino A, 2007, PSYCHOL SCI, V18, P642, DOI 10.1111/j.1467-9280.2007.01952.x
   Sikstr?m E, 2014, P 9 AUD MOSTL A C IT, P1
   SIMON JR, 1969, J EXP PSYCHOL, V81, P174, DOI 10.1037/h0027448
   SIRIGU A, 1991, BRAIN, V114, P629, DOI 10.1093/brain/114.1.629
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Snyder LH, 2000, VISION RES, V40, P1433, DOI 10.1016/S0042-6989(00)00052-3
   Sposito A, 2012, NEUROPSYCHOLOGIA, V50, P2187, DOI 10.1016/j.neuropsychologia.2012.05.022
   Tipper SP, 2006, PSYCHON B REV, V13, P493, DOI 10.3758/BF03193875
   Tucker M, 2004, ACTA PSYCHOL, V116, P185, DOI 10.1016/j.actpsy.2004.01.004
   Tucker M, 1998, J EXP PSYCHOL HUMAN, V24, P830, DOI 10.1037/0096-1523.24.3.830
   Turvey M. T., 1992, Ecological Psychology, V4, P173, DOI 10.1207/s15326969eco0403_3
   Vainio L, 2008, COGNITION, V108, P444, DOI 10.1016/j.cognition.2008.03.007
   Vainio L, 2011, BRAIN COGNITION, V77, P382, DOI 10.1016/j.bandc.2011.09.007
   WARREN WH, 1984, J EXP PSYCHOL HUMAN, V10, P683, DOI 10.1037/0096-1523.10.5.683
   WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371
   Witt JK, 2005, J EXP PSYCHOL HUMAN, V31, P880, DOI 10.1037/0096-1523.31.5.880
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Yamani Y, 2016, FRONT INTEGR NEUROSC, V9, DOI 10.3389/fnint.2015.00074
   Yu AB, 2014, J EXP PSYCHOL HUMAN, V40, P1861, DOI 10.1037/a0037397
NR 70
TC 5
Z9 6
U1 4
U2 34
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 615
EP 629
DI 10.1007/s10055-021-00511-8
EA MAR 2021
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000633734700001
DA 2024-07-18
ER

PT J
AU Pedram, S
   Ogie, R
   Palmisano, S
   Farrelly, M
   Perez, P
AF Pedram, Shiva
   Ogie, Robert
   Palmisano, Stephen
   Farrelly, Matthew
   Perez, Pascal
TI Cost-benefit analysis of virtual reality-based training for emergency
   rescue workers: a socio-technical systems approach
SO VIRTUAL REALITY
LA English
DT Article
ID TECHNOLOGY INVESTMENT DECISIONS; SWOT ANALYSIS; MODEL; FIELD; OPERATORS;
   DESIGN
AB Virtual reality (VR) is widely recognised as a promising technology for training emergency first responders and other safety-critical workers. It is uniquely able to immerse trainees in extreme situations that are too risky or dangerous to be examined in traditional real-world safety training. Most organisations seeking to implement VR safety training often limit their decisions to financial and technological factors. However, in this paper, we argue that a socio-technical systems approach is required to better appreciate the social costs and benefits of VR training, which are important for a successful implementation. The paper also reports our own research on a real-world implementation of VR safety training for the Mine Rescue Brigades in New South Wales, Australia. The training-conducted in both fully immersive (360 VR) and non-immersive (Desktop VR) virtual reality-involved a search and rescue operation which was necessitated by an underground fire at the bottom of the transport drift in a coal mine. Following this training, the 368 trainees not only completed a post-training questionnaire, but also were interviewed, to assess their training experiences in the VR environment. The findings provide a comprehensive account of the social costs and benefits of adopting VR as a safety training tool. Overall, the trainees perceived the benefits to far outweigh the costs, with an overall high inclination to recommend the VR training to other colleagues. Desktop VR was found to be as fit for delivering successful training as the more immersive 360 VR. However, this Desktop VR generated considerably less motion sickness in trainees. These findings should help organisations and training providers decide on: (1) whether or not to invest in VR safety training solutions; (2) which type technology/method of delivery to use.
C1 [Pedram, Shiva; Ogie, Robert; Perez, Pascal] Univ Wollongong, Fac Engn & Informat Sci, Smart Infrastruct Facil, Wollongong, NSW, Australia.
   [Palmisano, Stephen] Univ Wollongong, Fac Social Sci, Sch Psychol, Wollongong, NSW, Australia.
   [Farrelly, Matthew] Coal Serv Pty Ltd, Mines Rescue, Sydney, NSW, Australia.
C3 University of Wollongong; University of Wollongong
RP Pedram, S (corresponding author), Univ Wollongong, Fac Engn & Informat Sci, Smart Infrastruct Facil, Wollongong, NSW, Australia.
EM spedram@uow.edu.au
RI Palmisano, Stephen/O-1553-2018
OI Palmisano, Stephen/0000-0002-9140-5681; Pedram,
   Shiva/0000-0002-5835-4093
FU Coal Services Health and Safety Trust
FX This project was funded by Coal Services Health and Safety Trust.
CR Appelbaum S. H., 1997, Management Decision, V35, P452, DOI 10.1108/00251749710173823
   Ausburn L., 2004, J IND TEACHER ED, V41, P33
   Backlund P, 2007, IEEE INT CONF INF VI, P899
   Bahaei SS, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON SYSTEM RELIABILITY AND SAFETY (ICSRS 2019), P275, DOI [10.1109/icsrs48664.2019.8987702, 10.1109/ICSRS48664.2019.8987702]
   Barbosa Mendes J., 2010, 2010 IEEE INT C VIRT, P18
   Bhoir S, 2015, AEI 2015: BIRTH AND LIFE OF THE INTEGRATED BUILDING, P457
   BLUMENFELD PC, 1992, J EDUC PSYCHOL, V84, P272, DOI 10.1037/0022-0663.84.3.272
   Bostrom RP., 1977, MIS Quarterly, V1, P11, DOI [10.2307/248710, DOI 10.2307/249019, DOI 10.2307/248710, 10.2307/249019]
   Caserman P, 2018, LECT NOTES COMPUT SC, V11243, P175, DOI 10.1007/978-3-030-02762-9_18
   Chakraborty PR, 2000, MINER RESOUR ENG, V9, P437, DOI 10.1142/S0950609800000378
   Checa D, 2020, VIRTUAL REAL-LONDON, V24, P151, DOI 10.1007/s10055-019-00389-7
   Chen C.J., 2004, J INTERACTIVE LEARNI, V15, P147
   Chittaro L, 2018, SAFETY SCI, V102, P159, DOI 10.1016/j.ssci.2017.10.012
   Cordeiro C, 2015, SYMP VIRTUAL AUGMENT, P142, DOI 10.1109/SVR.2015.28
   Da, 2010, 63 ANN ASS INT C INT
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Dishaw MT, 1999, INFORM MANAGE-AMSTER, V36, P9, DOI 10.1016/S0378-7206(98)00101-3
   Düking P, 2018, FRONT PHYSIOL, V9, DOI 10.3389/fphys.2018.00128
   Engelbrecht H, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00101
   Filigenzi M T, 2000, Appl Occup Environ Hyg, V15, P465
   Filigenzi MT, 1999, AM J IND MED, P116
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Gagliati A, 2011, VTT SYMP, V269, P20
   Gazit Elhanan., 2006, VIRTUAL REAL-LONDON, V10, P271, DOI DOI 10.1007/S10055-006-0053-3
   Graham C., 2006, The Handbook of Blended Learning, P1
   Gregoriades A, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS, VOL 1 (ICEIS), P456, DOI 10.5220/0005822204560463
   Hanson K, 2008, EDUC TECHNOL SOC, V11, P118
   Haque S, 2006, IEEE T INF TECHNOL B, V10, P51, DOI 10.1109/TITB.2005.855529
   Hatsushika D, 2018, OCEANS 2018 MTS/IEEE CHARLESTON
   Heaton L, 1998, J INF TECHNOL, V13, P259, DOI 10.1057/jit.1998.5
   Henderson JV, 2005, ST HEAL T, V111, P185
   Hoang RV, 2010, COMPUT GRAPH-UK, V34, P655, DOI 10.1016/j.cag.2010.09.014
   Hsu Edbert B, 2013, PLoS Curr, V5, DOI 10.1371/currents.dis.1ea2b2e71237d5337fa53982a38b2aff
   Juricic, 2015, OFFSH MED C EXH
   Kavanagh S., 2017, THEMES SCI TECHNOLOG, V10, P85, DOI [DOI 10.1109/ICWT47785.2019.8978263, DOI 10.1016/J.COMPEDU.2019.103778]
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kinateder M, 2014, ACSIS-ANN COMPUT SCI, V2, P313
   Kowalski-Trakofler KM, 2003, J SAFETY RES, V34, P515, DOI 10.1016/j.jsr.2003.05.004
   Krug S., 2000, DONT MAKE ME THINK
   Le, 2012, EUROPEAN NETWORK QUA
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lei LiZ., 2005, Virtual reality, P194, DOI [10.1007/s10055-004-0149-6, DOI 10.1007/S10055-004-0149-6]
   Li M, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/6243085
   Liu XW, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND COMPUTER SCIENCE, VOL 1, PROCEEDINGS, P343, DOI 10.1109/ITCS.2009.291
   Lloréns R, 2015, ARCH PHYS MED REHAB, V96, P418, DOI 10.1016/j.apmr.2014.10.019
   Longo F, 2019, COMPUT IND, V105, P99, DOI 10.1016/j.compind.2018.12.003
   Lucas H., 1990, INFORM SYSTEMS IMPLE
   Lucas J, 2008, J INF TECHNOL CONSTR, V13, P637
   Macy B.A., 1993, RES ORG CHANGE DEV, V7, P235
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Markus ML, 1996, MIS QUART, V20, P385, DOI 10.2307/249561
   McComas J, 2002, CYBERPSYCHOL BEHAV, V5, P185, DOI 10.1089/109493102760147150
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Morel M, 2015, NEUROPHYSIOL CLIN, V45, P315, DOI 10.1016/j.neucli.2015.09.007
   Paquette DL, 2000, OCEANS 2000 MTS/IEEE - WHERE MARINE SCIENCE AND TECHNOLOGY MEET, VOLS 1-3, CONFERENCE PROCEEDINGS, P733, DOI 10.1109/OCEANS.2000.881344
   PASMORE W, 1982, HUM RELAT, V35, P1179, DOI 10.1177/001872678203501207
   Patle DS, 2019, VIRTUAL REAL-LONDON, V23, P293, DOI 10.1007/s10055-018-0354-3
   Patton M.Q., 1997, EVAL PRACT, V18, P147
   Pedram, 2018, INT C APPL HUM FACTO, P404, DOI DOI 10.1007/978-3-319-94223-0_38
   Pedram S, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103891
   Riva G, 2019, INT S PERV COMP PERV, P43
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Ryan SD, 2002, J MANAGE INFORM SYST, V19, P85, DOI 10.1080/07421222.2002.11045725
   Ryan SD, 2000, J MANAGE INFORM SYST, V16, P11, DOI 10.1080/07421222.2000.11518264
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Schultze U, 2010, J INF TECHNOL-UK, V25, P434, DOI 10.1057/jit.2010.25
   Schwebel DC, 2016, ACCIDENT ANAL PREV, V86, P9, DOI 10.1016/j.aap.2015.10.002
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Simon SC, 2019, COMPUT HUM BEHAV, V93, P141, DOI 10.1016/j.chb.2018.12.018
   Squelch AP, 2001, J S AFR I MIN METALL, V101, P209
   Stansfield S, 1997, P SOC PHOTO-OPT INS, V2933, P93, DOI 10.1117/12.263137
   Sutherland I.E., 1965, The Ultimate Display, P506, DOI DOI 10.1109/MC.2005.274
   Tanaka E. H., 2015, USING IMMERSIVE VIRT
   Thomson JA, 2005, J EXP PSYCHOL-APPL, V11, P175, DOI 10.1037/1076-898X.11.3.175
   Tichon J., 2011, J HLTH SAFETY RES PR, V3, P33
   Van Wyk E., 2009, P 6 INT C COMP GRAPH, P53, DOI DOI 10.1145/1503454.1503465
   Vincent DS, 2008, ACAD EMERG MED, V15, P1160, DOI 10.1111/j.1553-2712.2008.00191.x
   Walton R.E., 1989, RUNNING INTEGRATING
   Yang, 2012, VIRTUAL REALITY ITS, DOI 10.1007/978-3-642-31968-6_25
   Zhao D, 2015, SAFETY SCI, V77, P143, DOI 10.1016/j.ssci.2015.04.001
   Zhou B., 2011, J NAT DISS, V5, P008
   Zou BW, 2018, INTL CONF POWER SYST, P4806, DOI 10.1109/POWERCON.2018.8602224
NR 83
TC 13
Z9 14
U1 8
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1071
EP 1086
DI 10.1007/s10055-021-00514-5
EA MAR 2021
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000632276700001
DA 2024-07-18
ER

PT J
AU Cao, LZ
   Peng, C
   Dong, YZ
AF Cao, Lizhou
   Peng, Chao
   Dong, Yangzi
TI Ellic's Exercise Class: promoting physical activities during exergaming
   with immersive virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Exergaming; Virtual reality; Entertainment computing; Human-computer
   interaction
ID ACTIVE VIDEO GAMES; CHILDREN; REHABILITATION; TECHNOLOGY; PLAY
AB This work presents the design and evaluation of a set of three mini exercise games(exergames), called "Ellic's Exercise Class," which allows people to play in virtual reality (VR) using a head-mounted display (HMD) with the intention to promote physical activities. The exergames require the player to move hands, arms, and body to interact with sporting gameplay events. The game design methodology considers both display advantages and physical limitations in VR technologies. The games are evaluated in a usability study with the goal to understand participants' performance, gaming experience, effectiveness in motivating them to move, and their exercise intensity levels. In the study, we compare play of games in a VR environment simulated through an HMD with the play in front of a standard large flat-screen display (LFD), while ensuring the difficulty level of gameplay to be same in both. The participants' moving distances and their answers in questionnaires show that they become more active and engaged when playing exergames with HMD, but according to heart rate data, there is not significant evidence that playing with HMD would be better than that with LFD in terms of increasing the energy expenditure. We discuss the findings in accordance with the relationship and independence between engagement and exertion in exergaming.
C1 [Cao, Lizhou; Peng, Chao; Dong, Yangzi] Rochester Inst Technol, Golisano Coll Comp & Informat Sci, Sch Interact Games & Media, Rochester, NY 14623 USA.
C3 Rochester Institute of Technology
RP Peng, C (corresponding author), Rochester Inst Technol, Golisano Coll Comp & Informat Sci, Sch Interact Games & Media, Rochester, NY 14623 USA.
EM lc1248@rit.edu; cxpigm@rit.edu; yd8608@rit.edu
OI Peng, Chao/0000-0001-8838-2469
CR ALEX M, 2017, 2017 INT C IM VIS CO, P1, DOI DOI 10.1109/IVCNZ.2017.8402480
   Altamimi R., 2012, Journal of Computer and Information Technology, V1, P20, DOI 10.1371/journal.pone.0065351
   Amresh A, 2017, P 50 HAW INT C SYST
   [Anonymous], 2013, P 1 INT C GAM DES RE, DOI DOI 10.1145/2583008.25830
   Barathi SC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173982
   Better Health Channel, 2015, BETTER HLTH CHANNEL
   Bianchi-Berthouze N, 2007, LECT NOTES COMPUT SC, V4738, P102
   Biddiss E, 2010, ARCH PEDIAT ADOL MED, V164, P664, DOI 10.1001/archpediatrics.2010.104
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   CAO LZ, 2019, INFORM MULTIDISCIPLI, V6, DOI DOI 10.3390/INFORMATICS6040044
   Castañer M, 2016, INT J HUM-COMPUT ST, V96, P67, DOI 10.1016/j.ijhcs.2016.07.007
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [DOI 10.1145/2181037.2181040, 10.1145/2181037.2181040]
   Eckert M, 2017, LECT N BIOINFORMAT, V10209, P434, DOI 10.1007/978-3-319-56154-7_39
   Finke M., 2008, Proceedings of the 3rd International Conference on Digital Interactive Media in Entertainment and Arts, P26, DOI DOI 10.1145/1413634.1413644
   Finkelstein S, 2013, 2013 1ST WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P11, DOI 10.1109/VAAT.2013.6786186
   Finkelstein S, 2011, PRESENCE-TELEOP VIRT, V20, P78, DOI 10.1162/pres_a_00036
   Freina L, 2015, PROC EUR CONF GAME, P195
   Gao Y, 2011, LECT NOTES COMPUT SC, V6972, P35, DOI 10.1007/978-3-642-24500-8_5
   GILL DL, 1988, RES Q EXERCISE SPORT, V59, P191, DOI 10.1080/02701367.1988.10605504
   Graf DL, 2009, PEDIATRICS, V124, P534, DOI 10.1542/peds.2008-2851
   Hansberger JT, 2017, LECT NOTES COMPUT SC, V10280, P505, DOI 10.1007/978-3-319-57987-0_41
   IJsselsteijn Wijnand A, 2013, The Game Experience Questionnaire
   Jessup Schneider Adrian L., 2015, 2015 IEEE Games Entertainment Media Conference (GEM), P1, DOI 10.1109/GEM.2015.7377222
   Kessler GD, 2000, PRESENCE-TELEOP VIRT, V9, P187, DOI 10.1162/105474600566718
   Kim KJ, 2013, CYBERPSYCH BEH SOC N, V16, P329, DOI 10.1089/cyber.2012.0500
   Krause JM, 2014, J PHYS EDUC RECREAT, V85, P15, DOI 10.1080/07303084.2014.884428
   Lange B, 2012, DISABIL REHABIL, V34, P1863, DOI 10.3109/09638288.2012.670029
   Larsen CR., 2009, Bmj, V338, pb1802, DOI DOI 10.1136/BMJ.B1802
   Law ELC, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P257, DOI 10.1145/3242671.3242683
   Lee Y, 2017, DIS'17 COMPANION: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P138, DOI 10.1145/3064857.3079134
   Lin T, 2006, LECT NOTES COMPUT SC, V4073, P257
   Lopez M. B, 2012, P 2012 IEEE COMP SOC, P27
   Lyons EJ, 2015, GAMES HEALTH J, V4, P12, DOI 10.1089/g4h.2014.0072
   Lyons Elizabeth J, 2012, J Diabetes Sci Technol, V6, P839
   Lyons EJ, 2011, MED SCI SPORT EXER, V43, P1987, DOI 10.1249/MSS.0b013e318216ebf3
   McMahan R.P., 2006, Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P108, DOI DOI 10.1145/1180495.1180518
   Mestre DR., 2017, Electronic Imaging, V29, P31, DOI DOI 10.2352/ISSN.2470-1173.2017.3.ERVR-094
   Molina KI, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-156
   MOLINACARMONA R, 2020, INFORM MULTIDISCIPLI, V7, DOI DOI 10.3390/INFORMATICS7020020
   Moss JD, 2011, HUM FACTORS, V53, P308, DOI 10.1177/0018720811405196
   Mueller F, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2191, DOI 10.1145/2556288.2557163
   Nickel A, 2012, MEANINGFUL PLAY 2012
   Nickel A, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P161, DOI 10.1109/VR.2012.6180931
   Nunes de Vasconcelos G, 2019, DO WE STILL NEED CAV
   Olk B, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.172331
   Paw MJMCA, 2008, J SCI MED SPORT, V11, P163, DOI 10.1016/j.jsams.2007.06.001
   Peng C, 2017, ENTERTAIN COMPUT, V19, P53, DOI 10.1016/j.entcom.2016.12.001
   Piskorz J., 2014, POL PSYCHOL BULL, V45, P480
   Poels K., 2007, Game Experience Questionnaire: Development of A Self-report Measure to Assess the Psychological Impact of Digital Games
   Rank17, 2017, VR BASEBALL
   Rice M., 2011, P 2011 ACM SIGGRAPH, P17, DOI [10.1145/2018556.2018560, DOI 10.1145/2018556.2018560]
   Sabet S.S., 2019, Proceedings of the 11th ACM Workshop on Immersive Mixed and Virtual Environment Systems, P22
   Saposnik G, 2010, STROKE, V41, P1477, DOI 10.1161/STROKEAHA.110.584979
   Schell J., 2019, Tenth Anniversary: The Art of Game Design, DOI DOI 10.1201/B22101
   Shaw L. A., 2015, C RES PRACTICE INORM, V162, P61
   Shaw LA, 2015, P 8 AUSTR WORKSH HLT
   Shin JH, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-32
   Skjæret-Maroni N, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00964
   SOUTHARD DA, 1995, J ELECTRON IMAGING, V4, P413, DOI 10.1117/12.217267
   Stach T., 2009, Proceedings of the International Conference on Advances in Computer Entertainment Technology, P379
   Sun TL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069471
   Tanaka Y, 2016, 2016 IEEE 9TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA), P1, DOI 10.1109/IWCIA.2016.7805739
   Tece Bayrak A, 2020, P 53 HAW INT C SYST
   Treleaven J, 2015, VIRTUAL REAL-LONDON, V19, P267, DOI 10.1007/s10055-015-0266-4
   Wu H, 2016, SIGGRAPH ASIA 2016 V, DOI [10.1145/2996376.2996386, DOI 10.1145/2996376.2996386]
   Xie B, 2018, IEEE T VIS COMPUT GR, V24, P1661, DOI 10.1109/TVCG.2018.2793618
   Yoo S, 2017, ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P431, DOI 10.1145/3099023.3099115
   Yoo S, 2017, PROCEEDINGS OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P247, DOI 10.1145/3079628.3079679
   Yoo S, 2016, PROCEEDINGS OF THE 28TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2016), DOI 10.1145/3010915.3010987
   Yoo Soojeong, 2017, P 2017 CHI C HUM FAC, P3050, DOI [10.1145/3027063.3053203, DOI 10.1145/3027063.3053203, 10.1145/3027063, DOI 10.1145/3027063]
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 72
TC 16
Z9 17
U1 6
U2 35
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 597
EP 612
DI 10.1007/s10055-020-00477-z
EA OCT 2020
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000577951900001
DA 2024-07-18
ER

PT J
AU Pastel, S
   Chen, CH
   Martin, L
   Naujoks, M
   Petri, K
   Witte, K
AF Pastel, Stefan
   Chen, Chien-Hsi
   Martin, Luca
   Naujoks, Mats
   Petri, Katharina
   Witte, Kerstin
TI Comparison of gaze accuracy and precision in real-world and virtual
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Eye-tracking; Virtual reality; Gaze behavior; Head-mounted display;
   Accuracy; Precision
ID EYE-TRACKING DATA; FIXATION
AB Virtual reality (VR) is popular across many fields and is increasingly used in sports as a training tool. The reason, therefore, is recently improved display technologies, more powerful computation capacity, and lower costs of head-mounted displays for VR. As in the real-world (R), visual effects are the most important stimulus provided by VR. However, it has not been demonstrated whether the gaze behavior would achieve the same level in VR as in R. This information will be important for the development of applications or software in VR. Therefore, several tasks were designed to analyze the gaze accuracy and gaze precision using eye-tracking devices in R and VR. 21 participants conducted three eye-movement tasks in sequence: gaze at static targets, tracking a moving target, and gaze at targets at different distances. To analyze the data, an averaged distance with root mean square was calculated between the coordinates of each target and the recorded gaze points for each task. In gaze accuracy, the results showed no significant differences between R and VR in gaze at static targets (1 m distance, p > 0.05) and small significant differences at targets placed at different distances (p < 0.05), as well as large differences in tracking the moving target (p < 0.05). The precision in VR is significantly worse compared to R in all tasks with static gaze targets (p < 0.05). On the whole, this study gives a first insight into comparing foveal vision, especially gaze accuracy and precision between R and VR, and can, therefore, serve as a reference for the development of VR applications in the future.
C1 [Pastel, Stefan; Chen, Chien-Hsi; Martin, Luca; Naujoks, Mats; Petri, Katharina; Witte, Kerstin] Otto Von Guericke Univ, Inst Sports Sci 3, Dept Sports Engn & Movement Sci, Magdeburg, Germany.
C3 Otto von Guericke University
RP Pastel, S (corresponding author), Otto Von Guericke Univ, Inst Sports Sci 3, Dept Sports Engn & Movement Sci, Magdeburg, Germany.
EM stefan.pastel@ovgu.de
OI Pastel, Stefan/0000-0002-3662-2683
FU Projekt DEAL; German Research Foundation (DFG) [WI 1456/22-1]
FX Open Access funding provided by Projekt DEAL. The project was financed
   by the German Research Foundation (DFG) under Grant WI 1456/22-1.
CR [Anonymous], 2005, ACM Transactions on Applied Perception, DOI [DOI 10.1145/1077399.1077403, DOI 10.1145/1077399.10774032,3,9]
   Blignaut P, 2014, BEHAV RES METHODS, V46, P67, DOI 10.3758/s13428-013-0343-0
   Blignaut P, 2009, ATTEN PERCEPT PSYCHO, V71, P881, DOI 10.3758/APP.71.4.881
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   Clemotte A., 2014, P 2 INT C NEUR EL IN, P111
   Dalrymple KA, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00803
   Dorner R, 2013, VIRTUAL AUGMENTED RE, V48
   Drewes J., 2011, J VISION, V11, P494, DOI DOI 10.1167/11.11.494
   Düking P, 2018, FRONT PHYSIOL, V9, DOI 10.3389/fphys.2018.00128
   Duque G, 2013, CLIN INTERV AGING, V8, P257, DOI 10.2147/CIA.S41453
   Feit AM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1118, DOI 10.1145/3025453.3025599
   Gibaldi A, 2017, BEHAV RES METHODS, V49, P923, DOI 10.3758/s13428-016-0762-9
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Holmqvist K., 2012, P S EYE TRACK RES AP, P45, DOI [DOI 10.1145/2168556.2168563, 10.1145/2168556.2168563]
   Holmqvist K., 2015, EYE TRACKING COMPREH
   Hooge ITC, 2018, BEHAV RES METHODS, DOI [10.3758/s13428-0181135-3, DOI 10.3758/S13428-0181135-3]
   Hornof AJ, 2002, BEHAV RES METH INS C, V34, P592, DOI 10.3758/BF03195487
   Kenneth HolmqvistMarcus Nystrom., 2011, Eye Tracking: A Comprehensive Guide to Methods and Measures
   Kredel R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01845
   Krokos E, 2019, VIRTUAL REAL-LONDON, V23, P1, DOI 10.1007/s10055-018-0346-3
   Loomis JM, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P21
   Molina KI, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-156
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Nyström M, 2013, BEHAV RES METHODS, V45, P272, DOI 10.3758/s13428-012-0247-4
   Nyström M, 2010, BEHAV RES METHODS, V42, P188, DOI 10.3758/BRM.42.1.188
   Ooms K, 2015, J EYE MOVEMENT RES, V8, DOI 10.16910/jemr.8.1.5
   Petri K., 2018, International Journal of Computer Science in Sport, V17, P1, DOI 10.2478/ijcss-2018-0001
   Petri K., 2018, BIOMED J SCI TECH RE, V1, P5699, DOI DOI 10.26717/BJSTR.2018.07.001453
   Petri K, 2019, SPORTS ENG, V22, DOI 10.1007/s12283-019-0299-0
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Reichert E, 2019, THESIS
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rose FD, 2005, CYBERPSYCHOL BEHAV, V8, P241, DOI 10.1089/cpb.2005.8.241
   SensoMotoric Instruments, 2016, IVIEWETG US GUID VER
   Tirp J., 2015, Psychol Test Assess Model, V57, P57, DOI DOI 10.3389/FPSYG.2017.02183
   Vater C, 2017, CURR ISSUES SPORT SC, DOI [10.15203/CIS_2017.010, DOI 10.15203/CIS_2017.010]
   [No title captured]
NR 37
TC 21
Z9 22
U1 4
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 175
EP 189
DI 10.1007/s10055-020-00449-3
EA JUN 2020
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000537634800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Varga, MN
   Merrison-Hort, R
   Watson, P
   Borisyuk, R
   Livingstone, D
AF Varga, Marius N.
   Merrison-Hort, Robert
   Watson, Paul
   Borisyuk, Roman
   Livingstone, Dan
TI Tadpole VR: virtual reality visualization of a simulated tadpole spinal
   cord
SO VIRTUAL REALITY
LA English
DT Article
DE Data visualization; Neuroscience; Virtual reality; Visualization;
   Scientific visualization; Immersive
ID STEREOPSIS
AB Recent advances in "developmental" approach (combining experimental study with computational modeling) of neural networks produce increasingly large data sets, in both complexity and size. This poses a significant challenge in analyzing, visualizing and understanding not only the spatial structure but also the behavior of such networks. This paper describes a virtual reality application for visualization of two biologically accurate computational models that model the anatomical structure of a neural network comprised of 1500 neurons and over 80,000 connections. The visualization enables a user to observe the complex spatiotemporal interplay between seven unique types of neurons culminating in an observable swimming pattern. We present a detailed description of the design approach for the virtual environment, based on a set of initial requirements, followed up by the implementation and optimization steps. Lastly, the results of a pilot usability study are being presented on how confident participants are in their ability to understand how the alternating firing pattern between the two sides of the tadpole's body generates swimming motion.
C1 [Varga, Marius N.; Merrison-Hort, Robert; Watson, Paul; Livingstone, Dan] Univ Plymouth, Sch Comp & Math, Plymouth PL4 8AA, Devon, England.
   [Borisyuk, Roman] Univ Exeter, Coll Engn Math & Phys Sci, Harrison Bldg,Streatham Campus,North Pk Rd, Exeter EX4 4QF, Devon, England.
   [Borisyuk, Roman] Russian Acad Sci, Branch Keldysh Inst Appl Math, Inst Math Problems Biol, Pushchino 142290, Russia.
C3 University of Plymouth; University of Exeter; Russian Academy of
   Sciences; Pushchino Scientific Center for Biological Research (PSCBI) of
   the Russian Academy of Sciences
RP Varga, MN (corresponding author), Univ Plymouth, Sch Comp & Math, Plymouth PL4 8AA, Devon, England.
EM marius.varga@plymouth.ac.uk; robert.merrison@postgrad.plymouth.ac.uk;
   paul.watson-1@plymouth.ac.uk; r.m.borisyuk@exeter.ac.uk;
   D.Livingstone@plymouth.ac.uk
OI Varga, Marius N./0000-0001-7655-9829; Merrison-Hort,
   Robert/0000-0001-8215-7527; Watson, Paul WL/0000-0003-2797-0026;
   Livingstone, Dan/0000-0001-8211-886X
FU BBSRC [BB/L000814/1, BB/T002352/1] Funding Source: UKRI
CR [Anonymous], 2012, 2012 IEEE C HIGH PER
   Arsiwalla XD, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00002
   Borisyuk R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089461
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Bruckner S, 2009, IEEE T VIS COMPUT GR, V15, P1497, DOI 10.1109/TVCG.2009.121
   Bryson S., 1995, VIRTUAL REALITY APPL, P3
   Davis O, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13804-3
   DOSHER BA, 1986, VISION RES, V26, P973, DOI 10.1016/0042-6989(86)90154-9
   Esmaeili H., 2016, 2016 22 INT C VIRTUA, P1, DOI [10.1109/vsmm.2016.7863153, DOI 10.1109/VSMM.2016.7863147]
   Ferrario A, 2018, ELIFE, V7, DOI 10.7554/eLife.33281
   Fielder AR, 1996, EYE, V10, P233, DOI 10.1038/eye.1996.51
   Kasabov N, 2016, NEURAL NETWORKS, V78, P1, DOI 10.1016/j.neunet.2015.09.011
   Kolasinski EM, 1995, TECHNICAL REPORT
   Lee SY, 2003, PROC SPIE, V4756, P38, DOI 10.1117/12.497665
   Lin CY, 2011, IEEE PAC VIS SYMP, P35, DOI 10.1109/PACIFICVIS.2011.5742370
   Marder E, 2015, CURR OPIN NEUROBIOL, V31, P156, DOI 10.1016/j.conb.2014.10.012
   Marks S., 2014, Proceedings of the 29th International Conference on Image and Vision Computing New Zealand, P42, DOI [10.1145/2683405.2683424, DOI 10.1145/2683405.2683424]
   Marks S, 2017, EVOL SYST-GER, V8, P193, DOI 10.1007/s12530-016-9170-8
   McIntire JP, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P1, DOI 10.1109/3DVis.2014.7160093
   McIntire JP, 2014, DISPLAYS, V35, P18, DOI 10.1016/j.displa.2013.10.004
   Mora A, 2015, 2015 WORKSHOP ON RESEARCH, EDUCATION AND DEVELOPMENT OF UNMANNED AERIAL SYSTEMS (RED-UAS), P1, DOI 10.1109/RED-UAS.2015.7440984
   NEMIRE K, 1994, HUM FACTORS, V36, P79, DOI 10.1177/001872089403600105
   Roberts A, 2014, J NEUROSCI, V34, P608, DOI 10.1523/JNEUROSCI.3248-13.2014
   Roberts A, 2010, FRONT BEHAV NEUROSCI, V4, DOI 10.3389/fnbeh.2010.00016
   Sherif T, 2015, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00089
   VISHTON PM, 1995, J EXP PSYCHOL HUMAN, V21, P978, DOI 10.1037/0096-1523.21.5.978
   Von Kapri A, 2011, STUD HEALTH TECHNOL, V163, P685, DOI 10.3233/978-1-60750-706-2-685
   Ware C, 2012, INFORM VISUALIZATION, P280
   Ware C, 2012, INFORM VISUALIZATION, P358
   Ware C, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279640.1279642
   Xia MR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068910
   Yao R, 2015, OCULUS BEST PRACTICE
NR 32
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 1
EP 17
DI 10.1007/s10055-020-00431-z
EA MAR 2020
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000564413900001
DA 2024-07-18
ER

PT J
AU Checa, D
   Bustillo, A
AF Checa, David
   Bustillo, Andres
TI Advantages and limits of virtual reality in learning processes:
   Briviesca in the fifteenth century
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Learning; Immersive environments; Active learning;
   Presence; Game engine; Cultural heritage; Oculus Rift
AB Two teaching methodologies are presented and compared in this study: on the one hand, semi-guided tours in immersive virtual reality and, on the other, viewing video renderings of 3D environments. The two techniques are contrasted through 3D modeling of a fifteenth-century Spanish town called Briviesca, in an immersive environment, viewed with Oculus Rift. The suitability of virtual reality for teaching is assessed through questions on historical knowledge and urban layout. The understanding of the undergraduate students is evaluated, through questionnaires, after the viewing sessions. The responses of the students underline the effectiveness of the two methodologies: Video screenings received higher scores for historical ideas and the virtual tour was the most effective method at conveying knowledge learnt while viewing. Additionally, two user movements for controlling the virtual reality environment were tested: (1) gamepad locomotion and (2) roomscale movements combined with teleporting. The clear advantage of the second option was the total lack of motion sickness effects. However, the natural tendency using teleporting was to move very quickly through the city areas with no singular buildings and to spend more time in front of these types of buildings. They therefore missed visual information related to the first areas while retaining more information related to those buildings. Finally, the spatial location of singular buildings was clearly better acquired with the virtual tour.
C1 [Checa, David; Bustillo, Andres] Univ Burgos, Dept Civil Engn, Burgos, Spain.
C3 Universidad de Burgos
RP Bustillo, A (corresponding author), Univ Burgos, Dept Civil Engn, Burgos, Spain.
EM abustillo@ubu.es
RI Bustillo, Andres/I-1403-2015; Checa Cruz, David/J-2839-2017
OI Bustillo, Andres/0000-0003-2855-7532; Checa Cruz,
   David/0000-0001-6623-3614
FU NVIDIA Corporation
FX We gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan Xp GPU used for this research and Mario Alaguero
   for his work on the 3D models.
CR Alaguero M, 2015, CAA2014 21 CENTURY A, P575
   Alaguero M, 2015, BRIVIESCA SIGLO 14 S
   Alhalabi WS, 2016, BEHAV INFORM TECHNOL, V35, P919, DOI 10.1080/0144929X.2016.1212931
   Andreoli R., 2016, EUROMED 2016, P814, DOI DOI 10.1007/978-3-319-48496-965
   Bustillo A., 2015, Digit. Appl. Archaeol. Cult. Herit., V2, P248, DOI [10.1016/j.daach.2015.11.002, DOI 10.1016/J.DAACH.2015.11.002]
   Carrozzino M, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS & INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION & STANDARDS DIGITAL HERITAGE PROJECTS & APPLICATIONS, P187, DOI 10.1109/DigitalHeritage.2015.7419486
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Champion EM, 2008, INT J HERIT STUD, V14, P210, DOI 10.1080/13527250801953686
   Checa D, 2016, LECT NOTES COMPUT SC, V9769, P126, DOI 10.1007/978-3-319-40651-0_11
   Chen G, 2018, ART DES COMMUN HIGH, V17, P51, DOI 10.1386/adch.17.1.51_1
   Chen SN, 2013, MULTIMED TOOLS APPL, V62, P633, DOI 10.1007/s11042-011-0864-4
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Cohen J., 1988, STAT POWER ANAL BEHA
   De Paolis LT, 2013, LECT NOTES COMPUT SC, V7971, P632, DOI 10.1007/978-3-642-39637-3_50
   Debailleux L, 2018, LECT NOTES COMPUT SC, V10605, P289, DOI 10.1007/978-3-319-75826-8_24
   Delgado AR, 1996, MEM COGNITION, V24, P504, DOI 10.3758/BF03200938
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Hupont I, 2015, INT WORK QUAL MULTIM
   Kiourt Chairi., 2018, International Journal of Computational Methods in Heritage Science, V2, P23, DOI DOI 10.4018/IJCMHS.2018010103
   Lee EAL, 2010, LECT NOTES COMPUT SC, V6250, P79, DOI 10.1007/978-3-642-14484-4_8
   Loizides F, 2014, LECT NOTES COMPUT SC, V8740, P572, DOI 10.1007/978-3-319-13695-0_57
   Lucet G, 2009, COMM COM INF SC, V24, P1, DOI 10.1007/978-3-642-10226-4_1
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Muller N, 2017, INT CONF GAMES VIRTU, P55, DOI 10.1109/VS-GAMES.2017.8055811
   Passig D, 2016, COMPUT EDUC, V95, P296, DOI 10.1016/j.compedu.2016.01.009
   Polcar J., 2015, MM Science Journal, P613, DOI [DOI 10.17973/MMSJ.2015_06_201516, 10.17973/MMSJ.2015_06_201516]
   Remondino F, 2017, INT ARCH PHOTOGRAMM, V42-2, P591, DOI 10.5194/isprs-archives-XLII-2-W5-591-2017
   Roussou M, 2020, IEEE T EMERG TOP COM, V8, P233, DOI 10.1109/TETC.2017.2737983
   Webster R, 2016, INTERACT LEARN ENVIR, V24, P1319, DOI 10.1080/10494820.2014.994533
NR 29
TC 47
Z9 50
U1 2
U2 33
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 151
EP 161
DI 10.1007/s10055-019-00389-7
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800010
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Jain, P
   Bhavsar, R
   Shaik, K
   Kumar, A
   Pawar, BV
   Darbari, H
   Bhavsar, VC
AF Jain, Priyanka
   Bhavsar, Ram
   Shaik, Karimullah
   Kumar, Ajai
   Pawar, B. V.
   Darbari, Hemant
   Bhavsar, Virendrakumar C.
TI Virtual reality: an aid as cognitive learning environment-a case study
   of Hindi language
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Visual cognition; Cognitive learning; WebVR; Artificial
   intelligence; Natural language processing; Automatic text visualization
ID CONTEXT
AB The objective of this research is to propose a dynamic composition of behaviour-rich interactive 3D scene as a virtual environment for cognitive support using visual and linguistic analytics. Based on the constructivist theory of learning through visual cognition by Winn (A conceptual basis for educational applications of virtual reality, Technical report TR 93-9, Washington Technology University, 1993), we propose our work with a grounding that visual data are easy to comprehend for a person having linguistic learning difficulties. Virtual reality provides an environment for learners to actively pursue their knowledge needs by applying their theories in the 'real world'. Therefore, we focus our work on generating an interactive virtual environment. It decreases cognitive load for the person with difficulties in comprehension, especially in language reading, e.g. dyslexia. Our prior work related to the proposed research is named as Preksha-an automatic Hindi text visualizer. To the best of the knowledge of the authors, Preksha is the only known visualization work for an Indian Language, viz. Hindi. Belonging to morphologically-rich and free-word order Indian languages, this work on the Hindi Language is a novel interdisciplinary approach to develop a virtual environment for cognitive support. Application of an automatic text visualization with a suitable learning paradigm in a virtual environment is another novelty of this research.
C1 [Jain, Priyanka; Shaik, Karimullah; Kumar, Ajai; Darbari, Hemant] Ctr Dev Adv Comp, Pune, Maharashtra, India.
   [Bhavsar, Ram; Pawar, B. V.] KBC North Maharashtra Univ, Jalgaon, Maharashtra, India.
   [Bhavsar, Virendrakumar C.] Univ New Brunswick, Fac Comp Sci, Fredericton, NB, Canada.
C3 Centre for Development of Advanced Computing (C-DAC); Kavayitri
   Bahinabai Chaudhari North Maharashtra University, Jalgaon; University of
   New Brunswick
RP Jain, P (corresponding author), Ctr Dev Adv Comp, Pune, Maharashtra, India.
EM priyankaj@cdac.in
RI Pawar, Bhausaheb/AAR-5622-2021
OI Bhavsar, Ramchandra/0000-0003-4759-0303
CR Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   BEAUCHAMP GR, 1987, PEDIATR CLIN N AM, V34, P1439
   Daghestani L., 2012, COMP IT, V1, P31, DOI [10.4197/Comp1-1.2, DOI 10.4197/COMP1-1.2]
   EARLEY J, 1970, COMMUN ACM, V13, P94, DOI 10.1145/362007.362035
   Funge J, 1999, COMP GRAPH, P29, DOI 10.1145/311535.311538
   Gaddis T., 1998, Virtual reality in the school. Virtual reality and Education laboratory
   Guerra G, 2007, COMPUTER, V40, P42, DOI 10.1109/MC.2007.154
   Gupta A, 2009, THESIS
   Jain P., 2016, INT J MODERN COMPUTE, V4, P66
   Jain P, 2019, P INT C COMM INF PRO
   Jain P., 2018, Int. J. Comput. Appl., V2, P1797
   Jain P, 2017, P NAT C ADV COMP NCA
   Jain P, 2018, 3 INT C WORK RECENT, P1, DOI [10.1109/ICRAIE.2018.8710412, DOI 10.1109/ICRAIE.2018.8710412]
   Jain P, 2017, 2017 2ND INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), P132, DOI 10.1109/I2CT.2017.8226108
   Jain P, 2017, 2017 2ND INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), P110, DOI 10.1109/I2CT.2017.8226104
   Jain P, 2014, INT CONF COMM SYST, P886, DOI 10.1109/CSNT.2014.183
   Jose N, 2015, IEEE INT NEW CIRC
   JOSHI AK, 1975, J COMPUT SYST SCI, V10, P136, DOI 10.1016/S0022-0000(75)80019-5
   Keene EO, 2004, MOSAIC THOUGHT TEACH
   Lerman K, 2013, 2013 INTERNATIONAL CONFERENCE ON SOCIAL INTELLIGENCE AND TECHNOLOGY (SOCIETY), P80, DOI 10.1109/SOCIETY.2013.11
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   Majoy P, 1993, ZEPHER PRESS LEARNIN
   Mayer R. E., 2020, Multimedia Learning, V3rd
   Mnguni LE, 2014, SPRINGERPLUS, V3, DOI 10.1186/2193-1801-3-184
   Myreddi V., 1998, FUNCTIONAL ACAD STUD
   Pellegrino J.W., 1984, EDUC PSYCHOL-US, V19, P239, DOI DOI 10.1080/004615284095
   Rabinovitch JS, 1992, WHAT YOU SEE IS WHAT, p11/21
   Riva G, 2000, TELEMED J E-HEALTH, V6, P327, DOI 10.1089/153056200750040183
   ROUSSOU M, 2004, COMPUT ENTERTAIN, V2, DOI [10.1145/973801.973818, DOI 10.1145/973801.973818]
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711
   Schank RC, 2000, CYBERPSYCHOL BEHAV, V3, P9, DOI 10.1089/109493100316184
   Schnotz W, 2005, ETR&D-EDUC TECH RES, V53, P47, DOI 10.1007/BF02504797
   Singhal S., 1999, Networked Virtual Environments
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Wang Y, 2006, P CAN C EL COMP ENG, P1727, DOI [10.1109/ccece.2006.277686, DOI 10.1109/CCECE.2006.277686]
   Winn W, 1993, TR939 WASH TECHN U
   Wiriyathammabhum P, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3009906
   Yun RW, 2006, LECT NOTES COMPUT SC, V4181, P146
   Zhao R., 2002, DISTRIBUTED MULTIMED, P14
NR 39
TC 4
Z9 4
U1 7
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 771
EP 781
DI 10.1007/s10055-020-00426-w
EA FEB 2020
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000520050500001
DA 2024-07-18
ER

PT J
AU Shen, CW
   Ho, JT
   Ly, PTM
   Kuo, TC
AF Shen, Chien-wen
   Ho, Jung-tsung
   Pham Thi Minh Ly
   Kuo, Ting-chang
TI Behavioural intentions of using virtual reality in learning:
   perspectives of acceptance of information technology and learning style
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; UTAUT; Learning styles; Behavioural intentions
ID UNIFIED THEORY; USER ACCEPTANCE; PERCEIVED EASE; DETERMINANTS;
   RELIABILITY; TRAITS; DESIGN; MODEL; USAGE; FIT
AB The use of virtual reality (VR) has become a viable alternative to conventional learning methods in various knowledge domains. Wearable head-mounted displays (HMDs) are devices that provide users with an immersive VR experience. To investigate the direct determinants affecting students' reasons for HMD use in learning, hypotheses relating to information technology acceptance and Kolb's learning styles were proposed and tested in this study. Participants were recruited through stratified random sampling according to the population ratio of colleges at a university in Taiwan. Students were shown a video on VR applications in learning, after which an online survey was completed. In total, 387 questionnaires were collected of which 376 were valid. An inference analysis of the samples was performed by structural equation modelling with eight exogenous latent variables, namely the four constructs of the unified theory of acceptance and use of technology (UTAUT) and the four modes of Kolb's learning styles. All eight variables pointed to one endogenous latent variable: behavioural intention. The results showed all four constructs of the UTAUT to have a positive and significant effect on students' behavioural intention to use HMDs in learning and only the concrete experience mode of Kolb's learning styles to have a positive and significant effect. Based on these findings, this study provides suggestions on how to encourage HMDs use in learning to VR developers and educational institutions.
C1 [Shen, Chien-wen; Ho, Jung-tsung; Kuo, Ting-chang] Natl Cent Univ, Dept Business Adm, Taoyuan 32001, Taiwan.
   [Pham Thi Minh Ly] Ton Duc Thang Univ, Fac Business Adm, SocialTech Res Grp, Ho Chi Minh City, Vietnam.
C3 National Central University; Ton Duc Thang University
RP Ly, PTM (corresponding author), Ton Duc Thang Univ, Fac Business Adm, SocialTech Res Grp, Ho Chi Minh City, Vietnam.
EM phamthiminhly@tdt.edu.vn
RI Pham, Thi Minh Ly/ABI-6179-2020
OI Shen, Chien-wen/0000-0002-3792-0818; Ho, Jung-Tsung/0000-0002-9785-4373
FU Ministry of Science and Technology, Taiwan [MOST 105-2410-H-008-037]
FX This research was supported in part by the Ministry of Science and
   Technology, Taiwan, under contract #MOST 105-2410-H-008-037.
CR AbuShanab E, 2010, COMMUN ASSOC INF SYS, V26, P493
   Al-Qeisi K, 2014, J BUS RES, V67, P2282, DOI 10.1016/j.jbusres.2014.06.016
   Aldás-Manzano J, 2009, IND MANAGE DATA SYST, V109, P739, DOI 10.1108/02635570910968018
   Ali NS, 2017, J ENG APPL SCI, V12, P783
   ANDERSON JC, 1988, PSYCHOL BULL, V103, P411, DOI 10.1037/0033-2909.103.3.411
   [Anonymous], LEARN INDIVIDUAL DIF
   Antonieta A., 2014, Blucher Design Proceedings, V1, P495
   Bandura A., 1986, Social foundations of thought and action: A social cognitive theory, V1986, P23
   Barnett T, 2015, EUR J INFORM SYST, V24, P374, DOI 10.1057/ejis.2014.10
   BOLLEN KA, 1992, SOCIOL METHOD RES, V21, P205, DOI 10.1177/0049124192021002004
   Carlsson C., 2006, System Sciences, V6, p132a, DOI [DOI 10.1109/HICSS.2006.38, https://doi.org/10.1109/HICSS.2006.38]
   Cheon J.H., 2004, IACR Cryptology ePrint Archive, V2004, P15
   Chiu CM, 2008, INFORM MANAGE-AMSTER, V45, P194, DOI 10.1016/j.im.2008.02.003
   COMPEAU DR, 1995, MIS QUART, V19, P189, DOI 10.2307/249688
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Devaraj S, 2008, INFORM SYST RES, V19, P93, DOI 10.1287/isre.1070.0153
   Fetscherin M, 2008, J ELECTRON COMMER RE, V9, P231
   Fishbein M., 1980, UNDERSTANDING ATTITU
   Goodhue DL, 1995, MANAGE SCI, V41, P1827, DOI 10.1287/mnsc.41.12.1827
   GOODHUE DL, 1995, MIS QUART, V19, P213, DOI 10.2307/249689
   Hair JF, 2010, Multivariate data analysis
   Haller M., 1999, IMEKO - XV. World Congress. Measurement to Improve the Quality of Life in the 2st Century - Measurement Helps to Coordinate Nature with Human Activities - Vol. X. TEG-17. ISMCR'99 Topical Workshop on Virtual Reality and Advanced Human-Robot Systems, P291
   Hanson K, 2008, EDUC TECHNOL SOC, V11, P118
   Hauptman H, 2011, COMPUT EDUC, V57, P2106, DOI 10.1016/j.compedu.2011.05.008
   Hu PJ, 1999, J MANAGE INFORM SYST, V16, P91, DOI 10.1080/07421222.1999.11518247
   IDC, 2017, WORLDW SHIPM AR VR H
   Jonassen D.H., 2000, EDUC TECHNOL, V40, P21
   Jordanov WL, 2001, ANN M MIDS ED RES AS
   Kayes DC, 2005, J BUS PSYCHOL, V20, P249, DOI 10.1007/s10869-005-8262-4
   Kim J.-Y., 2013, INT J DIGITAL CONTEN, V7, P261, DOI DOI 10.1177/0273475311420233
   Kolb AY, 2005, ACAD MANAG LEARN EDU, V4, P193, DOI 10.5465/AMLE.2005.17268566
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Komarraju M, 2011, PERS INDIV DIFFER, V51, P472, DOI 10.1016/j.paid.2011.04.019
   LEONARDBARTON D, 1988, MANAGE SCI, V34, P1252, DOI 10.1287/mnsc.34.10.1252
   Li J, 2006, PROC MONOGR ENG WATE, P183, DOI 10.1145/1125170.1125218
   Lytras MD, 2016, BEHAV INFORM TECHNOL, V35, P877, DOI 10.1080/0144929X.2016.1235815
   Manolis C, 2013, LEARN INDIVID DIFFER, V23, P44, DOI 10.1016/j.lindif.2012.10.009
   Marchewka J.T., 2007, Communication o f the IIMA, V7, P93
   Maruping LM, 2017, J ASSOC INF SCI TECH, V68, P623, DOI 10.1002/asi.23699
   Nunnally JC, 1978, PSYCHOMETRIC THEORY, V2nd
   Nunnally JC, 1978, PSYCHOMETRIC THEORY
   Pelargos PE, 2017, J CLIN NEUROSCI, V35, P1, DOI 10.1016/j.jocn.2016.09.002
   ROBERTS ML, 1979, J MARKETING, V43, P28, DOI 10.2307/1250144
   Salvadori A, 2016, INT J QUANTUM CHEM, V116, P1731, DOI 10.1002/qua.25207
   Shaw RS, 2012, COMPUT EDUC, V58, P111, DOI 10.1016/j.compedu.2011.08.013
   Shih YC, 2008, EDUC TECHNOL SOC, V11, P56
   Sun KT, 2008, COMPUT EDUC, V50, P1411, DOI 10.1016/j.compedu.2007.01.003
   Svendsen GB, 2013, BEHAV INFORM TECHNOL, V32, P323, DOI 10.1080/0144929X.2011.553740
   Taylor S, 1995, MIS QUART, V19, P561, DOI 10.2307/249633
   Teo T, 2014, INTERACT LEARN ENVIR, V22, P51, DOI 10.1080/10494820.2011.641674
   Terrell S. R., 2002, Internet and Higher Education, V5, P345, DOI 10.1016/S1096-7516(02)00128-8
   Thatcher JB, 2002, MIS QUART, V26, P381, DOI 10.2307/4132314
   van Schaik P, 2009, J EDUC COMPUT RES, V40, P229, DOI 10.2190/EC.40.2.e
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2000, INFORM SYST RES, V11, P342, DOI 10.1287/isre.11.4.342.11872
   Venkatesh V, 2012, MIS QUART, V36, P157
   Wang KH, 2006, J COMPUT ASSIST LEAR, V22, P207, DOI 10.1111/j.1365-2729.2006.00166.x
   Wu YL, 2007, IN C IND ENG ENG MAN, P199, DOI 10.1109/IEEM.2007.4419179
NR 58
TC 78
Z9 83
U1 3
U2 71
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2019
VL 23
IS 3
SI SI
BP 313
EP 324
DI 10.1007/s10055-018-0348-1
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA IR5QR
UT WOS:000481490500009
DA 2024-07-18
ER

PT J
AU Bock, O
   Drescher, U
   Janouch, C
   Haeger, M
   van Winsum, W
   Voelcker-Rehage, C
AF Bock, Otmar
   Drescher, Uwe
   Janouch, Christin
   Haeger, Mathias
   van Winsum, Wim
   Voelcker-Rehage, Claudia
TI An experimental paradigm for the assessment of realistic human
   multitasking
SO VIRTUAL REALITY
LA English
DT Article
DE Human cognition; Multitasking costs; Ecological validity; Car driving;
   Street crossing
ID DUAL-TASK PERFORMANCE; CELL PHONE; AGE; CONVERSATIONS; INFORMATION;
   ATTENTION; COSTS; SPEED
AB Human multitasking has been evaluated with paradigms that administered tworarely threeconcurrent tasks. In everyday life, however, we usually face an ever-changing sequence of distinct concurrent tasks. Available studies therefore provided valuable insights into our ability for dual tasking, but they did not address the natural interplay of dual tasking and task switching. The present study was undertaken to explore the feasibility of two new paradigms which replicate that interplay in virtual reality. We used car driving simulator software to implement a virtual car-driving task as well as a virtual street-crossing task. Either task was administered alone, as well as concurrently with a battery of loading tasks that mimicked activities of everyday life. The loading tasks used different sensory modalities, different cognitive processes, and different output channels and were presented in an ever-changing sequence. Cronbach's alpha scores of key registered variables were high, which indicates that our approach is reliable. Driving and street-crossing performance deteriorated under multitask conditions, which indicates that our approach is sensitive to multitasking. This is the first study to demonstrate the feasibility of an experimental paradigm for the assessment of natural multitasking, i.e., of combined dual tasking and task switching. This paradigm could be of interest for basic science as well as for prevention and rehabilitation settings.
C1 [Bock, Otmar; Drescher, Uwe; Haeger, Mathias] German Sport Univ Cologne, Cologne, Germany.
   [Janouch, Christin; Voelcker-Rehage, Claudia] Tech Univ Chemnitz, Chemnitz, Germany.
   [van Winsum, Wim] Carnetsoft BV, Groningen, Netherlands.
C3 German Sport University Cologne; Technische Universitat Chemnitz
RP Bock, O (corresponding author), German Sport Univ Cologne, Cologne, Germany.
EM bock@dshs-koeln.de
RI van+Winsum, Wim/AAN-6433-2020; Voelcker-Rehage, Claudia/ABA-2163-2020
OI van+Winsum, Wim/0000-0002-5053-5797; Voelcker-Rehage,
   Claudia/0000-0001-5398-4099; Bock, Otmar/0000-0003-0485-6765
FU German Research Foundation (Deutsche Forschungsgemeinschaft, DFG) [SPP
   1772];  [BO 649/22-1];  [VO 1432/19-1]
FX This research was supported by Grants within the Priority Program SPP
   1772 from the German Research Foundation (Deutsche
   Forschungsgemeinschaft, DFG), Grants BO 649/22-1 and VO 1432/19-1. One
   of the authors (WvW) owns the Carnetsoft (R) company, which sells the
   driving simulator used in our study. Neither the person nor the company
   provided financial support for our work. We undertook every effort to
   avoid any reporting bias and any advertorial content.
CR [Anonymous], 1973, Attention and Effort
   Banducci SE, 2016, HUM FACTORS, V58, P150, DOI 10.1177/0018720815609501
   Bland JM, 1997, BRIT MED J, V314, P572, DOI 10.1136/bmj.314.7080.572
   Bock O, 2013, HUM MOVEMENT SCI, V32, P249, DOI 10.1016/j.humov.2012.12.009
   Bock O, 2010, GAIT POSTURE, V32, P645, DOI 10.1016/j.gaitpost.2010.09.009
   Burgess PW, 2000, CONTROL OF COGNITIVE PROCESSES: ATTENTION AND PERFORMANCE XVIII, P465
   Burgess PW, 2000, NEUROPSYCHOLOGIA, V38, P848, DOI 10.1016/S0028-3932(99)00134-7
   Byington KW, 2013, ACCIDENT ANAL PREV, V51, P78, DOI 10.1016/j.aap.2012.11.001
   Cassavaugh ND, 2009, APPL ERGON, V40, P943, DOI 10.1016/j.apergo.2009.02.001
   Chaddock L, 2012, MED SCI SPORT EXER, V44, P749, DOI 10.1249/MSS.0b013e31823a90cb
   Chaytor N, 2003, NEUROPSYCHOL REV, V13, P181, DOI 10.1023/B:NERV.0000009483.91468.fb
   Drews FA, 2009, HUM FACTORS, V51, P762, DOI 10.1177/0018720809353319
   Dux PE, 2009, NEURON, V63, P127, DOI 10.1016/j.neuron.2009.06.005
   Ewolds HE, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02241
   Feng J, 2017, EUR J AGEING, V14, P167, DOI 10.1007/s10433-016-0399-7
   Hazeltine E, 2002, J EXP PSYCHOL HUMAN, V28, P527, DOI 10.1037//0096-1523.28.3.527
   Helm WR, 1981, P HUM FACTORS SOC AN, V25, P518
   Hick WE, 1952, Q J EXP PSYCHOL, V4, P11, DOI 10.1080/17470215208416600
   Horrey WJ, 2006, HUM FACTORS, V48, P196, DOI 10.1518/001872006776412135
   Jersild A.T., 1927, ARCH PSYCHOL, V89, P5
   Kleinsorge T, 2001, PSYCHOL RES-PSYCH FO, V65, P216, DOI 10.1007/s004260100062
   Koch I, 2005, PSYCHON B REV, V12, P107, DOI 10.3758/BF03196354
   Kray J, 2000, PSYCHOL AGING, V15, P126, DOI 10.1037//0882-7974.15.1.126
   Laloyaux J, 2014, PSYCHIAT RES, V217, P163, DOI 10.1016/j.psychres.2014.03.026
   Liepelt R, 2011, Q J EXP PSYCHOL, V64, P1251, DOI 10.1080/17470218.2010.543284
   Manor B, 2016, J COGNITIVE NEUROSCI, V28, P275, DOI 10.1162/jocn_a_00897
   MAYER RE, 1976, MEM COGNITION, V4, P603, DOI 10.3758/BF03213224
   Mayr U, 2000, J EXP PSYCHOL GEN, V129, P4, DOI 10.1037/0096-3445.129.1.4
   MCDOWD JM, 1986, J GERONTOL, V41, P764, DOI 10.1093/geronj/41.6.764
   Minear M, 2008, MEM COGNITION, V36, P1470, DOI 10.3758/MC.336.8.1470
   Monsell S, 2003, MEM COGNITION, V31, P327, DOI 10.3758/BF03194391
   Neider MB, 2011, PSYCHOL AGING, V26, P260, DOI 10.1037/a0021566
   Norman D.A., 1986, ATTENTION TO ACTION
   Proctor RW, 2018, Q J EXP PSYCHOL, V71, P1281, DOI 10.1080/17470218.2017.1322622
   ROGERS RD, 1995, J EXP PSYCHOL GEN, V124, P207, DOI 10.1037/0096-3445.124.2.207
   Schumacher EH, 2001, PSYCHOL SCI, V12, P101, DOI 10.1111/1467-9280.00318
   Sekuler AB, 2000, EXP AGING RES, V26, P103, DOI 10.1080/036107300243588
   SHEA JB, 1979, J EXP PSYCHOL-HUM L, V5, P179, DOI 10.1037/0278-7393.5.2.179
   Strayer DL, 2003, J EXP PSYCHOL-APPL, V9, P23, DOI 10.1037/1076-898X.9.1.23
   Strobach T, 2012, PSYCHOL RES-PSYCH FO, V76, P74, DOI 10.1007/s00426-011-0323-x
   Telford CW, 1931, J EXP PSYCHOL, V14, P1, DOI 10.1037/h0073262
   Verhaeghen P, 2003, PSYCHOL AGING, V18, P443, DOI 10.1037/0882-7974.18.3.443
   Verhaeghen P, 2012, AGING NEUROPSYCHOL C, V19, P1, DOI 10.1080/13825585.2011.645009
   Welford AT, 1952, B J PSYCHOL-GEN SECT, V43, P2, DOI 10.1111/j.2044-8295.1952.tb00322.x
   Wickens C.D., 1991, Multiple-task performance, P3, DOI DOI 10.1201/9781003069447-2
   Wollesen B, 2014, EUR REV AGING PHYS A, V11, P5, DOI 10.1007/s11556-013-0122-z
   Zinke K, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00041
NR 47
TC 9
Z9 9
U1 1
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2019
VL 23
IS 1
BP 61
EP 70
DI 10.1007/s10055-018-0342-7
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA HN8ZN
UT WOS:000460487500006
DA 2024-07-18
ER

PT J
AU Phanomchoeng, G
   Chancharoen, R
   Lumia, R
AF Phanomchoeng, Gridsada
   Chancharoen, Ratchatin
   Lumia, Ron
TI Developing vibrotactile haptic stimuli based on measured human
   capabilities
SO VIRTUAL REALITY
LA English
DT Article
DE Vibrotactile; Haptic; Haptic wrist; Haptic belt; Tactile; Tactons; Human
   computer interaction
AB This paper describes an approach to design tactile haptic signals that help humans "visualize" an environment through the use of a vibrotactile haptic wristband that has four vibration motors. A human response map to tactile input while sitting was determined experimentally. It shows the zones where humans can classify signals with a high success rate based on minimum Duration of Stimulus (DOS) ("on" periods) and "off" periods of the haptic signals. It was also shown experimentally that a human's ability to recognize tactile patterns depends on the level of engagement required by the activity. This paper provides an approach to predict a human response map for various activities. The map during sitting is used to design the signals to send information to a human. Two types of signals are developed: sequence stimuli and digital codes. Sequence stimuli create an on/off rhythm for the vibration motors that humans can sense directly without a decoding process. Experiments show that humans can recognize 10 levels of sequence stimuli with a success rate greater than 80%. This class of signals is useful for applications where information must be repeated frequently, e.g., range information sent to a human parking a car. The second class of signals is digital codes, similar to Morse code, where a sequence of long and short motor DOS represents each code. The meaning of the signal is associated with a specific code. From 27 digital codes, experiments showed a successful recognition rate of 78.7%. An application for the digital code method is to pick specific menu items, based on the codes, for fast food restaurants.
C1 [Phanomchoeng, Gridsada; Chancharoen, Ratchatin] Chulalongkorn Univ, Dept Mech Engn, Bangkok 10330, Thailand.
   [Lumia, Ron] Univ New Mexico, Dept Mech Engn, Albuquerque, NM 87131 USA.
C3 Chulalongkorn University; University of New Mexico
RP Phanomchoeng, G (corresponding author), Chulalongkorn Univ, Dept Mech Engn, Bangkok 10330, Thailand.
EM gridsada.phanomchoeng@gmail.com; ratchatin.c@chula.ac.th; lumia@unm.edu
RI Phanomchoeng, Gridsada/AGV-6639-2022
OI Phanomchoeng, Gridsada/0000-0002-6518-0992
FU Chulalongkorn University Strategic Research Grant [CU-57-074-AS]
FX This paper was supported by the Chulalongkorn University Strategic
   Research Grant CU-57-074-AS.
CR Akita J, 2014, SIGGRAPH ASIA 2014 E
   [Anonymous], 1994, DYNAMICS SYSTEMS CON
   Bosman S., 2003, GentleGuide: An Exploration of Haptic Output for Indoors Pedestrian Guidance, P358
   Brewster S., 2004, C RES PRACT INF TECH, V28, P15, DOI DOI 10.1145/67880.1046599
   Chantranuwathana S, 2005, 19 C MECH ENG NETW T
   Erp JBV., 2005, ACM T APPL PERCEPT, V2, P106, DOI [10.1145/1060581.1060585, DOI 10.1145/1060581.1060585]
   Guo WJ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P135, DOI 10.1109/ROBIO.2009.5420612
   GUYOT GW, 1982, PERCEPT MOTOR SKILL, V54, P1289, DOI 10.2466/pms.1982.54.3c.1289
   Kohli L, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P445
   Lieberman J, 2007, IEEE T ROBOT, V23, P919, DOI 10.1109/TRO.2007.907481
   Lindeman RW., 2006, Virtual Reality, V9, P203, DOI [DOI 10.1007/S10055-005-0010-6, 10.1007/s10055-005-0010-6]
   Matsuura M., 2010, 2010 IEEE INT C COMM, P1
   McDaniel T.L., 2009, 27th International Conference Extended Abstracts on Human Factors in Computing Systems, P4669
   Phanomchoeng G, 2010, IEEE T VEH TECHNOL, V59, P2266, DOI 10.1109/TVT.2010.2042090
   Poupyrev I., 2002, Ambient touch: designing tactile interfaces for handheld devices, P51
   Poupyrev I, 2004, HAPTIC FEEDBACK PEN, P1309
   Rattanachotithavorn S, 2011, 5 C TRS C ROB IND TE
   Scheggi S, 2014, IEEE T HAPTICS, V7, P499, DOI 10.1109/TOH.2014.2332173
   Sergi F, 2008, P IEEE RAS-EMBS INT, P433, DOI 10.1109/BIOROB.2008.4762827
   Stanley AA, 2012, IEEE T HAPTICS, V5, P240, DOI 10.1109/TOH.2012.33
   Szymczak Delphine, 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P157, DOI 10.1007/978-3-642-31404-9_27
   Tsukada K, 2004, LECT NOTES COMPUT SC, V3205, P384
   Van Erp J.B. F., 2002, P EUROHAPTICS 2002, P18
   Van Erp JBF, 2004, TRANSPORT RES F-TRAF, V7, P247, DOI 10.1016/j.trf.2004.09.003
   van Erp JBF, 2001, LECT NOTES COMPUT SC, V2058, P165
   Yang Ungyeon, 2002, INT C ARTIFICIAL REA, P4
   Yano H, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P196, DOI 10.1109/WHC.2009.4810889
NR 27
TC 3
Z9 3
U1 1
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2017
VL 21
IS 4
BP 203
EP 212
DI 10.1007/s10055-017-0309-0
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA FG6HN
UT WOS:000410473200004
DA 2024-07-18
ER

PT J
AU Bunnun, P
   Subramanian, S
   Mayol-Cuevas, WW
AF Bunnun, Pished
   Subramanian, Sriram
   Mayol-Cuevas, Walterio W.
TI In-Situ interactive image-based model building for Augmented Reality
   from a handheld device
SO VIRTUAL REALITY
LA English
DT Article
DE Model building; Augmented Reality; Handheld device
AB Three-dimensional models of objects and their creation process are central for a variety of applications in Augmented Reality. In this article, we present a system that is designed for in-situ modeling using interactive techniques for two generic versions of handheld devices equipped with cameras. The system allows online building of 3D wireframe models through a combination of user interaction and automated methods. In particular, we concentrate in rigorous evaluation of the two devices and interaction methods in the context of 3D feature selection. We present the key components of our system, discuss our findings and results and identify design recommendations.
C1 [Bunnun, Pished; Subramanian, Sriram; Mayol-Cuevas, Walterio W.] Univ Bristol, Dept Comp Sci, Bristol, Avon, England.
C3 University of Bristol
RP Bunnun, P (corresponding author), Univ Bristol, Dept Comp Sci, Bristol, Avon, England.
EM pbunnun@cs.bris.ac.uk; sriram@cs.bris.ac.uk; wmayol@cs.bris.ac.uk
RI Subramanian, Sriram/AAF-3232-2019; Mayol-Cuevas, Walterio/AAD-6590-2019
OI Subramanian, Sriram/0000-0002-5266-8366; Mayol-Cuevas,
   Walterio/0000-0001-8973-1931
CR Bastian J, 2010, P 6 IEEE ACM INT S M
   Bowman D.A., 2005, 3D User Interfaces: Theory and Practice
   Brown M., 2000, ELECT P 11 BRIT MACH, P11
   Bunnun P., 2008, P IEEE ACM INT S MIX
   Chekhlov D., 2007, P IEEE ACM INT S MIX, P1
   Comport AI, 2006, IEEE T VIS COMPUT GR, V12, P615, DOI 10.1109/TVCG.2006.78
   Davison A., 2003, INT S MIX AUGM REAL
   DEBEVEC PE, 1996, SIGGRAPH96
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   Faugeras O, 1988, TECHNICAL REPORT
   Freeman R., 2006, VRST '06: Proceedings of the ACM symposium on Virtual reality software and technology, P61
   GEE AP, 2006, INT S VIS COMP
   Grossman Tovi, 2006, P 19 ANN ACM S US IN
   Kim K, 2010, P 6 IEEE ACM INT S M
   Kim S, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P19
   Klein G., 2007, P IEEE ACM INT S MIX
   Lepetit V., 2003, P 2 IEEE ACM INT S M
   Neubert J, 2007, P IEEE ACM INT S MIX
   Newcombe RA, 2010, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2010.5539794
   PAN Q, 2009, P 20 BRIT MACH VIS C
   Reitmayr G., 2007, P 6 IEEE ACM INT S M
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Simon G, 2006, INT SYM MIX AUGMENT, P193
   TUKEY JW, 1977, EXPLORTARY DATA ANAL
   Vacchetti L., 2004, INT S MIX AUGM REAL
   van den Hengel A., 2009, P IEEE ACM INT S MIX
   van den Hengel A., 2007, P SIGGRAPH
   Varadarajan V.S., 1974, LIE GROUPS LIE ALGEB
NR 28
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2013
VL 17
IS 2
SI SI
BP 137
EP 146
DI 10.1007/s10055-011-0206-x
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 139IH
UT WOS:000318575200004
DA 2024-07-18
ER

PT J
AU Karadogan, E
   Williams, RL
AF Karadogan, Ernur
   Williams, Robert L., II
TI Haptic modules for palpatory diagnosis training of medical students
SO VIRTUAL REALITY
LA English
DT Article
DE Haptic modules; Haptic medical simulation; Medical education;
   Osteopathic medicine; Palpatory diagnosis
ID SIMULATOR; VALIDATION
AB We have developed and evaluated a novel tool based on haptics and virtual reality technology for augmenting the teaching of palpatory diagnosis. This novel tool can act as an automated expert and an animated textbook to illuminate palpatory diagnosis concepts by touch on a laptop PC and by using affordable haptic interfaces that can be housed in a medical student resource library. It can be used for unlimited student practice for improving skills from Osteopathic Manipulative Medicine laboratory and also as a repeatable and objective measure of palpatory skill to track student progress. The system was evaluated by 22 osteopathic medical students (16 first- and 6 second-year). The majority of the participating students (> 90.9 %) thought that future practice with the system may help them develop their palpatory skills. The majority (> 77.3 %) of the students also thought that the instructions on the module screens were clear. When the students were asked about the user interface, most of the students (> 86.4 %) responded that it was clear and easy to interpret. Evaluation results also showed that when the students were asked whether they would like to use the modules in the future for training at least 90.9 % of them answered "Yes" or "Maybe." The achievement of purpose ratings for individual modules changed between 6.27 and 8.82 on a 10-point scale. This project has the potential to be extended from osteopathic medicine to allopathic medicine, veterinary medicine, physical therapy, massage therapy, and chiropractic schools.
C1 [Karadogan, Ernur; Williams, Robert L., II] Ohio Univ, Dept Mech Engn, Russ Coll Engn & Technol, Athens, OH 45701 USA.
C3 University System of Ohio; Ohio University
RP Williams, RL (corresponding author), Ohio Univ, Dept Mech Engn, Russ Coll Engn & Technol, 262 Stocker Ctr, Athens, OH 45701 USA.
EM williar4@ohio.edu
OI KARADOGAN, ERNUR/0000-0001-7842-7360
CR Allen PVB, 1941, JAOA               2, V40, P276
   [Anonymous], GLOSS OST TERM
   Baillie S, 2005, ST HEAL T, V111, P33
   Burdea G, 1999, IEEE T BIO-MED ENG, V46, P1253, DOI 10.1109/10.790503
   Carter HV, 1927, J AM OSTEOPATH ASSOC, V26, P1006
   Casiez G., 2003, P VIRT REAL INT C, P35
   Cathie A, 1974, FASCIA BODY RELATION, P81
   Degenhardt BF, 2005, J AM OSTEOPATH ASSOC, V105, P465
   DENSLOW J S, 1964, J Am Osteopath Assoc, V63, P1107
   DiGiovanna EL, 1991, OSTEOPATHIC APPROACH, P8
   Dinsmore M, 1997, P IEEE VIRT REAL ANN, P54, DOI 10.1109/VRAIS.1997.583044
   Forrest N, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P646, DOI 10.1109/WHC.2009.4810800
   Fung YC, 1993, BIOMECHANICS MECH PR, P41
   Howell JN, 2008, 52 ANN AOA RES C LAS
   Howell JN, 2005, SAE TRANSACTIONS, V114, P2865
   Howell JN, 2008, BMC MED EDUC, P8
   Howell JN, 2006, SAE DIG HUM MOD C LY
   Howell JN, 2008, J AM OSTEOPATH ASSOC, V108, P29
   Karadogan E, 2010, SIMUL HEALTHC, V5, P279, DOI 10.1097/SIH.0b013e3181e9e783
   Kessler GD., 1995, ACM Transactions on Computer-Human Interaction, V2, P263
   Kohno Y., 2001, P 11 INT C ART REAL
   Langrana N, 1997, COMPUT GRAPH, V21, P451, DOI 10.1016/S0097-8493(97)00021-6
   Parkes R, 2009, STUD HEALTH TECHNOL, V142, P244, DOI 10.3233/978-1-58603-964-6-244
   Pugh CM, 2002, J AM MED INFORM ASSN, V9, P448, DOI 10.1197/jamia.M1107
   Pugh CM, 2001, JAMA-J AM MED ASSOC, V286, P1021, DOI 10.1001/jama.286.9.1021-a
   Srinivasan M. A., 1996, Proceedings of the ASME Dynamic Systems and Control Division, P555
   Zhang Y, 2009, MMVR 17 LONG BEACH C
NR 27
TC 6
Z9 6
U1 0
U2 29
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2013
VL 17
IS 1
BP 45
EP 58
DI 10.1007/s10055-013-0220-2
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 089NC
UT WOS:000314916300004
DA 2024-07-18
ER

PT J
AU Takács, B
AF Takacs, Barnabas
TI Immersive interactive reality: Internet-based on-demand VR for cultural
   presentation
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive interactive reality; Cultural presentation; Virtual reality
   on-demand; Virtual human interface; Panoramic broadcasting (PanoCAST)
ID VIDEO
AB This paper presents an Internet-based virtual reality technology, called panoramic broadcasting (PanoCAST) where multiple viewers share an experience yet each having full control of what they see independent from other viewers. Our solution was developed for telepresence-based cultural presentation and entertainment services. The core architecture involves a compact spherical vision system that compresses and transmits data from multiple digital video sources to a central host computer, which in turn distributes the recorded information among multiple render-and streaming servers for personalized viewing over the Internet or mobile devices. In addition, using advanced computer vision, tracking and animation features, the PanoCAST architecture introduces the notion of Clickable Content Management (CCM), where each visual element in the image becomes a source for providing further information, educational content and cultural detail. Key contributions of our application to advance the state-of-the-art include bringing streaming panoramic video onto mobile platforms, an advanced tracking interface to turn visual elements into sources of interaction, physical simulation to combine the benefits of panoramic video with that of 3D models and animated, photo-realistic faces to help users express their emotions in shared online virtual cultural experiences as well as a feedback mechanism in such environments. Therefore, we argue that the PanoCAST system offers a low-cost and economical solution for personalized content distribution and as such it can serve as a unified basis for novel applications many of which are demonstrated in this paper.
C1 [Takacs, Barnabas] Digital Elite Inc, Los Angeles, CA USA.
   [Takacs, Barnabas] Tech Univ Budapest BME, Budapest, Hungary.
C3 Budapest University of Technology & Economics
RP Takács, B (corresponding author), Digital Elite Inc, Los Angeles, CA USA.
EM BTakacs@digitalCustom.com
CR *AD, 2009, AD FLASH PLAYER
   *APPL, 2009, QUICKTIME
   BALDWIN J, 1999, P IEEE INT C ROB
   *FRAUNH HHI, 2009, OMN
   *GOOGL, 2009, GOOGL STREET VIEW
   Gross M, 2003, ACM T GRAPHIC, V22, P819, DOI 10.1145/882262.882350
   *IMM MED, 2009, DOD CAM
   *KAID, 2009, GO PAN
   KIMBER D, 2001, P ACM MULT OTT
   Majumder A, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P169, DOI 10.1145/319463.319485
   NEUMANN U, 2000, P ACM MULT 2000 OCT, P493
   NG KT, 2001, P INT S INT MULT VID
   Ouglov A, 2005, P SOC PHOTO-OPT INS, V5682, P326, DOI 10.1117/12.585534
   PATIL R, 2004, P IEEE RSJ INT C INT
   *POINT GREY RES, 2009, LADYBUG2 LADYBUG3 CA
   PRYOR L, 2000, USER DIRECTED NEWS
   QIN N, 2007, P IEEE INT C INT ROB
   Rhee SM, 2007, IEEE T VIS COMPUT GR, V13, P156, DOI 10.1109/TVCG.2007.17
   Rizzo A., 2004, P 5 INT C DIS VIRT R
   Rizzo A.A., 2003, HUM-COMPUT INTERACT, V1, P1233
   RIZZO AA, 2001, USABILITY EVALUATION, V1, P792
   SUN X, 2002, IEEE INT C MULT
   Takács B, 2005, IEEE COMPUT GRAPH, V25, P40, DOI 10.1109/MCG.2005.113
   Takács B, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1231176
   Takacs Barnabas, 2008, International Journal of Virtual Reality, V7, P53
   TAKACS B, 2007, P ICEC07 SHANGH CHIN
   TAKACS B, 1999, P ICCV 99 CORF GREEC
   Takacs B., 2006, INT J VIRTUAL REALIT, V5, P1
   Zheng HF, 2007, ADV MULTIMED, V2007, DOI 10.1155/2007/61491
   2009, IMMERSIVE INTERACTIV
   2009, FUNICONS
   2005, INTERACTIVE PANORAMI
NR 32
TC 4
Z9 5
U1 0
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2011
VL 15
IS 4
SI SI
BP 267
EP 278
DI 10.1007/s10055-010-0157-7
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IC
UT WOS:000296280300003
DA 2024-07-18
ER

PT J
AU Londero, A
   Viaud-Delmon, I
   Baskind, A
   Delerue, O
   Bertet, S
   Bonfils, P
   Warusfel, O
AF Londero, Alain
   Viaud-Delmon, Isabelle
   Baskind, Alexis
   Delerue, Olivier
   Bertet, Stephanie
   Bonfils, Pierre
   Warusfel, Olivier
TI Auditory and visual 3D virtual reality therapy for chronic subjective
   tinnitus: theoretical framework
SO VIRTUAL REALITY
LA English
DT Article
DE Tinnitus; Virtual reality; Neuroplasticity
ID PHANTOM LIMB PAIN; HEARING-LOSS; PATHOPHYSIOLOGY; PERSONALITY;
   PERCEPTION; MECHANISMS; DEPRESSION
AB It is estimated that similar to 10% of the adult population in developed countries is affected by subjective tinnitus. Physiopathology of subjective tinnitus remains incompletely explained. Nevertheless, subjective tinnitus is thought to result from hyperactivity and neuroplastic reorganization of cortical and subcortical networks following acoustic deafferentation induced by cochlear or auditory nerve damage. Involvement of both auditory and non-auditory central nervous pathways explains the conscious perception of tinnitus and also the potentially incapacitating discomfort experienced by some patients (sound hypersensitivity, sleep disorders, attention deficit, anxiety or depression). These clinical patterns are similar to those observed in chronic pain following amputation where conditioning techniques using virtual reality have been shown both to be theoretically interesting and effectively useful. This analogy led us to develop an innovative setup with dedicated auditory and visual 3D virtual reality environments in which unilateral subjective tinnitus sufferers are given the possibility to voluntarily manipulate an auditory and visual image of their tinnitus (tinnitus avatar). By doing so, the patients will be able to transfer their subjective auditory perception to the tinnitus avatar and to gain agency on this multimodal virtual percept they hear, see and spatially control. Repeated sessions of such virtual reality immersions are then supposed to contribute to tinnitus treatment by promoting cerebral plasticity. This paper describes the theoretical framework and setup adjustments required by this very first attempt to adapt virtual reality techniques to subjective tinnitus treatment. Therapeutic usefulness will be validated by a further controlled clinical trial.
C1 [Viaud-Delmon, Isabelle; Delerue, Olivier; Bertet, Stephanie; Warusfel, Olivier] IRCAM, Paris, France.
   [Londero, Alain; Bonfils, Pierre] Hop Europeen Georges Pompidou, Serv ORL & Chirurg Cervicofaciale, Paris, France.
   [Londero, Alain; Baskind, Alexis; Bonfils, Pierre] Univ Paris 05, CNRS, Fac Med Rene Descartes, Lab Rech Syst Sensori Moteurs LNRS,Unite UMR 7060, F-75270 Paris, France.
   [Viaud-Delmon, Isabelle; Warusfel, Olivier] CNRS, UMR 9912, Paris, France.
C3 Assistance Publique Hopitaux Paris (APHP); Universite Paris Cite;
   Hopital Universitaire Europeen Georges-Pompidou - APHP; Centre National
   de la Recherche Scientifique (CNRS); Universite Paris Cite; Centre
   National de la Recherche Scientifique (CNRS); Sorbonne Universite
RP Warusfel, O (corresponding author), IRCAM, Paris, France.
EM warusfel@ircam.fr
OI warusfel, olivier/0000-0003-3299-0048; Viaud-Delmon,
   Isabelle/0000-0002-8664-3941
FU Tinnitus Research Initiative Grant [PB 07 01]; french ANR [RIAM 004 02];
   AMPLIFON France; Fondation "Les Gueules Cassees"
FX This research is supported by a Tinnitus Research Initiative Grant (PB
   07 01), by the french ANR RIAM 004 02 "EarToy" and by AMPLIFON France.
   S. Bertet received a grant from Fondation "Les Gueules Cassees".
CR Andersson G, 2002, CLIN PSYCHOL REV, V22, P977, DOI 10.1016/S0272-7358(01)00124-6
   Andersson G, 2003, AURIS NASUS LARYNX, V30, P129, DOI 10.1016/S0385-8146(03)00008-7
   Andersson G, 2006, ACTA OTO-LARYNGOL, V126, P39, DOI 10.1080/03655230600895226
   AXELSSON A, 1989, British Journal of Audiology, V23, P53, DOI 10.3109/03005368909077819
   Baguley DM, 2005, OTOL NEUROTOL, V26, P1061, DOI 10.1097/01.mao.0000185043.54147.3a
   Bartels H, 2008, EAR HEARING, V29, P947, DOI 10.1097/AUD.0b013e3181888f83
   Bauer Carol A, 2004, Curr Opin Otolaryngol Head Neck Surg, V12, P413, DOI 10.1097/01.moo.0000134443.29853.09
   Belli S, 2008, EUR ARCH OTO-RHINO-L, V265, P279, DOI 10.1007/s00405-007-0440-8
   BRUNGART D, 1999, P IEEE WORKSH APP SI, V17, P1
   Cacace AT, 2003, HEARING RES, V175, P112, DOI 10.1016/S0378-5955(02)00717-7
   Caffier PP, 2006, EAR HEARING, V27, P619, DOI 10.1097/01.aud.0000240504.77861.1a
   Cole J, 2009, DISABIL REHABIL, V31, P846, DOI 10.1080/09638280802355197
   Crönlein T, 2007, PROG BRAIN RES, V166, P227, DOI 10.1016/S0079-6123(07)66021-X
   Daniel J, 2004, P 116 AUD ENG SOC CO
   De Ridder D, 2004, NEUROSURGERY, V54, P381, DOI 10.1227/01.NEU.0000103420.53487.79
   De Ridder D, 2007, PROG BRAIN RES, V166, P55, DOI 10.1016/S0079-6123(07)66005-1
   Delb W, 2008, APPL PSYCHOPHYS BIOF, V33, P211, DOI 10.1007/s10484-008-9065-y
   DERIDDER D, 2005, THESIS ANTWERPEN U
   Dobie RA, 1999, LARYNGOSCOPE, V109, P1202, DOI 10.1097/00005537-199908000-00004
   EGGERMONT JJ, 1990, HEARING RES, V48, P111, DOI 10.1016/0378-5955(90)90202-Z
   Eggermont JJ, 2007, PROG BRAIN RES, V166, P19, DOI 10.1016/S0079-6123(07)66002-6
   Eichhammer P, 2007, PROG BRAIN RES, V166, P83, DOI 10.1016/S0079-6123(07)66008-7
   Folmer Robert L, 2008, Int Tinnitus J, V14, P127
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P290, DOI 10.1162/pres.1996.5.3.290
   Herraiz C, 2006, EUR ARCH OTO-RHINO-L, V263, P504, DOI 10.1007/s00405-006-0019-9
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Husain FT, 2007, PROG BRAIN RES, V166, P125, DOI 10.1016/S0079-6123(07)66011-7
   Jastreboff PJ, 2007, PROG BRAIN RES, V166, P415, DOI 10.1016/S0079-6123(07)66040-3
   Jastreboff PJ, 2006, ORL-J OTO-RHIN-LARYN, V68, P23, DOI 10.1159/000090487
   JASTREBOFF PJ, 1990, NEUROSCI RES, V8, P221, DOI 10.1016/0168-0102(90)90031-9
   Jot JM, 1999, MULTIMEDIA SYST, V7, P55, DOI 10.1007/s005300050111
   Langguth B, 2007, PROG BRAIN RES, V166, P221, DOI 10.1016/S0079-6123(07)66020-8
   Lewald J, 2002, J NEUROSCI, V22, DOI 10.1523/JNEUROSCI.22-03-j0005.2002
   Londero A, 2006, PRESSE MED, V35, P1213, DOI 10.1016/S0755-4982(06)74792-3
   Loomis J.M., 1992, Presence: Teleoperators and Virtual Environments, V1, P113, DOI 10.1162/pres.1992.1.1.113
   Malham DG, 1995, COMPUT MUSIC J, V19, P58, DOI 10.2307/3680991
   Meric C., 1996, J FR ORL, V45, P409
   Moller AR, 2007, PROG BRAIN RES, V166, P47, DOI 10.1016/S0079-6123(07)66004-X
   Moller AR, 2001, NEUROL RES, V23, P565, DOI 10.1179/016164101101199009
   Mrena R, 2007, ACTA OTO-LARYNGOL, V127, P729, DOI 10.1080/00016480601002013
   Murray CD, 2007, DISABIL REHABIL, V29, P1465, DOI 10.1080/09638280601107385
   Nelson Jeffrey J, 2004, Ear Nose Throat J, V83, P472
   Norena A, 2002, AUDIOL NEURO-OTOL, V7, P358, DOI 10.1159/000066156
   Noreña AJ, 2003, HEARING RES, V183, P137, DOI 10.1016/S0378-5955(03)00225-9
   Noreña AJ, 2007, NEUROREPORT, V18, P1251, DOI 10.1097/WNR.0b013e3282202c35
   Riva G, 2005, CYBERPSYCHOL BEHAV, V8, P220, DOI 10.1089/cpb.2005.8.220
   Savastano M, 2004, J OTOLARYNGOL, V33, P248, DOI 10.2310/7070.2004.03057
   Searchfield GD, 2007, PROG BRAIN RES, V166, P441, DOI 10.1016/S0079-6123(07)66043-9
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   SHULMAN A, 1987, DIAGNOSTIC TREATMENT, P248
   Smits M, 2007, NEURORADIOLOGY, V49, P669, DOI 10.1007/s00234-007-0231-3
   Viaud-Delmon I, 2006, EUR PSYCHIAT, V21, P501, DOI 10.1016/j.eurpsy.2004.10.004
   VIAUDDELMON I, 2004, ANN REV CYBERTHER TE, V2, P143
   Viirre Erik, 2007, Int Tinnitus J, V13, P110
   Vio MM, 2005, DRUG DISCOV TODAY, V10, P1263, DOI 10.1016/S1359-6446(05)03594-4
   Weiss Patrice L, 2004, J Neuroeng Rehabil, V1, P12, DOI 10.1186/1743-0003-1-12
   Weisz N, 2005, PLOS MED, V2, P546, DOI 10.1371/journal.pmed.0020153
   Weisz N, 2006, HEARING RES, V222, P108, DOI 10.1016/j.heares.2006.09.003
   Weisz N, 2007, J NEUROSCI, V27, P1479, DOI 10.1523/JNEUROSCI.3711-06.2007
   Welch D, 2008, EAR HEARING, V29, P684, DOI 10.1097/AUD.0b013e318177d9ac
   WIGHTMAN FL, 1989, J ACOUST SOC AM, V85, P858, DOI 10.1121/1.397557
   Zwiers MP, 2001, J NEUROSCI, V21, part. no., DOI 10.1523/JNEUROSCI.21-09-j0002.2001
NR 62
TC 13
Z9 15
U1 6
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2010
VL 14
IS 2
BP 143
EP 151
DI 10.1007/s10055-009-0135-0
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HV
UT WOS:000296279600005
OA hybrid
DA 2024-07-18
ER

PT J
AU Inderbitzin, M
   Wierenga, S
   Väljamäe, A
   Bernardet, U
   Verschure, PFMJ
AF Inderbitzin, Martin
   Wierenga, Sytse
   Vaeljamaee, Aleksander
   Bernardet, Ulysses
   Verschure, Paul F. M. J.
TI Social cooperation and competition in the mixed reality space eXperience
   Induction Machine XIM
SO VIRTUAL REALITY
LA English
DT Article
DE Human behavior; Social behavior; Cooperation; Competition; Proxemics;
   Mixed reality; XIM; Game play
ID DISTANCE
AB Although the architecture of mixed reality spaces is becoming increasingly more complex, our understanding of human behavior in such spaces is still limited. Despite the sophisticated methods deployed in ethology and behavioral biology to track and analyze the actions and movements of animals, we rarely find studies that focus on the understanding of human behavior using such instruments. Here, we address this issue by analyzing social behavior and physical actions of multiple humans who are engaging in a game. As a paradigm of social interaction, we constructed a mixed reality football game in which two teams of two players have to cooperate and compete in order to win. This paradigm was deployed in the, so-called, eXperience Induction Machine (XIM), a human accessible, fully instrumented space that supports full body interaction in mixed reality without the need for body-mounted sensors. Our results show that winning and losing strategies can be discerned by specific behavioral patterns and proxemics. This demonstrates that mixed reality systems such as XIM provide new paradigms for the investigation of human social behavior.
C1 [Inderbitzin, Martin; Wierenga, Sytse; Vaeljamaee, Aleksander; Bernardet, Ulysses; Verschure, Paul F. M. J.] Univ Pompeu Fabra, SPECS, IUA, Barcelona 08018, Spain.
   [Verschure, Paul F. M. J.] Inst Catalana Recerca & Estudis Avanats, ICREA, Barcelona 08010, Spain.
C3 Pompeu Fabra University; ICREA
RP Inderbitzin, M (corresponding author), Univ Pompeu Fabra, SPECS, IUA, Roc Boronat 138, Barcelona 08018, Spain.
EM minderbitzin@iua.upf.edu
RI Verschure, Paul/AAR-2340-2021; Bernardet, Ulysses/D-5477-2016; Valjamae,
   Aleksander/C-9952-2013
OI Verschure, Paul/0000-0003-3643-9544; Bernardet,
   Ulysses/0000-0003-4659-3035; Valjamae, Aleksander/0000-0001-6071-3211
FU EU [27731]; ICREA Funding Source: Custom
FX We acknowledge the use of the Original Floor System developed by the
   Institute of Neuroinformatics of ETH Zurich and of the University of
   Zurich. This work was carried out as part of the PRESENCCIA project, a
   EU funded integrated project under the FP6-IST FET program (project
   number 27731).
CR [Anonymous], 1993, Prisoner's Dilemma
   [Anonymous], 2003, Second life
   AXELROD R, 1981, SCIENCE, V211, P1390, DOI 10.1126/science.7466396
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   BERNARDET U, 2007, P 10 ANN INT WORKSH, P329
   Bialik C., 2007, WALL STR J
   Bobick AF, 2000, COMMUN ACM, V43, P60, DOI 10.1145/330534.330541
   DEFANTI TA, 1993, SIGGRAPH 93, P135
   Delbrück T, 2007, ROBOT AUTON SYST, V55, P433, DOI 10.1016/j.robot.2007.01.006
   Deutsch M, 1949, HUM RELAT, V2, P129, DOI 10.1177/001872674900200204
   Edgecomb SJ, 2006, J SCI MED SPORT, V9, P25, DOI 10.1016/j.jsams.2006.01.003
   Eng K, 2003, REV NEUROSCIENCE, V14, P145
   Eng K, 2006, PRESENCE-TELEOP VIRT, V15, P403, DOI 10.1162/pres.15.4.403
   *GARAGEGAMES, 2008, TORQ GAM ENG
   Gillath O, 2008, MEDIA PSYCHOL, V11, P259, DOI 10.1080/15213260801906489
   Hall Edward Twitchell, 1966, HIDDEN DIMENSION
   HALL ET, 1963, AM ANTHROPOL, V65, P1003, DOI 10.1525/aa.1963.65.5.02a00020
   Heldal I, 2005, PRESENCE-VIRTUAL AUG, V14, P563, DOI 10.1162/105474605774918679
   HOLLERER T, 2007, P 2007 WORKSH EM DIS, V252
   ICKNER WJ, 1982, THESIS YALE U
   *IQR, 2008, IQR SIM LARG SCAL NE
   Lefevre S., 2000, P IARP C MACH VIS AP, P501
   Manzolli J, 2005, COMPUT MUSIC J, V29, P55, DOI 10.1162/0148926054798133
   MATHEWS Z, 2007, P 4 INTUITION INT C, P26
   Schell J, 2001, IEEE COMPUT GRAPH, V21, P11, DOI 10.1109/38.933519
   STANTON D, 2001, P SIGCHI C HUM FACT, P482
   Steed Anthony., 2003, P ACM SIGGRAPH S INT, P51
   Vogiazou Y, 2005, INTERACT TECHNOL SMA, V2, P117, DOI 10.1108/17415650580000037
   Xu M, 2005, IEE P-VIS IMAGE SIGN, V152, P232, DOI 10.1049/ip-vis:20041257
   Yee N, 2007, CYBERPSYCHOL BEHAV, V10, P115, DOI 10.1089/cpb.2006.9984
NR 31
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2009
VL 13
IS 3
BP 153
EP 158
DI 10.1007/s10055-009-0119-0
PN 1
PG 6
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XE
UT WOS:000208104300003
DA 2024-07-18
ER

PT J
AU Jeong, DH
   Song, CG
   Chang, R
   Hodges, L
AF Jeong, Dong Hyun
   Song, Chang G.
   Chang, Remco
   Hodges, Larry
TI User experimentation: an evaluation of velocity control techniques in
   immersive virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; 3D interaction; Velocity control technqiues
ID WALKING; DESIGN; TRAVEL
AB While many of the existing velocity control techniques are well designed, the techniques are often application-specific, making it difficult to compare their effectiveness. In this paper, we evaluate five known velocity control techniques using the same experimental settings. We compare the techniques based on the assumption that a good travel technique should be easy to learn and easy to use, should cause the user to have few collisions with the VE, should allow the user to complete tasks faster, and should promote better recollection of the environment afterwards. In our experiments, we ask twenty users to use each velocity control technique to navigate through virtual corridors while performing information-gathering tasks. In all cases, the users use pointing to indicate the direction of travel. We then measure the users' ability to recollect the information they see in the VE, as well as how much time they spend in the VE and how often they collide with the virtual walls. After each test, we use questionnaires to evaluate the ease of learning and ease of use of the velocity control technique, and the users' sense of presence in the environment. Each of the travel techniques is then evaluated based on the users' performances in the VE and the results of their questionnaires.
C1 [Jeong, Dong Hyun; Chang, Remco] UNC Charlotte, Dept Comp Sci, Charlotte, NC 28223 USA.
   [Song, Chang G.] Hallym Univ, Dept Comp Engn, Chunchon, South Korea.
   [Hodges, Larry] Clemson Univ, Sch Comp, Clemson, SC USA.
C3 University of North Carolina; University of North Carolina Charlotte;
   Hallym University; Clemson University
RP Jeong, DH (corresponding author), UNC Charlotte, Dept Comp Sci, Charlotte, NC 28223 USA.
EM dhjeong@uncc.edu; cgsong@hallym.ac.kr; rchang@uncc.edu; lfh@clemson.edu
RI Song, Chang Geun/Q-6341-2019; Jeong, Dong H/AAC-6736-2019
OI Song, Chang Geun/0000-0003-0204-6160; Chang, Remco/0000-0002-6484-6430;
   Jeong, Dong Hyun/0000-0001-5271-293X
CR [Anonymous], P INT TRAIN SIM ED C
   Barfield W., 1995, VIRTUAL ENV ADV INTE, P473, DOI [DOI 10.1093/OSO/9780195075557.001.0001, 10.1093/oso/9780195075557.001.0001]
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 1999, PRESENCE-TELEOP VIRT, V8, P618, DOI 10.1162/105474699566521
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P75, DOI 10.1162/105474601750182333
   Bowman DA, 1999, J VISUAL LANG COMPUT, V10, P37, DOI 10.1006/jvlc.1998.0111
   BOWMAN DA, 1998, SPRINGER VIRTUAL REA, V3, P120
   BOWMAN DA, 2001, SIGGRAPH 2001
   BREDERSON JD, 1999, UUCS99016
   Brogan DC, 1998, IEEE COMPUT GRAPH, V18, P58, DOI 10.1109/38.708561
   Darken R.P., 1996, P SIGCHI C HUMAN FAC, P142, DOI DOI 10.1145/238386.238459
   Gabbard JL, 1999, IEEE COMPUT GRAPH, V19, P51, DOI 10.1109/38.799740
   JEONG DH, 2004, P GRAPH 2004 SING, P237
   JEONG DH, 2005, P PAC GRAPH 2005 MAC, P157
   Kamphuis A., 2004, SCA '04: Proceedings of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P19
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kessler GD, 2000, PRESENCE-TELEOP VIRT, V9, P187, DOI 10.1162/105474600566718
   LEE CS, 2005, P KOR MULT SOC SPRIN, P293
   Marsh T., 2001, Proceedings of the workshop on guiding users through interactive experiences, P149
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Mine M., 1995, TR95018 UNC
   PATON M, 1994, P CHI94 BOST, P255
   Poupyrev I, 1997, P ACM S VIRT REAL SO, P21
   PROFFITT DR, 1989, J EXP PSYCHOL HUMAN, V15, P384, DOI 10.1037/0096-1523.15.2.384
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Smith BT, 2002, IEEE T NEUR SYS REH, V10, P22, DOI 10.1109/TNSRE.2002.1021583
   Tanawongsuwan R, 2004, PROC CVPR IEEE, P783
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
NR 28
TC 4
Z9 5
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2009
VL 13
IS 1
BP 41
EP 50
DI 10.1007/s10055-008-0098-6
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XC
UT WOS:000208104100006
DA 2024-07-18
ER

PT J
AU Marshall, B
   Uiga, L
   Parr, JVV
   Wood, G
AF Marshall, B.
   Uiga, L.
   Parr, J. V. V.
   Wood, G.
TI A preliminary investigation into the efficacy of training soccer heading
   in immersive virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Football; Concussion; sub-concussion; Intervention; Sport
ID SPORT PERFORMANCE; QUIET-EYE; IMPACT
AB Recent research has suggested a link between repetitive soccer heading and the increased incidence of neurodegenerative disease in retired players. In response, restrictions have been introduced to limit the amount of soccer heading in training and competitive matches. Therefore, while heading remains an integral part of the game, players are restricted in the amount of training that they can gain on this important skill without potentially harming their long-term wellbeing. The aim of this study was to provide a preliminary investigation into the efficacy of training soccer heading in immersive virtual reality (VR) which allows the practice of the skill without the risk of repetitive head impacts. Thirty-six recreational soccer players were divided into a VR group (n = 18) who trained soccer heading on three occasions over a 7-10-day period in VR and a control group (n = 18) who received no training in soccer heading. Measures of real-world heading performance (i.e. the number of goals scored and shot accuracy), perceived confidence and perceived self-efficacy were assessed pre- and post-training. The results showed that the VR group experienced significant improvements in the number of goals scored and increased their perceptions of confidence and self-efficacy. These results show preliminary support for the inclusion of VR-based training in soccer heading where players can hone their heading skills without exposure to repeated head impacts. Implications and practical applications are discussed.
C1 [Marshall, B.; Uiga, L.; Parr, J. V. V.; Wood, G.] Manchester Metropolitan Univ, Dept Sport & Exercise Sci, Manchester, England.
   [Marshall, B.; Uiga, L.; Parr, J. V. V.; Wood, G.] Manchester Metropolitan Univ Inst Sport, Manchester, England.
C3 Manchester Metropolitan University
RP Marshall, B (corresponding author), Manchester Metropolitan Univ, Dept Sport & Exercise Sci, Manchester, England.; Marshall, B (corresponding author), Manchester Metropolitan Univ Inst Sport, Manchester, England.
EM ben.marshall@mmu.ac.uk
OI Marshall, Ben/0000-0003-2557-5399; Wood, Greg/0000-0003-0851-7090; Parr,
   Johnny/0000-0002-3096-2601; Uiga, Liis/0000-0002-5371-9428
CR Bird JM, 2020, J SPORT PSYCHOL ACTI, V11, P115, DOI 10.1080/21520704.2018.1563573
   Borglund F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21092966
   Caccese JB, 2018, SPORT BIOMECH, V17, P462, DOI 10.1080/14763141.2017.1360385
   Dessing JC, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013161
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Field A, 2018, Discovering Statistics Using IBM SPSS Statistics, Vfifth
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Gray R, 2009, RES Q EXERCISE SPORT, V80, P491
   Gutierrez GM, 2014, PEDIATR EXERC SCI, V26, P33, DOI 10.1123/pes.2013-0102
   Harris D, 2022, INVESTIGATION FEED F
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   Holden MK., 2002, Neurol Rep, V26, P62, DOI DOI 10.1097/01253086-200226020-00003
   Le Noury P, 2022, SPORTS MED, V52, P1473, DOI 10.1007/s40279-022-01669-0
   Long Y, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00783-2
   Mao RDQ, 2021, J SURG RES, V268, P40, DOI 10.1016/j.jss.2021.06.045
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Moritz SE, 2000, RES Q EXERCISE SPORT, V71, P280, DOI 10.1080/02701367.2000.10608908
   Murgia M, 2014, PSYCHOL SPORT EXERC, V15, P642, DOI 10.1016/j.psychsport.2014.07.009
   Pagé C, 2019, J SPORT SCI, V37, P2403, DOI 10.1080/02640414.2019.1638193
   PEPER L, 1994, J EXP PSYCHOL HUMAN, V20, P591, DOI 10.1037/0096-1523.20.3.591
   Quintero LM, 2020, J APPL BEHAV ANAL, V53, P237, DOI 10.1002/jaba.557
   Rao HM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00058
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   Russell ER, 2021, JAMA NEUROL, V78, P1057, DOI 10.1001/jamaneurol.2021.2403
   Freitas JRS, 2021, PSYCHIAT QUART, V92, P1685, DOI 10.1007/s11126-021-09935-6
   Slowinski P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-38204-z
   Snowden T, 2021, J NEUROTRAUM, V38, P169, DOI 10.1089/neu.2020.7130
   The FA, 2021, ENGL FOOTB INTR NEW
   Tirp J., 2015, Psychol Test Assess Model, V57, P57, DOI DOI 10.3389/FPSYG.2017.02183
   Tsai WL, 2022, IEEE T VIS COMPUT GR, V28, P2970, DOI 10.1109/TVCG.2020.3046326
   UEFA, 2020, UEFA HEAD GUID YOUTH
   US Soccer, 2019, US YOUTH SOCC POL PL
   Verhaeghen P, 2003, PSYCHOL AGING, V18, P443, DOI 10.1037/0882-7974.18.3.443
   Vine SJ, 2015, ANXIETY STRESS COPIN, V28, P467, DOI 10.1080/10615806.2014.986722
   Witte K, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.903021
   Wood G, 2021, VIRTUAL REAL-LONDON, V25, P43, DOI 10.1007/s10055-020-00441-x
   Wood G, 2017, J SPORT EXERCISE PSY, V39, P327, DOI 10.1123/jsep.2017-0016
   Wood G, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171782
   Wood G, 2012, PSYCHOL SPORT EXERC, V13, P721, DOI 10.1016/j.psychsport.2012.05.003
NR 39
TC 4
Z9 4
U1 6
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2397
EP 2404
DI 10.1007/s10055-023-00807-x
EA JUN 2023
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:001005080500001
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Jiang, HY
   Weng, DD
   Song, Z
   Dongye, XN
   Zhang, ZL
AF Jiang, Haiyan
   Weng, Dongdong
   Song, Zhen
   Dongye, Xiaonuo
   Zhang, Zhenliang
TI DexHand: dexterous hand manipulation motion synthesis for virtual
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Hand motion; Plausible hand interaction; Hand synthesis; Object
   manipulation; Virtual hand; Neural network; Deep learning
ID CAPTURE; GRASPS
AB Natural object manipulation is one of the important human skills. However, generating natural hand manipulation motions that are adaptive to object shapes and the tasks at hand in virtual reality is still a challenge. In this paper, we propose a neural network-based finger movement generation approach, enabling the generation of plausible hand motions interacting with objects. Given the object shape and movement features in the wrist coordinate system, the first network Generator infers the hand pose at the current frame that matches the object motion and shape. The second network Optimizer then fine-tunes the pose to improve the plausibility of hand-object interaction. Notably, a differentiable optimization module is proposed to generate the training dataset for Optimizer. Experimental results show that our approach can generate plausible dexterous hand manipulation motions for hand-object interaction without obvious delay.
C1 [Jiang, Haiyan; Weng, Dongdong; Dongye, Xiaonuo; Zhang, Zhenliang] Beijing Inst Technol, Beijing Engn Res Ctr Mixed Real & Adv Display, Beijing 100081, Peoples R China.
   [Song, Zhen] Cent Acad Drama, Adv Res Ctr Digitalizat Tradit Drama, Beijing, Peoples R China.
C3 Beijing Institute of Technology; Central Academy of Drama
RP Weng, DD (corresponding author), Beijing Inst Technol, Beijing Engn Res Ctr Mixed Real & Adv Display, Beijing 100081, Peoples R China.; Song, Z (corresponding author), Cent Acad Drama, Adv Res Ctr Digitalizat Tradit Drama, Beijing, Peoples R China.
EM jianghybit@163.com; crgj@bit.edu.cn; songzhen@zhongxi.cn;
   dyxndyxn@163.com; zzlyw10@gmail.com
RI Dongye, Xiaonuo/JHU-1261-2023
FU Beijing Outstanding Young Scientist Program [BJJWZYJH01201910048035];
   National Key R&D Program of China [2018YFB1403901]; National Natural
   Science Foundation of China [62072036]; 111 Project [B18005]
FX This work was supported by the Beijing Outstanding Young Scientist
   Program (BJJWZYJH01201910048035), the National Key R&D Program of China
   (No. 2018YFB1403901), the National Natural Science Foundation of China
   (No. 62072036), and the 111 Project (B18005).
CR Alexanderson S, 2017, COMPUT GRAPH-UK, V69, P59, DOI 10.1016/j.cag.2017.10.001
   Andrychowicz M, 2020, INT J ROBOT RES, V39, P3, DOI 10.1177/0278364919887447
   [Anonymous], 2005, ACM SIGGRAPH EUR S C, DOI DOI 10.1145/1073368.1073413
   Baraff David., 1997, An Introduction to Physically Based Modelling, SIGGRAPH '97 Course Notes, P97
   Boukhayma A, 2019, PROC CVPR IEEE, P10835, DOI 10.1109/CVPR.2019.01110
   Brahmbhatt S, 2019, IEEE INT C INT ROBOT, P2386, DOI [10.1109/IROS40897.2019.8967960, 10.1109/iros40897.2019.8967960]
   Charissis V, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041397
   Clevert D. A., 2015, FAST ACCURATE DEEP N
   Corona E, 2020, PROC CVPR IEEE, P5030, DOI 10.1109/CVPR42600.2020.00508
   Corsaro M, 2021, IEEE INT C INT ROBOT, P4647, DOI 10.1109/IROS51168.2021.9636876
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Delrieu T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P266, DOI [10.1109/VR46266.2020.1581332505844, 10.1109/VR46266.2020.00-58]
   Depierre A, 2018, IEEE INT C INT ROBOT, P3511, DOI 10.1109/IROS.2018.8593950
   El-Khoury S, 2009, IEEE INT CONF ROBOT, P595, DOI 10.1109/ROBOT.2009.5152272
   Garre C., 2011, 2011 IEEE World Haptics Conference (WHC 2011), P239, DOI 10.1109/WHC.2011.5945492
   Grady P, 2021, PROC CVPR IEEE, P1471, DOI 10.1109/CVPR46437.2021.00152
   Höll M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P175, DOI 10.1109/VR.2018.8448284
   Hwang JP, 2021, COMPUT GRAPH FORUM, V40, P266, DOI 10.1111/cgf.14187
   Jarrassé N, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-113
   Jiang HY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P132, DOI 10.1109/ISMAR-Adjunct.2018.00051
   Jiang HW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11087, DOI 10.1109/ICCV48922.2021.01092
   Jorg Sophie, 2020, SIGGR APH '20:ACM SIGGRAPH 2020 Courses, DOI 10.1145/3388769.3407494
   Juan MC, 2023, VIRTUAL REAL-LONDON, V27, P1157, DOI 10.1007/s10055-022-00722-7
   Kingma D. P., 2014, arXiv
   Kokic M, 2019, IEEE INT C INT ROBOT, P3980, DOI [10.1109/iros40897.2019.8967961, 10.1109/IROS40897.2019.8967961]
   Kry PG, 2006, ACM T GRAPHIC, V25, P872, DOI 10.1145/1141911.1141969
   Kumar A., 2021, ARXIV
   Kumar V, 2015, IEEE-RAS INT C HUMAN, P657, DOI 10.1109/HUMANOIDS.2015.7363441
   Li Y, 2007, IEEE T VIS COMPUT GR, V13, P732, DOI [10.1109/TVCG.2007.1033, 10.1109/TVCG.2007.1033.]
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu C.K., 2008, ACM SIGGRAPH EUR S C, P163
   Liu CK, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531365
   Liu HX, 2019, IEEE INT CONF ROBOT, P5180, DOI [10.1109/icra.2019.8794230, 10.1109/ICRA.2019.8794230]
   Liu M, 2019, IEEE INT C INT ROBOT, P1518, DOI [10.1109/iros40897.2019.8968115, 10.1109/IROS40897.2019.8968115]
   Lundell J, 2021, IEEE INT CONF ROBOT, P4495, DOI 10.1109/ICRA48506.2021.9561228
   Miller AT, 2004, IEEE ROBOT AUTOM MAG, V11, P110, DOI 10.1109/MRA.2004.1371616
   Morrison D., 2018, ARXIV
   Mousavian A, 2019, IEEE I CONF COMP VIS, P2901, DOI 10.1109/ICCV.2019.00299
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Murali A, 2020, IEEE INT CONF ROBOT, P6232, DOI [10.1109/ICRA40945.2020.9197318, 10.1109/icra40945.2020.9197318]
   Paszke A, 2019, ADV NEUR IN, V32
   Redmon J, 2015, IEEE INT CONF ROBOT, P1316, DOI 10.1109/ICRA.2015.7139361
   Rosales C, 2012, IEEE INT CONF ROBOT, P550, DOI 10.1109/ICRA.2012.6225238
   Rosalesa C, 2011, P ROB SCI SYST, P289
   Santello M, 1998, J NEUROSCI, V18, P10105
   Spurr A, 2018, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2018.00017
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Supancic JS, 2018, INT J COMPUT VISION, V126, P1180, DOI 10.1007/s11263-018-1081-7
   Taheri Omid, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P581, DOI 10.1007/978-3-030-58548-8_34
   Tian H, 2019, IEEE T VIS COMPUT GR, V25, P2623, DOI 10.1109/TVCG.2018.2849381
   Verschoor M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P183, DOI 10.1109/VR.2018.8447555
   Wheatland N, 2015, COMPUT GRAPH FORUM, V34, P735, DOI 10.1111/cgf.12595
   Wu Z, 2014, ARXIV
   Ye YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185537
   Yuan SX, 2018, PROC CVPR IEEE, P2636, DOI 10.1109/CVPR.2018.00279
   Zhang H, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3448978, 10.1145/3450626.3459830]
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
   Zhang ZL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P739, DOI 10.1109/VR.2018.8446129
   Zhao WP, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508412
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 61
TC 1
Z9 1
U1 6
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2341
EP 2356
DI 10.1007/s10055-023-00810-2
EA MAY 2023
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000997497700001
DA 2024-07-18
ER

PT J
AU Pedram, S
   Kennedy, G
   Sanzone, S
AF Pedram, Shiva
   Kennedy, Grace
   Sanzone, Sal
TI Toward the validation of VR-HMDs for medical education: a systematic
   literature review
SO VIRTUAL REALITY
LA English
DT Review
DE HMD-VR; Virtual reality; Immersive technology; Surgical training;
   Medical training; Systematic review; Requirement; Validation
ID IMMERSIVE VIRTUAL-REALITY; SIMULATION; ENVIRONMENTS
AB The latest technological advancements in the domain of virtual reality (VR) have created new opportunities to use VR as a training platform for medical students and practitioners more broadly. Despite the growing interest in the use of VR as a training tool, a commonly identified gap in VR-training for medical education is the confidence in the long-term validity of the applications. A systematic literature review was undertaken to explore the extent of VR (in particular head-mounted displays) applications for medical training with an additional focus on validation measures. The papers included in this review discussed empirical case studies of specific applications; however, these were mostly concerned with human-computer interaction and were polarized between demonstrating that a conceptual technology solution was feasible for simulation or looked at specific areas of VR usability with little discussion on validation measures for long-term training effectiveness and outcomes. The review uncovered a wide range of ad hoc applications and studies in terms of technology vendors, environments, tasks, envisaged users and effectiveness of learning outcomes. This presents decision-making challenges for those seeking to adopt, implement and embed such systems in teaching practice. The authors of this paper then take a wider socio-technical systems perspective to understand how the holistic training system can be engineered and validated effectively as fit for purpose, through distillation of a generic set of requirements from the literature review to aid design specification and implementation, and to drive more informed and traceable validation of these types of systems. In this review, we have identified 92 requirement statements in 11 key areas against which a VR-HMD training system could be validated; these were grouped into design considerations, learning mechanisms and implementation considerations.
C1 [Pedram, Shiva; Kennedy, Grace] Univ Wollongong, Fac Engn & Informat Sci, SMART Infrastruct Facil, Wollongong, Australia.
   [Sanzone, Sal] Univ Wollongong, Fac Sci Med & Hlth, Sch Med, Wollongong, Australia.
C3 University of Wollongong; University of Wollongong
RP Pedram, S (corresponding author), Univ Wollongong, Fac Engn & Informat Sci, SMART Infrastruct Facil, Wollongong, Australia.
EM spedram@uow.edu.au; gracek@uow.edu.au; sals@uow.edu.au
OI Pedram, Shiva/0000-0002-5835-4093
FU Vantari VR (NSW, Australia); UOW Advantage SME (Wollongong, Australia)
   Tech voucher program
FX This project was funded by Vantari VR (NSW, Australia) and UOW Advantage
   SME (Wollongong, Australia) Tech voucher program, as part of NSW
   treasury Boosting Business Innovation Program. The authors would like to
   thank the personnel of Vantari VR and the UOW Graduate School of
   Medicine for their helpfulness and support.
CR Alavi M, 2001, INFORM SYST RES, V12, P1, DOI 10.1287/isre.12.1.1.9720
   [Anonymous], 2018, 29148 ISOIECIEEE
   [Anonymous], 2002, INNOVATIVE CARE CHRO
   Barteit S, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/29080
   Bernardo A, 2017, WORLD NEUROSURG, V106, P1015, DOI 10.1016/j.wneu.2017.06.140
   Bielsa VF, 2021, J PLAST RECONSTR AES, V74, P2372, DOI 10.1016/j.bjps.2021.03.066
   BLUMENFELD PC, 1992, J EDUC PSYCHOL, V84, P272, DOI 10.1037/0022-0663.84.3.272
   Bracq MS, 2021, NURSE EDUC PRACT, V53, DOI 10.1016/j.nepr.2021.103056
   Bracq MS, 2019, NURS EDUC TODAY, V79, P153, DOI 10.1016/j.nedt.2019.05.026
   Breitkreuz KR, 2021, CLIN SIMUL NURS, V53, P49, DOI 10.1016/j.ecns.2020.10.003
   Chang CW, 2019, IEEE ACCESS, V7, P43637, DOI 10.1109/ACCESS.2019.2905143
   Chheang V, 2021, COMPUT GRAPH-UK, V99, P234, DOI 10.1016/j.cag.2021.07.009
   Corrêa CG, 2019, MED ENG PHYS, V63, P6, DOI 10.1016/j.medengphy.2018.11.002
   CSIKSZENTMIHALYI M, 1990, DAEDALUS, V119, P115
   Duh HBL, 2004, PRESENCE-TELEOP VIRT, V13, P578, DOI 10.1162/1054746042545283
   Fairén M, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01550-5
   Fox J., 2009, J MEDIA PSYCHOL-GER, V21, P95, DOI DOI 10.1027/1864-1105.21.3.95
   Gelardi L, 2020, HLTH SIMULATION
   Hattab G, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-92536-x
   Huber T, 2018, INT J COMPUT ASS RAD, V13, P281, DOI 10.1007/s11548-017-1686-2
   Huber T, 2017, SURG ENDOSC, V31, P4472, DOI 10.1007/s00464-017-5500-6
   INTERNATIONAL ORGANIZATION FOR STANDARDIZATION, 2018, ISO9241211
   INTERNATIONAL ORGANIZATION FOR STANDARDIZATION, 2016, ISO134852016
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Jou M, 2013, COMPUT HUM BEHAV, V29, P433, DOI 10.1016/j.chb.2012.04.020
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kenngott HG, 2022, SURG ENDOSC, V36, P126, DOI 10.1007/s00464-020-08246-4
   Koppell J., 2011, Handb Transnatl Gov Inst Innov, V41, P289
   LeClair B, 2018, INT J IND ERGONOM, V64, P23, DOI 10.1016/j.ergon.2017.10.001
   Lin PH, 2019, INT J HUM-COMPUT INT, V35, P1736, DOI 10.1080/10447318.2019.1571784
   Lohre Ryan, 2020, JSES Int, V4, P215, DOI 10.1016/j.jseint.2020.02.005
   Lopes A, INT C DES US EXP US, P499
   Lopes A, 2017, DESIGN USER EXPERIEN
   Mäkinen H, 2022, BEHAV INFORM TECHNOL, V41, P1, DOI 10.1080/0144929X.2020.1788162
   Makransky G, 2019, COMPUT EDUC, V134, P15, DOI 10.1016/j.compedu.2019.02.002
   Mao RDQ, 2021, J SURG RES, V268, P40, DOI 10.1016/j.jss.2021.06.045
   Masuoka Yoshihito, 2019, JMIR Med Educ, V5, pe11921, DOI 10.2196/11921
   Matthews S, 2021, 2021 7TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN), P192, DOI 10.23919/iLRN52045.2021.9459383
   Mayer RE, 2014, ACKNOWLEDGMENTS DEDI, V59
   McKnight RR, 2020, CURR REV MUSCULOSKE, V13, P663, DOI 10.1007/s12178-020-09667-3
   Mehrotra Divya, 2021, J Oral Biol Craniofac Res, V11, P486, DOI 10.1016/j.jobcr.2021.06.002
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Nilsson NC, 2015, P IEEE VIRT REAL ANN, P249, DOI 10.1109/VR.2015.7223389
   Nutakor D., 2008, Design and evaluation of a virtual reality training system for new underground rockbolters
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Papagiannakis G, 2020, ACM SIGGRAPH 2020 IM, P1
   Pedram S, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.941225
   Pedram S, 2021, VIRTUAL REAL-LONDON, V25, P1071, DOI 10.1007/s10055-021-00514-5
   Pedram S, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103891
   Pelargos PE, 2017, J CLIN NEUROSCI, V35, P1, DOI 10.1016/j.jocn.2016.09.002
   Pithers R.Thomas., 1998, IMPROVING LEARNING E
   Plotzky C, 2021, NURS EDUC TODAY, V101, DOI 10.1016/j.nedt.2021.104868
   Rahman R, 2020, SURG INNOV, V27, P88, DOI 10.1177/1553350619871787
   Renganayagalu SK, 2021, TECHNOL KNOWL LEARN, V26, P999, DOI 10.1007/s10758-020-09489-9
   Sillitto H., 2019, INCOSE
   Silva JNA, 2018, JACC-BASIC TRANSL SC, V3, P420, DOI 10.1016/j.jacbts.2017.11.009
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Tcha-Tokey K, 2018, ADV HUM-COMPUT INTER, V2018, DOI 10.1155/2018/7827286
   van Eck N.J., 2010, VOSVIEWER VISUALIZIN
   Vaughan N, 2016, MED ENG PHYS, V38, P59, DOI 10.1016/j.medengphy.2015.11.021
   Webster J, 1997, ACAD MANAGE J, V40, P1282, DOI 10.5465/257034
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xu XH, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P328
   Yamazaki A, 2021, AURIS NASUS LARYNX, V48, P1081, DOI 10.1016/j.anl.2021.03.009
   Yan Y, 2019, ADV INTELL SYST, V777, P239, DOI 10.1007/978-3-319-94706-8_27
NR 66
TC 6
Z9 6
U1 20
U2 39
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2255
EP 2280
DI 10.1007/s10055-023-00802-2
EA MAY 2023
PG 26
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000986434800001
PM 37360815
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Chang, E
   Billinghurst, M
   Yoo, B
AF Chang, Eunhee
   Billinghurst, Mark
   Yoo, Byounghyun
TI Brain activity during cybersickness: a scoping review
SO VIRTUAL REALITY
LA English
DT Review
DE Cybersickness; VR sickness; Electroencephalogram; Virtual reality
ID VISUALLY INDUCED MOTION; EEG; SICKNESS; FREQUENCY; AGE; SEVERITY; GENDER
AB Virtual reality (VR) experiences can cause a range of negative symptoms such as nausea, disorientation, and oculomotor discomfort, which is collectively called cybersickness. Previous studies have attempted to develop a reliable measure for detecting cybersickness instead of using questionnaires, and electroencephalogram (EEG) has been regarded as one of the possible alternatives. However, despite the increasing interest, little is known about which brain activities are consistently associated with cybersickness and what types of methods should be adopted for measuring discomfort through brain activity. We conducted a scoping review of 33 experimental studies in cybersickness and EEG found through database searches and screening. To understand these studies, we organized the pipeline of EEG analysis into four steps (preprocessing, feature extraction, feature selection, classification) and surveyed the characteristics of each step. The results showed that most studies performed frequency or time-frequency analysis for EEG feature extraction. A part of the studies applied a classification model to predict cybersickness indicating an accuracy between 79 and 100%. These studies tended to use HMD-based VR with a portable EEG headset for measuring brain activity. Most VR content shown was scenic views such as driving or navigating a road, and the age of participants was limited to people in their 20 s. This scoping review contributes to presenting an overview of cybersickness-related EEG research and establishing directions for future work.
C1 [Chang, Eunhee; Billinghurst, Mark] Univ South Australia, Empath Comp Lab, Mawson Lakes, SA, Australia.
   [Yoo, Byounghyun] Korea Inst Sci & Technol, Ctr Artificial Intelligence, 5 Hwarangro14 Gil, Seoul 02792, South Korea.
   [Yoo, Byounghyun] Korea Univ Sci & Technol, KIST Sch, Artificial Intelligence & Robot, 5 Hwarangro 14 Gil, Seoul 02792, South Korea.
C3 University of South Australia; Korea Institute of Science & Technology
   (KIST); Korea Institute of Science & Technology (KIST)
RP Yoo, B (corresponding author), Korea Inst Sci & Technol, Ctr Artificial Intelligence, 5 Hwarangro14 Gil, Seoul 02792, South Korea.; Yoo, B (corresponding author), Korea Univ Sci & Technol, KIST Sch, Artificial Intelligence & Robot, 5 Hwarangro 14 Gil, Seoul 02792, South Korea.
EM eunhee.chang@unisa.edu.au; mark.billinghurst@unisa.edu.au; yoo@byoo.net
RI Yoo, Byounghyun/C-8404-2009; Billinghurst, Mark/AAJ-4236-2020
OI Yoo, Byounghyun/0000-0001-9299-349X; Billinghurst,
   Mark/0000-0003-4172-6759
FU Industrial Technology Innovation Program - Ministry of Trade, Industry &
   Energy (MOTIE, Korea) [20012462]; National Research Foundation of Korea
   (NRF) - Korea government (MSIT) [NRF-2021R1A2C2093065,
   NRF-2021R1A6A3A14039652]
FX This work was supported by the Industrial Technology Innovation Program
   (20012462) funded by the Ministry of Trade, Industry & Energy (MOTIE,
   Korea) and the National Research Foundation of Korea (NRF) grant
   (NRF-2021R1A2C2093065 and NRF-2021R1A6A3A14039652) funded by the Korea
   government (MSIT).
CR Ahn MH, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.600839
   Ambrosini E, 2016, NEUROIMAGE, V124, P843, DOI 10.1016/j.neuroimage.2015.09.035
   Arafat IM, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P113, DOI 10.1109/VR.2018.8446194
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Arsalan Naqvi SyedAli., 2014, Intelligent and Advanced Systems (ICIAS), 2014 5th International Conference on, P1
   Ball C, 2021, TELEMAT INFORM, V65, DOI 10.1016/j.tele.2021.101728
   Bigdely-Shamlo N, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00016
   Bos JE, 2010, APPL ERGON, V41, P516, DOI 10.1016/j.apergo.2009.11.007
   Celikcan U, 2019, 2019 3 INT S MULTIDI, P1, DOI [10.1109/ISMSIT.2019.8932870, DOI 10.1109/ISMSIT.2019.8932870]
   Chang E, 2022, VIRTUAL REAL-LONDON, V26, P1193, DOI 10.1007/s10055-021-00622-2
   Chang E, 2021, J COMPUT DES ENG, V8, P728, DOI 10.1093/jcde/qwab010
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chang E, 2013, INT WINT WORKSH BR, P62, DOI 10.1109/IWW-BCI.2013.6506631
   Chen J, 2017, NEUROPSYCHOLOGIA, V102, P206, DOI 10.1016/j.neuropsychologia.2017.06.024
   Chen YC, 2010, NEUROIMAGE, V49, P2862, DOI 10.1016/j.neuroimage.2009.10.005
   Choi MH, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P20
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Dennison M, 2019, PROC SPIE, V11006, DOI 10.1117/12.2519085
   Dianatfar Morteza, 2023, Flexible Automation and Intelligent Manufacturing: The Human-Data-Technology Nexus: Proceedings of FAIM 2022. Lecture Notes in Mechanical Engineering, P246, DOI 10.1007/978-3-031-18326-3_25
   Garcia-Agundez A, 2019, GAMES HEALTH J, V8, P439, DOI 10.1089/g4h.2019.0045
   Gumilar I, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519746
   Halbig A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694567
   Heo J, 2020, J ELECTR ENG TECHNOL, V15, P1323, DOI 10.1007/s42835-020-00373-1
   Jeong DK, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3283387
   Jeong D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P827, DOI [10.1109/VR.2019.8798334, 10.1109/vr.2019.8798334]
   Kaushik P, 2019, IEEE SENS J, V19, P2634, DOI 10.1109/JSEN.2018.2885582
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Khoirunnisaa AZ, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (IBIOMED), P48, DOI 10.1109/IBIOMED.2018.8534877
   Kim JY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122501
   Kim J, 2019, IEEE I CONF COMP VIS, P10579, DOI 10.1109/ICCV.2019.01068
   Kim YY, 2008, PRESENCE-TELEOP VIRT, V17, P1, DOI 10.1162/pres.17.1.1
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Knight M. M., 2006, ACM SIGGRAPH 2006 Res Posters, DOI [10.1145/1179622.1179846, DOI 10.1145/1179622.1179846]
   Ko LW, 2013, 2013 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE, COGNITIVE ALGORITHMS, MIND, AND BRAIN (CCMB), P158, DOI 10.1109/CCMB.2013.6609180
   Krokos E, 2022, VIRTUAL REAL-LONDON, V26, P77, DOI 10.1007/s10055-021-00517-2
   Kusumandari DE, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON TECHNOLOGY, INFORMATICS, MANAGEMENT, ENGINEERING, AND ENVIRONMENT (TIME-E 2014), P335, DOI 10.1109/TIME-E.2014.7011642
   Lee CC, 2021, J SUPERCOMPUT, V77, P4831, DOI 10.1007/s11227-020-03458-w
   Lee S, 2019, IEEE IMAGE PROC, P440, DOI [10.1109/icip.2019.8802983, 10.1109/ICIP.2019.8802983]
   Lee Y. M., 2019, P 10 INT DRIV S HUM, P252, DOI [10.17077/drivingassessment, DOI 10.17077/DRIVINGASSESSMENT, DOI 10.17077/DRIVINGASSESSMENT.1703]
   Lee Y, 2020, IEEE INT C BIOINF BI, P538, DOI 10.1109/BIBE50027.2020.00093
   Lee Y, 2021, J COMPUT DES ENG, V8, P756, DOI 10.1093/jcde/qwab012
   Li XL, 2020, COMPUT METH PROG BIO, V188, DOI 10.1016/j.cmpb.2019.105266
   Li Y, 2019, BIOMED SIGNAL PROCES, V49, P202, DOI 10.1016/j.bspc.2018.12.007
   Liao CY, 2020, IEEE ACCESS, V8, P126784, DOI 10.1109/ACCESS.2020.3008165
   Lin CT, 2007, P ANN INT IEEE EMBS, P3872, DOI 10.1109/IEMBS.2007.4353178
   Liu R, 2020, J IMAGING SCI TECHN, V64, DOI 10.2352/J.ImagingSci.Technol.2020.64.2.020501
   Luck S. J., 2005, INTRO EVENT RELATED, DOI DOI 10.1007/S10409-008-0217-3
   Ma YQ, 2021, PSYCHOPHYSIOLOGY, V58, DOI 10.1111/psyp.13893
   Matsushita Y, 2021, J COMPUT DES ENG, V8, P1499, DOI 10.1093/jcde/qwab054
   Mawalid MA, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING, NETWORK AND INTELLIGENT MULTIMEDIA (CENIM), P29, DOI 10.1109/CENIM.2018.8711320
   Michel CM, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00325
   Morgan ML, 2005, NEUROPSYCHOBIOLOGY, V52, P71, DOI 10.1159/000086608
   Naqvi SAA, 2015, AUSTRALAS PHYS ENG S, V38, P721, DOI 10.1007/s13246-015-0379-9
   Oh SH, 2018, I C INF COMM TECH CO, P568, DOI 10.1109/ICTC.2018.8539479
   Pane ES, 2018, INT CONF INTEL INFOR, P170, DOI 10.1109/ICIIBMS.2018.8549968
   Park S, 2022, VIRTUAL REAL-LONDON, V26, P979, DOI 10.1007/s10055-021-00600-8
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   REGAN EC, 1994, AVIAT SPACE ENVIR MD, V65, P527
   Richer N, 2020, IEEE T NEUR SYS REH, V28, P1825, DOI 10.1109/TNSRE.2020.3000971
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Shao SY, 2011, CLIN NEUROPHYSIOL, V122, P1838, DOI 10.1016/j.clinph.2011.02.014
   Srinivasan R, 1998, BEHAV RES METH INS C, V30, P8, DOI 10.3758/BF03209412
   Stradford J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.639478
   Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850
   Wang G., 2021, LECT NOTES COMPUTER, V12776, P97, DOI [10.1007/978-3-030-78114-9_8, DOI 10.1007/978-3-030-78114-9_8, 10.1007/978-3-030-78114-9]
   Weber D, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.733673
   Wei CS, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P365, DOI 10.1109/IJCNN.2011.6033244
   Wei Y, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116028
   Wibirama S, 2020, VIRTUAL REAL-LONDON, V24, P39, DOI 10.1007/s10055-019-00386-w
   Wu JT, 2020, INT J IND ERGONOM, V78, DOI 10.1016/j.ergon.2020.102981
   Yi-Tien Lin, 2018, SID Symposium Digest of Technical Papers, V49, P862, DOI 10.1002/sdtp.12267
   Yildirim C, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P351, DOI 10.1109/AIVR50618.2020.00072
   Yuval-Greenberg S, 2008, NEURON, V58, P429, DOI 10.1016/j.neuron.2008.03.027
NR 74
TC 8
Z9 8
U1 9
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2073
EP 2097
DI 10.1007/s10055-023-00795-y
EA APR 2023
PG 25
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000968151700001
PM 37360812
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Chen, JJ
   Zhou, YT
   Zhai, JQ
AF Chen, Juanjuan
   Zhou, Yuting
   Zhai, Junqing
TI Incorporating AR/VR-assisted learning into informal science
   institutions: A systematic review
SO VIRTUAL REALITY
LA English
DT Review
DE Augmented and virtual reality; Informal science institutions; Learning
   outcomes; Science centres; Science museums
ID AUGMENTED REALITY; VIRTUAL-REALITY; ENVIRONMENTS; EDUCATION; TECHNOLOGY;
   MUSEUMS; LABORATORIES; ENGAGEMENT; SCAFFOLDS; KNOWLEDGE
AB Virtual reality (VR) and augmented reality (AR) technologies have been used in informal science institutions such as science centres, science museums, zoos, botanical gardens, and aquariums to provide visitors with engaging and appealing learning experiences. However, there is a lack of systematic reviews to synthesise the contexts in which such technologies have been applied, how AR/VR-assisted learning is designed, and what learning outcomes have commonly been reported in such learning contexts. A total of 22 studies were identified for this review. We find, first, that AR and VR have been primarily used in science museums and biology learning, mainly for learning content knowledge. Learning activities supported by AR typically involve the scientific observation of phenomena or objects. Second, AR and VR are often used to superimpose supplementary materials onto exhibits and simulate scientific phenomena or visually present abstract concepts. Mobile devices are more prevalent than head-mounted displays or other techniques. Third, perceptions and knowledge achievement are typically measured outcomes, and incorporating AR and VR has the potential to promote academic achievement and perceptions. Several implications are provided for future research.
C1 [Chen, Juanjuan; Zhou, Yuting; Zhai, Junqing] Zhejiang Univ, Sch Educ, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Zhai, JQ (corresponding author), Zhejiang Univ, Sch Educ, Hangzhou 310058, Peoples R China.
EM jqzhai@zju.edu.cn
RI CHEN, Juanjuan/N-2586-2019
OI CHEN, Juanjuan/0000-0002-1273-9465; Zhai, Junqing/0000-0003-1810-7466
FU Zhejiang Federation of Humanities & Social Sciences [22NDJC005Z];
   National Natural Science Foundation of China [72274171]
FX AcknowledgementsThis study was funded by the Zhejiang Federation of
   Humanities & Social Sciences (22NDJC005Z) and National Natural Science
   Foundation of China (72274171).
CR Abich J IV, 2021, VIRTUAL REAL-LONDON, V25, P919, DOI 10.1007/s10055-020-00498-8
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Anderson D, 2000, SCI EDUC, V84, P658, DOI 10.1002/1098-237X(200009)84:5<658::AID-SCE6>3.0.CO;2-A
   Araiza-Alba P, 2021, COMPUT EDUC, V164, DOI 10.1016/j.compedu.2020.104121
   Arici F, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103647
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Behrendt M., 2014, International Journal of Environmental Science Education, V9, P235, DOI [DOI 10.12973/IJESE.2014.213A, 10.12973/ijese.2014.213A, DOI 10.12973/IJESE.2014.213]
   Bettelli A, 2020, ANN REV CYBERTHERAPY, V18, P57
   Bower M, 2014, EDUC MEDIA INT, V51, P1, DOI 10.1080/09523987.2014.889400
   Boyce CJ, 2014, J SCI EDUC TECHNOL, V23, P815, DOI 10.1007/s10956-014-9514-8
   Cai S, 2013, INT J ENG EDUC, V29, P856
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Carter M, 2020, J ZOO AQUAR RES, V8, P239, DOI 10.19227/jzar.v8i4.500
   Chen JJ, 2018, REV EDUC RES, V88, P799, DOI 10.3102/0034654318791584
   Chernikova O, 2020, REV EDUC RES, V90, P499, DOI 10.3102/0034654320933544
   Chiu JL, 2015, COMPUT EDUC, V85, P59, DOI 10.1016/j.compedu.2015.02.007
   Crowley K, 2014, CAMBRIDGE HANDBOOK OF THE LEARNING SCIENCES, 2ND EDITION, P461
   de Jong T, 2013, SCIENCE, V340, P305, DOI 10.1126/science.1230579
   de Rijcke S, 2011, LIBR TRENDS, V59, P663, DOI 10.1353/lib.2011.0020
   Dudzik B, 2018, THESIS U WASHINGTON
   Eshach H., 2007, J SCI ED TECHNOLOGY, V16, P171, DOI [DOI 10.1007/S10956-006-9027-1, 10.1007/s10956-006-9027-1]
   Falk J. H., 2000, Learning from museums: Visitor Experiences and the making of meaning
   Falk J.H., 2008, Digital technologies and the museum experience, P19
   Falk JH, 2016, SCI EDUC, V100, P849, DOI 10.1002/sce.21225
   Bernarduzzi LF, 2021, SCI EDUC-NETHERLANDS, V30, P755, DOI 10.1007/s11191-021-00197-z
   Fu QK, 2018, COMPUT EDUC, V119, P129, DOI 10.1016/j.compedu.2018.01.004
   Garzón J, 2019, VIRTUAL REAL-LONDON, V23, P447, DOI 10.1007/s10055-019-00379-9
   Hall T, 2006, J COMPUT ASSIST LEAR, V22, P231, DOI 10.1111/j.1365-2729.2006.00177.x
   Harrington MCR, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P813, DOI [10.1109/VRW50115.2020.00-18, 10.1109/VRW50115.2020.00257]
   Hsiao HS, 2016, INTERACT LEARN ENVIR, V24, P205, DOI 10.1080/10494820.2013.834829
   Hsu TY, 2018, DATA TECHNOL APPL, V52, P294, DOI 10.1108/DTA-05-2016-0042
   Huang TC, 2016, COMPUT EDUC, V96, P72, DOI 10.1016/j.compedu.2016.02.008
   Ishida T, 2019, INT J SPACE-BASED SI, V9, P61
   Kisiel J.F., 2006, Science Teacher, V73, P46
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Kyndt E, 2013, EDUC RES REV-NETH, V10, P133, DOI 10.1016/j.edurev.2013.02.002
   Lin W, 2019, 2019 12TH ASIA PACIFIC WORKSHOP ON MIXED AND AUGMENTED REALITY (APMAR), P43, DOI 10.1109/apmar.2019.8709286
   Makransky G, 2018, ETR&D-EDUC TECH RES, V66, P1141, DOI 10.1007/s11423-018-9581-2
   Mayer RE, 2009, MULTIMEDIA LEARNING, 2ND EDITION, P1, DOI 10.1017/CBO9780511811678
   Mayer R. E., 2014, The Cambridge handbook of multimedia learning, V2nd, P31, DOI [https://doi.org/10.1017/CBO9781139547369.005, DOI 10.1017/CBO9780511816819.004, 10.1017/cbo9780511816819.004]
   Mayer RE, 2020, LEARN INSTR, V70, DOI 10.1016/j.learninstruc.2019.05.010
   Mayer RE, 2014, LEARN INSTR, V33, P12, DOI 10.1016/j.learninstruc.2014.02.004
   Meekaew N, 2018, 2018 7TH INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS (IIAI-AAI 2018), P250, DOI 10.1109/IIAI-AAI.2018.00055
   Merchant Z, 2012, COMPUT EDUC, V59, P551, DOI 10.1016/j.compedu.2012.02.004
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Moher D, 2016, SYST REV-LONDON, V5, DOI 10.1186/s13643-016-0191-y
   Morélot S, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104145
   Mujtaba T, 2018, STUD SCI EDUC, V54, P41, DOI 10.1080/03057267.2018.1442820
   Natl Res Council, 2009, LEARNING SCIENCE IN INFORMAL ENVIRONMENTS: PEOPLE, PLACES, AND PURSUITS, P1
   Ogi T, 2019, 21 INT C NETWORK BAS
   Oh S, 2018, IEEE T LEARN TECHNOL, V11, P115, DOI 10.1109/TLT.2017.2750673
   Osborne J, 2007, INT J SCI EDUC, V29, P1441, DOI 10.1080/09500690701491122
   Patle DS, 2019, VIRTUAL REAL-LONDON, V23, P293, DOI 10.1007/s10055-018-0354-3
   Pellas N, 2019, VIRTUAL REAL-LONDON, V23, P329, DOI 10.1007/s10055-018-0347-2
   Puig A, 2020, VIRTUAL REAL-LONDON, V24, P343, DOI 10.1007/s10055-019-00391-z
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Reeves SM, 2021, COMPUT EDUC, V175, DOI 10.1016/j.compedu.2021.104320
   Renganayagalu SK, 2021, TECHNOL KNOWL LEARN, V26, P999, DOI 10.1007/s10758-020-09489-9
   Rennie LJ, 2014, HANDBOOK OF RESEARCH ON SCIENCE EDUCATION, VOL II, P120
   Rosenbaum E., 2007, Journal of Science Education and Technology, V16, P31, DOI DOI 10.1007/S10956-006-9036-0
   Salmi H, 2017, INT J SCI EDUC PART, V7, P253, DOI 10.1080/21548455.2016.1254358
   Sandifer C, 2003, J RES SCI TEACH, V40, P121, DOI 10.1002/tea.10068
   Savela N, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041392
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Schäfer MS, 2009, SCI COMMUN, V30, P475, DOI 10.1177/1075547008326943
   Schwan S, 2014, EDUC PSYCHOL-US, V49, P70, DOI 10.1080/00461520.2014.917588
   Shaby N, 2021, SCI EDUC, V105, P938, DOI 10.1002/sce.21666
   Smith JW, 2015, INT J ENV RES PUB HE, V12, P11486, DOI 10.3390/ijerph120911486
   Sommerauer P, 2014, COMPUT EDUC, V79, P59, DOI 10.1016/j.compedu.2014.07.013
   Sugiura A, 2019, ANAT SCI EDUC, V12, P561, DOI 10.1002/ase.1822
   Sultan L, 2019, ADV MED EDUC PRACT, V10, P907, DOI 10.2147/AMEP.S219344
   Takahashi TB, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P385, DOI 10.1109/SITIS.2013.69
   Tenenbaum HR, 2015, SCI EDUC, V99, P1073, DOI 10.1002/sce.21184
   Tscholl M, 2016, SCI EDUC, V100, P877, DOI 10.1002/sce.21228
   Wang JS, 2014, THESIS U PENNSYLVANI
   Weingart P, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0254201
   Yoon S, 2017, EDUC TECHNOL SOC, V20, P156
   Yoon SA, 2018, RES SCI TECHNOL EDUC, V36, P261, DOI 10.1080/02635143.2017.1386645
   Yoon SA, 2014, TECHTRENDS, V58, P49, DOI 10.1007/s11528-013-0720-7
   Yoon SA, 2013, SCI EDUC, V97, P848, DOI 10.1002/sce.21079
   Yoon SA, 2012, INT J COMP-SUPP COLL, V7, P519, DOI 10.1007/s11412-012-9156-x
   Zimmerman HT, 2016, ADV INTELL SYST COMP, V406, P101, DOI 10.1007/978-3-319-26518-6_4
NR 83
TC 4
Z9 4
U1 20
U2 82
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 1985
EP 2001
DI 10.1007/s10055-023-00789-w
EA MAR 2023
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000952093900001
DA 2024-07-18
ER

PT J
AU Zhang, L
   He, WP
   Bai, HD
   Zou, QY
   Wang, SX
   Billinghurst, M
AF Zhang, Li
   He, Weiping
   Bai, Huidong
   Zou, Qianyuan
   Wang, Shuxia
   Billinghurst, Mark
TI A hybrid 2D-3D tangible interface combining a smartphone and controller
   for virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Hybrid interface; Virtual reality; Interaction paradigm; Tangible
   interface; Smartphone; Controller
ID IMPACT
AB Virtual reality (VR) controllers are widely used for 3D virtual object selection and manipulation in immersive virtual worlds, while touchscreen-based devices like smartphones or tablets provide precise 2D tangible input. However, VR controllers and touchscreens are used separately in most cases. This research physically integrates a VR controller and a smartphone to create a hybrid 2D-3D tangible interface for VR interactions, combining the strength of both devices. The hybrid interface inherits physical buttons, 3D tracking, and spatial input from the VR controller while having tangible feedback, 2D precise input, and content display from the smartphone's touchscreen. We review the capabilities of VR controllers and smartphones to summarize design principles and then present a design space with nine typical interaction paradigms for the hybrid interface. We developed an interactive prototype and three application modes to demonstrate the combination of individual interaction paradigms in various VR scenarios. We conducted a formal user study through a guided walkthrough to evaluate the usability of the hybrid interface. The results were positive, with participants reporting above-average usability and rating the system as excellent on four out of six user experience questionnaire scales. We also described two use cases to demonstrate the potential of the hybrid interface.
C1 [Zhang, Li; He, Weiping; Wang, Shuxia] Northwestern Polytech Univ, Cyber Phys Interact Lab, 127 West Youyi Rd, Xian 710072, Peoples R China.
   [Bai, Huidong; Zou, Qianyuan; Billinghurst, Mark] Univ Auckland, Auckland Bioengn Inst, 70 Symonds St, Auckland 1010, New Zealand.
C3 Northwestern Polytechnical University; University of Auckland
RP Zhang, L; He, WP (corresponding author), Northwestern Polytech Univ, Cyber Phys Interact Lab, 127 West Youyi Rd, Xian 710072, Peoples R China.
EM zhl93@mail.nwpu.edu.cn; weiping@nwpu.edu.cn; huidong.bai@auckland.ac.nz;
   qzou984@aucklanduni.ac.nz; shuxiaw@nwpu.edu.cn;
   mark.billinghurst@auckland.ac.nz
RI Billinghurst, Mark/AAJ-4236-2020
OI Billinghurst, Mark/0000-0003-4172-6759; Zou,
   Qianyuan/0000-0003-2568-1925
FU National Key R &D Program of China [2019YFB1703800, 2021YFB1714900,
   2021YFB1716200, 2020YFB1712503]; Programme of Introducing Talents of
   Discipline to Universities (111 Project), China [B13044]; Fundamental
   Research Funds for the Central Universities, NPU [3102020gxb003]
FX This work was partially supported by the National Key R &D Program of
   China (Grant Nos. 2019YFB1703800, 2021YFB1714900, 2021YFB1716200,
   2020YFB1712503), the Programme of Introducing Talents of Discipline to
   Universities (111 Project), China (Grant No. B13044), the Fundamental
   Research Funds for the Central Universities, NPU (Grant No.
   3102020gxb003)
CR Afonso L, 2017, IEEE SYMP 3D USER, P247, DOI 10.1109/3DUI.2017.7893364
   Alaee G., 2018, IEEE VRS 4 WORKSH EV, P10
   [Anonymous], 2008, P 20 AUSTR C COMP HU, P331, DOI DOI 10.1145/1517744.1517810
   Babic T, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P2, DOI 10.1145/3267782.3267785
   Bai HD, 2021, COMPUT GRAPH-UK, V97, P42, DOI 10.1016/j.cag.2021.04.004
   Bai Huidong, 2017, ICAT EGVE, P83
   Bergé LP, 2014, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'14), P125, DOI 10.1145/2628363.2628374
   Besançon L, 2017, IEEE T VIS COMPUT GR, V23, P881, DOI 10.1109/TVCG.2016.2599217
   Biener V, 2020, IEEE T VIS COMPUT GR, V26, P3490, DOI 10.1109/TVCG.2020.3023567
   Billinghurst M., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P155, DOI 10.1145/261135.261163
   Bornik A, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P29, DOI 10.1109/TRIDUI.2006.1618267
   Boustila S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P860, DOI [10.1109/VR.2019.8798238, 10.1109/vr.2019.8798238]
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bragdon Andrew., 2011, Proceedings of the International Conference on Interactive Tabletops and Surfaces (ITS'11), P212, DOI DOI 10.1145/2076354.2076393
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Büschel W, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'19), DOI 10.1145/3338286.3340113
   Chang YK, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281567
   Chen SB, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312762
   Cheng LP, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186482
   Cho Isaac, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P133, DOI 10.1109/3DUI.2015.7131738
   de Haan G., 2006, EUROGRAPHICS S VIRTU, P109
   Desai AP, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P217, DOI 10.1109/CRV.2017.16
   Dong ZY, 2021, ENVIRON SCI POLLUT R, V28, P2415, DOI [10.1145/3416315.3416316, 10.1007/s11356-020-10651-0]
   Drey T., 2020, P 2020 CHI C HUM FAC, P1, DOI [10.1145/3313831.3376628, DOI 10.1145/3313831.3376628]
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P151, DOI 10.1109/VR.2018.8446250
   Gugenheimer J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P49, DOI 10.1145/2984511.2984576
   GUIARD Y., 1988, Cognition and Action in Skilled Behaviour, P205, DOI DOI 10.1016/S0166-4115(08)60623-8
   Hartmann J, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188535
   Hoppe M, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P7, DOI 10.1145/3282894.3282898
   Huang YJ, 2021, INT J HUM-COMPUT INT, V37, P169, DOI 10.1080/10447318.2020.1809248
   Issartel P, 2017, PRESENCE-TELEOP VIRT, V26, P66, DOI 10.1162/PRES_a_00287
   Jetter HC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376652
   Kim H, 2014, INT CONF UBIQ ROBOT, P324, DOI 10.1109/URAI.2014.7057534
   Kim MJ, 2008, HUM-COMPUT INTERACT, V23, P101, DOI 10.1080/07370020802016415
   Kim YR, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P333, DOI 10.1145/2993369.2996330
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Le HuyViet., 2016, P 2016 CHI C EXTENDE, P2576
   Lee CJ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281618
   Lei Gao, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P629, DOI 10.1145/3441000.3441038
   Liang HN, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P455, DOI 10.1145/3013971.3014005
   Lindeman RW, 1999, P IEEE VIRT REAL ANN, P205, DOI 10.1109/VR.1999.756952
   Ma XY, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P263, DOI 10.1145/3172944.3172988
   Manuri F, 2015, PROCEEDINGS OF THE 2015 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNOLOGIES FOR INTERACTIVE ENTERTAINMENT, P37, DOI 10.4108/icst.intetain.2015.259629
   Matulic Fabrice., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3411764.3445583
   Mezner T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P372, DOI [10.1109/VR46266.2020.00-47, 10.1109/VR46266.2020.1581107639032]
   Millette A, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P21, DOI [10.1109/ISMAR-Adjunct.2016.23, 10.1109/ISMAR-Adjunct.2016.0030]
   Mine M., 2014, ACM Symposium on Spatial User Interaction, P80
   Mohr P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300815
   Normand E, 2018, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2018.00043
   Schmidt Dominik., 2012, P DESIGNING INTERACT, P318
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Sharmila A., 2021, Journal of Medical Engineering & Technology, V45, P6, DOI 10.1080/03091902.2020.1838642
   Sommer B, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Steed A, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P43, DOI 10.1109/3DUI.2013.6550195
   Surale HB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300243
   Takashina T, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P449, DOI 10.1145/3279778.3279921
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vanukuru R., 2020, 26 ACM S VIRTUAL REA, DOI [10.1145/3385956.3422113, DOI 10.1145/3385956.3422113]
   Ventura J, 2014, IEEE T VIS COMPUT GR, V20, P531, DOI 10.1109/TVCG.2014.27
   Vinayak, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P12, DOI 10.1145/2839462.2839490
   Wang SX, 2021, INT SYM MIX AUGMENT, P362, DOI 10.1109/ISMAR-Adjunct54149.2021.00082
   Wang SX, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P156, DOI 10.1109/ISMAR-Adjunct.2019.00-58
   Zhang L, 2021, SIGGRAPH ASIA 2021 P, DOI [10.1145/3476124.3488636, DOI 10.1145/3476124.3488636]
   Zhang L, 2021, SIGGRAPH '21: ACM SIGGRAPH 2021 POSTERS, DOI 10.1145/3450618.3469166
   Zhang L, 2021, INT SYM MIX AUGMENT, P321, DOI 10.1109/ISMAR-Adjunct54149.2021.00072
   Zhang Li, 2020, SIGGRAPH ASIA 2020 X, DOI [10.1145/3415256.3421499, DOI 10.1145/3415256.3421499]
   Zhu FY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376233
NR 69
TC 1
Z9 1
U1 3
U2 26
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1273
EP 1291
DI 10.1007/s10055-022-00735-2
EA DEC 2022
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000900188400001
DA 2024-07-18
ER

PT J
AU Casuso-Holgado, MJ
   García-Muñoz, C
   Martín-Valero, R
   Lucena-Anton, D
   Moral-Munoz, JA
   Cortés-Vega, MD
AF Jesus Casuso-Holgado, Maria
   Garcia-Munoz, Cristina
   Martin-Valero, Rocio
   Lucena-Anton, David
   Moral-Munoz, Jose A.
   Cortes-Vega, Maria-Dolores
TI Dropout rate in randomised controlled trials of balance and gait
   rehabilitation in multiple sclerosis: is it expected to be different for
   virtual reality-based interventions? A systematic review with
   meta-analysis and meta-regression
SO VIRTUAL REALITY
LA English
DT Review
DE Dropout rate; Multiple sclerosis; Adherence; Virtual reality; Attrition
ID PEOPLE; BIAS; ESTIMATORS; ATTRITION; VARIANCE
AB To assess and meta-analyse the pooled dropout rate from the randomised control trilas that use virtual reality for balance or gait rehabilitation in people with multiple sclerosis. A systematic review of randomised control trials with meta-analysis and meta-regressions was performed. A search was conducted in PubMed, Scopus, Web of Science, the Physiotherapy Evidence Database, the Cochrane Database, CINHAL, LILACS, ScienceDirect, and ProQuest. It was last updated in July 2022. After the selection of studies, a quality appraisal was carried out using the PEDro Scale and the Revised Cochrane risk-of-bias tool for randomised trials. A descriptive analysis of main characteristics and dropout information was performed. An overall proportion meta-analysis calculated the pooled dropout rate. Odds ratio meta-analysis compared the dropout likelihood between interventions. The meta-regression evaluated the influence of moderators related to dropout. Sixteen studies with 656 participants were included. The overall pooled dropout rate was 6.6% and 5.7% for virtual reality and 9.7% in control groups. The odds ratio (0.89, p = 0.46) indicated no differences in the probability of dropouts between the interventions. The number, duration, frequency, and weeks of sessions, intervention, sex, multiple sclerosis phenotype, Expanded Disability Status Scale score, and PEDro score were not moderators (p > 0.05). Adverse events were not reported and could not be analysed as moderators. Dropouts across the virtual reality and control comparators were similar without significant differences. Nonetheless, there is a slight trend that could favour virtual reality. Standardisation in reporting dropouts and adverse events is recommended for future trials. PROSPERO database, registration number ID CRD42021284989.
C1 [Jesus Casuso-Holgado, Maria; Cortes-Vega, Maria-Dolores] Univ Seville, Dept Physiotherapy, Seville, Spain.
   [Garcia-Munoz, Cristina; Lucena-Anton, David; Moral-Munoz, Jose A.] Univ Cadiz, Dept Nursing & Physiotherapy, Cadiz, Spain.
   [Martin-Valero, Rocio] Univ Malaga, Dept Physiotherapy, Malaga, Spain.
   [Moral-Munoz, Jose A.] Univ Cadiz, Inst Res & Innovat Biomed Sci Prov Cadiz INiBICA, Cadiz, Spain.
   [Jesus Casuso-Holgado, Maria; Garcia-Munoz, Cristina] Univ Seville, UMSS Res Grp, Seville, Spain.
C3 University of Sevilla; Universidad de Cadiz; Universidad de Malaga;
   Universidad de Cadiz; University of Sevilla
RP García-Muñoz, C (corresponding author), Univ Cadiz, Dept Nursing & Physiotherapy, Cadiz, Spain.; García-Muñoz, C (corresponding author), Univ Seville, UMSS Res Grp, Seville, Spain.
RI Martin-Valero, Rocio/H-8097-2013; García Muñoz, Cristina/ABD-1688-2020;
   Lucena-Anton, David/X-8730-2019; Cortés-Vega,
   María-Dolores/ABF-7852-2020; Moral-Munoz, Jose A./A-5893-2014;
   CASUSO-HOLGADO, MARIA JESUS/I-9778-2018
OI Martin-Valero, Rocio/0000-0002-1664-3647; García Muñoz,
   Cristina/0000-0003-2621-2098; Lucena-Anton, David/0000-0003-2441-5342;
   Cortés-Vega, María-Dolores/0000-0002-9514-8811; Moral-Munoz, Jose
   A./0000-0002-6465-982X; CASUSO-HOLGADO, MARIA JESUS/0000-0002-4217-6827
CR Abou L, 2022, J BODYW MOV THER, V29, P74, DOI 10.1016/j.jbmt.2021.09.015
   Amedoro A, 2020, MULT SCLER RELAT DIS, V41, DOI 10.1016/j.msard.2020.102022
   Arafah AM, 2017, CLIN REHABIL, V31, P809, DOI 10.1177/0269215516658338
   Asadzadeh Afsoon, 2021, Informatics in Medicine Unlocked, V24, DOI 10.1016/j.imu.2021.100562
   Balduzzi S, 2019, EVID-BASED MENT HEAL, V22, P153, DOI 10.1136/ebmental-2019-300117
   Bell ML, 2013, BMJ-BRIT MED J, V346, DOI 10.1136/bmj.e8668
   Bevens W, 2022, J MED INTERNET RES, V24, DOI 10.2196/27735
   Brichetto G, 2015, MULT SCLER J, V21, P1055, DOI 10.1177/1352458514557985
   Calabrò RS, 2017, J NEUROL SCI, V377, P25, DOI 10.1016/j.jns.2017.03.047
   Cooper CL, 2018, CLIN TRIALS, V15, P189, DOI 10.1177/1740774517752113
   Cribari-Neto F, 2010, J STAT SOFTW, V34, P1
   Crutzen R, 2015, PSYCHOL HEALTH, V30, P122, DOI 10.1080/08870446.2014.953526
   Dalmazane M, 2021, MULT SCLER RELAT DIS, V51, DOI 10.1016/j.msard.2021.102928
   Debska M, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16193673
   Dennett R, 2020, MULT SCLER RELAT DIS, V43, DOI 10.1016/j.msard.2020.102169
   Egger M, 1997, BMJ-BRIT MED J, V315, P629, DOI 10.1136/bmj.315.7109.629
   Forsberg A, 2015, DISABIL REHABIL, V37, P338, DOI 10.3109/09638288.2014.918196
   GART JJ, 1967, BIOMETRIKA, V54, P181, DOI 10.2307/2333861
   Grover S, 2021, INDIAN J PSYCHIAT, V63, P41, DOI 10.4103/psychiatry.IndianJPsychiatry_87_19
   Gustavsson M, 2022, DISABIL REHABIL, V44, P6759, DOI 10.1080/09638288.2021.1972351
   Harbord RM, 2006, STAT MED, V25, P3443, DOI 10.1002/sim.2380
   Harrer M., 2021, DOING META ANAL R HA, DOI DOI 10.1201/9781003107347
   Higgins J, 2021, Cochrane Handbook for Systematic Reviews of Interventions version 6.3
   Hoang P, 2016, MULT SCLER J, V22, P94, DOI 10.1177/1352458515579442
   Hortobágyi T, 2022, ARCH PHYS MED REHAB, V103, P1908, DOI 10.1016/j.apmr.2022.04.012
   Jack K, 2010, MANUAL THER, V15, P220, DOI 10.1016/j.math.2009.12.004
   Casuso-Holgado MJ, 2018, CLIN REHABIL, V32, P1220, DOI 10.1177/0269215518768084
   Kalron A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0124-y
   Khalafallah A, 2010, MEDITERR J HEMATOL I, V2, DOI [10.1136/bmj.l4898, 10.4084/MJHID.2010.005]
   Khalil H, 2018, NEUROREHABILITATION, V43, P473, DOI 10.3233/NRE-182471
   Levac DE, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0587-8
   Lozano-Quilis JA, 2014, JMIR SERIOUS GAMES, V2, P43, DOI 10.2196/games.2933
   Maher CG, 2003, PHYS THER, V83, P713, DOI 10.1093/ptj/83.8.713
   Massetti T, 2018, J CENT NERV SYST DIS, V10, DOI 10.1177/1179573518813541
   Matamala-Gomez M, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.646902
   Moan ME, 2021, FRONT AGING NEUROSCI, V13, DOI 10.3389/fnagi.2021.735251
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Molhemi F, 2023, DISABIL REHABIL, V45, P1343, DOI 10.1080/09638288.2022.2060332
   Molhemi F, 2021, ARCH PHYS MED REHAB, V102, P290, DOI 10.1016/j.apmr.2020.09.395
   Moore H, 2022, MULT SCLER RELAT DIS, V64, DOI 10.1016/j.msard.2022.103954
   Morel M, 2015, NEUROPHYSIOL CLIN, V45, P315, DOI 10.1016/j.neucli.2015.09.007
   Munari D, 2020, RESTOR NEUROL NEUROS, V38, P151, DOI 10.3233/RNN-190974
   Nagashima K, 2019, STAT METHODS MED RES, V28, P1689, DOI 10.1177/0962280218773520
   Nascimento AS, 2021, MULT SCLER RELAT DIS, V54, DOI 10.1016/j.msard.2021.103128
   Ozkul C., 2020, EUR J INTEGR MED, V35, P101092, DOI [10.1016/j.eujim.2020.101092, DOI 10.1016/J.EUJIM.2020.101092]
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Pagliari C, 2021, J TELEMED TELECARE, DOI 10.1177/1357633X211054839
   Peruzzi A, 2017, DISABIL REHABIL, V39, P1557, DOI 10.1080/09638288.2016.1224935
   Peruzzi A, 2016, MULT SCLER RELAT DIS, V5, P91, DOI 10.1016/j.msard.2015.11.002
   Phillips R, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-024537
   Pitrou I, 2009, ARCH INTERN MED, V169, P1756, DOI 10.1001/archinternmed.2009.306
   Robinson J, 2015, BMC SPORTS SCI MED R, V7, DOI 10.1186/s13102-015-0001-1
   Room J, 2021, PHYSIOTHERAPY, V113, P107, DOI 10.1016/j.physio.2021.06.001
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   Russo M, 2018, INT J REHABIL RES, V41, P166, DOI 10.1097/MRR.0000000000000270
   Schwarzer G, 2019, RES SYNTH METHODS, V10, P476, DOI 10.1002/jrsm.1348
   Shi LY, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000015987
   Tafti D., 2022, MULT SCLER J
   Thompson AJ, 2018, LANCET NEUROL, V17, P162, DOI 10.1016/S1474-4422(17)30470-2
   Tollár J, 2020, MED SCI SPORT EXER, V52, P1007, DOI 10.1249/MSS.0000000000002228
   Torous J, 2020, J AFFECT DISORDERS, V263, P413, DOI 10.1016/j.jad.2019.11.167
   Viechtbauer W, 2005, J EDUC BEHAV STAT, V30, P261, DOI 10.3102/10769986030003261
   Voinescu A, 2021, J CLIN MED, V10, DOI 10.3390/jcm10071478
   Wright I, 2021, J AFFECT DISORDERS, V281, P880, DOI 10.1016/j.jad.2020.11.039
   Yazgan YZ, 2020, MULT SCLER RELAT DIS, V39, DOI 10.1016/j.msard.2019.101902
NR 65
TC 2
Z9 2
U1 3
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3451
EP 3467
DI 10.1007/s10055-022-00733-4
EA DEC 2022
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000895033800004
PM 36533191
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU McAnally, K
   Wallwork, K
   Wallis, G
AF McAnally, Ken
   Wallwork, Kieran
   Wallis, Guy
TI The efficiency of visually guided movement in real and virtual space
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Human-computer interaction; Visual-motor control;
   Training
ID INFORMATION; TOUCH
AB There is an increasing interest in the use of low-cost virtual reality (VR) for training and simulation. As effective training for many tasks requires efficient sensory-motor coordination, we investigated the efficiency of visually guided movement in VR using a standardised Fitts' tapping task. Throughput is a measure of movement efficiency and was significantly lower in VR than for a touchscreen. This difference was particularly marked for targets distributed in depth and is likely to reflect known limitations of VR visual display. The addition of haptic cues increased throughput slightly. The lower throughput in VR was due to both a decrease in the precision of pointing and an increase in movement time. Movement distances were equivalent for the touchscreen and VR, but on average slightly smaller than specified by the task. VR presentation also resulted in more numerous double touches on targets. There was evidence of a small and rapid learning effect for VR, but this was limited to the first block of 9 trials (252 movements). For tasks requiring skilled sensory-motor coordination, current low-cost VR may not provide the same transfer of training as the real world.
C1 [McAnally, Ken; Wallwork, Kieran; Wallis, Guy] Univ Queensland, Sch Human Movement & Nutr Sci, St Lucia, Qld 4072, Australia.
C3 University of Queensland
RP McAnally, K (corresponding author), Univ Queensland, Sch Human Movement & Nutr Sci, St Lucia, Qld 4072, Australia.
EM kenneth.mcanally@uq.edu.au
OI McAnally, Ken/0000-0003-1787-0750
FU ARC Discovery project [DP190100533]; ARC Linkage Grant [LP180100377];
   Australian Research Council [LP180100377] Funding Source: Australian
   Research Council
FX This research was supported by ARC Discovery project grant DP190100533
   (to GW) and ARC Linkage Grant LP180100377 (Industry Partner: Boeing) (to
   GW).
CR Allerton DJ, 2010, AERONAUT J, V114, P747, DOI 10.1017/S0001924000004231
   Badash I, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.12.24
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P184, DOI [10.1109/VR46266.2020.1581205539914, 10.1109/VR46266.2020.00-67]
   Batmaz AU, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P585, DOI [10.1109/vr.2019.8797975, 10.1109/VR.2019.8797975]
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bingham GP, 2001, J EXP PSYCHOL HUMAN, V27, P1314, DOI 10.1037//0096-1523.27.6.1314
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Brown M., 2016, Exploring the Magic Behind the HTC Vive Controller
   Chun K, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P53, DOI 10.1109/HAVE.2004.1391881
   Clark LD, 2020, INT J HUM-COMPUT ST, V139, DOI 10.1016/j.ijhcs.2020.102413
   Culbertson H, 2018, ANNU REV CONTR ROBOT, V1, P385, DOI 10.1146/annurev-control-060117-105043
   Dahlstrom N, 2009, THEOR ISS ERGON SCI, V10, P305, DOI 10.1080/14639220802368864
   Department of Defense, 2019, MILSTD1472GWCHANGE1
   Ding J, 2011, P NATL ACAD SCI USA, V108, pE733, DOI 10.1073/pnas.1105183108
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Fu MJ, 2011, IEEE INT C INT ROBOT, P3460, DOI 10.1109/IROS.2011.6048296
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Howard IP., 2002, SEEING DEPTH
   HTC Corporation, 2022, DIST CORR THEOR WAV
   Hu HH, 2000, IEEE VISUAL, P179, DOI 10.1109/VISUAL.2000.885692
   ISO, 2012, ISO/TS 9241-411
   JaaAro KM, 1997, P SOC PHOTO-OPT INS, V3012, P319, DOI 10.1117/12.274474
   Joyce Richard, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P2328, DOI 10.1177/1071181319631309
   Joyce R.D., AIAA MODELING SIMULA, DOI DOI 10.2514/6.2017-1313
   Kalckert A, 2014, CONSCIOUS COGN, V26, P117, DOI 10.1016/j.concog.2014.02.003
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Kohli L, 2012, 3D US INT 3DUI 2012, P105, DOI DOI 10.1109/3DUI.2012.6184193
   Lin CJ, 2015, J SOC INF DISPLAY, V23, P319, DOI 10.1002/jsid.378
   Liu L, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P219, DOI 10.1109/VR.2009.4811026
   Ljubic S, 2015, LECT NOTES COMPUT SC, V9175, P318, DOI 10.1007/978-3-319-20678-3_31
   Machuca MDB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300437
   MacKenzie IS, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1633
   McAnally K, 2022, PSYCHOL RES-PSYCH FO, V86, P1847, DOI 10.1007/s00426-021-01613-3
   Mon-Williams M, 2000, ERGONOMICS, V43, P391, DOI 10.1080/001401300184486
   Musil Richard, 2022, HMD GEOMETRY DATABAS
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Scarfe P, 2019, ANNU REV VIS SCI, V5, P529, DOI 10.1146/annurev-vision-091718-014942
   Schwind V., 2019, P MENSCH COMPUTER 20, P211, DOI DOI 10.1145/3340764.3340769
   Scott MacKenzie I., 2015, Human-Computer Interaction. Interaction Technologies. 17th International Conference, HCI International 2015. Proceedings: LNCS 9170, P238, DOI 10.1007/978-3-319-20916-6_23
   Soukoreff RW, 2004, INT J HUM-COMPUT ST, V61, P751, DOI 10.1016/j.ijhcs.2004.09.001
   Teather R. J., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P87, DOI 10.1109/3DUI.2011.5759222
   Teather R.J., 2010, Poster at Graphics Interface
   Warton DI, 2011, ECOLOGY, V92, P3, DOI 10.1890/10-0340.1
NR 45
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 1187
EP 1197
DI 10.1007/s10055-022-00724-5
EA DEC 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000895033800003
DA 2024-07-18
ER

PT J
AU Turchet, L
   Carraro, M
   Tomasetti, M
AF Turchet, Luca
   Carraro, Marco
   Tomasetti, Matteo
TI FreesoundVR: soundscape composition in virtual reality using online
   sound repositories
SO VIRTUAL REALITY
LA English
DT Article
DE Musical XR; Composition; Soundscape; Internet of audio things
ID MUSIC; ART
AB The intersection between sound and music computing and Virtual Reality (VR) has grown significantly over the past decades, amounting to an established area of research today. However, still scarce research has been conducted on the development of specific tools for sound design and composition. In this paper, we investigate a new way of exploring online sound repositories to retrieve sounds to be used in soundscape composition, which leverages the VR medium. Specifically, we created a VR system that allows users to search, download, and explore Freesound content in an immersive manner, as well as to use it for soundscape composition practices via a virtual digital audio workstation (DAW). The tags associated to a sound in the repository were converted into virtual objects and environments, which the user could navigate while listening to the sound. We conducted a user study with 16 composers where the developed system was compared against a conventional counterpart comprising the Freesound web version and the Audacity DAW. Overall, quantitative and qualitative results did not indicate a clear and generalized preference for a system over the other. The usability of the two systems along with their offered creativity support, cognitive workload and emotional impact were deemed to be at a comparable level. Nevertheless, the full potential of VR in creating novel compositional experiences also clearly emerged. Our study shows that VR is an effective medium to support users' creativity during the process of exploring and selecting sounds from an online repository as well as for composing a soundscape.
C1 [Turchet, Luca; Carraro, Marco; Tomasetti, Matteo] Univ Trento, Dept Informat Engn & Comp Sci, Via Sommar 9, I-38123 Trento, Italy.
C3 University of Trento
RP Turchet, L (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, Via Sommar 9, I-38123 Trento, Italy.
EM luca.turchet@unitn.it; marco.carraro@unitn.it; matteo.tomasetti@unitn.it
RI Turchet, Luca/M-9679-2013
OI Turchet, Luca/0000-0003-0711-8098; Tomasetti, Matteo/0000-0001-5951-0302
FU Universita degli Studi di Trento within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Trento within
   the CRUI-CARE Agreement.
CR Akkermans V., 2011, INT SOC MUS INF RETR
   [Anonymous], 2017, P 18 ISMIR C SUZH CH, DOI DOI 10.5281/ZENODO.1417159
   Barri, 2009, P INT C NEW INTERFAC, P264
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Buckley Z, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1497, DOI [10.1109/VR.2019.8797768, 10.1109/vr.2019.8797768]
   Carey, 2016, INT C NEW INTERFACES
   Chapman O, 2009, ORGAN SOUND, V14, P83, DOI 10.1017/S1355771809000120
   Cherry E, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2617588
   Ciciliani M, 2020, J NEW MUSIC RES, V49, P104, DOI 10.1080/09298215.2019.1703013
   Costa W, 2019, SYMP VIRTUAL AUGMENT, P216, DOI 10.1109/SVR.2019.00046
   d'Escriván J, 2009, ORGAN SOUND, V14, P65, DOI 10.1017/S1355771809000090
   Drever J.L., 2002, ORGAN SOUND, V7, P21
   Eckel G, 2001, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P571, DOI 10.1109/IV.2001.942112
   Favory X, 2018, ARXIV181110988V1, P60
   Font Frederic, 2021, AM '21: Audio Mostly 2021, P182, DOI 10.1145/3478384.3478388
   Font F., 2013, P 2013 ACM MULTIMEDI, P411, DOI 10.1145/2502081.2502245
   Font F, 2016, 61ST AES INTERNATIONAL CONFERENCE ON AUDIO FOR GAMES
   Freeman J, 2011, ORGAN SOUND, V16, P272, DOI 10.1017/S1355771811000288
   Graham R, 2016, AUDIO ENG SOC C 2016
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Koutsomichalis Marinos., 2013, Journal of Sonic Studies, V4
   Leonard M, 2014, MUSIC SOUND DOCUMENT, P180
   Masu R, 2020, P INT C NEW INTERFAC, P109
   Moore Alec G., 2015, 2015 IEEE S 3D USER, P205, DOI 10.1109/3DUI.2015.7131772
   OModhrain Sile, 2015, TEI, V15, P709, DOI [10.1145/2677199.2687895, DOI 10.1145/2677199.2687895]
   Polfreman R, 2009, P INT C NEW INT MUS, P226
   Schafer R. M, 1977, The Tuning of the World, DOI DOI 10.2307/3345272
   Schirosa M, 2010, 17 CIM C MUSICAL INF
   Skach S, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P80, DOI 10.1145/3173225.3173272
   Truax B., 1992, COMPANION CONT MUSIC, P374
   Truax B, 2008, ORGAN SOUND, V13, P103, DOI 10.1017/S1355771808000149
   Truax Barry., 1996, CONTEMP MUSIC REV, V15, P49, DOI [DOI 10.1080/07494469600640351, https://doi.org/10.1080/07494469600640351]
   Turchet Luca, 2020, AM '20: Proceedings of the 15th International Conference on Audio Mostly, P160, DOI 10.1145/3411109.3411113
   Turchet L, 2021, IEEE ACCESS, V9, P15810, DOI 10.1109/ACCESS.2021.3052931
   Turchet L, 2020, IEEE INTERNET THINGS, V7, P10233, DOI 10.1109/JIOT.2020.2997047
   Turchet L, 2018, PROC CONF OPEN INNOV, P375, DOI 10.23919/FRUCT.2018.8588110
   Turchet L, 2013, APPL ACOUST, V74, P566, DOI 10.1016/j.apacoust.2012.10.010
   Turner P, 2003, P INT C AUDITORY DIS, P148
   Valle A, 2014, INT COMPUTER MUSIC C
   Valle A, 2010, LECT NOTES COMPUT SC, V5954, P330
   Verron C, 2010, IEEE T AUDIO SPEECH, V18, P1550, DOI 10.1109/TASL.2009.2037402
   Westerkamp Hildegard., 2002, ORGAN SOUND, V7, P51, DOI [https://doi.org/10.1017/S1355771802001085, DOI 10.1017/S1355771802001085, 10.1017/S1355771802001085]
   Wright AC, 2013, PHYS STATUS SOLIDI B, V250, P931, DOI 10.1002/pssb.201248500
   Wrightson Kendall., 2000, SOUNDSCAPE, V1, P10
   Zappi V, 2012, P SOUND MUSIC COMPUT, P403
NR 47
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 903
EP 915
DI 10.1007/s10055-022-00705-8
EA SEP 2022
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000862242800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Chao, YP
   Kang, CJ
   Chuang, HH
   Hsieh, MJ
   Chang, YC
   Kuo, TBJ
   Yang, CCH
   Huang, CG
   Fang, TJ
   Li, HY
   Lee, LA
AF Chao, Yi-Ping
   Kang, Chung-Jan
   Chuang, Hai-Hua
   Hsieh, Ming-Ju
   Chang, Yu-Che
   Kuo, Terry B. J.
   Yang, Cheryl C. H.
   Huang, Chung-Guei
   Fang, Tuan-Jen
   Li, Hsueh-Yu
   Lee, Li-Ang
TI Comparison of the effect of 360° versus two-dimensional virtual reality
   video on history taking and physical examination skills learning among
   undergraduate medical students: a randomized controlled trial
SO VIRTUAL REALITY
LA English
DT Article
DE Cognitive load; History taking; Physical examination; Two-dimensional
   video; Virtual reality; 360 degrees video
ID CLINICAL-EVALUATION EXERCISE; COGNITIVE LOAD MEASURES; MINI-CEX;
   PERFORMANCE; SIMULATION; EXAMPLES; VALIDITY; TOOL
AB Before caring for patients, video instruction is commonly used for undergraduate medical students, and 360 degrees virtual reality (VR) videos have gained increasing interest in clinical medical education. Therefore, the effect of immersive 360 degrees VR video learning compared with two-dimensional (2D) VR video learning in clinical skills acquisition should be evaluated. This randomized, intervention-controlled clinical trial was aimed to assess whether immersive 360 degrees VR video improves undergraduate medical students' learning effectiveness and reduces the cognitive load in history taking and physical examination (H&P) training. From May 1 2018 to October 30 2018, 64 senior undergraduate medical students in a tertiary academic hospital were randomized to receive a 10-min immersive 360 degrees (360 degrees VR video group; n= 32) or 2D VR instructional video (2D VR video group; n= 32), including essential knowledge and competency of H&P. The demographic characteristics of the two groups were comparable for age, sex, and cognitive style. The total procedure skill score, physical examination score, learner's satisfaction score, and total cognitive load in the 360 degrees VR video group were significantly higher than those in the 2D VR video group (effect sizes [95% confidence interval]: 0.72 [0.21-1.22], 0.63 [0.12-1.13], 0.56 [0.06-1.06], and 0.53 [0.03-1.03], respectively). This study suggested that a10-minute 360 degrees VR video instruction helped undergraduate medical students perform fundamental H&P skills as effectively as 2D VR video. Furthermore, the 360 degrees VR video might result in significantly better procedural metrics of physical examinations with higher learner satisfaction despite the higher cognitive load.
C1 [Chao, Yi-Ping] Chang Gung Univ, Grad Inst Med Mechatron, Dept Comp Sci & Informat Engn, Taoyuan 33302, Taiwan.
   [Chao, Yi-Ping] Chang Gung Mem Hosp, Dept Neurol, Linkou Main Branch, Taoyuan 33305, Taiwan.
   [Kang, Chung-Jan; Chuang, Hai-Hua; Hsieh, Ming-Ju; Chang, Yu-Che; Fang, Tuan-Jen; Li, Hsueh-Yu; Lee, Li-Ang] Chang Gung Univ, Coll Med, Fac Med, Grad Inst Clin Med Sci, Taoyuan 33302, Taiwan.
   [Kang, Chung-Jan; Fang, Tuan-Jen; Li, Hsueh-Yu; Lee, Li-Ang] Chang Gung Mem Hosp, Dept Otorhinolaryngol Head & Neck Surg, Linkou Main Branch, 5 Fu Hsing St, Taoyuan 33305, Taiwan.
   [Chuang, Hai-Hua] Chang Gung Mem Hosp, Dept Family Med, Linkou Main Branch, Taoyuan 33305, Taiwan.
   [Chuang, Hai-Hua; Lee, Li-Ang] Natl Tsing Hua Univ, Coll Life Sci, Sch Med, Hsinchu 300044, Taiwan.
   [Chuang, Hai-Hua] Natl Taipei Univ Technol, Dept Ind Engn & Management, Taipei 10608, Taiwan.
   [Hsieh, Ming-Ju] Chang Gung Mem Hosp, Dept Surg, Linkou Main Branch, Taoyuan 33305, Taiwan.
   [Chang, Yu-Che] Chang Gung Mem Hosp, Dept Emergency Med, Linkou Main Branch, Taoyuan 33305, Taiwan.
   [Kuo, Terry B. J.; Yang, Cheryl C. H.; Lee, Li-Ang] Natl Yang Ming Chiao Tung Univ, Inst Brain Sci, Taipei 11221, Taiwan.
   [Huang, Chung-Guei] Chang Gung Mem Hosp, Dept Lab Med, Linkou Main Branch, Taoyuan 33305, Taiwan.
   [Huang, Chung-Guei] Chang Gung Univ, Grad Inst Biomed Sci, Dept Med Biotechnol & Lab Sci, Taoyuan 33302, Taiwan.
C3 Chang Gung University; Chang Gung Memorial Hospital; Chang Gung
   University; Chang Gung Memorial Hospital; Chang Gung Memorial Hospital;
   National Tsing Hua University; National Taipei University of Technology;
   Chang Gung Memorial Hospital; Chang Gung Memorial Hospital; National
   Yang Ming Chiao Tung University; Chang Gung Memorial Hospital; Chang
   Gung University
RP Lee, LA (corresponding author), Chang Gung Univ, Coll Med, Fac Med, Grad Inst Clin Med Sci, Taoyuan 33302, Taiwan.; Lee, LA (corresponding author), Chang Gung Mem Hosp, Dept Otorhinolaryngol Head & Neck Surg, Linkou Main Branch, 5 Fu Hsing St, Taoyuan 33305, Taiwan.; Lee, LA (corresponding author), Natl Tsing Hua Univ, Coll Life Sci, Sch Med, Hsinchu 300044, Taiwan.; Lee, LA (corresponding author), Natl Yang Ming Chiao Tung Univ, Inst Brain Sci, Taipei 11221, Taiwan.
EM yiping@mail.cgu.edu.tw; handneck@gmail.com; chhaihua@gmail.com;
   hsiehmj2@gmail.com; changyuche@gmail.com; tbjkuo@gmail.com;
   cchyang@gmail.com; joyce@cgmh.org.tw; fang3109@cgmh.org.tw;
   hyli38@cgmh.org.tw; Dr.Li.Ang.Lee@gmail.com
RI Chang, Yu-Che/ISU-6223-2023; Li, Hsueh-Yu/JMR-1981-2023; Chuang,
   Hai-Hua/A-5144-2015; Hsieh, Ming-Ju/AAY-2569-2021; Chao,
   Yi-Ping/GOP-0833-2022
OI Li, Hsueh-Yu/0000-0002-9016-8098; Chuang, Hai-Hua/0000-0002-7394-4016;
   Hsieh, Ming-Ju/0000-0003-2450-4257; Chao, Yi-Ping/0000-0002-1681-5410
FU Ministry of Science and Technology, Taiwan, R.O.C.
   [106-2511-S-182A-003-MY2, 108-2511-H-182A-001-]; Chang Gung Medical
   Foundation, Taiwan, R.O.C. [CMRPG3G1381-3]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, R.O.C. (106-2511-S-182A-003-MY2 and 108-2511-H-182A-001-) and a
   grant from the Chang Gung Medical Foundation, Taiwan, R.O.C.
   (CMRPG3G1381-3) awarded to L.-A.
CR Abich J IV, 2021, VIRTUAL REAL-LONDON, V25, P919, DOI 10.1007/s10055-020-00498-8
   Al Ansari A, 2013, ACAD MED, V88, P413, DOI 10.1097/ACM.0b013e318280a953
   Alaker M, 2016, INT J SURG, V29, P85, DOI 10.1016/j.ijsu.2016.03.034
   Andersen SAW, 2016, LARYNGOSCOPE, V126, pE74, DOI 10.1002/lary.25449
   Andersen SAW, 2016, J SURG EDUC, V73, P45, DOI 10.1016/j.jsurg.2015.09.010
   Andersen SA, 2015, JAMA OTOLARYNGOL, V141, P913, DOI 10.1001/jamaoto.2015.1563
   Blair C, 2021, BMC MED EDUC, V21, DOI 10.1186/s12909-021-03013-y
   Buttussi F, 2021, IEEE T LEARN TECHNOL, V14, pC, DOI 10.1109/TLT.2020.3033766
   Buttussi F, 2018, IEEE T VIS COMPUT GR, V24, P1063, DOI 10.1109/TVCG.2017.2653117
   Chang YC, 2013, J ACUTE MED, V3, P110, DOI 10.1016/j.jacme.2013.06.004
   Chao YP, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/13124
   Checa D, 2023, VIRTUAL REAL-LONDON, V27, P3301, DOI 10.1007/s10055-021-00607-1
   Chen GR, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.35576
   CHI MTH, 1989, COGNITIVE SCI, V13, P145, DOI 10.1207/s15516709cog1302_1
   Danielson AR, 2019, MED EDUC ONLINE, V24, DOI 10.1080/10872981.2019.1608142
   Eggleton K, 2016, FAM MED, V48, P624
   Erfani Khanghahi Masoumeh, 2018, Med J Islam Repub Iran, V32, P45, DOI 10.14196/mjiri.32.45
   Fiorella L, 2017, J EDUC PSYCHOL, V109, P653, DOI 10.1037/edu0000161
   Frederiksen JG, 2020, SURG ENDOSC, V34, P1244, DOI 10.1007/s00464-019-06887-8
   Izard SG, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0900-2
   Gutiérrez F, 2007, STUD HEALTH TECHNOL, V125, P155
   Hansen J, 2020, CBE-LIFE SCI EDUC, V19, DOI 10.1187/cbe.19-11-0253
   HART S G, 1988, P139
   Hsin LJ, VIRTUAL REAL-LONDON
   Kara CO, 2018, TURK ARCH OTORHINOL, V56, P7, DOI 10.5152/tao.2018.3065
   Keifenheim KE, 2015, BMC MED EDUC, V15, DOI 10.1186/s12909-015-0443-x
   Khan R, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008237.pub3
   Kogan Jennifer R, 2002, Acad Med, V77, P1156, DOI 10.1097/00001888-200211000-00021
   Kyaw BM, 2019, J MED INTERNET RES, V21, DOI 10.2196/12959
   Lange C, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07785
   Lee HS, 2020, RESTOR NEUROL NEUROS, V38, P165, DOI 10.3233/RNN-190975
   Lee LA., 2018, J LARYNGOL OTOL, V07, P69, DOI [10.4172/2324-8785-c3-014, DOI 10.4172/2324-8785-C3-014]
   Lee LA, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.8987
   Letterie GS, 2002, AM J OBSTET GYNECOL, V187, pS37, DOI 10.1067/mob.2002.127361
   Lohre R, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.31217
   Lungu AJ, 2021, EXPERT REV MED DEVIC, V18, P47, DOI 10.1080/17434440.2021.1860750
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Moher David, 2010, J Clin Epidemiol, V63, pe1, DOI [10.1016/j.ijsu.2011.10.001, 10.1136/bmj.c869, 10.1016/j.jclinepi.2010.03.004]
   Morrison G.R., 2007, DESIGNING EFFECTIVE, V5th
   Naismith LM, 2015, PERSPECT MED EDUC, V4, P344, DOI 10.1007/s40037-015-0221-9
   Naismith LM, 2015, MED EDUC, V49, P805, DOI 10.1111/medu.12732
   Nas J, 2020, JAMA CARDIOL, V5, P328, DOI 10.1001/jamacardio.2019.4992
   Noble LM, 2018, PATIENT EDUC COUNS, V101, P1712, DOI 10.1016/j.pec.2018.04.013
   NORCINI JJ, 1995, ANN INTERN MED, V123, P795, DOI 10.7326/0003-4819-123-10-199511150-00008
   Norcini J, 2007, MED TEACH, V29, P855, DOI 10.1080/01421590701775453
   PAAS FGWC, 1992, J EDUC PSYCHOL, V84, P429, DOI 10.1037/0022-0663.84.4.429
   Pedram S, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627333
   Plancher G, 2010, NEUROPSYCHOLOGY, V24, P379, DOI 10.1037/a0018680
   Pulijala Y, 2018, INT J ORAL MAX SURG, V47, P1199, DOI 10.1016/j.ijom.2018.01.005
   Renkl A, 1998, CONTEMP EDUC PSYCHOL, V23, P90, DOI 10.1006/ceps.1997.0959
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Sankaranarayanan G, 2020, AM J SURG, V220, P620, DOI 10.1016/j.amjsurg.2020.02.002
   SCOTT N, 1981, J MED EDUC, V56, P565
   Sewell JL, 2019, MED TEACH, V41, P256, DOI 10.1080/0142159X.2018.1505034
   Sukumar Smrithi, 2021, MedEdPORTAL, V17, P11106, DOI 10.15766/mep_2374-8265.11106
   Sultan L, 2019, ADV MED EDUC PRACT, V10, P907, DOI 10.2147/AMEP.S219344
   Suresh Kp, 2011, J Hum Reprod Sci, V4, P8, DOI 10.4103/0974-1208.82352
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Tariq EF, 2020, ANN MED SURG, V60, P1, DOI 10.1016/j.amsu.2020.10.010
   Tippett WJ, 2009, CYBERPSYCHOL BEHAV, V12, P169, DOI 10.1089/cpb.2008.0218
   Toy S, 2020, SIMUL HEALTHC, V15, P388, DOI 10.1097/SIH.0000000000000458
   Tsue Terance T, 2014, J Grad Med Educ, V6, P162, DOI 10.4300/JGME-06-01s1-21
   Vasile C, 2011, PROCD SOC BEHV, V12, P478, DOI 10.1016/j.sbspro.2011.02.059
   von Fragstein M, 2008, Med Educ, V42, P1100, DOI DOI 10.1111/J.1365-2923.2008.03137.X
   Witkin H.A., 1971, A manual for the embedded figures tests
   Wu JL, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.575094
   Yang YY, 2011, J CHIN MED ASSOC, V74, P531, DOI 10.1016/j.jcma.2011.10.002
   Yoganathan S, 2018, INT J SURG, V54, P24, DOI 10.1016/j.ijsu.2018.04.002
NR 68
TC 6
Z9 6
U1 6
U2 22
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 637
EP 650
DI 10.1007/s10055-022-00664-0
EA AUG 2022
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000841069300001
PM 35992202
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Dong, JQ
   Xia, ZY
   Zhao, QF
   Zhao, N
AF Dong, Jiaqi
   Xia, Zeyang
   Zhao, Qunfei
   Zhao, Ning
TI Human-machine integration based augmented reality assisted wire-bending
   training system for orthodontics
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Wire bending; Gesture recognition; Temporal logical
   relation; Focus Grid Optical Flow; Orthodontic treatment
AB With the increasing demand for orthodontic treatment, the skill of wire bending is more and more important for orthodontists. Traditional wire bending training needs a high cost of time and resources. In this paper, an augmented reality assisted wire-bending training system (ARAWTS) is proposed. ARAWTS provides 4 typical wire bending training tasks for the trainee and can give training feedback and improvement advice to the trainee by gesture recognition during the training. For the elaborate and vague wire bending gesture recognition, we develop a temporal logical relation (TLR) module to sparsely sample dense frames and learn the TLRs between frames of gestures. To reduce the computational cost and time, we introduce a new type of sparse optical flow called Focus Grid Optical Flow (FGOF). From the results of experiments, the proposed algorithm implemented on an AR device (HoloLens) achieves a high recognition rate with low computational complexity and ARAWTS is proved reliable.
C1 [Dong, Jiaqi; Zhao, Qunfei] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.
   [Xia, Zeyang] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Zhao, Ning] Shanghai Jiao Tong Univ, Shanghai Peoples Hosp 9, Sch Med, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS; Shanghai Jiao Tong University
RP Xia, ZY (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
EM zy.xia@siat.ac.cn
FU National Natural Science Foundation of China [U2013205]
FX This study was funded by the National Natural Science Foundation of
   China (U2013205).
CR Balleste F, 2013, HDB RES TECHNOSELF I, P574
   Baraldi L, 2014, IEEE COMPUT SOC CONF, P702, DOI 10.1109/CVPRW.2014.107
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cheng WT, 2019, NEURAL COMPUT APPL, V31, P309, DOI 10.1007/s00521-018-3775-8
   Dong JQ, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102583
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Hilliges O, 2017, U.S. Patent, Patent No. [9,552,673, 9552673]
   Hughes CE, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.139
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, CORR ABS170506950
   Kethman W, 2021, DIGITAL SURG, P275
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Kono H, 2020, ORTHOD WAVES, V79, P57, DOI 10.1080/13440241.2020.1741070
   Lau MN, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0254478
   Lee SH, 2021, IEEE ACCESS, V9, P65871, DOI 10.1109/ACCESS.2021.3075778
   Lee SH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10060740
   Lo YC, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052315
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Nyre-Yu M. M., 2019, Determining System Requirements for Human-Machine Integration in Cyber Security Incident Response
   Osti F, 2021, VIRTUAL REAL-LONDON, V25, P523, DOI 10.1007/s10055-020-00470-6
   Rios Horacio, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P87, DOI 10.1007/978-3-642-22021-0_11
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivarajan S, 2021, BMC MED EDUC, V21, DOI 10.1186/s12909-021-02717-5
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Tang YM, 2021, J COMPUT ASSIST LEAR, V37, P359, DOI 10.1111/jcal.12494
   Vakaliuk TA, 2021, CEUR WORKSHOP PROC
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Waters N E, 1975, Br J Orthod, V2, P15
   Wong S.-F., 2007, IEEE COMPUTER SOC C, P1
   Wu XY, 2020, MULTIMED TOOLS APPL, V79, P9193, DOI 10.1007/s11042-019-7193-4
   Wu YH, 2018, CHIN AUTOM CONGR, P2446, DOI 10.1109/CAC.2018.8623035
   Zhao Z., 2008, Proc. British Machine Vision Conference, P1
   Zhou J, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.103944
   Zhu GM, 2017, IEEE ACCESS, V5, P4517, DOI 10.1109/ACCESS.2017.2684186
NR 38
TC 2
Z9 2
U1 5
U2 30
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 627
EP 636
DI 10.1007/s10055-022-00675-x
EA AUG 2022
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000836831800001
DA 2024-07-18
ER

PT J
AU Sansone, LG
   Stanzani, R
   Job, M
   Battista, S
   Signori, A
   Testa, M
AF Sansone, Lucia Grazia
   Stanzani, Ronny
   Job, Mirko
   Battista, Simone
   Signori, Alessio
   Testa, Marco
TI Robustness and static-positional accuracy of the SteamVR 1.0 virtual
   reality tracking system
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Accuracy testing; Tracker occlusion; Validation Study
   [Publication Type]; SteamVR tracking; HTC Vive PRO
AB The use of low-cost immersive virtual reality systems is rapidly expanding. Several studies started to analyse the accuracy of virtual reality tracking systems, but they did not consider in depth the effects of external interferences in the working area. In line with that, this study aimed at exploring the static-positional accuracy and the robustness to occlusions inside the capture volume of the SteamVR (1.0) tracking system. To do so, we ran 3 different tests in which we acquired the position of HTC Vive PRO Trackers (2018 version) on specific points of a grid drawn on the floor, in regular tracking conditions and with partial and total occlusions. The tracking system showed a high inter- and intra-rater reliability and detected a tilted surface with respect to the floor plane. Every acquisition was characterised by an initial random offset. We estimated an average accuracy of 0.5 +/- 0.2 cm across the entire grid (XY-plane), noticing that the central points were more accurate (0.4 +/- 0.1 cm) than the outer ones (0.6 +/- 0.1 cm). For the Z-axis, the measurements showed greater variability and the accuracy was equal to 1.7 +/- 1.2 cm. Occlusion response was tested using nonparametric Bland-Altman statistics, which highlighted the robustness of the tracking system. In conclusion, our results promote the SteamVR system for static measures in the clinical field. The computed error can be considered clinically irrelevant for exercises aimed at the rehabilitation of functional movements, whose several motor outcomes are generally measured on the scale of metres.
C1 [Sansone, Lucia Grazia; Stanzani, Ronny; Job, Mirko; Battista, Simone; Testa, Marco] Univ Genoa, Dept Neurosci Rehabil Ophthalmol Genet Maternal &, Campus Savona,Via Magliotto 2, I-17100 Savona, SV, Italy.
   [Signori, Alessio] Univ Genoa, Dept Hlth Sci, Biostat Unit, Genoa, Italy.
C3 University of Genoa; University of Genoa
RP Sansone, LG (corresponding author), Univ Genoa, Dept Neurosci Rehabil Ophthalmol Genet Maternal &, Campus Savona,Via Magliotto 2, I-17100 Savona, SV, Italy.
EM luciagrazia.sansone@medicina.unige.it
RI Signori, Alessio/L-3081-2016; Battista, Simone/HXH-8288-2023
OI Signori, Alessio/0000-0001-6289-9144; Battista,
   Simone/0000-0002-7471-1951; Sansone, Lucia Grazia/0000-0002-4201-7762
FU DINOGMI Department of Excellence of MIUR 2018-2022 [232-2016]
FX This work was developed within the framework of the DINOGMI Department
   of Excellence of MIUR 2018-2022 (232-2016).
CR Ameler T, 2019, IEEE ENG MED BIO, P1465, DOI [10.1109/EMBC.2019.8856992, 10.1109/embc.2019.8856992]
   Bland JM, 1999, STAT METHODS MED RES, V8, P135, DOI 10.1177/096228029900800204
   Bland JM, 2010, STAT METHODS ASSESSI, V9
   Borges M, 2018, IEEE INT C INT ROBOT, P2610, DOI 10.1109/IROS.2018.8593707
   Campo-Prieto P, 2021, VIRTUAL REAL-LONDON, V25, P801, DOI 10.1007/s10055-020-00495-x
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Conconi M, 2021, J BIOMECH, V114, DOI 10.1016/j.jbiomech.2020.110162
   Giavarina D, 2015, BIOCHEM MEDICA, V25, P141, DOI 10.11613/BM.2015.015
   Izard SG, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0900-2
   Hemphill S, 2020, DIGIT HEALTH, V6, DOI 10.1177/2055207620950929
   HTC Corp, 2020, 2Q29100 HTC VIV HEAD
   HTC Corp, 2017, HTC VIV TRACK DEV GU
   Ikbal MS, 2021, IEEE ACCESS, V9, P3798, DOI 10.1109/ACCESS.2020.3047698
   Bascones JLJ, 2019, NEUROCOMPUTING, V353, P96, DOI 10.1016/j.neucom.2018.05.132
   Jost TA, 2019, J BIOMECH, V97, DOI 10.1016/j.jbiomech.2019.109379
   Jung K, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02215
   Laut J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117013
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Maciejewski M, 2018, TESTING STEAMVR TRAC
   Maciejewski M, 2020, METROL MEAS SYST, V27, P601, DOI 10.24425/mms.2020.134841
   Nabiyouni Mahdi., 2017, Frontiers in ICT, V3, P34
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Paternain S, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR)
   Piccoli Alessandro, 2018, J Funct Morphol Kinesiol, V3, DOI 10.3390/jfmk3030040
   Powden CJ, 2019, INT J SPORTS PHYS TH, V14, P683, DOI 10.26603/ijspt20190683
   Rossettini G, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/2946465
   Sitole SP, 2020, IEEE SENS J, V20, P8576, DOI 10.1109/JSEN.2020.2983933
   Spitzley KA, 2019, J BIOMECH, V87, P172, DOI 10.1016/j.jbiomech.2019.02.015
   Stanzani R, 2020, IEEE SENS J, V20, P10267, DOI 10.1109/JSEN.2020.2992733
   Stine RA, 2001, SOCIOL METHOD RES, V30, P124, DOI 10.1177/0049124101030001011
   van der Veen SM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173632
   Wulf G, 2013, INT REV SPORT EXER P, V6, P77, DOI 10.1080/1750984X.2012.723728
NR 32
TC 7
Z9 8
U1 1
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 903
EP 924
DI 10.1007/s10055-021-00584-5
EA NOV 2021
PG 22
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000717407500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Davis, L
   McHenry, N
   Carrera, M
   Brady, L
   Mayorga, K
   Balthazor, B
   Gomez, I
   Chamitoff, G
   Diaz-Artiles, A
AF Davis, Leah
   McHenry, Neil
   Carrera, Manuel
   Brady, Lauren
   Mayorga, Kevin
   Balthazor, Brock
   Gomez, Israel
   Chamitoff, Gregory
   Diaz-Artiles, Ana
TI Remote virtual whiteboard assistance for improving task performance
   during lunar surface operations
SO VIRTUAL REALITY
LA English
DT Article
DE Extravehicular activity; Virtual reality; Augmented reality; Spacewalks
ID MAINTENANCE; SUPPORT
AB During extravehicular activities (EVAs), astronauts are heavily dependent on the Mission Center (MCC) and their Intra-Vehicular Astronaut (IVA) counterparts. Each procedure step in a mission is relayed to the astronaut through a real-time voice loop, and emergency procedures are written on cuff checklists that astronauts must read from their spherically shaped helmet. In all situations, crew members heavily rely on IVA or MCC support, especially when they do not understand a procedure or need help with a specific problem. However, it can be hard to communicate procedures effectively due to a lack of visual diagrams and situational awareness between the two parties. To improve EVA efficiency, we investigated the use of a virtual whiteboard on a heads-up display during a lunar surface EVA task with virtual reality (VR). The virtual whiteboard allows MCC to send additional visual guidance (e.g., drawings and annotations) overlayed on the astronaut's visual field of view to better assist with mission tasks. We conducted a between-subjects experiment where 21 participants were asked to accomplish a rover repair procedure, with (n = 11) and without (n = 10) the virtual whiteboard, using a VR lunar environment with support of a research proctor acting as MCC. The whiteboard group completed the rover procedure 39.1% faster than the non-whiteboard group, and this difference was statistically significant (p = 0.017). The total number of words exchanged during the experimental sessions was not statistically different between groups (p = 0.99). However, participants in the whiteboard group showed a tendency to talk less than their counterparts, while the research proctor in the whiteboard group showed a tendency to speak more. Finally, analysis of the spatial locations during the experiment indicated that whiteboard participants stayed closer to the rover, showing a better focus on the task at hand and therefore short completion times. The results of this experiment inform future development of AR spacesuit technologies for future planetary exploration EVA operations.
C1 [Davis, Leah; McHenry, Neil; Carrera, Manuel; Brady, Lauren; Mayorga, Kevin; Chamitoff, Gregory; Diaz-Artiles, Ana] Texas A&M Univ, Dept Aerosp Engn, College Stn, TX 77843 USA.
   [Balthazor, Brock] Texas A&M Univ, Dept Biomed Sci, College Stn, TX 77843 USA.
   [Gomez, Israel] Texas A&M Univ, Dept Mech & Mfg Engn, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station; Texas
   A&M University System; Texas A&M University College Station; Texas A&M
   University System; Texas A&M University College Station
RP Diaz-Artiles, A (corresponding author), Texas A&M Univ, Dept Aerosp Engn, College Stn, TX 77843 USA.
EM leahbrooke99@tamu.edu; neil@tamu.edu; mannycarr214@tamu.edu;
   laurenbrady01@tamu.edu; kevinamayorga@tamu.edu; brockbalthazor@tamu.edu;
   izzygomezthree@tamu.edu; chamitoff@tamu.edu; adartiles@tamu.edu
RI /D-6022-2017
OI /0000-0002-0459-9327; Davis, Leah/0000-0001-5947-0144
FU NASA Human Research Program [80NSSC19K0656]; NASA Innovative Advanced
   Concepts (NIAC) program [80NSSC19K0969]
FX This work was partially supported by the NASA Human Research Program
   (Grant Number 80NSSC19K0656) and the NASA Innovative Advanced Concepts
   (NIAC) program (Grant Number 80NSSC19K0969).
CR Abramovici M, 2017, PROC CIRP, V59, P18, DOI 10.1016/j.procir.2016.09.042
   Anandapadmanaban E., 2018, 48 INT C ENV SYST
   [Anonymous], 2020, ART PLAN
   [Anonymous], 1997, J ENG EDUC, DOI [10.1002/j.2168-9830.1997.tb00278.x, DOI 10.1002/J.2168-9830.1997.TB00278.X]
   [Anonymous], 2017, UNIMERSIV 1214
   Boud A. C., 1999, 1999 IEEE International Conference on Information Visualization (Cat. No. PR00210), P32, DOI 10.1109/IV.1999.781532
   Dunbar B., JSC HUMAN SPACEFLIGH
   Eppler D, 2013, ACTA ASTRONAUT, V90, P224, DOI 10.1016/j.actaastro.2012.03.009
   Halim A. A., 2018, J. Fundam. Appl. Sci, V10, P412
   Keller N, 2021, AEROSP CONF PROC, DOI 10.1109/AERO50100.2021.9438234
   Lim AK, 2022, SURG ENDOSC, V36, P988, DOI 10.1007/s00464-021-08363-8
   Matsuo T., 2021, J PHYS FIT SPORTS ME, V10, P145, DOI [10.7600/jpfsm.10.145, DOI 10.7600/JPFSM.10.145]
   Mauldin J, 2021, TREADMILL 2 AUGMENTE
   McHenry N., 2020, AIAA Scitech 2020 Forum, DOI DOI 10.2514/6.2020-0168
   McHenry N, 2020, AEROSP CONF PROC, DOI 10.1109/aero47225.2020.9172268
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Miller M., 2014, INFORM FLOW MODEL HU
   Moro C, 2021, BRIT J EDUC TECHNOL, V52, P680, DOI 10.1111/bjet.13049
   Mourtzis D, 2017, PROC CIRP, V63, P46, DOI 10.1016/j.procir.2017.03.154
   Norheim J., 2018, IEEE AER C, V2018, P1, DOI [10.1109/AERO.2018.8396510, DOI 10.1109/AERO.2018.8396510]
   Schlueter JA., 2018, THESIS, V16457, DOI [10.31274/etd-180810-6087, DOI 10.31274/ETD-180810-6087]
   Technologies Unity, UN GAM ENG
   Valve Index&REG;-Upgrade Your Experience-Valve Corporation, HEADSET HEAD MOUNTED
   VanVoorhis CRW, 2007, TUTOR QUANT METHODS, V3, P43, DOI 10.20982/tqmp.03.2.p043
   Webel Sabine, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P123, DOI 10.1007/978-3-642-22021-0_15
   Weeks JK, 2021, ACAD RADIOL, V28, P871, DOI 10.1016/j.acra.2020.07.008
   Woodruff R., 2021, 72 INT ASTR C DUB UN
   Zhuang Y, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5542822
NR 28
TC 2
Z9 2
U1 2
U2 12
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 559
EP 570
DI 10.1007/s10055-021-00596-1
EA OCT 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000712484100001
DA 2024-07-18
ER

PT J
AU Augenstein, TE
   Kortemeyer, D
   Glista, L
   Krishnan, C
AF Augenstein, Thomas E.
   Kortemeyer, Daniel
   Glista, Lawrence
   Krishnan, Chandramouli
TI Enhancing mirror therapy via scaling and shared control: a novel
   open-source virtual reality platform for stroke rehabilitation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual rehabilitation; Motor control; Telehealth; Low cost; Illusion;
   Mirror neurons
ID UPPER EXTREMITY FUNCTION; UPPER-LIMB FUNCTION; MOTOR RECOVERY;
   REFLECTION; TASKS
AB Mirror therapy is increasingly used in stroke rehabilitation to improve functional movements of the affected limb. However, the extent of mirroring in conventional mirror therapy is typically fixed (1:1) and cannot be tailored based on the patient's impairment level. Further, the movements of the affected limb are not actively incorporated in the therapeutic process. To address these issues, we developed an immersive VR system using HTC Vive and Leap Motion, which communicates with our free and open-source software environment programmed using SteamVR and the Unity 3D gaming engine. The mirror therapy VR environment was incorporated with two novel features: (1) scalable mirroring and (2) shared control. In the scalable mirroring, mirror movements were programmed to be scalable between 0 and 1, where 0 represents no movements, 0.5 represents 50% mirroring, and 1 represents 100% mirroring. In shared control, the contribution of the mirroring limb to the movements was programmed to be scalable between 0 to 1, where 0 represents 100% contribution from the mirroring limb (i.e., no mirroring), 0.5 represents 50% of movements from the mirrored limb and 50% of movements from the mirroring limb, and 1 represents full mirroring (i.e., no shared movements). Validation experiments showed that these features worked appropriately. The proposed VR-based mirror therapy is the first fully developed system that is freely available to the rehabilitation science community. The scalable and shared control features can diversify mirror therapy and potentially augment the outcomes of rehabilitation, although this needs to be verified through future experiments.
C1 [Augenstein, Thomas E.; Kortemeyer, Daniel; Glista, Lawrence; Krishnan, Chandramouli] Michigan Med, Neuromuscular & Rehabil Robot Lab NeuRRo Lab, Dept Phys Med & Rehabil, 325 E Eisenhower Pkwy,Room 3011,3rd Floor, Ann Arbor, MI 48108 USA.
   [Augenstein, Thomas E.; Krishnan, Chandramouli] Univ Michigan, Robot Inst, Ann Arbor, MI 48109 USA.
   [Glista, Lawrence] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
   [Krishnan, Chandramouli] Univ Michigan, Dept Biomed Engn, Ann Arbor, MI 48109 USA.
   [Krishnan, Chandramouli] Univ Michigan, Sch Kinesiol, Ann Arbor, MI 48109 USA.
C3 University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan; University of Michigan System;
   University of Michigan; University of Michigan System; University of
   Michigan
RP Krishnan, C (corresponding author), Michigan Med, Neuromuscular & Rehabil Robot Lab NeuRRo Lab, Dept Phys Med & Rehabil, 325 E Eisenhower Pkwy,Room 3011,3rd Floor, Ann Arbor, MI 48108 USA.; Krishnan, C (corresponding author), Univ Michigan, Robot Inst, Ann Arbor, MI 48109 USA.; Krishnan, C (corresponding author), Univ Michigan, Dept Biomed Engn, Ann Arbor, MI 48109 USA.; Krishnan, C (corresponding author), Univ Michigan, Sch Kinesiol, Ann Arbor, MI 48109 USA.
EM mouli@umich.edu
FU University of Michigan Office of Research under the Mcubed Diamond
   grant; National Institutes of Health [R01 EB019834]; National Science
   Foundation [DGE 1256260, 1804053]
FX This work was partly supported by the University of Michigan Office of
   Research under the Mcubed Diamond grant, National Institutes of Health
   (Grant #R01 EB019834), and National Science Foundation (Award #DGE
   1256260 and Award #1804053). Any opinions, findings, and conclusions or
   recommendations expressed in this material are those of the author(s)
   and do not necessarily reflect the views of the funding agencies.
CR Abbink DA, 2012, COGN TECHNOL WORK, V14, P19, DOI 10.1007/s10111-011-0192-5
   Aiya KN, 2013, TOP STROKE REHABIL, V20, P210, DOI 10.1310/tsr2003-210
   Arya KN, 2019, NEUROPSYCHOL REHABIL, V29, P1193, DOI 10.1080/09602011.2017.1377087
   Arya KN, 2015, J STROKE CEREBROVASC, V24, P1738, DOI 10.1016/j.jstrokecerebrovasdis.2015.03.026
   Bai ZF, 2020, BRAIN BEHAV, V10, DOI 10.1002/brb3.1489
   Broderick P, 2018, GAIT POSTURE, V63, P208, DOI 10.1016/j.gaitpost.2018.05.017
   Crosbie JH, 2007, DISABIL REHABIL, V29, P1139, DOI 10.1080/09638280600960909
   Fritzsch C, 2014, RESTOR NEUROL NEUROS, V32, P269, DOI 10.3233/RNN-130343
   Garry MI, 2005, EXP BRAIN RES, V163, P118, DOI 10.1007/s00221-005-2226-9
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Heinrich C, 2021, VIRTUAL REAL-LONDON, V25, P313, DOI 10.1007/s10055-020-00456-4
   Hirschhauser CS., 2020, VIRT REAL INT ENH UP
   Hoermann S, 2017, DISABIL REHABIL, V39, P1503, DOI 10.1080/09638288.2017.1291765
   In T, 2016, MED SCI MONITOR, V22, P4046, DOI 10.12659/MSM.898157
   Kang YJ, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-71
   Kim K, 2016, J PHYS THER SCI, V28, P483, DOI 10.1589/jpts.28.483
   Kleim JA, 2008, J SPEECH LANG HEAR R, V51, pS225, DOI 10.1044/1092-4388(2008/018)
   Lee D, 2014, J STROKE CEREBROVASC, V23, P1319, DOI 10.1016/j.jstrokecerebrovasdis.2013.11.006
   Lu EC, 2011, DISABIL REHABIL-ASSI, V6, P420, DOI 10.3109/17483107.2010.544370
   Morales-Rodriguez Maria Lucila, 2007, Virtual Reality, V11, P175, DOI 10.1007/s10055-006-0063-1
   Morkisch N, 2019, RESTOR NEUROL NEUROS, V37, P421, DOI 10.3233/RNN-190935
   O'Sullivan N, 2018, PERCEPTION, V47, P197, DOI 10.1177/0301006617743392
   Organization WH, 2002, The world health report 2002: reducing risks, promoting healthy life
   Park Y, 2015, J PHYS THER SCI, V27, P1499, DOI 10.1589/jpts.27.1499
   Ramachandran VS, 2019, RESTOR NEUROL NEUROS, V37, P437, DOI 10.3233/RNN-190971
   RAMACHANDRAN VS, 1995, NATURE, V377, P489, DOI 10.1038/377489a0
   Ranganathan R, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0300-8
   Samuelkamaleshkumar S, 2014, ARCH PHYS MED REHAB, V95, P2000, DOI 10.1016/j.apmr.2014.06.020
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Subramanian SK, 2013, NEUROREHAB NEURAL RE, V27, P13, DOI 10.1177/1545968312449695
   Subramanian SK, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-36
   Thieme H, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008449.pub3
   Virani SS, 2020, CIRCULATION, V141, pE139, DOI 10.1161/CIR.0000000000000757
   Weber LM, 2019, AM J PHYS MED REHAB, V98, P783, DOI 10.1097/PHM.0000000000001190
   Zhu MH, 2020, Int J Nurs Sci, V7, P170, DOI 10.1016/j.ijnss.2020.04.004
NR 35
TC 5
Z9 5
U1 4
U2 31
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 525
EP 538
DI 10.1007/s10055-021-00593-4
EA OCT 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000707569100001
PM 35600315
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wu, HY
   Huang, KN
   Deng, YY
   Tu, HW
AF Wu, Huiyue
   Huang, Kaini
   Deng, Yanyi
   Tu, Huawei
TI Exploring the design space of eyes-free target acquisition in virtual
   environments
SO VIRTUAL REALITY
LA English
DT Article
DE Eyes-free target acquisition; Games; Immersive environments; Spatial
   memory; Virtual reality
AB Supporting smooth target acquisition is an important objective in immersive virtual reality (VR) environments. However, users were obliged to search for objects relying on the vision channel in traditional VR systems. Such eyes-engaged technologies may significantly degrade the interaction efficiency and user experience, particularly when users have to turn their head frequently to search for virtual objects in the limited field of view of a head-mounted display. In this paper, we report a two-stage study which investigates the capability of VR users to acquire spatial targets without eye engagement (i.e., eyes-free target acquisition). First, we measure the eyes-free performance of users in terms of control accuracy and subjective task load. Second, we evaluate the effects of eyes-free acquisition on memory capacity, spatial offset, and task completion time in the context of a VR game. Starting from a set of 54 spatial positions, we identify 18 optimal locations (half on the left side of the user's body and half on the right) that allow both accurate and comfortable target acquisition without visual attention. After a short training period, users could accurately and quickly acquire 17 targets in a VR game with an average offset of 10.5 cm and an average completion time of 2.7 s. According to our results, we suggest how to optimize the spatial layout, number of targets, target locations, and interaction techniques for eyes-free acquisition in VR applications. Our work can serve as a foundation for future development of eyes-free methods of target acquisition in VR.
C1 [Wu, Huiyue; Huang, Kaini; Deng, Yanyi] Sun Yat Sen Univ, Sch Commun & Design, Guangzhou, Peoples R China.
   [Wu, Huiyue] Guangdong Key Lab Big Data Anal & Simulat Publ Op, Guangzhou, Peoples R China.
   [Tu, Huawei] La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic, Australia.
C3 Sun Yat Sen University; La Trobe University
RP Tu, HW (corresponding author), La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic, Australia.
EM wuhuiyue@mail.sysu.edu.cn
OI Wu, Huiyue/0000-0001-7027-518X
FU National Natural Science Foundation of China [61772564]; Guangdong Basic
   and Applied Basic Research Foundation [2021A1515011990]
FX The authors wish to thank the anonymous reviewers for their insightful
   comments. We also want to thank Wanying Feng, Wanxue Xu, and Jinfang
   Zhang for their help in user interviews and data collection. This work
   was supported by the National Natural Science Foundation of China under
   Grant No. 61772564 and the Guangdong Basic and Applied Basic Research
   Foundation under Grant No. 2021A1515011990.
CR [Anonymous], 2004, P AUSTR USER INTERFA
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Caluya NR, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P387, DOI 10.1109/VR.2018.8447561
   Cheng C, 2012, SCI CHINA INFORM SCI, V55, P1528, DOI 10.1007/s11432-011-4436-z
   Cockburn A, 2011, INT J HUM-COMPUT ST, V69, P401, DOI 10.1016/j.ijhcs.2011.02.005
   Cockburn A., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P203, DOI 10.1145/503376.503413
   Davenport C, 1997, ARL9710LOGICON972 U
   De Lillo C, 2012, COGN PROCESS, V13, pS243, DOI 10.1007/s10339-012-0448-x
   Deng CL, 2019, HUM FACTORS, V61, P879, DOI 10.1177/0018720819831517
   Edge D., 2009, Proc. TEI'09, P69
   Fine JM, 2014, ACTA PSYCHOL, V149, P24, DOI 10.1016/j.actpsy.2014.02.012
   Forsberg A., 1996, P 9 ANN ACM S USER I, P95, DOI 10.1145/237091.237105
   Gacem H, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P51, DOI 10.1145/2983310.2985751
   Grasset, 2007, P 8 ACM SIGCHI NZ CH, P17, DOI DOI 10.1145/1278960.1278963
   Grossman Tovi., 2005, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI '05, P281, DOI [10.1145/1054972.1055012, DOI 10.1145/1054972.1055012]
   HART S G, 1988, P139
   HENRY D, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P33, DOI 10.1109/VRAIS.1993.380801
   Kolsch M., 2003, Proceedings of the human factors and ergonomics society annual meeting, V47, P787
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   Li FCY, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P125
   Lincoln Janet E., 1972, ENG DATA COMPENDIUM, V2, P1053
   MacLean A., 1991, Human-Computer Interaction, V6, P201, DOI 10.1207/s15327051hci0603&4_2
   Matheis RJ, 2007, CLIN NEUROPSYCHOL, V21, P146, DOI 10.1080/13854040601100668
   McMahan RP, 2015, HUM FACTORS ERGON, P285
   Penumudi SA, 2020, APPL ERGON, V84, DOI 10.1016/j.apergo.2019.103010
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Ramcharitar Adrian., 2018, Proceedings of the 44th Graphics Interface Conference, P123, DOI DOI 10.20380/GI2018.17
   Tavanti M, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P139, DOI 10.1109/INFVIS.2001.963291
   Tu HW, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300848
   Vanacken L, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P115
   Vogel D., 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095041, DOI 10.1145/1095034.1095041]
   Ware C., 1997, ACM Transactions on Computer-Human Interaction, V4, P309, DOI 10.1145/267135.267136
   Wilcox Laurie M., 2006, ACM Trans. on Perception, V3, P412, DOI [DOI 10.1145/1190036.1190041, 10.1145/1190036.1190041]
   Worden Aileen., 1997, P SIGCHI C HUMAN FAC, P266, DOI DOI 10.1145/258549.258724
   Wu HY, 2020, INT J HUM-COMPUT INT, V36, P978, DOI 10.1080/10447318.2019.1706331
   Xiao R, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1221, DOI 10.1145/2858036.2858212
   Yan YK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173616
   Zhou QS, 2020, IEEE T VIS COMPUT GR, V26, P3423, DOI [10.1109/TVCG.2020.3023570, 10.1109/TVCG.2020.3023.570]
NR 39
TC 3
Z9 3
U1 1
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2022
VL 26
IS 2
BP 513
EP 524
DI 10.1007/s10055-021-00591-6
EA OCT 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 1J0CG
UT WOS:000707569100003
DA 2024-07-18
ER

PT J
AU Montoya, MF
   Muñoz, J
   Henao, OA
AF Montoya, Maria Fernanda
   Munoz, John
   Henao, Oscar Alberto
TI Fatigue-aware videogame using biocybernetic adaptation: a pilot study
   for upper-limb rehabilitation with sEMG
SO VIRTUAL REALITY
LA English
DT Article
DE Videogame design; Upper limb; Virtual rehabilitation; sEMG;
   Biocybernetic adaptation; Monoparesis; Hemiparesis
ID VIRTUAL-REALITY; STROKE
AB Physical rehabilitation has been widely used to restore or maintain motor capabilities of patients with upper-limb mobility limitations. Despite its effectiveness, physical rehabilitation has several difficulties in engaging patients with the multiple therapeutical sessions required to obtain measurable benefits. Novel technologies incorporate gamification strategies to encourage participants to play during the rehabilitation sessions (instead of counting repetitions), providing benefits for therapy adherence. "Serious" or also called applied games have been used as a complementary therapy for neuromuscular disorders. However, the therapy effectiveness of several serious games for health has been questioned by the clinical experts since crucial factors associated with the physical rehabilitation are not commonly included in the gameplay. This study reports the use of a physiologically aware serious game developed using surface electromyography (sEMG) to capture upper-limb muscular fatigue levels of participants. We carried out a pilot study lasting four weeks with five participants diagnosed with monoparesis/hemiparesis to evaluate the feasibility of using the fatigue-adaptive game called Force Defense as a complementary tool for physical rehabilitation in a local community-based rehabilitation center. Preliminary results suggest a positive user gameplay experience as well as good usability of the system reported by participants after the first intervention session. Moreover, we showed how the physiological adaptation was able to encourage participants to maintain exertion in the therapeutically desired zone, thus improving the system's effectiveness. Participants also improved in their functional abilities of the upper limbs and the game performance measured in pre- and post-moments and reported reduced levels of perceived fatigue after the end of the training program.
C1 [Montoya, Maria Fernanda; Munoz, John; Henao, Oscar Alberto] Univ Tecnol Pereira, HCI Grp, Pereira, Colombia.
   [Munoz, John] Univ Waterloo, Syst Design Engn Dept, Waterloo, ON, Canada.
C3 Universidad Tecnologica de Pereira; University of Waterloo
RP Montoya, MF (corresponding author), Univ Tecnol Pereira, HCI Grp, Pereira, Colombia.
EM mf.mv@utp.edu.co; john.munoz.hci@uwaterloo.ca; oscarhe@utp.edu.co
OI Montoya, Maria Fernanda/0000-0001-8587-2358
CR Agredo CA., 2005, ARQ NEURO-PSIQUIAT, V3, P847
   [Anonymous], P 18 INT C HUM COMP
   [Anonymous], 2008, GAME EXPERIENC UNPUB
   Bonnechere B., 2018, Serious games in physical rehabilitation: from theory to practice
   Borg E, 2010, SCAND J MED SCI SPOR, V20, P644, DOI 10.1111/j.1600-0838.2009.00985.x
   Borg G., 1998, Borg's Perceived Exertion and Pain Scales, DOI DOI 10.1249/00005768-199809000-00018
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Brooks AL., 2018, RECENT ADV TECHNOLOG, DOI 10.1007/978-3-319-49879-9
   Grecco LAC, 2015, CLIN REHABIL, V29, P1212, DOI 10.1177/0269215514566997
   Corbetta D, 2015, J PHYSIOTHER, V61, P117, DOI 10.1016/j.jphys.2015.05.017
   Cram JR, 2011, CRAMS INTRO SURFACE
   Csikszentmihalyi M., 1975, Beyond boredom and anxiety, DOI DOI 10.1037/10516-164
   De Luca CJ, 1997, J APPL BIOMECH, V13, P135, DOI 10.1123/jab.13.2.135
   Dorner R, 2016, 2 INT C PERS TECHN, V9970, DOI 10.1007/978-3-319-46152-6
   Fairclough S.H., 2014, ADV PHYSL COMPUTING
   Fairclough SH, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P571
   Galiano-Castillo N, 2014, EUR J ONCOL NURS, V18, P206, DOI 10.1016/j.ejon.2013.10.008
   Hocine N, 2011, 2011 IEEE 1 INT C SE, P1, DOI [10.1109/SeGAH.2011.6165459, DOI 10.1109/SEGAH.2011.6165459]
   Jayaram S, 1997, COMPUT AIDED DESIGN, V29, P575, DOI 10.1016/S0010-4485(96)00094-2
   Kourtis LC, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0084-2
   Laver KE, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub2
   Levac DanielleE., 2014, VIRTUAL REALITY PHYS, P25
   Manera V, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01243
   Merletti R., 2016, Surface Electromyography: Physiology, Engineering. and Applications
   Merletti R., 2000, European Journal of Physical and Rehabilitation Medicine, V36, P167
   Montoya MF, 2019, PROCEEDINGS OF THE 5TH WORKSHOP ON ICTS FOR IMPROVING PATIENTS REHABILITATION RESEARCH TECHNIQUES, REHAB'19, P152, DOI 10.1145/3364138.3364170
   Montoya MF, 2020, IEEE T NEUR SYS REH, V28, P740, DOI 10.1109/TNSRE.2020.2968869
   Muñoz JE, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P329, DOI 10.1145/3242671.3242673
   Newbutt N., 2015, TECHNOLOGIES INCLUSI
   Pons JL., 2014, Emerging Therapies in Neurorehabilitation
   Puddu G., 2013, REHABILITATION SPORT
   Rawat S, 2016, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2016), P115, DOI 10.1109/SYSMART.2016.7894501
   Sawyer B, 2008, IEEE COMPUT GRAPH, V28, P83, DOI 10.1109/MCG.2008.114
   Serbedzija NB, 2009, IEEE C EVOL COMPUTAT, P2063, DOI 10.1109/CEC.2009.4983195
   Sinclair J., 2009, P 6 AUSTR C INT ENT, P1
   Taub E, 2013, STROKE, V44, P1383, DOI 10.1161/STROKEAHA.111.000559
NR 36
TC 3
Z9 3
U1 0
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 277
EP 290
DI 10.1007/s10055-021-00561-y
EA JUL 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000679655600002
DA 2024-07-18
ER

PT J
AU Martirosov, S
   Bures, M
   Zítka, T
AF Martirosov, Sergo
   Bures, Marek
   Zitka, Tomas
TI Cyber sickness in low-immersive, semi-immersive, and fully immersive
   virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Cyber sickness; Virtual reality; Stereoscopic projection; Head-mounted
   display; Dexterity test
ID MOTION SICKNESS; SEX-DIFFERENCES; POSTURAL SWAY; ENVIRONMENTS;
   PERFORMANCE; CYBERSICKNESS; SIMULATOR; QUALITY; SKILLS; TRAVEL
AB It is known that virtual reality (VR) experience may cause cyber sickness. One aspect of VR is an immersion or otherwise sense of presence, the sense of feeling oneself in a virtual world. In this paper an experiment which was conducted in order to find the link between level of immersion and cyber sickness felt by participants is presented. Eighty-nine participants aged between 19 and 36 years have been equally divided into four groups with different level of VR immersion. The low-immersive group was represented by PC with monoscopic screen, the semi-immersive group was represented by CAVE with stereoscopic projector, the fully immersive group was represented by VR head-mounted display, and the last group was the control group without any kind of immersion. The task for the participants was to navigate through the maze for a specified amount of time (10 min). The Simulator Sickness Questionnaire was used as a subjective measure tool for cyber sickness level and Grooved Pegboard Test for assessing the fine dexterity, both before and after the experiment. Regarding the time spend in VR the fully immersive environment had the biggest problems as more than half of the participants had to stop before 10 min (p < 0.001). Concerning the cyber sickness, the significant increase in nausea score between pre-test and post-test scores has been observed in semi-immersive group (p = 0.0018) and fully immersive group (p < 0.0001). The increase in oculomotor score was smaller. The significant difference was noted only in fully immersive group (p = 0.0449). In spite of great nausea factor after the VR immersion the participants did not show a decrease of fine dexterity in any group (p < 0.001).
C1 [Martirosov, Sergo; Bures, Marek; Zitka, Tomas] Univ West Bohemia, Univ 8, Plzen 30100, Czech Republic.
C3 University of West Bohemia Pilsen
RP Bures, M (corresponding author), Univ West Bohemia, Univ 8, Plzen 30100, Czech Republic.
EM martiros@kpv.zcu.cz; buresm@kpv.zcu.cz
RI Bures, Marek/I-9077-2016; Bures, Marek/HSC-6984-2023
FU University of West Bohemia [SGS-2019-002, SGS-2021-028]
FX This paper was created with the subsidy of the University of West
   Bohemia internal Grant No. SGS-2019-002.; This paper was created with
   the subsidy of the University of West Bohemia internal Grant No.
   SGS-2021-028 -Developmental and training tools for the interaction of
   man and cyber-physical production system.
CR Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Bailenson J., 2018, EXPERIENCE DEMAND WH
   Bockelman P, 2017, CCIS, P3, DOI DOI 10.1007/978-3-319-58753-0_1
   Boot WR, 2008, ACTA PSYCHOL, V129, P387, DOI 10.1016/j.actpsy.2008.09.005
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Bruck S, 2009, STUD HEALTH TECHNOL, V144, P169, DOI 10.3233/978-1-60750-017-9-169
   Bryden PJ, 2005, BRAIN COGNITION, V58, P258, DOI 10.1016/j.bandc.2004.12.004
   Callaghan MJ, 2015, INT CONF REMOT ENGIN, P235, DOI 10.1109/REV.2015.7087298
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Chatti MA, 2012, INT J TECHNOL ENHANC, V4, P318, DOI 10.1504/IJTEL.2012.051815
   Chompoonuch J., 2011, Proceeding of The School of Information and Telecommunication Engineering, Tokai University, Vol, V4, No, P34
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Coe Robert, 2002, ITS EFFECT SIZE STUP, P1
   Davis S, 2015, P 11 AUSTR C INT ENT, V27, P30
   Djaouti D., 2011, Handb. Res. Improv. Learn. Motiv. through Educ. games Multidiscip. approaches, P118, DOI 10.4018/978-1-60960-495-0
   Dorado Jose L., 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P145, DOI 10.1109/3DUI.2015.7131742
   Duh HBL, 2004, PRESENCE-TELEOP VIRT, V13, P578, DOI 10.1162/1054746042545283
   Duh HBL, 2002, PRESENCE-TELEOP VIRT, V11, P324, DOI 10.1162/105474602317473259
   Duh HBL, 2001, P IEEE VIRT REAL ANN, P235, DOI 10.1109/VR.2001.913791
   Durlach, 1992, ACM SIGGRAPH COMPUT, DOI 10.1145/142413.142416
   Emoto M, 2008, DISPLAYS, V29, P90, DOI 10.1016/j.displa.2007.09.010
   Eseryel D, 2014, EDUC TECHNOL SOC, V17, P42
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Hale K.S., 2002, HDB VIRTUAL ENV DESI
   Hale KS, 2006, APPL ERGON, V37, P329, DOI 10.1016/j.apergo.2005.06.009
   Hell S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P153, DOI 10.1109/AIVR.2018.00032
   Jarmon L, 2009, COMPUT EDUC, V53, P169, DOI 10.1016/j.compedu.2009.01.010
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kiryu T, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-34
   Kitchen D., 1998, Journal of Educational Technology Systems, V27, P245
   Kobayashi N, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P664, DOI 10.1109/GCCE.2015.7398678
   Koslucher F, 2016, EXP BRAIN RES, V234, P313, DOI 10.1007/s00221-015-4462-y
   Kuze J, 2008, DISPLAYS, V29, P159, DOI 10.1016/j.displa.2007.09.007
   Kwok KKK, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P91, DOI 10.1109/ISMAR-Adjunct.2018.00041
   Lathan, 2001, REAL TIME GRAPHICS, V9, P3
   LaValle SM, 2014, IEEE INT CONF ROBOT, P187, DOI 10.1109/ICRA.2014.6906608
   Lemole GM, 2007, NEUROSURGERY, V61, P142, DOI 10.1227/01.neu.0000279734.22931.21
   Liu HR, 2018, I C VIRTUAL REALITY, P150, DOI 10.1109/ICVRV.2018.00052
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Miller HL, 2016, CYBERPSYCH BEH SOC N, V19, P246, DOI 10.1089/cyber.2014.0682
   Monahan T, 2008, COMPUT EDUC, V50, P1339, DOI 10.1016/j.compedu.2006.12.008
   MOSKALIUK J, 2013, CYBERPSYCHOLOGYBEHAV
   Moskaliuk J, 2013, ERGONOMICS, V56, P195, DOI 10.1080/00140139.2012.745623
   Narciso D, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON GRAPHICS AND INTERACTION (ICGI 2019), P115, DOI [10.1109/ICGI47575.2019.8955071, 10.1109/icgi47575.2019.8955071]
   National Research Council, 2000, PEOPLE LEARN BRAIN M
   Waliño-Paniagua CN, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/9780587
   Papachristos NM, 2017, IEEE INT CONF ADV LE, P477, DOI 10.1109/ICALT.2017.145
   Parsons TD, 2004, NEUROPSYCHOLOGIA, V42, P555, DOI 10.1016/j.neuropsychologia.2003.08.014
   Patterson R, 2006, HUM FACTORS, V48, P555, DOI 10.1518/001872006778606877
   Polcar J., 2015, MM Science Journal, P613, DOI [DOI 10.17973/MMSJ.2015_06_201516, 10.17973/MMSJ.2015_06_201516]
   Porcino TM, 2017, IEEE INT CONF SERIOU
   Prabhu VG, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P235, DOI 10.1109/AIVR46125.2019.00049
   Regenbrecht H, 2015, TECHNOLOGY REHABILIT, P85
   Romano DM, 2001, CYBERPSYCHOL BEHAV, V4, P265, DOI 10.1089/109493101300117947
   RUFF RM, 1993, PERCEPT MOTOR SKILL, V76, P1219, DOI 10.2466/pms.1993.76.3c.1219
   Schild J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P775, DOI 10.1109/VR.2018.8446160
   Seay AF, 2001, P IEEE VIRT REAL ANN, P299, DOI 10.1109/VR.2001.913806
   Singh RP, 2020, DIABETES METAB SYND, V14, P661, DOI 10.1016/j.dsx.2020.05.011
   Speicher M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P816, DOI 10.1109/VR.2018.8446187
   Stauffert JP, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P121, DOI 10.1109/VR.2018.8446195
   Stoffregen TA, 2008, HUM FACTORS, V50, P322, DOI 10.1518/001872008X250755
   Sugita N, 2007, P ANN INT IEEE EMBS, P303, DOI 10.1109/IEMBS.2007.4352284
   Suma EA, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P27, DOI 10.1109/3DUI.2010.5444726
   Suma EA, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P245, DOI 10.1109/VR.2009.4811037
   Vasylevska K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P566, DOI [10.1109/VR.2019.8797752, 10.1109/vr.2019.8797752]
   Wang YY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1874, DOI [10.1109/VR.2019.8798213, 10.1109/vr.2019.8798213]
   Wenger, 2019, 2018 9 INT C INF INT
   Young SD, 2006, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2006.44
   Zanbaka CA, 2005, IEEE T VIS COMPUT GR, V11, P694, DOI 10.1109/TVCG.2005.92
   ZHONGGEN Y, 2019, INT J COMPUT GAMES T
NR 74
TC 56
Z9 64
U1 7
U2 47
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 15
EP 32
DI 10.1007/s10055-021-00507-4
EA MAY 2021
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000652111800001
PM 34025203
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Tan, SY
   Arshad, H
   Abdullah, A
AF Tan, Siok Yee
   Arshad, Haslina
   Abdullah, Azizi
TI An improved colour binary descriptor algorithm for mobile augmented
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Colour descriptor; FREAK; HSV; Mobile augmented reality; RGB
ID PERFORMANCE
AB The incorporation of both virtual content and real world in augmented reality (AR) allows real-time engagement with the virtual objects. The selection of an appropriate tracking algorithm is important to optimise the performance of mobile AR applications given the limited processing capabilities and memories of mobile devices like smartphones. Tracking in AR consists of four essential components, namely detector, descriptor, matcher, and pose estimator. Since a descriptor substantially affects the overall performance of a mobile AR application, it must have short computational time and remains invariant to scale, rotation, and lighting changes. Studies have proposed Fast Retina Keypoint (FREAK) descriptor as the most suitable descriptor for mobile AR applications. Unlike other greyscale descriptors, FREAK has shorter computational time and is less likely to be affected by scale and rotation changes. However, it overlooks the vital colour space information. Focusing on enhancing the efficiency and robustness of FREAK, this study proposed the use of CRH-FREAK (RGB + HSV) descriptor and applied the vertical concatenation technique that combined all extracted keypoints vertically. The robustness of the proposed descriptors against scale, rotation, and lighting changes was verified using Mikolajczyk and Amsterdam Library of Object Images (ALOI) datasets. The developed CRH-FREAK descriptors used six colour spaces to describe the keypoints, which made them slower than the original FREAK. However, the size reduction of CRH-FREAK from 512 bits to 128 bits in this study successfully reduced the computational time to 29.49 ms, which was found comparable to the original FREAK. The improved efficiency and robustness of a 128-bit CRH-FREAK descriptor benefit the future development of mobile AR applications that remain invariant to scale, rotation, and lighting changes.
C1 [Tan, Siok Yee; Arshad, Haslina; Abdullah, Azizi] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence & Technol, Bangi 43600, Selangor, Malaysia.
C3 Universiti Kebangsaan Malaysia
RP Tan, SY (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Artificial Intelligence & Technol, Bangi 43600, Selangor, Malaysia.
EM esther@ukm.edu.my
FU Ministry of Higher Education Malaysia [FRGS/1/2018/ICT01/UKM/02/5]
FX This work was supported by the Ministry of Higher Education Malaysia
   (FRGS/1/2018/ICT01/UKM/02/5).
CR Abd Majid N. A., 2018, J. ICT Res. Appl, V8, P1494, DOI [10.18517/ijaseit.8.4-2.6801, DOI 10.18517/IJASEIT.8.4-2.6801]
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bernal J., 2010, Feature detectors and feature descriptors: Where we are now
   Bianco S, 2015, DIGIT SIGNAL PROCESS, V44, P1, DOI 10.1016/j.dsp.2015.06.001
   Bleser Gabriele., 2009, VISUAL INERTIAL SLAM
   Bolyos, 2013, P CESCG 2013 17 CENT
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Cruz E, 2019, VIRTUAL REAL-LONDON, V23, P281, DOI 10.1007/s10055-018-0338-3
   Fan P, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P726, DOI 10.1109/ICNIDC.2009.5360809
   Felzenszwalb P., 2013, TRECVID 2013, P1
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   GEUSEBROEK J, 2005, INT J COMPUT VISION
   Guan W, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348826
   Hua JZ, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S021800141940010X
   Kottman M., 2011, SPRING C COMP GRAPH, P28
   LAM M, 2020, VIRTUAL REAL-LONDON
   Lam MC, 2020, TEM J, V9, P351, DOI 10.18421/TEM91-48
   Less, 2014, P 4 IIEEJ INT WORKSH
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maekawa, 2014, EVALUATION IMAGE FEA
   Mahieu R, 2015, REAL TIME MOBILE AUG
   Markatopoulou Foteini, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P282, DOI 10.1007/978-3-319-14445-0_25
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nguyen TV, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2964284.2973807
   Obeidy WK, 2013, LECT NOTES COMPUT SC, V8237, P447, DOI 10.1007/978-3-319-02958-0_41
   Rabbi I., 2013, ACTA GRAPH, V24, P29, DOI DOI 10.9790/0661-0222329
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Satoh K, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P67, DOI 10.1109/ISAR.2001.970516
   Sung YT, 2016, COMPUT EDUC, V94, P252, DOI 10.1016/j.compedu.2015.11.008
   Tan SY, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0207191
   Tan SY., 2018, INT J ADV SCI ENG IN, V8, P1672, DOI [10.18517/ijaseit.8.4-2.6810, DOI 10.18517/IJASEIT.8.4-2.6810]
   Tang GL, 2019, MULTIMED TOOLS APPL, V78, P23415, DOI 10.1007/s11042-019-7566-8
   Uchiyama H., 2012, 18 KOR JAP JOINT WOR
   Ufkes A, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P226, DOI 10.1109/CRV.2013.51
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wafy M, 2015, INT J ADV COMPUT SC, V6, P81
   Wu J, 2013, MEAS SCI REV, V13, P122, DOI 10.2478/msr-2013-0021
   Yang CK, 2020, VIRTUAL REAL-LONDON, V24, P527, DOI 10.1007/s10055-019-00415-8
   Zhang LF, 2018, TEH VJESN, V25, P1119, DOI 10.17559/TV-20180408120907
   Zhou JD, 2011, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP.2011.6116405
NR 43
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2021
VL 25
IS 4
BP 1193
EP 1219
DI 10.1007/s10055-021-00519-0
EA MAY 2021
PG 27
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA WK6PS
UT WOS:000649226500001
DA 2024-07-18
ER

PT J
AU Chiquet, S
   Martarelli, CS
   Mast, FW
AF Chiquet, Sandra
   Martarelli, Corinna S.
   Mast, Fred W.
TI Eye movements to absent objects during mental imagery and visual memory
   in immersive virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Mental imagery; Visual memory; Eye movements; Eye
   tracking
ID FUNCTIONAL-ROLE; LOOKING; PLAY
AB The role of eye movements in mental imagery and visual memory is typically investigated by presenting stimuli or scenes on a two-dimensional (2D) computer screen. When questioned about objects that had previously been presented on-screen, people gaze back to the location of the stimuli, even though those regions are blank during retrieval. It remains unclear whether this behavior is limited to a highly controlled experimental setting using 2D screens or whether it also occurs in a more naturalistic setting. The present study aims to overcome this shortcoming. Three-dimensional (3D) objects were presented along a circular path in an immersive virtual room. During retrieval, participants were given two tasks: to visualize the objects, which they had encoded before, and to evaluate a statement about visual details of the object. We observed longer fixation duration in the area, on which the object was previously displayed, when compared to other possible target locations. However, in 89% of the time, participants fixated none of the predefined areas. On the one hand, this shows that looking at nothing may be overestimated in 2D screen-based paradigm, on the other hand, the looking at nothing effect was still present in the 3D immersive virtual reality setting, and thus it extends external validity of previous findings. Eye movements during retrieval reinstate spatial information of previously inspected stimuli.
C1 [Chiquet, Sandra; Mast, Fred W.] Univ Bern, Dept Psychol, CH-3012 Bern, Switzerland.
   [Martarelli, Corinna S.] Swiss Distance Univ Inst, CH-3900 Brig, Switzerland.
C3 University of Bern
RP Chiquet, S (corresponding author), Univ Bern, Dept Psychol, CH-3012 Bern, Switzerland.
EM sandra.chiquet@psy.unibe.ch; corinna.martarelli@fernuni.ch;
   fred.mast@psy.unibe.ch
RI Martarelli, Corinna/AAJ-2990-2021
OI Martarelli, Corinna/0000-0001-9160-793X
FU University of Bern
FX Open access funding provided by University of Bern.
CR Altmann GTM, 2004, COGNITION, V93, pB79, DOI 10.1016/j.cognition.2004.02.005
   Bone MB, 2019, CEREB CORTEX, V29, P1075, DOI 10.1093/cercor/bhy014
   Brandt SA, 1997, J COGNITIVE NEUROSCI, V9, P27, DOI 10.1162/jocn.1997.9.1.27
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   CEBOLLA A, 2019, FRONT PSYCHOL, V10
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Eichert N, 2018, BEHAV RES METHODS, V50, P1102, DOI 10.3758/s13428-017-0929-z
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Grogorick S, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119890
   Gurtner LM, 2019, J VISION, V19, DOI 10.1167/19.1.17
   Harris DJ, 2019, EXP BRAIN RES, V237, P2761, DOI 10.1007/s00221-019-05642-8
   Johansson O, 2011, STUD INT PERFORM, P33
   Johansson R, 2006, COGNITIVE SCI, V30, P1053, DOI 10.1207/s15516709cog0000_86
   Johansson R, 2014, PSYCHOL SCI, V25, P236, DOI 10.1177/0956797613498260
   Johansson R, 2012, J EXP PSYCHOL HUMAN, V38, P1289, DOI 10.1037/a0026585
   Kisker J., 2019, Current Psychology, P1
   Kruschke J, 2014, DOING BAYESIAN DATA, DOI [DOI 10.1016/B978-0-12-405888-0.09999-2, DOI 10.1016/B978-0-12-405888-0.00001-5]
   KUMCU A, 2018, PSYCHOL RES
   Kumcu A., 2016, P 38 ANN C COGNITIVE, P2387
   Laeng B, 2002, COGNITIVE SCI, V26, P207, DOI 10.1016/S0364-0213(01)00065-9
   Laeng B, 2014, COGNITION, V131, P263, DOI 10.1016/j.cognition.2014.01.003
   Lee MD, 2005, PSYCHOL REV, V112, P662, DOI 10.1037/0033-295X.112.3.662
   Lohr DJ, 2019, EVALUATING DATA QUAL
   Maggio MG, 2019, J NATL MED ASSOC, V111, P457, DOI 10.1016/j.jnma.2019.01.003
   Makowski D, 2017, CONSCIOUS COGN, V53, P194, DOI 10.1016/j.concog.2017.06.015
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Martarelli CS, 2017, PSYCHOL RES-PSYCH FO, V81, P721, DOI 10.1007/s00426-016-0781-2
   Martarelli CS, 2013, PSYCHOL RES-PSYCH FO, V77, P303, DOI 10.1007/s00426-012-0439-7
   Martarelli CS, 2011, BRIT J DEV PSYCHOL, V29, P425, DOI 10.1348/026151010X495844
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Ospina R, 2012, COMPUT STAT DATA AN, V56, P1609, DOI 10.1016/j.csda.2011.10.005
   Richardson DC, 2000, COGNITION, V76, P269, DOI 10.1016/S0010-0277(00)00084-6
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Scholz A., 2011, Proceedings of the 33rd Annual Conference of the Cognitive Science Society, P1070
   Scholz A, 2018, MEM COGNITION, V46, P230, DOI 10.3758/s13421-017-0760-x
   Scholz A, 2016, PSYCHOL RES-PSYCH FO, V80, P149, DOI 10.1007/s00426-014-0639-4
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spivey MJ, 2001, PSYCHOL RES-PSYCH FO, V65, P235, DOI 10.1007/s004260100059
   Wagenmakers EJ, 2007, PSYCHON B REV, V14, P779, DOI 10.3758/BF03194105
   Wantz AL, 2016, COGN PROCESS, V17, P105, DOI 10.1007/s10339-015-0741-6
NR 41
TC 12
Z9 12
U1 1
U2 15
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2021
VL 25
IS 3
BP 655
EP 667
DI 10.1007/s10055-020-00478-y
EA OCT 2020
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA UD3ZW
UT WOS:000583485200001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Jamil, MH
   Park, W
   Eid, M
AF Jamil, Muhammad Hassan
   Park, Wanjoo
   Eid, Mohamad
TI Emotional responses to watching and touching 3d emotional face in a
   virtual environment
SO VIRTUAL REALITY
LA English
DT Article
DE Emotions; Facial expressions; Haptic interaction; Virtual environments
ID FACIAL EXPRESSIONS; CIRCUMPLEX MODEL; PERCEPTION; RECOGNITION;
   DIMENSIONS; VALENCE; REALITY
AB Facial expressions play a crucial role in modulating the emotional responses in the viewers. Touch is an important factor in shaping human emotions and social communication. The objective of this study is to investigate the effects of viewing and touching a virtual emotional face on the emotional responses of a viewer/toucher. In the case of touching the model, the effects of physical properties, namely stiffness and texture, are examined. Emotional facial expressions for neutrality, anger, fear, disgust, happiness, surprise, and sadness are developed and experimentally validated for the visual stimuli whereas four combinations of stiffness/texture properties are examined for the physical properties (low/high stiffness and smooth/rough texture). 25 participants viewed and touched the virtual emotional face and reported their respective emotional responses. The results showed that watching angry, happy, surprised, and sad faces significantly increased their anger, happiness, surprise, and sadness levels, respectively (p < 0.05). Watching a scared or a sad face significantly modulated the participants' surprise levels (p < 0.05). On the other hand, viewing and touching an angry face significantly reduced the surprise level in the toucher (p < 0.05). As for differences based on physical properties, our results suggested that viewing and touching the disgusted face significantly modulated sadness. In particular, high stiffness/rough texture condition resulted in a significant increase in sadness while viewing and touching the disgusted face, compared to the high stiffness/smooth texture condition (p < 0.01). These conclusions suggest that viewing and touching an emotional face in a virtual environment modulates the emotional responses in the viewer/toucher. Findings of this study help the field of virtual reality to expand to a greater understanding of building emotionally compelling interpersonal interactions in the virtual environments.
C1 [Jamil, Muhammad Hassan; Park, Wanjoo; Eid, Mohamad] New York Univ Abu Dhabi, Abu Dhabi 129188, Saadiyat Island, U Arab Emirates.
C3 New York University Abu Dhabi
RP Eid, M (corresponding author), New York Univ Abu Dhabi, Abu Dhabi 129188, Saadiyat Island, U Arab Emirates.
EM mohamad.eid@nyu.edu
OI Jamil, Muhammad Hassan/0000-0001-9854-8733; Park,
   Wanjoo/0000-0003-1467-4156
FU New York University Abu Dhabi
FX This research was supported by New York University Abu Dhabi.
CR Abdi H., 2010, ENCY RES DESIGN, V169, P1
   [Anonymous], 2002, Handbook of Psychology, DOI DOI 10.1002/0471264385.WEI0406
   [Anonymous], 1984, APPROACHES EMOTION
   Aviezer H, 2008, PSYCHOL SCI, V19, P724, DOI 10.1111/j.1467-9280.2008.02148.x
   Barnes CJ, 2004, WEAR, V257, P740, DOI 10.1016/j.wear.2004.03.018
   Baumeister R. F., 2001, Review of General Psychology, V5, P323, DOI [10.1037/1089-2680.5.4.323, DOI 10.1037/1089-2680.5.4.323]
   Bernal G., 2017, P CHI C HUM FACT COM, P2395, DOI 10.1145/3027063.3053207
   Bhatta SR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00367
   Calbi M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01684
   Cardello AV, 2003, TEXT RES J, V73, P221, DOI 10.1177/004051750307300306
   Chen XJ, 2009, INT J DES, V3, P67
   CHILDS THC, 2007, J ENG TRIBOL, V221, P427, DOI DOI 10.1243/13506501JET217
   Dailey MN, 2002, J COGNITIVE NEUROSCI, V14, P1158, DOI 10.1162/089892902760807177
   Deng H, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02278
   Dimberg U, 2011, J NONVERBAL BEHAV, V35, P17, DOI 10.1007/s10919-010-0098-6
   Dyck M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003628
   Eid MA, 2016, IEEE ACCESS, V4, P26, DOI 10.1109/ACCESS.2015.2497316
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Essick GK, 2010, NEUROSCI BIOBEHAV R, V34, P192, DOI 10.1016/j.neubiorev.2009.02.003
   ETCOFF NL, 1992, COGNITION, V44, P227, DOI 10.1016/0010-0277(92)90002-Y
   Flack WF, 1999, EUR J SOC PSYCHOL, V29, P203, DOI 10.1002/(SICI)1099-0992(199903/05)29:2/3<203::AID-EJSP924>3.0.CO;2-8
   Friesen E., 1978, PALO ALTO, V3
   GESCHEIDER GA, 1991, PERCEPT PSYCHOPHYS, V50, P45, DOI 10.3758/BF03212204
   Hatfield E., 1993, CURR DIR PSYCHOL SCI, V2, P96, DOI [DOI 10.1111/1467-8721.EP10770953, 10.1111/1467-8721.ep10770953]
   Hess U, 2013, PERS SOC PSYCHOL REV, V17, P142, DOI 10.1177/1088868312472607
   HOLLINS M, 1993, PERCEPT PSYCHOPHYS, V54, P697, DOI 10.3758/BF03211795
   Israr A, 2018, 2018 CHI C HUM FACT, P1, DOI DOI 10.1145/3170427.3188546EVENT-PLACE:MONTREALQC,CANADA
   Klinger E, 2005, CYBERPSYCHOL BEHAV, V8, P76, DOI 10.1089/cpb.2005.8.76
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Kret ME, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00810
   Lane RD, 1999, NEUROPSYCHOLOGIA, V37, P989, DOI 10.1016/S0028-3932(99)00017-2
   Lawrence-Wood ER, 2011, TRUST ME THIS IS NT
   Lederman SJ, 2007, PSYCHOL SCI, V18, P158, DOI 10.1111/j.1467-9280.2007.01866.x
   Lederman SJ, 2007, CAN J EXP PSYCHOL, V61, P169, DOI 10.1037/cjep2007017
   Lederman SJ, 2008, IEEE T HAPTICS, V1, P27, DOI [10.1109/TOH.2008.3, 10.1109/ToH.2008.3]
   Lewis MB, 2012, EMOTION, V12, P852, DOI 10.1037/a0029275
   Löken LS, 2009, NAT NEUROSCI, V12, P547, DOI 10.1038/nn.2312
   Lu YZ, 2016, SOC NEUROSCI-UK, V11, P618, DOI 10.1080/17470919.2015.1120238
   Marcus GE, 2017, POLIT SCI RES METH, V5, P733, DOI 10.1017/psrm.2015.65
   Min YK, 2005, APPL PSYCHOPHYS BIOF, V30, P137, DOI 10.1007/s10484-005-4310-0
   Mumenthaler C, 2015, J EXP PSYCHOL GEN, V144, P392, DOI 10.1037/xge0000059
   Nagano H., 2013, International J. Affective Engineering, V12, P375, DOI DOI 10.5057/IJAE.12.375
   Oatley K., 1987, Cogn Emot, V1, P29, DOI DOI 10.1080/02699938708408362
   Okamoto S, 2013, IEEE T HAPTICS, V6, P81, DOI [10.1109/ToH.2012.32, 10.1109/TOH.2012.32]
   Ollivier R, 2019, MUSIC PERCEPT, V37, P95, DOI 10.1525/MP.2019.37.2.95
   Parkinson B, 2009, PERS SOC PSYCHOL B, V35, P1071, DOI 10.1177/0146167209336611
   Pell PJ, 2011, VISION RES, V51, P1889, DOI 10.1016/j.visres.2011.06.017
   Peters K, 2015, PSYCHOL BULL, V141, P966, DOI 10.1037/bul0000020
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Ravaja N, 2017, SCI REP-UK, V7, DOI 10.1038/srep40504
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schroeder U, 2004, HUM BRAIN MAPP, V23, P181, DOI 10.1002/hbm.20057
   Seeley SH, 2015, CURR OPIN PSYCHOL, V3, P58, DOI 10.1016/j.copsyc.2015.02.009
   Singh H, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00893
   Smith C, 1997, PSYCHOL FACIAL EXPRE, V229
   Susskind JM, 2007, NEUROPSYCHOLOGIA, V45, P152, DOI 10.1016/j.neuropsychologia.2006.05.001
   Vrticka P, 2014, EMOTION, V14, P161, DOI 10.1037/a0034619
   Yohanan S, 2012, INT J SOC ROBOT, V4, P163, DOI 10.1007/s12369-011-0126-7
   Zhao K, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074096
NR 61
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 553
EP 564
DI 10.1007/s10055-020-00473-3
EA OCT 2020
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000579250500001
DA 2024-07-18
ER

PT J
AU Clifton, J
   Palmisano, S
AF Clifton, Jeremy
   Palmisano, Stephen
TI Effects of steering locomotion and teleporting on cybersickness and
   presence in HMD-based virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Motion sickness; Cybersickness; Virtual reality; Head-mounted display;
   Presence
ID INDUCED MOTION SICKNESS; CONSOLE VIDEO GAMES; POSTURAL INSTABILITY;
   OPTOKINETIC NYSTAGMUS; SIMULATOR SICKNESS; SEX-DIFFERENCES; VECTION;
   ENVIRONMENTS; CUES; EXPERIENCE
AB While head-mounted display-based virtual reality (VR) can produce compelling feelings of presence (or "being there") in its users, it also often induces motion sickness. This study compared the presence, cybersickness and perceptions of self-motion (or "vection") induced when using two common methods of virtual locomotion: steering locomotion and teleporting. In four trials, conducted over two separate days, 25 participants repeatedly explored the "Red Fall" virtual environment in the game Nature Treks VR for 16 min at a time. Although steering locomotion was found to be more sickening on average than teleporting, 9 participants reported more severe sickness while teleporting. On checking their spontaneous postural activity before entering VR, these "TELEsick" participants were found to differ from "STEERsick" participants in terms of their positional variability when attempting to stand still. While cybersickness was not altered by having the user stand or sit during gameplay, presence was enhanced by standing during virtual locomotion. Cybersickness was found to increase with time in trial for both methods of virtual locomotion. By contrast, presence only increased with time in trial during steering locomotion (it did not vary over time when teleporting). Steering locomotion was also found to generate greater presence for female, but not male, participants. While there was not a clear advantage for teleporting over steering locomotion in terms of reducing cybersickness, we did find some evidence of the benefits of steering locomotion for presence.
C1 [Clifton, Jeremy; Palmisano, Stephen] Univ Wollongong, Sch Psychol, Wollongong, NSW 2522, Australia.
C3 University of Wollongong
RP Palmisano, S (corresponding author), Univ Wollongong, Sch Psychol, Wollongong, NSW 2522, Australia.
EM stephenp@uow.edu.au
RI ; Palmisano, Stephen/O-1553-2018
OI Clifton, Jeremy/0000-0002-9635-2566; Palmisano,
   Stephen/0000-0002-9140-5681
CR Al Zayer M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300584
   Allen B, 2016, ENTERTAIN COMPUT, V13, P1, DOI 10.1016/j.entcom.2016.01.001
   [Anonymous], 2018, 2018 10 INT C QUALIT, DOI DOI 10.1109/QOMEX.2018.8463433
   [Anonymous], 1975, Motion sickness
   Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Bangay S, 1998, STUD HLTH TECHNOL IN, DOI [10.1016/j.apergo.2016.05.003, DOI 10.1016/J.APERGO.2016.05.003]
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Bles W, 1998, BRAIN RES BULL, V47, P481, DOI 10.1016/S0361-9230(98)00115-4
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bonato F, 2005, AVIAT SPACE ENVIR MD, V76, P823
   Bonato F, 2004, AVIAT SPACE ENVIR MD, V75, P306
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bonnet CT, 2006, HUM MOVEMENT SCI, V25, P800, DOI 10.1016/j.humov.2006.03.001
   Bouchard S, 2004, 3RD IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2004, P59, DOI 10.1109/HAVE.2004.1391882
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Busscher B., 2011, Journal of CyberTherapy and Rehabilitation, V4, P15
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   Chang CH, 2013, EXP BRAIN RES, V229, P235, DOI 10.1007/s00221-013-3609-y
   Chang CH, 2012, EXP BRAIN RES, V217, P299, DOI 10.1007/s00221-011-2993-4
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Cook HE, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01901
   Cooper N, 2016, PERCEPTION, V45, P332
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   De Leo G, 2014, SIMUL HEALTHC, V9, P1, DOI 10.1097/SIH.0b013e3182a99dd9
   Diels C, 2007, AVIAT SPACE ENVIR MD, V78, P659
   Felnhofer A., 2012, P INT SOC PRESENCE R
   Felnhofer A, 2014, COMPUT HUM BEHAV, V31, P272, DOI 10.1016/j.chb.2013.10.045
   Flanagan MB, 2002, AVIAT SPACE ENVIR MD, V73, P1067
   Freitag S, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2014.6798852
   Frommel J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102082
   Gamito P., 2008, Annual Review of CyberTherapy and Telemedicine: Changing the Face of Healthcare, P83
   Garcia A., 2010, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V54, P1551, DOI [DOI 10.1177/154193121005401941, 10.1518/107118110X12829370088967, DOI 10.1518/107118110X12829370088967]
   Gavgani AM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182790
   Golding JF, 2012, AVIAT SPACE ENVIR MD, V83, P477, DOI 10.3357/ASEM.3095.2012
   Hill KJ, 2000, DISPLAYS, V21, P25, DOI 10.1016/S0141-9382(00)00029-9
   Huurnink A, 2013, J BIOMECH, V46, P1392, DOI 10.1016/j.jbiomech.2013.02.018
   Jacob Habgood M. P., 2018, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P371, DOI 10.1109/VR.2018.8446130
   Ji JTT, 2009, HUM FACTORS, V51, P739, DOI 10.1177/0018720809349708
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Keshavarz B, 2015, HUM FACTORS ERGON, P647
   Keshavarz B, 2017, J EXP PSYCHOL-APPL, V23, P85, DOI 10.1037/xap0000107
   Keshavarz B, 2014, EXP BRAIN RES, V232, P827, DOI 10.1007/s00221-013-3793-9
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim J, 2010, J VISION, V10, DOI 10.1167/10.12.7
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Knight Melinda M, 2006, P 3 S APPL PERC GRAP, P162, DOI DOI 10.1145/1140491.1140539
   Koslucher F, 2016, EXP BRAIN RES, V234, P313, DOI 10.1007/s00221-015-4462-y
   Koslucher F, 2015, AEROSP MED HUM PERF, V86, P787, DOI 10.3357/AMHP.4243.2015
   Lachlan K, 2011, COMMUN RES REP, V28, P27, DOI 10.1080/08824096.2010.518924
   Lackner JR, 2014, EXP BRAIN RES, V232, P2493, DOI 10.1007/s00221-014-4008-8
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Lawson B D, 2005, P 11 INT C HUM COMP, P1
   Lawson BD, 2015, HDB VIRTUAL ENV DESI, P532
   LAWTHER A, 1988, AVIAT SPACE ENVIR MD, V59, P399
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Ling Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096144
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Liu CL, 2011, LECT NOTES COMPUT SC, V6764, P490, DOI 10.1007/978-3-642-21619-0_61
   Llorach Gerard., 2014, P 20 ACM S VIRTUAL R, P137, DOI DOI 10.1145/2671015.2671120
   LORCH RF, 1990, J EXP PSYCHOL LEARN, V16, P149, DOI 10.1037/0278-7393.16.1.149
   Mania K, 2001, CYBERPSYCHOL BEHAV, V4, P247, DOI 10.1089/109493101300117938
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Milleville-Pennel I, 2015, ACCIDENT ANAL PREV, V74, P192, DOI 10.1016/j.aap.2014.10.021
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Mondellini M, 2018, LECT NOTES COMPUT SC, V10850, P3, DOI 10.1007/978-3-319-95270-3_1
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nguyen-Vo T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P415, DOI 10.1109/VR.2018.8446383
   Nichols S, 2000, INT J HUM-COMPUT ST, V52, P471, DOI 10.1006/ijhc.1999.0343
   Nooij SAE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175305
   Oman C M, 1982, Acta Otolaryngol Suppl, V392, P1
   Palmisano S, 2007, AVIAT SPACE ENVIR MD, V78, P951, DOI 10.3357/ASEM.2079.2007
   Palmisano S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195886
   Palmisano S, 2018, EXP BRAIN RES, V236, P315, DOI 10.1007/s00221-017-5130-1
   Palmisano S, 2017, DISPLAYS, V46, P1, DOI 10.1016/j.displa.2016.11.001
   Palmisano S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01205
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Palmisano S, 2012, J VISION, V12, DOI 10.1167/12.12.15
   Palmisano S, 2011, SEEING PERCEIVING, V24, P173, DOI 10.1163/187847511X570817
   Pedram, 2018, INT C APPL HUM FACTO, P404, DOI DOI 10.1007/978-3-319-94223-0_38
   Ragan Eric D., 2012, JOINT VIRTUAL REALIT, P1, DOI [10.2312/EGVE/JVRC12/081-084, DOI 10.2312/EGVE/JVRC12/081-084]
   Read JCA, 2014, ERGONOMICS, V57, P1140, DOI 10.1080/00140139.2014.914581
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI DOI 10.1145/1166087.1166091
   Riecke BE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00713
   Robillard G, 2003, CYBERPSYCHOL BEHAV, V6, P467, DOI 10.1089/109493103769710497
   Rothbaum BO, 2014, AM J PSYCHIAT, V171, P640, DOI 10.1176/appi.ajp.2014.13121625
   Ruddle RA, 2004, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2004.1310067
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Sargunam SP, 2017, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2017.7892227
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Seay A.F., 2002, CHI 02 EXTENDED ABST, P784, DOI DOI 10.1145/506443.506596
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smart LJ, 2014, ECOL PSYCHOL, V26, P301, DOI 10.1080/10407413.2014.958029
   Smart LJ, 2002, HUM FACTORS, V44, P451, DOI 10.1518/0018720024497745
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Steinicke F, 2013, Human walking in virtual environments
   Stoffregen TA, 2000, HUM FACTORS, V42, P458, DOI 10.1518/001872000779698097
   Stoffregen TA, 1998, BRAIN RES BULL, V47, P437, DOI 10.1016/S0361-9230(98)00102-6
   Stoffregen TA, 2008, HUM FACTORS, V50, P322, DOI 10.1518/001872008X250755
   Stoffregen TA, 2014, EXP BRAIN RES, V232, P1389, DOI 10.1007/s00221-014-3859-3
   Stoffregen TA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066949
   Stoffregen TA, 2010, ECOL PSYCHOL, V22, P169, DOI 10.1080/10407413.2010.496645
   Villard SJ, 2008, HUM FACTORS, V50, P332, DOI 10.1518/001872008X250728
   Webb NA, 2003, AVIAT SPACE ENVIR MD, V74, P622
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
   Wilson JR, 1997, ADV HUM FACT ERGON, V21, P889
   Witmer BG, 1996, INT J HUM-COMPUT ST, V45, P413, DOI 10.1006/ijhc.1996.0060
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xiang Liu, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P416, DOI 10.1007/978-3-319-39907-2_40
   Yokota Y, 2005, ACTA OTO-LARYNGOL, V125, P280, DOI 10.1080/00016480510003192
   ZACHARIAS GL, 1981, EXP BRAIN RES, V41, P159
NR 118
TC 69
Z9 75
U1 1
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2020
VL 24
IS 3
BP 453
EP 468
DI 10.1007/s10055-019-00407-8
EA NOV 2019
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA NI0EZ
UT WOS:000493691100001
DA 2024-07-18
ER

PT J
AU Alfalah, SFM
   Falah, JFM
   Alfalah, T
   Elfalah, M
   Muhaidat, N
   Falah, O
AF Alfalah, Salsabeel F. M.
   Falah, Jannat F. M.
   Alfalah, Tasneem
   Elfalah, Mutasem
   Muhaidat, Nadia
   Falah, Orwa
TI A comparative study between a virtual reality heart anatomy system and
   traditional medical teaching modalities
SO VIRTUAL REALITY
LA English
DT Article
DE Medical education; Virtual reality; Anatomy; Heart; Comparative study
AB The aim of using virtual reality (VR) as a medical training tool is to offer additional means to teach students and to improve the quality of medical skills. A novel system was developed to fulfil the requirements of modern medical education and overcome the challenges faced by both students and lecturers in the process of knowledge transfer. A heart three-dimensional model presented in a virtual reality (VR) environment has been implemented in order to facilitate a new educational modality. This paper reports the outcome of a comparative study between traditional medical teaching modalities and virtual reality technology. This study was conducted in the Faculty of Medicine in the University of Jordan. The participants were asked to perform system trials and experiment with the system by navigating through the system interfaces, as well as being exposed to the traditional physical model of the human heart that is currently used in the faculty during practical anatomy sessions. Afterwards, they were asked to provide feedback via a comparative questionnaire. The participants' replies to the questions regarding the Physical Heart Model and VR heart anatomy system were assessed for reliability using Cronbach's alpha. The first group's (Physical Heart Model questions) alpha value was 0.689. The second group's (VR heart anatomy system questions) alpha value was 0.791. Comparing students' experience results between the traditional method (Physical Heart Model) and the VR heart anatomy system, the mean scores showed a distinct increase in the values. This indicates that the developed system enhanced their experience in anatomy learning and the provided tools improved their understanding of heart anatomy. Results demonstrated the usefulness of the system by showing a higher satisfaction rate for the provided tools regarding structure and visualisation.
C1 [Alfalah, Salsabeel F. M.] Univ Jordan, Dept Comp Informat Syst, Amman, Jordan.
   [Falah, Jannat F. M.] Al Balqa Appl Univ, Dept Comp Sci, Amman, Jordan.
   [Alfalah, Tasneem] Appl Sci Univ, Dept Business Adm, Amman, Jordan.
   [Elfalah, Mutasem] Univ Jordan, Fac Med, Dept Ophthalmol, Amman, Jordan.
   [Muhaidat, Nadia] Univ Jordan, Fac Med, Dept Obstet & Gynaecol, Amman, Jordan.
   [Falah, Orwa] Univ Edinburgh, Dept Vasc Surg, Edinburgh, Midlothian, Scotland.
C3 University of Jordan; Al-Balqa Applied University; Applied Science
   University - Jordan; University of Jordan; University of Jordan;
   University of Edinburgh
RP Alfalah, SFM (corresponding author), Univ Jordan, Dept Comp Informat Syst, Amman, Jordan.
EM Salsabeel.alfalah@gmail.com; Janatalrabie@hotmail.com;
   Tasneem_alabady@hotmail.com; Mutasemrabie@hotmail.com;
   Nadiadat@hotmail.com; orwafalah@hotmail.com
RI Muhaidat, Nadia/ACN-6230-2022; muhaidat, nadia/AAP-8860-2021
OI Muhaidat, Nadia/0000-0002-3495-799X; Elfalah,
   Mutasem/0000-0002-9677-6203
CR Alfalah Salsabeel F. M., 2013, Virtual, Augmented and Mixed Reality. Systems and Applications. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings, Part II: LNCS 8022, P3, DOI 10.1007/978-3-642-39420-1_1
   AlFalah SFM, 2013, J ENTERP INF MANAG, V26, P183, DOI 10.1108/17410391311289622
   Charissis V, 2010, COGN TECHNOL WORK, V12, P41, DOI 10.1007/s10111-008-0117-0
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   CRONBACH LJ, 1970, PSYCHOL BULL, V74, P68, DOI 10.1037/h0029382
   Engum SA, 2003, AM J SURG, V186, P67, DOI 10.1016/S0002-9610(03)00109-0
   Falah Jannat, 2013, Virtual, Augmented and Mixed Reality. Systems and Applications. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings, Part II: LNCS 8022, P122, DOI 10.1007/978-3-642-39420-1_14
   Falah J., 2014, INTELLIGENT SYSTEMS, V591, P369, DOI [10.1007/978-3-319-14654-6_23, DOI 10.1007/978-3-319-14654-6_23]
   Falah J., 2012, INT C MAN RES ICMR, V2, P360
   Falah J, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P752, DOI 10.1109/SAI.2014.6918271
   Gallo L, 2010, COMPUT BIOL MED, V40, P350, DOI 10.1016/j.compbiomed.2010.01.006
   Onyesolu M, 2009, P WORLD C ENG COMP S
   Peterson D, 2013, INTED PROC, P3285
   Sakellariou Sophia, 2011, Virtual and Mixed Reality - Systems and Applications. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P54, DOI 10.1007/978-3-642-22024-1_7
   Sakellariou S, 2009, LECT NOTES COMPUT SC, V5622, P605, DOI 10.1007/978-3-642-02771-0_67
   Saunders M, 2012, RES METHODS BUSINESS, P430
   Vozenilek J, 2004, ACAD EMERG MED, V11, P1149, DOI 10.1197/j.aem.2004.08.003
NR 17
TC 65
Z9 67
U1 2
U2 52
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2019
VL 23
IS 3
SI SI
BP 229
EP 234
DI 10.1007/s10055-018-0359-y
PG 6
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA IR5QR
UT WOS:000481490500003
DA 2024-07-18
ER

PT B
AU Greengard, S
AF Greengard, Samuel
BA Greengard, S
BF Greengard, S
TI THE TECHNOLOGY BEHIND THE REALITY
SO VIRTUAL REALITY
SE MIT Press Essential Knowledge Series
LA English
DT Article; Book Chapter
CR [Anonymous], 2014, ENGADGET        0520
   [Anonymous], 2013, DIFFRACTIVE HOLOGRAP
   [Anonymous], 2016, WALL STREET J   0518
   [Anonymous], 2016, REAL DEAL VIRTUAL AU
   [Anonymous], 2018, TOUCHING VIRTUAL MIC
   [Anonymous], 2018, TIMEOUT         0817
   [Anonymous], 2017, AUGMENTED REALITY BE
   Bigler CM, 2018, APPL OPTICS, V57, P2007, DOI 10.1364/AO.57.002007
   Friedman D, 2007, PRESENCE-TELEOP VIRT, V16, P100, DOI 10.1162/pres.16.1.100
   Metz Rachel, 2017, MIT TECHNOLOGY  0322
   Milgram P., 1994, IEICE T INFORM SYSTE, VE77-D
   Paney Anjul, 2016, P SIGGRAPH 2016 EM T
   Razzaque Sharif, 2002, EVGE P WORKSH VIRT E
NR 13
TC 0
Z9 0
U1 0
U2 0
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142 USA
BN 978-0-262-53752-0
J9 MIT PRESS ESSENT
PY 2019
BP 65
EP +
PG 31
WC History & Philosophy Of Science; Social Sciences, Interdisciplinary
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH)
SC History & Philosophy of Science; Social Sciences - Other Topics
GA BO0CD
UT WOS:000490259200005
DA 2024-07-18
ER

PT J
AU Lepouras, G
AF Lepouras, Georgios
TI Comparing methods for numerical input in immersive virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Numerical input; Immersive virtual environments
ID TEXT ENTRY; GESTURES; DESIGN; GLOVE
AB Numeric input is a sub-case of alphanumeric input where a user wishes to communicate a numerical value to the computer. While this is a straightforward task for windows-based environments, this is not the case for immersive virtual environments. In this paper we design, implement, and evaluate different methods based on gestures or hand-held devices such as wireless numeric keyboards and gamepads. The assessment showed that hand-held devices can be easier to use and faster for data input. A numeric keyboard can offer fast input for positive, small numbers, while the gamepad-based method can offer uniform performance. Although the gesture-based method did not perform as well, there is still scope for its use when a designer needs a method that leaves both user's hands free during interaction.
C1 [Lepouras, Georgios] Univ Peloponnese, Dept Informat & Telecommun, Tripolis, Arcadia, Greece.
C3 University of Peloponnese
RP Lepouras, G (corresponding author), Univ Peloponnese, Dept Informat & Telecommun, Tripolis, Arcadia, Greece.
EM G.Lepouras@uop.gr
RI Lepouras, Georgios/AAM-3058-2021
OI Lepouras, Georgios/0000-0001-6094-3308
CR Ardito C, 2009, C HUM SYST INTERACT, P289
   Bailly G, 2012, INT J HUM-COMPUT ST, V70, P673, DOI 10.1016/j.ijhcs.2012.05.006
   Baldauf M, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808202
   Bowman D. A., 2002, Virtual Reality, V6, P122, DOI 10.1007/s100550200013
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2154
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Braffort A., 1996, ASSETS '96. The Second Annual ACM Conference on Assistive Technologies, P102, DOI 10.1145/228347.228364
   Brown M, 2015, HUM-COMPUT INT-SPRIN, P263, DOI 10.1007/978-3-319-15985-0_12
   CARD SK, 1980, COMMUN ACM, V23, P396, DOI 10.1145/358886.358895
   Cardoso A, 2013, P IEEE VIRT REAL ANN, P165, DOI 10.1109/VR.2013.6549414
   Clarkson E., 2005, CHI 05 EXTENDED ABST, P1288, DOI DOI 10.1145/1056808.1056898
   Demirdjian David., 2005, VIRTUAL REAL-LONDON, V8, P222
   Fels SS, 1998, IEEE T NEURAL NETWOR, V9, P205, DOI 10.1109/72.655042
   Foong OM, 2008, P WORLD ACAD SCI ENG, P44
   Go K., 2008, P CHI 08 HUM FACT CO, P3141, DOI [10.1145/1358628.1358821, DOI 10.1145/1358628.1358821]
   González G, 2009, NEW TRENDS ON HUMAN-COMPUTER INTERACTION: RESEARCH, DEVELOPMENT, NEW TOOLS AND METHODS, P109, DOI 10.1007/978-1-84882-352-5_11
   Hesselmann T., 2011, P ACM INT C INTERACT, P256, DOI DOI 10.1145/2076354.2076403
   Hoste L, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P156, DOI 10.1145/2254556.2254585
   Isokoski P., 2004, P 3 NORDIC C HUMAN C, P105
   Kim S., 2004, P 2004 ACM SIGGRAPH, P336
   Koltringer Thomas, 2007, Proceedings Graphics Interface 2007, P103, DOI 10.1145/1268517.1268536
   Latoschik M. E., 2001, Proceedings AFRIGRAPH 2001. 1st International Conference on Computer Graphics, Virtual Reality and Visualisation, P95, DOI 10.1145/513867.513888
   LaViola J., 1999, INT C COMPUTER GRAPH, P221
   Laviola J. J.  Jr., 2000, Proceedings of the IASTED International Conference. Computer Graphics and Imaging, P1
   Lee Seongil., 2003, Proceedings of the 2003 Conference on Universal Usability, CUU '03, P142
   Lepouras G, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P240, DOI 10.1109/VECIMS.2009.5068901
   MacKenzie IS, 2002, HUM-COMPUT INTERACT, V17, P147, DOI 10.1207/S15327051HCI172&3_2
   MULLER J, 1998, ACOUST SPEECH SIG PR, P3757
   Natapov D., 2009, Proceedings of Graphics Interface 2009, P223
   Ni T, 2011, INT J HUM-COMPUT ST, V69, P551, DOI 10.1016/j.ijhcs.2011.05.001
   Norman DA, 2013, Basic Books
   Oshita M., 2012, P WASA 2012 WORKSH S, V1, P27, DOI [10.1145/2425296.2425301, DOI 10.1145/2425296.2425301]
   Poupyrev I, 1998, P IEEE VIRT REAL ANN, P126, DOI 10.1109/VRAIS.1998.658467
   Rosenberg R, 1999, IEEE T SYST MAN CY C, V29, P186, DOI 10.1109/5326.760563
   Sandnes FE, 2007, INTERACT COMPUT, V19, P140, DOI 10.1016/j.intcom.2006.08.003
   Skripcak T, 2011, INT J SOFT COMPUT EN, V1, P57
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   Terajima K., 2009, P CHI HUM FACT COMP, P3739, DOI [10.1145/1520340.1520564, DOI 10.1145/1520340.1520564]
   WILLIAMS EJ, 1949, AUST J SCI RES SER A, V2, P149, DOI 10.1071/CH9490149
   Wilson AD., 2006, Proceedings of the SIGCHI conference on Human Factors in computing systems, P475, DOI [10.1145/1124772.1124844, DOI 10.1145/1124772.1124844]
NR 40
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2018
VL 22
IS 1
BP 63
EP 77
DI 10.1007/s10055-017-0312-5
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA FX0UJ
UT WOS:000425762200006
DA 2024-07-18
ER

PT J
AU Seibert, J
   Shafer, DM
AF Seibert, Jonmichael
   Shafer, Daniel M.
TI Control mapping in virtual reality: effects on spatial presence and
   controller naturalness
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Spatial presence; Video games; Controller naturalness;
   Natural mapping
ID SCREEN SIZE; VIDEO; MOTION; ENVIRONMENTS; IMMERSION; ENJOYMENT; IMPACT;
   IMAGE; SENSE
AB This study explores how a video game player's sense of being in a game world (i.e., spatial presence) is impacted by the use of a virtual reality head-mounted display (VR HMD). Research focused on VR (as realized with the use of HMDs) has fallen by the wayside since the early 1990s due to the limitations in the technology. With modern reimagining of VR HMDs, there is now an opportunity to reexamine the impact it has on gaming experience. This article explores the results of an experiment in which university students played video games using either a VR HMD or a standard monitor while playing a first-person shooter video game. Control interface was also manipulated between incomplete tangible mapped devices (Razer Hydra) and directionally mapped devices (mouse and keyboard). Results indicated that VR HMDs have a positive impact on a players' level of spatial presence and feelings of controller naturalness. Controller naturalness also impacted spatial presence regardless of display condition.
C1 [Seibert, Jonmichael] Florida State Univ, Coll Commun & Informat, 4100 Univ Ctr,Bldg C, Tallahassee, FL 32306 USA.
   [Shafer, Daniel M.] Baylor Univ, Dept Film & Digital Media, One Bear Pl 97321, Waco, TX 76798 USA.
C3 State University System of Florida; Florida State University; Baylor
   University
RP Seibert, J (corresponding author), Florida State Univ, Coll Commun & Informat, 4100 Univ Ctr,Bldg C, Tallahassee, FL 32306 USA.
EM jcs16b@my.fsu.edu
RI Shafer, Daniel Mark/HGD-5911-2022; Shafer, Daniel/GMX-1167-2022
OI Shafer, Daniel Mark/0000-0002-4960-2761; Shafer,
   Daniel/0000-0002-4960-2761
CR Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Bracken C.C., 2010, Immersed in Media: Telepresence in Everyday Life
   Burdea G. C., 2003, Virtual reality technology
   Juan MC, 2009, PRESENCE-VIRTUAL AUG, V18, P232, DOI 10.1162/pres.18.3.232
   Garreffa A, 2014, OCULUS RIFT RAZER HY
   Hou JH, 2012, COMPUT HUM BEHAV, V28, P617, DOI 10.1016/j.chb.2011.11.007
   Ijsselsteijn W, 2001, PRESENCE-TELEOP VIRT, V10, P298, DOI 10.1162/105474601300343621
   International Society for Presence Research, 2000, CONC PRES EXPL STAT
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kim KJ, 2013, CYBERPSYCH BEH SOC N, V16, P329, DOI 10.1089/cyber.2012.0500
   Klimmt C, 2007, CYBERPSYCHOL BEHAV, V10, P845, DOI 10.1089/cpb.2007.9942
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lang B, 2016, HANDS ON OCULUS TOUC
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Limperos AM, 2011, CYBERPSYCH BEH SOC N, V14, P345, DOI 10.1089/cyber.2010.0146
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Nabioyuni M, 2015, INT C ART REAL TEL E
   Norman D., 1988, PSYCHOL EVERYDAY THI
   Norman D. A., 1986, Cognitive Engineering, P31, DOI [10.1201/b15703-3, DOI 10.1201/B15703]
   Robertson A, 2015, VALVES VIRTUAL REALI
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Shafer DM, 2014, PRESENCE-TELEOP VIRT, V23, P267, DOI 10.1162/PRES_a_00193
   Shafer DM, 2011, PRESENCE-TELEOP VIRT, V20, P591, DOI 10.1162/PRES_a_00084
   Shafer DM, 2015, 2015 SMPTE TECHN C S
   Shoemaker N, 2011, RAZER HYDRA
   Skalski P, 2010, PSYCHNOLOGY J, V8, P67
   Skalski P, 2011, NEW MEDIA SOC, V13, P224, DOI 10.1177/1461444810370949
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P447, DOI 10.1162/105474698565848
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Tamborini R., 2010, Immersed in media: Telepresence in everyday life, P5
   Tamborini R, 2004, J BROADCAST ELECTRON, V48, P335
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vinson NG, 2012, P 2012 GRAPH INT C, P1
   Vorderer P, 2004, COMMUN THEOR, V14, P388, DOI 10.1093/ct/14.4.388
   Vorderer P, 2000, LEA COMMUN SER, P21
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
NR 38
TC 63
Z9 76
U1 2
U2 43
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2018
VL 22
IS 1
BP 79
EP 88
DI 10.1007/s10055-017-0316-1
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA FX0UJ
UT WOS:000425762200007
DA 2024-07-18
ER

PT J
AU Ravyse, WS
   Blignaut, AS
   Leendertz, V
   Woolner, A
AF Ravyse, Werner Siegfried
   Blignaut, A. Seugnet
   Leendertz, Verona
   Woolner, Alex
TI Success factors for serious games to enhance learning: a systematic
   review
SO VIRTUAL REALITY
LA English
DT Review
DE Artificial intelligence (AI); Feedback; Interaction; Narrative; Realism;
   Serious games
ID VIDEO GAME; EDUCATIONAL GAMES; VIRTUAL-REALITY; PHYSICAL-EDUCATION;
   SCHOOL-CHILDREN; COMPUTER GAME; DESIGN; PERFORMANCE; SIMULATION;
   ENGAGEMENT
AB There is no doubt that an abundance of factors exists that makes learning with serious games successful. Research articles reporting on these factors, however, tend to focus on select serious game elements and do not combine all salient factors for successful learning with serious games. Addressing this gap is a necessity for the success of serious games and may even alleviate long-standing debates about pedagogy over enjoyment, how much realism is enough or whether artificial intelligence is worth the cost. This article examines existing academic literature from 2000 to 2015, extracting shared serious game success factors that have had an encouraging impact on gameful learning experiences. As such, we subsequently aim to withdraw the field from a perpetual spiral of does-my-game-work research toward more worthwhile why-does-my-game-not-work research. Qualitative content analysis through the constant comparison method (CCM) analyzed a total of 63 articles from a variety of recognized electronic libraries and databases. Through this analysis, we reveal five central serious game themes: backstory and production; realism; artificial intelligence and adaptivity; interaction; and feedback and debriefing, all of which require deliberate intertwining with pedagogical content to ensure successful learning. This review unravels each of the five themes into their constituent factors and consequently presents the factors as practical guidelines that serious games producers should strive to include in their game productions. Applying these recommendations whenever serious games are considered will provide a foundation for effective gameful learning experiences.
C1 [Ravyse, Werner Siegfried; Blignaut, A. Seugnet; Leendertz, Verona] North West Univ, Fac Econ Sci & IT, TELIT SA, Vaal Triangle Campus,Hendrik van Eck Blvd, ZA-1911 Vanderbijlpark, South Africa.
   [Woolner, Alex] Coventry Univ, Serious Games Inst, Priory St, Coventry CV1 5FB, W Midlands, England.
C3 North West University - South Africa; Vaal University of Technology
   (VUT); Coventry University
RP Ravyse, WS (corresponding author), North West Univ, Fac Econ Sci & IT, TELIT SA, Vaal Triangle Campus,Hendrik van Eck Blvd, ZA-1911 Vanderbijlpark, South Africa.
EM werner.ravyse@gmail.com
FU National Research Foundation of South Africa
FX This work is based on research support, in part, by the National
   Research Foundation of South Africa. Any opinion, findings and
   conclusions or recommendations expressed in this material are those of
   the authors, and therefore, the NRF does accept any liability in regard
   thereto. We also wish to acknowledge the effort of the librarians of the
   North-West University.
CR Abt ClarkC., 1970, SERIOUS GAMES
   Admiraal W, 2014, INT J INCLUSIVE EDUC, V18, P1208, DOI 10.1080/13603116.2014.885592
   Akl EA, 2008, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006411.pub2
   Alamri A, 2014, COMPUT HUM BEHAV, V30, P468, DOI 10.1016/j.chb.2013.06.021
   Annetta L, 2014, INFORM SCIENCES, V264, P61, DOI 10.1016/j.ins.2013.10.028
   Annetta L, 2009, INT J SCI EDUC, V31, P1091, DOI 10.1080/09500690801968656
   Annetta LA, 2009, COMPUT EDUC, V53, P74, DOI 10.1016/j.compedu.2008.12.020
   [Anonymous], 2008, NEW
   [Anonymous], 2010, J COMPUTER GAME CULT
   [Anonymous], 2007, Journal of Applied Educational Technology
   [Anonymous], COMPUTERS ED
   Arnab S, 2013, COMPUT EDUC, V69, P15, DOI 10.1016/j.compedu.2013.06.013
   Barab S, 2012, COMPUT EDUC, V58, P518, DOI 10.1016/j.compedu.2011.08.001
   Baranowski T, 2011, AM J PREV MED, V40, P33, DOI 10.1016/j.amepre.2010.09.029
   Bedwell WL, 2012, SIMULAT GAMING, V43, P729, DOI 10.1177/1046878112439444
   Bellotti F., 2009, ACM COMPUTERS ENTERT, V7, P23, DOI DOI 10.1145/1541895.1541903
   Bellotti F., 2012, J. Comput. Cult. Herit., V5, P4, DOI [DOI 10.1145/2399180.2399185, https://doi.org/10.1145/2399180.2399185]
   Bhoopathi P S, 2007, Int J Psychiatr Nurs Res, V12, P1497
   Blakely G, 2009, J ADV NURS, V65, P259, DOI 10.1111/j.1365-2648.2008.04843.x
   Boeije H, 2002, QUAL QUANT, V36, P391, DOI 10.1023/A:1020909529486
   Boyle E, 2011, ENTERTAIN COMPUT, V2, P69, DOI 10.1016/j.entcom.2010.12.002
   Brom C, 2011, COMPUT EDUC, V57, P1971, DOI 10.1016/j.compedu.2011.04.007
   Brom C, 2010, MULTIMEDIA SYST, V16, P23, DOI 10.1007/s00530-009-0174-0
   Buttussi F, 2013, INT J MED INFORM, V82, P798, DOI 10.1016/j.ijmedinf.2013.05.007
   Byun J, 2015, COMPUT HUM BEHAV, V46, P129, DOI 10.1016/j.chb.2014.12.052
   Cheng MT, 2015, COMPUT EDUC, V86, P18, DOI 10.1016/j.compedu.2015.03.007
   Cheng MT, 2014, BRIT J EDUC TECHNOL, V45, P820, DOI 10.1111/bjet.12098
   Cheng MT, 2012, J BIOL EDUC, V46, P203, DOI 10.1080/00219266.2012.688848
   Chittaro L, 2015, COMPUT HUM BEHAV, V50, P508, DOI 10.1016/j.chb.2015.03.074
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Connolly TM, 2011, COMPUT EDUC, V57, P1389, DOI 10.1016/j.compedu.2011.01.009
   Cook DA, 2013, MED TEACH, V35, pE844, DOI 10.3109/0142159X.2012.714886
   Couceiro RM, 2013, EDUC INF TECHNOL, V18, P531, DOI 10.1007/s10639-011-9179-3
   Crookall D, 2014, ENGAGING GAMEPLAY DE
   de Freitas S, 2014, INFORM SCIENCES, V264, P1, DOI 10.1016/j.ins.2014.01.036
   DeSmet A, 2014, PREV MED, V69, P95, DOI 10.1016/j.ypmed.2014.08.026
   Dickey MD, 2011, BRIT J EDUC TECHNOL, V42, P456, DOI 10.1111/j.1467-8535.2009.01032.x
   DONNELLY CM, 1993, J EXP PSYCHOL LEARN, V19, P975, DOI 10.1037/0278-7393.19.4.975
   Echeverría A, 2011, COMPUT EDUC, V57, P1127, DOI 10.1016/j.compedu.2010.12.010
   Feinstein A. H., 2002, Simulation & Gaming, V33, P425, DOI 10.1177/1046878102238606
   Garris R., 2002, Simulation & Gaming, V33, P441, DOI 10.1177/1046878102238607
   Gee JP, 2005, PHI KAPPA PHI FORUM, P33
   Gentner D, 1997, AM PSYCHOL, V52, P32, DOI 10.1037/0003-066X.52.1.32
   Giessen HW, 2015, PROCD SOC BEHV, V174, P2240, DOI 10.1016/j.sbspro.2015.01.881
   González-González C, 2014, COMPUT HUM BEHAV, V31, P602, DOI 10.1016/j.chb.2013.06.039
   González-González C, 2012, COMPUT EDUC, V58, P250, DOI 10.1016/j.compedu.2011.08.014
   Hainey T, 2007, INT J INFORM MANAGE, V27, P438, DOI 10.1016/j.ijinfomgt.2007.08.008
   Hamalainen R, 2008, COMPUT EDUC, V50, P98, DOI 10.1016/j.compedu.2006.04.001
   Hämäläinen R, 2011, TECHNOL PEDAGOG EDUC, V20, P61, DOI 10.1080/1475939X.2011.554010
   Harriketamo, 2010, Journal of Educational Multimedia and Hypermedia, V19, P399
   Hong JC, 2015, COMPUT EDUC, V88, P109, DOI 10.1016/j.compedu.2015.04.018
   Hong JC, 2013, COMPUT EDUC, V66, P74, DOI 10.1016/j.compedu.2013.02.007
   Hong JC, 2013, INTERACT LEARN ENVIR, V21, P39, DOI 10.1080/10494820.2010.542760
   Huizenga J, 2009, J COMPUT ASSIST LEAR, V25, P332, DOI [10.1111/J.1365-2729.2009.00316.x, 10.1111/j.1365-2729.2009.00316.x]
   Hunicke R., 2004, Proc. AAAI Wksp. Challenges in Game AI, V4, P1722
   Hwang GJ, 2015, COMPUT EDUC, V81, P13, DOI 10.1016/j.compedu.2014.09.006
   Hwang GJ, 2013, COMPUT EDUC, V69, P121, DOI 10.1016/j.compedu.2013.07.008
   Hwang GJ, 2012, COMPUT EDUC, V59, P1246, DOI 10.1016/j.compedu.2012.05.009
   Hwang GJ, 2013, BRIT J EDUC TECHNOL, V44, P183, DOI 10.1111/j.1467-8535.2012.01285.x
   Hwang GJ, 2012, ETR&D-EDUC TECH RES, V60, P623, DOI 10.1007/s11423-012-9241-x
   Johnson CI, 2010, COMPUT HUM BEHAV, V26, P1246, DOI 10.1016/j.chb.2010.03.025
   Jonassen DH, 1994, Educ Technol, V34, P34
   Ke FF, 2008, COMPUT EDUC, V51, P1609, DOI 10.1016/j.compedu.2008.03.003
   Ke FF, 2007, BRIT J EDUC TECHNOL, V38, P249, DOI 10.1111/j.1467-8535.2006.00593.x
   Ke FF, 2013, BRIT J EDUC TECHNOL, V44, P225, DOI 10.1111/j.1467-8535.2012.01326.x
   Kickmeier-Rust MD, 2010, J COMPUT ASSIST LEAR, V26, P95, DOI 10.1111/j.1365-2729.2009.00332.x
   Kiili K., 2005, Internet and Higher Education, V8, P183, DOI 10.1016/j.iheduc.2005.06.001
   Kitchenham B., 2007, 2007001 EBSE
   Knight JF, 2010, RESUSCITATION, V81, P1175, DOI 10.1016/j.resuscitation.2010.03.042
   Kriz WC, 2006, SIMULAT GAMING, V37, P268, DOI 10.1177/1046878106287950
   Kuk K, 2012, EXPERT SYST APPL, V39, P8051, DOI 10.1016/j.eswa.2012.01.138
   Mayo JA, 2001, J CONSTR PSYCHOL, V14, P187, DOI 10.1080/10720530126292
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Mcmahon M, 2011, AACE EDM C 2011
   Michael D., 2006, SERIOUS GAMES GAMES
   Minovic M, 2011, J UNIVERS COMPUT SCI, V17, P1241
   Mortara M, 2014, J CULT HERIT, V15, P318, DOI 10.1016/j.culher.2013.04.004
   Moseley A, 2014, SIMULATION GAMING, V45, P611
   Niedenthal S, 2009, WHAT WE TALK WE TALK
   Nor Azan Mat Zin, 2013, Journal of Next Generation Information Technology, V4, P9, DOI 10.4156/jnit.vol4.issue4.2
   Norman G, 2012, MED EDUC, V46, P636, DOI 10.1111/j.1365-2923.2012.04243.x
   Osterman K., 1998, USING CONSTRUCTIVISM
   Papastergiou M, 2009, COMPUT EDUC, V53, P603, DOI 10.1016/j.compedu.2009.04.001
   Peters V. A. M., 2004, Simulation & Gaming, V35, P70, DOI 10.1177/1046878103253719
   Petridis P., 2010, An Engine Selection Methodology for High Fidelity Serious Games. s.l, P27, DOI [10.1109/VS-GAMES.2010.26, DOI 10.1109/VS-GAMES.2010.26]
   Prensky Marc, 2001, Digital Game-Based Learning
   Riffe D, 1998, LEAS COMMUNICATIONS
   Rodriguez DM, 2014, DRUG ALCOHOL REV, V33, P129, DOI 10.1111/dar.12102
   Russell S., 2014, ARTIF INTELL
   Sacfung Akekachai, 2014, Advanced Materials Research, V931-932, P583, DOI 10.4028/www.scientific.net/AMR.931-932.583
   Sadler TD, 2015, SCI EDUC, V99, P696, DOI 10.1002/sce.21171
   Schmitz B, 2015, COMPUT EDUC, V85, P160, DOI 10.1016/j.compedu.2015.02.012
   Schmitz B, 2015, COMPUT EDUC, V81, P35, DOI 10.1016/j.compedu.2014.09.001
   Schmitz B, 2014, PERVASIVE MOB COMPUT, V14, P57, DOI 10.1016/j.pmcj.2013.09.002
   Serrano-Laguna A, 2014, ENTERTAIN COMPUT, V5, P313, DOI 10.1016/j.entcom.2014.02.003
   Sherry JL, 2013, CHALLENGE AUDIENCE R, V139, P11, DOI [10.1002/cad.20027, DOI 10.1002/CAD.20027]
   Sitzmann T, 2011, PERS PSYCHOL, V64, P489, DOI 10.1111/j.1744-6570.2011.01190.x
   Soflano M, 2015, COMPUT EDUC, V86, P105, DOI 10.1016/j.compedu.2015.02.009
   Soflano M, 2015, COMPUT EDUC, V86, P192, DOI 10.1016/j.compedu.2015.03.015
   Squire KD, 2013, PERFORM IMPROV Q, V26, P101, DOI 10.1002/piq.21139
   Susi T., 2007, Serious Games: An Overview
   Thompson D, 2010, SIMULAT GAMING, V41, P587, DOI 10.1177/1046878108328087
   Torrente J, 2014, COMPUT SCI INF SYST, V11, P369, DOI 10.2298/CSIS121209013T
   Torrente J, 2009, EDUC TECHNOL SOC, V12, P359
   Van der Hulst AH, 2012, HOMOLUDENS MAGAZINE, P96
   van der Spek ED, 2013, BRIT J EDUC TECHNOL, V44, P156, DOI 10.1111/j.1467-8535.2011.01282.x
   Van Eck R., 2006, J COMPUTERS MATH SCI, V25, P165
   Van Eck R., 2006, EDUCAUSE REV, V41, P16, DOI DOI 10.1145/950566.950596
   Vandercruysse S., 2012, HDB RES SERIOUS GAME, P628
   Verpoorten D, 2014, EDUC INF TECHNOL, V19, P361, DOI 10.1007/s10639-012-9219-7
   Virvou M, 2005, EDUC TECHNOL SOC, V8, P54
   Virvou M, 2008, COMPUT EDUC, V50, P154, DOI 10.1016/j.compedu.2006.04.004
   Vygotsky L. S., 1978, Mind in Society: The Development of Higher Psychological Processes, DOI 10.2307/j.ctvjf9vz4
   Webster D, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-108
   Westera W, 2008, J COMPUT ASSIST LEAR, V24, P420, DOI 10.1111/j.1365-2729.2008.00279.x
   Whitton N, 2011, INT J GAME-BASED LEA, V1, P75, DOI 10.4018/ijgbl.2011010106
   Whitton Nicola., 2013, International Review of Qualitative Research, V6, P424, DOI DOI 10.1525/IRQR.2013.6.3.424
   Wiemeyer J., 2010, INT J COMPUTER SCI S, V9, P65
   Wouters P, 2013, J EDUC PSYCHOL, V105, P249, DOI 10.1037/a0031311
   Yoon H, 2014, INT J MULTIMEDIA UBI, V9, P205, DOI [10.14257/ijmue.2014.9.7.17, DOI 10.14257/IJMUE.2014.9.7.17]
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 122
TC 92
Z9 106
U1 8
U2 161
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2017
VL 21
IS 1
BP 31
EP 58
DI 10.1007/s10055-016-0298-4
PG 28
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA EN6MV
UT WOS:000396119000003
DA 2024-07-18
ER

PT J
AU Iwai, D
   Nagase, M
   Sato, K
AF Iwai, Daisuke
   Nagase, Momoyo
   Sato, Kosuke
TI Shadow removal of projected imagery by occluder shape measurement in a
   multiple overlapping projection system
SO VIRTUAL REALITY
LA English
DT Article
DE Shadow removal; Multiple overlapping projection; Synthetic aperture
   capturing; Visual hull
ID LIGHT SUPPRESSION; ELIMINATION
AB This paper presents a shadow removal technique for a multiple overlapping projection system. In particular, this paper deals with situations where cameras cannot be placed between the occluder and projection surface. We apply a synthetic aperture capturing technique to estimate the appearance of the projection surface, and a visual hull reconstruction technique to measure the shape of the occluder. Once the shape is acquired, shadow regions on the surface can be estimated. The proposed shadow removal technique allows users to balance between the following two criteria: the likelihood of new shadow emergence and the spatial resolution of the projected results. Through a real projection experiment, we evaluate the proposed shadow removal technique.
C1 [Iwai, Daisuke; Nagase, Momoyo; Sato, Kosuke] Osaka Univ, Grad Sch Engn Sci, Toyonaka, Osaka 5608531, Japan.
C3 Osaka University
RP Iwai, D (corresponding author), Osaka Univ, Grad Sch Engn Sci, 1-3 Machikaneyama, Toyonaka, Osaka 5608531, Japan.
EM daisuke.iwai@sys.es.osaka-u.ac.jp
RI Iwai, Daisuke/R-8174-2019
OI Iwai, Daisuke/0000-0002-3493-5635
FU Grants-in-Aid for Scientific Research [22135003] Funding Source: KAKEN
CR [Anonymous], 2015, Photogrammetric Engineering Remote Sensing, DOI [DOI 10.1080/10671188.1967.10616517, 10.14358/PERS.81.2.103, DOI 10.14358/PERS.81.2.103]
   Audet S., 2007, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2007.383470
   Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Bimber O, 2006, IEEE T VIS COMPUT GR, V12, P658, DOI 10.1109/TVCG.2006.75
   Bimber O, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P14
   Bimber O, 2008, COMPUT GRAPH FORUM, V27, P2219, DOI 10.1111/j.1467-8659.2008.01175.x
   Cham TJ, 2003, PROC CVPR IEEE, P513
   Jaynes C, 2004, IEEE T VIS COMPUT GR, V10, P290, DOI 10.1109/TVCG.2004.1272728
   Jaynes C, 2001, IEEE VISUAL, P175, DOI 10.1109/VISUAL.2001.964509
   Jones B. R., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P165, DOI 10.1109/ISMAR.2010.5643566
   Ladikos A, 2008, P IEEE WORKSH VIS CO
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Low Kok-Lim., 2001, VRST 01, P93, DOI DOI 10.1145/505008.505026
   Nagase M, 2011, VIRTUAL REAL-LONDON, V15, P119, DOI 10.1007/s10055-010-0168-4
   Raskar R, 2001, SPRING EUROGRAP, P89
   Sato K., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P657
   Sugaya Y., 2010, P INT WORKSH PROJ CA, P13
   Sukthankar R, 2001, PROC CVPR IEEE, P151
   Summet J, 2007, IEEE T VIS COMPUT GR, V13, P508, DOI 10.1109/TVCG.2007.1007
   Vaish V., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.244
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yoshida T., 2003, P INT C VIRT SYST MU, P161
NR 22
TC 7
Z9 7
U1 1
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2014
VL 18
IS 4
BP 245
EP 254
DI 10.1007/s10055-014-0250-4
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AT0AZ
UT WOS:000344600500002
DA 2024-07-18
ER

PT J
AU Kahn, S
AF Kahn, Svenja
TI Reducing the gap between Augmented Reality and 3D modeling with
   real-time depth imaging
SO VIRTUAL REALITY
LA English
DT Article
DE 3D modeling; Augmented Reality; Computer vision; Tracking; Depth
   imaging; Analysis-by-synthesis
ID TRACKING; REGISTRATION; CAMERA
AB Whereas 3D surface models are often used for augmented reality (e.g., for occlusion handling or model-based camera tracking), the creation and the use of such dense 3D models in augmented reality applications usually are two separated processes. The 3D surface models are often created in offline preparation steps, which makes it difficult to detect changes and to adapt the 3D model to these changes. This work presents a 3D change detection and model adjustment framework that combines AR techniques with real-time depth imaging to close the loop between dense 3D modeling and augmented reality. The proposed method detects the differences between a scene and a 3D model of the scene in real time. Then, the detected geometric differences are used to update the 3D model, thus bringing AR and 3D modeling closer together. The accuracy of the geometric difference detection depends on the depth measurement accuracy as well as on the accuracy of the intrinsic and extrinsic parameters. To evaluate the influence of these parameters, several experiments were conducted with simulated ground truth data. Furthermore, the evaluation shows the applicability of AR and depth image-based 3D modeling for model-based camera tracking.
C1 Fraunhofer IGD, Darmstadt, Germany.
RP Kahn, S (corresponding author), Fraunhofer IGD, Darmstadt, Germany.
EM svenja.kahn@igd.fraunhofer.de
FU German BMBF project AVILUSplus [01IM08002]
FX This work was partially funded by the German BMBF project AVILUSplus
   (01IM08002).
CR [Anonymous], 2011, P RGB D WORKSH 3D PE
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bastian J., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P199, DOI 10.1109/ISMAR.2010.5643570
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bleser G., 2005, J WSCG, P47
   Bleser G, 2009, THESIS TU KAISERSLAU
   Bleser G, 2007, J REAL-TIME IMAGE PR, V2, P161, DOI 10.1007/s11554-007-0034-0
   Bosche F., 2008, THESIS U WATERLOO
   Bosche F., 2006, P JOINT INT C COMP D, P37
   Bosché F, 2010, ADV ENG INFORM, V24, P107, DOI 10.1016/j.aei.2009.08.006
   Engelhard N, 2010, KINECTAUTOCALIBRATIO
   Franke T., 2011, Proceedings of the 16th International Conference on 3D Web Technology, P71, DOI DOI 10.1145/2010425.2010439
   Gall J, 2006, LECT NOTES COMPUT SC, V4319, P84
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Georgel P., 2007, P 2007 6 IEEE ACM IN, P1, DOI DOI 10.1109/ISMAR.2007.4538834
   Georgel P, 2009, INT SYM MIX AUGMENT, P187, DOI 10.1109/ISMAR.2009.5336468
   Georgel PF, 2009, IEEE COMPUT GRAPH, V29, P65, DOI 10.1109/MCG.2009.123
   Haller M., 2004, ACM International Conference on Virtual Reality Continuum and its Applications in Industry, P189, DOI [10.1145/1044588.1044627, DOI 10.1145/1044588.1044627]
   Huhle Benjamin, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P255, DOI 10.1504/IJISTA.2008.021288
   Ingo Schiller ChristianBeder., 2008, INT ARCH PHOTOGRAMME, V21, P297
   Kahn Svenja, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P241, DOI 10.1109/ISMAR.2010.5643587
   Kahn S, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P302
   Klein G, 2009, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2009.5336495
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Lindner M, 2007, ISSCS 2007: INTERNATIONAL SYMPOSIUM ON SIGNALS, CIRCUITS AND SYSTEMS, VOLS 1 AND 2, P121
   Newcombe RA, 2010, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2010.5539794
   Oggier T, 2006, LECT NOTES ARTIF INT, V4021, P212
   OpenNI, 2011, OP FRAM
   Pan Q, 2009, P 20 BRIT MACH VIS C, P11
   Panagopoulos A, 2009, PROC CVPR IEEE, P651, DOI 10.1109/CVPRW.2009.5206665
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   van den Hengel A, 2009, INT SYM MIX AUGMENT, P107, DOI 10.1109/ISMAR.2009.5336482
   Webel S, 2007, 2007 6 IEEE ACM INT, P281
   Wuest H., 2008, THESIS TU DARMSTADT
   Wuest H, 2007, LECT NOTES COMPUT SC, V4673, P20
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 37
TC 10
Z9 12
U1 0
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2013
VL 17
IS 2
SI SI
BP 111
EP 123
DI 10.1007/s10055-011-0203-0
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 139IH
UT WOS:000318575200002
DA 2024-07-18
ER

PT J
AU Regia-Corte, T
   Marchal, M
   Cirio, G
   Lécuyer, A
AF Regia-Corte, Tony
   Marchal, Maud
   Cirio, Gabriel
   Lecuyer, Anatole
TI Perceiving affordances in virtual reality: influence of person and
   environmental properties in perception of standing on virtual grounds
SO VIRTUAL REALITY
LA English
DT Article
DE Perception of affordances; Visual perception; Posture; Slanted surface;
   Virtual environments; Head-mounted display
ID POSTURAL AFFORDANCES; SCALED INFORMATION; HAPTIC PERCEPTION; VISUAL
   GUIDANCE; ANXIETY
AB We evaluated the perception of affordances in virtual environments (VE). In our work, we considered the affordances for standing on a virtual slanted surface. Participants were asked to judge whether a virtual slanted surface supported upright stance. The objective was to evaluate whether this perception was possible in virtual reality (VR) and comparable to previous works conducted in real environments. We found that the perception of affordances for standing on a slanted surface in virtual reality is possible and comparable (with an underestimation) to previous studies conducted in real environments. We also found that participants were able to extract and to use virtual information about friction in order to judge whether a slanted surface supported an upright stance. Finally, results revealed that the person's position on the slanted surface is involved in the perception of affordances for standing on virtual grounds. Taken together, our results show quantitatively that the perception of affordances can be effective in virtual environments and influenced by both environmental and person properties. Such a perceptual evaluation of affordances in VR could guide VE designers to improve their designs and to better understand the effect of these designs on VE users.
C1 [Regia-Corte, Tony; Marchal, Maud; Cirio, Gabriel; Lecuyer, Anatole] INRIA Rennes, F-35042 Rennes, France.
C3 Universite de Rennes
RP Regia-Corte, T (corresponding author), INRIA Rennes, Campus Univ Beaulieu, F-35042 Rennes, France.
EM tony.regiacorte@gmail.com; maud.marchal@inria.fr;
   gabriel.cirio@inria.fr; anatole.lecuyer@inria.fr
FU European community [222107 NIW]
FX The authors would like to thank Mr. Laurent Bonnet for his help on the
   design of the virtual reality setup and experimental benchmark. This
   work was supported by the European community under FP7 FET-Open grant
   agreement no. 222107 NIW-Natural Interactive Walking.
CR [Anonymous], 1999, INTERACTION, DOI DOI 10.1145/301153.301168
   BOOTSMA R J, 1992, Ecological Psychology, V4, P1
   Chemero A, 2003, ECOL PSYCHOL, V15, P181, DOI 10.1207/S15326969ECO1502_5
   Cornus S, 1999, ECOL PSYCHOL, V11, P249, DOI 10.1207/s15326969eco1104_1
   FITZPATRICK P, 1994, ECOL PSYCHOL, V6, P265, DOI 10.1207/s15326969eco0604_2
   Fitzpatrick P, 2003, IEEE INT CONF ROBOT, P3140
   Flach JM, 1998, PRESENCE-TELEOP VIRT, V7, P90, DOI 10.1162/105474698565550
   Gibson J., 1979, The ecological approach to visual perception
   Gross D, 2004, THESIS U CENTRAL FLO
   Gross DC, 2005, PRESENCE-VIRTUAL AUG, V14, P482, DOI 10.1162/105474605774785244
   HOUTMAN ILD, 1989, J PERS ASSESS, V53, P575, DOI 10.1207/s15327752jpa5303_14
   JIANG Y, 1994, PERCEPT PSYCHOPHYS, V56, P691, DOI 10.3758/BF03208362
   JIANG Y, 1993, STUDIES IN PERCEPTION AND ACTION II, P333
   Jones KS, 2003, ECOL PSYCHOL, V15, P107, DOI 10.1207/S15326969ECO1502_1
   Kinsella-Shaw Jeffrey M., 1992, Ecological Psychology, V4, P223, DOI 10.1207/s15326969eco0404_2
   Klevberg GL, 2002, HUM MOVEMENT SCI, V21, P169, DOI 10.1016/S0167-9457(02)00100-8
   Lepecq JC, 2009, VIRTUAL REAL-LONDON, V13, P141, DOI 10.1007/s10055-009-0118-1
   Malek EA, 2008, Q J EXP PSYCHOL, V61, P1813, DOI 10.1080/17470210701712978
   MARK LS, 1987, J EXP PSYCHOL HUMAN, V13, P361, DOI 10.1037/0096-1523.13.3.361
   McGrenere J, 2000, PROC GRAPH INTERF, P179
   Michaels C.F., 1981, Direct perception
   Norman D. A., 1988, PSYCHOL EVERYDAY THI
   OREGAN JK, 1989, PERCEPT PSYCHOPHYS, V46, P434, DOI 10.3758/BF03210858
   Oudejans RRD, 1996, J EXP PSYCHOL HUMAN, V22, P879, DOI 10.1037/0096-1523.22.4.879
   PEPER L, 1994, J EXP PSYCHOL HUMAN, V20, P591, DOI 10.1037/0096-1523.20.3.591
   Pijpers JR, 2006, ECOL PSYCHOL, V18, P131, DOI 10.1207/s15326969eco1803_1
   Regia-Corte T, 2008, EXP BRAIN RES, V191, P25, DOI 10.1007/s00221-008-1492-8
   Regia-Corte T, 2010, P IEEE VIRT REAL ANN, P207, DOI 10.1109/VR.2010.5444789
   Richardson MJ, 2007, J EXP PSYCHOL HUMAN, V33, P845, DOI 10.1037/0096-1523.33.4.845
   Sahin E, 2007, ADAPT BEHAV, V15, P447, DOI 10.1177/1059712307084689
   Steinicke F., 2009, Proceedings of the 6th Symposium on Applied Perception in Graphics and Visualization, P19, DOI 10.1145/1620993.1620998
   Stoffregen TA, 2003, ECOL PSYCHOL, V15, P115, DOI 10.1207/S15326969ECO1502_2
   Turvey M.T., 1992, Ecological Psychology, V4, P173, DOI DOI 10.1207/S15326969ECO04033
   Ugur E, 2011, ROBOT AUTON SYST, V59, P580, DOI 10.1016/j.robot.2011.04.005
   Ugur E, 2010, ADAPT BEHAV, V18, P258, DOI 10.1177/1059712310370625
   WARREN WH, 1984, J EXP PSYCHOL HUMAN, V10, P683, DOI 10.1037/0096-1523.10.5.683
   WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371
NR 37
TC 27
Z9 31
U1 2
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2013
VL 17
IS 1
BP 17
EP 28
DI 10.1007/s10055-012-0216-3
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 089NC
UT WOS:000314916300002
DA 2024-07-18
ER

PT J
AU Atashgah, MAA
   Malaek, SMB
AF Atashgah, M. A. Amiri
   Malaek, S. M. B.
TI An integrated virtual environment for feasibility studies and
   implementation of aerial MonoSLAM
SO VIRTUAL REALITY
LA English
DT Article
DE 3D graphics engine; Virtual environment; MonoSLAM; General aviation;
   Aerial navigation
ID LOCALIZATION; NAVIGATION
AB This work presents a complete framework of an integrated aerial virtual environment (IAVE), which could effectively help implementing MonoSLAM (single-camera simultaneous localization and mapping) on an aerial vehicle. The developed system allows investigating different flight conditions without using any preloaded maps or predefined features. A 3D graphical engine integrated with a full 6 DOF aircraft dynamic simulator together with its trajectory generator completes the package. The 3D engine generates and accumulates real-time images of a general camera installed on the aerial vehicle. We effectively exploit C++ to develop the 3D graphics engine (3DGE) and all its associated visual effects, including different types of lighting, climate conditions, and moving objects. The existing 3DGE exploits the so-called Frenet Adapted Frames (FAF) with constrained angular velocities that is very effective in motion modeling of both ground and aerial moving objects. An in-house-developed MATLAB GUI puts into service the offline MonoSLAM system, which is very user friendly. The current version of IAVE effectively employs the so-called Inverse Depth Parameterization notions for features' depth estimation in monocular SLAM, where different case studies show its dependable results for low-cost aerial navigation of a general aviation low-speed aircraft.
C1 [Atashgah, M. A. Amiri; Malaek, S. M. B.] Sharif Univ Technol, Dept Aerosp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Atashgah, MAA (corresponding author), Sharif Univ Technol, Dept Aerosp Engn, Tehran, Iran.
EM atashgah@ae.sharif.edu; malaek@sharif.edu
RI Atashgah, MohammadAli Amiri/ABA-3376-2020
OI Atashgah, MohammadAli Amiri/0000-0002-8096-4162
CR Amiri-Atashgah MA, 2009, FLIGHT SIM C TEHR
   [Anonymous], JSBSIM OPEN SOURCE P
   Berndt J., 2004, AIAA MOD SIM TECHN C
   Blanco JL., 2010, MOBILE ROBOT PROGRAM
   Bouguet J., 2010, CAMERA CALIBRATION T
   Brooks F., 1999, WHATS REAL VIRTUAL R
   Cesetti A, 2009, MED C CONTR AUTOMAT, P910, DOI 10.1109/MED.2009.5164661
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276
   Conte G, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/387308
   Davison AJ, 2004, IFAC S INT AUT VEH 2
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Diosi A, 2004, P 2004 IEEE RSJ INT
   Farouki RT, 2009, COMPUT ANIMAT VIRT W, V20, P457, DOI 10.1002/cav.274
   Frese U, 2006, AUTON ROBOT, V20, P25, DOI 10.1007/s10514-006-5735-x
   Funke J, 2009, BRIT MACH VIS C 2009
   Harris C., 1988, ALVEY VISION C, P147151
   Johnson AE, 2007, AIAA C EXH 2007
   Johnson EN, 2005, IEEE T AERO ELEC SYS, V41
   Jung I, 2003, P 9 INT C COMP VIS N
   Kim J, 2004, P I MECH ENG G-J AER, V218, P399, DOI 10.1243/0954410042794957
   Kim JH, 2003, IEEE INT CONF ROBOT, P406
   LEONARD JJ, 1991, IEEE T ROBOTIC AUTOM, V7, P376, DOI 10.1109/70.88147
   Luna F.D., 2006, INTRO 3D GAME PROGRA
   MONTIEL JMM, 2006, ROBOTICS SCI SYSTEMS
   Mourikis AI, 2007, AIAA C 2007 ATL GA
   Rolfe J.M., 1986, Flight simulation
   Roskam J., 1987, Airplane Design, V21, P213
   Saghafi F, 2000, THESIS SHARIF U TECH
   Sim DG, 1999, IEEE T IMAGE PROCESS, V8, P429, DOI 10.1109/83.748898
   Sim DG, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P629, DOI 10.1109/ICIP.1996.560953
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404
   Sola J., 2007, THESIS I NATL POLITE
   Stevens B., 2003, Aircraft Control and Simulation
   Sunderhauf N., 2007, IEEE INT WORKSH SAF
NR 34
TC 10
Z9 12
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2012
VL 16
IS 3
BP 215
EP 232
DI 10.1007/s10055-011-0197-7
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 990MV
UT WOS:000307635900004
DA 2024-07-18
ER

PT J
AU Alvarez, JC
   Su, HJ
AF Alvarez, Juan Camilo
   Su, Hai-Jun
TI VRMDS: an intuitive virtual environment for supporting the conceptual
   design of mechanisms
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Conceptual design; Computer-aided design; Mechanism
   design
AB This paper presents Virtual Reality Mechanism Design Studio (VRMDS), an intuitive virtual environment for supporting the interactive design and simulation of mechanisms. The studio allows users to build spatial or planar mechanisms through intuitive operations and subsequently simulate their dynamic motion. Written in Python script language, VRMDS provides 3D stereoscopic immersive visualization, haptic enabled interaction, head and hand tracking and a user-friendly graphical user interface. A data model for organizing the data structure of links and commonly used mechanical joints is designed and implemented upon the basis of the Vizard Virtual Reality (VR) library. Within the virtual environment, the user can create links and assemble them into a mechanism by defining joints between links. Simultaneously, a corresponding MATLAB's SimMechanics model is automatically created at run time. The dynamics simulation of mechanisms is enabled by interfacing with the dynamics solver built-in SimMechanics. The user may choose to run the system in an immersive VR environment or a desktop environment. The result is a versatile mechanism design tool that is beneficial to the early stages of the design process. A case study of a spatial mechanism is provided to demonstrate the usefulness of this system in mechanism design.
C1 [Alvarez, Juan Camilo; Su, Hai-Jun] Univ Maryland Baltimore Cty, Dept Mech Engn, Baltimore, MD 21250 USA.
C3 University System of Maryland; University of Maryland Baltimore County
RP Su, HJ (corresponding author), Univ Maryland Baltimore Cty, Dept Mech Engn, 1000 Hilltop Circle, Baltimore, MD 21250 USA.
EM haijun@umbc.edu
RI Su, Haijun/B-8145-2012
OI Su, Haijun/0000-0002-3132-0213
FU National Science Foundation [0900517]; Div Of Civil, Mechanical, &
   Manufact Inn; Directorate For Engineering [1153184, 0900517] Funding
   Source: National Science Foundation
FX The authors acknowledge the support of the National Science Foundation
   grant no. 0900517.
CR Antonya Csaba, 2007, Virtual Reality, V11, P275, DOI 10.1007/s10055-007-0074-6
   Barbieri L, 2008, INT J ADV MANUF TECH, V38, P1085, DOI 10.1007/s00170-007-1160-3
   Bierbaum A, 2001, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2001.913774
   Bourdot P, 2010, COMPUT AIDED DESIGN, V42, P445, DOI 10.1016/j.cad.2008.10.014
   Brough John E., 2007, Virtual Reality, V11, P189, DOI 10.1007/s10055-007-0076-4
   Burdea G., 2002, Virtual reality technology second edition
   Cheng HH, 2006, ENG COMPUT-GERMANY, V21, P237, DOI 10.1007/s00366-005-0008-4
   Erlemeier TA, 2006, THESIS IOWA STATE U
   Fiorentino M, 2006, P WORKSH VIRT REAL P
   Furlong TJ, 1999, J MECH DESIGN, V121, P515, DOI 10.1115/1.2829491
   Jayaram S, 1999, IEEE COMPUT GRAPH, V19, P44, DOI 10.1109/38.799739
   Jayaram S., 2001, Journal of Computing and Information Science in Engineering, V1, P72, DOI [https://doi.org/10.1115/1.1353846, DOI 10.1115/1.1353846]
   Larochelle PM, 1993, P 1993 NSF DES MAN S
   Larochelle PM, 1998, P ASME DETC 98 SEPT
   McCarthy J.M., 2000, GEOMETRIC DESIGN LIN
   Nelson L., 1994, Proc. of the ASME Design Technical Conference, V70, P263
   Seth A, 2008, J COMPUT INF SCI ENG, V8, DOI 10.1115/1.3006306
   Seth U, 2009, P ASME IDETC CIE 200
   Stan SD, 2008, LECT NOTES ARTIF INT, V5314, P1265, DOI 10.1007/978-3-540-88513-9_134
   Su H.-J., 2002, ASME INT DES ENG TEC
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   Tsai L.W., 2000, Mechanism design: enumeration of kinematic structures according to function
   Ullman D.G., 2003, The Mechanical Design Process
   Vance JM, 2002, P ASME IDETC CIE 200
   Wan H, 2004, ASME 2004 DES ENG TE
   Zhu WH, 2008, J COMPUT INF SCI ENG, V8, DOI 10.1115/1.2988340
NR 26
TC 9
Z9 13
U1 2
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2012
VL 16
IS 1
SI SI
BP 57
EP 68
DI 10.1007/s10055-009-0144-z
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 897NL
UT WOS:000300657600007
DA 2024-07-18
ER

PT B
AU Oropesa, I
   Lamata, P
   Sánchez-González, P
   Pagador, JB
   García, ME
   Sánchez-Margallo, FM
   Gómez, EJ
AF Oropesa, Ignacio
   Lamata, Pablo
   Sanchez-Gonzalez, Patricia
   Pagador, Jose B.
   Garcia, Maria E.
   Sanchez-Margallo, Francisco M.
   Gomez, Enrique J.
BE Kim, JJ
TI Virtual Reality Simulators for Objective Evaluation on Laparoscopic
   Surgery: Current Trends and Benefits.
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
ID CONSTRUCT-VALIDITY; SKILLS ASSESSMENT; LEARNING-CURVE; FACE VALIDITY;
   MIST-VR; VALIDATION; LAPSIM; COMPETENCE; ACQUISITION; PERFORMANCE
C1 [Oropesa, Ignacio; Lamata, Pablo; Sanchez-Gonzalez, Patricia; Garcia, Maria E.; Gomez, Enrique J.] Tech Univ Madrid, ETSIT, Bioengn & Telemed Grp, Madrid, Spain.
   [Oropesa, Ignacio; Sanchez-Gonzalez, Patricia; Gomez, Enrique J.] Networking Res Ctr Bioengn Biomat & Nanomed, Madrid, Spain.
   [Pagador, Jose B.; Sanchez-Margallo, Francisco M.] Minimally Invas Surg Ctr Jesus Uson, Madrid, Spain.
C3 Universidad Politecnica de Madrid; CIBER - Centro de Investigacion
   Biomedica en Red; CIBERBBN
RP Oropesa, I (corresponding author), Tech Univ Madrid, ETSIT, Bioengn & Telemed Grp, Madrid, Spain.
RI Sánchez-González, Patricia/B-3718-2015; Sánchez-González,
   Patricia/AAE-2067-2020; Pagador, Blas/D-5914-2011; Oropesa,
   Ignacio/L-6252-2014; Sánchez Margallo, Francisco Miguel
   Miguel/I-5605-2019; Pagador, J. Blas/J-9858-2016; Lamata,
   Pablo/AAE-7884-2020; Oropesa, Ignacio/JWP-3272-2024; GOMEZ, ENRIQUE
   J/K-6698-2017
OI Sánchez-González, Patricia/0000-0001-9871-0884; Pagador,
   Blas/0000-0002-4382-5075; Oropesa, Ignacio/0000-0003-4560-285X; Sánchez
   Margallo, Francisco Miguel Miguel/0000-0003-2138-988X; Pagador, J.
   Blas/0000-0002-4382-5075; Lamata, Pablo/0000-0002-3097-4928; GOMEZ,
   ENRIQUE J/0000-0001-6998-1407
CR Agarwal R, 2003, STUD HEALTH TECHNOL, V94, P1
   Aggarwal R, 2009, BRIT J SURG, V96, P1086, DOI 10.1002/bjs.6679
   Ayodeji ID, 2007, SURG ENDOSC, V21, P1641, DOI 10.1007/s00464-007-9219-7
   Balaniuk R, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P1310, DOI 10.1109/IROS.2000.893200
   Bloom B, 1956, TAXONOMY ED OBJECTIV
   Botden S M B I, 2008, Surg Technol Int, V17, P26
   Botden SMBI, 2007, WORLD J SURG, V31, P764, DOI 10.1007/s00268-006-0724-y
   Broe D, 2006, SURG ENDOSC, V20, P900, DOI 10.1007/s00464-005-0530-x
   Cano AM, 2008, LECT NOTES COMPUT SC, V5104, P191, DOI 10.1007/978-3-540-70521-5_21
   Cavallo F, 2006, STUD HEALTH TECHNOL, V119, P79
   Chmarra MK, 2007, MINIM INVASIV THER, V16, P328, DOI 10.1080/13645700701702135
   Chmarra MK, 2008, SURG ENDOSC, V22, P2140, DOI 10.1007/s00464-008-9937-5
   Chmarra MK, 2010, SURG ENDOSC, V24, P1031, DOI 10.1007/s00464-009-0721-y
   Chmarra MK, 2006, SENSOR ACTUAT A-PHYS, V126, P328, DOI 10.1016/j.sna.2005.10.040
   Cotin S., 2002, P MED IM COMP COMP A
   Cuschieri A, 2005, SURG-J R COLL SURG E, V3, P125, DOI 10.1016/S1479-666X(05)80032-0
   Datta V, 2001, J AM COLL SURGEONS, V193, P479, DOI 10.1016/S1072-7515(01)01041-9
   Datta V, 2002, SURGERY, V131, P318, DOI 10.1067/msy.2002.120235
   Delingette H, 1998, P IEEE, V86, P512, DOI 10.1109/5.662876
   Eriksen JR, 2005, SURG ENDOSC, V19, P1216, DOI 10.1007/s00464-004-2154-y
   Fichera Alessandro, 2005, JSLS, V9, P125
   Freudenthal A., 2010, J BIOMEDICA IN PRESS
   Fried GM, 2008, WORLD J SURG, V32, P156, DOI 10.1007/s00268-007-9143-y
   Gallagher AG, 2004, SURG ENDOSC, V18, P660, DOI 10.1007/s00464-003-8176-z
   Gallagher AG, 2003, SURG ENDOSC, V17, P1525, DOI 10.1007/s00464-003-0035-4
   García-Pérez V, 2009, IEEE T INF TECHNOL B, V13, P451, DOI 10.1109/TITB.2009.2016838
   Greco E. M. D., 2008, CAN ASS GEN SURG ANN
   Gurusamy KS, 2009, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006575.pub2
   Halsted WS, 1904, B JOHNS HOPKINS HOSP, V15, P267
   Hanna GB, 1998, SURG ENDOSC-ULTRAS, V12, P997, DOI 10.1007/s004649900765
   HARDEN RM, 1975, BRIT MED J, V1, P447, DOI 10.1136/bmj.1.5955.447
   Hassan I, 2005, CHIRURG, V76, P151, DOI 10.1007/s00104-004-0936-3
   Hassan I, 2008, WIEN KLIN WOCHENSCHR, V120, P70, DOI 10.1007/s00508-008-0930-8
   Horeman T., 2010, SURG ENDOSCOPY
   Issenberg SB, 2005, MED TEACH, V27, P10, DOI 10.1080/01421590500046924
   Kitagawa M, 2005, J THORAC CARDIOV SUR, V129, P151, DOI 10.1016/j.jtcvs.2004.05.029
   Kneebone R, 2003, MED EDUC, V37, P267, DOI 10.1046/j.1365-2923.2003.01440.x
   Kühnapfel U, 2000, COMPUT GRAPH-UK, V24, P671, DOI 10.1016/S0097-8493(00)00070-4
   Lamata P, 2006, SURG ENDOSC, V20, P1368, DOI 10.1007/s00464-004-9269-z
   Lamata P., 2006, METHODOLOGIES ANAL D
   Lamata P, 2007, COMPUT METH PROG BIO, V85, P273, DOI 10.1016/j.cmpb.2006.12.002
   Lamata P, 2006, IEEE COMPUT GRAPH, V26, P69, DOI 10.1109/MCG.2006.125
   Langelotz C, 2005, LANGENBECK ARCH SURG, V390, P534, DOI 10.1007/s00423-005-0571-6
   Larsen CR, 2006, SURG ENDOSC, V20, P1460, DOI 10.1007/s00464-005-0745-x
   Liselotte L. M., 2009, J SOC LAPAROENDSCOPI, V13, P279
   Maithel S, 2006, SURG ENDOSC, V20, P104, DOI 10.1007/s00464-005-0054-4
   Martin JA, 1997, BRIT J SURG, V84, P273, DOI 10.1046/j.1365-2168.1997.02502.x
   McCluney A, 2006, P SAGES
   McDougall EM, 2006, J AM COLL SURGEONS, V202, P779, DOI 10.1016/j.jamcollsurg.2006.01.004
   Meier U, 2005, COMPUT METH PROG BIO, V77, P183, DOI 10.1016/j.cmpb.2004.11.002
   MILLER GE, 1990, ACAD MED, V65, pS63, DOI 10.1097/00001888-199009000-00045
   Monserrat C, 2003, LECT NOTES COMPUT SC, V2673, P59
   Moorthy K, 2003, BMJ-BRIT MED J, V327, P1032, DOI 10.1136/bmj.327.7422.1032
   Neary PC, 2008, SURG ENDOSC, V22, P2301, DOI 10.1007/s00464-008-9900-5
   Newmark J, 2007, AM J OBSTET GYNECOL, V197, DOI 10.1016/j.ajog.2007.07.026
   Okrainec A., 2008, ASS SURG ED ANN M TO
   Pellen MGC, 2009, SURG ENDOSC, V23, P130, DOI 10.1007/s00464-008-0066-y
   Picinbono G, 2002, CR BIOL, V325, P335, DOI 10.1016/S1631-0691(02)01453-1
   Pithioux M, 2005, COMPUT GRAPH-UK, V29, P135, DOI 10.1016/j.cag.2004.11.002
   Ritter EM, 2007, SURG ENDOSC, V21, P1441, DOI 10.1007/s00464-007-9261-5
   Ro CY, 2005, ST HEAL T, V111, P414
   Rosen Jacob, 2002, Comput Aided Surg, V7, P49, DOI 10.1002/igs.10026
   Rosser JC, 1997, ARCH SURG-CHICAGO, V132, P200
   Sánchez-Peralta LF, 2010, INT J COMPUT ASS RAD, V5, P307, DOI 10.1007/s11548-010-0425-8
   Satava R M, 2003, Surg Endosc, V17, P220, DOI 10.1007/s00464-002-8869-8
   Satava RM, 2008, WORLD J SURG, V32, P141, DOI 10.1007/s00268-007-9374-y
   Schijven M, 2003, SURG ENDOSC, V17, P803, DOI 10.1007/s00464-002-9151-9
   Schreuder HWR, 2009, AM J OBSTET GYNECOL, V200, DOI 10.1016/j.ajog.2008.12.030
   Scott DJ, 2000, J AM COLL SURGEONS, V191, P272, DOI 10.1016/S1072-7515(00)00339-2
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Sherman V, 2005, SURG ENDOSC, V19, P678, DOI 10.1007/s00464-004-8943-5
   Sidhu RS, 2004, SURGERY, V135, P6, DOI 10.1016/S0039-6060(03)00154-5
   Sinigaglia S, 2005, INT CONGR SER, V1281, P509, DOI 10.1016/j.ics.2005.03.195
   Sokollik C, 2004, SURG ENDOSC, V18, P495, DOI 10.1007/s00464-003-9065-1
   Stone R, 2004, BMJ-BRIT MED J, V328, P1115, DOI 10.1136/bmj.328.7448.1115
   Stylopoulos N, 2004, SURG ENDOSC, V18, P782, DOI 10.1007/s00464-003-8932-0
   Tavakol M, 2008, J SURG EDUC, V65, P77, DOI 10.1016/j.jsurg.2007.11.003
   Tendick F, 2000, PRESENCE-VIRTUAL AUG, V9, P236, DOI 10.1162/105474600566772
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Thijssen AS, 2010, AM J SURG, V199, P529, DOI 10.1016/j.amjsurg.2009.04.015
   Vassiliou MC, 2005, AM J SURG, V190, P107, DOI 10.1016/j.amjsurg.2005.04.004
   Verdaasdonk EGG, 2007, SURG ENDOSC, V21, P214, DOI 10.1007/s00464-005-0852-8
   Verdaasdonk EGG, 2006, SURG ENDOSC, V20, P511, DOI 10.1007/s00464-005-0230-6
   Woodrum DT, 2006, AM J SURG, V191, P28, DOI 10.1016/j.amjsurg.2005.10.018
   Youngblood PL, 2005, J AM COLL SURGEONS, V200, P546, DOI 10.1016/j.jamcollsurg.2004.11.011
   Zhang AM, 2008, SURG ENDOSC, V22, P1440, DOI 10.1007/s00464-007-9625-x
NR 86
TC 5
Z9 6
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 349
EP 374
D2 10.5772/553
PG 26
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400017
DA 2024-07-18
ER

PT J
AU Pettey, G
   Bracken, CC
   Rubenking, B
   Buncher, M
   Gress, E
AF Pettey, Gary
   Bracken, Cheryl Campanella
   Rubenking, Bridget
   Buncher, Michael
   Gress, Erika
TI Telepresence, soundscapes and technological expectation: putting the
   observer into the equation
SO VIRTUAL REALITY
LA English
DT Article
DE Telepresence; Sound; Speakers; Headphones; Technological expectation
ID TELEVISION; NEWS
AB In an experiment exploring the impact of sound on sensations of telepresence, 126 participants watched a video clip using either headphones or speakers. The results illustrate that sound is an important factor in stimulating telepresence responses in audiences. Interactions between soundscape and screen size were also revealed. A traverse interaction between aural/visual congruency and soundscapes was evident. A second data set of 102 participants was collected to illuminate the effect of technological expectation that emerged in the first study. Expectations had been mentioned in other studies, and the data support the notion that people have an expectation of the technological quality of a presentation. The results suggest that examining expectations could assist in future conceptualizations of telepresence.
C1 [Pettey, Gary; Bracken, Cheryl Campanella; Gress, Erika] Cleveland State Univ, Sch Commun, Cleveland, OH 44115 USA.
   [Rubenking, Bridget] Indiana Univ, Dept Telecommun, Bloomington, IN 47405 USA.
   [Buncher, Michael] Michigan State Univ, Dept Commun, E Lansing, MI 48824 USA.
C3 University System of Ohio; Cleveland State University; Indiana
   University System; Indiana University Bloomington; Michigan State
   University
RP Bracken, CC (corresponding author), Cleveland State Univ, Sch Commun, 2121 Euclid Ave,MU 223, Cleveland, OH 44115 USA.
EM c.bracken@csuohio.edu
OI Rubenking, Bridget/0000-0002-9364-9612
CR ANNAUD JJ, 1981, QUEST FIRE MOTION PI
   [Anonymous], 1977, HUMAN EMOTIONS
   Besmer F.E., 1983, Horses, Musicians, and Gods: The Hausa Cult of Possession Trance
   BLESSER B, 2007, WORKING VOCABULARY E
   Blesser Barry., 2007, Spaces Speak, Are You Listening?
   Bracken CC, 2005, MEDIA PSYCHOL, V7, P191, DOI 10.1207/S1532785XMEP0702_4
   BRACKEN CC, 2008, INF PROC DIV INT COM
   Bracken CC, 2006, J BROADCAST ELECTRON, V50, P723, DOI 10.1207/s15506878jobem5004_9
   Deeprose C, 2004, BRIT J ANAESTH, V92, P171, DOI 10.1093/bja/aeh054
   Freeman J., 2004, PRES ICA 2004 P
   Hall Edward Twitchell, 1966, HIDDEN DIMENSION
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Heeter C, 2003, PRESENCE-TELEOP VIRT, V12, P335, DOI 10.1162/105474603322391587
   Ivory JD, 2007, J COMMUN, V57, P532, DOI 10.1111/j.1460-2466.2007.00356.x
   Izard C.E., 1974, DIFFERENTIAL EMOTION
   Izard C.E., 1972, PATTERNS OF EMOTIONS
   Kallinen K, 2007, COMPUT HUM BEHAV, V23, P303, DOI 10.1016/j.chb.2004.10.014
   Kim T., 1997, J COMPUT MED COMMUN, V3, pJCMC325
   LARSSON P, 2007, 10 ANN INT WORKSH PR
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   LEGROUX S, 2007, P10 ANN INT WORKSH
   Lombard M., 2000, Resources for the study of presence
   LOMBARD M, 1997, J COMPUT-MEDIAT COMM, V13, P573
   LOMBARD M, 2009, 12 ANN INT C PRES WO
   LOMBARD M, 2008, MED BEC REAL WORKSH
   NUNEZ D, 2007, P10 ANN INT WORKSH
   PETTEY G, 2008, P 11 ANN INT M PRES, P38
   Portas CM, 2000, NEURON, V28, P991, DOI 10.1016/S0896-6273(00)00169-0
   Rattenborg NC, 1999, NATURE, V397, P397, DOI 10.1038/17037
   Rouget Gilbert., 1985, MUSIC TRANCE THEORY
   Skalski P, 2007, MEDIA PSYCHOL, V10, P385, DOI 10.1080/15213260701533102
   TAJADURAJIMENEZ A, 2007, P10 ANN INT WORKSH
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   *THX, 2009, HDTV BUYING TIPS THX
   *THX, 2009, THX CERT CIN
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 36
TC 14
Z9 15
U1 2
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2010
VL 14
IS 1
SI SI
BP 15
EP 25
DI 10.1007/s10055-009-0148-8
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HU
UT WOS:000296279400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Portnoy, DB
   Smoak, ND
   Marsh, KL
AF Portnoy, David B.
   Smoak, Natalie D.
   Marsh, Kerry L.
TI Perceiving interpersonally-mediated risk in virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Sexual risk; Embodiment; Interpersonal risk
ID REALITY; BEHAVIOR; PREDICTORS; INTERNET; THERAPY; FUTURE; REASON
AB Using virtual reality (VR) to examine risky behavior that is mediated by interpersonal contact, such as agreeing to have sex, drink, or smoke with someone, offers particular promise and challenges. Social contextual stimuli that might trigger impulsive responses can be carefully controlled in virtual environments (VE), and yet manipulations of risk might be implausible to participants if they do not feel sufficiently immersed in the environment. The current study examined whether individuals can display adequate evidence of presence in a VE that involved potential interpersonally-induced risk: meeting a potential dating partner. Results offered some evidence for the potential of VR for the study of such interpersonal risk situations. Participants' reaction to the scenario and risk-associated responses to the situation suggested that the embodied nature of virtual reality override the reality of the risk's impossibility, allowing participants to experience adequate situational embedding, or presence.
C1 [Portnoy, David B.; Smoak, Natalie D.; Marsh, Kerry L.] Univ Connecticut, Ctr Hlth Intervent & Prevent, Storrs, CT 06269 USA.
   [Portnoy, David B.] NCI, NIH, Bethesda, MD 20892 USA.
   [Smoak, Natalie D.] Illinois Wesleyan Univ, Dept Psychol, Bloomington, IL 61701 USA.
C3 University of Connecticut; National Institutes of Health (NIH) - USA;
   NIH National Cancer Institute (NCI); Illinois Wesleyan University
RP Marsh, KL (corresponding author), Univ Connecticut, Ctr Hlth Intervent & Prevent, Storrs, CT 06269 USA.
EM portnoydb@mail.nih.gov; kerry.l.marsh@uconn.edu
OI Marsh, Kerry/0000-0001-5106-5419; Portnoy, David/0000-0003-2175-9457
FU University of Connecticut, Center for Health, Intervention, and
   Prevention; National Institute of Mental Health
FX This research was supported by grants to Kerry L. Marsh and David B.
   Portnoy from the University of Connecticut, Center for Health,
   Intervention, and Prevention. This article was written while the third
   author was supported by a grant from the National Institute of Mental
   Health. We would like to thank our research assistants for help with
   data collection and the two volunteers who recorded Blair's voice.
CR AMBADY N, 1992, PSYCHOL BULL, V111, P256, DOI 10.1037/0033-2909.111.2.256
   Austin John L., 2003, DO THINGS WORDS
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Bargh JA, 1996, J PERS SOC PSYCHOL, V71, P230, DOI 10.1037/0022-3514.71.2.230
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bordnick PS, 2008, ADDICT BEHAV, V33, P743, DOI 10.1016/j.addbeh.2007.12.010
   Buck R, 2004, J BUS RES, V57, P647, DOI 10.1016/S0148-2963(02)00308-9
   Clark H., USING LANGUAGE
   Eastwick PW, 2009, SOC INFLUENCE, V4, P18, DOI 10.1080/15534510802254087
   EASTWICK PW, 2005, SOC PERS SOC PSYCH A
   Epstein J, 2007, SEX ROLES, V56, P23, DOI 10.1007/s11199-006-9169-x
   Gamberini L, 2003, ERGONOMICS, V46, P842, DOI 10.1080/0014013031000111266
   Gibson J., 1979, The ecological approach to visual perception
   Gilbert M., 1996, LIVING TOGETHER RATI
   Gilbert M., 2000, SOCIALITY RESPONSIBI
   Goldberg LR, 2006, J RES PERS, V40, P84, DOI 10.1016/j.jrp.2005.08.007
   Lance L.M., 2004, COLL STUD J, V38, P579
   Lee JH, 2003, CYBERPSYCHOL BEHAV, V6, P275, DOI 10.1089/109493103322011560
   Marsh KL, 2006, ECOL PSYCHOL, V18, P1, DOI 10.1207/s15326969eco1801_1
   Marsh KL, 2001, Z EXP PSYCHOL, V48, P161
   MARSH KL, EUR J SOC P IN PRESS
   McCloy R, 2001, BRIT MED J, V323, P912, DOI 10.1136/bmj.323.7318.912
   North MM, 1997, ST HEAL T, V44, P59
   Paul EL, 2000, J SEX RES, V37, P76, DOI 10.1080/00224490009552023
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Rizzo A, 2005, STUD HEALTH TECHNOL, V111, P407
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Vincenzi DA, 2003, NAV ENG J, V115, P79, DOI 10.1111/j.1559-3584.2003.tb00189.x
   Williams KD, 2000, J PERS SOC PSYCHOL, V79, P748, DOI 10.1037/0022-3514.79.5.748
NR 32
TC 2
Z9 3
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2010
VL 14
IS 1
SI SI
BP 67
EP 76
DI 10.1007/s10055-009-0120-7
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HU
UT WOS:000296279400007
PM 20228871
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wissmath, B
   Weibel, D
   Mast, FW
AF Wissmath, Bartholomaeus
   Weibel, David
   Mast, Fred W.
TI Measuring presence with verbal versus pictorial scales: a comparison
   between online- and ex post-ratings
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Online measurement; Post-rating; Verbal measures; Pictorial
   measures; SAM
ID VIRTUAL ENVIRONMENTS; PRESENCE QUESTIONNAIRE; SELECTIVE ATTENTION;
   TELEPRESENCE; TELEVISION; RESPONSES; REALISM
AB In this study, we compare subjective online- and post-immersion measures. Although its relevance appears obvious from a theoretical and applied research perspective, this question has not yet been addressed in previous studies. In addition, we also compare verbally and pictorially anchored scales. These factors were measured in different contents using a 2 9 2 9 2 design. We manipulated time of measure (online vs. ex post), type of measure (verbal vs. visual), and content (language vs. language-free). Participants (N = 162) evaluated two video clips in terms of presence. No differences between averaged online- and post-immersion measures were found and online judgments did not interfere with the sensation of presence. In line with findings from other areas of research, the use of pictorially anchored items has major advantages. Our results suggest that those items require less mental workload and assess the sensation of presence more directly than verbally anchored items. We discuss the theoretical implications of our findings.
C1 [Wissmath, Bartholomaeus; Weibel, David; Mast, Fred W.] Univ Bern, Dept Psychol, Bern 9, Switzerland.
   [Wissmath, Bartholomaeus; Weibel, David] Swiss Univ Inst Distance Educ, CH-3900 Brig, Switzerland.
C3 University of Bern
RP Wissmath, B (corresponding author), Univ Bern, Dept Psychol, Muesmattstr 45, Bern 9, Switzerland.
EM wissmath@psy.unibe.ch; david.weibel@psy.unibe.ch; fred.mast@psy.unibe.ch
RI Mast, Fred/B-5058-2013
OI Mast, Fred/0000-0002-0665-4457; Wissmath,
   Bartholomaus/0000-0002-6222-6094; Weibel, David/0000-0002-1848-9065
CR [Anonymous], J COMPUT MEDIAT COMM
   [Anonymous], 1985, COGNITIVE PSYCHOPHYS
   Baddeley A., 2000, The Oxford Handbook of Memory, P77
   Bracken CC, 2005, MEDIA PSYCHOL, V7, P191, DOI 10.1207/S1532785XMEP0702_4
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   CAMPBELL DT, 1959, PSYCHOL BULL, V56, P81, DOI 10.1037/h0046016
   Draper JV, 1998, HUM FACTORS, V40, P354, DOI 10.1518/001872098779591386
   Freeman J, 2000, PRESENCE-TELEOP VIRT, V9, P149, DOI 10.1162/105474600566691
   Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI DOI 10.1162/PRES.1992.1.2.262
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P274, DOI 10.1162/pres.1996.5.3.274
   Ijsselsteijn W, 1998, DISPLAYS, V18, P207, DOI 10.1016/S0141-9382(98)00022-5
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Insko B.E., 2003, BEING THERE CONCEPTS, P211
   JEX H R, 1988, P5
   LANG A, 2000, SELF ASSESSMENT MANI
   LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x
   Lavie N, 2005, TRENDS COGN SCI, V9, P75, DOI 10.1016/j.tics.2004.12.004
   Lavie N, 1997, PSYCHOL SCI, V8, P395, DOI 10.1111/j.1467-9280.1997.tb00432.x
   Lombard M, 2000, HUM COMMUN RES, V26, P75, DOI 10.1111/j.1468-2958.2000.tb00750.x
   Lombard M., 2008, MED ENV BEC REAL WME
   Lombard M, 1997, J COMPUT MEDIAT COMM, V3
   Lombard M., 2005, TEMPLE PRESENCE INVE
   McCulloch CharlesE., 2000, Generalized, linear, and mixed models
   Minsky M., 1980, OMNI, V2, P45, DOI DOI 10.1145/566654.566630
   SCHLOERB DW, 1995, PRESENCE-TELEOP VIRT, V4, P64, DOI 10.1162/pres.1995.4.1.64
   Schneider EF, 2004, HUM COMMUN RES, V30, P361, DOI 10.1111/j.1468-2958.2004.tb00736.x
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2007, PRESENCE-TELEOP VIRT, V16, P447, DOI 10.1162/pres.16.4.447
   Snow MP, 1998, HUM FACTORS, V40, P386, DOI 10.1518/001872098779591395
   Sternberg RJ, 2000, PSYCHOL PUBLIC POL L, V6, P159, DOI 10.1037//1076-8971.6.1.159
   Steuer J., 1992, J COMMUN, V42, P72
   Szalma JL, 2004, HUM FACTORS, V46, P219, DOI 10.1518/hfes.46.2.219.37334
   van Baren J., 2004, MEASUREMENT, P1
   Welch RB, 1996, PRESENCE-TELEOP VIRT, V5, P263, DOI 10.1162/pres.1996.5.3.263
   WELCH RB, 1997, DESIGNS COMPUTING SY, P271
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 40
TC 18
Z9 21
U1 0
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2010
VL 14
IS 1
SI SI
BP 43
EP 53
DI 10.1007/s10055-009-0127-0
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HU
UT WOS:000296279400005
DA 2024-07-18
ER

PT J
AU Lepecq, JC
   Bringoux, L
   Pergandi, JM
   Coyle, T
   Mestre, D
AF Lepecq, Jean-Claude
   Bringoux, Lionel
   Pergandi, Jean-Marie
   Coyle, Thelma
   Mestre, Daniel
TI Afforded actions as a behavioral assessment of physical presence in
   virtual environments
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Behavior; Affordance; Virtual reality
ID SPATIAL PRESENCE; BODY; PERCEPTION; APERTURES; MOTION
AB A particular affordance was used as a potential candidate for behavioral assessment of physical presence in virtual environments. The subjects' task was to walk through a virtual aperture of variable widths. In the case of presence, the subjects' body orientation, while walking, was hypothesized to be adapted to the width of the aperture and to their own shoulder width. Results show that most subjects adapted their behavior to both their body architecture and the virtual width constraints. These subjects exhibited a behavioral transition from frontal walking to body rotation while walking through broad to narrow apertures. The same behavioral transition has already been documented in real environments (Warren and Whang in J Exp Psychol Human Percept Perform 13(3):371-383, 1987). This behavioral adjustment is thus assumed to be an objective indication of presence. Beyond these results, the present study suggests that every afforded action could be a potential tool for sensorimotor assessment of physical presence.
C1 [Lepecq, Jean-Claude; Bringoux, Lionel; Pergandi, Jean-Marie; Coyle, Thelma; Mestre, Daniel] Univ Mediterranee, UMR 6233, Inst Sci Mouvement, CNRS, F-13288 Marseille 9, France.
C3 Aix-Marseille Universite; Centre National de la Recherche Scientifique
   (CNRS)
RP Lepecq, JC (corresponding author), Univ Mediterranee, UMR 6233, Inst Sci Mouvement, CNRS, 163 Ave Luminy,CP 910, F-13288 Marseille 9, France.
EM jean-claude.lepecq@univmed.fr
RI Bringoux, Lionel/IVV-5593-2023; Mestre, Daniel/J-9526-2015
OI Bringoux, Lionel/0000-0003-3939-8151; Mestre, Daniel/0000-0002-0399-4747
CR [Anonymous], J COMP MEDIAT COMMUN
   Berlucchi G, 1997, TRENDS NEUROSCI, V20, P560, DOI 10.1016/S0166-2236(97)01136-3
   Carassa A., 2005, Proceedings of the 27th Annual Conference of the Cognitive Science Society: 2005, P384
   DeFanti TA, 1993, Proceedings of the 20th annual conference on Computer graphics and interactive techniques, P135, DOI 10.1145/166117.166134.
   Flach JM, 1998, PRESENCE-TELEOP VIRT, V7, P90, DOI 10.1162/105474698565550
   Freeman J, 2000, PRESENCE-TELEOP VIRT, V9, P149, DOI 10.1162/105474600566691
   Gibson J., 1979, The ecological approach to visual perception
   Gordon MS, 2004, ECOL PSYCHOL, V16, P87, DOI 10.1207/s15326969eco1602_1
   Hecht D, 2007, CYBERPSYCHOL BEHAV, V10, P243, DOI 10.1089/cpb.2006.9962
   Higuchi T, 2006, EXP BRAIN RES, V175, P50, DOI 10.1007/s00221-006-0525-4
   Holmes N. P., 2006, HUMAN BODY PERCEPTIO, P15
   Ijsselsteijn W, 2001, PRESENCE-TELEOP VIRT, V10, P298, DOI 10.1162/105474601300343621
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Insko BE, 2003, EMERG COMMUNICAT, V5, P109
   *INT SOC PRES RES, 2008, CONC PRES EXPL STAT
   Ishak S, 2008, J EXP PSYCHOL HUMAN, V34, P1501, DOI 10.1037/a0011393
   Lombard M, 2007, PSYCHNOLOGY J, V5, P197
   Mars F, 2005, TRAV HUMAIN, V68, P125, DOI 10.3917/th.682.0125
   Popper K., 2005, The logic of scientific discovery
   Sas C, 2003, PRESENCE-TELEOP VIRT, V12, P523, DOI 10.1162/105474603322761315
   Schubert TW, 2009, COMMUN THEOR, V19, P161, DOI 10.1111/j.1468-2885.2009.01340.x
   Slater M, 2002, PRESENCE-TELEOP VIRT, V11, P435, DOI 10.1162/105474602760204327
   STAPPERS PJ, 1999, 2 INT WORKSH PRES U
   Tinsworth D., 2001, Special study: Injuries and deaths associated with children's playground equipment
   van Baren J., 2004, Compendium of presence measures. (IST FET OMNIPRES project)
   WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371
   Wiederhold B.K., 2001, CYBERPSYCHOLOGY, P175
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zahorik P, 1998, PRESENCE-VIRTUAL AUG, V7, P78, DOI 10.1162/105474698565541
NR 30
TC 35
Z9 39
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2009
VL 13
IS 3
BP 141
EP 151
DI 10.1007/s10055-009-0118-1
PN 1
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XE
UT WOS:000208104300002
DA 2024-07-18
ER

PT J
AU Fares, C
   Hamam, Y
AF Fares, Charbel
   Hamam, Yskandar
TI Optimisation-based proximity queries and penetration depth computation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality (VR); Proximity queries (PQ); Penetration depth (PD);
   Linear programming
AB The virtual reality (VR) was found to be a perfect technique that could be used as a training approach, since it shows many advantages despite its weakness. In the VR some major bottlenecks arises namely the proximity queries (PQ) and penetration depth computation. This paper shows a novel algorithm used to solve those problems. Problems of PQ are ubiquitous within many tasks in computer graphics, virtual environments, robotics, manufacturing, and mechanical design. Interactions in any virtual scene usually involve contact or close proximity between its objects. Determining which pairs of objects are in contact or at close proximity is a complex task in most of the virtual environments. The PQ is the shortest vector over which one object needs to be translated in order to bring the pair in contact.
C1 [Fares, Charbel] Holy Spirit Univ Kaslik, FSGI, Kaslik, Lebanon.
   [Fares, Charbel; Hamam, Yskandar] ESIEE, Lab A2SI, F-93162 Noisy Le Grand, France.
   [Hamam, Yskandar] FSATI Tshwane Univ Technol, Pretoria, South Africa.
C3 Universite Gustave-Eiffel; ESIEE Paris; Tshwane University of Technology
RP Fares, C (corresponding author), Holy Spirit Univ Kaslik, FSGI, Kaslik, Lebanon.
EM charbelfares@usek.edu.lb; y.hamam@esiee.fr
OI Fares, Charbel/0000-0002-4741-752X
CR Agarwal P. K., 2000, Nordic Journal of Computing, V7, P227
   Cameron S, 1997, IEEE INT CONF ROBOT, P3112, DOI 10.1109/ROBOT.1997.606761
   Cameron S., 1991, Proceedings. Symposium on Solid Modeling Foundations and CAD/CAM Applications, P129, DOI 10.1145/112515.112537
   Cameron S. A., 1986, Proceedings 1986 IEEE International Conference on Robotics and Automation (Cat. No.86CH2282-2), P591
   DOBKIN D, 1993, ALGORITHMICA, V9, P518, DOI 10.1007/BF01190153
   DWORKIN P, 1993, P EUR WORKSH AN SIM, P175
   EDELSBRUNNER H, 1985, J ALGORITHM, V6, P213, DOI 10.1016/0196-6774(85)90039-2
   FISHER S, 2001, P EG WORKSH COMP AN
   GILBERT EG, 1988, IEEE T ROBOTIC AUTOM, V4, P193, DOI 10.1109/56.2083
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Gregory A., 2000, P IEEE VIS C
   HOFF K, 2001, P ACM S INT 3D GRAPH
   HSU D, 1998, P 3 WORKSH ALG FDN R
   HUBBARD PM, 1993, P IEEE S RES FRONT V
   Kim YJ, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P209, DOI 10.1109/HAPTIC.2002.998960
   Klosowski JT, 1998, IEEE T VIS COMPUT GR, V4, P21, DOI 10.1109/2945.675649
   LIN MC, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1008, DOI 10.1109/ROBOT.1991.131723
   McKenna M., 1990, Computer Graphics, V24, P29, DOI 10.1145/97880.97882
   McNeely WA, 1999, COMP GRAPH, P401, DOI 10.1145/311535.311600
   Mirtich B, 1998, ACM T GRAPHIC, V17, P177, DOI 10.1145/285857.285860
   MIRTICH B, 2000, P ACM SIGGRAPH
   Ong C, 1996, IEEE T ROB AUTOM, V12
   QUINLAN S, 1994, IEEE INT CONF ROBOT, P3324, DOI 10.1109/ROBOT.1994.351059
   Requicha A. A. G., 1993, Manufacturing Review, V6, P269
   Stewart DE, 1996, INT J NUMER METH ENG, V39, P2671
   Teschner M, 2004, P EUROGRAPHICS
   VanDen Bergen G., 2001, GAM DEV C, V170
NR 27
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2009
VL 13
IS 2
BP 131
EP 136
DI 10.1007/s10055-009-0116-3
PG 6
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA V19XD
UT WOS:000208104200005
DA 2024-07-18
ER

PT J
AU Salehi, F
   Pariafsai, F
   Dixit, MK
AF Salehi, Faezeh
   Pariafsai, Fatemeh
   Dixit, Manish K.
TI The impact of misaligned idiotropic and visual axes on spatial ability
   under altered visuospatial conditions
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented and virtual reality; Spatial cognition; Spatial ability;
   Interdisciplinary projects
AB Spatial ability, a critical dimension of human cognition, represents the ability to gather, perceive, and manipulate spatial information to create an accurate and complete mental representation of spatial environments. Previous studies have examined spatial ability in normal spatial conditions of the earth. However, emerging technologies and increasing exploration of hard-to-reach locations are transforming future workplaces into environments with altered visuospatial conditions, which may pose serious challenges to workers' productivity and safety. One such condition is the misalignment of idiotropic and visual axes that may exist in microgravity during space explorations or underwater during deep-sea explorations. In this study, we investigate whether and to what extent misaligned idiotropic and visual axes influence spatial ability. The misalignment was simulated in Virtual Reality (VR) with three conditions: aligned (control group), misaligned (experiment group I), and dynamically misaligned (experiment group II) idiotropic and visual axes. The spatial ability of 99 participants was measured through spatial visualization, relations, and orientation abilities using the Purdue Spatial Visualization Test: Rotations (PSVTR), Mental Cutting Test (MCT), and Perspective-Taking Ability (PTA) test, respectively. For the MCT and PTA tests, the results show no significant differences in response accuracy among the three conditions. The PSVTR test results reflect a statistically significant difference in accuracy among the groups. The three groups did not have significantly different response times for the three tests. The results suggest that the misalignment of the body and visual axes may influence spatial visualization, but may not impact spatial relations or orientation.
C1 [Salehi, Faezeh; Dixit, Manish K.] Texas A&M Univ, Dept Construct Sci, 3137 TAMU, College Stn, TX 77843 USA.
   [Pariafsai, Fatemeh] BGSU, Dept Construct Management, Bowling Green, OH 43403 USA.
C3 Texas A&M University System; Texas A&M University College Station;
   University System of Ohio; Bowling Green State University
RP Salehi, F (corresponding author), Texas A&M Univ, Dept Construct Sci, 3137 TAMU, College Stn, TX 77843 USA.
EM faezehsalehi@tamu.edu; fpariaf@bgsu.edu; mdixit@tamu.edu
RI Pariafsai, Fatemeh/AAS-8922-2020
OI Dixit, Manish/0000-0001-8622-8388; Salehi, Faezeh/0000-0002-8607-2878
FU National Science Foundation
FX The presented work has been supported by the US National Science
   Foundation (NSF) through grant CNS 1928695. The authors gratefully
   acknowledge the support from the NSF. Any opinions, findings,
   conclusions, and recommendations expressed in this paper are those of
   the authors and do not necessarily represent those of the NSF.
CR Alberty M, 2015, How to train your astronauts
   Alberty M, 2017, How to train your astronauts
   ANNETT M, 1992, BRIT J PSYCHOL, V83, P493, DOI 10.1111/j.2044-8295.1992.tb02455.x
   [Anonymous], NASA Extreme Environment Mission Operations
   [Anonymous], 1939, Special Aptitude Test in Spatial Relations (MCT)
   Buckley J, 2018, EDUC PSYCHOL REV, V30, P947, DOI 10.1007/s10648-018-9432-z
   Carroll J., 1993, Human cognitive abilities: A survey of factoranalytic studies
   CASEY MB, 1995, DEV PSYCHOL, V31, P697, DOI 10.1037/0012-1649.31.4.697
   Castro-Alonso JC., 2019, Visuospatial processing for education in health and natural sciences, P23, DOI DOI 10.1007/978-3-030-20969-8_2
   Clement G, 2011, SPACE TECHNOL LIB, V23, P1, DOI 10.1007/978-1-4419-9905-4
   Clément G, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132317
   Contero M, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.107
   de Bruin N, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00007
   Dowker A, 1996, BEHAV BRAIN SCI, V19, P251, DOI 10.1017/S0140525X0004245X
   Dyde RT, 2009, EXP BRAIN RES, V194, P647, DOI 10.1007/s00221-009-1741-5
   Dye MWG, 2009, NEUROPSYCHOLOGIA, V47, P1780, DOI 10.1016/j.neuropsychologia.2009.02.002
   Ekstrom R., 1976, Kit of factor-referenced cognitive tests
   Ernst Jeremy V., 2017, Engineering Design Graphics Journal, V81, P1
   Fatemah A, 2020, J CHEM EDUC, V97, P992, DOI 10.1021/acs.jchemed.9b00690
   Fehringer BC, 2021, Supplementary materials to: R-Cube-SR test: a new test for spatial relations distinguishable from visualization
   Fennema E., 1974, Mathematics, spatial ability and the sexes
   Gabriel KI, 2011, SEX ROLES, V64, P81, DOI 10.1007/s11199-010-9877-0
   Garg A, 1999, MED TEACH, V21, P519
   Gholami S, 2022, MATER DESIGN, V220, DOI 10.1016/j.matdes.2022.110878
   Guo J, 2016, INT C MAN MACH ENV S
   Guzsvinecz T, 2022, VIRTUAL REAL-LONDON, V26, P601, DOI 10.1007/s10055-021-00509-2
   Ha O, 2013, PROC FRONT EDUC CONF
   Harle M, 2011, J CHEM EDUC, V88, P351, DOI 10.1021/ed900003n
   Harris D, 2021, BRIT J EDUC PSYCHOL, V91, P409, DOI 10.1111/bjep.12371
   Harris LR, 2010, SEEING PERCEIVING, V23, P81, DOI 10.1163/187847510X490826
   Harris LR, 2011, PROG BRAIN RES, V191, P133, DOI 10.1016/B978-0-444-53752-2.00008-4
   He XY, 2021, INT J EDUC RES, V109, DOI 10.1016/j.ijer.2021.101795
   Hegarty M, 2004, INTELLIGENCE, V32, P175, DOI 10.1016/j.intell.2003.12.001
   Hegarty Mary., 2020, Applied spatial cognition, P285
   Heo M, 2020, COMPUT EDUC, V146, DOI 10.1016/j.compedu.2019.103747
   HIER DB, 1982, NEW ENGL J MED, V306, P1202, DOI 10.1056/NEJM198205203062003
   Höffler TN, 2010, EDUC PSYCHOL REV, V22, P245, DOI 10.1007/s10648-010-9126-7
   Hoffman M, 2011, P NATL ACAD SCI USA, V108, P14786, DOI 10.1073/pnas.1015182108
   Jain D, 2016, P 2016 CHI C HUM FAC
   Jain D, 2016, P 29 ANN S US INT SO
   Jenkin MR, 2011, SEEING PERCEIVING, V24, P53, DOI 10.1163/187847511X555292
   Kanas N, 2015, Psychology in deep space
   Kanas N, 2008, SPACE TECHNOL LIB, V22, P15, DOI 10.1007/978-1-4020-6770-9_2
   Katsioloudis Petros, 2014, Journal of Technology Education, V26, P88
   Katsioloudis PJ, 2014, Eng Des Graph J, V78, P2
   Khine M.S., 2017, Visual-spatial ability in STEM education, P3, DOI DOI 10.1007/978-3-319-44385-0_1
   Kincl L., 2003, OCCUPATIONAL ERGONOM, V3, P251, DOI 10.3233/OER-2003-3406
   Kozhevnikov M, 2001, MEM COGNITION, V29, P745, DOI 10.3758/BF03200477
   Kyttälä M, 2014, LEARN INDIVID DIFFER, V29, P59, DOI 10.1016/j.lindif.2013.10.010
   Langlois J, 2020, ANAT SCI EDUC, V13, P71, DOI 10.1002/ase.1873
   Li XS, 2021, SCI EDUC-NETHERLANDS, V30, P121, DOI 10.1007/s11191-020-00167-x
   Li Y., 2020, Virtual Reality Intelligent Hardware, V2, P556, DOI [10.1016/j.vrih.2020.08.001, DOI 10.1016/J.VRIH.2020.08.001]
   Liao H, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6030060
   Liao K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085192
   Lin Y, 2021, 54 HAW INT C SYST SC
   LINN MC, 1985, CHILD DEV, V56, P1479, DOI 10.1111/j.1467-8624.1985.tb00213.x
   Lohman D. F., 1979, SPATIAL ABILITY REV
   Lohman DavidF., 1988, Spatial abilities as traits, processes, and knowledge
   Long LO, 2011, PRESENCE-TELEOP VIRT, V20, P466, DOI 10.1162/PRES_a_00066
   Lowrie T, 2019, J COGN DEV, V20, P729, DOI 10.1080/15248372.2019.1653298
   Lowrie T, 2017, BRIT J EDUC PSYCHOL, V87, P170, DOI 10.1111/bjep.12142
   Maeda Y, 2011, 2011 ASEE ANN C EXP
   Maeda Y, 2013, EDUC PSYCHOL REV, V25, P69, DOI 10.1007/s10648-012-9215-x
   Marin F, 2018, arXiv, DOI 10.48550/ARXIV.1806.03856
   McGee M.G., 1979, HUMAN SPATIAL ABILIT
   Meirhaeghe N, 2020, ACTA ASTRONAUT, V170, P375, DOI 10.1016/j.actaastro.2020.01.039
   Miiro S, 2017, The issues and complexities surrounding the future of long duration spaceflight
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Miyake A, 2001, J EXP PSYCHOL GEN, V130, P621, DOI 10.1037/0096-3445.130.4.621
   Nagy-Kondor R., 2022, Quality Quantity, DOI DOI 10.1007/S11135-021-01284-7
   Németh B, 2007, ANN MATH INFORM, V34, P123
   Newell FN., 2011, INSIGHT RES PRACT VI, V4, P103
   Oman Charles M., 2007, P209, DOI 10.1007/978-0-387-71978-8_13
   Park H, 2021, 17 BIENN INT C ENG S
   Park Y, 2020, GERM C SPAT COGN
   Pittalis M, 2010, EDUC STUD MATH, V75, P191, DOI 10.1007/s10649-010-9251-8
   Quaiser-Pohl C., 2003, INT J TEST, V3, P219, DOI [10.1207/S15327574IJT03032, DOI 10.1207/S15327574IJT03032, 10.1207/S15327574IJT0303_2]
   Quasha WH, 1937, J EDUC PSYCHOL, V28, P197, DOI 10.1037/h0059880
   Rahmawati L, 2021, INT SEM PROC
   Rilea SL, 2008, BRAIN COGNITION, V67, P168, DOI 10.1016/j.bandc.2008.01.001
   Samsudin K, 2011, EDUC TECHNOL SOC, V14, P179
   Sandor A, 2016, Memo on speech alarms: replication and validation of results
   Schaller S, 2018, Applying game learning principles to analyze and identify improvements for scuba training simulations
   Schlack A, 2005, J NEUROSCI, V25, P4616, DOI 10.1523/JNEUROSCI.0455-05.2005
   Schulteis M., 2002, Ethical Issues Clin Neuropsychol, V243, P80
   Shebilske WL, 2006, AVIAT SPACE ENVIR MD, V77, P404
   Stapleton T, 2016, Environmental control and life support for deep space travel
   Strauss S., 2004, Extravehicular Mobility Unit Training Suit Symptom Study Report
   Sweeney K, 2014, ANAT SCI EDUC, V7, P289, DOI 10.1002/ase.1418
   Tito J, 2021, 2021 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI 2021), P1103, DOI 10.1109/CSCI54926.2021.00233
   TRACY DM, 1987, SEX ROLES, V17, P115, DOI 10.1007/BF00287620
   Tsutsumi E, 2008, J GEOM GRAPH, V12, P109
   Wulandari N, 2021, conference series
   Xie F, 2020, EDUC PSYCHOL REV, V32, P113, DOI 10.1007/s10648-019-09496-y
   Yuan L, 2019, FRONT BEHAV NEUROSCI, V13, DOI 10.3389/fnbeh.2019.00128
   Zaehle T, 2007, BRAIN RES, V1137, P92, DOI 10.1016/j.brainres.2006.12.044
NR 96
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3633
EP 3647
DI 10.1007/s10055-023-00859-z
EA SEP 2023
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:001065767500001
DA 2024-07-18
ER

PT J
AU Lau, KW
AF Lau, Kung Wong
TI Learning game innovations in immersive game environments: a factor
   analytic study of students' learning inventory in virtual reality
SO VIRTUAL REALITY
LA English
DT Article
DE Game innovations; Immersive environment; Digital gaming; Virtual
   reality; Learning inventory
ID SIMULATIONS; DESIGN; MODEL
AB The research is designed to trigger students' game innovations and facilitate their creative learning process by providing them with a "stimulated" immersive game environment to achieve self-regulated learning practice. This research has tailor-made three situated immersive games for data collection. The Self-regulated Learning model is applied to investigate students' cognitive, motivational, and emotional aspects of their learning process in these immersive game environments. This study involved a sample of 64 undergraduate students in interactive media design. The three factors and foci in this research are, (1) Cognitive Processing for Creative Thinking, (2) Personal Learning Motivation (PLM), and (3) Environmental Stimulation in Game. The positive results of this research indicated the use of immersive games in game innovation education is promising. The use of situated learning pedagogy provides students with an effective learning process for discovery learning. Students are experiencing "learn-by-doing" and exploring diverse solutions through the experiences gathered from the stimulated immersive environments. The result also provides educators with an alternative pedagogical approach to refining their future curriculums.
C1 [Lau, Kung Wong] Hong Kong Shue Yan Univ, Dept Journalism & Commun, Virtual Real Lab, 10 Wai Tsui Cres, 852-2804 8570, Hong Kong, Peoples R China.
C3 Hong Kong Shue Yan University
RP Lau, KW (corresponding author), Hong Kong Shue Yan Univ, Dept Journalism & Commun, Virtual Real Lab, 10 Wai Tsui Cres, 852-2804 8570, Hong Kong, Peoples R China.
EM laukw@hksyu.edu
RI LAU, Kung Wong/G-3653-2010
OI LAU, Kung Wong/0000-0003-4896-264X
CR Badiozaman IFA, 2022, INNOV EDUC TEACH INT, V59, P586, DOI 10.1080/14703297.2021.1899034
   Bowman DA, 1999, PRESENCE-TELEOP VIRT, V8, P317, DOI 10.1162/105474699566251
   Bruckman A., 1995, Convergence: The International Journal of Research into New Media Technologies, V1, P94, DOI 10.1177/135485659500100110
   Brunson AL, 2022, J EXPERIENT EDUC, V45, P413, DOI 10.1177/10538259221077178
   Burgos D, 2007, COMPUT HUM BEHAV, V23, P2656, DOI 10.1016/j.chb.2006.08.002
   Butler J. C., 2000, Campus-Wide Information Systems, V17, P44, DOI 10.1108/10650740010316998
   Cai ZH, 2022, EDUC PSYCHOL REV, V34, P537, DOI 10.1007/s10648-021-09655-0
   Calongne C., 2008, EDUCAUSE Review, V43, P36
   Church D., 1999, Formal abstract design tools
   Clark DB, 2016, REV EDUC RES, V86, P79, DOI 10.3102/0034654315582065
   de Freitas S, 2006, COMPUT EDUC, V46, P249, DOI 10.1016/j.compedu.2005.11.007
   De Freitas S., 2006, LEARN MEDIA TECHNOL, V31, P343, DOI [10.1080/17439880601021967, DOI 10.1080/17439880601021967]
   Dirckinck-Holmfeld L., 2002, LEARNING VIRTUAL ENV, P31
   Draper J V, 1999, Cyberpsychol Behav, V2, P349, DOI 10.1089/cpb.1999.2.349
   Ensmann S, 2021, TECHTRENDS, V65, P884, DOI 10.1007/s11528-021-00630-8
   Gaggioli A., 2001, Towards CyberPsychology: Mind, Cognitions and Society in the Internet Age, P157
   Hays RT, 2000, MIL PSYCHOL, V12, P161, DOI 10.1207/S15327876MP1203_1
   HKDEA, 2018, HONG KONG DIG ENT IN
   Horvat N, 2022, VIRTUAL REAL-LONDON, V26, P1227, DOI 10.1007/s10055-022-00630-w
   Johnson LF, 2008, THEOR PRACT, V47, P161, DOI 10.1080/00405840801992397
   Kiili K, 2007, BRIT J EDUC TECHNOL, V38, P394, DOI 10.1111/j.1467-8535.2007.00704.x
   Kuksa I, 2009, ART DES COMMUN HIGH, V7, P73, DOI 10.1386/adch.7.2.73_1
   Kung Wong Lau, 2012, Journal of Design Research, V10, P170, DOI 10.1504/JDR.2012.047922
   Lau KW, 2015, INTERACT LEARN ENVIR, V23, P3, DOI 10.1080/10494820.2012.745426
   Lee YH, 2012, CYBERPSYCH BEH SOC N, V15, P190, DOI 10.1089/cyber.2011.0328
   Lewis MW, 1992, EMERGING USES COMPUT
   Liu J., 2002, Virtual environments for teaching and learning, P75
   Liu RX, 2022, J COMPUT ASSIST LEAR, V38, P1422, DOI 10.1111/jcal.12688
   Mantovani F., 2001, Towards cyberpsychology: Mind, cognition and society in the internet age, P207
   Mayrose J., 2012, American Journal of Engineering Education (AJEE), V3, P13, DOI DOI 10.19030/AJEE.V3I1.6885
   Messick S., 1984, Social and technical issues in testing: Implications for test construction and usage, P156
   Monahan T, 2008, COMPUT EDUC, V50, P1339, DOI 10.1016/j.compedu.2006.12.008
   Patton R, 2020, STUD ART EDUC, V61, P155, DOI 10.1080/00393541.2020.1738165
   Ritterfeld U, 2009, CYBERPSYCHOL BEHAV, V12, P691, DOI 10.1089/cpb.2009.0099
   Salen Katie, 2004, RULES PLAY GAME DESI
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Stott D, 2007, STUDENT BMJ
   Sugahara S, 2019, J EDUC BUS, V94, P297, DOI 10.1080/08832323.2018.1527751
   Velabora C., 2022, INFORMATION, V134, p25p
   ZIMMERMAN BJ, 1986, AM EDUC RES J, V23, P614, DOI 10.2307/1163093
   ZIMMERMAN BJ, 1988, J EDUC PSYCHOL, V80, P284, DOI 10.1037/0022-0663.80.3.284
NR 41
TC 2
Z9 2
U1 5
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2023
VL 27
IS 3
BP 2331
EP 2339
DI 10.1007/s10055-023-00811-1
EA MAY 2023
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA GO0O4
UT WOS:000994757600001
DA 2024-07-18
ER

PT J
AU Im, JE
   Gu, JY
   Lim, EJ
   Lee, JG
AF Im, Ji-Eun
   Gu, Ja-Young
   Lim, Eun-Jeong
   Lee, Jae-Gi
TI Virtual reality technology using a 360° video: development and
   evaluation of an educational tool for intraoral radiography using the
   bisecting angle technique
SO VIRTUAL REALITY
LA English
DT Article
DE Bisecting angle technique; Dental education; Head-mounted display;
   Intraoral radiography; Virtual reality; 360 degrees video
AB Intraoral radiography (IOR) practice education is essential for dental students. However, the risk of radiation exposure has resulted in the use of textbooks to learn IOR. Thus, a new educational tool that can effectively use fewer shots or provide indirect experience when practice is not feasible is needed. In this study, we developed a new educational tool called "educational media for the bisecting angle technique" using virtual reality (EMBAT-VR) and evaluated the user experience among students. IOR was divided into 12 steps for 14 teeth, and a scenario was prepared from the perspectives of the operator and patient. On the basis of this scenario, the IOR was reenacted and recorded using a 360 degrees camera. The tool was built on a head-mounted display using the Unity Engine. Eighty-four students were enrolled to evaluate the task performance, browsing search, and satisfaction on a 5-point Likert scale; the corresponding values for the tests were 3. 78 +/- 0.70, 3.88 +/- 0.76, and 4.01 +/- 0.71, respectively. EMBAT-VR was used to investigate the satisfaction (user experience). Responses to 21 questions from 24 students who used traditional textbooks (control group) and 22 students who used the VR educational tool (experimental group) were statistically analyzed using the Mann-Whitney U test. A statistically significant difference was observed between the experimental (4.16 +/- 0.64) and control (2.69 +/- 0.54) groups. In the usability evaluation, EMBAT-VR presented with a higher score than traditional textbooks. Nonetheless, its effect when performing actual IOR imaging needs follow-up research.
C1 [Im, Ji-Eun; Lim, Eun-Jeong] Namseoul Univ, Dept Dent Hyg, Grad Sch, Cheonan, South Korea.
   [Gu, Ja-Young] Sahmyook Hlth Univ, Dept Dent Hyg, Seoul, South Korea.
   [Lee, Jae-Gi] Namseoul Univ, Coll Hlth & Hlth Care, Dept Dent Hyg, Room 106,91 Daehak Ro,Seonghwan Eup, Cheonan 31020, Chungcheongnamd, South Korea.
   [Lim, Eun-Jeong] Seoyeong Univ, Dept Dent Hyg, Paju, South Korea.
C3 Namseoul University; Namseoul University
RP Lee, JG (corresponding author), Namseoul Univ, Coll Hlth & Hlth Care, Dept Dent Hyg, Room 106,91 Daehak Ro,Seonghwan Eup, Cheonan 31020, Chungcheongnamd, South Korea.
EM leejaegi@nsu.ac.kr
OI Im, Ji Eun/0000-0002-1160-9976
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2020R1I1A3061952]
FX AcknowledgementsThis research was supported by the Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Education (NRF-2020R1I1A3061952).
CR Abuhammad A, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5030010
   Alfalah SFM, 2019, VIRTUAL REAL-LONDON, V23, P229, DOI 10.1007/s10055-018-0359-y
   Chang CY, 2022, INTERACT LEARN ENVIR, V30, P400, DOI 10.1080/10494820.2019.1661854
   Fahim S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083719
   Figueiredo M., 2021, Smart Innov. Syst. Technol, V198, P261, DOI [10.1007/978-3-030-55374-626, DOI 10.1007/978-3-030-55374-626]
   Firetto MC, 2019, RADIOL MED, V124, P887, DOI 10.1007/s11547-019-01038-4
   Grondahl H G, 1992, Dentomaxillofac Radiol, V21, P198
   Hanson J, 2020, NURS EDUC TODAY, V92, DOI 10.1016/j.nedt.2020.104518
   Huang JW, 2017, P IEEE VIRT REAL ANN, P37, DOI 10.1109/VR.2017.7892229
   Katsioloudis Petros, 2017, Engineering Design Graphics Journal, V81, P11
   Kazzi D, 2007, INT ENDOD J, V40, P526, DOI 10.1111/j.1365-2591.2007.01251.x
   Kullman L, 2012, DENT TRAUMATOL, V28, P193, DOI 10.1111/j.1600-9657.2011.01099.x
   Kurul R, 2020, ANAT SCI EDUC, V13, P648, DOI 10.1002/ase.1959
   Liebermann A, 2020, J DENT EDUC, V84, P1143, DOI 10.1002/jdd.12235
   Manousaridis G, 2015, RADIAT PROT DOSIM, V165, P111, DOI 10.1093/rpd/ncv088
   MCDONALD SP, 1984, COMMUNITY DENT ORAL, V12, P173, DOI 10.1111/j.1600-0528.1984.tb01433.x
   Morales-Vadillo Rafael, 2019, General Dentistry, V67, P21
   Mori M, 2022, ORAL RADIOL, V38, P147, DOI 10.1007/s11282-021-00538-2
   Moussa R, 2022, EUR J DENT, V16, P14, DOI 10.1055/s-0041-1731837
   Murbay S, 2020, EUR J DENT EDUC, V24, P5, DOI 10.1111/eje.12453
   Nassar HM, 2020, J DENT EDUC, V84, P812, DOI 10.1002/jdd.12138
   Pieri L, 2022, VIRTUAL REAL-LONDON, V26, P639, DOI 10.1007/s10055-021-00526-1
   Pirker J, 2021, IEEE COMPUT GRAPH, V41, P76, DOI 10.1109/MCG.2021.3067999
   Senior A, 2018, J DENT EDUC, V82, P61, DOI 10.21815/JDE.018.011
   Serman N, 2007, DENTOMAXILLOFAC RAD, V36, P443, DOI 10.1259/dmfr/82631203
   Shin N., 2003, DISTANCE EDUC, V24, P1, DOI DOI 10.1080/01587910303048
   Stepan K, 2017, INT FORUM ALLERGY RH, V7, P1006, DOI 10.1002/alr.21986
   Sutcliffe AG, 2000, BEHAV INFORM TECHNOL, V19, P415, DOI 10.1080/014492900750052679
   Sutherland J, 2019, J DIGIT IMAGING, V32, P38, DOI 10.1007/s10278-018-0122-7
   Tak NY, 2023, EUR J DENT EDUC, V27, P1, DOI 10.1111/eje.12769
   Tugnait A, 2003, J DENT, V31, P197, DOI 10.1016/S0300-5712(03)00013-7
   Vandenberghe B, 2010, EUR RADIOL, V20, P2637, DOI 10.1007/s00330-010-1836-1
   Vano E, 2007, Biomed Imaging Interv J, V3, pe26, DOI 10.2349/biij.3.2.e26
   Ventura S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02509
   Vertemati M, 2019, SURG INNOV, V26, P359, DOI 10.1177/1553350618822860
   Yin MS, 2021, J BIOMED INFORM, V114, DOI 10.1016/j.jbi.2020.103659
   Zafar S, 2021, EUR ARCH PAEDIATR DE, V22, P667, DOI 10.1007/s40368-021-00604-7
NR 37
TC 1
Z9 1
U1 4
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3599
EP 3612
DI 10.1007/s10055-023-00803-1
EA MAY 2023
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000982785800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Lam, WWT
   Fong, KNK
AF Lam, Winnie W. T.
   Fong, Kenneth N. K.
TI The application of markerless motion capture (MMC) technology in
   rehabilitation programs: a systematic review and meta-analysis
SO VIRTUAL REALITY
LA English
DT Review
DE Markerless motion capture; Virtual reality; Rehabilitation; Stroke;
   Upper extremity
ID VIRTUAL-REALITY SYSTEM; STROKE; BALANCE; OUTCOMES; PEOPLE; KINECT;
   TELEREHABILITATION; IMPROVEMENT; INTENSITY; STRENGTH
AB This review explores the effects of markerless motion capture technology-based rehabilitation programs targeting clinical populations and identifies the types of MMC systems used. A systematic search was conducted in the PubMed, Medline, CINAHL, CENTRAL, EMBASE, and IEEE databases. All eligible studies-single-group or controlled trial studies investigating the effectiveness of MMC technology-based rehabilitation programs-were selected. Single-group studies were qualitatively described; only controlled trial studies were included in the meta-analysis. Effects regarding the application of MMC technology for different types of patients and training body parts are summarized. Five single-group studies and 18 controlled trial studies were included. All studies applied MMC technology as a form of virtual reality training to provide rehabilitation programs. Most of the studies were conducted in regard to upper extremity training in stroke populations. Our meta-analysis revealed that there is no significant difference in the upper limb rehabilitation effects between VR training and control interventions. There is potential to apply MMC technology as an alternative way of providing rehabilitation to increase patients' motivation and adherence. Future studies on the design of training programs and MMC systems in home settings, which are affordable and accessible for patients, are warranted. (This review is registered in PROSPERO, registration ID: CRD42022298189).
C1 [Lam, Winnie W. T.; Fong, Kenneth N. K.] Hong Kong Polytech Univ, Dept Rehabil Sci, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Fong, KNK (corresponding author), Hong Kong Polytech Univ, Dept Rehabil Sci, Kowloon, Hong Kong, Peoples R China.
EM rsnkfong@polyu.edu.hk
RI Fong, Kenneth N. K./F-9608-2014
OI Fong, Kenneth N. K./0000-0001-5909-4847
FU Research Impact Fund [R5028-20]; Research Grants Council, University
   Grants Committee, Hong Kong SAR
FX This work was partially supported by the Research Impact Fund (Grant
   No.: R5028-20), Research Grants Council, University Grants Committee,
   Hong Kong SAR.
CR Afsar SI, 2018, J STROKE CEREBROVASC, V27, P3473, DOI 10.1016/j.jstrokecerebrovasdis.2018.08.007
   Alsinglawi B, 2019, BIOSYST BIOROBOT, V21, P252, DOI 10.1007/978-3-030-01845-0_50
   [Anonymous], 2021, THIS IS WHY MICROSOF
   Avcil E, 2021, ACTA NEUROL BELG, V121, P1053, DOI 10.1007/s13760-020-01400-8
   Bonato Paolo, 2005, J Neuroeng Rehabil, V2, P2, DOI 10.1186/1743-0003-2-2
   Burridge JH, 2017, J NEUROL PHYS THER, V41, pS32, DOI 10.1097/NPT.0000000000000183
   Cannell J, 2018, CLIN REHABIL, V32, P191, DOI 10.1177/0269215517720790
   Carr J.H., 2010, Neurological rehabilitation: optimizing motor performance
   Cho GH, 2014, J PHYS THER SCI, V26, P615, DOI 10.1589/jpts.26.615
   Cuesta-Gómez A, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00718-x
   Dabholkar1 Twinkle Y., 2020, Indian Journal of Public Health Research & Development, V11, P210, DOI DOI 10.37506/IJPHRD.V11I11.11375
   de Los Reyes-Guzman A, 2022, Rehabilitacion (Madr), V56, P173, DOI 10.1016/j.rh.2021.07.001
   DESROSIERS J, 1994, ARCH PHYS MED REHAB, V75, P751
   Ding WL, 2018, J BACK MUSCULOSKELET, V31, P611, DOI 10.3233/BMR-140203
   Fernández-González P, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0593-x
   Gramstad A, 2013, DISABIL REHABIL-ASSI, V8, P287, DOI 10.3109/17483107.2012.699993
   Hess JA, 2005, J MANIP PHYSIOL THER, V28, P582, DOI 10.1016/j.jmpt.2005.08.013
   Higgins J, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.ED000049
   Hughes AM., 2017, SAFE HOME ASSISTIVE, P59, DOI [10.1007/978-3-319-42890-1_5, DOI 10.1007/978-3-319-42890-1_5]
   Hughes CML, 2020, HEALTH INFORM J, V26, P1104, DOI 10.1177/1460458219868356
   Jaume-i-Capó A, 2014, IEEE T NEUR SYS REH, V22, P419, DOI 10.1109/TNSRE.2013.2279155
   Jonsdottir J, 2019, MULT SCLER RELAT DIS, V35, P76, DOI 10.1016/j.msard.2019.07.010
   Kharrazi H, 2012, GAMES HEALTH J, V1, P153, DOI 10.1089/g4h.2012.0011
   Kizony R, 2003, J VISUAL COMP ANIMAT, V14, P261, DOI 10.1002/vis.323
   Knippenberg E, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18147641
   Knippenberg E, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0270-x
   Lee G, 2013, J PHYS THER SCI, V25, P595, DOI 10.1589/jpts.25.595
   Lee JC, 2008, IEEE PERVAS COMPUT, V7, P39, DOI 10.1109/MPRV.2008.53
   Lee M, 2016, J REHABIL RES DEV, V53, P239, DOI 10.1682/JRRD.2014.07.0164
   Lee SI, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2829208
   Levin MF, 2012, NEUROL THER, V1, DOI 10.1007/s40120-012-0003-9
   Liang QH, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.5.051003
   Lloréns R, 2015, CLIN REHABIL, V29, P261, DOI 10.1177/0269215514543333
   Lloréns R, 2015, ARCH PHYS MED REHAB, V96, P418, DOI 10.1016/j.apmr.2014.10.019
   Lozano-Quilis JA, 2014, JMIR SERIOUS GAMES, V2, P43, DOI 10.2196/games.2933
   Lu W, 2016, IEEE SIGNAL PROC LET, V23, P1188, DOI 10.1109/LSP.2016.2590470
   Maceira-Elvira P, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0612-y
   Moseley AM, 2002, AUST J PHYSIOTHER, V48, P43, DOI 10.1016/S0004-9514(14)60281-6
   Mousavi Hondori Hossein, 2014, J Med Eng, V2014, P846514, DOI 10.1155/2014/846514
   Mubin O, 2022, DISABIL REHABIL-ASSI, V17, P159, DOI 10.1080/17483107.2020.1768309
   Mündermann L, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-6
   Waliño-Paniagua CN, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/9780587
   Norouzi-Gheidari N, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17010113
   Palacios-Navarro G, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0289-0
   Paneroni M, 2015, COPD, V12, P217, DOI 10.3109/15412555.2014.933794
   Pastor I, 2012, IEEE ENG MED BIO, P1286, DOI 10.1109/EMBC.2012.6346173
   Pereira Margarida F, 2020, J Biomed Inform, V111, P103584, DOI 10.1016/j.jbi.2020.103584
   Pompeu JE, 2014, PHYSIOTHERAPY, V100, P162, DOI 10.1016/j.physio.2013.10.003
   Pusztai Z, 2017, IEEE INT CONF COMP V, P394, DOI 10.1109/ICCVW.2017.53
   Qiu QY, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00789-w
   Rodríguez-Hernández M, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11050555
   Saposnik G, 2016, LANCET NEUROL, V15, P1019, DOI 10.1016/S1474-4422(16)30121-1
   Sarfo FS, 2018, J STROKE CEREBROVASC, V27, P2306, DOI 10.1016/j.jstrokecerebrovasdis.2018.05.013
   Seo NJ, 2019, AM J OCCUP THER, V73, DOI 10.5014/ajot.2019.031682
   Shiri S, 2012, TOP STROKE REHABIL, V19, P277, DOI 10.1310/tsr1904-277
   Sin H, 2013, AM J PHYS MED REHAB, V92, P871, DOI 10.1097/PHM.0b013e3182a38e40
   Tan CO, 2020, NEUROLOGY, V95, pE2462, DOI 10.1212/WNL.0000000000010839
   Tarakci E, 2016, 23 PRES 2016 C
   Tarakci E, 2020, J HAND THER, V33, P220, DOI 10.1016/j.jht.2019.03.012
   Teasell Robert W, 2003, Top Stroke Rehabil, V10, P29
   Tsekleves E, 2016, DISABIL REHABIL-ASSI, V11, P413, DOI 10.3109/17483107.2014.981874
   Vanbellingen T, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00654
   Wang ZR, 2017, NEURAL REGEN RES, V12, P1823, DOI 10.4103/1673-5374.219043
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 64
TC 5
Z9 5
U1 5
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2023
VL 27
IS 4
BP 3363
EP 3378
DI 10.1007/s10055-022-00696-6
EA SEP 2022
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AZ9X2
UT WOS:000854862900001
DA 2024-07-18
ER

PT J
AU van Gemert, T
   Hornbæk, K
   Bergström, J
AF van Gemert, Thomas
   Hornbaek, Kasper
   Bergstrom, Joanna
TI Step on it: asymmetric gain functions improve starting and stopping in
   virtual reality walking
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Walking; Non-isometric; Transfer function; Gain;
   Locomotion; Acceleration; Stopping
AB Transfer functions with a high translational gain can increase the range of walking in virtual reality. These functions determine how much virtual movements are amplified compared to the corresponding physical movements. However, it is unclear how the design of these functions influences the user's gait and experience when walking with high gain values. In a mixed-methods study with 20 users, we find that their best transfer functions are nonlinear and asymmetrical for starting and stopping. We use an optimization approach to determine individually optimized functions that are significantly better than a common approach of using a constant gain. Based on interviews, we also discuss what qualities of walking matter to users and how these vary across different functions. Our work shows that it is possible to create high-gain walking techniques that offer dramatically increased range of motion and speed but still feel like normal walking.
C1 [van Gemert, Thomas; Hornbaek, Kasper; Bergstrom, Joanna] Univ Copenhagen, Dept Comp Sci, Univ Pk 5, DK-2100 Copenhagen, Denmark.
C3 University of Copenhagen
RP van Gemert, T (corresponding author), Univ Copenhagen, Dept Comp Sci, Univ Pk 5, DK-2100 Copenhagen, Denmark.
EM tvg@di.ku.dk; kash@di.ku.dk; joanna@di.ku.dk
RI Bergström, Joanna/AAZ-1583-2021; Hornbaek, Kasper/F-8286-2014
OI Bergström, Joanna/0000-0001-6764-5661; van Gemert,
   Thomas/0000-0001-7827-3760; Hornbaek, Kasper/0000-0001-8742-1198
FU European Union [801199]; Presence Lab - Carlsberg Foundation [CF20-0686]
FX This project has received funding from the European Union's Horizon 2020
   research and innovation programme under the Marie Sklodowska-Curie grant
   agreement No. 801199. The project has been supported by the Presence Lab
   granted by the Carlsberg Foundation, application CF20-0686.
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Nguyen A, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139167
   [Anonymous], 2006, Proceedings of the 3rd Symposium on Applied Perception in Graphics and Visualization, APGV'06, DOI 10.1145/1140491.1140495
   Cortes CAT, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365694
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Janeh O, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343119
   Janeh O, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3022731
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   LAND MF, 1994, NATURE, V369, P742, DOI 10.1038/369742a0
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Lewis J. R., 2013, Conference on human factors in computing systemsProceedings, P2099, DOI DOI 10.1145/2470654.2481287
   Matthis JS, 2018, CURR BIOL, V28, P1224, DOI 10.1016/j.cub.2018.03.008
   Meta Platforms Inc, 2022, ADAPTIVE EXPERIMENTA
   Meta Quest Support, 2022, WHATS IPD ADJUST IT
   Mohler Betty., 2007, 13th Eurographics Symposium on Virtual Environments and 10th Immersive Projection Technology Workshop (IPT-EGVE 2007), P85, DOI DOI 10.2312/PE/VE2007SHORT/085-088
   Mohler BJ, 2007, ACM T APPL PERCEPT, V4, DOI [10.1145/1227134.1227138, 10.1145/1227134/1227138]
   Multon F., 2013, Human Walking in Virtual Environments, P55, DOI [10.1007/978-1-4419-8432- 6_3, DOI 10.1007/978-1-4419-8432-6_3]
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   Nabiyouni M., 2016, PROC ACM COMPANION I, P115, DOI DOI 10.1145/3009939.3010076
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   RIESER JJ, 1995, J EXP PSYCHOL HUMAN, V21, P480, DOI 10.1037/0096-1523.21.3.480
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Unity Technologies, 2013, WHAT IS MATH ANIMATI
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Williams B, 2008, DISSERTATION
   Williams-Sanders B, 2019, LECT NOTES COMPUT SC, V11574, P277, DOI 10.1007/978-3-030-21607-8_22
   Wilson G, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173673
   Zanbaka C, 2004, P IEEE VIRT REAL ANN, P149, DOI 10.1109/VR.2004.1310068
NR 31
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2023
VL 27
IS 2
BP 777
EP 795
DI 10.1007/s10055-022-00692-w
EA SEP 2022
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA I3LP6
UT WOS:000852101100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Litleskare, S
   Fröhlich, F
   Flaten, OE
   Haile, A
   Johnsen, SAK
   Calogiuri, G
AF Litleskare, Sigbjorn
   Frohlich, Fred
   Flaten, Ole Einar
   Haile, Amelia
   Johnsen, Svein Age Kjos
   Calogiuri, Giovanna
TI Taking real steps in virtual nature: a randomized blinded trial
SO VIRTUAL REALITY
LA English
DT Article
DE Green exercise; Virtual reality; Immersive virtual environments; Virtual
   green exercise; Mixed-methods
ID AFFECTIVE RESPONSES; PHYSICAL-ACTIVITY; MOTION SICKNESS; GREEN EXERCISE;
   ENVIRONMENTS; PERCEPTION; OUTDOOR; TECHNOLOGY; OUTCOMES; HEALTH
AB Studies show that green exercise (i.e., physical activity in the presence of nature) can provide the synergistic psychophysiological benefits of both physical exercise and nature exposure. The present study aimed to investigate the extent to which virtual green exercise may extend these benefits to people that are unable to engage in active visits to natural environments, as well as to promote enhanced exercise behavior. After watching a video validated to elicit sadness, participants either performed a treadmill walk while exposed to one of two virtual conditions, which were created using different techniques (360 degrees video or 3D model), or walked on a treadmill while facing a blank wall (control). Quantitative and qualitative data were collected in relation to three overarching themes: "Experience," "Physical engagement" and "Psychophysiological recovery." Compared to control, greater enjoyment was found in the 3D model, while lower walking speed was found in the 360 degrees video. No significant differences among conditions were found with respect to heart rate, perceived exertion, or changes in blood pressure and affect. The analysis of qualitative data provided further understanding on the participants' perceptions and experiences. These findings indicate that 3D model-based virtual green exercise can provide some additional benefits compared to indoor exercise, while 360 degrees video-based virtual green exercise may result in lower physical engagement.
C1 [Litleskare, Sigbjorn; Haile, Amelia; Calogiuri, Giovanna] Inland Norway Univ Appl Sci, Dept Publ Hlth & Sport Sci, Elverum, Norway.
   [Frohlich, Fred; Flaten, Ole Einar] Inland Norway Univ Appl Sci, Game Sch, Dept Game Dev, Hamar, Norway.
   [Johnsen, Svein Age Kjos] Inland Norway Univ Appl Sci, Dept Psychol, Lillehammer, Norway.
   [Calogiuri, Giovanna] Univ South Eastern Norway, Ctr Hlth & Technol, Dept Nursing & Hlth Sci, Drammen, Norway.
C3 Inland Norway University of Applied Sciences; Inland Norway University
   of Applied Sciences; Inland Norway University of Applied Sciences;
   University College of Southeast Norway
RP Litleskare, S (corresponding author), Inland Norway Univ Appl Sci, Dept Publ Hlth & Sport Sci, Elverum, Norway.
EM sigbjorn.litleskare@inn.no
RI Calogiuri, Giovanna/KEH-7493-2024
OI Calogiuri, Giovanna/0000-0003-1289-1026; Froehlich,
   Fred/0000-0002-4006-9497; Litleskare, Sigbjorn/0000-0001-8322-2837
FU University of South-Eastern Norway; Inland Norway University of Applied
   Sciences; Regional Research Fond-Innlandet, Norway [292761]; European
   Union [869764]
FX The research activity of the authors was primarily funded by their
   institutions, namely University of South-Eastern Norway and Inland
   Norway University of Applied Sciences. The study received funding from
   the Regional Research Fond -Innlandet, Norway (grant n. 292761). As part
   of the GoGreenRoutes project, G.C., O.E.F., F.F., and S.L. received
   funding by the European Union's Horizon 2020 research and innovation
   program under grant agreement No. 869764. Open Access funding provided
   by Inland Norway University Of Applied Sciences.
CR Akers A, 2012, ENVIRON SCI TECHNOL, V46, P8661, DOI 10.1021/es301685g
   Alkahtani S., 2019, Clinical Nutrition Experimental, V28, P92, DOI [10.1016/j.yclnex.2019.10.003, DOI 10.1016/J.YCLNEX.2019.10.003]
   BORG GAV, 1982, MED SCI SPORT EXER, V14, P377, DOI 10.1249/00005768-198205000-00012
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Browning MHEM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.02200
   Browning MHEM, 2021, ENVIRON BEHAV, V53, P687, DOI 10.1177/0013916520906481
   Calogiuri G., 2013, EIIC P EIIC 2 EL INT
   Calogiuri G, 2021, NATURE AND HEALTH, P127
   Calogiuri G, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02321
   Calogiuri G, 2016, INT J ENV RES PUB HE, V13, DOI 10.3390/ijerph13111165
   Calogiuri G, 2015, PERCEPT MOTOR SKILL, V121, P350, DOI 10.2466/06.PMS.121c17x0
   Calogiuri G, 2014, BMC PUBLIC HEALTH, V14, DOI 10.1186/1471-2458-14-873
   Chan SHM, 2023, VIRTUAL REAL-LONDON, V27, P3285, DOI 10.1007/s10055-021-00604-4
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   DISHMAN RK, 1985, PUBLIC HEALTH REP, V100, P158
   Duncan MJ, 2014, INT J ENV RES PUB HE, V11, P3678, DOI 10.3390/ijerph110403678
   Focht BC, 2009, RES Q EXERCISE SPORT, V80, P611
   Frost S, 2022, J ENVIRON PSYCHOL, V80, DOI 10.1016/j.jenvp.2022.101765
   Frumkin H, 2017, ENVIRON HEALTH PERSP, V125, DOI 10.1289/EHP1663
   GODIN G, 1985, Canadian Journal of Applied Sport Sciences, V10, P141
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Guna J, 2019, FUTURE GENER COMP SY, V91, P263, DOI 10.1016/j.future.2018.08.049
   HARTE JL, 1995, PSYCHOPHYSIOLOGY, V32, P49, DOI 10.1111/j.1469-8986.1995.tb03405.x
   Hartig T, 1997, SCAND HOUS PLAN RES, V14, P175, DOI 10.1080/02815739708730435
   Hartig T, 2003, J ENVIRON PSYCHOL, V23, P109, DOI 10.1016/S0272-4944(02)00109-3
   Joseph A, 2020, HERD-HEALTH ENV RES, V13, P11, DOI 10.1177/1937586720924787
   Kahn PH, 2008, J ENVIRON PSYCHOL, V28, P192, DOI 10.1016/j.jenvp.2007.10.008
   Kajosaari A, 2021, LANDSCAPE URBAN PLAN, V206, DOI 10.1016/j.landurbplan.2020.103978
   Kaplan R., 1989, EXPERIENCE NATURE PS
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Knaust T, 2022, VIRTUAL REAL-LONDON, V26, P925, DOI 10.1007/s10055-021-00595-2
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lacharité-Lemieux M, 2015, MENOPAUSE, V22, P731, DOI 10.1097/GME.0000000000000366
   Lahart I, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16081352
   Liszio S, 2018, ANN REV CYBERTHERAPY, V16, P87
   Litleskare S, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17051738
   Litleskare S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02436
   Lox C. L., 2000, Measurement in Physical Education and Exercise Science, V4, P79, DOI 10.1207/S15327841Mpee0402_4
   Mayer FS, 2009, ENVIRON BEHAV, V41, P607, DOI 10.1177/0013916508319745
   Meredith GR, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02942
   Mieras ME, 2014, J STRENGTH COND RES, V28, P2324, DOI 10.1519/JSC.0000000000000384
   Mostajeran F, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83277-y
   Nichols S, 2000, INT J HUM-COMPUT ST, V52, P471, DOI 10.1006/ijhc.1999.0343
   Nukarinen T, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382956
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Pretty J, 2005, INT J ENVIRON HEAL R, V15, P319, DOI 10.1080/09603120500155963
   Pretty J., 2003, GREEN EXERCISE COMPL
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Rogerson M., 2019, Physical activity in natural settings, P75, DOI [10.4324/9781315180144-4, DOI 10.4324/9781315180144-4]
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Shookster Daniel, 2020, Int J Exerc Sci, V13, P1242
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Smith JW, 2015, INT J ENV RES PUB HE, V12, P11486, DOI 10.3390/ijerph120911486
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Triberti S, 2014, CYBERPSYCH BEH SOC N, V17, P335, DOI 10.1089/cyber.2014.0054
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P672, DOI [10.1109/VR46266.2020.00-14, 10.1109/VR46266.2020.1581256520838]
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   White MP, 2016, PREV MED, V91, P383, DOI 10.1016/j.ypmed.2016.08.023
   White MP, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44097-3
   White MP, 2015, INT J ENV RES PUB HE, V12, P11929, DOI 10.3390/ijerph120911929
   White MP, 2018, NEUROPSYCH DIS TREAT, V14, P3001, DOI 10.2147/NDT.S179038
   Yeo NL, 2020, J ENVIRON PSYCHOL, V72, DOI 10.1016/j.jenvp.2020.101500
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Yin J, 2018, BUILD ENVIRON, V132, P255, DOI 10.1016/j.buildenv.2018.01.006
NR 72
TC 6
Z9 6
U1 4
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1777
EP 1793
DI 10.1007/s10055-022-00670-2
EA JUL 2022
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000824818600001
PM 35818369
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Lu, JJ
   Luo, TR
   Zhang, MM
   Shen, YZ
   Zhao, P
   Cai, N
   Yang, XZ
   Pan, ZG
   Stephens, M
AF Lu, Jijian
   Luo, Tianren
   Zhang, Mingmin
   Shen, Yuze
   Zhao, Peng
   Cai, Ning
   Yang, Xiaozhe
   Pan, Zhigeng
   Stephens, Max
TI Examining the impact of VR and MR on future teachers' creativity
   performance and influencing factors by scene expansion in instruction
   designs
SO VIRTUAL REALITY
LA English
DT Article
DE Instruction design; Creativity; Virtual reality (VR); Mixed reality
   (MR); Creativity support systems; Attention; Relaxation; Flow
ID AUGMENTED REALITY; LEARNING-PERFORMANCE; EXPERIENCE; SUPPORT;
   PERSONALITY; PSYCHOLOGY; THINKING; SCALE; EEG
AB Unlike the traditional environment, VR and MR environments provide novel, natural, lifelike 3D user interfaces, which can stimulate the imagination of users. Whether VR and MR environments can influence the creativity and its impact factors (flow, attention, and relaxation) of future teachers' scene expansion in instruction design are the focus of the study. Moreover, the differences between the impacts of VR and MR environments on creativity and its impact factors are also questions worth exploring. In this study, we developed VR and MR experiment environments as creativity support systems to stimulate future teachers' creativity before they carry out the instruction design of experimental courses. The results show that the creativity, flow, and attention of future teachers which use the VR and MR environments were higher than in the traditional environment. Moreover, the future teachers' creativity of scene expansion in MR environment was higher than VR environment, the future teachers' attention of VR environment was higher than MR environment, and the future teachers.' relaxation of VR environment was lower than the traditional environment. These findings provide a useful inspiration, i.e. too high concentration or too high relaxation is not conducive to the production of creativity. The MR creativity support system that provides moderate and balanced attention and relaxation can good stimulate the creativity of future teachers in the instruction design. We expect these findings to inspire the design of creativity support systems and foster future teachers' creativity level in instructional design.
C1 [Lu, Jijian; Zhao, Peng] Hangzhou Normal Univ, Jing Hengyi Sch Educ, 2318 Yuhangtang Rd, Hangzhou, Peoples R China.
   [Luo, Tianren] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, 4 South Fourth St, Beijing, Peoples R China.
   [Luo, Tianren] Chinese Acad Sci, Inst Software, Beijing Key Lab Human Comp Interact, 4 South Fourth St, Beijing, Peoples R China.
   [Luo, Tianren] Univ Chinese Acad Sci, Coll Comp Sci & Technol, 19 Yuquan Rd, Beijing, Peoples R China.
   [Zhang, Mingmin] Zhejiang Univ, Coll Comp Sci & Technol, 866 Yuhangtang Rd, Hangzhou, Peoples R China.
   [Shen, Yuze; Cai, Ning] Hangzhou Normal Univ, Inst Virtual Real & Intelligent Syst, 2318 Yuhangtang Rd, Hangzhou, Peoples R China.
   [Yang, Xiaozhe] East China Normal Univ, Inst Curriculum & Instruct, 3663 Zhongshan North Rd, Shanghai, Peoples R China.
   [Pan, Zhigeng] Nanjing Univ Informat Sci & Technol, Coll Artificial Intelligence, 219 Ningliu Rd, Nanjing, Peoples R China.
   [Stephens, Max] Univ Melbourne, Melbourne Grad Sch Educ, Melbourne, Vic 3010, Australia.
C3 Hangzhou Normal University; Chinese Academy of Sciences; Institute of
   Software, CAS; Chinese Academy of Sciences; Institute of Software, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Zhejiang University; Hangzhou Normal University; East China Normal
   University; Nanjing University of Information Science & Technology;
   University of Melbourne
RP Zhang, MM (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, 866 Yuhangtang Rd, Hangzhou, Peoples R China.; Pan, ZG (corresponding author), Nanjing Univ Informat Sci & Technol, Coll Artificial Intelligence, 219 Ningliu Rd, Nanjing, Peoples R China.
EM zhangmm95@zju.edu.cn; 1026559065@qq.com; 626980463@qq.com;
   443922077@qq.com; m.Stephens@unimelb.edu.au
RI zhang, mm/IWV-4201-2023; Lu, Jijian/HMD-2487-2023; Luo,
   Tianren/CAI-9775-2022; Zhang, Miao/JXY-8985-2024; Lu,
   Jijian/GYV-0784-2022
OI Luo, Tianren/0000-0002-6752-9182; Lu, Jijian/0000-0003-0208-9486
FU National Key RD Plan of China [2018YFB1004903]; NSFC [62077041]; VR
   experiment teaching project in Zhejiang Province [2019(5)-264]; Ministry
   of Education Industry-University Cooperation Project [202101031035];
   University Student Science and Technology Innovation Activity Plan in
   Zhejiang Province (Xinmiao Talent Plan) of China [2020R427068]; Hangzhou
   Normal University
FX This research was conducted with the National Key R&D Plan of China
   (2018YFB1004903), NSFC project (62077041), VR experiment teaching
   project in Zhejiang Province (2019(5)-264), Ministry of Education
   Industry-University Cooperation Project (No. 202101031035), the diligent
   research project of Hangzhou Normal University and University Student
   Science and Technology Innovation Activity Plan in Zhejiang Province
   (Xinmiao Talent Plan, Grant No. 2020R427068) of China.
CR Amabile TM, 2012, J CREATIVE BEHAV, V46, P3, DOI 10.1002/jocb.001
   Baer M, 2006, J APPL PSYCHOL, V91, P963, DOI 10.1037/0021-9010.91.4.963
   Bakeman R., 1997, Observing interaction. An introduction to sequential analysis, DOI [DOI 10.1017/CBO9780511527685, 10.1017/cbo9780511527685]
   Beghetto RA, 2007, HIGH ABIL STUD, V18, P59, DOI 10.1080/13598130701350668
   Billinghurst M, 2012, COMPUTER, V45, P56, DOI 10.1109/MC.2012.111
   Bimber O, 2004, ISMAR, V306
   Bueno E, 2014, INT J ARCHIT COMPUT, V12, P495, DOI 10.1260/1478-0771.12.4.495
   Chaudhuri S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866205
   Cropley A.J., 2008, Cambridge Journal of Education, V38, P355, DOI DOI 10.1080/03057640802286871
   Cropley A, 2006, CREATIVITY RES J, V18, P391, DOI 10.1207/s15326934crj1803_13
   Cropley D., 2008, PSYCHOL AESTHET CREA, V2, P155, DOI [DOI 10.1037/1931-3896.2.3.155, 10.1037/1931-3896.2.3.155, 10.1037=1931-3896.2.3.155]
   Crowley Katie, 2010, 2010 IEEE 10th International Conference on Advanced Learning Technologies (ICALT 2010), P276, DOI 10.1109/ICALT.2010.81
   Csikszentmihalyi, 1997, FLOW PSYCHOL DISCOVE, P29
   Cybulski JL, 2015, COMPUT HUM BEHAV, V42, P20, DOI 10.1016/j.chb.2013.10.061
   Dalgarno B, 2009, COMPUT EDUC, V53, P853, DOI 10.1016/j.compedu.2009.05.005
   Di Serio A, 2013, COMPUT EDUC, V68, P586, DOI 10.1016/j.compedu.2012.03.002
   Dietrich A, 2010, PSYCHOL BULL, V136, P822, DOI 10.1037/a0019749
   Ding XQ, 2014, BEHAV BRAIN FUNCT, V10, DOI 10.1186/1744-9081-10-9
   Ding XQ, 2015, LEARN INDIVID DIFFER, V37, P217, DOI 10.1016/j.lindif.2014.11.019
   Doll WJ, 2013, INNOVATIVE STRATEGIES AND APPROACHES FOR END-USER COMPUTING ADVANCEMENTS, P242, DOI 10.4018/978-1-4666-2059-9.ch013
   Eaglestone B, 2007, J DOC, V63, P443, DOI 10.1108/00220410710758968
   El Sayed NAM, 2011, COMPUT EDUC, V56, P1045, DOI 10.1016/j.compedu.2010.10.019
   Fink A, 2014, NEUROSCI BIOBEHAV R, V44, P111, DOI 10.1016/j.neubiorev.2012.12.002
   Forgionne G, 2007, DECIS SUPPORT SYST, V42, P2126, DOI 10.1016/j.dss.2006.05.009
   Furnham A, 2008, PERS INDIV DIFFER, V45, P613, DOI 10.1016/j.paid.2008.06.023
   Gabora L, 2010, CREATIVITY RES J, V22, P1, DOI 10.1080/10400410903579494
   Gilhooly KJ, 2007, BRIT J PSYCHOL, V98, P611, DOI 10.1111/j.2044-8295.2007.tb00467.x
   Gruzelier J, 2010, NEUROSCI LETT, V480, P112, DOI 10.1016/j.neulet.2010.06.019
   Haller CS, 2011, CREATIVITY RES J, V23, P99, DOI 10.1080/10400419.2011.571182
   Hung YH, 2017, J COMPUT ASSIST LEAR, V33, P252, DOI 10.1111/jcal.12173
   Ie A, 2012, COMPUT HUM BEHAV, V28, P1526, DOI 10.1016/j.chb.2012.03.022
   Indurkhya B., 2015, COMPUTATIONAL CREATI, V5, P58
   Iordache DD, 2012, STUD INFORM CONTROL, V21, P233
   Jackson SA, 1996, J SPORT EXERCISE PSY, V18, P17, DOI 10.1123/jsep.18.1.17
   Jahnke I, 2020, COMPUT EDUC, V146, DOI 10.1016/j.compedu.2019.103782
   Jimenez C. O. S., 2011, 2011 IEEE International Games Innovation Conference (IGIC 2011), P31, DOI 10.1109/IGIC.2011.6115125
   Jou M, 2013, COMPUT HUM BEHAV, V29, P433, DOI 10.1016/j.chb.2012.04.020
   Kaufman JC, 2012, PSYCHOL AESTHET CREA, V6, P298, DOI 10.1037/a0029751
   Kendall M., 1990, Correlation methods
   Kim KH, 2006, CREATIVITY RES J, V18, P3, DOI 10.1207/s15326934crj1801_2
   Kuo YC, 2017, COMPUT HUM BEHAV, V75, P218, DOI 10.1016/j.chb.2017.05.017
   Lai C-H., 2017, LECT NOTES COMPUT SC, V10, P176, DOI [10.1007/978-3-319-52836-6_20, DOI 10.1007/978-3-319-52836-6_20]
   Lin HC., 2020, THINK SKILLS CREAT, V7, P100
   Lin TY., 2017, EURASIA J MATH SCI T, V6, P13
   Lu JJ, 2023, INTERACT LEARN ENVIR, V31, P270, DOI 10.1080/10494820.2020.1777167
   Lu JJ, 2019, INTERACT LEARN ENVIR, V27, P645, DOI 10.1080/10494820.2019.1610452
   Luo A, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/2/026010
   Luo TR, 2020, IEEE T VIS COMPUT GR, V26, P3524, DOI 10.1109/TVCG.2020.3023602
   Luo TR, 2018, I C VIRTUAL REALITY, P116, DOI 10.1109/ICVRV.2018.00033
   Maki Y., 2012, Proceedings of the 2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel & Distributed Computing (SNPD 2012), P325, DOI 10.1109/SNPD.2012.45
   McFarland DJ, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1941487.1941506
   Nusbaum EC, 2011, PERS INDIV DIFFER, V51, P571, DOI 10.1016/j.paid.2011.05.013
   Pan ZG, 2022, VIRTUAL REAL-LONDON, V26, P279, DOI 10.1007/s10055-021-00560-z
   Pellas N, 2019, VIRTUAL REAL-LONDON, V23, P329, DOI 10.1007/s10055-018-0347-2
   Pinheiro IR, 2014, CREATIVITY RES J, V26, P263, DOI 10.1080/10400419.2014.929404
   Pittman C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1126, DOI [10.1109/VR.2019.8797908, 10.1109/vr.2019.8797908]
   Prabhakaran R, 2014, BEHAV RES METHODS, V46, P641, DOI 10.3758/s13428-013-0401-7
   Rebolledo-Mendez G, 2009, INT C HUMAN COMPUTER
   Sanei S, 2013, EEG Signal Processing
   Seligman MEP, 2000, AM PSYCHOL, V55, P5, DOI 10.1037/0003-066X.55.1.5
   Shneiderman B., 2002, Information Visualization, V1, P5, DOI 10.1057/palgrave/ivs/9500006
   Smith SM, 1995, CREATIVE COGNITION A
   Stolaki A, 2018, COMPUT EDUC, V123, P195, DOI 10.1016/j.compedu.2018.05.009
   Stull AT, 2013, COMPUT HUM BEHAV, V29, P2546, DOI 10.1016/j.chb.2013.06.012
   Su CH, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11041027
   Sun JCY, 2014, COMPUT EDUC, V72, P80, DOI 10.1016/j.compedu.2013.10.010
   Van Kerrebroeck H, 2017, COMPUT HUM BEHAV, V77, P437, DOI 10.1016/j.chb.2017.07.019
   Veale T, 2013, APPL COGN LINGUIST, V21, P1, DOI 10.1515/9783110295290
   Villanueva A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376146
   Voigt M, 2013, 225234 IEEE
   Voigt M, 2012, DESIGN SCI RES INFOR
   Wang CC, 2014, INFORM MANAGE-AMSTER, V51, P912, DOI 10.1016/j.im.2014.05.010
   Wang Q, 2013, IEEE T NEUR SYS REH, V21, P225, DOI 10.1109/TNSRE.2012.2236576
   Wei XD, 2015, COMPUT EDUC, V81, P221, DOI 10.1016/j.compedu.2014.10.017
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yang XZ, 2018, ETR&D-EDUC TECH RES, V66, P1231, DOI 10.1007/s11423-018-9604-z
   Yeh YC, 2019, COMPUT EDUC, V132, P63, DOI 10.1016/j.compedu.2019.01.001
   Zabelina DL, 2010, PSYCHOL AESTHET CREA, V4, P136, DOI 10.1037/a0017379
NR 78
TC 2
Z9 2
U1 16
U2 68
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1615
EP 1636
DI 10.1007/s10055-022-00652-4
EA MAY 2022
PG 22
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000805461600001
DA 2024-07-18
ER

PT J
AU Montagud, M
   Li, J
   Cernigliaro, G
   El Ali, A
   Fernández, S
   Cesar, P
AF Montagud, Mario
   Li, Jie
   Cernigliaro, Gianluca
   El Ali, Abdallah
   Fernandez, Sergi
   Cesar, Pablo
TI Towards socialVR: evaluating a novel technology for watching videos
   together
SO VIRTUAL REALITY
LA English
DT Article
DE Evaluation Protocol; Presence; Togetherness; Social VR; Virtual Reality;
   Volumetric Media
ID VIRTUAL-REALITY; COMPRESSION; EXPERIENCE; IMMERSION
AB Social VR enables people to interact over distance with others in real-time. It allows remote people, typically represented as avatars, to communicate and perform activities together in a shared virtual environment, extending the capabilities of traditional social platforms like Facebook and Netflix. This paper explores the benefits and drawbacks provided by a lightweight and low-cost Social VR platform (SocialVR), in which users are captured by several cameras and reconstructed in real-time. In particular, the paper contributes with (1) the design and evaluation of an experimental protocol for Social VR experiences; (2) the report of a production workflow for this new type of media experiences; and (3) the results of experiments with both end-users (N = 15 pairs) and professionals (N = 22 companies) to evaluate the potential of the SocialVR platform. Results from the questionnaires and semi-structured interviews show that end-users rated positively towards the experiences provided by the SocialVR platform, which enabled them to sense emotions and communicate effortlessly. End-users perceived the photo-realistic experience of SocialVR similar to face-to-face scenarios and appreciated this new creative medium. From a commercial perspective, professionals confirmed the potential of this communication medium and encourage further research for the adoption of the platform in the commercial landscape.
C1 [Montagud, Mario; Cernigliaro, Gianluca; Fernandez, Sergi] I2CAT Fdn, Barcelona, Spain.
   [Montagud, Mario] Univ Valencia UV, Valencia, Spain.
   [Li, Jie; El Ali, Abdallah; Cesar, Pablo] Ctr Wiskunde Informat CWI, Amsterdam, Netherlands.
   [Cesar, Pablo] Delft Univ Technol, Delft, Netherlands.
C3 Internet I Innovacio Digital A Catalunya (I2CAT); University of
   Valencia; Delft University of Technology
RP Montagud, M (corresponding author), I2CAT Fdn, Barcelona, Spain.; Montagud, M (corresponding author), Univ Valencia UV, Valencia, Spain.
EM mario.montagud@i2cat.net; Jie.Li@cwi.nl; gianluca.cernigliaro@i2cat.net;
   Abdallah.El.Ali@cwi.nl; sergi.fernandez@i2cat.net; P.S.Cesar@cwi.nl
FU European Union [762111]; ACCIO (Generalitat de Catalunya)
   [COMRDI18-1-0008]; Spanish Ministry of Science, Innovation and
   Universities with a Juan de la Cierva-Incorporacion grant
   [IJCI-2017-34611]
FX This work has been funded by European Union's Horizon 2020 program,
   under agreement n degrees 762111 (VRTogether) and by ACCIO (Generalitat
   de Catalunya) under agreement COMRDI18-1-0008 (ViVIM project). Work by
   Mario Montagud has been additionally funded by the Spanish Ministry of
   Science, Innovation and Universities with a Juan de la
   Cierva-Incorporacion grant, with reference IJCI-2017-34611.
CR Alexiadis DS, 2017, IEEE T CIRC SYST VID, V27, P798, DOI 10.1109/TCSVT.2016.2576922
   [Anonymous], Rabbitmq
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Boronat F, 2018, IEEE T BROADCAST, V64, P52, DOI 10.1109/TBC.2017.2737819
   Cavallo M, 2019, 2019 IEEE C VIRTUAL
   Cesar P., 2011, 2011 IEEE Consumer Communications and Networking Conference (CCNC 2011), P347, DOI 10.1109/CCNC.2011.5766487
   Cesar P., 2011, P NETW EL MED SUMM N, P27
   Chiariglione, MOVING PICTURE EXPER
   Christaki K, 2019, LECT NOTES COMPUT SC, V11295, P80, DOI 10.1007/978-3-030-05710-7_7
   Christoforou C, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00072
   Churchill E. F., 1998, Virtual Reality, V3, P3, DOI 10.1007/BF01409793
   Churchill Elizabeth F, 2012, Collaborative virtual environments: digital places and spaces for interaction
   Cui L, 2019, IEEE CONSUM ELECTR M, V8, P17, DOI 10.1109/MCE.2019.2905483
   de Belen RA, 2019, SYSTEMATIC REV CURRE
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Fairchild AJ, 2017, IEEE T CIRC SYST VID, V27, P814, DOI 10.1109/TCSVT.2016.2580425
   Debarba HG, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-12176-9
   Garau, 2003, P SIGCHI C HUM FACT
   Geerts D, 2011, P SIGCHI C HUMAN FAC
   Geerts D., 2008, P UXTV 2008, P71, DOI DOI 10.1145/1453805.1453822
   Gunkel S, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P233, DOI 10.1145/3210825.3213566
   Gunkel SNB, 2017, ADJ PUBL 2017 ACM IN, P8384
   Heidicker P, 2017, 2017 IEEE S 3D USER
   Herrewijn L, 2015, COMPUT HUM BEHAV, V53, P544, DOI 10.1016/j.chb.2014.06.012
   Huang EM, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P585
   Jansen Jack, 2020, P 11 ACM MULT SYST C
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Lachat E, 2015, INT ARCH PHOTOGRAMM, V40-5, P93, DOI 10.5194/isprsarchives-XL-5-W4-93-2015
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   Le DA, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P485, DOI [10.1109/VRW50115.2020.0-175, 10.1109/VRW50115.2020.00101]
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Levoy, 1985, CITESEER
   Li J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300897
   Li WW, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P524, DOI 10.1109/SITIS.2014.106
   Maglo A, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2693443
   Mamou K, 2008, 15 IEEE INT C IMAGE
   MANTOVANI G, 1995, HUM RELAT, V48, P669, DOI 10.1177/001872679504800604
   Marfil D, 2019, IEEE T BROADCAST, V65, P645, DOI 10.1109/TBC.2018.2878285
   McGill M, 2016, ACM T COMPUT-HUM INT, V23, DOI 10.1145/2983530
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Orts-Escolano S, 2016, P 29 ANN S USER INTE
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   Roth D, 2016, 2016 IEEE VIRTUAL RE
   Rothe S, 2018, INT C INT DIG STOR
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981
   Sherman WilliamR., 2003, UNDERSTANDING VIRTUA
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Thomas DR, 2006, AM J EVAL, V27, P237, DOI 10.1177/1098214005283748
   Ursu, 2013, P 21 ACM INT C MULT
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Waters RC, 1997, PRESENCE-TELEOP VIRT, V6, P461, DOI 10.1162/pres.1997.6.4.461
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 59
TC 9
Z9 9
U1 1
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1593
EP 1613
DI 10.1007/s10055-022-00651-5
EA MAY 2022
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000792079100001
PM 35572185
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kim, WH
   Cho, SE
   Hong, JP
   Kim, H
   Maeng, S
   Kang, JM
   Na, KS
   Oh, SH
   Park, JW
   Bae, JN
   Cho, SJ
AF Kim, Won-Hyoung
   Cho, Seo-Eun
   Hong, Jin Pyo
   Kim, Hyeyoung
   Maeng, Seri
   Kang, Jae Myeong
   Na, Kyoung-Sae
   Oh, Seok-Hee
   Park, Jung Woon
   Bae, Jae Nam
   Cho, Seong-Jin
TI Effectiveness of virtual reality exposure treatment for posttraumatic
   stress disorder due to motor vehicle or industrial accidents
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; PTSD; Exposure; Motor vehicle accident; Industrial
   accident
ID COGNITIVE-PROCESSING THERAPY; PROLONGED EXPOSURE; ANXIETY; ENVIRONMENTS
AB Virtual reality exposure treatment (VRET) for post-traumatic stress disorder (PTSD) is an emerging treatment. The purpose of this study was to examine the effectiveness and safety of VRET in patients with PTSD due to motor vehicle or industrial accidents. Twenty-six patients with PTSD (19 motor vehicle accidents and 7 industrial accidents) and eighteen subjects without PTSD were enrolled in five VRET sessions that were conducted using a head-mounted display. The VRET was based on systematic desensitization and included psychoeducation and training for breathing and relaxation techniques. The effectiveness of VRET was evaluated using the Posttraumatic Stress Disorder Checklist-Civilian version (PCL-C), Impact of Event Scale-Revised (IES-R), Clinical Global Impression-Severity scale (CGI-S), and Sheehan Disability Scale (SDS). Safety was assessed using the Simulator Sickness Questionnaire and Presence Questionnaire. After controlling for age, sex, marital status, job, economic status, and body mass index, we found that the CGI-S (F = 12.76, p = 0.001), PCL-C (F = 11.87, p = 0.002), IES-R (total score; F-8.31, p = 0.007), and SDS-A (F = 7.53, p = 0.010) scores in the VRET group were lower than those in the control group. Responses to the Simulator Sickness and Presence questionnaires did not differ significantly between the VRET and control groups (p > 0.05). In conclusion, for patients with PTSD due to motor vehicle accidents, VRET is a safe and potentially effective treatment method. Future randomized controlled studies are needed to provide stronger evidence for the effectiveness of VRET in patients with PTSD.
C1 [Kim, Won-Hyoung; Kim, Hyeyoung; Maeng, Seri; Bae, Jae Nam] Inha Univ Hosp, Dept Psychiat, Incheon, South Korea.
   [Cho, Seo-Eun; Kang, Jae Myeong; Na, Kyoung-Sae; Cho, Seong-Jin] Gachon Univ, Dept Psychiat, Gil Med Ctr, Incheon, South Korea.
   [Hong, Jin Pyo] Sungkyunkwan Univ, Dept Psychiat, Samsung Med Ctr, Sch Med, Seoul, South Korea.
   [Oh, Seok-Hee] Gachon Univ, Dept Comp Engn, Seongnam, South Korea.
   [Park, Jung Woon] Gachon Univ, Dept IT Convergence Engn, Grad Sch, Seongnam, South Korea.
C3 Inha University; Inha University Hospital; Gachon University;
   Sungkyunkwan University (SKKU); Samsung Medical Center; Gachon
   University; Gachon University
RP Bae, JN (corresponding author), Inha Univ Hosp, Dept Psychiat, Incheon, South Korea.; Cho, SJ (corresponding author), Gachon Univ, Dept Psychiat, Gil Med Ctr, Incheon, South Korea.
EM arztin01@hanmail.net; jnbae@inha.ac.kr; sjcho@gilhospital.com
RI OH, SEOKHEE/ITX-1602-2023; 김, 원형/HLP-6085-2023
OI OH, SEOKHEE/0000-0001-7122-0463; 김, 원형/0000-0002-6650-3685; Cho,
   Seo-Eun/0000-0002-3991-2192; Bae, Jae Nam/0000-0002-5024-6231; Na,
   Kyoung-Sae/0000-0002-0148-9827; Maeng, Seri/0000-0001-6850-5548; Park,
   Jung woon/0000-0001-6271-4904; Kim, Hyeyoung/0000-0002-2313-8892
FU Institute of Information & Communications Technology Planning &
   Evaluation (IITP) - Korean government (MSIT) [2017-0-00180]; Ministry of
   Science and ICT (MSIT), Korea, under an Information Technology Research
   Center (ITRC) support program [IITP-2020-2017-0-01630]; INHA University
   Research Grant
FX This work was supported by an Institute of Information & Communications
   Technology Planning & Evaluation (IITP) grant funded by the Korean
   government (MSIT) (No. 2017-0-00180, development of complex bio-signal
   response information-based intelligent virtual reality (VR) life care
   technology) and the Ministry of Science and ICT (MSIT), Korea, under an
   Information Technology Research Center (ITRC) support program
   (IITP-2020-2017-0-01630) supervised by the Institute for Information &
   Communications Technology Promotion (IITP). This work was supported by
   an INHA University Research Grant.
CR [Anonymous], 1999, J Clin Psychiatry, V60 Suppl 16, P3
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Barton KA, 1996, BEHAV RES THER, V34, P805, DOI 10.1016/0005-7967(96)00027-7
   Beck JG, 2007, BEHAV THER, V38, P39, DOI 10.1016/j.beth.2006.04.001
   Benbow AA, 2019, J ANXIETY DISORD, V61, P18, DOI 10.1016/j.janxdis.2018.06.006
   Bisson JI, 2007, BRIT J PSYCHIAT, V190, P97, DOI 10.1192/bjp.bp.106.021402
   BLANCHARD EB, 1994, BEHAV RES THER, V32, P283, DOI 10.1016/0005-7967(94)90123-6
   Canadian Agency for Drugs and Technologies in Health, 2014, VIRT REAL EXP THER A
   Cottraux J, 2008, PSYCHOTHER PSYCHOSOM, V77, P101, DOI 10.1159/000112887
   Cukor J, 2009, CLIN PSYCHOL REV, V29, P715, DOI 10.1016/j.cpr.2009.09.001
   Deng WR, 2019, J AFFECT DISORDERS, V257, P698, DOI 10.1016/j.jad.2019.07.086
   Evans S, 2009, J CLIN PSYCHOL, V65, P684, DOI 10.1002/jclp.20575
   Foa E.B., 1998, Treating the trauma of rape: Cognitive-behavioral therapy for PTSD
   Foa EB, 2018, JAMA-J AM MED ASSOC, V319, P354, DOI 10.1001/jama.2017.21242
   Foo EB, 2003, PSYCHIAT ANN, V33, P47
   Gerardi M, 2008, J TRAUMA STRESS, V21, P209, DOI 10.1002/jts.20331
   Gerardi M, 2010, CURR PSYCHIAT REP, V12, P298, DOI 10.1007/s11920-010-0128-4
   Gonçalves R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048469
   Guy W, 2000, TASK FORC HDB PSYCH
   Jang DP, 2000, CYBERPSYCHOL BEHAV, V3, P369, DOI 10.1089/10949310050078814
   Jorge Ricardo E, 2015, Continuum (Minneap Minn), V21, P789, DOI 10.1212/01.CON.0000466667.20403.b1
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim D, 2008, J EMDR PRACT RES, V2, P57, DOI 10.1891/1933-3196.2.1.57
   Kothgassner OD, 2019, EUR J PSYCHOTRAUMATO, V10, DOI 10.1080/20008198.2019.1654782
   KUCH K, 1985, CAN J PSYCHIAT, V30, P426, DOI 10.1177/070674378503000610
   Lombard M., 2009, P 12 ANN INT WORKSH, P1
   McDonagh A, 2005, J CONSULT CLIN PSYCH, V73, P515, DOI 10.1037/0022-006X.73.3.515
   McDonald SD, 2010, CLIN PSYCHOL REV, V30, P976, DOI 10.1016/j.cpr.2010.06.012
   McFarlane AC, 2007, OCCUP MED-OXFORD, V57, P404, DOI 10.1093/occmed/kqm070
   Min BC, 2004, APPL ERGON, V35, P549, DOI 10.1016/j.apergo.2004.06.002
   Monson CM, 2006, J CONSULT CLIN PSYCH, V74, P898, DOI 10.1037/0022-006X.74.5.898
   Nishith P, 2002, J CONSULT CLIN PSYCH, V70, P880, DOI 10.1037/0022-006X.70.4.880
   NORRIS FH, 1992, J CONSULT CLIN PSYCH, V60, P409, DOI 10.1037/0022-006X.60.3.409
   Powers MB, 2010, CLIN PSYCHOL REV, V30, P635, DOI 10.1016/j.cpr.2010.04.007
   Robillard G, 2003, CYBERPSYCHOL BEHAV, V6, P467, DOI 10.1089/109493103769710497
   Rothbaum BO, 2009, DEPRESS ANXIETY, V26, P209, DOI 10.1002/da.20556
   Sheehan D.V., 1983, ANXIETY DIS
   Walshe DG, 2003, CYBERPSYCHOL BEHAV, V6, P329, DOI 10.1089/109493103322011641
   Weathers F., 1993, INT SOC TRAUM STRESS
   Weiss D, 2007, Assessing psychological trauma and PTSD, P219, DOI DOI 10.1007/978-0-387-70990-1_10
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolpe J., 1969, PRACTICE BEHAV THERA
   은헌정, 2005, [JOURNAL OF THE KOREAN NEUROPSYCHIATRIC ASSOCIATION, 신경정신의학], V44, P303
NR 43
TC 0
Z9 0
U1 2
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1539
EP 1549
DI 10.1007/s10055-022-00623-9
EA APR 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000785590700001
DA 2024-07-18
ER

PT J
AU Caldas, OI
   Sanchez, N
   Mauledoux, M
   Avilés, OF
   Rodriguez-Guerrero, C
AF Caldas, Oscar, I
   Sanchez, Natalia
   Mauledoux, Mauricio
   Aviles, Oscar F.
   Rodriguez-Guerrero, Carlos
TI Leading presence-based strategies to manipulate user experience in
   virtual reality environments
SO VIRTUAL REALITY
LA English
DT Article
DE Coherence; Immersion; Motivation; Presence; User experience; Virtual
   reality
ID REHABILITATION; IMMERSION; COHERENCE; HAND; GAME
AB Virtual reality (VR) has been widely used to simulate various real-like environments suitable to explore and interact, similar to being genuinely there (i.e., allowing presence). User experience in virtual environments (VE) is highly subjective, and presence-based self-reports have addressed its assessment; however, it is unclear how a diverse set of VR features relates to the subscales of the questionnaires (e.g., engagement, immersion, or Attention), which could be helpful to create and improve immersive VE. Consequently, most current studies have appealed to self-defined criteria to design their VE in response to a lack of accepted methodological frameworks. Therefore, we systematically reviewed the current publications to identify critical design elements to promote presence and realistic experiences in VR-games users. We extracted information from different databases (Scopus, Web of Science, PubMed, ACM, IEEE, Springer, and Scholar) and used inclusion and exclusion criteria to reduce the original set of 595 candidates to 53 final papers. The findings showed that better quality and quantity in resources allocation (software and hardware) and more accuracy in objects and characters, which all refer to higher immersion, provide Place Illusion (PI), i.e., the spatial dimension of presence. Furthermore, Scenario's Realism, external stimuli, and coherent match between virtual and real worlds (including body representation) are decisive to set Plausibility Illusion (PSI), i.e., the dimension associated with coherence. Finally, performance feedback, character customization, and multiplayer mechanics are crucial to assure motivation and agency, which are user-exclusive but crucial to defining presence's perception. Moreover, about 65% of the analyzed studies agreed that immersive media and social interaction could simultaneously influence PI and PSI.
C1 [Caldas, Oscar, I; Sanchez, Natalia; Mauledoux, Mauricio; Aviles, Oscar F.] Univ Mil Nueva Granada, Fac Engn, Davinci Res Grp, Bogota, Colombia.
   [Caldas, Oscar, I; Rodriguez-Guerrero, Carlos] Vrije Univ Brussel & Flanders Make, Dept Mech Engn, Robot & Multibody Mech Res Grp, Brussels, Belgium.
C3 Universidad Militar Nueva Granada
RP Caldas, OI (corresponding author), Univ Mil Nueva Granada, Fac Engn, Davinci Res Grp, Bogota, Colombia.; Caldas, OI (corresponding author), Vrije Univ Brussel & Flanders Make, Dept Mech Engn, Robot & Multibody Mech Res Grp, Brussels, Belgium.
EM oscar.caldas@unimilitar.edu.co
RI Caldas, Oscar I./KPA-9561-2024; Avilés Sánchez, Oscar
   Fernando/G-6143-2011
OI Caldas, Oscar I./0000-0002-3105-4656; Avilés Sánchez, Oscar
   Fernando/0000-0001-8676-9926; Mauledoux, Mauricio/0000-0002-9964-947X;
   Rodriguez-Guerrero, Carlos/0000-0002-0297-9748; Sanchez Sanchez,
   Natalia/0000-0002-8875-9120
FU Vicerrectoria de Investigaciones in Universidad Militar Nueva Granada
   (UMNG) [ING-IMP-3124]; UMNG; VUB
FX This work was financially supported by Vicerrectoria de Investigaciones
   in Universidad Militar Nueva Granada (UMNG) under Grant ING-IMP-3124
   (2020-2021). Oscar I. Caldas received research support from both UMNG
   and VUB as a part of a Joint PhD Agreement.
CR Alexander A.L., 2005, DARWARS Training Impact Group, V5, P1, DOI [DOI 10.1016/J.ATHORACSUR.2004.02.012, DOI 10.5171/2012.800962]
   Baranes AF, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00317
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Biocca F., 2001, 4 ANN INT WORKSH PRE, P1
   Birk MV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2982, DOI 10.1145/2858036.2858062
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Çakiroglu Ü, 2019, J EDUC COMPUT RES, V57, P1723, DOI 10.1177/0735633119854030
   Caldas OI, 2020, IEEE T NEUR SYS REH, V28, P1109, DOI 10.1109/TNSRE.2020.2985308
   Chiao HM, 2018, J HOSP LEIS SPORT TO, V23, P29, DOI 10.1016/j.jhlste.2018.05.002
   Chittaro L, 2015, COMPUT HUM BEHAV, V50, P508, DOI 10.1016/j.chb.2015.03.074
   Choudhary Z, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P425, DOI [10.1109/VR46266.2020.00-41, 10.1109/VR46266.2020.1581089101511]
   Collins J, 2017, PRESENCE-TELEOP VIRT, V26, P16, DOI 10.1162/PRES_a_00284
   Csikszentmihalyi M., 1998, Finding flow: The psychology of engagement with everyday life
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Cuthbert R, 2020, PROCEEDINGS OF THE 31ST AUSTRALIAN CONFERENCE ON HUMAN-COMPUTER-INTERACTION (OZCHI'19), P221, DOI 10.1145/3369457.3369475
   Dawson P., 2013, SCI RES, V04, P20, DOI 10.4236/blr.2013.41003
   De Leo G, 2014, SIMUL HEALTHC, V9, P1, DOI 10.1097/SIH.0b013e3182a99dd9
   Deci E.L., 2004, RICHERCHE PSICHOLOGI, V27, P17, DOI DOI 10.1016/S0065-2601(08)60130-6
   Eckstein B, 2019, ENTERTAIN COMPUT, V31, DOI 10.1016/j.entcom.2019.100306
   Ferdani D, 2020, J CULT HERIT, V43, P129, DOI 10.1016/j.culher.2019.12.004
   Fox J, 2020, TELEMAT INFORM, V46, DOI 10.1016/j.tele.2019.101320
   Fröhner J, 2019, IEEE T HAPTICS, V12, P339, DOI 10.1109/TOH.2018.2889497
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   Gilbert SB, 2016, PRESENCE-TELEOP VIRT, V25, P322, DOI 10.1162/PRES_a_00276
   Gilpin HR, 2015, RHEUMATOLOGY, V54, P678, DOI 10.1093/rheumatology/keu367
   Vargas JCG, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030897
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Gorsic M, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0231-4
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01743
   Henderson A, 2007, TOP STROKE REHABIL, V14, P52, DOI 10.1310/tsr1402-52
   Hofer M., 2020, FRONT VIRTUAL REAL, V1, P2, DOI [10.3389/frvir.2020.00002, DOI 10.3389/FRVIR.2020.00002]
   Hooi R, 2017, TELEMAT INFORM, V34, P1454, DOI 10.1016/j.tele.2017.06.009
   Kim K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P529, DOI [10.1109/VR46266.2020.00-30, 10.1109/VR46266.2020.1581084624004]
   Kim K, 2019, COMPUT GRAPH-UK, V83, P23, DOI 10.1016/j.cag.2019.06.006
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Knaepen K, 2015, HUM MOVEMENT SCI, V40, P248, DOI 10.1016/j.humov.2015.01.001
   Li CY, 2020, J RETAIL CONSUM SERV, V54, DOI 10.1016/j.jretconser.2019.102018
   Ma ZX, 2020, MEDIA PSYCHOL, V23, P865, DOI 10.1080/15213269.2019.1651655
   Madier K, 2019, THESIS U MICHIGAN
   Maffei L, 2016, SUSTAIN CITIES SOC, V27, P338, DOI 10.1016/j.scs.2016.06.022
   Makransky G, 2019, COMPUT EDUC, V134, P15, DOI 10.1016/j.compedu.2019.02.002
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Manivannan S, 2019, J HEAD TRAUMA REHAB, V34, pE52, DOI 10.1097/HTR.0000000000000412
   Martini M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00438
   Nierula B, 2017, J PAIN, V18, P645, DOI 10.1016/j.jpain.2017.01.003
   Novak D, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-64
   Pals R, 2014, J ENVIRON PSYCHOL, V40, P108, DOI 10.1016/j.jenvp.2014.05.004
   Peng W, 2012, COMPUT HUM BEHAV, V28, P2100, DOI 10.1016/j.chb.2012.06.014
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Ramírez-Fernández C, 2015, INT CONF PER COMP, P280, DOI 10.4108/icst.pervasivehealth.2015.260242
   Rodriguez-Guerrero C, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00242
   Rose T, 2018, APPL ERGON, V69, P153, DOI 10.1016/j.apergo.2018.01.009
   Sagnier C, 2020, INT J HUM-COMPUT INT, V36, P993, DOI 10.1080/10447318.2019.1708612
   Sailer M, 2017, COMPUT HUM BEHAV, V69, P371, DOI 10.1016/j.chb.2016.12.033
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Simeone AL, 2015, 2015 IEEE 1ST WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P19, DOI 10.1109/WEVR.2015.7151690
   Skarbez R, 2021, IEEE T VIS COMPUT GR, V27, P3839, DOI 10.1109/TVCG.2020.2983701
   Skarbez R, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281530
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Staddon JER, 2003, ANNU REV PSYCHOL, V54, P115, DOI 10.1146/annurev.psych.54.101601.145124
   Stanton TR, 2018, PEERJ, V6, DOI 10.7717/peerj.5206
   Swanson LR, 2015, GAMES HEALTH J, V4, P253, DOI 10.1089/g4h.2014.0074
   Taub M, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103781
   Turkay S, 2015, CYBERPSYCHOLOGY, V9, DOI 10.5817/CP2015-3-2
   van den Berg ME, 2018, FRONT PHYSIOL, V9, DOI 10.3389/fphys.2018.00424
   van't Riet J, 2018, BASIC APPL SOC PSYCH, V40, P180, DOI 10.1080/01973533.2018.1459301
   Vorderer P., 2003, Proceedings of the 2nd International Conference on Entertainment Computing (ICEC 2003), Pittsburgh, P1
   Werbach K., 2012, For the win: How game thinking can revolutionize your business
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu DY, 2018, COMMUN RES REP, V35, P434, DOI 10.1080/08824096.2018.1525349
   Yildirim Ç, 2019, ENTERTAIN COMPUT, V31, DOI 10.1016/j.entcom.2019.100308
   Yu R, 2019, THESIS VIRGINIA POLY
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 79
TC 8
Z9 8
U1 3
U2 31
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1507
EP 1518
DI 10.1007/s10055-022-00645-3
EA MAR 2022
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000775830800001
DA 2024-07-18
ER

PT J
AU Monica, R
   Aleotti, J
AF Monica, Riccardo
   Aleotti, Jacopo
TI Evaluation of the Oculus Rift S tracking system in room scale virtual
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Head mounted displays; Tracking technologies; Room-scale virtual reality
ID ACCURACY
AB In specific virtual reality applications that require high accuracy it may be advisable to replace the built-in tracking system of the HMD with a third party solution. The purpose of this research work is to evaluate the accuracy of the built-in tracking system of the Oculus Rift S Head Mounted Display (HMD) in room scale environments against a motion capture system. In particular, an experimental evaluation of the Oculus Rift S inside-out tracking technology was carried out, compared to the performance of an outside-in tracking method based on the OptiTrack motion capture system. In order to track the pose of the HMD using the motion capture system the Oculus Rift S was instrumented with passive retro-reflective markers and calibrated. Experiments have been performed on a dataset of multiple paths including simple motions as well as more complex paths. Each recorded path contained simultaneous changes in both position and orientation of the HMD. Our results indicate that in room-scale environments the average translation error for the Oculus Rift S tracking system is about 1.83 cm, and the average rotation error is about 0.77 degrees, which is 2 orders of magnitude higher than the performance that can be achieved using a motion capture system.
C1 [Monica, Riccardo; Aleotti, Jacopo] Univ Parma, Dept Engn & Architecture, Parco Area Sci 181A, I-43124 Parma, Italy.
C3 University of Parma
RP Aleotti, J (corresponding author), Univ Parma, Dept Engn & Architecture, Parco Area Sci 181A, I-43124 Parma, Italy.
EM riccardo.monica@unipr.it; jacopo.aleotti@unipr.it
CR Ameler T, 2019, IEEE ENG MED BIO, P1465, DOI [10.1109/EMBC.2019.8856992, 10.1109/embc.2019.8856992]
   Bauer P, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051622
   Borges M, 2018, IEEE INT C INT ROBOT, P2610, DOI 10.1109/IROS.2018.8593707
   Borrego A, 2018, GAMES HEALTH J, V7, P151, DOI 10.1089/g4h.2017.0114
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Chang C M, 2016, Proceedings of the 24th ACM international conference on Multimedia, P655, DOI [10.1145/2964284.2967303, DOI 10.1145/2964284.2967303]
   Chessa M, 2019, HUM-COMPUT INTERACT, V34, P51, DOI 10.1080/07370024.2016.1243478
   Debarba HG, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P539, DOI 10.1109/VR.2018.8446497
   Flueratoru L, 2020, INT C ULTRA MOD TELE, P214, DOI [10.1109/icumt51630.2020.9222439, 10.1109/ICUMT51630.2020.9222439]
   Greiff M., 2019, 2019 22th International Conference on Information Fusion (FUSION), P1
   Groves LA, 2019, INT J COMPUT ASS RAD, V14, P1207, DOI 10.1007/s11548-019-01992-4
   Guaitolini M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103325
   HORAUD R, 1995, INT J ROBOT RES, V14, P195, DOI 10.1177/027836499501400301
   Ikbal MS, 2021, IEEE ACCESS, V9, P3798, DOI 10.1109/ACCESS.2020.3047698
   Jansen W, 2019, IEEE SENS J, V19, P8824, DOI 10.1109/JSEN.2019.2921644
   Jost TA, 2021, DISABIL REHABIL-ASSI, V16, P632, DOI 10.1080/17483107.2019.1688398
   Jost TA, 2019, J BIOMECH, V97, DOI 10.1016/j.jbiomech.2019.109379
   Lubetzky AV, 2019, J BIOMECH, V86, P175, DOI 10.1016/j.jbiomech.2019.02.004
   Lwowski J, 2020, IEEE SYST MAN CYBERN, V6, P15, DOI 10.1109/MSMC.2020.2969031
   Marchetto J, 2019, HUM FACTORS, V61, P1340, DOI 10.1177/0018720819835088
   Merriaux P, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071591
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Palma G, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13112186
   Rolland J, 1999, FUNDAMENTALS WEARABL, P110
   Spitzley KA, 2019, J BIOMECH, V87, P172, DOI 10.1016/j.jbiomech.2019.02.015
   Suznjevic M, 2017, INT WORK QUAL MULTIM
   van der Veen SM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173632
   Vox JP, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093145
   Wu R, 2020, IEEE POSITION LOCAT, P1311, DOI [10.1109/plans46316.2020.9110225, 10.1109/PLANS46316.2020.9110225]
   Xu X, 2015, J BIOMECH, V48, P721, DOI 10.1016/j.jbiomech.2015.01.005
   Zhang ZC, 2018, IEEE INT C INT ROBOT, P7244, DOI 10.1109/IROS.2018.8593941
NR 31
TC 10
Z9 10
U1 1
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2022
VL 26
IS 4
BP 1335
EP 1345
DI 10.1007/s10055-022-00637-3
EA FEB 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 5Q4XQ
UT WOS:000761837800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Cha, HS
   Chang, WD
   Im, CH
AF Cha, Ho-Seung
   Chang, Won-Du
   Im, Chang-Hwan
TI Deep-learning-based real-time silent speech recognition using facial
   electromyogram recorded around eyes for hands-free interfacing in a
   virtual reality environment
SO VIRTUAL REALITY
LA English
DT Article
DE Deep learning; Facial electromyography; Human-computer interface;
   Myoelectric control; Silent speech recognition; Virtual reality
AB Speech recognition technology is a promising hands-free interfacing modality for virtual reality (VR) applications. However, it has several drawbacks, such as limited usability in a noisy environment or a public place and limited accessibility to those who cannot generate loud and clear voices. These limitations may be overcome by employing a silent speech recognition (SSR) technology utilizing facial electromyograms (fEMGs) in a VR environment. In the conventional SSR systems, however, fEMG electrodes were attached around the user's lips and neck, thereby creating new practical issues, such as the requirement of an additional wearable system besides the VR headset, necessity of a complex and time-consuming procedure for attaching the fEMG electrodes, and discomfort and limited facial muscle movements of the user. To solve these problems, we propose an SSR system using fEMGs measured by a few electrodes attached around the eyes of a user, which can also be easily incorporated into available VR headsets. To enhance the accuracy of classifying the fEMG signals recorded from limited recording locations relatively far from the phonatory organs, a deep neural network-based classification method was developed using similar fEMG data previously collected from other individuals and then transformed by dynamic positional warping. In the experiments, the proposed SSR system could classify six different fEMG patterns generated by six silently spoken words with an accuracy of 92.53%. To further demonstrate that our SSR system can be used as a hands-free control interface in practical VR applications, an online SSR system was implemented.
C1 [Cha, Ho-Seung; Chang, Won-Du; Im, Chang-Hwan] Hanyang Univ, Dept Biomed Engn, 222 Wangsimni Ro, Seoul 04763, South Korea.
   [Chang, Won-Du] Pukyong Natl Univ, Dept Comp Engn, 45 Yongso Ro, Busan 48513, South Korea.
C3 Hanyang University; Pukyong National University
RP Im, CH (corresponding author), Hanyang Univ, Dept Biomed Engn, 222 Wangsimni Ro, Seoul 04763, South Korea.
EM hoseungcha@gmail.com; cross12@gmail.com; ich@hanyang.ac.kr
RI Im, Chang-Hwan/ABB-4391-2021
OI Im, Chang-Hwan/0000-0003-3795-3318; Cha, Ho-Seung/0000-0002-9492-2318;
   Chang, Won-Du/0000-0002-7437-4211
FU Samsung Science and Technology Foundation [SRFC-TB1703-05]; National
   Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2019R1A2C2086593]; Institute of Information and communications
   Technology Planning and Evaluation (IITP) - Korea government (MIST)
   [2020-0-01373]
FX This was supported in part by the Samsung Science and Technology
   Foundation [SRFC-TB1703-05, facial electromyogram-based facial
   expression recognition for interactive VR applications], in part by the
   National Research Foundation of Korea (NRF) grant funded by the Korea
   government (MSIT). (No. NRF-2019R1A2C2086593), and in part by the
   Institute of Information and communications Technology Planning and
   Evaluation (IITP) grant funded by the Korea government (MIST) (No.
   2020-0-01373, Artificial Intelligence Graduate School Program (Hanyang
   University)).
CR Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Cha HS, 2020, IEEE ACCESS, V8, P62065, DOI 10.1109/ACCESS.2020.2983608
   Chang WD, 2016, COMPUT METH PROG BIO, V124, P19, DOI 10.1016/j.cmpb.2015.10.011
   Chang WD, 2014, J APPL MATH, DOI 10.1155/2014/528071
   Chang WD, 2009, INT J PATTERN RECOGN, V23, P967, DOI 10.1142/S0218001409007454
   Denby B, 2010, SPEECH COMMUN, V52, P270, DOI 10.1016/j.specom.2009.08.002
   Deng YB, 2014, INTERSPEECH, P1164
   Gunkel SNB, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P498, DOI 10.1145/3204949.3208115
   Hachet M., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P189
   He JY, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/4/046005
   He ZY, 2017, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON RELIABILITY SYSTEMS ENGINEERING (ICRSE 2017)
   Hermus K, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/45821
   Hueber T, 2010, SPEECH COMMUN, V52, P288, DOI 10.1016/j.specom.2009.11.004
   Ito T, 2005, SPEECH COMMUN, V45, P139, DOI 10.1016/j.specom.2003.10.005
   Janke M, 2017, IEEE-ACM T AUDIO SPE, V25, P2375, DOI 10.1109/TASLP.2017.2738568
   Ji Y, 2018, SPEECH COMMUN, V98, P42, DOI 10.1016/j.specom.2018.02.002
   Kapur A, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P43, DOI 10.1145/3172944.3172977
   Kim M, 2017, IEEE-ACM T AUDIO SPE, V25, P2323, DOI 10.1109/TASLP.2017.2758999
   Kranzlmuller D., 2001, ITG-Fachbericht, P101
   Lee KR, 2017, IEEE T NEUR SYS REH, V25, P37, DOI 10.1109/TNSRE.2016.2542524
   Mavridou I, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P152, DOI 10.1145/3131277.3134366
   Mavridou I, 2017, P IEEE VIRT REAL ANN, P441, DOI 10.1109/VR.2017.7892369
   Meltzner GS, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aac965
   Meltzner GS, 2017, IEEE-ACM T AUDIO SPE, V25, P2386, DOI 10.1109/TASLP.2017.2740000
   Miyashita H., 2008, P 18 INT C ART REAL, P20
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Phinyomark A., 2018, Big Data Cognitive Computing, V2, DOI DOI 10.3390/BDCC2030021
   Phinyomark A, 2013, EXPERT SYST APPL, V40, P4832, DOI 10.1016/j.eswa.2013.02.023
   Schultz T, 2010, SPEECH COMMUN, V52, P341, DOI 10.1016/j.specom.2009.12.002
   Shibano N, 2004, 2004 IEEE VIRT REAL, P101
   Srisuwan N, 2018, MED BIOL ENG COMPUT, V56, P1041, DOI 10.1007/s11517-017-1723-x
   Stedmon AW, 2011, INT J HUM-COMPUT ST, V69, P3, DOI 10.1016/j.ijhcs.2010.09.002
   Wand M, 2014, IEEE T BIO-MED ENG, V61, P2515, DOI 10.1109/TBME.2014.2319000
   Wang J, 2015, PRELIMINARY TEST REA, P38, DOI [10.3115/v1/w14-1906, DOI 10.3115/V1/W14-1906]
   Wang Y, 2021, NEUROCOMPUTING, V451, P25, DOI 10.1016/j.neucom.2021.03.025
NR 36
TC 4
Z9 4
U1 3
U2 31
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1047
EP 1057
DI 10.1007/s10055-021-00616-0
EA JAN 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000749126800001
DA 2024-07-18
ER

PT J
AU Liu, DSM
   Wu, SJ
AF Liu, Damon Shing-Min
   Wu, Shao-Jun
TI Light direction estimation and hand touchable interaction for augmented
   reality
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality (AR); Light source estimation; Gesture recognition;
   Human-computer interaction
ID MODEL
AB Augmented reality is a technology that combines a virtual world with the real world. How to improve the realism of augmented reality is an important topic. One focus of this paper is lighting consistency between virtual and real world, and the other is interaction with virtual object using hands. Estimating lighting conditions through traditional methods often requires many prior knowledge of the scene. We propose a method that estimates the light direction based on shadows and foreground objects with only one scene image. We detect and calculate the relative direction of an object and its shadow in the scene to estimate the azimuth of the light, and use area size ratio of the object and its shadow to estimate the elevation angle of the light. We used some real scenes to test our method. However, the exact light direction of the real world is difficult to acquire, so we further verified our method by establishing a number of virtual scenes with preset light direction. Moreover, hand gesture-based human-computer interaction provides a natural and easy way for interaction. Traditional augmented reality interactions use markers or touch screens. We apply gesture recognition and hand touchable interaction in augmented reality, allowing the user's hand to occlude the virtual object in the picture, and recognize the gesture. By adding estimated light and hand touchable interactions, we enhance the realism of augmented reality.
C1 [Liu, Damon Shing-Min; Wu, Shao-Jun] Natl Chung Cheng Univ, Comp Sci Dept, 168 Univ Rd, Chiayi, Taiwan.
C3 National Chung Cheng University
RP Liu, DSM (corresponding author), Natl Chung Cheng Univ, Comp Sci Dept, 168 Univ Rd, Chiayi, Taiwan.
EM damon@computer.org
CR Bambach S, 2015, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2015.226
   Berbar M.A., 2011, International Journal of Video Image Processing and Network Security, V11, P1
   Cambon, 2014, PIKACHU MODEL
   Chang SH, 2018, SA'18: SIGGRAPH ASIA 2018 POSTERS, DOI 10.1145/3283289.3283348
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   de Castro T. K., 2012, 2012 14th Symposium on Virtual and Augmented Reality (SVR), P36, DOI 10.1109/SVR.2012.9
   Debevec P., 1998, SIGGRAPH98, P189, DOI DOI 10.1145/280814.280864
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Duchêne S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2756549
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   El Sibai R, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER AND APPLICATIONS (ICCA), P18, DOI 10.1109/COMAPP.2017.8079780
   Flickr, 2019, SCEN IM INT
   Georgoulis S, 2016, DELIGHT NET DECOMPOS
   Godbehere AB, 2012, P AMER CONTR CONF, P4305
   Greg, 2019, SCENE IMAGES INTERNE
   Haber T, 2009, PROC CVPR IEEE, P627, DOI 10.1109/CVPRW.2009.5206753
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hold-Geoffroy Y, 2017, PROC CVPR IEEE, P2373, DOI 10.1109/CVPR.2017.255
   Hosek L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185591
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jiang D, 2007, IEEE INT CONF MOB, P1001
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kanbara M, 2004, INT C PATT RECOG, P911, DOI 10.1109/ICPR.2004.1334407
   Kosecká J, 2002, LECT NOTES COMPUT SC, V2353, P476
   Laffont PY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366221
   Lalonde JF, 2009, IEEE I CONF COMP VIS, P183, DOI 10.1109/ICCV.2009.5459163
   Lalonde Jean-Francois, 2014, 2014 2 INT C 3D VISI, P131
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Manresa C., 2005, ELECT LETT COMPUTER, V3, P96, DOI DOI 10.5565/REV/ELCVIA.109
   Matterport, 2017, SCEN IM INT
   Ng CW, 2002, IMAGE VISION COMPUT, V20, P993, DOI 10.1016/S0262-8856(02)00113-0
   Ong EJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P889
   Panagopoulos A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130334
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   PEREZ R, 1993, SOL ENERGY, V50, P235, DOI 10.1016/0038-092X(93)90017-I
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Poudel R.P.K., 2019, ARXIV190204502, P289
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   Rematas K, 2016, PROC CVPR IEEE, P4508, DOI 10.1109/CVPR.2016.488
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Sato I, 2003, IEEE T PATTERN ANAL, V25, P290, DOI 10.1109/TPAMI.2003.1182093
   Seo DW, 2013, EXPERT SYST APPL, V40, P3784, DOI 10.1016/j.eswa.2012.12.091
   Sugano N, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2003.1240690
   Wang Y, 2003, GRAPH MODELS, V65, P185, DOI 10.1016/S1524-0703(03)00043-2
   Wehrwein S, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P460, DOI 10.1109/3DV.2015.58
   Xiaowu Chen, 2011, 2011 12th International Conference on Computer-Aided Design and Computer Graphics, P450, DOI 10.1109/CAD/Graphics.2011.19
   Xu P., 2017, ARXIV PREPRINT ARXIV
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 54
TC 1
Z9 1
U1 1
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1155
EP 1172
DI 10.1007/s10055-022-00624-8
EA JAN 2022
PG 18
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000745586400001
DA 2024-07-18
ER

PT J
AU Seedhouse, E
AF Seedhouse, Erik
TI Presence within the virtual reality environment of the international
   space station
SO VIRTUAL REALITY
LA English
DT Article
DE Immersive; Learning; Navigation; Presence; Virtual reality
AB Virtual Reality (VR) is becoming an increasingly effective and powerful medium for learning, especially when applied to environments such as the International Space Station (ISS) that requires acquiring situational awareness (SA) and navigation. Research has shown, and continues to show, an encouraging array of positive learning outcomes when applying VR technology to support and improve learning. Findings include observing positive effects on spatial awareness (SA), astronaut navigation, and presence. Additionally, research has demonstrated that learners enjoy their VR experience and acknowledge the potential of VR in enhancing quality of instruction, especially regarding the immersive realism, or presence, that the virtual environment provides. It is argued that this sense of presence encourages and enhances self-paced learning and permits a more student-centered instructional approach. VR has been used in myriad fields and is not just an educational tool. But as an educational tool VR may be used to support only certain types of learning, because the medium may not work for all kinds of learning. That is because presence comprises several characteristics such as sensory effects, distraction, and realism. Also, the sense of presence may be affected by characteristics of a specific environment. To investigate this latter statement the objective of this study was to evaluate four components of presence (sensory, distraction, realism and involvement) while participants navigated through a VR-rendered ISS environment to assess sense of presence and to determine the level of presence in the virtual world of the ISS. The results indicate that when applied to these visual and kinesthetic modes of learning (the other modes being auditory and reading and writing), VR as an instructional tool is not superior to conventional learning. This result was borne out of the assessment of the comparisons between groups when completing navigation tasks and diagram tasks.
C1 [Seedhouse, Erik] Embry Riddle Aeronaut Univ, Appl Aviat Sci Dept, Spaceflight Operat, 1 Aerosp Blvd, Daytona Beach, FL 32115 USA.
C3 Embry-Riddle Aeronautical University
RP Seedhouse, E (corresponding author), Embry Riddle Aeronaut Univ, Appl Aviat Sci Dept, Spaceflight Operat, 1 Aerosp Blvd, Daytona Beach, FL 32115 USA.
EM seedhoue@erau.edu
OI Seedhouse, Erik/0000-0001-7230-727X
FU Embry-RiddleAeronautical University FIRST Grant [13225]
FX This work was funded by the Embry-RiddleAeronautical University FIRST
   Grant 13225.
CR Aoki H, 2008, ACTA ASTRONAUT, V63, P841, DOI 10.1016/j.actaastro.2007.11.001
   Barnett M., 2005, JOURNALOFCOMPUTERS M, V24, P333
   Crosier I. K., 2000, Education and Information Technologies, V5, P329, DOI 10.1023/A:1012009725532
   Crumpton LL, 1997, COMPUT IND ENG, V33, P217, DOI 10.1016/S0360-8352(97)00078-8
   Dalgarno B., 2002, WINDS CHANGE SEA LEA, V1, P149
   Strangman N., 2003, VIRTUAL REALITYSIMUL
   Um E.R., 2007, Proceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications, V2007, P4176
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Youngblut C., 1998, ED USES VIRTUAL REAL
NR 9
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 1145
EP 1153
DI 10.1007/s10055-021-00615-1
EA JAN 2022
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000744756100001
DA 2024-07-18
ER

PT J
AU Knaust, T
   Felnhofer, A
   Kothgassner, OD
   Höllmer, H
   Gorzka, RJ
   Schulz, H
AF Knaust, Thiemo
   Felnhofer, Anna
   Kothgassner, Oswald D.
   Hoellmer, Helge
   Gorzka, Robert-Jacek
   Schulz, Holger
TI Exposure to virtual nature: the impact of different immersion levels on
   skin conductance level, heart rate, and perceived relaxation
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual relaxation; Virtual nature; 360 degrees Videos; 360 degrees
   Nature video; Monoscopic 360 degrees video; Immersion
ID STRESS RECOVERY; TECHNOLOGY; REALITY; ENVIRONMENTS; SCENES
AB It is generally accepted that natural environments reduce stress and improve mood. Since access to natural environments is sometimes limited, virtual natural environments, especially monoscopic 360 degrees nature videos, offer a viable alternative. However, it remains unclear whether presenting monoscopic 360 degrees nature videos via a head-mounted display (HMD) or a PC monitor results in larger relaxation effects. Therefore, this study examined whether a monoscopic 360 degrees beach video presented with an HMD is significantly more relaxing than the same video presented via a PC screen, or no video at all (control condition), in altering skin conductance level (SCL), heart rate (HR), and perceived relaxation. Overall, 102 adults (40.2% females, age range 19-62 years) participated in a counterbalanced, randomized, controlled, within-subject experiment. All participants were subjected to three stressors comprising different mental arithmetic tasks, followed by three different recovery phases (HMD, PC, control). For SCL, the results showed a significantly larger decrease in the HMD and PC than in the control condition, but no significant differences between the HMD and PC condition. For HR, there were no significant differences between the recovery conditions. However, the HMD condition was rated significantly more relaxing than the other conditions, with no significant differences between the PC and control condition. Exploratory analyses showed that these results were not moderated by the participants' age, gender, or technology anxiety. Overall, the psychophysiological results showed no significant benefit favoring the HMD over PC condition, although the self-reported relaxation ratings did. Future studies are warranted to clarify this divergence.
C1 [Knaust, Thiemo; Hoellmer, Helge] Bundeswehr Hosp Hamburg, Ctr Mental Hlth, Hamburg, Germany.
   [Felnhofer, Anna] Med Univ Vienna, Dept Pediat & Adolescent Med, Vienna, Austria.
   [Kothgassner, Oswald D.] Med Univ Vienna, Dept Child & Adolescent Psychiat, Vienna, Austria.
   [Gorzka, Robert-Jacek] German Mil Police Command, Dept Psychol, Hannover, Germany.
   [Schulz, Holger] Univ Hosp Hamburg Eppendorf, Dept Med Psychol, Hamburg, Germany.
C3 Medical University of Vienna; Medical University of Vienna; University
   of Hamburg; University Medical Center Hamburg-Eppendorf
RP Knaust, T (corresponding author), Bundeswehr Hosp Hamburg, Ctr Mental Hlth, Hamburg, Germany.
EM thiemo1knaust@bundeswehr.org
RI Gorzka, Robert-Jacek/AHD-8663-2022; Gorzka, Robert/IAN-5203-2023;
   Kothgassner, Oswald David/I-5024-2019; Knaust, Thiemo/AED-8211-2022;
   Felnhofer, Anna/D-6458-2017
OI Kothgassner, Oswald David/0000-0002-3243-0238; Knaust,
   Thiemo/0000-0002-9187-2853; Felnhofer, Anna/0000-0002-0081-7489;
   Hoellmer, Helge/0000-0002-6706-9470; Schulz, Holger/0000-0001-5375-0030
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL. No funds,
   grants, or other support was received.
CR Alvarsson JJ, 2010, INT J ENV RES PUB HE, V7, P1036, DOI 10.3390/ijerph7031036
   Amores J, 2018, INT CONF WEARAB IMPL, P98, DOI 10.1109/BSN.2018.8329668
   Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   Annerstedt M, 2013, PHYSIOL BEHAV, V118, P240, DOI 10.1016/j.physbeh.2013.05.023
   BENSHAKHAR G, 1985, PSYCHOPHYSIOLOGY, V22, P292, DOI 10.1111/j.1469-8986.1985.tb01603.x
   Bilgin P, 2019, IEEE SYS MAN CYBERN, P2833, DOI 10.1109/SMC.2019.8914326
   Birkett MA, 2011, JOVE-J VIS EXP, DOI 10.3791/3238
   Blum J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02172
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Brooks AM, 2017, J ENVIRON PSYCHOL, V54, P91, DOI 10.1016/j.jenvp.2017.10.004
   Browning MHEM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.02200
   Browning MHEM, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02667
   Bruner JS., 1948, Current trends in social psychology, P71
   Calogiuri G, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02321
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Chirico A, 2019, CYBERPSYCH BEH SOC N, V22, P220, DOI 10.1089/cyber.2018.0393
   Cohen J., 1988, STAT POWER ANAL BEHA
   Corazon SS, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16101711
   CRONBACH LJ, 1951, PSYCHOMETRIKA, V16, P297, DOI [10.1007/BF02310555, DOI 10.1007/BF02310555]
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Diener E, 2010, SOC INDIC RES, V97, P143, DOI 10.1007/s11205-009-9493-y
   Egleston BL, 2011, STAT MED, V30, P3560, DOI 10.1002/sim.4377
   EGNER L, 2020, INT J ENV RES PUBLIC
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Felnhofer A., 2013, P USABILITY DAY, VXI, P1
   Felnhofer A, 2014, COMPUT HUM BEHAV, V31, P272, DOI 10.1016/j.chb.2013.10.045
   FOWLES DC, 1981, PSYCHOPHYSIOLOGY, V18, P232, DOI 10.1111/j.1469-8986.1981.tb03024.x
   Heerink M, 2010, INT J SOC ROBOT, V2, P361, DOI 10.1007/s12369-010-0068-5
   Huang JW, 2017, P IEEE VIRT REAL ANN, P37, DOI 10.1109/VR.2017.7892229
   KAHNEMAN D, 1969, J EXP PSYCHOL, V79, P164, DOI 10.1037/h0026952
   Kamal SA, 2020, TECHNOL SOC, V60, DOI 10.1016/j.techsoc.2019.101212
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Khazan I., 2013, The clinical handbook of biofeedback : a step by step guide for training and practice with mindfulness
   KIRSCHBAUM C, 1993, NEUROPSYCHOBIOLOGY, V28, P76, DOI 10.1159/000119004
   Kothgassner O., 2014, INTERACTING PRESENCE
   Kothgassner OD., 2013, TUI. Technology Usage Inventory
   Kothgassner OD, 2018, CYBERPSYCH BEH SOC N, V21, P318, DOI 10.1089/cyber.2017.0691
   Lazarus R.S., 1994, Emotion and adaptation
   Liszio S, 2018, ANN REV CYBERTHERAPY, V16, P87
   Loo, 2002, J MANAGERIAL PSYCHOL, V17, P68, DOI DOI 10.1108/02683940210415933
   Manis KT, 2019, J BUS RES, V100, P503, DOI 10.1016/j.jbusres.2018.10.021
   Mostajeran F, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83277-y
   Nukarinen T, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382956
   Ohly H, 2016, J TOXICOL ENV HEAL B, V19, P305, DOI 10.1080/10937404.2016.1196155
   Orr N, 2021, GERIATRICS-BASEL, V6, DOI 10.3390/geriatrics6010027
   Pizzoli SFM, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00479
   Postmes T, 2013, BRIT J SOC PSYCHOL, V52, P597, DOI 10.1111/bjso.12006
   Riches S, 2021, SOC PSYCH PSYCH EPID, V56, P1707, DOI 10.1007/s00127-021-02110-z
   Ritter KA, 2022, VIRTUAL REAL-LONDON, V26, P571, DOI 10.1007/s10055-021-00502-9
   ROCKSTROH C, 2020, J MEDIA PSYCHOL-GER
   Rockstroh C, 2019, INT J HUM-COMPUT ST, V130, P209, DOI 10.1016/j.ijhcs.2019.06.011
   Scherer KR, 2019, ANNU REV PSYCHOL, V70, P719, DOI 10.1146/annurev-psych-122216-011854
   Schulz AW, 2018, EFFICIENT COGNITION: THE EVOLUTION OF REPRESENTATIONAL DECISION MAKING, P1, DOI 10.1177/0013916518800798
   Schutte NS, 2017, ECOPSYCHOLOGY, V9, P1, DOI 10.1089/eco.2016.0042
   Schwartz M., 2017, BIOFEEDBACK PRACTITI, V4th
   Shaffer F, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00258
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   ULRICH RS, 1981, ENVIRON BEHAV, V13, P523, DOI 10.1177/0013916581135001
   Valtchanov D, 2010, CYBERPSYCH BEH SOC N, V13, P503, DOI 10.1089/cyber.2009.0308
   Vaquero-Blasco MA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062219
   Villani D., 2007, Int. J. Stress Manag. Copyr, V14, P260, DOI [DOI 10.1037/1072-5245.14.3.260, 10.1037/1072-5245.14.3.260https://dx.doi.org/10.1037/1072-5245.14.3.260, DOI 10.1037/1072-5245.14.3.260HTTPS://DX.DOI.ORG/10.1037/1072-5245.14.3.260]
   Wang CA, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.01029
   Wang XB, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16183263
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   White MP, 2018, NEUROPSYCH DIS TREAT, V14, P3001, DOI 10.2147/NDT.S179038
   World Health Organization, 2016, Urban Green Spaces and Health: A Review of Evidence
   Yeo NL, 2020, J ENVIRON PSYCHOL, V72, DOI 10.1016/j.jenvp.2020.101500
   Yin J, 2018, BUILD ENVIRON, V132, P255, DOI 10.1016/j.buildenv.2018.01.006
   Yu CP, 2020, URBAN FOR URBAN GREE, V56, DOI 10.1016/j.ufug.2020.126863
NR 71
TC 27
Z9 28
U1 11
U2 57
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2022
VL 26
IS 3
BP 925
EP 938
DI 10.1007/s10055-021-00595-2
EA NOV 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 4G7HZ
UT WOS:000716832500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Gao, YF
   González, VA
   Yiu, TW
   Cabrera-Guerrero, G
   Li, N
   Baghouz, A
   Rahouti, A
AF Gao, Yifan
   Gonzalez, Vicente A.
   Yiu, Tak Wing
   Cabrera-Guerrero, Guillermo
   Li, Nan
   Baghouz, Anouar
   Rahouti, Anass
TI Immersive virtual reality as an empirical research tool: exploring the
   capability of a machine learning model for predicting construction
   workers' safety behaviour
SO VIRTUAL REALITY
LA English
DT Article
DE Construction sector; Safety behaviour; Machine learning; Virtual reality
ID WORKPLACE SAFETY; UNSAFE ACTS; PERSONALITY; RISK; TECHNOLOGIES;
   METAANALYSIS; PERFORMANCE; VALIDATION; MOTIVATION; MANAGEMENT
AB In recent years, research has found that people have stable predispositions to engage in certain behavioural patterns to work safely or unsafely, which vary among individuals as a function of their personality features. In this regard, an innovative machine learning model has been recently developed to predict workers' behavioural tendency based on personality factors. This paper presents an empirical evaluation of the model's prediction performance (i.e. the degree to which the model can generate similar results compared to reality) to address the issue of the model's usability before it is implemented in real situations. As virtual reality allows a good grip on fidelity resembling real-world situations, it can stimulate more natural behaviour responses from participants to increase ecological validity of experimental results. Thus, we implemented a virtual reality experimentation environment to assess workers' safety behaviour. The model's prediction capability was then evaluated by comparing the model prediction results and workers' safety behaviour as assessed in virtual reality. The comparison results showed that the model predictions on two dimensions of workers' safety behaviour (i.e. task and contextual performance) were in good agreement with the virtual reality experimental results, with Spearman correlation coefficients of 79.7% and 87.8%, respectively. The machine learning model thus proved to have good prediction capability, which allows the model to help identify vulnerable workers who are prone to undertake unsafe behaviours. The findings also suggest that virtual reality is a promising method for measuring workers' safety behaviour as it can provide a realistic and safe environment for experimentation.
C1 [Gao, Yifan] Zhejiang Univ, Coll Civil Engn & Architecture, 866 Yuhangtang Rd, Hangzhou 310058, Zhejiang, Peoples R China.
   [Gonzalez, Vicente A.] Univ Auckland, Fac Engn, Dept Civil & Environm Engn, Auckland, New Zealand.
   [Yiu, Tak Wing] Massey Univ, Sch Built Environm, Auckland, New Zealand.
   [Cabrera-Guerrero, Guillermo] Pontificia Univ Catolica Valparaiso, Escuela Ingn Informat, Valparaiso, Chile.
   [Li, Nan] Tsinghua Univ, Dept Construct Management, Beijing, Peoples R China.
   [Baghouz, Anouar] Univ Mons, Dept Civil Engn & Struct Mech, Mons, Belgium.
   [Rahouti, Anass] Fire Safety Consulting, Rue Pirou 41, Ligny, Belgium.
C3 Zhejiang University; University of Auckland; Massey University;
   Pontificia Universidad Catolica de Valparaiso; Tsinghua University;
   University of Mons
RP Gao, YF (corresponding author), Zhejiang Univ, Coll Civil Engn & Architecture, 866 Yuhangtang Rd, Hangzhou 310058, Zhejiang, Peoples R China.
EM yfgao91@zju.edu.cn; v.gonzalez@auckland.ac.nz; tyiu@massey.ac.nz;
   guillermo.cabrera@pucv.cl; nanli@tsinghua.edu.cn;
   anouar.baghouz@student.umons.ac.be; arh@fscint.eu
RI Li, Nan/IXD-8260-2023; Cabrera-Guerrero, Guillermo/AAA-4172-2022; Yiu,
   (Kenneth) Tak Wing/A-3334-2009; lin, wang/JCA-7967-2023; Li,
   Nan/W-4397-2017
OI Yiu, (Kenneth) Tak Wing/0000-0002-8466-7130; Li,
   Nan/0000-0002-7272-4273; Gao, Yifan/0000-0003-2781-6862
FU Department of Civil and Environmental Engineering at The University of
   Auckland
FX This research is supported by Department of Civil and Environmental
   Engineering at The University of Auckland.
CR ACC, 2018, NUMB NEW ACC WORK RE
   Ajzen I., 1985, UNDERSTANDING ATTITU, P11, DOI 10.1007/978-3-642-69746-3_2
   Al-Haadir S, 2013, P 19 CIB WORLD BUILD, P5
   Al-Shabbani Z, 2020, CONSTRUCTION RESEARCH CONGRESS 2020: SAFETY, WORKFORCE, AND EDUCATION, P213
   Antwi-Afari MF, 2018, AUTOMAT CONSTR, V96, P433, DOI 10.1016/j.autcon.2018.10.004
   Arias S, 2021, FIRE MATER, V45, P462, DOI 10.1002/fam.2922
   Asiain J, 2022, BRIT J GUID COUNS, V50, P1, DOI 10.1080/03069885.2021.1885008
   Baldissone G, 2019, SAFETY SCI, V119, P240, DOI 10.1016/j.ssci.2018.10.006
   Beus JM, 2015, J APPL PSYCHOL, V100, P481, DOI 10.1037/a0037916
   BLS.gov, 2018, US BUR LAB STAT IND
   Chessa M, 2019, HUM-COMPUT INTERACT, V34, P51, DOI 10.1080/07370024.2016.1243478
   Choi B, 2017, AUTOMAT CONSTR, V84, P31, DOI 10.1016/j.autcon.2017.08.005
   Christian MS, 2009, J APPL PSYCHOL, V94, P1103, DOI 10.1037/a0016172
   Clarke S, 2008, APPL PSYCHOL-INT REV, V57, P94, DOI 10.1111/j.1464-0597.2007.00267.x
   Cohen J., 1992, Current Directions in Psychological Science, V1, P98, DOI [DOI 10.1111/1467-8721.EP10768783, 10.1111/1467-8721.ep10768783]
   Earle AM, 2020, J AM COLL HEALTH, V68, P374, DOI 10.1080/07448481.2018.1557197
   Engelbrecht H, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00101
   Fang DQ, 2019, BRIT J OPHTHALMOL, V103, P415, DOI 10.1136/bjophthalmol-2018-311874
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Faulhaber AK, 2019, SCI ENG ETHICS, V25, P399, DOI 10.1007/s11948-018-0020-x
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Fyhri A, 2012, ACCIDENT ANAL PREV, V49, P470, DOI 10.1016/j.aap.2012.03.017
   Gao Y, 2020, THESIS U AUCKLAND
   Gao YF, 2020, J CONSTR ENG M, V146, DOI 10.1061/(ASCE)CO.1943-7862.0001763
   Gao YF, 2019, COMPUT EDUC, V138, P101, DOI 10.1016/j.compedu.2019.05.003
   Geiger M, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02153
   Geller ES, 2010, BEST KIND PRIDE IS W
   Gillison FB, 2019, HEALTH PSYCHOL REV, V13, P110, DOI 10.1080/17437199.2018.1534071
   Gorji A, 2018, MEAS SCI TECHNOL, V29, DOI 10.1088/1361-6501/aac8c2
   Gou JP, 2019, EXPERT SYST APPL, V115, P356, DOI 10.1016/j.eswa.2018.08.021
   Grawitch M., 2006, Consulting Psychology Journal: Practice and Research, V58, P129, DOI [10.1037/1065-9293.58.3.129, DOI 10.1037/1065-9293.58.3.129]
   Greuter S., 2013, PROC 2013 DIGRA INT
   Guerin RJ, 2020, J SAFETY RES, V72, P189, DOI 10.1016/j.jsr.2019.12.002
   Guo HL, 2018, J CONSTR ENG M, V144, DOI 10.1061/(ASCE)CO.1943-7862.0001497
   Guo HL, 2017, AUTOMAT CONSTR, V73, P135, DOI 10.1016/j.autcon.2016.10.004
   Han T, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P913, DOI 10.1145/3242587.3242667
   Harwell MR, 2001, REV EDUC RES, V71, P105, DOI 10.3102/00346543071001105
   Hasanzadeh S, 2019, J CONSTR ENG M, V145, DOI 10.1061/(ASCE)CO.1943-7862.0001673
   Hasanzadeh S, 2019, COMPUTING IN CIVIL ENGINEERING 2019: VISUALIZATION, INFORMATION MODELING, AND SIMULATION, P137
   Heyde A., 2014, J ERGON, V4, P2, DOI [10.4172/2165-7556.1000130, DOI 10.4172/2165-7556.1000130]
   Hirao Y, 2018, J IMAGING SCI TECHN, V62, DOI 10.2352/J.ImagingSci.Technol.2018.62.6.060402
   Hoffmann EA, 2008, SOCIOL INQ, V78, P270, DOI 10.1111/j.1475-682X.2008.00240.x
   Hogan J, 2013, HUM PERFORM, V26, P20, DOI 10.1080/08959285.2012.736899
   Jackson CJ, 2009, 8 IOP C C P MANL SYD, P75
   Jelonek M, 2019, P MENSCH COMP HAMB G
   Jitwasinkul B, 2016, SAFETY SCI, V82, P264, DOI 10.1016/j.ssci.2015.09.027
   Jones T, 2016, J PAIN, V17, pS102, DOI 10.1016/j.jpain.2016.01.319
   Kataoka Y, 2018, P 2018 ACM COMP INT
   Kim H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174075
   Krzykowska K, 2019, INT J AEROSPACE ENG, V2019, DOI 10.1155/2019/7632958
   Laurent J, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03201
   Lee CE, 2018, J OBSTET GYNAECOL CA, V40, P158, DOI 10.1016/j.jogc.2017.06.025
   Lee J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300301
   Li ASW, 2019, APPL PSYCHOL-HLTH WE, V11, P382, DOI 10.1111/aphw.12154
   Li C, 2019, APPL MATH MODEL, V65, P390, DOI 10.1016/j.apm.2018.08.017
   Li H, 2016, SAFETY SCI, V84, P78, DOI 10.1016/j.ssci.2015.11.025
   Li H, 2012, AUTOMAT CONSTR, V22, P498, DOI 10.1016/j.autcon.2011.11.009
   Li X, 2018, AUTOMAT CONSTR, V86, P150, DOI 10.1016/j.autcon.2017.11.003
   Lloréns R, 2015, ARCH PHYS MED REHAB, V96, P418, DOI 10.1016/j.apmr.2014.10.019
   Lu XQ, 2016, SAFETY SCI, V86, P184, DOI 10.1016/j.ssci.2016.02.018
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Maurer TJ, 1998, J APPL PSYCHOL, V83, P324, DOI 10.1037/0021-9010.83.2.324
   Mayer RE, 2017, J COMPUT ASSIST LEAR, V33, P403, DOI 10.1111/jcal.12197
   Mentrikoski JM, 2019, BURNS, V45, P1242, DOI 10.1016/j.burns.2019.02.006
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   Nascimento-Ferreira MV, 2018, OBES REV, V19, P810, DOI 10.1111/obr.12676
   Nazemi M, 2021, ACCIDENT ANAL PREV, V151, DOI 10.1016/j.aap.2020.105943
   Newman JM, 2019, J ARTHROPLASTY, V34, P554, DOI 10.1016/j.arth.2018.11.017
   Norman P, 2019, PSYCHOL HEALTH, V34, P478, DOI 10.1080/08870446.2018.1544369
   Panuwatwanich K, 2017, INT J OCCUP SAF ERGO, V23, P60, DOI 10.1080/10803548.2016.1235424
   Patel DA, 2016, SAFETY SCI, V89, P240, DOI 10.1016/j.ssci.2016.06.020
   Patel DA, 2015, J MANAGE ENG, V31, DOI 10.1061/(ASCE)ME.1943-5479.0000348
   Patel DA, 2015, J CONSTR ENG M, V141, DOI 10.1061/(ASCE)CO.1943-7862.0000922
   Rafiei MH, 2018, J CONSTR ENG M, V144, DOI 10.1061/(ASCE)CO.1943-7862.0001570
   Rajagopalan G, 2021, A Python Data Analyst's Toolkit: Learn Python and Python-based Libraries with applications in data analysis and statistics, P243, DOI [10.1007/978-1-4842-6399-0_7, DOI 10.1007/978-1-4842-6399-0_7]
   Rau PLP, 2020, INT J OCCUP SAF ERGO, V26, P719, DOI 10.1080/10803548.2018.1493259
   Rivera E, 2003, BREAST CANCER RES, V5, pR114, DOI 10.1186/bcr618
   Rose A, 2019, SAF HEALTH WORK-KR, V10, P166, DOI 10.1016/j.shaw.2018.10.001
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Samant SS, 2019, FOOD QUAL PREFER, V73, P75, DOI 10.1016/j.foodqual.2018.12.006
   Scardapane S, 2019, NEURAL NETWORKS, V110, P19, DOI 10.1016/j.neunet.2018.11.002
   Seo HC, 2015, SAFETY SCI, V77, P160, DOI 10.1016/j.ssci.2015.03.010
   Shakerian M, 2019, SAFETY SCI, V120, P89, DOI 10.1016/j.ssci.2019.06.041
   Shi Y, 2018, CONSTR RES C NEW ORL
   Shi YM, 2019, AUTOMAT CONSTR, V104, P197, DOI 10.1016/j.autcon.2019.04.015
   Shuang D, 2015, PROCEDIA ENGINEER, V123, P125, DOI 10.1016/j.proeng.2015.10.069
   Sing CP, 2014, J CONSTR ENG M, V140, DOI 10.1061/(ASCE)CO.1943-7862.0000858
   Singaravel S, 2018, ADV ENG INFORM, V38, P81, DOI 10.1016/j.aei.2018.06.004
   STATS.gov, 2018, NATL BUR STAT CHIN S
   Stentz T., 2019, ARXIV PREPRINT ARXIV
   Steyerberg E., 2019, CLIN PREDICTION MODE, DOI DOI 10.1007/978-3-030-16399-0
   Varela-Aldás J, 2020, ADV INTELL SYST, V1026, P684, DOI 10.1007/978-3-030-27928-8_104
   Vehtari A, 2017, STAT COMPUT, V27, P1433, DOI 10.1007/s11222-016-9709-3
   Wang L, 2018, J COGNITIVE NEUROSCI, V30, P432, DOI [10.1162/jocn_a_01190, 10.1080/09205071.2017.1326850]
   Wenk N, 2023, VIRTUAL REAL-LONDON, V27, P307, DOI 10.1007/s10055-021-00565-8
   Wolf D, 2019, IEEE T VIS COMPUT GR, V25, P3169, DOI 10.1109/TVCG.2019.2932215
   Wolff A, 2019, HUM BRAIN MAPP, V40, P789, DOI 10.1002/hbm.24412
   Worksafe, 2015, HLTH SAF WORK ACT
   Wu TLY, 2019, INT J HUM-COMPUT INT, V35, P1569, DOI 10.1080/10447318.2018.1555736
   Xi WY, 2019, INT J HUM-COMPUT ST, V127, P169, DOI 10.1016/j.ijhcs.2018.09.010
   Yang LJ, 2017, EXPERT SYST APPL, V78, P347, DOI 10.1016/j.eswa.2017.02.013
   Yu Y, 2017, ASCE INT WORKSH COMP
   Yuan X, 2018, PERS INDIV DIFFER, V122, P55, DOI 10.1016/j.paid.2017.10.005
   Zhang JS, 2019, J SAFETY RES, V68, P187, DOI 10.1016/j.jsr.2018.11.006
NR 105
TC 14
Z9 14
U1 8
U2 77
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 361
EP 383
DI 10.1007/s10055-021-00572-9
EA SEP 2021
PG 23
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000692079200001
DA 2024-07-18
ER

PT J
AU Phelan, I
   Furness, PJ
   Matsangidou, M
   Babiker, NT
   Fehily, O
   Thompson, A
   Carrion-Plaza, A
   Lindley, SA
AF Phelan, Ivan
   Furness, Penny J.
   Matsangidou, Maria
   Babiker, Nathan T.
   Fehily, Orla
   Thompson, Andrew
   Carrion-Plaza, Alicia
   Lindley, Shirley A.
TI Designing effective virtual reality environments for pain management in
   burn-injured patients
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Burn injuries; Pain; Anxiety; Interactivity;
   Patient-centred design
ID BODY-IMAGE DISSATISFACTION; RUBBER HANDS FEEL; CARTOON DISTRACTION;
   ANALGESIA; HYPNOSIS; CHILDREN; THERAPY; ADJUSTMENT; STRATEGIES; DISTRESS
AB Burn patients engage in repetitive painful therapeutic treatments, such as wound debridement, dressing changes, and other medical processes high in procedural pain. Pharmacological analgesics have been used for managing pain, but with ineffective results and negative side effects. Studies on pain management for burn patients suggested that Virtual Reality can treat procedural pain. This paper describes the process of designing, testing, and deploying a Virtual Reality system into a hospital setting. Firstly, a workshop was conducted to identify the most suitable types of Virtual Reality contents for the needs of burn-injured patients. Then, an experimental study, with 15 healthy adults, explored the analgesic impact of the Virtual Reality contents. The pain was induced through a cold pressor. Finally, we deployed the Virtual Reality system into the hospital to examine its efficiency on burn-injured inpatients. This study presents factors for the effective design and deployment of Virtual Reality for burn-injured patients residing in a hospital. Those factors refer to the use of cartoonish features and a choice of content based on each patient's interests to increase the positive emotions and the use of interactive features, portable equipment to reduce pain and increase the feasibility of the technology in clinical settings. Finally, our results indicated that the extension of the VR use after the therapeutic session could support more effective pain treatment. Trial registration number Protocol ID: AA8434.
C1 [Phelan, Ivan; Matsangidou, Maria; Carrion-Plaza, Alicia; Lindley, Shirley A.] Sheffield Hallam Univ, Coll Social Sci & Arts, Ctr Culture Media & Soc, Sheffield S1 1WB, S Yorkshire, England.
   [Furness, Penny J.] Sheffield Hallam Univ, Coll Social Sci & Arts, Ctr Behav Sci & Appl Psychol CeBSAP, Sheffield S1 1WB, S Yorkshire, England.
   [Babiker, Nathan T.; Fehily, Orla] Sheffield Teaching Hosp NHS Fdn Trust, Dept Psychol Serv, Sheffield S10 2JF, S Yorkshire, England.
   [Thompson, Andrew] Univ Sheffield, Dept Psychol, Sheffield S1 2LT, S Yorkshire, England.
C3 Sheffield Hallam University; Sheffield Hallam University; University of
   Sheffield; University of Sheffield
RP Phelan, I (corresponding author), Sheffield Hallam Univ, Coll Social Sci & Arts, Ctr Culture Media & Soc, Sheffield S1 1WB, S Yorkshire, England.
EM I.Phelan@shu.ac.uk
OI CARRION-PLAZA, ALICIA/0000-0001-7815-1472; Furness,
   Penny/0000-0003-4916-8800; Thompson, Andrew/0000-0001-6788-7222; phelan,
   ivan/0000-0001-5120-8256; Matsangidou, Maria/0000-0003-3804-5565
FU UK Medical Research Council Confidence (MRC) [147828]; MRC [MC_PC_15034]
   Funding Source: UKRI
FX This study was funding by UK Medical Research Council Confidence (MRC)
   Grant No.: 147828.
CR [Anonymous], 2001, BONICAS MANAG PAIN
   Berger MM, 2010, BURNS, V36, P639, DOI 10.1016/j.burns.2009.08.009
   BERNSTEIN NORMAN R., 1965, INT J CLIN EXP HYPN, V13, P1, DOI 10.1080/00207146508412920
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   BOWER GH, 1981, AM PSYCHOL, V36, P129, DOI 10.1037/0003-066X.36.2.129
   Brown C, 2000, AM SURGEON, V66, P367
   Candas Victor, 2005, Journal of Physiological Anthropology and Applied Human Science, V24, P33, DOI 10.2114/jpa.24.33
   Capelari EDP, 2009, PERCEPTION, V38, P92, DOI 10.1068/p5892
   Carrougher GJ, 2009, J BURN CARE RES, V30, P785, DOI 10.1097/BCR.0b013e3181b485d3
   Cassidy KL, 2002, PAIN MED, V3, P108, DOI 10.1046/j.1526-4637.2002.02027.x
   Cherny N, 2001, J CLIN ONCOL, V19, P2542, DOI 10.1200/JCO.2001.19.9.2542
   CHOINIERE M, 1992, ANAESTHESIA, V47, P467, DOI 10.1111/j.1365-2044.1992.tb02266.x
   Christie MJ, 2000, CLIN EXP PHARMACOL P, V27, P520, DOI 10.1046/j.1440-1681.2000.03291.x
   Cohen LL, 1997, J PEDIATR PSYCHOL, V22, P355, DOI 10.1093/jpepsy/22.3.355
   Czub M., 2012, POL J APPL PSYCHOL, V10, P7
   Dahlquist LM, 2009, J PEDIATR PSYCHOL, V34, P574, DOI 10.1093/jpepsy/jsn023
   De Jong AE, 2013, NOTES BURN NURSING A
   Durgin FH, 2007, PSYCHOL SCI, V18, P152, DOI 10.1111/j.1467-9280.2007.01865.x
   Edwards J., 2011, WOUNDS UK, V7, P122
   Ehde DM, 1998, J BURN CARE REHABIL, V19, P436, DOI 10.1097/00004630-199809000-00014
   Fauerbach JA, 2002, HEALTH PSYCHOL, V21, P115, DOI 10.1037//0278-6133.21.2.115
   Fauerbach JA, 2000, PSYCHOSOM MED, V62, P576, DOI 10.1097/00006842-200007000-00017
   FERNANDEZ E, 1989, PAIN, V38, P123, DOI 10.1016/0304-3959(89)90230-3
   FINER BL, 1961, PLAST RECONSTR SURG, V27, P49, DOI 10.1097/00006534-196101000-00006
   Furness PJ, 2019, J BURN CARE RES, V40, P878, DOI 10.1093/jbcr/irz106
   Garrett B, 2014, CLIN J PAIN, V30, P1089, DOI 10.1097/AJP.0000000000000064
   Gold JI, 2007, CYBERPSYCHOL BEHAV, V10, P536, DOI 10.1089/cpb.2007.9993
   Gold Jeffrey I., 2011, VIRTUAL REALITY PAIN
   Gold JI, 2006, CYBERPSYCHOL BEHAV, V9, P207, DOI 10.1089/cpb.2006.9.207
   Hegedüs G, 2014, EUR J PAIN, V18, P1173, DOI 10.1002/j.1532-2149.2014.00466.x
   Hodge J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174088
   Hoffman HG, 2004, NEUROREPORT, V15, P1245, DOI 10.1097/01.wnr.0000127826.73576.91
   Hoffman HG, 2007, ANESTH ANALG, V105, P1776, DOI 10.1213/01.ane.0000270205.45146.db
   Hoffman HG, 2014, CYBERPSYCH BEH SOC N, V17, P397, DOI 10.1089/cyber.2014.0058
   Kimble R, 2006, CHI 06 HUM FACT COMP, P129, DOI [10.1145/1125451.1125482, DOI 10.1145/1125451.1125482]
   Kipping B, 2012, BURNS, V38, P650, DOI 10.1016/j.burns.2011.11.010
   Lang EV, 2000, LANCET, V355, P1486, DOI 10.1016/S0140-6736(00)02162-0
   Law EF, 2011, J PEDIATR PSYCHOL, V36, P84, DOI 10.1093/jpepsy/jsq063
   Le May S, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927934
   Lee J, 2012, ANESTH ANALG, V115, P1168, DOI 10.1213/ANE.0b013e31824fb469
   Maani CV, 2011, J TRAUMA, V71, pS125, DOI 10.1097/TA.0b013e31822192e2
   Macleod R, 2016, HEALTH PSYCHOL, V35, P1197, DOI 10.1037/hea0000391
   Mahar PD, 2012, BURNS, V38, P147, DOI 10.1016/j.burns.2011.09.015
   Markus LA, 2009, BURNS, V35, P967, DOI 10.1016/j.burns.2009.01.013
   Martin MA, 1997, ART PSYCHOTHER, V24, P447, DOI 10.1016/S0197-4556(97)00020-8
   Martini M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00438
   Matsangidou M., 2019, FEASIBILITY VIRTUAL
   Matsangidou M., 2017, Brit J Neurosci Nurs, V13, P133, DOI [10.12968/bjnn.2017.13.3.133, DOI 10.12968/BJNN.2017.13.3.133]
   Matsangidou M, 2019, PSYCHOL SPORT EXERC, V41, P218, DOI 10.1016/j.psychsport.2018.07.004
   Matsangidou M, 2017, LECT NOTES COMPUT SC, V10516, P273, DOI 10.1007/978-3-319-68059-0_18
   MELZACK R, 1965, SCIENCE, V150, P971, DOI 10.1126/science.150.3699.971
   Miller Arlene C., 1992, Journal of Burn Care and Rehabilitation, V13, P576, DOI 10.1097/00004630-199209000-00012
   Moseley GL, 2007, PAIN, V133, P64, DOI 10.1016/j.pain.2007.03.002
   Ohrbach R, 1998, CLIN J PAIN, V14, P167, DOI 10.1097/00002508-199806000-00013
   Patterson D R, 1987, J Burn Care Rehabil, V8, P263, DOI 10.1097/00004630-198707000-00005
   Patterson DR, 2004, AM J CLIN HYPN, V47, P43, DOI 10.1080/00029157.2004.10401474
   Patterson DR, 1997, J CONSULT CLIN PSYCH, V65, P60, DOI 10.1037/0022-006X.65.1.60
   Patterson DR., 2002, P AM BURN ANN M, P2
   Perry S., 1981, J BURN CARE REHABILI, V2, P322, DOI [DOI 10.1097/00004630-198111000-00004, 00004630-198111000-00004]
   Phelan I, 2019, J BURN CARE RES, V40, P85, DOI 10.1093/jbcr/iry052
   PTACEK JT, 1995, J PAIN SYMPTOM MANAG, V10, P446, DOI 10.1016/0885-3924(95)00083-B
   Richardson P, 2009, BURNS, V35, P921, DOI 10.1016/j.burns.2009.03.003
   Rose V., 2018, A Scoping Review Exploring the Feasibility of Virtual Reality Technology Use with Individuals Living with Dementia, DOI [10.2312/egve.20181325, DOI 10.2312/EGVE.20181325]
   Schmitt YS, 2011, BURNS, V37, P61, DOI 10.1016/j.burns.2010.07.007
   Schneider JC, 2017, J BURN CARE RES, V38, pE635, DOI 10.1097/BCR.0000000000000542
   Seers K, 1998, J ADV NURS, V27, P466, DOI 10.1046/j.1365-2648.1998.00538.x
   Sil S, 2014, J BEHAV MED, V37, P156, DOI 10.1007/s10865-012-9479-0
   Stoddard FJ, 2006, J AM ACAD CHILD PSY, V45, P87, DOI 10.1097/01.chi.0000184934.71917.3a
   Tabbaa L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300466
   Thombs BD, 2008, J PSYCHOSOM RES, V64, P205, DOI 10.1016/j.jpsychores.2007.09.003
   Thombs BD, 2007, GEN HOSP PSYCHIAT, V29, P14, DOI 10.1016/j.genhosppsych.2006.09.002
   WAKEMAN RJ, 1978, AM J CLIN HYPN, V21, P3
   Weinberg K, 2000, J BURN CARE REHABIL, V21, P157, DOI 10.1097/00004630-200021020-00013
   Wickens CD, 2008, HUM FACTORS, V50, P397, DOI 10.1518/001872008X288420
NR 74
TC 9
Z9 9
U1 10
U2 52
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2023
VL 27
IS 1
SI SI
BP 201
EP 215
DI 10.1007/s10055-021-00552-z
EA JUN 2021
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA C2LQ9
UT WOS:000665571300001
PM 36915632
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Gonçalves, G
   Melo, M
   Barbosa, L
   Vasconcelos-Raposo, J
   Bessa, M
AF Goncalves, Guilherme
   Melo, Miguel
   Barbosa, Luis
   Vasconcelos-Raposo, Jose
   Bessa, Maximino
TI Evaluation of the impact of different levels of self-representation and
   body tracking on the sense of presence and embodiment in immersive VR
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Embodiment; Presence; Body tracking; Body
   representation
ID VIRTUAL ENVIRONMENTS; AVATAR
AB The main goal of this paper is to investigate the effect of different types of self-representations through floating members (hands vs. hands + feet), virtual full body (hands + feet vs. full-body avatar), walking fidelity (static feet, simulated walking, real walking), and number of tracking points used (head + hands, head + hands + feet, head + hands + feet + hip) on the sense of presence and embodiment through questionnaires. The sample consisted of 98 participants divided into a total of six conditions in a between-subjects design. The HTC Vive headset, controllers, and trackers were used to perform the experiment. Users were tasked to find a series of hidden objects in a virtual environment and place them in a travel bag. We concluded that (1) the addition of feet to floating hands can impair the experienced realism (p = 0.039), (2) both floating members and full-body avatars can be used without affecting presence and embodiment (p > 0.05) as long as there is the same level of control over the self-representation, (3) simulated walking scores of presence and embodiment were similar when compared to static feet and real walking tracking data (p > 0.05), and (4) adding hip tracking overhead, hand and feet tracking (when using a full-body avatar) allows for a more realistic response to stimuli (p = 0.002) and a higher overall feeling of embodiment (p = 0.023).
C1 [Goncalves, Guilherme; Melo, Miguel; Barbosa, Luis; Vasconcelos-Raposo, Jose; Bessa, Maximino] INESC TEC, Porto, Portugal.
   [Barbosa, Luis; Vasconcelos-Raposo, Jose; Bessa, Maximino] Univ Tras Os Montes & Alto Douro, Vila Real, Portugal.
C3 INESC TEC; University of Tras-os-Montes & Alto Douro
RP Gonçalves, G (corresponding author), INESC TEC, Porto, Portugal.
EM guilhermeg@utad.pt
RI VASCONCELOS-RAPOSO, JOSE/JMB-6306-2023; VASCONCELOS-RAPOSO,
   JOSÉ/G-3743-2010; Gonçalves, Guilherme/ISS-7521-2023; Barbosa,
   Luis/S-3953-2019
OI VASCONCELOS-RAPOSO, JOSÉ/0000-0002-3456-9727; Gonçalves,
   Guilherme/0000-0002-3264-587X; Barbosa, Luis/0000-0002-6478-6669; Bessa,
   Maximino/0000-0002-3002-704X; Melo, Miguel/0000-0003-4050-3473
FU ERDF - European Regional Development Fund through the Operational
   Programme for Competitiveness and Internationalisation - COMPETE 2020
   Programme; National Funds through the Portuguese funding agency, FCT -
   Fundacao para a Ciencia e a Tecnologia [POCI01-0145-FEDER-028618]
FX This work is financed by the ERDF -European Regional Development Fund
   through the Operational Programme for Competitiveness and
   Internationalisation -COMPETE 2020 Programme and by National Funds
   through the Portuguese funding agency, FCT -Fundacao para a Ciencia e a
   Tecnologia within project POCI01-0145-FEDER-028618 entitled PERFECT
   -Perceptual Equivalence in virtual Reality For authEntiC Training.
CR [Anonymous], 2008, P 2008 ACM S VIRTUAL, DOI DOI 10.1145/1450579.1450614
   [Anonymous], 2018, 25 2018 IEEE C VIRT, DOI DOI 10.1109/VR.2018.8446229
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Biocca Frank, 2014, Social Computing and Social Media. 6th International Conference, SCSM 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8531, P421, DOI 10.1007/978-3-319-07632-4_40
   BIOCCA F, 1997, J COMPUT-MEDIAT COMM, P12, DOI DOI 10.1109/CT.1997.617676
   EA MCMANUS., 2011, P ACM SIGGRAPH S APP, P37, DOI DOI 10.1145/2077451.2077458
   George D., 2011, SPSS for windows step by step: A simple study guide and reference, V10/e
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Hambleton RK., 2011, Cross-cultural research methods in psychology, P46, DOI DOI 10.1017/CBO9780511779381.004
   Kilimann J, 2018, 2018 IEEE 1 WORKSH A, P1, DOI [10.1109/ANIVAE.2018.8587272, DOI 10.1109/ANIVAE.2018.8587272]
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Latoschik M. E., 2017, P 23 ACM S VIRT REAL, P1, DOI [10.1145/3139131.3139156, DOI 10.1145/3139131.3139156]
   LIN Q., 2013, P ACM S APPL PERCEPT, P107
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P225, DOI 10.1109/VR.2015.7223377
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P227, DOI 10.1109/VR.2015.7223378
   Melo M, 2018, COMPUT GRAPH-UK, V71, P159, DOI 10.1016/j.cag.2017.11.007
   Nakamura J., 2009, Handbook of Positive Psychology, V2nd, P194, DOI [DOI 10.1093/OXFORDHB/9780195187243.013.0018, 10.1093/oxfordhb/9780195187243.013.0018]
   Park C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1114, DOI [10.1109/VR.2019.8798345, 10.1109/vr.2019.8798345]
   Petri K., 2018, International Journal of Computer Science in Sport, V17, P1, DOI 10.2478/ijcss-2018-0001
   Reidy, 2007, STAT MATHS PSYCHOL
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Stereoarts, 2018, SAFULLBODYIK
   Tajadura-Jiménez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09497-3
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   van der Hoort B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020195
   Vasconcelos-Raposo J, 2016, PRESENCE-VIRTUAL AUG, V25, P191, DOI 10.1162/PRES_a_00261
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 35
TC 16
Z9 18
U1 2
U2 21
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2022
VL 26
IS 1
BP 1
EP 14
DI 10.1007/s10055-021-00530-5
EA MAY 2021
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA ZE7SB
UT WOS:000650833700001
DA 2024-07-18
ER

PT J
AU Park, J
   Choi, J
   Rhee, C
AF Park, Jiseob
   Choi, Junho
   Rhee, Cheul
TI Futuristic VR image presentation technique for better mobile commerce
   effectiveness
SO VIRTUAL REALITY
LA English
DT Article
DE Virtualgraph; Reality-based closed-loop 3D image; Evocativeness; Guided
   imagery; Telepresence; VR images; VR contents
ID VISUAL-IMAGERY; VIRTUAL-REALITY; PERCEIVED TASTE; IMPACT; RECALL;
   LIKELIHOOD; VIVIDNESS; INTENTION; PICTURES; QUALITY
AB Previous studies show that VR images can influence consumers' attitudes and behaviors by evoking imagination. In this study, we introduce a reality-based closed-loop 3D image (hereafter Virtualgraph). Then, we try to see whether such image would increase evocativeness in a mobile commerce environment and whether higher telepresence of the visual image of a product can increase the purchase intention of that product. In order to find the above, we developed a model comprised of constructs containing telepresence, perceived value price, perceived food quality, and vividness of visual imagery questionnaire (VVIQ). We used Virtualgraph application to conduct an experiment and then conducted an interview as well as a survey. As results of the experiment, survey, and interview, we found the followings. First, users evoke imagination better with Virtualgraph than with still images. Second, increased evocativeness affects purchase intention if the perceived quality of fresh food product is satisfactory. Third, increased evocativeness makes users value products higher and do even much higher when the perceived quality of fresh food product is good. From the interview, we could find that the experimental group had higher purchase intentions and perceived products as more expensive ones. Also, they perceived images of products clearer and more vivid than did the control group. We also discuss the strategic implications of using Virtualgraph in mobile shopping malls.
C1 [Park, Jiseob] Catholic Univ Pusan, Dept Management Informat Syst, 57 Oryundae Ro, Pusan 46252, South Korea.
   [Choi, Junho] Yonsei Univ, Grad Sch Informat, Yonsei Ro 50, Seoul 03722, South Korea.
   [Rhee, Cheul] Ajou Univ, Sch Business, San 5, Suwon 16499, South Korea.
C3 Catholic University Pusan; Yonsei University; Ajou University
RP Rhee, C (corresponding author), Ajou Univ, Sch Business, San 5, Suwon 16499, South Korea.
EM crhee@ajou.ac.kr
OI rhee, cheul/0000-0003-2673-7783
CR Albarracin D., 2014, HDB ATTITUDES
   Amedi A, 2005, NEURON, V48, P859, DOI 10.1016/j.neuron.2005.10.032
   [Anonymous], DESIGNING CONDUCTING
   [Anonymous], 1992, PRESENCE-VIRTUAL AUG, DOI [10.1162/pres.1992.1.1.109, DOI 10.1162/PRES.1992.1.1.109]
   Babin LaurieA., 1999, J RETAIL CONSUM SERV, V6, P91, DOI DOI 10.1016/S0969-6989(98)00004-6
   BARFIELD W, 1993, ADV HUM FACT ERGON, V19, P699
   Barfield W., 1995, J VIRTUAL REALITY SO, V1, P3, DOI DOI 10.1007/BF02009709
   Betts G. H, 1923, MIND ITS ED
   Bocker M, 1993, P HUM FACT ERG SOC A
   BONE PF, 1992, J CONSUM RES, V19, P93, DOI 10.1086/209289
   Brengman Malaika, 2019, Virtual Reality, V23, P269, DOI 10.1007/s10055-018-0335-6
   Chebat JC, 2010, J BUS RES, V63, P735, DOI 10.1016/j.jbusres.2009.05.009
   Cheng YW, 2007, CEREB CORTEX, V17, P1979, DOI 10.1093/cercor/bhl107
   Chin WW, 1998, QUANT METH SER, P295
   Cohen J., 1988, STAT POWER ANAL BEHA, V2nd, DOI [10.4324/9780203771587, DOI 10.4324/9780203771587]
   Coman E., 2003, IMPACT IMAGINATION C
   Cruz E, 2019, VIRTUAL REAL-LONDON, V23, P281, DOI 10.1007/s10055-018-0338-3
   Cui X, 2007, VISION RES, V47, P474, DOI 10.1016/j.visres.2006.11.013
   Cyr D, 2009, MIS QUART, V33, P539
   Day G., 1990, MARKET DRIVEN STRATE
   Ekstrom R.B., 1976, KIT FACTORREFERENCED
   Elder RS, 2010, J CONSUM RES, V36, P748, DOI 10.1086/605327
   Engel JF, 1982, CONSURNER BEHAV
   Felip F, 2020, VIRTUAL REAL-LONDON, V24, P439, DOI 10.1007/s10055-019-00406-9
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Fuehrer D, 2008, OBESITY, V16, P945, DOI 10.1038/oby.2008.33
   Gefen D, 2000, Communications of the Association for Information Systems, V4, P7, DOI [10.1016/j.emj.2021.07.010, DOI 10.1016/J.EMJ.2021.07.010, DOI 10.17705/1CAIS.00407]
   GREGORY WL, 1982, J PERS SOC PSYCHOL, V43, P89, DOI 10.1037/0022-3514.43.1.89
   Hatakeyama T, 1997, PERCEPT MOTOR SKILL, V84, P1315, DOI 10.2466/pms.1997.84.3c.1315
   Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687
   Jacoby J., 1977, INFORM PROCESSING PE, P73
   Johnson HC, 2001, THESIS
   Kim Gun-Hee, 2005, [Journal of the Korean Society of Food Science and Nutrition, 한국식품영양과학회지], V34, P1566
   Klassen AC, 2012, QUAL LIFE RES, V21, P377, DOI 10.1007/s11136-012-0122-x
   Klein LR, 2003, J INTERACT MARK, V17, P41, DOI 10.1002/dir.10046
   Lau KW, 2019, VIRTUAL REAL-LONDON, V23, P255, DOI 10.1007/s10055-018-0362-3
   Li HR, 2002, J ADVERTISING, V31, P43, DOI 10.1080/00913367.2002.10673675
   Liang CY, 2013, INT J TECHNOL DES ED, V23, P1037, DOI 10.1007/s10798-012-9224-6
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   MacKay KJ, 1997, ANN TOURISM RES, V24, P537, DOI 10.1016/S0160-7383(97)00011-X
   MAKENS JC, 1965, J APPL PSYCHOL, V49, P261, DOI 10.1037/h0022455
   MARKS DF, 1973, BRIT J PSYCHOL, V64, P17, DOI 10.1111/j.2044-8295.1973.tb01322.x
   MARKS DF, 1973, PERCEPT PSYCHOPHYS, V14, P407, DOI 10.3758/BF03211175
   MCKELVIE SJ, 1979, BRIT J PSYCHOL, V70, P51, DOI 10.1111/j.2044-8295.1979.tb02142.x
   MCKELVIE SJ, 1994, BRIT J PSYCHOL, V85, P93, DOI 10.1111/j.2044-8295.1994.tb02510.x
   Mikalef Patrick, 2013, J. theor. appl. electron. commer. res., V8, P17, DOI 10.4067/S0718-18762013000100003
   Miller G.A., 1973, COMMUNICATION LANGUA
   Nicol JJ, 2008, QUAL REP, V13, P316
   O'Donohue WT., 2004, Cognitive behavior therapy: Applying empirically supported techniques in your practice
   PAIVIO A, 1973, COGNITIVE PSYCHOL, V5, P176, DOI 10.1016/0010-0285(73)90032-7
   Park J, 2019, COMPUT HUM BEHAV, V101, P466, DOI 10.1016/j.chb.2018.08.054
   Pegler MartinM., 2006, Visual merchandising and display
   Petrova PetiaK., 2008, HDB CONSUMER PSYCHOL, P505
   Petrova PK, 2005, J CONSUM RES, V32, P442, DOI 10.1086/497556
   Pylyshyn Z, 2003, TRENDS COGN SCI, V7, P113, DOI 10.1016/S1364-6613(03)00003-2
   Richardson Alan, IMAGERY, P22
   Robertson T.S., 1971, Innovative behavior and communication
   Rodríguez-Ardura I, 2014, COMPUT HUM BEHAV, V30, P508, DOI 10.1016/j.chb.2013.06.016
   Sheridan TB, 1996, PRESENCE-TELEOP VIRT, V5, P241, DOI 10.1162/pres.1996.5.2.241
   SHERMAN SJ, 1985, PERS SOC PSYCHOL B, V11, P118, DOI 10.1177/0146167285111011
   Simmons WK, 2005, CEREB CORTEX, V15, P1602, DOI 10.1093/cercor/bhi038
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stice E, 2008, SCIENCE, V322, P449, DOI 10.1126/science.1161550
   Su KW, 2020, VIRTUAL REAL-LONDON, V24, P241, DOI 10.1007/s10055-019-00394-w
   SWANN WB, 1982, J PERS SOC PSYCHOL, V43, P475, DOI 10.1037/0022-3514.43.3.475
   Sweeney JC, 2001, J RETAILING, V77, P203, DOI 10.1016/S0022-4359(01)00041-0
   Teo HH, 2003, MIS QUART, V27, P19, DOI 10.2307/30036518
   Tusek DL, 1997, DIS COLON RECTUM, V40, P172, DOI 10.1007/BF02054983
   vanManen M, 1997, QUAL HEALTH RES, V7, P345, DOI 10.1177/104973239700700303
   Verhagen T, 2012, COMPUT HUM BEHAV, V28, P484, DOI 10.1016/j.chb.2011.10.020
   Wansink B, 2001, FOOD QUAL PREFER, V12, P69, DOI 10.1016/S0950-3293(00)00031-8
   Wells JD, 2011, MIS QUART, V35, P373
   Wilson B., 2007, Australian and New Zealand Marketing Academy Conference, Otago, Australia, P791
   WRIGHT P, 1980, J CONSUM RES, V7, P176, DOI 10.1086/208805
   Wu CM, 2017, VIRTUAL REAL-LONDON, V21, P19, DOI 10.1007/s10055-016-0296-6
   Zampini M, 2004, J SENS STUD, V19, P347, DOI 10.1111/j.1745-459x.2004.080403.x
   ZEITHAML VA, 1982, J CONSUM RES, V8, P357, DOI 10.1086/208876
   Zhang KZK, 2016, DECIS SUPPORT SYST, V86, P95, DOI 10.1016/j.dss.2016.04.001
   Zmud R. W., 1993, Journal of Management Information Systems, V9, P175
NR 79
TC 6
Z9 6
U1 0
U2 27
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2021
VL 25
IS 2
BP 341
EP 356
DI 10.1007/s10055-020-00459-1
EA JUL 2020
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA SE2QO
UT WOS:000550596100001
DA 2024-07-18
ER

PT J
AU Glueck, AC
   Han, DY
AF Glueck, Amanda C.
   Han, Dong Y.
TI Improvement potentials in balance and visuo-motor reaction time after
   mixed reality action game play: a pilot study
SO VIRTUAL REALITY
LA English
DT Article
DE Mixed reality; Action games; Visuo-motor; Reaction time; Balance
ID ACTION VIDEO GAMES; VESTIBULAR REHABILITATION; EXPERIENCE; DIZZINESS;
   TASK
AB Over the past several decades, there has been much interest regarding the effects of video game play. Research has evaluated the behavioral, cognitive, and psychological effects of video game play, and found individuals who play games using complex and dynamic game settings and require focused attention with quick responses, such as action video games, demonstrate improved cognitive performance. Action video game training has also yielded rehabilitation efficacy for a myriad of patients, such as stroke patients and individuals with vestibular and balance deficits. Recently, new technology platforms have been developed such as mixed reality (MR); however, little to no research has been conducted examining the effects of advanced technology platforms. The purpose of the current study was to explore whether MR game training improved visuo-motor reaction time and balance performances. Fourteen participants (11 male; 18-50 years of age) underwent baseline and post-intervention assessments, and then complete 8 h of MR action game training. Visuo-motor reaction times were obtained via computerized Automated Neurocognitive Assessment Metric testing and balance measures were obtained via Sensory Organizational Testing. Baseline and post-intervention comparisons were analyzed using Wilcoxon signed-rank tests. Baseline and post-intervention visuo-motor reaction time and balance comparisons revealed that MR game training yielded significant reaction time improvements (p < 0.05) and vestibular performances (p < 0.05) following game training. Our results suggest visuo-motor reaction time and balance performances were significantly improved following of 8 h of action MR game training.
C1 [Glueck, Amanda C.; Han, Dong Y.] Univ Kentucky, Dept Neurol, Lexington, KY 40536 USA.
   [Han, Dong Y.] Univ Kentucky, Dept Neurosurg, Lexington, KY 40506 USA.
   [Han, Dong Y.] Univ Kentucky, Dept Phys Med & Rehabil, Lexington, KY 40506 USA.
   [Han, Dong Y.] Univ Kentucky, Spinal Cord & Brain Injury Res Ctr, Lexington, KY 40506 USA.
C3 University of Kentucky; University of Kentucky; University of Kentucky;
   University of Kentucky
RP Han, DY (corresponding author), Univ Kentucky, Dept Neurol, Lexington, KY 40536 USA.; Han, DY (corresponding author), Univ Kentucky, Dept Neurosurg, Lexington, KY 40506 USA.; Han, DY (corresponding author), Univ Kentucky, Dept Phys Med & Rehabil, Lexington, KY 40506 USA.; Han, DY (corresponding author), Univ Kentucky, Spinal Cord & Brain Injury Res Ctr, Lexington, KY 40506 USA.
EM d.han@uky.edu
RI Glueck, Amanda/HJZ-4598-2023
OI Glueck, Amanda/0000-0002-1978-5165
CR Alsalaheen BA, 2013, PHYSIOTHER RES INT, V18, P100, DOI 10.1002/pri.1532
   Anguera JA, 2013, NATURE, V501, P97, DOI 10.1038/nature12486
   Bavelier D, 2012, ANNU REV NEUROSCI, V35, P391, DOI 10.1146/annurev-neuro-060909-152832
   Bialystok E, 2006, CAN J EXP PSYCHOL, V60, P68, DOI 10.1037/cjep2006008
   Castel AD, 2005, ACTA PSYCHOL, V119, P217, DOI 10.1016/j.actpsy.2005.02.004
   Cernich A, 2007, ARCH CLIN NEUROPSYCH, V22, pS101, DOI 10.1016/j.acn.2006.10.008
   Chandra S, 2016, PROCEDIA COMPUT SCI, V84, P115, DOI 10.1016/j.procs.2016.04.074
   Chanpimol Shane, 2017, Arch Physiother, V7, DOI 10.1186/s40945-017-0033-9
   Clark K, 2011, ACTA PSYCHOL, V136, P67, DOI 10.1016/j.actpsy.2010.10.003
   Cole WR, 2013, ARCH CLIN NEUROPSYCH, V28, P732, DOI 10.1093/arclin/act040
   Cook MR, 2002, PSYCHOPHARMACOLOGY, V162, P186, DOI 10.1007/s00213-002-1074-6
   Cuthbert JP, 2014, BRAIN INJURY, V28, P181, DOI 10.3109/02699052.2013.860475
   Franceschini S, 2013, CURR BIOL, V23, P462, DOI 10.1016/j.cub.2013.01.044
   Green CS, 2012, CURR BIOL, V22, pR197, DOI 10.1016/j.cub.2012.02.012
   Green CS, 2015, CURR OPIN BEHAV SCI, V4, P103, DOI 10.1016/j.cobeha.2015.04.012
   Green CS, 2010, CURR BIOL, V20, P1573, DOI 10.1016/j.cub.2010.07.040
   Green CS, 2003, NATURE, V423, P534, DOI 10.1038/nature01647
   Herdman SJ., 2014, VESTIBULAR REHABILIT, VFourth
   Li RW, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1001135
   Lo Bue-Estes C, 2008, PERCEPT MOTOR SKILL, V107, P933, DOI 10.2466/PMS.107.3.933-945
   McDermott AF, 2014, COMPUT HUM BEHAV, V34, P69, DOI 10.1016/j.chb.2014.01.018
   Micarelli A, 2017, INT J REHABIL RES, V40, P325, DOI 10.1097/MRR.0000000000000244
   NASHNER LM, 1990, NEUROL CLIN, V8, P331, DOI 10.1016/S0733-8619(18)30359-1
   Pavlou M, 2004, J NEUROL, V251, P983, DOI 10.1007/s00415-004-0476-2
   Pavlou M, 2011, GAIT POSTURE, V33, P113, DOI 10.1016/j.gaitpost.2010.10.085
   Phillips JS, 2018, J LARYNGOL OTOL, V132, P202, DOI 10.1017/S0022215118000075
   Reeves DL, 2007, ARCH CLIN NEUROPSYCH, V22, pS15, DOI 10.1016/j.acn.2006.10.013
   Shumway-Cook A., 2007, VESTIBULAR REHABILIT, V3rd, P444
   Strobach T, 2012, ACTA PSYCHOL, V140, P13, DOI 10.1016/j.actpsy.2012.02.001
   Trueblood PR, 2018, ACTA OTO-LARYNGOL, V138, P597, DOI 10.1080/00016489.2018.1429653
   Wrisley DM, 2007, ARCH PHYS MED REHAB, V88, P1049, DOI 10.1016/j.apmr.2007.05.003
NR 31
TC 15
Z9 15
U1 4
U2 42
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2020
VL 24
IS 2
BP 223
EP 229
DI 10.1007/s10055-019-00392-y
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA LH2FV
UT WOS:000528603800003
DA 2024-07-18
ER

PT J
AU Anderson, A
   Boppana, A
   Wall, R
   Acemyan, CZ
   Adolf, J
   Klaus, D
AF Anderson, Allison
   Boppana, Abhishektha
   Wall, Ryan
   Acemyan, Claudia Ziegler
   Adolf, Jurine
   Klaus, David
TI Framework for developing alternative reality environments to engineer
   large, complex systems
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Augmented reality; Hybrid reality; Spacecraft design
ID VIRTUAL-REALITY; BUILT ENVIRONMENT; DESIGN; IMMERSION; TAXONOMY;
   FIDELITY; TACTILE
AB We present a framework for alternative reality (XR) technologies to enable an understanding of what constitutes an XR environment when used in the context of design and engineering of large, complex systems. The framework provides guidelines for implementing the corresponding desired human sensory experience. This work is founded on the existing literature which defines theoretical Spectra, such as Fidelity, to systematically characterize an XR environment taxonomy. We identify landmarks for four XR categories within these Spectra and provide definitions that can used to establish a common vernacular. We further map these to specific human sensing modalities that are influenced by XR, such as tactility and vision, and define the technical requirements needed to augment the human experience in the desired XR environment. Finally, we connect the theoretical elements to the technical requirements to create an integrated XR framework. The utility of this framework is demonstrated in a case study addressing the use of XR technologies for five stakeholder groups involved in the evaluation of spacecraft habitat design and operations. This demonstrates the utility of the proposed XR taxonomy in a spacecraft habitat design process, which could be extended to other similar applications.
C1 [Anderson, Allison; Boppana, Abhishektha; Wall, Ryan; Klaus, David] Univ Colorado, Smead Dept Aerosp Engn Sci, Boulder, CO 80309 USA.
   [Acemyan, Claudia Ziegler; Adolf, Jurine] NASA, Johnson Space Ctr, Human Res Program, Human Factors & Behav Performanc Element, Houston, TX USA.
   [Acemyan, Claudia Ziegler] Rice Univ, Dept Psychol Sci, Houston, TX USA.
C3 University of Colorado System; University of Colorado Boulder; National
   Aeronautics & Space Administration (NASA); NASA Johnson Space Center;
   Rice University
RP Anderson, A; Boppana, A (corresponding author), Univ Colorado, Smead Dept Aerosp Engn Sci, Boulder, CO 80309 USA.
EM apanders@colorado.edu; abhishektha@colorado.edu; rywa3960@colorado.edu;
   claudiaz@rice.edu; jurine.a.adolf@nasa.gov; klaus@colorado.edu
RI Anderson, Allison/AAY-6536-2020
OI Anderson, Allison/0000-0001-7808-8557; Boppana,
   Abhishektha/0000-0003-4260-0488
FU NASA Human Research Program [80NSSC18K0198]
FX This work was funded by the NASA Human Research Program, Grant
   80NSSC18K0198.
CR Acemyan CZ, 2018, J ENVIRON PSYCHOL, V56, P30, DOI 10.1016/j.jenvp.2018.02.006
   Adams E., 2017, WIRED
   [Anonymous], 2011, NASASTD3001
   [Anonymous], 2008, SPACE PSYCHOL PSYCHI
   Arayici Y., 2011, Structural Survey, V29, P7, DOI 10.1108/02630801111118377
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Begault Durand R, 2000, 3 SOUND VIRTUAL REAL
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Castronovo F, 2013, COMPUTERS AIDED DESI, V9, P892
   Cohen M, 2012, MOCKUPS 101 CODE STA, DOI [10.2514/6.2012-5153., DOI 10.2514/6.2012-5153]
   Dubois Emmanuel., 2010, ENG MIXED REALITY SY
   Eastman C.M., 2008, BIM Handbook: A Guide to Building Information Modeling for Owners, Managers, Designers, Engineers and Contractors
   Engelberg D, 2002, INT FED INFO PROC, V99, P203
   Fishkin KP, 2004, PERS UBIQUIT COMPUT, V8, P347, DOI 10.1007/s00779-004-0297-4
   Goulding JS, 2014, J INF TECHNOL CONSTR, V19, P308
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Hale KS, 2009, ERGONOMICS, V52, P187, DOI 10.1080/00140130802376000
   Hammond W.E., 1999, AIAA EDUC S
   Hays T, 1980, 490 US ARM RES I BEH
   Hettinger L.J., 1992, Presence: Teleoperators & Virtual Environments, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Heydarian A, 2015, AUTOMAT CONSTR, V54, P116, DOI 10.1016/j.autcon.2015.03.020
   Higdon K. P., 2008, PROC 11 BIENNIAL ASC, P1, DOI [10.1061/40988(323)96, DOI 10.1061/40988(323)96]
   Ishii H., 2008, TANGIBLE BITS PIXELS
   KELLY DH, 1979, J OPT SOC AM, V69, P1340, DOI 10.1364/JOSA.69.001340
   Kim M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051141
   Klaus DM, 2009, INT C ENV SYST, V8
   Larsson P, 2010, HUM-COMPUT INT-SPRIN, P143, DOI 10.1007/978-1-84882-733-2_8
   Leithinger D, 2015, IEEE COMPUT GRAPH, V35, P5, DOI 10.1109/MCG.2015.111
   Lentz T, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/70540
   Liu D, 2009, HUMAN FACTORS SIMULA, V13, P561
   Mackay W.E., 1998, Proceedings of the working conference on Advanced visual interfaces, P13
   Maldovan KD, 2006, FRAMEWORK REV MOCKUP, V7
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mugge W, 2013, EXP BRAIN RES, V224, P635, DOI 10.1007/s00221-012-3341-z
   Mulenburg GM, 2002, DESIGN PROTOTYPE EXA
   NASA, 2020, NASA System Engineering Handbook
   Nolle S, 2006, AUGMENTED REALITY CO, P249, DOI [10.1109/ISMAR.2006.297829., DOI 10.1109/ISMAR.2006.297829]
   Paige JB, 2013, CLIN SIMUL NURS, V9, pE481, DOI 10.1016/j.ecns.2013.01.001
   Pamungkas D. S., 2016, International Journal of Computer Theory and Engineering, V8, P465, DOI 10.7763/IJCTE.2016.V8.1090
   Peter Z., 2008, PRODUCT ENG TOOLS ME, P277
   Picinali L, 2014, INT J HUM-COMPUT ST, V72, P393, DOI 10.1016/j.ijhcs.2013.12.008
   Pontonnier C, 2014, J MULTIMODAL USER IN, V8, P199, DOI 10.1007/s12193-013-0138-8
   Riecke BE, NFLUENCE AUDITORY CU, V9, DOI 10.1.1.490.7866&rep=rep1&type=pdf
   Robinett W., 1992, PRESENCE, V1, P229, DOI [10.1162/pres.1992.1.2.229, DOI 10.1162/PRES.1992.1.2.229]
   Rudd Jim, 1996, Interactions, V3, P76, DOI DOI 10.1145/223500.223514
   Ryu J, 2007, J ASIAN ARCHIT BUILD, V6, P57, DOI 10.3130/jaabe.6.57
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Sheridan T., 1992, Presence: Teleoperators and Virtual Environments, V1, P120, DOI DOI 10.1162/PRES.1992.1.1.120
   Västfjäll D, 2003, CYBERPSYCHOL BEHAV, V6, P181, DOI 10.1089/109493103321640374
   Whitmore Mihriban., 2013, Evidence Report: Risk of Incompatible Vehicle/Habitat Design
   Zeltzer D., 1992, Presence: Teleoperators Virtual Environments, V1, P127, DOI [DOI 10.1162/PRES.1992.1.1.127, 10.1162/pres.1992.1.1.127]
NR 51
TC 10
Z9 10
U1 1
U2 5
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2021
VL 25
IS 1
BP 147
EP 163
DI 10.1007/s10055-020-00448-4
EA MAY 2020
PG 17
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA QI2JK
UT WOS:000534980900001
DA 2024-07-18
ER

PT J
AU Casas, S
   Portalés, C
   Morillo, P
   Fernandez, M
AF Casas, Sergio
   Portales, Cristina
   Morillo, Pedro
   Fernandez, Marcos
TI To move or not to move? Analyzing motion cueing in vehicle simulators by
   means of massive simulations
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Motion cueing; Motion platform; Vehicle simulator;
   Massive simulation; Particle swarm optimization
ID DRIVING SIMULATOR; ALGORITHMS; SYSTEM; DESIGN; MODEL; PLATFORM
AB Motion platforms and motion cueing algorithms (MCA) have been included in virtual reality applications for several decades. They are necessary to provide suitable inertial cues in vehicle simulators. However, the great number of operational constraints that these devices and algorithms suffer, namely limited physical space, elevated costs, absence of sufficient power, difficulty of tuning and lack of standardized assessment methods, have hindered their widespread use. This work tries to clarify open questions in the field, such as: How important is MCA tuning? How much does size, number of DOF and power/latency matter? Can the absence of motion be better than poor motion cueing? What are the key factors that should be addressed to enhance the design of these devices? Although absolute certain answers cannot be given, this paper tries to clarify these research questions by performing massive experiments with simulated motion platforms of different types, sizes and powers. The information obtained from these experiments will be important to customize the design of real devices for this particular use. Ideally, subjective experiments with human experts would have been preferred. However, the use of simulated devices allows comparing many different motion platforms. In this paper, forty of these devices are simulated, optimized by means of a heuristic algorithm and compared with objective indicators in order to measure their relative performance using the classical MCA, something that would require an unreasonable amount of effort with real users and real devices. The obtained results show that MCA tuning is of the utmost importance in motion cueing. They also suggest that high power can usually compensate for lack of size and that a 6-DOF motion platform slightly improves the performance of a 3-DOF motion platform.
C1 [Casas, Sergio; Portales, Cristina; Morillo, Pedro; Fernandez, Marcos] Univ Valencia, Valencia, Spain.
C3 University of Valencia
RP Casas, S (corresponding author), Univ Valencia, Valencia, Spain.
EM Sergio.Casas@uv.es
RI Morillo, Pedro/ABG-8408-2020; Portalés, Cristina/K-2296-2015; Casas
   Yrurzum, Sergio/S-3693-2017; Fernández, Marcos/JDC-9198-2023
OI Portalés, Cristina/0000-0002-4520-2250; Casas Yrurzum,
   Sergio/0000-0002-0396-4628; Fernandez Marin, Marcos/0000-0002-0307-0392;
   Morillo, Pedro/0000-0002-9506-9611
CR Advani S., 2007, AIAA MOD SIM TECHN C
   [Anonymous], NASATP1999208766
   [Anonymous], ROYAL AER SOC C CUTT
   Arioui H, 2009, IEEE ASME INT C ADV, P1199
   Arioui H, 2011, IEEE T VEH TECHNOL, V60, P357, DOI 10.1109/TVT.2010.2090675
   Asadi H, 2016, 2016 IEEE INT C SYST
   Asadi H, 2017, IEEE T SYST MAN CY-S, V47, P238, DOI 10.1109/TSMC.2016.2523906
   Asadi H, 2015, VEHICLE SYST DYN, V53, P526, DOI 10.1080/00423114.2014.1003948
   Bailey R, 1987, FLIGHT SIM TECHN C
   Berger DR, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658354
   Bertollini G, 2014, P DRIV SIM C PAR
   Bruenger-Koch M, 2005, DRIV SIM C N AM DSC
   Bruenger-Koch M., 2006, DRIV SIM C AS PAC TS
   Bruschetta M, 2017, VEHICLE SYST DYN, V55, P802, DOI 10.1080/00423114.2017.1280173
   BURKICOHEN J, 2001, P AIAA MOD SIM TECHN
   Calabro FJ, 2011, P ROY SOC B-BIOL SCI, V278, P2840, DOI 10.1098/rspb.2010.2757
   Casas S., 2017, International Journal of Virtual and Augmented Reality (IJVAR), V1, P90, DOI [10.4018/IJVAR.2017010107, DOI 10.4018/IJVAR.2017010107]
   Casas S, 2018, MECHATRONICS, V53, P251, DOI 10.1016/j.mechatronics.2018.06.008
   Casas S, 2018, APPL SOFT COMPUT, V68, P125, DOI 10.1016/j.asoc.2018.03.044
   Casas S, 2017, REV IBEROAM AUTOM IN, V14, P455, DOI 10.1016/j.riai.2017.07.001
   Casas S, 2017, J ADV MECH DES SYST, V11, DOI 10.1299/jamdsm.2017jamdsm0023
   Casas S, 2016, SIMUL MODEL PRACT TH, V67, P137, DOI 10.1016/j.simpat.2016.06.002
   Casas S, 2015, HUM FACTORS, V57, P144, DOI 10.1177/0018720814538281
   Colombet F, 2008, DRIV SIM C MONT CARL
   Conrad B., 1971, CR114345 NASA
   Dagdelen M, 2009, CONTROL ENG PRACT, V17, P995, DOI 10.1016/j.conengprac.2009.03.002
   DNV, 2011, STAND CERT MAR SIM S
   Draper MH, 2001, HUM FACTORS, V43, P129, DOI 10.1518/001872001775992552
   Fischer M, 2009, BERICHTE DLRINSTITUT
   Fischer M, 2007, 2 MOT SIM C BRAUNWSC
   Fischer M, 2010, DRIV SIM C EUR PAR F
   FRANK LH, 1988, HUM FACTORS, V30, P201, DOI 10.1177/001872088803000207
   Garrett N.J.I., 2010, C CONTR
   Garrett NJI, 2013, VEHICLE SYST DYN, V51, P1151, DOI 10.1080/00423114.2013.783219
   GOUVERNEUR B, 2003, AIAA MOD SIM TECHN C
   Grant P.R., 1996, The Development of a Tuning Paradigm for Flight Simulator Motion Drive Algorithms
   Grant PR, 2009, VEHICLE SYST DYN, V47, P1075, DOI 10.1080/00423110802450185
   Grant PR, 1997, J AIRCRAFT, V34, P152, DOI 10.2514/2.2166
   Grant PR, 1997, J AIRCRAFT, V34, P145, DOI 10.2514/2.2158
   Groen EL, 2004, J VESTIBUL RES-EQUIL, V14, P375
   Hosman R, 2016, AERONAUT J, V120, P873, DOI 10.1017/aer.2016.35
   Huang ARW, 2003, IEEE T VEH TECHNOL, V52, P162, DOI 10.1109/TVT.2002.807157
   Icao S, 2009, MANUAL CRITERIA QUAL
   Izaguirre E, 2011, REV IBEROAM AUTOM IN, V8, P345, DOI 10.1016/j.riai.2011.09.003
   Jakobovi D, 2002, 8 INT SCI C PROD ENG
   Jansson J., 2014, DRIV SIM C
   Jones M., 2017, CEAS Aeronautical Journal, V8, P523
   Kemeny A, 1999, Introduction de la conference sur la simulation de conduite
   Kluver M, 2015, P DRIV SIM C TUB GER
   Kurosaki M., 1978, IFAC P, V11, P1311, DOI DOI 10.1016/S1474-6670(17)66089-0
   Laurens J, 2007, BIOL CYBERN, V96, P389, DOI 10.1007/s00422-006-0133-1
   MacNeilage PR, 2007, EXP BRAIN RES, V179, P263, DOI 10.1007/s00221-006-0792-0
   Mauro S., 2016, International Journal of Applied Engineering Research, V11, P9436
   Mohammadi A, 2018, EXPERT SYST APPL, V92, P73, DOI 10.1016/j.eswa.2017.09.004
   NAHON MA, 1990, J GUID CONTROL DYNAM, V13, P356, DOI 10.2514/3.20557
   NAHON MA, 1992, J GUID CONTROL DYNAM, V15, P376, DOI 10.2514/3.20846
   Nehaoua L., 2005, P 13 MED C CONTR AUT
   Nehaoua L, 2007, AM CONTR C 2007 ACC
   Nehaoua L, 2006, ICRA 2006
   Nehaoua L, 2008, IEEE T VEH TECHNOL, V57, P736, DOI 10.1109/TVT.2007.905336
   Optitrack, 2018, MOT CAPT SYST
   Page LR, 2000, SIMTECT 2000 P SYDN
   Pais ARV, 2009, PRESENCE-TELEOP VIRT, V18, P200, DOI 10.1162/pres.18.3.200
   Parrish R. V., 1975, Journal of Aircraft, V12, P44, DOI 10.2514/3.59800
   Parrish RV, 1973, AIAA VIS MOT SIM C P
   Pham D, 2015, OPTIMAL MOTION CUEIN, P127
   Pouliot NA, 1998, J AIRCRAFT, V35, P9, DOI 10.2514/2.2283
   Reid L.D., 1986, FLIGHT SIMULATION MO
   REID LD, 1988, J AIRCRAFT, V25, P639, DOI 10.2514/3.45635
   Reid LD, 1986, FLIGHT SIMULATION 2, P307
   Reid LD, 1985, FLIGHT SIMULATION 1, P296
   Reymond G, 2000, VEHICLE SYST DYN, V34, P249, DOI 10.1076/vesd.34.4.249.2059
   Romano RA, 2016, SAE TECHNICAL PAPER
   Royal-Aeronautical-Society, 1979, 50 YEARS FLIGHT SIM
   Salisbury IG, 2016, IEEE T CONTR SYST T, V24, P200, DOI 10.1109/TCST.2015.2424161
   Schmidt S., 1969, CALCULATION MOTION D
   Schmidt S. F., 1970, MOTION DRIVE SIGNALS
   Schroeder JA, 2000, J AIRCRAFT, V37, P580, DOI 10.2514/2.2669
   Schwarz CW, 2007, IEEE T SYST MAN CY A, V37, P562, DOI 10.1109/TSMCA.2007.897590
   Sinacori JB, 1977, DETERMINATION SOME R, V7805
   SIVAN R, 1982, IEEE T SYST MAN CYB, V12, P818, DOI 10.1109/TSMC.1982.4308915
   Slob J. J., 2008, STATE ART DRIVING SI
   Stahl K, 2014, 17 INT C INT TRANSP
   Stewart D., 1965, P I MECH ENG
   Stroosma O, 2013, AIAA MOD SIM TECHN M
   Telban Robert J., 2005, Technical Report
   Teufel H, 2007, AIAA MOD SIM TECHN C, P1
   Thondel E, 2012, EUR SIM MOD C ESM ES
   Wiskemann CM, 2014, AM HELICOPTER SOC 70
   [No title captured]
NR 90
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2020
VL 24
IS 1
BP 93
EP 108
DI 10.1007/s10055-019-00387-9
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA KI8QC
UT WOS:000511621800006
DA 2024-07-18
ER

PT J
AU Tang, YM
   Au, KM
   Lau, HCW
   Ho, GTS
   Wu, CH
AF Tang, Y. M.
   Au, K. M.
   Lau, H. C. W.
   Ho, G. T. S.
   Wu, C. H.
TI Evaluating the effectiveness of learning design with mixed reality (MR)
   in higher education
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Mixed reality; Extended reality; Education; Learning;
   HoloLens; University; Design
ID VIRTUAL-REALITY; MODEL
AB Virtual reality (VR) is rapidly developed and bringing advancement in various related technologies through the virtual world. It has high potential and plays an important role in education and training fields. Mixed reality (MR) is a type of hybrid system that involves both physical and virtual elements. While VR/MR has proved to be an effective way to improve the learning attitude and effectiveness for secondary students, however, not much work has been conducted on university students to compare the MR experience and traditional teaching approaches in learning design subjects. In this project, we investigated the effectiveness of students in learning design subjects with the support of MR. The effectiveness was measured based on their creativity and systematic approaches in design. Pretests and posttests were conducted to measure the learning effects. We also compared the learning effectiveness of a student's study with the MR and traditional teaching materials. Nonparametric analyses were conducted to investigate whether the improvements were significant. Experimental results showed that after studying with the support of the MR technology, the students' abilities in geometric analysis (mean difference = 4.36, p < 0.01) and creativity (mean difference = 1.59, p < 0.05) were significantly improved. The students' ability in model visualization was also significantly better than the control group (mean difference = 3.08, p < 0.05). It indicated that the results were positive by using the MR to support their study. The MR was also better than using traditional teaching notes in various measured effects.
C1 [Tang, Y. M.] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hung Hom, Kowloon, Hong Kong, Peoples R China.
   [Au, K. M.] HKU Sch Profess & Continuing Educ SPACE, Community Coll, Kowloon Bay, Kowloon, Hong Kong, Peoples R China.
   [Lau, H. C. W.] Western Univ Sydney, Sch Business, Penrith, NSW 2751, Australia.
   [Ho, G. T. S.; Wu, C. H.] Hang Seng Univ Hong Kong, Dept Supply Chain & Informat Management, Siu Lek Yuen, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; Western Sydney University; Hang Seng
   University of Hong Kong
RP Tang, YM (corresponding author), Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hung Hom, Kowloon, Hong Kong, Peoples R China.
EM mfymtang@polyu.edu.hk
RI WU, Chun Ho/H-8815-2012; Tang, YM/AAF-2055-2020
OI WU, Chun Ho/0000-0003-1259-4048; Tang, YM/0000-0001-8215-4190; Ho,
   G.T.S./0000-0002-8550-4974; Lau, HCW/0000-0001-8500-5684; AU, Kin Man,
   Kenneth,/0000-0002-9653-2997
FU Learning and Teaching Development Grant from the Hong Kong Polytechnic
   University, the Hong Kong Special Administrative Region, China
   [LTG16-19/SS/ISE1]
FX The author(s) received financial support by the Learning and Teaching
   Development Grant (LTG16-19/SS/ISE1) from the Hong Kong Polytechnic
   University, the Hong Kong Special Administrative Region, China, for the
   research, authorship and/or publication of this article.
CR Abramovici M, 2013, CIRP ANN-MANUF TECHN, V62, P159, DOI 10.1016/j.cirp.2013.03.076
   Al Janabi HF, 2020, SURG ENDOSC, V34, P1143, DOI 10.1007/s00464-019-06862-3
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   [Anonymous], HOLOLENS HARDW DET
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Barfield Woodrow., 2016, Fundamentals of wearable computers and augmented reality, V2nd
   Bates BN, 2012, VIRTUAL REALITY
   Bidarra J, 2017, OPEN LEARN, V32, P6, DOI 10.1080/02680513.2016.1265442
   Bideau B, 2010, IEEE COMPUT GRAPH, V30, P14, DOI 10.1109/MCG.2009.134
   Coyne L, 2018, CURR PHARM TEACH LEA, V10, P1384, DOI 10.1016/j.cptl.2018.07.005
   Dávideková M, 2017, PROCEDIA COMPUT SCI, V113, P253, DOI 10.1016/j.procs.2017.08.365
   Drexel University, 2018, HOLOLENS MIX REAL LE
   Fast-Berglund Å, 2018, PROCEDIA MANUF, V25, P31, DOI 10.1016/j.promfg.2018.06.054
   Friesike S, 2019, J OPER MANAG, V65, P735, DOI 10.1016/j.jom.2018.10.004
   Gownder J., 2016, Breakout vendors: Virtual and augmented reality"
   Hayes A.T., 2013, SYSTEMS APPL, P142
   Hayes AT, 2013, INT J GAMING COMPUT-, V5, P20, DOI 10.4018/jgcms.2013040102
   Hughes CE, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.139
   Jayaram S, 1997, COMPUT AIDED DESIGN, V29, P575, DOI 10.1016/S0010-4485(96)00094-2
   Jung T., 2015, INFORM COMMUNICATION, DOI 10.1007/978-3-319-28231-2
   Ke FF, 2016, COMPUT HUM BEHAV, V62, P212, DOI 10.1016/j.chb.2016.03.094
   Khan WA, 2011, SPRINGER SER ADV MAN, P1, DOI 10.1007/978-0-85729-186-8_1
   Laurillard D, 2013, J COMPUT ASSIST LEAR, V29, P15, DOI 10.1111/j.1365-2729.2011.00458.x
   Lele A, 2013, J AMB INTEL HUM COMP, V4, P17, DOI 10.1007/s12652-011-0052-4
   Liarokapis F., 2010, P 31 ANN C EUR ASS C, P9, DOI DOI 10.2312/EGED.20101010
   Lutters E, 2014, CIRP ANN-MANUF TECHN, V63, P607, DOI 10.1016/j.cirp.2014.05.010
   Meyer OA, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103603
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mizell D.W., 1992, P 25 HAW INT C SYST, VVolume 2, P659, DOI [DOI 10.1109/HICSS.1992.183317, 10.1109/HICSS.1992.183317]
   Molina KI, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-156
   Müller C, 2018, J INTEGR BIOINFORMAT, V15, DOI 10.1515/jib-2018-0005
   Neumann U, 1998, P IEEE VIRT REAL ANN, P4, DOI 10.1109/VRAIS.1998.658416
   Nikolakis G, 2004, LECT NOTES COMPUTER, V3025, DOI [10.1007/978-3-540-24674-9_11, DOI 10.1007/978-3-540-24674-9_11]
   Nisha B, 2019, EDUC PSYCHOL-UK, V39, P1233, DOI 10.1080/01443410.2019.1661356
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Parveau M, 2018, PROCEDIA COMPUT SCI, V141, P263, DOI 10.1016/j.procs.2018.10.180
   Pena-Rios A, 2016, THESIS
   Petrovici MA, 2013, PROCD SOC BEHV, V93, P146, DOI 10.1016/j.sbspro.2013.09.168
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Regenbrecht H, 2005, IEEE COMPUT GRAPH, V25, P48, DOI 10.1109/MCG.2005.124
   Riva G, 2002, CYBERPSYCHOL BEHAV, V5, P219, DOI 10.1089/109493102760147213
   Syberfeldt A, 2017, IEEE ACCESS, V5, P9118, DOI 10.1109/ACCESS.2017.2703952
   Tang YM, 2018, INT J ENG BUS MANAG, V10, DOI 10.1177/1847979018809599
   Unity, 2018, UN BERL 2018
   Wang XY, 2009, IEEE SYS MAN CYBERN, P3569, DOI 10.1109/ICSMC.2009.5346691
   Whyte J.K., 2003, Construction Management and Econo- mics, V21, P565
NR 46
TC 74
Z9 79
U1 23
U2 119
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD DEC
PY 2020
VL 24
IS 4
BP 797
EP 807
DI 10.1007/s10055-020-00427-9
EA FEB 2020
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA OC5AD
UT WOS:000517004400001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Faust, FG
   Catecati, T
   Sierra, ID
   Araujo, FS
   Ramírez, ARG
   Nickel, EM
   Ferreira, MGG
AF Faust, Fernanda Gomes
   Catecati, Tiago
   Sierra, Isabella de Souza
   Araujo, Fernanda Steinbruch
   Garcia Ramirez, Alejandro Rafael
   Nickel, Elton Moura
   Gomes Ferreira, Marcelo Gitirana
TI Mixed prototypes for the evaluation of usability and user experience:
   simulating an interactive electronic device
SO VIRTUAL REALITY
LA English
DT Article
DE Product prototyping; Augmented reality; Mixed prototyping; Usability;
   User experience
ID AUGMENTED REALITY; DESIGN EVALUATION; VIRTUAL-REALITY; SYSTEM
AB Mixed prototyping technology can be used to represent and simulate the behavior of interactive products at low cost and with great flexibility. This preliminary experimental research intends to verify the suitability of using this technology in the evaluation of usability and user experience of interactive products. Users and experts evaluate the mixed prototype of an image projector with regard to its own usability, and also with respect to its ability to be used to evaluate usability and user experience aspects of the real projector. Users perform tasks on both the real projector and its mixed prototype. In regard to these comparative performance evaluations, time to perform the task and number of errors show a clear positive relationship with the difficulty of the task for both mixed prototype and real projector. In regard to more subjective UX evaluations, the results show to be congruent. However, we realize that emotions assigned to the mixed prototype are influenced by the fascination that augmented reality arises in individuals. Experts evaluate the mixed prototype with respect to aspects of the interaction with the product that it is able to simulate, and with respect to the classes of products best suited to be prototyped. They highlighted the possibility of using the technology to evaluate product performance, ergonomics, and operation. In regard to the classes of products to be prototyped, experts' suggestions coincided with the classes of products that have already been used in research: household appliances, information and communication devices, and automotive parts and accessories.
C1 [Faust, Fernanda Gomes; Catecati, Tiago] Univ Fed Santa Catarina, Dept Engn Prod & Sistemas, Campus Trindade, Florianopolis, SC, Brazil.
   [Sierra, Isabella de Souza; Araujo, Fernanda Steinbruch; Nickel, Elton Moura; Gomes Ferreira, Marcelo Gitirana] Univ Estado Santa Catarina, Dept Design, Av Buriti 680,Ap 705B, BR-88034500 Florianopolis, SC, Brazil.
   [Garcia Ramirez, Alejandro Rafael] Univ Vale Itajai, Dept Comp Aplicada, Campus Itajai, Florianopolis, SC, Brazil.
C3 Universidade Federal de Santa Catarina (UFSC); Universidade do Estado de
   Santa Catarina; Universidade do Vale do Itajai
RP Ferreira, MGG (corresponding author), Univ Estado Santa Catarina, Dept Design, Av Buriti 680,Ap 705B, BR-88034500 Florianopolis, SC, Brazil.
EM marcelo.gitirana@gmail.com
RI Ramirez, Alejandro/ADD-6456-2022; Gomes Ferreira, Marcelo/D-5326-2009
OI Garcia Ramirez, Alejandro Rafael/0000-0002-1816-0016; Laboratory of
   Embedded and Distributed Systems, LEDS -/0000-0001-8768-2822; Faust,
   Fernanda Gomes/0000-0003-2935-7663; Gomes Ferreira,
   Marcelo/0000-0003-1912-9982; Catecati, Tiago/0000-0002-0502-5667
FU CNPq; CAPES; FAPESC
FX The authors would like to thank CNPq, CAPES, and FAPESC (Brazilian
   government agencies for scientific and technological development) for
   the financial support that makes this research possible.
CR [Anonymous], 2013, MEASURING USER EXPER
   Aoyama H, 2009, INT J INTERACT DES M, V3, P157, DOI 10.1007/s12008-009-0070-z
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Barbieri L, 2013, COMPUT IND, V64, P310, DOI 10.1016/j.compind.2012.11.010
   Bordegoni M, 2012, VIRTUAL PHYS PROTOTY, V7, P243, DOI 10.1080/17452759.2012.721605
   Bordegoni M, 2011, IEEE T HAPTICS, V4, P111, DOI [10.1109/TOH.2011.1, 10.1109/ToH.2011.1]
   Bordegoni M, 2009, INT J INTERACT DES M, V3, P177, DOI 10.1007/s12008-009-0073-9
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Bruno F, 2013, ENG COMPUT-GERMANY, V29, P375, DOI 10.1007/s00366-012-0293-7
   Caicedo DG, 2009, DESIGNING NEW PREMO
   Choi YM, 2015, PROCEDIA MANUF, V3, P2244, DOI 10.1016/j.promfg.2015.07.368
   Desmet P., 2003, Funology, V3, P111, DOI [DOI 10.1007/1-4020-2967-5_12, 10.1007/1-4020-2967-5_12]
   Faust F, 2012, WORK, V41, P1164, DOI 10.3233/WOR-2012-0298-1164
   Ferrise F., 2013, Computer-Aided Design and Applications, V10, P461, DOI DOI 10.3722/cadaps.2013.461-474
   Ferrise F, 2017, J INTELL MANUF, V28, P1695, DOI 10.1007/s10845-015-1163-0
   Haidarliu S, 2008, FRONT NEUROANAT, V2, DOI 10.3389/neuro.05.004.2008
   Jo DS, 2008, ETRI J, V30, P757, DOI 10.4218/etrij.08.0108.0209
   Kinard GR, 2002, ACTA HORTIC, P17, DOI 10.17660/ActaHortic.2002.568.1
   Landa J, 2013, ACTA U AGR SILVICULT, V60, P175, DOI [10.11118/actaun201260020175, DOI 10.11118/ACTAUN201260020175]
   Laurans G, 2012, INDRO PREMO2 NEW DIR, P13
   Lee JY, 2009, INT J ADV MANUF TECH, V45, P649, DOI 10.1007/s00170-009-2012-0
   Lee YG, 2010, COMPUT AIDED DESIGN, V42, P387, DOI 10.1016/j.cad.2009.11.003
   Lu S. C. Y., 1999, ANN CIRP, V48, P471, DOI DOI 10.1016/S0007-8506(07)63229-6
   Oikawa MA, 2012, INT SYM MIX AUGMENT, P307, DOI 10.1109/ISMAR.2012.6402587
   Park H, 2008, J ENG DESIGN, V19, P359, DOI 10.1080/09544820701474129
   Park H, 2014, J COMPUT DES ENG, V1, P289, DOI 10.7315/JCDE.2014.028
   Park H, 2013, J ADV MECH DES SYST, V7, P827, DOI 10.1299/jamdsm.7.827
   Park H, 2013, COMPUT IND, V64, P854, DOI 10.1016/j.compind.2013.05.006
   Park H, 2009, COMPUT IND, V60, P114, DOI 10.1016/j.compind.2008.09.001
   Park MK, 2015, J COMPUT DES ENG, V2, P38, DOI 10.1016/j.jcde.2014.11.004
   Regenbrecht H. T., 2002, Virtual Reality, V6, P151, DOI 10.1007/s100550200016
   Takahashi H, 2010, INT J INTERACT DES M, V4, P25, DOI 10.1007/s12008-009-0083-7
   Unger R., 2009, PROJECT GUIDE UX DES
   Verlinden Jouke, 2010, International Journal of Product Development, V11, P62, DOI 10.1504/IJPD.2010.032990
   Verlinden J, 2006, P TOOLS METH COMP EN, P523
   Verlinden JC, 2003, WSCG'2003, VOL 11, NO 3, CONFERENCE PROCEEDINGS, P496
   Verlinden J, 2008, STROJ VESTN-J MECH E, V54, P458
   Verlinden J, 2009, INT J INTERACT DES M, V3, P189, DOI 10.1007/s12008-009-0074-8
   Verlinden J, 2009, AI EDAM, V23, P289, DOI 10.1017/S0890060409000250
   Viganò G, 2004, INT J COMP INTEG M, V17, P653, DOI 10.1080/0951192042000273131
NR 40
TC 15
Z9 16
U1 3
U2 40
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2019
VL 23
IS 2
BP 197
EP 211
DI 10.1007/s10055-018-0356-1
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA HZ5RO
UT WOS:000468910500008
DA 2024-07-18
ER

PT J
AU Krokos, E
   Plaisant, C
   Varshney, A
AF Krokos, Eric
   Plaisant, Catherine
   Varshney, Amitabh
TI Virtual memory palaces: immersion aids recall
SO VIRTUAL REALITY
LA English
DT Article
DE Immersion; Experimental methods; HMD; 3D navigation; Visualization;
   Psychology; Training; Education; User study; Perception; Presence
ID SPATIAL MEMORY; PLACE CELLS; ENVIRONMENTS; NAVIGATION; PERFORMANCE;
   REALITY; MAPS
AB Virtual reality displays, such as head-mounted displays (HMD), afford us a superior spatial awareness by leveraging our vestibular and proprioceptive senses, as compared to traditional desktop displays. Since classical times, people have used memory palaces as a spatial mnemonic to help remember information by organizing it spatially and associating it with salient features in that environment. In this paper, we explore whether using virtual memory palaces in a head-mounted display with head-tracking (HMD condition) would allow a user to better recall information than when using a traditional desktop display with a mouse-based interaction (desktop condition). We found that virtual memory palaces in HMD condition provide a superior memory recall ability compared to the desktop condition. We believe this is a first step in using virtual environments for creating more memorable experiences that enhance productivity through better recall of large amounts of information organized using the idea of virtual memory palaces.
C1 [Krokos, Eric] Univ Maryland, AV Williams 4406, College Pk, MD 20742 USA.
   [Plaisant, Catherine] Univ Maryland, Hornbake Bldg 2117C, College Pk, MD 20742 USA.
   [Varshney, Amitabh] Univ Maryland, AV Williams 2119, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park;
   University System of Maryland; University of Maryland College Park;
   University System of Maryland; University of Maryland College Park
RP Krokos, E (corresponding author), Univ Maryland, AV Williams 4406, College Pk, MD 20742 USA.
EM ekrokos@umiacs.umd.edu; plaisant@cs.umd.edu; varshney@umiacs.umd.edu
OI Varshney, Amitabh/0000-0002-9873-2212
FU NSF [14-29404, 15-64212]; State of Maryland's MPower initiative; NVIDIA
   CUDA Center of Excellence; Direct For Computer & Info Scie & Enginr;
   Division Of Computer and Network Systems [1429404] Funding Source:
   National Science Foundation
FX We would like to extend our sincere appreciation to the anonymous
   reviewers who helped us refine this paper that significantly improved
   its presentation. We appreciate the support of the NSF Grants 14-29404,
   15-64212, the State of Maryland's MPower initiative, and the NVIDIA CUDA
   Center of Excellence. Any opinions, findings, conclusions, or
   recommendations expressed in this article are those of the authors and
   do not necessarily reflect the views of the research sponsors. Lastly,
   we would like to thank the 40 study participants.
CR [Anonymous], 2011, MED TOWN 01 DUBR
   [Anonymous], 2014, PAL INT 02
   Atkinson R. C., 1968, Psychology of learning and motivation, V2, P89, DOI [10.1016/S0079-7421(08)60422-3, DOI 10.1016/S0079-7421(08)60422-3, DOI 10.1017/CBO9781316422250.025]
   BADDELEY A, 1992, Science (Washington D C), V255, P556, DOI 10.1016/j.cub.2009.12.014
   Barry C, 2006, REV NEUROSCIENCE, V17, P71
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Baumann O, 2010, J NEUROSCI, V30
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brooks BM, 1999, MEMORY, V7, P65, DOI 10.1080/741943713
   BROOKS FP, 1992, TR92026 U N CAR CHAP
   Brown MW, 2001, NAT REV NEUROSCI, V2, P51, DOI 10.1038/35049064
   Burgess N, 2008, ANN NY ACAD SCI, V1124, P77, DOI 10.1196/annals.1440.002
   Buzsáki G, 2013, NAT NEUROSCI, V16, P130, DOI 10.1038/nn.3304
   Ekstrom AD, 2003, NATURE, V425, P184, DOI 10.1038/nature01964
   Fassbender E., 2006, J Comput Inf Syst, V2, P457
   Gardner Howard., 2006, Multiple Intelligences: New Horizons
   GODDEN DR, 1975, BRIT J PSYCHOL, V66, P325, DOI 10.1111/j.2044-8295.1975.tb01468.x
   Godwin-Jones R, 2010, LANG LEARN TECHNOL, V14, P4
   Harman J, 2017, LECT NOTES COMPUT SC, V10514, P128, DOI 10.1007/978-3-319-67684-5_9
   Harman Joshua., 2001, CHI 01 Extended Abstracts on Human Factors in Computing Systems, P407, DOI 10.1145/634067.634306
   HARRIS JE, 1980, MEM COGNITION, V8, P31, DOI 10.3758/BF03197549
   Hartley T, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0510
   Hok V, 2005, P NATL ACAD SCI USA, V102, P4602, DOI 10.1073/pnas.0407332102
   Julian Jaynes., 1976, ORIGIN CONSCIOUSNESS
   Kim J, 2011, J NEUROSCI, V31
   Kim Y, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670676
   Knauff M., 2013, SPACE REASON SPATIAL
   Legge ELG, 2012, ACTA PSYCHOL, V141, P380, DOI 10.1016/j.actpsy.2012.09.002
   Leutgeb S, 2005, CURR OPIN NEUROBIOL, V15, P738, DOI 10.1016/j.conb.2005.10.002
   Lever C, 2009, J NEUROSCI, V29, P9771, DOI 10.1523/JNEUROSCI.1319-09.2009
   Loomis JM, 1999, BEHAV RES METH INS C, V31, P557, DOI 10.3758/BF03200735
   Madl T, 2015, NEURAL NETWORKS, V65, P18, DOI 10.1016/j.neunet.2015.01.002
   Mania K, 2003, PRESENCE-TELEOP VIRT, V12, P296, DOI 10.1162/105474603765879549
   Mania K, 2001, CYBERPSYCHOL BEHAV, V4, P247, DOI 10.1089/109493101300117938
   Mayer JD, 2001, EMOTION, V1, P232, DOI 10.1037//1528-3542.1.3.232
   McCabe JA, 2015, TEACH PSYCHOL, V42, P169, DOI 10.1177/0098628315573143
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Moser EI, 2008, ANNU REV NEUROSCI, V31, P69, DOI 10.1146/annurev.neuro.31.061307.090723
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Parsons TD, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00660
   Pausch R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P13, DOI 10.1145/258734.258744
   Perrault ST, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P299, DOI 10.1145/2702123.2702126
   Ragan ED, 2010, PRESENCE-TELEOP VIRT, V19, P527, DOI 10.1162/pres_a_00016
   Repetto C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01839
   Richardson AE, 1999, MEM COGNITION, V27, P741, DOI 10.3758/BF03211566
   ROEDIGER HL, 1979, B PSYCHONOMIC SOC, V13, P339, DOI 10.3758/BF03336889
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Shapiro L, 2014, ROUTLEDGE HBK PHILOS, P1
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sowndararajan A, 2008, P 2008 WORKSH IMM PR, VIPT/EDT '08
   Wraga M, 2004, MEM COGNITION, V32, P399, DOI 10.3758/BF03195834
   Yates F. A., 1966, ART MEMORY
NR 54
TC 243
Z9 276
U1 5
U2 138
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2019
VL 23
IS 1
BP 1
EP 15
DI 10.1007/s10055-018-0346-3
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA HN8ZN
UT WOS:000460487500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, S
   Yu, H
   Wang, T
   Qi, L
   Dong, JY
   Liu, HH
AF Zhang, Shu
   Yu, Hui
   Wang, Ting
   Qi, Lin
   Dong, Junyu
   Liu, Honghai
TI Dense 3D facial reconstruction from a single depth image in
   unconstrained environment
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual face; Three-dimensional image acquisition; Three-dimensional
   sensing; 3D interpolation
ID PERCEPTION; SENSOR
AB With the increasing demands of applications in virtual reality such as 3D films, virtual human-machine interactions and virtual agents, the analysis of 3D human face is considered to be more and more important as a fundamental step in these tasks. Due to information provided by the additional dimension, 3D facial reconstruction enables aforementioned tasks to be achieved with higher accuracy than those based on 2D facial analysis. The denser the 3D facial model is, the more information it could provide. However, most existing dense 3D facial reconstruction methods require complicated processing and high system cost. To this end, this paper presents a novel method that simplifies the process of dense 3D facial reconstruction by employing only one frame of depth data obtained with an off-the-shelf RGB-D sensor. The proposed method is composed of two main stages: (a) the acquisition of the initial 3D facial point cloud with automatically 3D facial region cropping, and (b) the generating of the dense facial point cloud with RBF-based adaptive 3D point interpolation. Experiments reported in this paper demonstrate the competitive results with real-world data.
C1 [Zhang, Shu; Qi, Lin; Dong, Junyu] Ocean Univ China, Qingdao 266100, Peoples R China.
   [Zhang, Shu; Yu, Hui; Liu, Honghai] Univ Portsmouth, Portsmouth PO1 2DJ, Hants, England.
   [Wang, Ting] Shandong Univ Sci & Technol, Qingdao 266590, Peoples R China.
C3 Ocean University of China; University of Portsmouth; Shandong University
   of Science & Technology
RP Dong, JY (corresponding author), Ocean Univ China, Qingdao 266100, Peoples R China.
EM dongjunyu@ouc.edu.cn
RI Zhang, Shu/ABC-4379-2020; Yu, Hui/G-1115-2018
OI Zhang, Shu/0000-0002-5873-634X; Yu, Hui/0000-0002-7655-9228; Liu,
   Honghai/0000-0002-2880-4698
FU Engineering and Physical Sciences Research Council Project (EPSRC), UK
   [EP/N025849/1]; EU [611391]; National Natural Science Foundation of
   China (NSFC) [41576011]; International Science and Technology
   Cooperation Program of China (ISTCP) [2014DFA10410]; EPSRC
   [EP/N025849/1] Funding Source: UKRI
FX The Engineering and Physical Sciences Research Council Project (EPSRC),
   UK (No. EP/N025849/1); EU seventh framework programme under Grant
   Agreement No. 611391; National Natural Science Foundation of China
   (NSFC) (No. 41576011); and the International Science and Technology
   Cooperation Program of China (ISTCP) (No. 2014DFA10410).
CR Amidror I, 2002, J ELECTRON IMAGING, V11, P157, DOI 10.1117/1.1455013
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Bradley D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778778
   Brown R. A., 2015, J. Comput. Graph. Tech. (JCGT), V4, P50
   Chen G, 2016, VIRTUAL REAL-LONDON, V20, P159, DOI 10.1007/s10055-016-0291-y
   Chiabrando F, 2009, SENSORS-BASEL, V9, P10080, DOI 10.3390/s91210080
   Danescu R, 2012, SENSORS-BASEL, V12, P12940, DOI 10.3390/s121012940
   Essabbah M, 2014, VIRTUAL REAL-LONDON, V18, P219, DOI 10.1007/s10055-014-0247-z
   Fasshauer GE, 2012, SIAM J SCI COMPUT, V34, pA737, DOI 10.1137/110824784
   FRANKE R, 1991, SYMB COMPUT, P131
   Garcia E, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P657, DOI 10.1109/ITCC.2001.918872
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Har-Peled S., 2012, Theory of computing, V8, P321, DOI [DOI 10.4086/TOC.2012.V008A014, 10.4086/toc.2012.v008a014]
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hernandez M, 2015, IMAGE VISION COMPUT, V36, P61, DOI 10.1016/j.imavis.2014.12.004
   Hernoux F, 2015, VIRTUAL REAL-LONDON, V19, P1, DOI 10.1007/s10055-014-0255-z
   Hossain M. Shahriar, 2007, 2007 10th International Conference on Computer and Information Technology (ICCIT 2007), P1, DOI 10.1109/ICCITECHN.2007.4579387
   Hwang J, 2012, SENSORS-BASEL, V12, P12870, DOI 10.3390/s121012870
   Jo J, 2015, PATTERN RECOGN, V48, P73, DOI 10.1016/j.patcog.2014.07.013
   Lee M, 2014, COMPUT VIS IMAGE UND, V120, P59, DOI 10.1016/j.cviu.2013.12.010
   Lin IC, 2002, IEEE COMPUT GRAPH, V22, P72, DOI 10.1109/MCG.2002.1046631
   Mecca R, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P382, DOI 10.1109/3DV.2013.57
   Niclass C, 2014, IEEE J SOLID-ST CIRC, V49, P315, DOI 10.1109/JSSC.2013.2284352
   Nielson G.M., 1997, SCI VISUALIZATION
   Nister David, 2006, CVPR
   Qu C, 2013, VIRTUAL REAL-LONDON, V17, P307, DOI 10.1007/s10055-013-0231-z
   Sibson R., 1981, Interpreting Multivariate Data, P21, DOI DOI 10.1002/ADVS.201700552
   Silpa-Anan C., 2008, [39] C. Silpa-Anan and R. Hartley, "Optimized KD-trees for fast image descriptor matching", IEEE Conf. on Computer Vision and Pattern Recognition, 2008, pp. 1-8., P1, DOI [DOI 10.1109/CVPR.2008.4587638, 10.1109/CVPR.2008.4587638]
   Subbalakshmi C., 2014, INT J COMPUT, V14, P41
   Nguyen TT, 2015, SENSORS-BASEL, V15, P18587, DOI 10.3390/s150818587
   WILSON P.I., 2006, J COMPUT SMALL COLL, V21, P127
   Won-Sook Lee, 2007, Virtual Reality, V11, P229, DOI 10.1007/s10055-007-0071-9
   Yu H, 2012, COMPUT GRAPH-UK, V36, P152, DOI 10.1016/j.cag.2011.12.002
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhu Jiejie., 2008, IEEE C COMPUTER VISI, P1, DOI [DOI 10.1109/CVPR.2008.4587761, DOI 10.1145/1477862.1477875]
NR 35
TC 7
Z9 7
U1 0
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2018
VL 22
IS 1
BP 37
EP 46
DI 10.1007/s10055-017-0311-6
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA FX0UJ
UT WOS:000425762200004
DA 2024-07-18
ER

PT J
AU Schwebel, DC
   Severson, J
   He, YF
AF Schwebel, David C.
   Severson, Joan
   He, Yefei
TI Using smartphone technology to deliver a virtual pedestrian environment:
   usability and validation
SO VIRTUAL REALITY
LA English
DT Article
DE Pedestrian; Safety; Injury; Virtual reality; Simulation; Mobile
   smartphone
ID REALITY; MORTALITY; SICKNESS; TIME
AB Various programs effectively teach children to cross streets more safely, but all are labor- and cost-intensive. Recent developments in mobile phone technology offer opportunity to deliver virtual reality pedestrian environments to mobile smartphone platforms. Such an environment may offer a cost- and labor-effective strategy to teach children to cross streets safely. This study evaluated usability, feasibility, and validity of a smartphone-based virtual pedestrian environment. A total of 68 adults completed 12 virtual crossings within each of two virtual pedestrian environments, one delivered by smartphone and the other a semi-immersive kiosk virtual environment. Participants completed self-report measures of perceived realism and simulator sickness experienced in each virtual environment, plus self-reported demographic and personality characteristics. All participants followed system instructions and used the smartphone-based virtual environment without difficulty. No significant simulator sickness was reported or observed. Users rated the smartphone virtual environment as highly realistic. Convergent validity was detected, with many aspects of pedestrian behavior in the smartphone-based virtual environment matching behavior in the kiosk virtual environment. Anticipated correlations between personality and kiosk virtual reality pedestrian behavior emerged for the smartphone-based system. A smartphone-based virtual environment can be usable and valid. Future research should develop and evaluate such a training system.
C1 [Schwebel, David C.] Univ Alabama Birmingham, Dept Psychol, 1720 2nd Ave S,HHB 560, Birmingham, AL 35294 USA.
   [Severson, Joan; He, Yefei] Digital Artefacts LLC, Iowa City, IA USA.
C3 University of Alabama System; University of Alabama Birmingham
RP Schwebel, DC (corresponding author), Univ Alabama Birmingham, Dept Psychol, 1720 2nd Ave S,HHB 560, Birmingham, AL 35294 USA.
EM schwebel@uab.edu
RI Schwebel, David C./GXH-9944-2022
OI Schwebel, David C./0000-0002-2141-8970
FU Fogarty International Center; Office of Behavioral and Social Sciences
   Research of the National Institutes of Health [D43TW010310]; Eunice
   Kennedy Shriver National Institute of Child Health and Human Development
   [R21HD078371, R01HD088415, R21 TW010310]
FX Thanks to Anna Johnston and the students of the UAB Youth Safety Lab for
   their help with data collection, entry, and coding, and to the Digital
   Artefacts team for VR development and support. The research was
   supported by the Fogarty International Center and the Office of
   Behavioral and Social Sciences Research of the National Institutes of
   Health under Award Number D43TW010310 and by Grants R21HD078371 and
   R01HD088415 (Grant Nos. R21 TW010310, R21 TW010310) from the Eunice
   Kennedy Shriver National Institute of Child Health and Human
   Development. The content is solely the responsibility of the authors and
   does not necessarily represent the official views of the National
   Institutes of Health.
CR Adesso NA, 1974, THESIS
   [Anonymous], 1975, Motion sickness
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Bastawrous A, 2012, J MOB TECHNOL MED, V1, P22
   Benet-Martinez V, 1998, J PERS SOC PSYCHOL, V75, P729, DOI 10.1037/0022-3514.75.3.729
   Brooks JO, 2010, ACCIDENT ANAL PREV, V42, P788, DOI 10.1016/j.aap.2009.04.013
   Glasgow RE, 2012, AM J PUBLIC HEALTH, V102, P1274, DOI 10.2105/AJPH.2012.300755
   Grimshaw JM, 2012, IMPLEMENT SCI, V7, DOI 10.1186/1748-5908-7-50
   Haagsma JA, 2016, INJURY PREV, V22, P3, DOI 10.1136/injuryprev-2015-041616
   Institute for Health Metrics and Evaluation (IHME), 2016, GLOB BURD DIS GBD VI
   John O. P., 1999, BIG 5 TRAIT TAXONOMY
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Linnan H., 2010, 2010 CHINA SUMMARY R
   Liu L, 1999, Cyberpsychol Behav, V2, P567, DOI 10.1089/cpb.1999.2.567
   Ma S, 2013, BIOMED ENVIRON SCI, V26, P853, DOI 10.3967/bes2013.009
   Meir A, 2015, SAFETY SCI, V80, P33, DOI 10.1016/j.ssci.2015.07.007
   MERCY JA, 1993, HEALTH AFFAIR, V12, P7, DOI 10.1377/hlthaff.12.4.7
   Morrongiello BA, 2016, J PEDIATR PSYCHOL, V41, P265, DOI 10.1093/jpepsy/jsv078
   Sandels S, 1968, CHILDREN IN TRAFFIC
   Schwebel DC, 2008, ACCIDENT ANAL PREV, V40, P1394, DOI 10.1016/j.aap.2008.03.005
   Schwebel DC, 2016, ACCIDENT ANAL PREV, V86, P9, DOI 10.1016/j.aap.2015.10.002
   Schwebel DC, 2014, J PEDIATR PSYCHOL, V39, P826, DOI 10.1093/jpepsy/jsu024
   Thomson J.A., 1997, Community approach to road safety education (Department for Transport No. 3)
   Thomson JA, 2005, J EXP PSYCHOL-APPL, V11, P175, DOI 10.1037/1076-898X.11.3.175
   Turner M, 1999, ERGONOMICS, V42, P444, DOI 10.1080/001401399185586
   World Health Organization, 2016, SHOUDU GONGGONG WEIS
   World Health Organization, 2013, Pedestrian safety: a road safety manual for decision-makers and practitioners
   Zerhouni EA, 2005, NEW ENGL J MED, V353, P1621, DOI 10.1056/NEJMsb053723
NR 28
TC 14
Z9 16
U1 3
U2 24
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2017
VL 21
IS 3
BP 145
EP 152
DI 10.1007/s10055-016-0304-x
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA FB8YV
UT WOS:000406427400003
PM 29531502
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Yilmaz, RM
   Goktas, Y
AF Yilmaz, Rabia Meryem
   Goktas, Yuksel
TI Using augmented reality technology in storytelling activities: examining
   elementary students' narrative skill and creativity
SO VIRTUAL REALITY
LA English
DT Article
DE Interactive learning environments; Augmented reality; Media in
   education; Virtual reality; Storytelling
ID CHILDREN; SYSTEM; ACCEPTANCE; EDUCATION; ABILITY
AB The aim of the study was to examine the effects of augmented reality technology on stories in terms of narrative skill, story length and creativity and also to examine correlations between these variables. Posttest-only design with a nonequivalent group model was used. In this study, the sample consisted of 100 fifth-grade elementary students, comprising 46 boys and 54 girls. Purposive and convenience sampling methods were applied. For purposive sampling, the group's ages, education levels, and experiences in storytelling activities were gathered, and for convenience sampling, easy access to schools was considered. As data collection tools, a suitable narrative scale was used which was found in the literature and creative story form was developed by the researcher. According to the findings, mean scores for all variables for the experimental group were higher than those for the control group. Also, a statistically significant mean difference was found between the experimental and control groups with regard to narrative skill, length of stories, and creativity in stories. In fact, a positive correlation was found between all variables. It is important to recognize when a technology is found to contribute positively to narrative skill and creativity in telling stories, and to ensure this technology is used. Determining correlation between these variables may provide a contribution to studies about evaluating the effect of the new technologies.
C1 [Yilmaz, Rabia Meryem; Goktas, Yuksel] Ataturk Univ, Dept Comp Educ & Instruct Technol, TR-25240 Erzurum, Turkey.
C3 Ataturk University
RP Yilmaz, RM (corresponding author), Ataturk Univ, Dept Comp Educ & Instruct Technol, TR-25240 Erzurum, Turkey.
EM rkufrevi@atauni.edu.tr
RI YILMAZ, Rabia Meryem/AAG-4613-2019; Goktas, Yuksel/Q-7743-2019
OI YILMAZ, Rabia Meryem/0000-0002-0453-1357; 
FU Ataturk University Research Funding BAP [2012/503]
FX This study supported by Ataturk University Research Funding BAP by Grant
   Number 2012/503. A part of this study was presented at 3rd International
   Conference on Technical Education in Thailand. This study was conducted
   as part of the doctoral thesis entitled "Effects of Three Dimensional
   Storytelling Developed with Augmented Reality Technology on Narrative
   Skill and Creativity''.
CR Akçayir M, 2016, COMPUT HUM BEHAV, V57, P334, DOI 10.1016/j.chb.2015.12.054
   Alcaniz M., 2010, Augmented Reality Technology for Education
   Alsumait A, 2013, INT J PERVASIVE COMP, V9, P209, DOI 10.1108/IJPCC-07-2013-0016
   [Anonymous], SOC RES CHILD DEV C
   [Anonymous], SOCIAL INTERACTION S
   [Anonymous], 1 SWED AM WORKSH MOD
   [Anonymous], THESIS
   [Anonymous], ASISVET CHARLOTTE N
   [Anonymous], P 1999 C COMP SUPP C
   [Anonymous], YOU GO THERE YOU ARE
   [Anonymous], 12 INT C ADV LEARN T
   [Anonymous], 2012, ADV USABILITY EVAL 2
   [Anonymous], IEEE INT C VIRT ENV
   [Anonymous], P SIGGRAPH 04
   [Anonymous], THE EYEMAGIC BOOK
   [Anonymous], 2006, Proceedings of the ACM Symposium on Virtual Reality Software and Technology
   [Anonymous], 1986, Thought and Language-Revised Edition
   [Anonymous], ACM SIGGRAPH 2003 SK
   [Anonymous], 18 INT C ART REAL TE
   [Anonymous], THEOR PRACT COMPUT A
   [Anonymous], IDC 06 TAMP FINL
   [Anonymous], EXTENDED ABSTRACTS H
   [Anonymous], ANN PUBL POL SUMM CH
   [Anonymous], 2011, THESIS
   [Anonymous], PRETEND PLAY ENRICHE
   Aziz N. A. A., 2012, 2012 14th International Conference on Advanced Communication Technology (ICACT), P577
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Balog A, 2010, STUD INFORM CONTROL, V19, P319
   Bers M., 1999, Journal of Interactive Learning Research, V9, P603
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Bujak KR, 2013, COMPUT EDUC, V68, P536, DOI 10.1016/j.compedu.2013.02.017
   Cao XA, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P251
   Carlson KJ, 2016, CLIN SIMUL NURS, V12, P123, DOI 10.1016/j.ecns.2015.12.005
   Cassell J., 2001, Personal and Ubiquitous Computing, V5, P169, DOI 10.1007/PL00000018
   Cassell J, 2002, CHILDREN IN THE DIGITAL AGE, P123
   Cavazza M., 2007, P 15 ACM INT C MULT, P651, DOI DOI 10.1145/1291233.1291387
   Cellary W., 2002, Poland and the global information society: Logging on, P29
   Chen Y.C., 2006, Proceedings of the 2006 ACM international conference on Virtual reality continuum and its applications, P369
   Chien CH, 2010, LECT NOTES ENG COMP, P370
   Chu S.L., 2013, International Conference on Interactive Digital Storytelling, P144
   Chung S.K., 2007, ART EDUC, V60, P17
   Cook T.D., 1990, HDB IND ORG PSYCHOL, V1, P491
   Dillon G, 2012, INT J HUM-COMPUT ST, V70, P169, DOI 10.1016/j.ijhcs.2011.10.002
   Dünser A, 2008, ANN REV CYBERTHERAPY, V6, P41
   Dunser A., 2007, P 1 INT C TANG EMB I, P179, DOI [DOI 10.1145/1226969.1227006, 10.1145/1226969.1227006]
   Dunser A., 2007, Proceedings of Technologies for E-Learning and Digital Entertainment 2nd International Conference (Hong Kong, China, June 11-13, P305, DOI [10.1007/978-3-540-73011-8_31, DOI 10.1007/978-3-540-73011-8_31]
   Fraenkel J.R., 2000, DESIGN EVALUATE RES, V4th
   Fridin M, 2014, COMPUT EDUC, V70, P53, DOI 10.1016/j.compedu.2013.07.043
   Howe N, 2010, EARLY EDUC DEV, V21, P940, DOI 10.1080/10409280903440638
   Ivanova Malinka, 2011, International Journal of New Computer Architectures and their Applications, V1, P176
   Juan C, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P233, DOI 10.1109/ICALT.2008.122
   Kara N, 2014, INTERACT LEARN ENVIR, V22, P288, DOI 10.1080/10494820.2011.649767
   Kara N, 2013, EDUC TECHNOL SOC, V16, P28
   Kaufmann H, 2003, COMPUT GRAPH-UK, V27, P339, DOI 10.1016/S0097-8493(03)00028-1
   Kaufmann H., 2006, Proceeding of EDEN (European Distance and E-Learning Network) Conference, Vienna, P160
   Kaufmann H, 2004, THESIS
   Keedy AW, 2011, ANAT SCI EDUC, V4, P84, DOI 10.1002/ase.212
   Kerawalla L., 2006, Virtual Real, V10, P163, DOI [10.1007/s10055-006-0036-4, DOI 10.1007/S10055-006-0036-4]
   Kim K, 2014, VISUAL COMPUT, V30, P417, DOI 10.1007/s00371-013-0865-6
   Klopfer E., 2004, TechTrends, V49, P41
   Kye B., 2008, International Journal for Education Media and Technology, V2, P4
   Lee KH, 2005, INT EDUC J, V6, P194
   MALONEY KB, 1973, J APPL BEHAV ANAL, V6, P425, DOI 10.1901/jaba.1973.6-425
   McCabe A., 2003, PATTERNS NARRATIVE D
   McMillan J., 2010, Research in education: Evidence based inquiry, V7th
   Núñez M, 2008, MATH COMPUT SCI ENG, P271
   Oh S, 2008, LECT NOTES COMPUT SC, V5080, P40
   Pallant J., 2005, SPSS Survival Manual. A Step by Step Guide to Data Analysis Using IBM SPSS, DOI 10.4324/9781003117452
   Petersen DR, 2008, TOP LANG DISORD, V28, P115, DOI 10.1097/01.TLD.0000318933.46925.86
   Pinhanez CS, 2000, IBM SYST J, V39, P438, DOI 10.1147/sj.393.0438
   Popovici D.-M., 2004, International Journal of Distance Education Technologies, V2, P18, DOI 10.4018/jdet.2004100102
   Reilly JS, 1998, BRAIN LANG, V61, P335, DOI 10.1006/brln.1997.1882
   Russell A, 2010, TEI 2010, P271
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Schrier K., 2006, ACM SIGGRAPH 2006 Educators program on - SIGGRAPH'06 p, P15, DOI [DOI 10.1145/1179295.1179311, 10.1145/1179295.1179311]
   Shelton B., 2002, 1 IEEE INT AUGM REAL
   Shen Y, 2010, COMPUT ENTERTAIN, V8, P11, DOI DOI 10.1145/1899687.1899693
   Singhal S., 2012, INT J COMPUTER APPL, DOI [10.5120/7700-1041, DOI 10.5120/7700-1041]
   Sugimoto M., 2009, Proceedings of the 8th International Conference on Interaction Design and Children, P214
   Sumadio DD, 2010, INT C COMPUT ENG APP, P461, DOI 10.1109/ICCEA.2010.239
   Sylla C., 2011, P C HUMAN FACTORS CO, P1363, DOI 10.1145/1979742.1979775
   Tabachnick, 2013, Using multivariate statistics, V6th
   Tarng W, 2015, VIRTUAL REAL-LONDON, V19, P253, DOI 10.1007/s10055-015-0265-5
   Torrance E.P., 1968, Education and the creative potential
   Torrance E. P., 1966, TORRANCE TEST CREATI
   Wagner C., 1999, CHILD LANG TEACH THE, V15, P113, DOI [DOI 10.1177/026565909901500202, 10.1177/026565909901500202]
   Wang DL, 2008, COMPUT HUM BEHAV, V24, P2507, DOI 10.1016/j.chb.2008.03.014
   Wang DL, 2014, J SUPERCOMPUT, V70, P269, DOI 10.1007/s11227-012-0855-x
   Wright A., 1995, Creating stories with children
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yoon SA, 2012, INT J COMP-SUPP COLL, V7, P519, DOI 10.1007/s11412-012-9156-x
   Yuen S.C.Y., 2011, J. Educ. Technol. Dev. Exch. (JETDE), V4, P11, DOI [10.18785/jetde.0401.10, DOI 10.18785/JETDE.0401.10]
   ZhiYing Zhou, 2008, International Journal of Virtual Reality, V7, P9
   Zhou Z., 2004, P 2004 ACM SIGCHI IN, P364, DOI [DOI 10.1145/1067343.1067404, 10.1145/1067343.1067404]
   Zhou ZY, 2004, PERS UBIQUIT COMPUT, V8, P374, DOI 10.1007/s00779-004-0300-0
NR 95
TC 62
Z9 69
U1 5
U2 144
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2017
VL 21
IS 2
BP 75
EP 89
DI 10.1007/s10055-016-0300-1
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA EV3ZT
UT WOS:000401698600002
DA 2024-07-18
ER

PT J
AU Zheng, MT
   Zhu, JF
   Xiong, XD
   Zhou, SP
   Zhang, YJ
AF Zheng, Maoteng
   Zhu, Junfeng
   Xiong, Xiaodong
   Zhou, Shunping
   Zhang, Yongjun
TI 3D model reconstruction with common hand-held cameras
SO VIRTUAL REALITY
LA English
DT Article
DE 3D model reconstruction; Hand-held cameras; Bundle block adjustment;
   Preconditioned conjugate gradients; Multi-view stereo
ID LIDAR DATA; AIRBORNE; INTEGRATION; ADJUSTMENT
AB A 3D model reconstruction workflow with hand-held cameras is developed. The exterior and interior orientation models combined with the state-of-the-art structure from motion and multi-view stereo techniques are applied to extract dense point cloud and reconstruct 3D model from digital images. An overview of the presented 3D model reconstruction methods is given. The whole procedure including tie point extraction, relative orientation, bundle block adjustment, dense point production and 3D model reconstruction is all reviewed in brief. Among them, we focus on bundle block adjustment procedure; the mathematical and technical details of bundle block adjustment are introduced and discussed. Finally, four scenes of images collected by hand-held cameras are tested in this paper. The preliminary results have shown that sub-pixel (< 1 pixel) accuracy can be achieved with the proposed exterior-interior orientation models and satisfactory 3D models can be reconstructed using images collected by hand-held cameras. This work can be applied in indoor navigation, crime scene reconstruction, heritage reservation and other applications in geosciences.
C1 [Zheng, Maoteng; Zhou, Shunping] China Univ Geosci, Natl Engn Res Ctr Geog Informat Syst, Wuhan, Peoples R China.
   [Zhu, Junfeng; Xiong, Xiaodong] Smart Mapping Technol Inc, Beijing, Peoples R China.
   [Zhang, Yongjun] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan, Peoples R China.
C3 China University of Geosciences; Wuhan University
RP Zheng, MT (corresponding author), China Univ Geosci, Natl Engn Res Ctr Geog Informat Syst, Wuhan, Peoples R China.
EM tengve@163.com
RI Zhang, Yongjun/HCH-7076-2022; zheng, maoteng/KDN-2048-2024
OI Zhang, Yongjun/0000-0001-9845-4251; zheng, maoteng/0000-0002-3533-4129
FU National Natural Science Foundation of China [41601502, 41571434]; China
   Postdoctoral Science Foundation [2015M572224]; Fundamental Research
   Funds for the Central Universities; China University of Geosciences
   (Wuhan) [CUG160838]; Key Laboratory for Aerial Remote Sensing Technology
   of National Administration of Surveying, Mapping and Geoinformation
   (NASG) [2014B01]
FX This project is funded by the National Natural Science Foundation of
   China under grant 41601502 and 41571434, China Postdoctoral Science
   Foundation under Grant 2015M572224, the Fundamental Research Funds for
   the Central Universities, China University of Geosciences (Wuhan) under
   Grant CUG160838, and the Key Laboratory for Aerial Remote Sensing
   Technology of National Administration of Surveying, Mapping and
   Geoinformation (NASG) under Grant 2014B01.
CR Ackermann F, 1999, ISPRS J PHOTOGRAMM, V54, P64, DOI 10.1016/S0924-2716(99)00009-X
   Acute3D, 2015, TURN PHOT 3D MOD AUT
   Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9_3
   Agisoft, 2015, PHOT
   [Anonymous], 2008, LEVELS DETAIL 3D BUI
   Baltsavias EP, 1999, ISPRS J PHOTOGRAMM, V54, P83, DOI 10.1016/S0924-2716(99)00014-3
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Bru R, 2008, SIAM J SCI COMPUT, V30, P2302, DOI 10.1137/070696088
   Bujnak M, 2009, IEEE I CONF COMP VIS, P1803, DOI 10.1109/ICCV.2009.5459402
   BYROD M, 2009, BRIT MACH VIS C
   Byröd M, 2010, LECT NOTES COMPUT SC, V6312, P114, DOI 10.1007/978-3-642-15552-9_9
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552
   Elias M, 2010, P 3 INT WORKSH INN I, P1
   Eos Software module Inc, 2015, ACC AFF 3D MOD MEAS
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   García-Gago J, 2014, REMOTE SENS-BASEL, V6, P5671, DOI 10.3390/rs6065671
   HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044
   Jesse, 2015, OPEN SOURCE PHOTOGRA
   Jian YD, 2011, IEEE I CONF COMP VIS, P295, DOI 10.1109/ICCV.2011.6126255
   Jiang T., 2014, P 2014 ICHVE INT C H, P1, DOI 10.1109/ICHVE.2014.7035488
   Kato A, 2009, REMOTE SENS ENVIRON, V113, P1148, DOI 10.1016/j.rse.2009.02.010
   Kim CJ, 2009, SENSORS-BASEL, V9, P5679, DOI 10.3390/s90705679
   Kocaman S., 2006, INT ARCH PHOTOGRAMME, V36
   Krasic S, 2014, NEXUS NETW J, V16, P273, DOI 10.1007/s00004-014-0188-6
   Li HY, 2012, INT GEOSCI REMOTE SE, P463, DOI 10.1109/IGARSS.2012.6350870
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma RJ, 2004, THESIS
   Ozaki M., 2011, SICE 2011 - 50th Annual Conference of the Society of Instrument and Control Engineers of Japan, P48
   Park SY, 2004, IMAGE VISION COMPUT, V22, P623, DOI 10.1016/j.imavis.2004.01.002
   Parker Susan, 2008, Canaveral National Seashore: Historic Resource Study, P1
   Rau JY, 2003, PHOTOGRAMM ENG REM S, V69, P181, DOI 10.14358/PERS.69.2.181
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   SimActive Inc, 2015, SIM ANN CORRELATOR3D
   Sohn G, 2007, ISPRS J PHOTOGRAMM, V62, P43, DOI 10.1016/j.isprsjprs.2007.01.001
   Susaki J, 2013, REMOTE SENS-BASEL, V5, P5944, DOI 10.3390/rs5115944
   Tsung-I Lnen, 2014, 2014 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P93, DOI 10.1109/ICCE-TW.2014.6904117
   Van Leeuwen M, 2010, REMOTE SENS LETT, V1, P125, DOI 10.1080/01431161003649339
   Wang Y., 2012, THESIS
   Yang XY, 2013, REMOTE SENS ENVIRON, V135, P36, DOI 10.1016/j.rse.2013.03.020
   Yu Q, 2014, INT ARCH PHOTOGRAMME, VXL-4, P335
   Zhang DQ, 2013, INT CONF PERVAS COMP, P1
   Zhang K, 2006, IEEE T GEOSCI REMOTE, V44, P2523, DOI 10.1109/TGRS.2006.874137
   Zheng MT, 2016, COMPUT GEOSCI-UK, V92, P70, DOI 10.1016/j.cageo.2016.04.006
   Zhu LL, 2014, REMOTE SENS-BASEL, V6, P3075, DOI 10.3390/rs6043075
NR 45
TC 5
Z9 5
U1 1
U2 40
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2016
VL 20
IS 4
BP 221
EP 235
DI 10.1007/s10055-016-0297-5
PG 15
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA DY6FF
UT WOS:000385201100004
DA 2024-07-18
ER

PT J
AU García, AA
   Bobadilla, IG
   Figueroa, GA
   Ramírez, MP
   Román, JM
AF Ayala Garcia, Andres
   Galvan Bobadilla, Israel
   Arroyo Figueroa, Gustavo
   Perez Ramirez, Miguel
   Munoz Roman, Javier
TI Virtual reality training system for maintenance and operation of
   high-voltage overhead power lines
SO VIRTUAL REALITY
LA English
DT Article
DE E-learning; Interactive training; Virtual reality; Power distribution
   systems; High-voltage overhead power lines maintenance
ID SIMULATION; ENVIRONMENTS; ROOM
AB The maintenance of high-voltage overhead power lines involves high-risk procedures; the accidents involving live lines maintenance can be lethal. This paper presents the architecture and main features of a novel non-immersive virtual reality training system for maintenance of high-voltage overhead power lines. The general aim of this work was to provide electric utilities a suitable work-force training system to train and to certify operators working in complex and unsafe environments. The developed system has three components: the virtual warehouse, interactive 3D environments, and a learning management system. The workforce training system consists of thirty-one maintenance maneuvers, including the application of different techniques and equipment designed for various structures. Additionally, the system, using 3D animations, illustrates the safety conditions required before starting the maintenance procedures. To fit the worker's different skill levels, the system has three operation modes: learning, practice, and evaluation, which can be accessed according to the trainee's level of knowledge. The system is currently used to train thousands of overhead power lines operators of an electric utility in Mexico. The system has demonstrated to be a cost-effective tool for transferring skills and knowledge to new workers while reducing the time and money invested in their training.
C1 [Ayala Garcia, Andres; Galvan Bobadilla, Israel; Arroyo Figueroa, Gustavo; Perez Ramirez, Miguel; Munoz Roman, Javier] Inst Invest Elect, Gerencia Tecnol Informac, Reforma 113 Col Palmira, Cuernavaca 62490, Morelos, Mexico.
RP Bobadilla, IG (corresponding author), Inst Invest Elect, Gerencia Tecnol Informac, Reforma 113 Col Palmira, Cuernavaca 62490, Morelos, Mexico.
EM andres.ayala@iie.org.mx; igalvan@iie.org.mx; garroyo@iie.org.mx;
   mperez@iie.org.mx; jjmunoz@iie.org.mx
RI Arroyo-Figueroa, Gustavo/O-4911-2016; Figueroa, Gustavo
   Arroyo/AAI-8248-2020
OI Arroyo-Figueroa, Gustavo/0000-0003-0764-045X; 
CR de Sousa MPA, 2010, INT J ELEC POWER, V32, P599, DOI 10.1016/j.ijepes.2009.11.016
   Angelova Anelia., 2007, Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P1
   Arendarski B, 2008, IEEE INT SYM ELEC IN, P483, DOI 10.1109/ELINSL.2008.4570378
   Baeta Miranda M, 2010, P IEEE 3 INT C HUM C, P1
   Barrett M., 2011, ISAST T COMPUTERS IN, V3, P1
   Breen Jr PT, 1995, RUR EL POW C 1995 39
   Cai J, 2000, HMVC LAYERED PATTERN
   Coutaz J., 1987, INTERACT 87, P431
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   DUNN R, 1989, EDUC LEADERSHIP, V46, P50
   El-Chaar J., 2011, Proceedings of 2011 9th International Conference on Reliability, Maintainability and Safety (ICRMS 2011), P1376, DOI 10.1109/ICRMS.2011.5979485
   Engstrom J, 2007, UNDERGROUND CABLES T
   Feng Y., 2009, P S PHOT OPT SOPO 20, P1, DOI [10.1109/APPEEC.2009.4918327.-5, DOI 10.1109/APPEEC.2009.4918327.-5, DOI 10.1109/CLEOPR.2009.5292579]
   Freund E, 1999, IEEE T ROBOTIC AUTOM, V15, P411, DOI 10.1109/70.768175
   Gallagher AG, 2004, LANCET, V364, P1538, DOI 10.1016/S0140-6736(04)17278-4
   Galvan I, 2010, P WORLD C ENG COMP S
   GARANT E, 1995, IEEE PACIF, P296, DOI 10.1109/PACRIM.1995.519528
   Guobin Tao, 2010, 2010 2nd International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC 2010), P37, DOI 10.1109/IHMSC.2010.108
   Gutierrez-Requejo J, 2013, 26 REUN VER POT APL
   Hamilton EC, 2002, SURG ENDOSC, V16, P406, DOI 10.1007/s00464-001-8149-z
   Helander MG., 1997, HDB HUMAN COMPUTER I
   Hillier Y., 2009, Innovation in teaching and learning in vocational education and training: International perspectives (NCVER Research Overview)
   Israel G, 2001, B IIE, V35, P117
   Israel G, 2011, B IIE, V35, P99
   KOZAK JJ, 1993, ERGONOMICS, V36, P777, DOI 10.1080/00140139308967941
   Kriz Zachary, 2010, INT NUCL REN EN C, P1
   Li JR, 2003, COMPUT IND, V52, P109, DOI 10.1016/S0166-3615(03)00103-9
   Matsubara Y, 2002, INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION, VOLS I AND II, PROCEEDINGS, P922, DOI 10.1109/CIE.2002.1186114
   Mól ACA, 2009, PROG NUCL ENERG, V51, P382, DOI 10.1016/j.pnucene.2008.04.003
   MOSHELL M, 1993, COMPUTER, V26, P81, DOI 10.1109/2.192003
   Mukherjee S, 2006, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, PROCEEDINGS, P688, DOI 10.1109/ITNG.2006.95
   Ou SC, 2002, IEEE ICIT' 02: 2002 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS I AND II, PROCEEDINGS, P348, DOI 10.1109/ICIT.2002.1189920
   Pantelidis VS, 1997, COMPUT APPL ENG EDUC, V5, P3, DOI 10.1002/(SICI)1099-0542(1997)5:1<3::AID-CAE1>3.0.CO;2-H
   Park CH, 2006, INT J HUM-COMPUT INT, V20, P285, DOI 10.1207/s15327590ijhc2003_7
   Perez M, 2004, B IIE, V28, P39
   Rizzo A, 2011, J CLIN PSYCHOL MED S, V18, P176, DOI 10.1007/s10880-011-9247-2
   Romero G, 2008, ELECTR POW SYST RES, V78, P409, DOI 10.1016/j.epsr.2007.03.014
   Rosen JM, 1996, IEEE VIRT REAL ANN I
   Seymour NE, 2008, WORLD J SURG, V32, P182, DOI 10.1007/s00268-007-9307-9
   Shaikh A., 1995, 1995 Canadian Conference on Electrical and Computer Engineering (Cat. No.95TH8103), P788, DOI 10.1109/CCECE.1995.526413
   Shiau YH, 2007, IEEE INT CONF INF VI, P807
   Simoes P.D. da Silva., 2011, 2011 IEEE 1st International Conference on Serious Games and Applications for Health (SeGAH). IEEE, P1
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Tam EK, 1998, IEEE T POWER SYST, V13, P829, DOI 10.1109/59.708691
   Tam EK, 1999, IEEE T POWER SYST, V14, P802, DOI 10.1109/59.780889
   Tang CY, 2007, ICIT 07 IEEE INT C I
   Tang XX, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P78, DOI 10.1109/ICMA.2009.5246470
   Tao Ni, 2011, Proceedings of the 2011 International Conference on Transportation and Mechanical & Electrical Engineering (TMEE), P494, DOI 10.1109/TMEE.2011.6199249
   Webster A, 1996, COMPUTING IN CIVIL ENGINEERING, P913
   Xu JZ, 2008, Proceedings of 2008 International Conference on Construction & Real Estate Management, Vols 1 and 2, P1137
   Xu Wu, 2011, 2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference (ITAIC 2011), P167, DOI 10.1109/ITAIC.2011.6030177
   Yuan SQ, 2007, C IND ELECT APPL, P2686
   Zhang G, 2003, IEEE INT C ROB INT S
NR 53
TC 71
Z9 75
U1 5
U2 58
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2016
VL 20
IS 1
BP 27
EP 40
DI 10.1007/s10055-015-0280-6
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA DM1FY
UT WOS:000376092000003
DA 2024-07-18
ER

PT J
AU Nakashima, Y
   Uno, Y
   Kawai, N
   Sato, T
   Yokoya, N
AF Nakashima, Yuta
   Uno, Yusuke
   Kawai, Norihiko
   Sato, Tomokazu
   Yokoya, Naokazu
TI AR image generation using view-dependent geometry modification and
   texture mapping
SO VIRTUAL REALITY
LA English
DT Article
DE View-dependent geometry modification; View-dependent texture mapping;
   Augmented reality; Free-viewpoint image generation
AB Augmented reality (AR) applications often require virtualized real objects, i.e., virtual objects that are built based on real objects and rendered from an arbitrary viewpoint. In this paper, we propose a method for real object virtualization and AR image generation based on view-dependent geometry modification and texture mapping. The proposed method is a hybrid of model- and image-based rendering techniques that uses multiple input images of the real object as well as the object's three-dimensional (3D) model obtained by an automatic 3D reconstruction technique. Even with state-of-the-art technology, the reconstructed 3D model's accuracy can be insufficient, resulting in such visual artifacts as false object boundaries. The proposed method generates a depth map from a 3D model of a virtualized real object and expands its region in the depth map to remove the false object boundaries. Since such expansion reveals the background pixels in the input images, which is particularly undesirable for AR applications, we preliminarily extract object regions and use them for texture mapping. With our GPU implementation for real-time AR image generation, we experimentally demonstrated that using expanded geometry reduces the number of required input images and maintains visual quality.
C1 [Nakashima, Yuta; Uno, Yusuke; Kawai, Norihiko; Sato, Tomokazu; Yokoya, Naokazu] Nara Inst Sci & Technol NAIST, Nara 6300192, Japan.
C3 Nara Institute of Science & Technology
RP Nakashima, Y (corresponding author), Nara Inst Sci & Technol NAIST, 8916-5 Takayama Cho, Nara 6300192, Japan.
EM n-yuta@is.naist.jp; yusuke-u@is.naist.jp; norihi-k@is.naist.jp;
   tomoka-s@is.naist.jp; yokoya@is.naist.jp
RI Nakashima, Yuta/Y-6218-2019
OI Nakashima, Yuta/0000-0001-8000-3567
FU Japan Society for the Promotion of Science KAKENHI . [23240024];
   Grants-in-Aid for Scientific Research [25540086] Funding Source: KAKEN
FX This work is partly supported by the Japan Society for the Promotion of
   Science KAKENHI No. 23240024.
CR Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bastian J., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P199, DOI 10.1109/ISMAR.2010.5643570
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238
   Davis A, 2012, COMPUT GRAPH FORUM, V31, P305, DOI 10.1111/j.1467-8659.2012.03009.x
   Debevec P., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P105
   Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Irani M, 2002, LECT NOTES COMPUT SC, V2351, P883
   Jancosek M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3121, DOI 10.1109/CVPR.2011.5995693
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Klein George, 2007, P1
   Kolev K, 2012, IEEE T PATTERN ANAL, V34, P493, DOI 10.1109/TPAMI.2011.150
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Metaio GmbH, MET SDK
   NVIDIA Developer Zone, CONJUGATEGRADIENTUM
   Renka RJ, 1997, ACM T MATH SOFTWARE, V23, P435, DOI 10.1145/275323.275330
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Wu C., 2011, VisualSFM: A visual structure from motion system
   Wu C., 2007, Siftgpu: A gpu implementation of david lowe's scale invariant feature transform (sift)
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
NR 22
TC 5
Z9 7
U1 0
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2015
VL 19
IS 2
BP 83
EP 94
DI 10.1007/s10055-015-0259-3
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA CJ9MO
UT WOS:000355826700002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mirzaei, MA
   Merienne, F
   Oliver, JH
AF Mirzaei, M. Ali
   Merienne, Frederic
   Oliver, James H.
TI New wireless connection between user and VE using speech processing
SO VIRTUAL REALITY
LA English
DT Article
DE Speak-to-VR; Wi-Fi network; Speech processing; VRPN server
AB This paper presents a novel speak-to-VR virtual-reality peripheral network (VRPN) server based on speech processing. The server uses a microphone array as a speech source and streams the results of the process through a Wi-Fi network. The proposed VRPN server provides a handy, portable and wireless human machine interface that can facilitate interaction in a variety interfaces and application domains including HMD- and CAVE-based virtual reality systems, flight and driving simulators and many others. The VRPN server is based on a speech processing software development kits and VRPN library in C++. Speak-to-VR VRPN works well even in the presence of background noise or the voices of other users in the vicinity. The speech processing algorithm is not sensitive to the user's accent because it is trained while it is operating. Speech recognition parameters are trained by hidden Markov model in real time. The advantages and disadvantages of the speak-to-VR server are studied under different configurations. Then, the efficiency and the precision of the speak-to-VR server for a real application are validated via a formal user study with ten participants. Two experimental test setups are implemented on a CAVE system by using either Kinect Xbox or array microphone as input device. Each participant is asked to navigate in a virtual environment and manipulate an object. The experimental data analysis shows promising results and motivates additional research opportunities.
C1 [Mirzaei, M. Ali; Merienne, Frederic] Paris Tech, Inst Image, Lab Le2i, Paris, France.
   [Oliver, James H.] Iowa State Univ, Virtual Real Applicat Ctr, Ames, IA USA.
C3 Iowa State University
RP Mirzaei, MA (corresponding author), Paris Tech, Inst Image, Lab Le2i, Paris, France.
EM mirzai142.nri@gmail.com; oliver@iastate.edu
RI ; Oliver, James/A-4590-2014
OI Chardonnet, Jean-Remy/0000-0002-8926-1359; Merienne,
   Frederic/0000-0003-4466-4776; Oliver, James/0000-0003-2815-4928
CR Boyle A, 2008, SCIENCE, V3147, P10
   Day PN, 2001, LECT NOTES ARTIF INT, V2117, P75
   DiVerdi S, 2006, PROC SPIE, V6055, DOI 10.1117/12.643286
   Fischbach M, 2011, P IEEE VIRT REAL ANN, P255, DOI 10.1109/VR.2011.5759495
   Intel, 2013, VOIC RECOG SYNTH US
   iSpeech, 2011, SPEECH PROC SDK MOB
   Jinghui G, 2005, J GUANGXI ACAD SCI, V3, P169
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kinect Joystiq., 2011, KIN COMP BEH TECH EX
   Lyngso R, 2012, NAROTAMA, V1, P1
   NILSSON M, 2002, THESIS BLEKINGE I TE
   Pulakka H, 2011, IEEE T AUDIO SPEECH, V19, P2170, DOI 10.1109/TASL.2011.2118206
   Retrieved P, 2010, KINECT XBOX 360 SPEC
   Rodriguez-Andina J, 2001, 2011 IEEE INT C AC S, V2, P1217
   Rübsamen M, 2012, IEEE T SIGNAL PROCES, V60, P740, DOI 10.1109/TSP.2011.2174233
   SAR, 2005, ADV SCI LETT
   Shao W, 2013, ADV SCI LETT, V19, P1071
   Stone JE, 2010, LECT NOTES COMPUT SC, V6454, P382, DOI 10.1007/978-3-642-17274-8_38
   Store M, 2010, KINECT XBOX 360
   Suma EA, 2011, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2011.5759491
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   Zhu F-W, 2004, J SHANGHAI U, V5
NR 22
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2014
VL 18
IS 4
BP 235
EP 243
DI 10.1007/s10055-014-0248-y
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AT0AZ
UT WOS:000344600500001
DA 2024-07-18
ER

PT J
AU Vélaz, Y
   Lozano-Rodero, A
   Suescun, A
   Gutiérrez, T
AF Velaz, Yaiza
   Lozano-Rodero, Alberto
   Suescun, Angel
   Gutierrez, Teresa
TI Natural and hybrid bimanual interaction for virtual assembly tasks
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; Haptics; Markerless Mocap; Human-computer interaction;
   Assembly training; Bimanual assembly simulation
ID SYSTEM
AB This paper focuses on the simulation of bimanual assembly/disassembly operations for training or product design applications. Most assembly applications have been limited to simulate only unimanual tasks or bimanual tasks with one hand. However, recent research has introduced the use of two haptic devices for bimanual assembly. We propose a more natural and low-cost bimanual interaction than existing ones based on Markerless motion capture (Mocap) systems. Specifically, this paper presents two interactions based on a Markerless Mocap technology and one interaction based on combining Markerless Mocap technology with haptic technology. A set of experiments following a within-subjects design have been implemented to test the usability of the proposed interfaces. The Markerless Mocap-based interactions were validated with respect to two-haptic-based interactions, as the latter has been successfully integrated into bimanual assembly simulators. The pure Markerless Mocap interaction proved to be either the most or least efficient depending on the configuration (with 2D or 3D tracking, respectively). Usability results among the proposed interactions and the two-haptic based interaction showed no significant differences. These results suggest that Markerless Mocap or hybrid interactions are valid solutions for simulating bimanual assembly tasks when the precision of the motion is not critical. The decision on which technology to use should depend on the trade-off between the precision requested to simulate the task, the cost, and inner features of the technology.
C1 [Velaz, Yaiza; Lozano-Rodero, Alberto; Suescun, Angel] Ceit, Ctr Estudios & Invest Tecn Guipuzcoa, Dept Mech Engn, Donostia San Sebastian 20018, Spain.
   [Gutierrez, Teresa] TECNALIA, Ind & Transport Div, Derio 48160, Spain.
C3 University of Navarra
RP Vélaz, Y (corresponding author), Ceit, Ctr Estudios & Invest Tecn Guipuzcoa, Dept Mech Engn, Paseo Manuel Lardizabal 15, Donostia San Sebastian 20018, Spain.
EM yvelaz@gmail.com; alozano@ceit.es; asuescun@ceit.es;
   teresa.gutierrez@tecnalia.com
RI Suescun, Angel/D-7387-2019
OI Suescun, Angel/0000-0002-3012-0068
CR Abate AF, 2009, J VISUAL LANG COMPUT, V20, P318, DOI 10.1016/j.jvlc.2009.07.003
   Adams JR, 2001, VIRTUAL TRAINING MAN, V2
   [Anonymous], 2010, 2010 IEEE GLOBAL TEL
   [Anonymous], 2001, J COMPUT INF SCI ENG
   Avizzano CA, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P165
   Belluco P, 2010, PROCEEDINGS OF THE ASME WORLD CONFERENCE ON INNOVATIVE VIRTUAL REALITY, P295
   Bloomfield A, 2003, P IEEE VIRT REAL ANN, P225, DOI 10.1109/VR.2003.1191143
   Bordegoni M, 2009, LECT NOTES COMPUT SC, V5622, P303, DOI 10.1007/978-3-642-02771-0_34
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Cao Y, 2010, LECT NOTES COMPUT SC, V6315, P729
   Chen Cheng-jun, 2010, Proceedings of the Third International Conference on Information and Computing Science (ICIC 2010), P147, DOI 10.1109/ICIC.2010.131
   Gupta SK, 2008, VIRT MAN WORKSH UMCP
   GUTIERREZ T, 2010, P 18 IEE INT S ROB H, P428, DOI DOI 10.1109/ROMAN.2010
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jun Y, 2005, INT J COMPUT INTEG M, V18, P442, DOI 10.1080/09511920400030153
   Jung B, 1998, IEEE IND ELEC, P2152, DOI 10.1109/IECON.1998.724054
   Lee JY, 2010, INT J ADV MANUF TECH, V51, P1069, DOI 10.1007/s00170-010-2671-x
   Leino SP, 2009, LECT NOTES COMPUT SC, V5622, P346, DOI 10.1007/978-3-642-02771-0_39
   Lu XJ, 2012, ADV INTEL SOFT COMPU, V142, P105
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Oikonomidis I, 2012, P IEEE C CV IN PRESS
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Poyade M, 2009, LECT NOTES COMPUT SC, V5622, P365, DOI 10.1007/978-3-642-02771-0_41
   Romero J, 2010, IEEE INT CONF ROBOT, P458, DOI 10.1109/ROBOT.2010.5509753
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   Seth A, 2008, J COMPUT INF SCI ENG, V8, DOI 10.1115/1.3006306
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Unzueta L, 2008, THESIS U NAVARRA TEC
   Wang R., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology. UIST '11, P549
   Wang R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531397
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhu YD, 2007, LECT NOTES COMPUT SC, V4843, P408
NR 32
TC 8
Z9 8
U1 0
U2 20
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD SEP
PY 2014
VL 18
IS 3
BP 161
EP 171
DI 10.1007/s10055-013-0240-y
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA AN5HR
UT WOS:000340621900001
DA 2024-07-18
ER

PT J
AU Hamon, L
   Richard, E
   Richard, P
   Boumaza, R
   Ferrier, JL
AF Hamon, Ludovic
   Richard, Emmanuelle
   Richard, Paul
   Boumaza, Rachid
   Ferrier, Jean-Louis
TI RTIL-system: a Real-Time Interactive L-system for 3D interactions with
   virtual plants
SO VIRTUAL REALITY
LA English
DT Article
DE Virtual reality; L-system; Real-time interaction; Virtual plant; Fractal
AB The L-system is a rewriting process based on formal grammar and is used to generate 3D, dynamic structures such as virtual plants and fractal graphics. In previous works, we highlighted that existing L-system software applications and programs are limited, either in terms of human interaction or in terms of modelling. In particular, few of them allow the user to interact with virtual plants during their growth. Our own L-system engine was developed and called the real-time interactive L-system (RTIL-system). The RTIL-system covers most important L-system extensions such as parametric and context-sensitive features. Furthermore, real-time interactions with the user and the environment with respect to L-system formalism are available. This paper presents an RTIL-system focusing on human interaction, the Partial Interactive Derivation (PID) concept and further progress by the extension of PID to context-sensitive rules. To illustrate the potential of the RTIL-system, the effect of various interactive tasks such as sub-axis additions, pruning and bending on the subsequent dynamic development of virtual plants is described.
C1 [Hamon, Ludovic; Richard, Emmanuelle; Richard, Paul; Ferrier, Jean-Louis] Univ Angers, LISA, F-49000 Angers, France.
   [Boumaza, Rachid] Agrocampus Ouest Angers, UMR SAGAH, F-49045 Angers, France.
C3 Universite d'Angers; Institut Agro; Agrocampus Ouest
RP Hamon, L (corresponding author), Univ Angers, LISA, 62 Ave Notre Dame Du Lac, F-49000 Angers, France.
EM ludovic.hamon@univ-angers.fr; erichard@univ-angers.fr;
   paul.richard@univ-angers.fr
RI , AGROCAMPUS OUEST/O-6651-2016
OI , AGROCAMPUS OUEST/0000-0002-1800-4558
CR Baele X, 2005, International Conference on Shape Modeling and Applications, Proceedings, P184, DOI 10.1109/SMI.2005.38
   BORNHOFEN S, 2007, P VRIC LAV FRANC, P172
   Favre P, 2007, WORKSH GROWTH PHEN I
   Federl P, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P93
   Gilroy SW., 2008, P 16 ACM INT C MULTI, P945
   Ha T., 2006, The International Journal of Virtual Reality, V5, P21
   Hamon L, 2010, GRAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P370
   Hu BG, 2003, PLANT GROWTH MODELING AND APPLICATIONS, PROCEEDINGS, P21
   KARWOWSKI R, 2002, THESIS U CALGARY
   KURTH W, 1994, GROWTH GRAMMAR INTER
   LINDENMAYER A, 1968, J THEOR BIOL, V18, P280, DOI 10.1016/0022-5193(68)90079-9
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   MECH R, 2005, CPFG VERSION 4 0 USE
   Mech R, 1997, THESIS U CALGARY CAN
   Onishi K, 2006, LECT NOTES COMPUT SC, V3853, P222
   Onishi K., 2003, Proceedings of the ACM Symposium on Virtual Reality Software and Technology (Osaka, Japan, October 01 - 03, P66, DOI DOI 10.1145/1008653.1008667&GT
   Power J. L., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P175, DOI 10.1145/300523.300548
   Prusinkiewicz P., 1986, Proceedings of Graphics Interface '86 and Vision Interface '86, P247
   Prusinkiewicz P, 2000, AGTIVE 99 P INT WORK, V1779, P160
   Prusinkiewicz P, 2011, PUBLICATIONS 1986 20
   Prusinkiewicz P., 1990, ALGORITHMIC BEAUTY P
   Prusinkiewiez P, 2000, LECT NOTES COMPUT SC, V1779, P395
   Smith A. R., 1984, Computers & Graphics, V18, P1
NR 23
TC 5
Z9 8
U1 0
U2 17
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2012
VL 16
IS 2
BP 151
EP 160
DI 10.1007/s10055-011-0193-y
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 949EO
UT WOS:000304559300005
DA 2024-07-18
ER

PT J
AU Griffon, S
   Nespoulous, A
   Cheylan, JP
   Marty, P
   Auclair, D
AF Griffon, Sebastien
   Nespoulous, Amelie
   Cheylan, Jean-Paul
   Marty, Pascal
   Auclair, Daniel
TI Virtual reality for cultural landscape visualization
SO VIRTUAL REALITY
LA English
DT Article
DE Landscape; Visualization; Computer imagery; 3D modeling; Virtual reality
ID INTEGRATED ASSESSMENT; RURAL LANDSCAPES; VISUAL LANDSCAPE; INDICATORS;
   PERCEPTIONS; VEGETATION; FRAMEWORK; WOODLAND; DYNAMICS; SUPPORT
AB Although land managers and policy-makers generally have a good experience of what result can be expected from their decisions, they are often faced with difficulty when trying to communicate the visual impact of a management option to stakeholders, particularly when the landscape exhibits a high cultural value. Three-dimensional visualization of the landscape is often used for communicating with the stakeholders. A challenge in participatory methods for integrated assessment and policy planning is to view future changes in land use, according to scenarios. A 3-D landscape visualization component, SLE ("Seamless Landscape Explorer"), has been developed, which is launched after a scenario simulation to allow for exploration of landscape changes. Pressures causing such changes are translated into changes in the spatial configuration of the landscape. The different types of land-use are visualized thanks to a library of detailed textures, and vegetation can be added. This has been applied to a study of four scenarios in the French Mediterranean region, which were set up as part of a participatory process for discussing the planning of the regional peri-urban and agricultural policy, in an area dominated by the typical culturally sensitive Mediterranean matorral, ("garrigue" shrubland) surrounding the Pic Saint-Loup mountain. Examples of visualization are shown and discussed here.
C1 [Auclair, Daniel] INRA, UMR AMAP BotAn & BioinforMat Architecture Plantes, F-34398 Montpellier 5, France.
   [Griffon, Sebastien] INRA, UMR AMAP, F-34000 Montpellier, France.
   [Nespoulous, Amelie] CNRS, UMR ESPACE, F-34000 Montpellier, France.
   [Cheylan, Jean-Paul] CNRS, UMR ESPACE, F-84000 Avignon, France.
   [Cheylan, Jean-Paul] CIRAD ES, F-34000 Montpellier, France.
   [Marty, Pascal] CNRS, UMR CEFE, F-34000 Montpellier, France.
   [Marty, Pascal] CEFRES, USR, CNRS MAEE 3138, Prague 12800, Czech Republic.
C3 INRAE; CIRAD; Centre National de la Recherche Scientifique (CNRS);
   Institut de Recherche pour le Developpement (IRD); Universite de
   Montpellier; INRAE; CIRAD; Centre National de la Recherche Scientifique
   (CNRS); Institut de Recherche pour le Developpement (IRD); Universite de
   Montpellier; Centre National de la Recherche Scientifique (CNRS);
   Aix-Marseille Universite; Centre National de la Recherche Scientifique
   (CNRS); CIRAD; Universite PSL; Ecole Pratique des Hautes Etudes (EPHE);
   Institut Agro; Montpellier SupAgro; CIRAD; Centre National de la
   Recherche Scientifique (CNRS); Institut de Recherche pour le
   Developpement (IRD); Universite Paul-Valery; Universite de Montpellier
RP Auclair, D (corresponding author), INRA, UMR AMAP BotAn & BioinforMat Architecture Plantes, TA A-51,PS2 Bd Lironde, F-34398 Montpellier 5, France.
EM auclair@cirad.fr
OI Marty, Pascal/0000-0003-3040-464X
FU French ministry of Ecology and Sustainable Development; EU [010036-2]
FX The SLE software was developed within the SEAMLESS integrated project,
   EU 6th Framework Programme for Research Technological Development and
   Demonstration, Priority 1.1.6.3. Global Change and Ecosystems (European
   Commission, DG Research, contract no. 010036-2). The scenario building
   was done within the research action "Paysage et biodiversite: evaluation
   participative de la durabilite des strategies de gestion" funded by the
   "Landscape and sustainable development" (PDD- Paysage et developpement
   durable) programme from the French ministry of Ecology and Sustainable
   Development. The co-construction and the evaluation of the scenarios and
   results were done in close connection with the "Ecologistes de
   l'Euziere" association (http://www.euziere.org/), and the paintings were
   made by John Walsh.
CR AITCHINSON J, 1995, CULTURAL LANDSCAPES, P272
   [Anonymous], 2005, GEOCARREFOUR, DOI 10.4000/geocarrefour.1031
   Appleton K., 2005, Computers, Environment and Urban Systems, V29, P321, DOI 10.1016/j.compenvurbsys.2004.05.005
   Appleton K., 2002, Computers, Environment and Urban Systems, V26, P141, DOI 10.1016/S0198-9715(01)00041-2
   Appleton K, 2003, LANDSCAPE URBAN PLAN, V65, P117, DOI 10.1016/S0169-2046(02)00245-1
   Auclair D., 2001, Landscape Research, V26, P397, DOI 10.1080/01426390120090166
   Auclair D, 2001, EUR FOREST INST PROC, P207
   Bell S, 2001, LANDSCAPE URBAN PLAN, V54, P201, DOI 10.1016/S0169-2046(01)00136-0
   BERGEN SD, 1995, J FOREST, V93, P33
   Bishop ID, 2009, LAND USE POLICY, V26, P87, DOI 10.1016/j.landusepol.2008.01.010
   Bishop ID, 2005, ENVIRON MODELL SOFTW, V20, P1459, DOI 10.1016/j.envsoft.2004.06.014
   Bishop ID, 2001, LANDSCAPE URBAN PLAN, V52, P225, DOI 10.1016/S0169-2046(00)00118-3
   Bloom Charles., 2000, Terrain Texture Compositing by Blending in the Frame-Buffer from
   Buscher M., 2001, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V10, P1, DOI 10.1023/A:1011293210539
   Caplat P, 2006, LANDSCAPE ECOL, V21, P657, DOI 10.1007/s10980-005-4430-1
   CARTWRIGHT W, 2008, LANDSCAPE ANAL VISUA, P490
   CHEYLAN JP, 2002, METHODES OUTILS EVAL, P13
   COURNEDE PH, 2009, PMA09
   DANAHY JW, 1989, P CAAD FUT 89 EL DES, P363
   DANIEL TC, 1992, LANDSCAPE URBAN PLAN, V21, P261, DOI 10.1016/0169-2046(92)90036-Y
   Daniel TC, 2001, LANDSCAPE URBAN PLAN, V54, P267, DOI 10.1016/S0169-2046(01)00141-4
   Day AM, 2005, COMPUT GRAPH-UK, V29, P109, DOI 10.1016/j.cag.2004.11.011
   De Boer W., 2000, FAST TERRAIN RENDERI
   Debussche M, 1999, GLOBAL ECOL BIOGEOGR, V8, P3, DOI 10.1046/j.1365-2699.1999.00316.x
   DENG Q, 2009, COMPUT ANIMAT VIRTUA, V20, P1
   Dockerty T., 2005, Computers, Environment and Urban Systems, V29, P297, DOI 10.1016/j.compenvurbsys.2004.05.004
   Ervin S. M., 2001, LANDSCAPE MODELLING
   Frouws J, 1998, SOCIOL RURALIS, V38, P54, DOI 10.1111/1467-9523.00063
   Gardner RH, 2007, LANDSCAPE ECOL, V22, P15, DOI 10.1007/s10980-006-9011-4
   Gaucherel C, 2006, ECOL MODEL, V197, P159, DOI 10.1016/j.ecolmodel.2006.02.044
   Ghadirian P, 2008, LANDSCAPE URBAN PLAN, V86, P226, DOI 10.1016/j.landurbplan.2008.03.004
   Gobster PH, 2007, LANDSCAPE ECOL, V22, P959, DOI 10.1007/s10980-007-9110-x
   Griffon S, 2010, ENVIRONMENTAL AND AGRICULTURAL MODELLING: INTEGRATED APPROACHES FOR POLICY IMPACT ASSESSMENT, P133, DOI 10.1007/978-90-481-3619-3_6
   Hazen G, 2010, ENVIRONMENTAL AND AGRICULTURAL MODELLING: INTEGRATED APPROACHES FOR POLICY IMPACT ASSESSMENT, P159, DOI 10.1007/978-90-481-3619-3_7
   HERWIG A, 2002, P ANH U APPL SCI TRE, P162
   Iacucci G, 2003, ECSCW 2003: PROCEEDINGS OF THE EIGHTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P139
   Lange E, 2001, LANDSCAPE URBAN PLAN, V54, P163, DOI 10.1016/S0169-2046(01)00134-7
   Lange E, 2001, LANDSCAPE URBAN PLAN, V54, P1, DOI 10.1016/S0169-2046(01)00121-9
   Lange E, 2008, J ENVIRON MANAGE, V89, P245, DOI 10.1016/j.jenvman.2007.01.061
   Le Ber F, 2006, ECOL MODEL, V191, P170, DOI 10.1016/j.ecolmodel.2005.08.031
   LEBER F, 2010, LANDMOD 2010
   LEPART J, 1992, SPRINGER ECOLOGICAL, V92, P76
   Lovett A., 2005, COMPUT ENVIRON URBAN, V29, P249
   LOVETT A, 2001, VIRTUAL REALITY GEOG, P102
   MacFarlane R., 2005, Computers, Environment and Urban Systems, V29, P341, DOI 10.1016/j.compenvurbsys.2004.05.006
   Mander U, 2010, ECOL INDIC, V10, P1, DOI 10.1016/j.ecolind.2009.08.003
   MANSERGH I, 2008, LANDSCAPE ANAL VISUA, P469
   MARTY P, 2010, SOCIAL MOVEMENTS PUB, P131
   Muhar A, 2001, LANDSCAPE URBAN PLAN, V54, P5, DOI 10.1016/S0169-2046(01)00122-0
   NESPOULOUS A, 2004, THESIS U MONTPELLIER
   Nijnik M, 2008, LANDSCAPE URBAN PLAN, V86, P267, DOI 10.1016/j.landurbplan.2008.03.007
   Ode Å, 2010, ECOL INDIC, V10, P24, DOI 10.1016/j.ecolind.2009.02.013
   Ode A, 2009, J ENVIRON MANAGE, V90, P375, DOI 10.1016/j.jenvman.2007.10.013
   Olsson JA, 2009, ENVIRON SCI POLICY, V12, P562, DOI 10.1016/j.envsci.2009.01.012
   Orland B, 2001, LANDSCAPE URBAN PLAN, V54, P139, DOI 10.1016/S0169-2046(01)00132-3
   PAAR P, 2007, REAL CORP 007 PLAN I
   Paar P, 2006, COMPUT ENVIRON URBAN, V30, P815, DOI 10.1016/j.compenvurbsys.2005.07.002
   Perrin L, 2001, LANDSCAPE URBAN PLAN, V54, P33, DOI 10.1016/S0169-2046(01)00124-4
   PETTIT C, 2008, LECT NOTES GEOINFORM, DOI DOI 10.1007/978-3-540-69168-6_25
   Rivas V, 1997, GEOMORPHOLOGY, V18, P169, DOI 10.1016/S0169-555X(96)00024-4
   Salter JD, 2009, J ENVIRON MANAGE, V90, P2090, DOI 10.1016/j.jenvman.2007.08.023
   SAUGET N, 1996, ETUD RECH S, V29, P245
   Savill P., 1997, Plantation silviculture in Europe
   Sheppard S.R.J., 2006, INTEGRATED ASSESSMEN, V6, P79
   Sheppard SRJ, 2005, ENVIRON SCI POLICY, V8, P637, DOI 10.1016/j.envsci.2005.08.002
   SHEPPARD SRJ, 1982, THESIS U CALIFORNIA
   Sheppard SRJ, 2009, J ENVIRON MANAGE, V90, P2102, DOI 10.1016/j.jenvman.2007.09.012
   Sirami C, 2008, ECOGRAPHY, V31, P509, DOI 10.1111/j.0906-7590.2008.05403.x
   Sirami C, 2007, DIVERS DISTRIB, V13, P42, DOI 10.1111/j.1472-4642.2006.00297.x
   Snyder K., 2003, Planning Support Systems in Practice, P99, DOI [10.1007/978-3-540-24795-1_6, DOI 10.1007/978-3-540-24795-1_6]
   Soliva R, 2009, LAND USE POLICY, V26, P284, DOI 10.1016/j.landusepol.2008.03.007
   THOMAS AL, 1999, FARM WOODLANDS FUTUR, P69
   TYRVAINEN L, 2000, 21 IUFRO WORLD C FOR, V1, P338
   van Ittersum MK, 2008, AGR SYST, V96, P150, DOI 10.1016/j.agsy.2007.07.009
   Wissen U, 2008, J ENVIRON MANAGE, V89, P184, DOI 10.1016/j.jenvman.2007.01.062
NR 75
TC 20
Z9 23
U1 0
U2 61
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD NOV
PY 2011
VL 15
IS 4
SI SI
BP 279
EP 294
DI 10.1007/s10055-010-0160-z
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IC
UT WOS:000296280300004
DA 2024-07-18
ER

PT J
AU Bergig, O
   Hagbi, N
   El-Sana, J
   Kedem, K
   Billinghurst, M
AF Bergig, Oriel
   Hagbi, Nate
   El-Sana, Jihad
   Kedem, Klara
   Billinghurst, Mark
TI In-Place Augmented Reality
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented Reality content; Content transmission; Model embedding; Dual
   perception encoding; In-Place Augmented Reality
AB In this paper, we present a vision-based approach for transmitting virtual models for Augmented Reality, which we name In-Place Augmented Reality (IPAR). A two-dimensional representation of the virtual models is embedded in a printed image. We apply computer vision techniques to interpret the printed image and extract the virtual models, which are then overlaid on the printed image. The main advantages of our approach are: (1) the image of the embedded virtual models and their behaviors are understandable to a human without using an AR system and (2) no database or network communication is required to retrieve the models. To demonstrate the technology and test its usability, we implemented several applications and performed a user evaluation. We discuss how the proposed technique can be used for the development of applications in different domains such as education, advertisement, and gaming.
C1 [Bergig, Oriel; Hagbi, Nate; El-Sana, Jihad; Kedem, Klara] Ben Gurion Univ Negev, Visual Media Lab, IL-84105 Beer Sheva, Israel.
   [Billinghurst, Mark] Univ Canterbury, HIT Lab NZ, Christchurch 1, New Zealand.
C3 Ben Gurion University; University of Canterbury
RP Bergig, O (corresponding author), Ben Gurion Univ Negev, Visual Media Lab, IL-84105 Beer Sheva, Israel.
EM bergig@cs.bgu.ac.il; natios@cs.bgu.ac.il; el-sana@cs.bgu.ac.il;
   klara@cs.bgu.ac.il; mark.billinghurst@hitlabnz.org
RI Billinghurst, Mark/AAJ-4236-2020
OI Billinghurst, Mark/0000-0003-4172-6759
FU Lynn and William Frankel Center for Computer Sciences
FX We would like to thank the reviewers for their constructive comments.
   This work was supported by the Lynn and William Frankel Center for
   Computer Sciences.
CR [Anonymous], 2000, P DARE 2000 DES AUGM
   Davis R, 2007, COMPUTER, V40, P34, DOI 10.1109/MC.2007.324
   Fiala M., 2004, ARTAG IMPROVED MARKE
   Hagbi N, 2008, INT SYM MIX AUGMENT, P135, DOI 10.1109/ISMAR.2008.4637339
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Kato H., 1999, 2 INT WORKSH AUGM RE
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Landay JA, 2001, COMPUTER, V34, P56, DOI 10.1109/2.910894
   Langlotz T, 2007, LECT NOTES COMPUT SC, V4841, P363
   Laviola JJ, 2004, ACM T GRAPHIC, V23, P432, DOI 10.1145/1015706.1015741
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   SAARELMA H, 2005, GRAPHIC ARTS FINLAND, V34, P1
   Shin M, 2005, International Symposium on Mixed and Augmented Reality, Proceedings, P198
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   TSUNGYU L, 2007, COMPUTER INFORM SCI, P5
   1994, DESIGN QR CODE
   2008, STUDIERSTUBE TRACKER
   2001, NINTENDO E READER
NR 18
TC 6
Z9 8
U1 0
U2 18
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 201
EP 212
DI 10.1007/s10055-010-0158-6
PG 12
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200010
DA 2024-07-18
ER

PT J
AU Livingston, MA
   Ai, ZM
   Karsch, K
   Gibson, GO
AF Livingston, Mark A.
   Ai, Zhuming
   Karsch, Kevin
   Gibson, Gregory O.
TI User interface design for military AR applications
SO VIRTUAL REALITY
LA English
DT Article
DE Augmented reality; Mobile systems; User interface; Interaction;
   Evaluation
AB Designing a user interface for military situation awareness presents challenges for managing information in a useful and usable manner. We present an integrated set of functions for the presentation of and interaction with information for a mobile augmented reality application for military applications. Our research has concentrated on four areas. We filter information based on relevance to the user (in turn based on location), evaluate methods for presenting information that represents entities occluded from the user's view, enable interaction through a top-down map view metaphor akin to current techniques used in the military, and facilitate collaboration with other mobile users and/or a command center. In addition, we refined the user interface architecture to conform to requirements from subject matter experts. We discuss the lessons learned in our work and directions for future research.
C1 [Livingston, Mark A.; Ai, Zhuming; Karsch, Kevin; Gibson, Gregory O.] USN, Res Lab, Washington, DC 20375 USA.
C3 United States Department of Defense; United States Navy; Naval Research
   Laboratory
RP Livingston, MA (corresponding author), USN, Res Lab, Washington, DC 20375 USA.
EM mark.livingston@nrl.navy.mil
FU NRL; DARPA [FA8650-09-C-7908]
FX This work was supported in part by the NRL Base Program and in part by
   DARPA under the ULTRA-Vis Program for work as a performing member of the
   Lockheed Martin team, contract # FA8650-09-C-7908.
CR AI Z, 2009, INT S MIX AUGM REAL
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Azuma R, 2006, INT SYM MIX AUGMENT, P13
   BAJURA M, 1992, COMP GRAPH, V26, P203, DOI 10.1145/142920.134061
   Bane R, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P231, DOI 10.1109/ISMAR.2004.36
   BENFORD S, 1993, P ECSCW 93
   BOLSTAD CA, 2002, TOOLS SUPPORTING TEA
   Cutting JE, 2003, LOOKING INTO PICTURES, P215
   DISA Standards Management Branch, 2008, DEP DEF INT STAND CO
   Feiner S, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P74, DOI 10.1109/ISWC.1997.629922
   Feiner S. K., 1992, Visual Computer, V8, P292, DOI 10.1007/BF01897116
   FURNESS LTA, 1969, P S IM DISPL REC
   Höllerer T, 1999, COMPUT GRAPH-UK, V23, P779, DOI 10.1016/S0097-8493(99)00103-X
   Julier S, 2002, IEEE COMPUT GRAPH, V22, P12, DOI 10.1109/MCG.2002.1028721
   Julier S., 2003, WORKSH SOFTW TECHN A
   Livingston M.A., 2006, NATO HUM FACT MED PA
   Livingston MA, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P56, DOI 10.1109/ISMAR.2003.1240688
   Piekarski W., 2002, Third Australasian conference on User interfaces, P61
   Sandor C, 2007, EMERGING TECHNOLOGIES OF AUGMENTED REALITY: INTERFACES AND DESIGN, P218
   Tsuda T, 2006, IEICE T INF SYST, VE89D, P1781, DOI 10.1093/ietisy/e89-d.6.1781
NR 20
TC 29
Z9 33
U1 2
U2 46
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD JUN
PY 2011
VL 15
IS 2-3
SI SI
BP 175
EP 184
DI 10.1007/s10055-010-0179-1
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA 838IB
UT WOS:000296280200008
OA Green Submitted
DA 2024-07-18
ER

PT B
AU Kamieth, F
   Dähne, P
   Wichert, R
   Villalar, JL
   Jimenez-Mixco, V
   Arca, A
   Arredondo, MT
AF Kamieth, Felix
   Daehne, Patrick
   Wichert, Reiner
   Luis Villalar, Juan
   Jimenez-Mixco, Viveca
   Arca, Antonella
   Teresa Arredondo, Maria
BE Kim, JJ
TI Exploring the Potential of Virtual Reality for the Elderly and People
   with Disabilities
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
C1 [Kamieth, Felix; Daehne, Patrick; Wichert, Reiner] Fraunhofer Inst Comp Graph Res IGD Fh IGD, Darmstadt, Germany.
   [Luis Villalar, Juan; Jimenez-Mixco, Viveca; Arca, Antonella; Teresa Arredondo, Maria] Tech Univ Madrid LST UPM, Life Supporting Technol, Madrid, Spain.
C3 Fraunhofer Gesellschaft
RP Kamieth, F (corresponding author), Fraunhofer Inst Comp Graph Res IGD Fh IGD, Darmstadt, Germany.
RI Waldmeyer, María Teresa Arredondo/AAQ-1497-2021
OI Waldmeyer, María Teresa Arredondo/0000-0003-3113-3976
CR Alankus G, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2113
   Arca A., 2009, ADJ P 3 EUR C AMB IN, P259
   Asghar Z., 2009, P 8 INT C MOB UB MUL
   Cabrera-Umpiérrez MF, 2006, CIRCUITS AND SYSTEMS FOR SIGNAL PROCESSING , INFORMATION AND COMMUNICATION TECHNOLOGIES, AND POWER SOURCES AND SYSTEMS, VOL 1 AND 2, PROCEEDINGS, P453, DOI 10.1109/MELCON.2006.1653136
   Cho S. W., 2010, IFMBE P, V29, P722
   Conde-Alvarez E., 2006, P 1 WORKSG TECHN HEA
   Connell B. R., 1997, Principles of Universal Design
   de Ruyter Boris, 2007, Interactions, V14, P30, DOI 10.1145/1273961.1273981
   *ETSI EG, 2008, 202487 ETSI EG
   Fernandez-Llatas C., 2010, IFMBE P 4, V29, P757
   Flores E., 2008, Proceedings of the 2008 International Conference on Advances in Computer Entertainment Technology, P381, DOI DOI 10.1145/1501750.1501839
   Ghedini F., 2008, P 7 ICDVRAT ARTABILI, P185
   Giannakouris K., 2008, Population and social conditions, Data in focus
   Jimenez-Mixco V, 2009, LECT NOTES COMPUT SC, V5615, P75, DOI 10.1007/978-3-642-02710-9_9
   Kamieth F., 2010, AMBIENT ASSISTED LIV
   Kim S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P133
   Lanier J., 1992, P VIRT REAL PERSN DI
   Lanyi C.S., 2006, The International Journal of Virtual Reality, V5, P55
   Lillo J., 2004, ANUARIO PSICOLOGIA, V35, P493
   Mackay H, 2000, SOC STUD SCI, V30, P737, DOI 10.1177/030631200030005004
   Maly J., 2009, ADJ P 3 EUR C AMB IN, P243
   Meisel A. H., 1993, P 1 ANN INT C VIRT R
   Micelli V., 2009, ADJ P 3 EUR C AMB IN, P231
   Middleton T., 1992, P VIRT REAL PERSN DI
   Mocholi J.B., 2010, IFMBE P, P655, DOI DOI 10.1007/978-3-642-13039-7_165
   Naranjo JC, 2009, LECT NOTES COMPUT SC, V5615, P228, DOI 10.1007/978-3-642-02710-9_26
   Nunez D., 2004, P 3 INT C COMPUTER G, V1, P83, DOI DOI 10.1145/1029949.1029964
   Pares Narcis., 2005, P 2005 C INTERACTION, P110, DOI DOI 10.1145/1109540.1109555
   Pithon T., 2009, TECHNOL DISABIL, V21, P1, DOI DOI 10.3233/TAD-2009-0268
   Pittarello F, 2006, P WORK C ADV VIS INT, P364
   Schafer J., 2009, ADJ P 3 EUR C AMB IN, P239
   Schatzlein F., 2009, ADJ P 3 EUR C AMB IN, P235
   Stanney KM, 1998, PRESENCE-TELEOP VIRT, V7, P327, DOI 10.1162/105474698565767
   Steg H., 2006, Europe Is Facing a Demographic Challenge: Ambient Assisted Living Offers Solutions"
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   VAALID, ICT200724309 VAALID
   VERITAS, 247765 VERITAS
   Villalar J. L., 2009, D3 1 AUTHORING ENV F
   Wegge KP, 2007, LECT NOTES COMPUT SC, V4554, P294
   Yalon-Chamovitz S, 2008, RES DEV DISABIL, V29, P273, DOI 10.1016/j.ridd.2007.05.004
NR 40
TC 2
Z9 2
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 395
EP 418
D2 10.5772/553
PG 24
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400019
DA 2024-07-18
ER

PT B
AU Sampaio, AZ
   Cruz, CO
   Martins, OP
AF Sampaio, Alcinia Z.
   Cruz, Carlos O.
   Martins, Octavio P.
BE Kim, JJ
TI Didactic Models in Civil Engineering Education: Virtual Simulation of
   Construction Works
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
C1 [Sampaio, Alcinia Z.; Cruz, Carlos O.; Martins, Octavio P.] Univ Tecn Lisboa, Dept Civil Engn & Architecture, Lisbon, Portugal.
C3 Universidade de Lisboa
RP Sampaio, AZ (corresponding author), Univ Tecn Lisboa, Dept Civil Engn & Architecture, Lisbon, Portugal.
RI Cruz, Carlos Oliveira/H-7921-2013; Sampaio, Alcínia Z./M-5777-2013;
   Sampaio, Zita/ABA-5067-2020
OI Cruz, Carlos Oliveira/0000-0003-2910-5298; Sampaio, Alcínia
   Z./0000-0002-8992-9603; 
CR [Anonymous], 2003, 4D CAD VISUALIZATION
   Aung W., 2006, INNOVATIONS 2006 INE, P397
   Duarte Jose, 2007, 24 ECAADE C ED COMP, P423
   EON, 2009, INTR WORK EON STUD
   FISCHER M, 2000, 4D CAD 3D MODELS INC
   Fischer M., 2004, 156 STANF U CIFE CTR
   Gibbon G. J., 2008, P ICEE 2008 CD ROM 5
   Gomes C., 2004, P INT C ED INN TECHN, P82
   Khanzode A., 2007, Proceedings of CIB 24th W78 Conference, P205
   Martins O, 2009, LECT NOTES COMPUT SC, V5738, P329, DOI 10.1007/978-3-642-04265-2_50
   Ozvoldova M., 2006, INNOVATIONS 2006, P297
   Petzold F., 2007, P ECAADE 07 25 C ED, P161
   Safigianni A.S., 2008, INNOVATIONS 2008 INE, P379
   Sampaio A., 2006, PROC M ICTE, V4, P1351
   Sampaio A., 2009, P IRF2009 3 INT C IN, P221
   Sampaio A. Z., 2009, P IADIS INT C E SOC, P284
   Sampaio A. Z., 2007, P ECAADE 07 25 C ED, P85
   Sampaio AZ, 2008, WSCG 2008, FULL PAPERS, P143
NR 18
TC 1
Z9 1
U1 0
U2 3
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 579
EP 598
D2 10.5772/553
PG 20
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400029
DA 2024-07-18
ER

PT B
AU Yabuki, N
AF Yabuki, Nobuyoshi
BE Kim, JJ
TI Application of Augmented Reality to Evaluate Invisible Height for
   Landscape Preservation
SO VIRTUAL REALITY
LA English
DT Article; Book Chapter
C1 [Yabuki, Nobuyoshi] Osaka Univ, Suita, Osaka 565, Japan.
C3 Osaka University
RP Yabuki, N (corresponding author), Osaka Univ, Suita, Osaka 565, Japan.
CR Abawi D. F., 2004, P 3 IEEE ACM INT S M
   [Anonymous], 2009, P 2009 ASCE INT WORK, DOI DOI 10.1061/41052(346)6
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Dawood N., 2009, P 9 INT C CONSTR APP, P217
   Higuchi Tadahiko., 1988, VISUAL SPATIAL STRUC
   HOLLERER T., 1997, ISWC 97, P208, DOI DOI 10.1007/BF01682023
   Jiang BL, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P97, DOI 10.1109/ISAR.2001.970519
   Kameda Y., 2004, P 3 IEEE ACM INT S M
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Lin Z., 2005, DIGITAL TERRAIN MODE
   Ota N., 2010, P INT C COMP CIV BUI
   Reitmayr Gerhard, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P109, DOI 10.1109/ISMAR.2006.297801
   Shin DH, 2009, AUTOMAT CONSTR, V18, P118, DOI 10.1016/j.autcon.2008.05.007
   Soubra S., 2008, P 8 INT C CONSTR APP, P42
   Steinbis J, 2008, INT SYM MIX AUGMENT, P183, DOI 10.1109/ISMAR.2008.4637357
   Thomas B, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P168, DOI 10.1109/ISWC.1998.729549
   Wang R, 2009, LECT NOTES COMPUT SC, V5738, P333, DOI 10.1007/978-3-642-04265-2_51
   Yabuki N, 2009, P 2009 INT WORKSH CO, P495
   Yabuki N, 2007, LECT NOTES COMPUT SC, V4674, P50
   You SY, 1999, IEEE COMPUT GRAPH, V19, P36, DOI 10.1109/38.799738
NR 20
TC 0
Z9 0
U1 0
U2 1
PU INTECH EUROPE
PI RIJEKA
PA JANEZA TRDINE9, RIJEKA, 51000, CROATIA
BN 978-953-307-518-1
PY 2011
BP 599
EP 614
D2 10.5772/553
PG 16
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BE6ZB
UT WOS:000374970400030
DA 2024-07-18
ER

PT J
AU Wallach, HS
   Safir, MP
   Samana, R
AF Wallach, Helene S.
   Safir, Marilyn P.
   Samana, Roy
TI Personality variables and presence
SO VIRTUAL REALITY
LA English
DT Article
DE Presence; Locus of control; Empathy; Immersion; Imagination;
   Dissociation; Virtual reality; Ethnicity; Gender
ID VIRTUAL ENVIRONMENTS; EXTERNAL CONTROL; IMAGINATION; IMAGERY; LOCUS;
   DISSOCIATION; RELIABILITY; IMMERSION; VIVIDNESS; VALIDITY
AB The present study was designed to examine the correlation between five personality traits (empathy, imagination, immersive tendencies, dissociation tendencies and locus of control) and presence. Moreover, this study aimed to identify an optimal virtual reality user's profile. Eighty-four students (66 women, 18 men) completed personality questionnaires, experienced exposure in a virtual environment and completed a presence questionnaire. Twenty-three women, among them 13 non-Jewish women and no men, neglected to look out the virtual window, and reported lower levels of presence. Presence correlated with immersive tendencies and empathy. However, empathy and internal locus of control were the best predictors for the sense of presence. A correlation between imagination and presence was only found in the group that avoided viewing the virtual window. This study revealed the importance of empathy and internal locus of control in the sense of presence. In addition, our findings suggest that the subject's imagination has an important role when the virtual environment is restricted and that we must attend to cultural and gender-related factors when investigating therapy using virtual reality technology.
C1 [Wallach, Helene S.; Safir, Marilyn P.; Samana, Roy] Univ Haifa, Dept Psychol, IL-31905 Haifa, Israel.
C3 University of Haifa
RP Wallach, HS (corresponding author), Univ Haifa, Dept Psychol, IL-31905 Haifa, Israel.
EM helenwa@yahoo.com; marilyn.safir@gmail.com; roys1@netvision.net.il
CR [Anonymous], VIRTUAL ENV 2000
   BANOS R, 1999, CYBERPSYCHOLOGY BEHA, V2, P135, DOI DOI 10.1518/001872098779591386
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   BARBER TX, 1979, AM J CLIN HYPN, V21, P84
   BERNSTEIN EM, 1986, J NERV MENT DIS, V174, P727, DOI 10.1097/00005053-198612000-00004
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Carlson E.B., 1993, Dissociation, V6, P16
   Davis M. H., 1994, Empathy: a social psychological approach
   Davis M. H., 1980, JSAS CATALOG SELECTE, V10, P85, DOI DOI 10.1037/0022-3514.44.1.113
   FRANKLE Y, 1968, HEBREW TRANSLA UNPUB
   Hair M, 2007, COMPUT HUM BEHAV, V23, P2791, DOI 10.1016/j.chb.2006.05.005
   Hecht D, 2007, CYBERPSYCHOL BEHAV, V10, P243, DOI 10.1089/cpb.2006.9962
   HERSCH PD, 1967, J CONSULT PSYCHOL, V31, P609, DOI 10.1037/h0025154
   Jacobson D, 2001, CYBERPSYCHOL BEHAV, V4, P653, DOI 10.1089/109493101753376605
   Jacobson D., 2002, J VIRTUAL ENV, V6, P1
   JACQUITH L, 1996, CONT HYPN, V13, P94
   Jurnet IA, 2005, P 8 INT WORKSH PRES
   Kaber DB, 2002, HUM FAC ER, P379
   KIZONY R, 2006, THESIS HEBREW U JERU
   Laarni J., 2004, P 7 ANN INT WORKSHOP, P88
   Laidlaw T.M., 1997, Contemporary Hypnosis, V14, P26, DOI [10.1002/ch.80, DOI 10.1002/CH.80]
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lefcourt H.M., 1982, LOCUS CONTROL CURREN, V2nd
   Murray CD, 2007, COMPUT HUM BEHAV, V23, P1347, DOI 10.1016/j.chb.2004.12.010
   Myers I.B., 1998, MANUAL GUIDE DEV USE, V3rd
   NEWMAN K, 2005, COMPUT ENTERTAIN, V3, P4
   Nicovich SG, 2005, J COMPUT-MEDIAT COMM, V10
   Pham MT, 2001, ORGAN BEHAV HUM DEC, V84, P226, DOI 10.1006/obhd.2000.2924
   Ravaja N., 2004, Proceedings of the Third Nordic Conference on Human-Computer Interaction: Nordic Conference on Human-Computer Interaction; Tampere, Finland, V82, P339
   Robillard G, 2003, CYBERPSYCHOL BEHAV, V6, P467, DOI 10.1089/109493103769710497
   Rothbaum BO, 2006, BEHAV THER, V37, P80, DOI 10.1016/j.beth.2005.04.004
   ROTTER JB, 1966, PSYCHOL MONOGR, V80, P1, DOI 10.1037/h0092976
   Sacau A., 2005, 8 INT WORKSHOP PRESE, P143
   Sacau A, 2008, COMPUT HUM BEHAV, V24, P2255, DOI 10.1016/j.chb.2007.11.001
   Sack AT, 2005, SCHIZOPHRENIA BULL, V31, P97, DOI 10.1093/schbul/sbi011
   Sas C., 2004, Cognition, Technology & Work, V6, P53, DOI 10.1007/s10111-003-0145-8
   Sas C, 2003, PRESENCE-TELEOP VIRT, V12, P523, DOI 10.1162/105474603322761315
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   SCHWEITZER Y, 1976, THESIS B ILAN U RAMA
   Shamay-Tsoory SG, 2003, J COGNITIVE NEUROSCI, V15, P324, DOI 10.1162/089892903321593063
   SHEEHAN PW, 1967, J CLIN PSYCHOL, V23, P386, DOI 10.1002/1097-4679(196707)23:3<386::AID-JCLP2270230328>3.0.CO;2-S
   Sherer PP, 2008, INT J INTERCULT REL, V32, P17, DOI 10.1016/j.ijintrel.2007.09.002
   SINGER MJ, 1996, PRESENCE ME IN PRESS
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Somer E., 2001, Journal of Trauma Dissociation, V2, P53, DOI DOI 10.1300/J229V02N02_05
   Somer E., 2003, J SOC WORK PRACT ADD, V3, P25, DOI DOI 10.1300/J160v03n01_03
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   SUN J, 2005, THESIS U A M TEXAS
   Taylor CM, 2006, SA J IND PSYCHOL, V32, P63
   Thomas NJT, 1999, COGNITIVE SCI, V23, P207, DOI 10.1207/s15516709cog2302_3
   VALECHA GK, 1974, J PERS ASSESS, V38, P369, DOI 10.1080/00223891.1974.10119987
   WEBSTER J, 1992, MIS QUART, V16, P201, DOI 10.2307/249576
   Wickramasekera IE, 2003, INT J CLIN EXP HYP, V51, P390, DOI 10.1076/iceh.51.4.390.16413
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yu C. K., 2005, CONT HYPNOSIS, V22, P77, DOI DOI 10.1002/CH.26
NR 56
TC 52
Z9 59
U1 4
U2 42
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1359-4338
EI 1434-9957
J9 VIRTUAL REAL-LONDON
JI Virtual Real.
PD MAR
PY 2010
VL 14
IS 1
SI SI
BP 3
EP 13
DI 10.1007/s10055-009-0124-3
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Imaging Science & Photographic Technology
GA 838HU
UT WOS:000296279400002
DA 2024-07-18
ER

EF